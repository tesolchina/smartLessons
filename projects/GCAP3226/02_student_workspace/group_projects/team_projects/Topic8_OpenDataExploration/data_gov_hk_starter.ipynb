{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bf22677",
   "metadata": {},
   "source": [
    "# Data.gov.hk Web Crawling and API Access Starter Notebook\n",
    "\n",
    "## üéØ Project Objective\n",
    "This notebook helps you explore data.gov.hk to find datasets suitable for:\n",
    "- **Regression analysis** or **simulation modeling**\n",
    "- Connection to specific **government policy or decision**\n",
    "- **Data governance improvement** recommendations\n",
    "\n",
    "## üìã Team Requirements\n",
    "Your team must:\n",
    "1. **Be patient** - systematically explore multiple datasets\n",
    "2. **Select one specific dataset** connected to government policy\n",
    "3. **Choose modeling approach:**\n",
    "   - If data supports it: regression/simulation analysis\n",
    "   - If descriptive only: data governance improvement recommendations\n",
    "\n",
    "## üåü Why This Topic?\n",
    "- **More versatile and open-ended** than other topics\n",
    "- **Maximum flexibility** for creative exploration\n",
    "- **Exciting with some uncertainty** - perfect for adventurous teams!\n",
    "- **No prior foundation** - you're building something completely new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca207ef9",
   "metadata": {},
   "source": [
    "## Please note that the codes and instructions are generated by AI and could be wrong. Please consult AI to revise and adapt and seek help from your human teachers if needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c21ae1",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Setup: Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cd7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install requests beautifulsoup4 pandas matplotlib seaborn plotly lxml openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18d119a",
   "metadata": {},
   "source": [
    "## üìö Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db10b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üìÖ Notebook initialized on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24279fce",
   "metadata": {},
   "source": [
    "# üîç Phase 1: Discover Available Datasets\n",
    "\n",
    "## Step 1: Explore Data.gov.hk Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e868355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape data.gov.hk main categories\n",
    "def explore_data_gov_categories():\n",
    "    \"\"\"\n",
    "    Scrape the main categories from data.gov.hk\n",
    "    \"\"\"\n",
    "    base_url = \"https://data.gov.hk/en/\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        print(\"üåê Successfully connected to data.gov.hk!\")\n",
    "        print(f\"üìÑ Page title: {soup.title.string if soup.title else 'No title found'}\")\n",
    "        \n",
    "        # Look for category links or sections\n",
    "        categories = []\n",
    "        \n",
    "        # Try to find navigation or category sections\n",
    "        nav_links = soup.find_all('a', href=True)\n",
    "        for link in nav_links[:20]:  # Limit to first 20 for exploration\n",
    "            if 'dataset' in link.get('href', '').lower():\n",
    "                categories.append({\n",
    "                    'text': link.get_text(strip=True),\n",
    "                    'href': link.get('href')\n",
    "                })\n",
    "        \n",
    "        return categories\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"‚ùå Error connecting to data.gov.hk: {e}\")\n",
    "        return []\n",
    "\n",
    "# Explore categories\n",
    "categories = explore_data_gov_categories()\n",
    "print(f\"\\nüìä Found {len(categories)} potential category links:\")\n",
    "for i, cat in enumerate(categories[:10], 1):\n",
    "    print(f\"{i}. {cat['text'][:50]}... -> {cat['href'][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02436d3",
   "metadata": {},
   "source": [
    "## Step 2: Access Data.gov.hk API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dd20d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data.gov.hk API exploration\n",
    "def explore_data_gov_api():\n",
    "    \"\"\"\n",
    "    Explore the data.gov.hk API to find available datasets\n",
    "    \"\"\"\n",
    "    # Common API endpoints to try\n",
    "    api_endpoints = [\n",
    "        \"https://api.data.gov.hk/v1/datasets\",\n",
    "        \"https://data.gov.hk/api/\",\n",
    "        \"https://data.gov.hk/en/help/api-spec\"\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for endpoint in api_endpoints:\n",
    "        try:\n",
    "            print(f\"üîç Trying endpoint: {endpoint}\")\n",
    "            response = requests.get(endpoint, timeout=10)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                print(f\"‚úÖ Success! Status: {response.status_code}\")\n",
    "                \n",
    "                # Try to parse as JSON first\n",
    "                try:\n",
    "                    data = response.json()\n",
    "                    results[endpoint] = {\n",
    "                        'type': 'json',\n",
    "                        'data': data,\n",
    "                        'keys': list(data.keys()) if isinstance(data, dict) else 'list',\n",
    "                        'length': len(data) if isinstance(data, (list, dict)) else 'unknown'\n",
    "                    }\n",
    "                    print(f\"üìÑ JSON response with {len(data) if isinstance(data, (list, dict)) else 'unknown'} items\")\n",
    "                except json.JSONDecodeError:\n",
    "                    # If not JSON, treat as HTML/text\n",
    "                    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                    results[endpoint] = {\n",
    "                        'type': 'html',\n",
    "                        'title': soup.title.string if soup.title else 'No title',\n",
    "                        'content_length': len(response.text)\n",
    "                    }\n",
    "                    print(f\"üìÑ HTML response ({len(response.text)} chars)\")\n",
    "            else:\n",
    "                print(f\"‚ùå Failed: Status {response.status_code}\")\n",
    "                \n",
    "        except requests.RequestException as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "        time.sleep(1)  # Be respectful to the server\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Explore API endpoints\n",
    "api_results = explore_data_gov_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5976e971",
   "metadata": {},
   "source": [
    "## Step 3: Manual Dataset Categories\n",
    "\n",
    "Based on typical data.gov.hk structure, here are key categories to explore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa59bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define key dataset categories for systematic exploration\n",
    "dataset_categories = {\n",
    "    \"üöå Transport\": {\n",
    "        \"description\": \"Traffic patterns, public transport, road safety\",\n",
    "        \"policy_connection\": \"Transport policy, infrastructure planning\",\n",
    "        \"modeling_potential\": \"High - time series, regression analysis\",\n",
    "        \"examples\": [\"Bus route usage\", \"Traffic accident data\", \"MTR ridership\", \"Parking space utilization\"]\n",
    "    },\n",
    "    \"üå± Environment\": {\n",
    "        \"description\": \"Air quality, waste management, energy\",\n",
    "        \"policy_connection\": \"Environmental protection, sustainability\",\n",
    "        \"modeling_potential\": \"High - correlation analysis, trend prediction\",\n",
    "        \"examples\": [\"Air pollution indices\", \"Waste collection data\", \"Energy consumption\", \"Weather patterns\"]\n",
    "    },\n",
    "    \"üè• Health\": {\n",
    "        \"description\": \"Disease surveillance, healthcare utilization\",\n",
    "        \"policy_connection\": \"Public health policy, resource allocation\",\n",
    "        \"modeling_potential\": \"Medium-High - epidemiological modeling\",\n",
    "        \"examples\": [\"Infectious disease cases\", \"Hospital bed occupancy\", \"Vaccination rates\", \"Health expenditure\"]\n",
    "    },\n",
    "    \"üéì Education\": {\n",
    "        \"description\": \"School performance, enrollment, resources\",\n",
    "        \"policy_connection\": \"Education policy, funding allocation\",\n",
    "        \"modeling_potential\": \"Medium - performance analysis\",\n",
    "        \"examples\": [\"School enrollment\", \"Academic performance\", \"Teacher-student ratios\", \"Education spending\"]\n",
    "    },\n",
    "    \"üè† Housing\": {\n",
    "        \"description\": \"Property prices, public housing, development\",\n",
    "        \"policy_connection\": \"Housing policy, urban planning\",\n",
    "        \"modeling_potential\": \"High - price prediction, demand modeling\",\n",
    "        \"examples\": [\"Property transactions\", \"Public housing waiting times\", \"Construction permits\", \"Rental prices\"]\n",
    "    },\n",
    "    \"üíº Economy\": {\n",
    "        \"description\": \"Business licenses, employment, tourism\",\n",
    "        \"policy_connection\": \"Economic development, business regulation\",\n",
    "        \"modeling_potential\": \"High - economic indicator modeling\",\n",
    "        \"examples\": [\"Business registrations\", \"Employment rates\", \"Tourism arrivals\", \"GDP indicators\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display categories with modeling potential\n",
    "print(\"üéØ DATASET CATEGORIES FOR SYSTEMATIC EXPLORATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for category, info in dataset_categories.items():\n",
    "    print(f\"\\n{category}\")\n",
    "    print(f\"üìù Description: {info['description']}\")\n",
    "    print(f\"üèõÔ∏è Policy Connection: {info['policy_connection']}\")\n",
    "    print(f\"üìä Modeling Potential: {info['modeling_potential']}\")\n",
    "    print(f\"üí° Examples: {', '.join(info['examples'][:2])}...\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1815d70",
   "metadata": {},
   "source": [
    "# üî¨ Phase 2: Dataset Selection Framework\n",
    "\n",
    "## Step 4: Dataset Evaluation Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3c76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset evaluation framework\n",
    "def evaluate_dataset_potential(dataset_info):\n",
    "    \"\"\"\n",
    "    Evaluate a dataset's potential for regression/simulation analysis\n",
    "    \n",
    "    Returns: dictionary with evaluation scores and recommendations\n",
    "    \"\"\"\n",
    "    evaluation = {\n",
    "        'dataset_name': dataset_info.get('name', 'Unknown'),\n",
    "        'scores': {},\n",
    "        'recommendations': [],\n",
    "        'modeling_approach': None\n",
    "    }\n",
    "    \n",
    "    # Evaluation criteria (1-5 scale)\n",
    "    criteria = {\n",
    "        'data_volume': 'How much data is available? (1=very little, 5=extensive)',\n",
    "        'time_series': 'Does it have temporal dimension? (1=no, 5=rich time series)',\n",
    "        'numerical_variables': 'Are there quantitative variables? (1=mostly categorical, 5=many numerical)',\n",
    "        'policy_relevance': 'How connected to government decisions? (1=weak, 5=direct impact)',\n",
    "        'data_quality': 'How complete and accurate? (1=poor, 5=excellent)',\n",
    "        'update_frequency': 'How often updated? (1=rarely, 5=real-time)'\n",
    "    }\n",
    "    \n",
    "    print(f\"üìä EVALUATING DATASET: {evaluation['dataset_name']}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    total_score = 0\n",
    "    for criterion, description in criteria.items():\n",
    "        print(f\"\\n{criterion.replace('_', ' ').title()}: {description}\")\n",
    "        score = input(f\"Enter score (1-5): \")\n",
    "        try:\n",
    "            score = int(score)\n",
    "            if 1 <= score <= 5:\n",
    "                evaluation['scores'][criterion] = score\n",
    "                total_score += score\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è Invalid score, setting to 3 (neutral)\")\n",
    "                evaluation['scores'][criterion] = 3\n",
    "                total_score += 3\n",
    "        except ValueError:\n",
    "            print(\"‚ö†Ô∏è Invalid input, setting to 3 (neutral)\")\n",
    "            evaluation['scores'][criterion] = 3\n",
    "            total_score += 3\n",
    "    \n",
    "    evaluation['total_score'] = total_score\n",
    "    evaluation['average_score'] = total_score / len(criteria)\n",
    "    \n",
    "    # Generate recommendations based on scores\n",
    "    if evaluation['average_score'] >= 4.0:\n",
    "        evaluation['modeling_approach'] = \"High Potential for Regression/Simulation\"\n",
    "        evaluation['recommendations'].append(\"‚úÖ Excellent candidate for quantitative modeling\")\n",
    "        evaluation['recommendations'].append(\"üéØ Focus on regression analysis or simulation\")\n",
    "    elif evaluation['average_score'] >= 3.0:\n",
    "        evaluation['modeling_approach'] = \"Moderate Potential - Mixed Approach\"\n",
    "        evaluation['recommendations'].append(\"‚ö° Good for basic modeling with governance focus\")\n",
    "        evaluation['recommendations'].append(\"üîÑ Combine simple analysis with governance recommendations\")\n",
    "    else:\n",
    "        evaluation['modeling_approach'] = \"Focus on Data Governance Improvements\"\n",
    "        evaluation['recommendations'].append(\"üîß Emphasize data governance improvement analysis\")\n",
    "        evaluation['recommendations'].append(\"üìã Recommend better data collection/curation practices\")\n",
    "    \n",
    "    return evaluation\n",
    "\n",
    "# Example usage (interactive)\n",
    "print(\"üéØ DATASET EVALUATION FRAMEWORK\")\n",
    "print(\"Use this framework when you find a potential dataset!\")\n",
    "print(\"\\nüìù Instructions:\")\n",
    "print(\"1. Find a dataset on data.gov.hk\")\n",
    "print(\"2. Download sample data\")\n",
    "print(\"3. Run the evaluation function below\")\n",
    "print(\"4. Make decision based on recommendations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f83a1c0",
   "metadata": {},
   "source": [
    "## Step 5: Quick Dataset Download Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a59299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to quickly download and preview datasets\n",
    "def quick_dataset_preview(url, dataset_name=\"Unknown Dataset\"):\n",
    "    \"\"\"\n",
    "    Download and preview a dataset from data.gov.hk\n",
    "    Supports CSV, Excel, and JSON formats\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"üì• Downloading: {dataset_name}\")\n",
    "        print(f\"üîó URL: {url}\")\n",
    "        \n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Determine file type from URL or content type\n",
    "        if url.lower().endswith('.csv') or 'csv' in response.headers.get('content-type', '').lower():\n",
    "            df = pd.read_csv(url)\n",
    "            file_type = \"CSV\"\n",
    "        elif url.lower().endswith(('.xlsx', '.xls')) or 'excel' in response.headers.get('content-type', '').lower():\n",
    "            df = pd.read_excel(url)\n",
    "            file_type = \"Excel\"\n",
    "        elif url.lower().endswith('.json') or 'json' in response.headers.get('content-type', '').lower():\n",
    "            data = response.json()\n",
    "            if isinstance(data, list):\n",
    "                df = pd.DataFrame(data)\n",
    "            else:\n",
    "                df = pd.json_normalize(data)\n",
    "            file_type = \"JSON\"\n",
    "        else:\n",
    "            # Try CSV as default\n",
    "            df = pd.read_csv(url)\n",
    "            file_type = \"CSV (assumed)\"\n",
    "        \n",
    "        print(f\"‚úÖ Successfully loaded {file_type} file!\")\n",
    "        \n",
    "        # Generate preview report\n",
    "        report = {\n",
    "            'dataset_name': dataset_name,\n",
    "            'file_type': file_type,\n",
    "            'shape': df.shape,\n",
    "            'columns': list(df.columns),\n",
    "            'numeric_columns': list(df.select_dtypes(include=['number']).columns),\n",
    "            'datetime_columns': list(df.select_dtypes(include=['datetime']).columns),\n",
    "            'missing_data': df.isnull().sum().sum(),\n",
    "            'sample_data': df.head()\n",
    "        }\n",
    "        \n",
    "        # Display report\n",
    "        print(f\"\\nüìä DATASET PREVIEW REPORT\")\n",
    "        print(\"=\" * 40)\n",
    "        print(f\"üìÅ Dataset: {report['dataset_name']}\")\n",
    "        print(f\"üìÑ Type: {report['file_type']}\")\n",
    "        print(f\"üìè Shape: {report['shape'][0]:,} rows √ó {report['shape'][1]} columns\")\n",
    "        print(f\"üî¢ Numeric columns: {len(report['numeric_columns'])}/{len(report['columns'])}\")\n",
    "        print(f\"üìÖ DateTime columns: {len(report['datetime_columns'])}\")\n",
    "        print(f\"‚ùì Missing values: {report['missing_data']:,}\")\n",
    "        \n",
    "        print(f\"\\nüìã Columns: {', '.join(report['columns'][:5])}{'...' if len(report['columns']) > 5 else ''}\")\n",
    "        \n",
    "        if report['numeric_columns']:\n",
    "            print(f\"üî¢ Numeric: {', '.join(report['numeric_columns'][:5])}{'...' if len(report['numeric_columns']) > 5 else ''}\")\n",
    "        \n",
    "        print(f\"\\nüìã Sample Data:\")\n",
    "        display(report['sample_data'])\n",
    "        \n",
    "        # Modeling potential assessment\n",
    "        modeling_score = 0\n",
    "        if report['shape'][0] > 100: modeling_score += 1\n",
    "        if report['shape'][0] > 1000: modeling_score += 1\n",
    "        if len(report['numeric_columns']) >= 2: modeling_score += 1\n",
    "        if len(report['datetime_columns']) >= 1: modeling_score += 1\n",
    "        if report['missing_data'] / (report['shape'][0] * report['shape'][1]) < 0.1: modeling_score += 1\n",
    "        \n",
    "        print(f\"\\n‚≠ê Modeling Potential Score: {modeling_score}/5\")\n",
    "        \n",
    "        if modeling_score >= 4:\n",
    "            print(\"üéØ HIGH POTENTIAL for regression/simulation analysis!\")\n",
    "        elif modeling_score >= 3:\n",
    "            print(\"‚ö° MODERATE POTENTIAL - consider mixed approach\")\n",
    "        else:\n",
    "            print(\"üîß FOCUS ON DATA GOVERNANCE improvements\")\n",
    "        \n",
    "        return df, report\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading dataset: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Example usage instructions\n",
    "print(\"üîç QUICK DATASET PREVIEW FUNCTION\")\n",
    "print(\"=\"*40)\n",
    "print(\"Usage: df, report = quick_dataset_preview(url, 'Dataset Name')\")\n",
    "print(\"\\nüí° Tips:\")\n",
    "print(\"‚Ä¢ Look for datasets with >1000 rows for better modeling\")\n",
    "print(\"‚Ä¢ Prefer datasets with multiple numeric columns\")\n",
    "print(\"‚Ä¢ Time series data (dates) enable trend analysis\")\n",
    "print(\"‚Ä¢ Low missing data (<10%) is ideal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa825b32",
   "metadata": {},
   "source": [
    "# üìä Phase 3: Example Dataset Exploration\n",
    "\n",
    "## Step 6: Sample Data Analysis Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efe7cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for analyzing any dataset you select\n",
    "def comprehensive_dataset_analysis(df, dataset_name=\"Your Dataset\"):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis template for any dataset\n",
    "    \"\"\"\n",
    "    print(f\"üî¨ COMPREHENSIVE ANALYSIS: {dataset_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Basic Information\n",
    "    print(\"\\n1Ô∏è‚É£ BASIC DATASET INFORMATION\")\n",
    "    print(f\"üìè Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"üíæ Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # 2. Data Types Analysis\n",
    "    print(\"\\n2Ô∏è‚É£ DATA TYPES BREAKDOWN\")\n",
    "    dtype_counts = df.dtypes.value_counts()\n",
    "    for dtype, count in dtype_counts.items():\n",
    "        print(f\"üìä {dtype}: {count} columns\")\n",
    "    \n",
    "    # 3. Missing Data Analysis\n",
    "    print(\"\\n3Ô∏è‚É£ MISSING DATA ANALYSIS\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df)) * 100\n",
    "    missing_summary = pd.DataFrame({\n",
    "        'Missing Count': missing,\n",
    "        'Missing %': missing_pct\n",
    "    })\n",
    "    missing_summary = missing_summary[missing_summary['Missing Count'] > 0].sort_values('Missing %', ascending=False)\n",
    "    \n",
    "    if len(missing_summary) > 0:\n",
    "        print(f\"‚ö†Ô∏è {len(missing_summary)} columns have missing data:\")\n",
    "        display(missing_summary.head(10))\n",
    "    else:\n",
    "        print(\"‚úÖ No missing data found!\")\n",
    "    \n",
    "    # 4. Numeric Variables Analysis\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(f\"\\n4Ô∏è‚É£ NUMERIC VARIABLES ANALYSIS ({len(numeric_cols)} columns)\")\n",
    "        display(df[numeric_cols].describe())\n",
    "        \n",
    "        # Correlation analysis if multiple numeric columns\n",
    "        if len(numeric_cols) > 1:\n",
    "            print(\"\\nüîó CORRELATION MATRIX\")\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            correlation_matrix = df[numeric_cols].corr()\n",
    "            sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "            plt.title(f'Correlation Matrix - {dataset_name}')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    # 5. Categorical Variables Analysis\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    if len(categorical_cols) > 0:\n",
    "        print(f\"\\n5Ô∏è‚É£ CATEGORICAL VARIABLES ANALYSIS ({len(categorical_cols)} columns)\")\n",
    "        for col in categorical_cols[:5]:  # Show first 5 categorical columns\n",
    "            unique_count = df[col].nunique()\n",
    "            print(f\"üìä {col}: {unique_count} unique values\")\n",
    "            if unique_count <= 10:  # Show value counts for small categories\n",
    "                print(df[col].value_counts().head())\n",
    "            print(\"-\" * 30)\n",
    "    \n",
    "    # 6. Time Series Check\n",
    "    print(\"\\n6Ô∏è‚É£ TIME SERIES ANALYSIS\")\n",
    "    date_cols = []\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'datetime64[ns]' or 'date' in col.lower() or 'time' in col.lower():\n",
    "            date_cols.append(col)\n",
    "    \n",
    "    if date_cols:\n",
    "        print(f\"üìÖ Found {len(date_cols)} potential date columns: {date_cols}\")\n",
    "        for col in date_cols[:2]:  # Analyze first 2 date columns\n",
    "            try:\n",
    "                df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "                print(f\"üìä {col}: Range from {df[col].min()} to {df[col].max()}\")\n",
    "            except:\n",
    "                print(f\"‚ö†Ô∏è Could not parse {col} as datetime\")\n",
    "    else:\n",
    "        print(\"‚ùå No clear date/time columns found\")\n",
    "    \n",
    "    # 7. Modeling Recommendations\n",
    "    print(\"\\n7Ô∏è‚É£ MODELING RECOMMENDATIONS\")\n",
    "    recommendations = []\n",
    "    \n",
    "    if len(numeric_cols) >= 3:\n",
    "        recommendations.append(\"‚úÖ REGRESSION ANALYSIS: Multiple numeric variables available\")\n",
    "    \n",
    "    if date_cols and len(numeric_cols) >= 1:\n",
    "        recommendations.append(\"‚úÖ TIME SERIES ANALYSIS: Date columns with numeric targets\")\n",
    "    \n",
    "    if len(categorical_cols) >= 1 and len(numeric_cols) >= 1:\n",
    "        recommendations.append(\"‚úÖ CLASSIFICATION/SEGMENTATION: Mix of categorical and numeric variables\")\n",
    "    \n",
    "    if df.shape[0] >= 1000:\n",
    "        recommendations.append(\"‚úÖ SIMULATION MODELING: Sufficient sample size for robust analysis\")\n",
    "    \n",
    "    if len(recommendations) == 0:\n",
    "        recommendations.append(\"üîß DATA GOVERNANCE FOCUS: Limited quantitative modeling potential\")\n",
    "        recommendations.append(\"üìã Recommend improvements in data collection and curation\")\n",
    "    \n",
    "    for rec in recommendations:\n",
    "        print(rec)\n",
    "    \n",
    "    return {\n",
    "        'numeric_columns': list(numeric_cols),\n",
    "        'categorical_columns': list(categorical_cols),\n",
    "        'date_columns': date_cols,\n",
    "        'missing_data_summary': missing_summary,\n",
    "        'recommendations': recommendations\n",
    "    }\n",
    "\n",
    "# Instructions for use\n",
    "print(\"üéØ COMPREHENSIVE ANALYSIS TEMPLATE\")\n",
    "print(\"Use this after loading your chosen dataset:\")\n",
    "print(\"analysis_results = comprehensive_dataset_analysis(df, 'Your Dataset Name')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c5f138",
   "metadata": {},
   "source": [
    "# üèõÔ∏è Phase 4: Policy Connection Framework\n",
    "\n",
    "## Step 7: Linking Data to Government Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ed294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Framework for connecting datasets to government policy\n",
    "def policy_connection_analysis(dataset_name, data_summary):\n",
    "    \"\"\"\n",
    "    Help identify policy connections for your chosen dataset\n",
    "    \"\"\"\n",
    "    print(f\"üèõÔ∏è POLICY CONNECTION ANALYSIS: {dataset_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Policy areas framework\n",
    "    policy_areas = {\n",
    "        \"üöå Transport Policy\": {\n",
    "            \"keywords\": [\"transport\", \"traffic\", \"bus\", \"mtr\", \"road\", \"parking\", \"vehicle\"],\n",
    "            \"government_depts\": [\"Transport Department\", \"Highways Department\"],\n",
    "            \"decisions\": [\"Route planning\", \"Traffic management\", \"Infrastructure investment\"],\n",
    "            \"metrics\": [\"ridership\", \"accidents\", \"congestion\", \"emissions\"]\n",
    "        },\n",
    "        \"üå± Environmental Policy\": {\n",
    "            \"keywords\": [\"air\", \"pollution\", \"waste\", \"energy\", \"emission\", \"environment\"],\n",
    "            \"government_depts\": [\"Environmental Protection Department\", \"Development Bureau\"],\n",
    "            \"decisions\": [\"Pollution control\", \"Waste management\", \"Conservation measures\"],\n",
    "            \"metrics\": [\"pollution index\", \"waste volume\", \"energy consumption\"]\n",
    "        },\n",
    "        \"üè• Health Policy\": {\n",
    "            \"keywords\": [\"health\", \"hospital\", \"disease\", \"medical\", \"clinic\", \"patient\"],\n",
    "            \"government_depts\": [\"Department of Health\", \"Hospital Authority\"],\n",
    "            \"decisions\": [\"Resource allocation\", \"Service planning\", \"Disease prevention\"],\n",
    "            \"metrics\": [\"bed occupancy\", \"waiting times\", \"infection rates\"]\n",
    "        },\n",
    "        \"üè† Housing Policy\": {\n",
    "            \"keywords\": [\"housing\", \"property\", \"rent\", \"apartment\", \"building\", \"estate\"],\n",
    "            \"government_depts\": [\"Housing Department\", \"Development Bureau\"],\n",
    "            \"decisions\": [\"Public housing allocation\", \"Land use planning\", \"Rent control\"],\n",
    "            \"metrics\": [\"housing prices\", \"waiting lists\", \"occupancy rates\"]\n",
    "        },\n",
    "        \"üíº Economic Policy\": {\n",
    "            \"keywords\": [\"business\", \"employment\", \"income\", \"gdp\", \"economy\", \"trade\"],\n",
    "            \"government_depts\": [\"Commerce and Economic Development Bureau\", \"Labour Department\"],\n",
    "            \"decisions\": [\"Business regulation\", \"Employment support\", \"Economic development\"],\n",
    "            \"metrics\": [\"unemployment rate\", \"business registrations\", \"economic indicators\"]\n",
    "        },\n",
    "        \"üéì Education Policy\": {\n",
    "            \"keywords\": [\"school\", \"student\", \"education\", \"teacher\", \"university\", \"learning\"],\n",
    "            \"government_depts\": [\"Education Bureau\"],\n",
    "            \"decisions\": [\"School funding\", \"Curriculum planning\", \"Resource allocation\"],\n",
    "            \"metrics\": [\"enrollment\", \"performance\", \"teacher ratios\"]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Analyze dataset for policy connections\n",
    "    dataset_text = f\"{dataset_name} {' '.join(data_summary.get('columns', []))}\".lower()\n",
    "    \n",
    "    policy_matches = {}\n",
    "    for policy_area, details in policy_areas.items():\n",
    "        matches = 0\n",
    "        matched_keywords = []\n",
    "        \n",
    "        for keyword in details[\"keywords\"]:\n",
    "            if keyword in dataset_text:\n",
    "                matches += 1\n",
    "                matched_keywords.append(keyword)\n",
    "        \n",
    "        if matches > 0:\n",
    "            policy_matches[policy_area] = {\n",
    "                'match_score': matches,\n",
    "                'matched_keywords': matched_keywords,\n",
    "                'details': details\n",
    "            }\n",
    "    \n",
    "    # Display results\n",
    "    if policy_matches:\n",
    "        print(\"‚úÖ POLICY CONNECTIONS IDENTIFIED:\")\n",
    "        sorted_matches = sorted(policy_matches.items(), key=lambda x: x[1]['match_score'], reverse=True)\n",
    "        \n",
    "        for policy_area, match_info in sorted_matches[:3]:  # Show top 3 matches\n",
    "            print(f\"\\n{policy_area} (Score: {match_info['match_score']})\")\n",
    "            print(f\"üîë Keywords found: {', '.join(match_info['matched_keywords'])}\")\n",
    "            print(f\"üèõÔ∏è Relevant departments: {', '.join(match_info['details']['government_depts'])}\")\n",
    "            print(f\"üìã Potential decisions: {', '.join(match_info['details']['decisions'])}\")\n",
    "            print(\"-\" * 40)\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No clear policy connections identified automatically.\")\n",
    "        print(\"üí° Consider these general approaches:\")\n",
    "        print(\"‚Ä¢ Look for regulatory compliance aspects\")\n",
    "        print(\"‚Ä¢ Consider resource allocation decisions\")\n",
    "        print(\"‚Ä¢ Examine service delivery efficiency\")\n",
    "        print(\"‚Ä¢ Evaluate public interest implications\")\n",
    "    \n",
    "    # Policy questions generator\n",
    "    print(\"\\n‚ùì SUGGESTED POLICY RESEARCH QUESTIONS:\")\n",
    "    if policy_matches:\n",
    "        top_policy = sorted_matches[0]\n",
    "        policy_name = top_policy[0].replace('üèõÔ∏è', '').replace('üöå', '').replace('üå±', '').replace('üè•', '').replace('üè†', '').replace('üíº', '').replace('üéì', '').strip()\n",
    "        \n",
    "        questions = [\n",
    "            f\"How can {policy_name.lower()} be optimized using data-driven insights?\",\n",
    "            f\"What patterns in the data suggest improvements to current {policy_name.lower()}?\",\n",
    "            f\"How do data governance practices affect {policy_name.lower()} effectiveness?\",\n",
    "            f\"What additional data should government collect to improve {policy_name.lower()}?\"\n",
    "        ]\n",
    "    else:\n",
    "        questions = [\n",
    "            \"How can government data collection be improved for this domain?\",\n",
    "            \"What data governance challenges are evident in this dataset?\",\n",
    "            \"How could better data curation support policy decisions?\",\n",
    "            \"What data quality improvements would enhance government decision-making?\"\n",
    "        ]\n",
    "    \n",
    "    for i, question in enumerate(questions, 1):\n",
    "        print(f\"{i}. {question}\")\n",
    "    \n",
    "    return policy_matches\n",
    "\n",
    "# Example usage\n",
    "print(\"üéØ POLICY CONNECTION FRAMEWORK\")\n",
    "print(\"Use this to connect your dataset to government decisions:\")\n",
    "print(\"policy_analysis = policy_connection_analysis('Dataset Name', analysis_results)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49c80c2",
   "metadata": {},
   "source": [
    "# üîß Phase 5: Data Governance Analysis Framework\n",
    "\n",
    "## Step 8: Governance Assessment Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168818cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data governance assessment framework\n",
    "def data_governance_assessment(dataset_info, dataset_url):\n",
    "    \"\"\"\n",
    "    Assess data governance quality and generate improvement recommendations\n",
    "    \"\"\"\n",
    "    print(\"üîß DATA GOVERNANCE ASSESSMENT\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Governance criteria checklist\n",
    "    governance_criteria = {\n",
    "        \"üìä Data Quality\": {\n",
    "            \"completeness\": \"How complete is the dataset? (missing values, coverage)\",\n",
    "            \"accuracy\": \"How accurate is the data? (errors, inconsistencies)\",\n",
    "            \"timeliness\": \"How current is the data? (update frequency, lag time)\",\n",
    "            \"consistency\": \"How consistent is the format? (standardization, conventions)\"\n",
    "        },\n",
    "        \"üìã Documentation\": {\n",
    "            \"metadata\": \"Are variables clearly defined? (data dictionary available)\",\n",
    "            \"methodology\": \"Is data collection method documented? (process transparency)\",\n",
    "            \"context\": \"Is policy context provided? (purpose, use cases)\",\n",
    "            \"limitations\": \"Are data limitations acknowledged? (known issues, scope)\"\n",
    "        },\n",
    "        \"üåê Accessibility\": {\n",
    "            \"format\": \"Is data in machine-readable format? (CSV, JSON vs PDF)\",\n",
    "            \"availability\": \"Is data easily discoverable? (search, navigation)\",\n",
    "            \"download\": \"Is download process straightforward? (no barriers)\",\n",
    "            \"api\": \"Is API access available? (programmatic access)\"\n",
    "        },\n",
    "        \"üîÑ Maintenance\": {\n",
    "            \"updates\": \"How frequently is data updated? (regular schedule)\",\n",
    "            \"versioning\": \"Is historical data preserved? (version control)\",\n",
    "            \"contact\": \"Is there clear contact for questions? (support available)\",\n",
    "            \"feedback\": \"Is there mechanism for user feedback? (improvement process)\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    assessment_results = {}\n",
    "    total_score = 0\n",
    "    max_score = 0\n",
    "    \n",
    "    # Interactive assessment\n",
    "    print(f\"Assessing dataset: {dataset_info.get('name', 'Unknown')}\")\n",
    "    print(f\"URL: {dataset_url}\")\n",
    "    print(\"\\nRate each aspect (1=Poor, 2=Fair, 3=Good, 4=Excellent, 0=Unknown):\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for category, criteria in governance_criteria.items():\n",
    "        print(f\"\\n{category}\")\n",
    "        category_scores = {}\n",
    "        \n",
    "        for criterion, description in criteria.items():\n",
    "            print(f\"  {criterion}: {description}\")\n",
    "            while True:\n",
    "                try:\n",
    "                    score = int(input(f\"    Rate {criterion} (0-4): \"))\n",
    "                    if 0 <= score <= 4:\n",
    "                        category_scores[criterion] = score\n",
    "                        if score > 0:  # Only count towards total if not \"Unknown\"\n",
    "                            total_score += score\n",
    "                            max_score += 4\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"    Please enter a number between 0-4\")\n",
    "                except ValueError:\n",
    "                    print(\"    Please enter a valid number\")\n",
    "        \n",
    "        assessment_results[category] = category_scores\n",
    "    \n",
    "    # Calculate overall governance score\n",
    "    overall_score = (total_score / max_score * 100) if max_score > 0 else 0\n",
    "    \n",
    "    print(f\"\\nüìä GOVERNANCE ASSESSMENT RESULTS\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Overall Governance Score: {overall_score:.1f}%\")\n",
    "    \n",
    "    # Category breakdown\n",
    "    for category, scores in assessment_results.items():\n",
    "        category_avg = sum(s for s in scores.values() if s > 0) / len([s for s in scores.values() if s > 0]) if any(s > 0 for s in scores.values()) else 0\n",
    "        print(f\"{category}: {category_avg:.1f}/4.0\")\n",
    "    \n",
    "    # Generate recommendations\n",
    "    print(f\"\\nüí° IMPROVEMENT RECOMMENDATIONS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    # Specific recommendations based on low scores\n",
    "    for category, scores in assessment_results.items():\n",
    "        for criterion, score in scores.items():\n",
    "            if score == 1:  # Poor scores get specific recommendations\n",
    "                if criterion == \"completeness\":\n",
    "                    recommendations.append(\"üîß Improve data completeness: Implement validation checks and mandatory field requirements\")\n",
    "                elif criterion == \"metadata\":\n",
    "                    recommendations.append(\"üìã Create comprehensive data dictionary with variable definitions and units\")\n",
    "                elif criterion == \"format\":\n",
    "                    recommendations.append(\"üíæ Provide data in machine-readable formats (CSV, JSON) instead of PDF\")\n",
    "                elif criterion == \"updates\":\n",
    "                    recommendations.append(\"üîÑ Establish regular update schedule and communicate timing to users\")\n",
    "                elif criterion == \"api\":\n",
    "                    recommendations.append(\"üåê Develop API access for programmatic data retrieval\")\n",
    "    \n",
    "    # General recommendations based on overall score\n",
    "    if overall_score >= 80:\n",
    "        recommendations.append(\"‚úÖ Excellent governance practices - consider as best practice example\")\n",
    "    elif overall_score >= 60:\n",
    "        recommendations.append(\"‚ö° Good foundation - focus on specific improvement areas identified above\")\n",
    "    elif overall_score >= 40:\n",
    "        recommendations.append(\"üîß Significant improvements needed - prioritize data quality and documentation\")\n",
    "    else:\n",
    "        recommendations.append(\"üö® Major governance gaps - comprehensive reform needed\")\n",
    "    \n",
    "    # Display recommendations\n",
    "    if recommendations:\n",
    "        for i, rec in enumerate(recommendations, 1):\n",
    "            print(f\"{i}. {rec}\")\n",
    "    \n",
    "    return {\n",
    "        'overall_score': overall_score,\n",
    "        'category_results': assessment_results,\n",
    "        'recommendations': recommendations\n",
    "    }\n",
    "\n",
    "print(\"üéØ DATA GOVERNANCE ASSESSMENT\")\n",
    "print(\"Use this to evaluate and improve data governance:\")\n",
    "print(\"governance_results = data_governance_assessment(dataset_info, dataset_url)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342617b5",
   "metadata": {},
   "source": [
    "# üéØ Phase 6: Your Project Development\n",
    "\n",
    "## Step 9: Project Checklist and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f41f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project development checklist\n",
    "def project_checklist():\n",
    "    \"\"\"\n",
    "    Interactive checklist for your open data exploration project\n",
    "    \"\"\"\n",
    "    checklist_items = {\n",
    "        \"üîç Discovery Phase\": [\n",
    "            \"Browse data.gov.hk systematically by category\",\n",
    "            \"Identify 3-5 potential datasets of interest\", \n",
    "            \"Download sample data for initial assessment\",\n",
    "            \"Document dataset URLs and basic information\"\n",
    "        ],\n",
    "        \"üìä Dataset Selection\": [\n",
    "            \"Use quick_dataset_preview() for each candidate\",\n",
    "            \"Run comprehensive_dataset_analysis() on top choices\",\n",
    "            \"Evaluate modeling potential (regression/simulation feasibility)\",\n",
    "            \"Select ONE dataset for your project focus\"\n",
    "        ],\n",
    "        \"üèõÔ∏è Policy Connection\": [\n",
    "            \"Run policy_connection_analysis() on chosen dataset\",\n",
    "            \"Research relevant government departments and decisions\",\n",
    "            \"Formulate specific policy research questions\",\n",
    "            \"Connect analysis to real government decision-making\"\n",
    "        ],\n",
    "        \"üîß Governance Assessment\": [\n",
    "            \"Complete data_governance_assessment() evaluation\",\n",
    "            \"Identify specific governance improvement opportunities\",\n",
    "            \"Research best practices from other jurisdictions\",\n",
    "            \"Develop actionable recommendations\"\n",
    "        ],\n",
    "        \"üìà Analysis Approach\": [\n",
    "            \"Choose primary method: regression/simulation OR governance focus\",\n",
    "            \"Set up analysis framework using provided templates\",\n",
    "            \"Plan visualizations and key findings presentation\",\n",
    "            \"Prepare policy implications and recommendations\"\n",
    "        ],\n",
    "        \"üìã Documentation\": [\n",
    "            \"Document data discovery process and selection rationale\",\n",
    "            \"Create comprehensive analysis notebook\",\n",
    "            \"Prepare policy brief with recommendations\",\n",
    "            \"Plan final presentation for class discussion\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"‚úÖ OPEN DATA EXPLORATION PROJECT CHECKLIST\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Use this checklist to track your progress:\\n\")\n",
    "    \n",
    "    for phase, items in checklist_items.items():\n",
    "        print(f\"{phase}\")\n",
    "        for item in items:\n",
    "            print(f\"  ‚òê {item}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"üéØ SUCCESS CRITERIA:\")\n",
    "    print(\"‚úÖ Clear policy relevance with government connection\")\n",
    "    print(\"‚úÖ Appropriate analytical approach (regression/simulation OR governance)\")\n",
    "    print(\"‚úÖ Actionable recommendations for policy improvements\")\n",
    "    print(\"‚úÖ Evidence of systematic data exploration process\")\n",
    "    print(\"‚úÖ Professional presentation of findings\")\n",
    "    \n",
    "    print(\"\\nüí° REMEMBER:\")\n",
    "    print(\"‚Ä¢ Be patient - good datasets require systematic exploration\")\n",
    "    print(\"‚Ä¢ Focus on ONE specific dataset with clear policy connection\")\n",
    "    print(\"‚Ä¢ Choose approach based on data characteristics\")\n",
    "    print(\"‚Ä¢ This is MORE EXCITING with some uncertainty - embrace the exploration!\")\n",
    "    \n",
    "    return checklist_items\n",
    "\n",
    "# Display the checklist\n",
    "checklist = project_checklist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1a1911",
   "metadata": {},
   "source": [
    "# üöÄ Ready to Start Your Exploration!\n",
    "\n",
    "## Quick Start Guide\n",
    "\n",
    "1. **Start Exploring:** Browse data.gov.hk and use the functions above to analyze potential datasets\n",
    "2. **Be Patient:** Remember, finding the right dataset takes time and systematic exploration\n",
    "3. **Choose Your Approach:** \n",
    "   - **High modeling potential:** Focus on regression/simulation analysis\n",
    "   - **Limited modeling potential:** Focus on data governance improvements\n",
    "4. **Connect to Policy:** Always link your analysis to specific government decisions\n",
    "5. **Document Everything:** Keep track of your exploration process\n",
    "\n",
    "## Remember: This Topic is More Exciting with Some Uncertainty!\n",
    "\n",
    "Unlike other topics with solid foundations, you're building something completely new. Embrace the exploration process and the uncertainty - that's what makes this option exciting and rewarding!\n",
    "\n",
    "**Good luck with your data exploration journey! üéØ**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
