# Comparing artificial intelligence and human coaching goal attainment efficacy

**Authors:** Nicky Terblanche¹*, Joanna Molyn², Erik de Haan³,⁴, Viktor O. Nilsson³

¹ University of Stellenbosch Business School, Cape Town, South Africa  
² University of Oxford Brookes, Oxford, United Kingdom  
³ Ashridge Centre for Coaching, Hult International Business School, Berkhamsted (Herts.), United Kingdom  
⁴ VU University Amsterdam, Amsterdam, The Netherlands

\* nickyt@usb.ac.za

## Abstract

The history of artificial intelligence (AI) is filled with hype and inflated expectations. Notwithstanding, AI is finding its way into numerous aspects of humanity including the fast-growing helping profession of coaching. Coaching has been shown to be efficacious in a variety of human development facets. The application of AI in a narrow, specific area of coaching has also been shown to work. What remains uncertain, is how the two compare. In this paper we compare two equivalent longitudinal randomised control trial studies that measured the increase in clients' goal attainment as a result of having received coaching over a 10-month period. The first study involved human coaches and the replication study used an AI chatbot coach. In both studies, human coaches and the AI coach were significantly more effective in helping clients reach their goals compared to the two control groups. Surprisingly however, the AI coach was as effective as human coaches at the end of the trials. We interpret this result using AI and goal theory and present three significant implications: AI coaching could be scaled to democratize coaching; AI coaching could grow the demand for human coaching; and AI could replace human coaches who use simplistic, model-based coaching approaches. At present, AI's lack of empathy and emotional intelligence make human coaches irreplicable. However, understanding the efficacy of AI coaching relative to human coaching may promote the focused use of AI, to the significant benefit of society.

## Introduction

Since its inception in the 1950s, artificial intelligence (AI) has seen several periods of growth and decline, casting doubt on its actual versus claimed efficacy [1]. Lately, renewed interest in AI has led to numerous novel applications of this technology, including in healthcare and helping professions such as psychology and coaching [2-4]. In this paper, coaching is defined as a one-on-one structured conversation between a coach and client with the aim of facilitating sustainable change for the individual and potentially other stakeholders [5]. Coaching is a late entrant to the application of AI, and AI's role and efficacy in coaching remain largely under-researched.

Coaching is an important helping profession. It is a fast-growing multi-billion dollar per year industry [6] and has grown substantially both in practice and research in the last decade.

Here's the cleaned Markdown:

Recent studies on the application of AI in psychology have suggested that AI could be effective in certain domains of promoting human wellbeing. Fulmer et al. [18], for example, used an AI agent based on cognitive behavioral therapy (CBT) to reduce self-identified symptoms of depression and anxiety in college students. They concluded that AI could serve as a cost-effective and accessible therapeutic agent. Greer et al. [19] found that young adult cancer patients had reduced anxiety compared to a control group after using a positive psychology-based AI coach for four weeks. These findings suggest that, while AI lacks true human intelligence and emotions, positive outcomes are possible even in practices that have traditionally relied on a strong human connection. This might potentially also be the case for coaching.

One of the primary focal areas of coaching and what sets it apart from other helping professions, is assisting clients with goal attainment [20, 21]. Understanding the efficacy of AI coaching compared to human coaching in the domain of goal attainment therefore seems like a reasonable starting point for AI coaching research. This leads us to ask the following research question: In a similar setting, how does AI coaching compare to human coaching efficacy in relation to client goal attainment?

In this paper, we investigate this question by presenting a comparison of the two studies on goal attainment coaching: the first involving human coaches and the second an AI coach. We interpret the results in terms of the current state of AI and goal theory. We also discuss the way these results may pave the way for aspects of coaching to be made more widely available and the implication for coaches and the coaching industry. Given the continued growth of coaching as a helping profession and its proven efficacy, understanding how AI could play a role in scaling and democratizing this service is an important research area.

## Current capabilities of artificial intelligence

AI has seen several false starts mostly because of exaggerated claims of progress and ability that inevitably led to disappointment. An example is Marvin Minsky, the father of AI who back in 1967 stated that "Within a generation . . . the problem of creating artificial intelligence will substantially be solved" [22]. AI has experienced a few "winters" where these types of exaggerations led to withdrawal of funding and the collapse of interest in AI research and development [1]. However, the recent resurgence in AI interest appears to be more sustainable as AI is focused on specific specialist areas in line with current AI capabilities, and shows promise in areas such as decision-making processes [23].

AI is defined as "the broad collection of technologies, such as computer vision, language processing, robotics, robotic process automation and virtual agents that are able to mimic cognitive human functions" [24 p4]. However, in order to understand AI's realistic capabilities, it is important to distinguish between three types of AI:

- Artificial narrow intelligence (ANI) refers to systems that can perform a specific task in a narrow context, such as a self-driving car
- Artificial general intelligence (AGI) refers to systems that have intelligence similar to human intelligence
- Artificial super intelligence (ASI) refers to systems that can outperform human intelligence [25-27]

AGI and ASI do not currently exist and by acknowledging this fact, it creates a more realistic picture of what AI and specifically ANI can accomplish [28].

## Human-AI Interactions in Coaching

For the foreseeable future AI entities will remain unconscious machines that can at best support humans in complex, specific tasks [17]. This implies that ANI systems will be highly specialised and skilled in specific tasks and may even outperform humans in these narrow focus areas [29]. Perhaps instead of waiting for true AGI, multiple narrow AI applications could be interconnected to collaboratively perform tasks in a synergistic manner, possibly with utility beyond what a singly ANI application could do [17]. AI is not yet poised to completely replace humans; however, the improved ability of AI and its increased use in the helping professions suggest we need to investigate more closely the relationship between AI and human interaction. In the highly human-centric context of coaching, the human-AI relationship becomes critical.

### Human-AI Interactions and Relationships in Coaching

An indication of the growing importance of human-AI interaction is the emergence of studies augmenting current human-computer interaction (HCI) theory dedicated to human-centered AI (HCAI) [30] and human-AI interaction (HAII) [31]. The focus of AI development seems to be shifting away from pure scientific and academic exploration to useful applications that also consider human factors [30]. Human factors include the creation of AI systems that have social benefits and consider the ethical implications of AI. It also includes the consideration of the role of humans in the AI ecosystem and awareness of the need for a more human-centred approach [32, 33].

The advancement of AI, combined with the focus on placing humans at the centre, have led to new development of AI roles, ranging from being purely assistive to helping with team collaboration [34, 35]. The fast-growing area of AI-assisted decision-making, for example, requires clear boundaries on human versus AI authority and accountability. This is observed in the healthcare industry context, where decisions on patient care and diagnosis can have life or death consequences. As healthcare professionals team up with AI, there is a real danger that the "third wheel" effect (additional, potentially redundant or confusing opinions) may decrease combined human and AI effectiveness [23].

The present study is not focused on augmented human plus AI interaction since the AI coach used operates autonomously from a human coach. However, the AI coach's sole task is to interact with (coach) a human client. Therefore, the interaction and especially the relationship between the AI and human remain important. There are several suggested ways to create AI coaches that focus on strong human-AI relationships.

Of primary concern is the need for the AI to have social ability, demonstrate credibility and context awareness and be proactive in assisting clients [36]. It is also important that the AI coach strives to embody the aspects that make human coaching effective, including demonstrating trust, empathy, transparency, predictability, reliability, ability, benevolence, and integrity. To create a strong AI-human relationship these aspects can be operationalized as suggested in Table 1 (see Terblanche [4] for a detailed discussion).

### Potential Benefits and Ethical Challenges in AI Coaching

The application of AI in the helping professions and in coaching specifically holds numerous potential benefits. In the related field of psychology AI offers new modes of treatment, the ability to reach currently excluded populations, improve patient response and free up limited resources such as highly trained psychologists [51]. These same advantages apply to coaching.

The benefits of coaching are well researched and several meta-studies have shown that coaching can help people with various aspects including: performance and skills; wellbeing; coping; work attitudes; goal-directed self-regulation; improved work/life balance; psychological and social competencies; self-awareness and assertiveness, increased confidence;

Here's the cleaned Markdown:

## Goal Theory and Coach Maturity in Professional Coaching

developing relationships, networks and interpersonal skills; adapting to change more effectively; helping to set and achieve goals; role clarity; and changing behaviors [9, 10, 13]. However, not everyone has access to a coach, especially in less affluent societies. In Africa, for example, the average cost of an organisational coach is approximately 100 USD per session, which puts it out of reach of many [52]. The problem is not only cost. There is a dire shortage of skilled coaches in many parts of the world. Of the more than 40,000 coaches registered with the International Coaching Federation, fewer than 2,000 are in Africa [53]. It seems that currently most of humanity is excluded from the benefits of professional coaching, even though there are calls for coaching to be viewed as a social process that could benefit currently marginalized groups [54]. AI potentially holds the key to expanding the reach of coaching. The ability of AI to scale and provide basic coaching services at a vastly reduced cost could overcome these current limitations, possibly democratizing coaching to the significant benefit of society.

The use of AI in coaching raises ethical concerns. These include prevention of harm, lack of guidance on developing ethical AI, respect and protection of client autonomy, transparency in the use of algorithms, bias, and data ownership [4, 51]. For AI coaching to be widely accepted and trusted, these ethical challenges must be addressed by stakeholders [36].

### Goal Theory

An important theoretical foundation of this paper is goal theory as applied in coaching. Goal theory is well established and widely used due to a history of empirical research and application. It is in essence an approach explaining the need to establish goals as an intrinsic motivation where a relationship exists between goal difficulty, level of performance, and effort involved [55]. Goal theory is supported by five principles regarding goal setting: clarity (specific and clear); challenge (sufficiently difficult); commitment (buy-in from onset); feedback (regular stock-taking on progress); and complexity (not too complex) [56]. Goals are "internal representations of desired states or outcomes" [57 p388]. Goal setting and attainment have been shown to have a positive effect on workplace performance [56]. Goal attainment has also been linked to positive emotions and increased wellbeing [58-60].

Table 1. AI design practices to support strong coach-coachee relationships.

| Coach attribute | AI design consideration |
|----------------|------------------------|
| Trust | • Avoid the 'uncanny valley' effect [37] |
|      | • Communicate data privacy agreement [38] |
|      | • Create consistent AI personality [39] |
|      | • Reduce security and privacy concerns [40] |
| Empathy | • Use a human name and human-like conversational cues [41] |
|         | • Remember user's likes, dislikes and preferences across sessions [40] |
| Transparency | • Reveal non-humanness [42] |
|             | • Practice self-disclosure [43] |
|             | • Showcase purpose and ethical standards [44] |
| Predictability | • State possible behaviour change due to continuous learning [42] |
|               | • Find a balance between a predictable personality and sufficient human-like variation [45] |
|               | • Use conversational context in interactions [46] |
| Reliability | • Fail gracefully [42] |
|            | • Monitor chatbot performance and reliability [42] |
|            | • Provide confirmation messages [40] |
| Ability | • Use established theoretical models (e.g. goal attainment) [47, 48] |
|         | • Use personalisation and avoid generic responses [49] |
| Benevolence | • Communicate positive intent [42] |
|             | • Demonstrate a positive attitude and mood [40] |
| Integrity | • Clearly communicate limitations [42] |
|          | • Clarify purpose in the introductory message [50] |

Various factors influence peoples

Here's the cleaned Markdown:

summarized by Drake [75 p143]: "...as novices they learn the rules, as intermediates they break the rules, as masters they change the rules and as artisans they transcend the rules". This coach maturity model is testimony to how humans can integrate knowledge and apply learning across domains, allowing navigation of complex situations. While AI is currently incapable of this, the fact that ANI can perform specific tasks on a level of human competency and beyond [29] suggests that the lowest level of coach maturity (models-based) is potentially within the ability of a well-designed narrow AI system.

## Methodology

The two studies we compare were both longitudinal RCT designs. The studies were designed with the CONSORT guidelines for RCT research in mind and these guidelines were adhered to as far as possible [76]. Both studies were conducted over ten months with different groups of participants. Study 1 ran from October 2017 to July 2018 and consisted of a control group and a human coach group where participants received coaching from a human coach. Study 2 ran from November 2019 to August 2020 and consisted of a control group and an intervention group where participants received coaching from an AI chatbot coach. The second study was conducted after the first one because the AI coach was only created in 2019 after the completion of the first study. The same data collection instruments were used in both studies.

The research was approved by the ethics committee of a London-based University, project reference UREC/19.1.5.6. Written informed consent was obtained from all participants in both studies as per the requirements of the ethics approval.

## Participants

Participants in both studies were recruited via email from a business school in the United Kingdom. Their fields of study included business management, economics, marketing, tourism, events management and logistics. Participants in Study 1 were randomly allocated into two different groups: Control 1 (n = 105) and Human coaching (105). For Study 2, participants were allocated into Control 2 (n = 134) and AI coaching (n = 134) groups. In total over the two studies, 327 participants successfully submitted data over all eight time-points which were used for the data analysis. See Table 2 for group numbers, demographic distribution, and mean scores of the dependent variable used in this study.

| | Control 1 | Human coaching | Control 2 | AI coaching |
|---|---|---|---|---|
| n | 85 | 94 | 73 | 75 |
| Gender | 77% female | 64% female | 60% female | 54% female |
| Age | 23.04 (18–53) | 22.56 (18–51) | 23.81 (18–46) | 21.57 (18–48) |
| Goal attainment 1 | 25.95 (12.50) | 27.66 (11.65) | 27.22 (12.78) | 26.06 (12.17) |
| Goal attainment 2 | 27.68 (14.54) | 27.03 (11.22) | 27.03 (12.30) | 24.89 (12.19) |
| Goal attainment 3 | 29.31 (14.59) | 31.62 (11.56) | 30.53 (13.25) | 30.05 (11.31) |
| Goal attainment 4 | 31.26 (15.42) | 34.64 (13.16) | 32.56 (14.60) | 33.04 (13.58) |
| Goal attainment 5 | 32.25 (14.93) | 35.93 (13.78) | 31.35 (14.68) | 34.

## AI Coaching

Applying the principle of narrow AI to coaching suggests the creation of a form of artificial narrow intelligence (ANI) that can perform one specific coaching task, rather than an attempt to create a machine replica of a human coach. The AI coach used in this study, Coach Vici was based on expert system (ANI) principles using chatbot technology. The sole purpose of the chatbot was to help participants with goal attainment. Expert systems are considered a form of narrow AI and are described as complex software programs based on specialized knowledge, able to provide acceptable solutions to individual problems in a narrow topic area [80, 81]. Chatbots in turn are computer programs that interact with users via natural language either through text, voice, or both [82].

Vici is a custom-developed text-based chatbot deployed on the Telegram instant messaging platform. The chatbot was developed using the Designing AI Coach (DAIC) framework that recommends merging aspects of strong human coaching relationship with chatbot design best practices and using proven, evidence-based coaching theories as foundation [4]. In line with these recommendations, Vici was designed to facilitate goal attainment according to goal theory [55]. Vici had two types of text-based conversations with users. In the first type of conversation, Vici helped users to specify realistic goals by questioning them on the importance, feasibility and impact of their stated goals. Vici then helped users to commit to achievable actions that would help them reach their goals. In the second type of conversation, users would check in with Vici to report on their goal and action progress, reflect on obstacles that prevented them from progressing and changing their actions plans if necessary. These conversations assisted users to monitor the progress of their goals and actions. Vici also helped users to distinguish between proximal (< 6 months) and distal (> 6 months) goals [83]. Vici was available 24/7 to the experimental group and they could use it as often as they wanted, but at least once a month. A detailed analysis of the AI coach usages is presented in the Results.

## Measures

### Goal Attainment

Grant et al. [67] developed a goal attainment measure which was adapted for the purpose of this study. The goal attainment measure contained self-reported scores of how successful the participants perceived they had been in achieving their goals and how difficult they perceived their goals. The successful score was measured on 11 points, where each point represented 0%, 10%, 20%, etc. up to 100%. The difficulty score was measured using a seven-point Likert scale ranging from 'Very easy' to 'Very difficult'.

The overall goal attainment score was then calculated by multiplying the success and the difficulty score for each goal separately and dividing the scores for the two different goals to create an average goal attainment score.

## Results

To assess the implications of coaching on goal attainment, a 4x8 Mixed Factorial ANOVA was conducted using the four different groups (Control 1, Control 2, Human coach group and AI coach group) as grouping variable and their eight self-reported measures of goal attainment as dependent variables. A power-analysis using G*Power 3.1.9.7 [84] was conducted to determine the effect size required to identify a statistically significant interaction between four groups over eight time-points. A Mixed Factorial ANOVA with a within-between interaction of 327 participants, a power of 0.95 and alpha level of 0.05 indicated that effect of the coaching intervention would have to be above ηp² = .014 to identify a significant interaction.

The Mixed Factorial ANOVA indicated a statistically significant interaction of group and time, f (13.18, 1296.36) = 2.35, p = .004, ηρ² = .023. To break down this interaction, the development of goal attainment was first analysed within each group using separate Repeated Measures ANOVA over the eight time-points. The Repeated Measures ANOVA indicate

## Comparing Artificial Intelligence and Human Coaching Goal Attainment Efficacy

The effect size of ηρ2 = .023 which was higher than the critical effect size (> ηp2 = .014) according to the power analysis indicated that the sample size for this study was sufficient. These findings further indicate that the participants successfully increased their goal attainment over the time of the study. As shown in Fig 2, receiving coaching had a positive impact on the development of goal attainment for the participants, but both formats of coaching appeared to have had very similar effect.

We also analyzed the usage of the AI coach in terms of usage frequency of the chatbot to identify any potential within-group differences in Study 2. We were able to identify a significant difference in development of goal attainment when splitting the frequency of usage into two equal groups based on their median usage (6 AI coaching sessions, t(73) = -2.24, p = 0.028, d = 0.52). The lower usage group had an average increase on goal attainment of 17.62 (sd = 32.50) compared to 37.62 (sd = 34.16) in the higher usage group. This suggests that more frequent use of the AI coach led to higher goal attainment.

To understand the nature of goals across the two studies and four groups, two of the authors independently analysed the first goal in both studies to assess the theme of the goal, the type of outcome (concrete or vague goal) and whether the goal was proximal (<6 months) or distal (>6 months). The inter-rater reliability of the analysis indicated a very high similarity between the reviewers on all three categories, with Cohen's kappa of κ = .95, p < .001 for the theme of the goal, κ = .94 for the outcome and κ = .91, p < .001 for the timeline of the goal.

The themes of the goals that were identified related to the participants' studies (38%), self-development (22%), career (18%), health and wellbeing (16%), other (2%), finances (2%) family (1%) and property or car (1%). Most of the goals were concrete and measurable (60%), for example, "To gain overall mark of 75% in study year 1" and 58% of the goals were long-term focused (>6 months). Furthermore, the proportion of themes, type or proximal within the four different groups did not significantly differ among each other.

The type of outcome and the proximity of the goals were added as covariates into the model, but neither had a significant impact on the development of goal attainment (outcome, f(7, 2037) = 1.46, p > .05, ηp2 = .005) and proximity, f(7, 2037) = 2.06, p > .05, ηp2 = .007). The themes were analysed separately due to the large variety of the themes, but no significant differences between any of the themes were found on the development of goal attainment, f(7, 334) = .80, p > .05, ηp2 = .017). These findings indicate that the individual differences in the goals among the participants did not impact the development of goal attainment over time in this study.

## Discussion

This paper investigates the performance of an AI chatbot coach relative to human coaches in terms of client goal attainment by comparing two longitudinal RCT studies, the second being a replication study of the first. In both studies the experimental groups who had received either human coaching (Study 1) or AI coaching (Study 2) had significantly higher goal attainment than the control groups. A surprising result is that the AI coach rivalled the human coaches in participant goal attainment with a similar outcome at the end of the study after ten months (Human coach group = ηρ2 = .265, p < .001 and AI coach group = ηρ2 = .269, p < .001).

## Results and Implications

The results (Fig 2) show that the AI coach trailed the human coaches slightly throughout the eight measurements up to the last time-point (T8). Measures were taken monthly between T1 and T7 with a final follow-up measure (T8) after three months. Between T7 and T8, human coach participants did not receive any more coaching, whereas the AI coaching participants were free to keep using the AI coach. This could explain why goal attainment of human coaching participants declined between T7 and T8, but kept increasing for the AI coach group to ultimately equal the human coach group. The convenience and constant availability of the AI coach probably assisted in its performance relative to human coaches.

An important predictor of coaching success is the readiness of the coachee [85]. Due to the randomised nature of this study, we can assume that in both studies participants were equally open and ready for coaching. Being perceptive to coaching relates to a person's state at a particular time of day such as their energy levels, mental alertness, and general physical state. In the human coaching group, sessions were scheduled in advance and because two people are involved in the logistics, one can assume that at times appointments were honoured despite the coach or participant not being in an optimal state for the engagement, potentially negatively affecting the efficacy of that session. In the AI coaching group, the participants had complete freedom to decide when to have a conversation with the chatbot, which may have contributed to a more optimal engagement. While we did not explicitly measure these variables, we suggest that this convenience factor may have helped the AI coach to perform well compared to human coaches. Additionally, the AI coach was available 24/7 and participants could use it as often as they chose.

The results indicate that participants who used the AI coach more often had higher goal attainment. Human coaching is expensive and therefore participants in Study 1 only had one session per month. There was no extra cost associated with additional AI coaching sessions. This underscores two of the main advantages of AI coaching–its scalability and cost effectiveness compared to human coaching. The superior availability and use of the AI coach compared to the human coaches could therefore also explain why the AI coaching group performed so well relative to the human coaching group.

The implications of these results are three-fold:

1. Most importantly, this presents the possibility of democratization of coaching. A number of coaching efficacy meta-studies have shown coaching to be effective in helping people develop, grow and achieve their goals. Coaching is however reserved for a select few due to its cost and the availability of coaches, especially in low-income geographies such as Africa. Even in organizations, individual coaching is usually reserved for the managers and senior leaders. The results from this comparative study suggest that AI coaching, when implemented to have a specific focus in line with the current capabilities of narrow AI, is an affordable and scalable alternative to certain aspects of human coaching. The benefits of coaching could therefore be made available to many more people than is currently the case.

2. The second implication relates to the coaching industry. Many people are concerned that AI threatens their job security [86]. Coaches may therefore rightly be concerned that AI coaches, such as Vici, pose a threat to their livelihood. The opposite may in fact be true. If AI can help democratize coaching, more first-time users of coaching services would be exposed to the benefits of coaching. Due to the limited abilities of AI, at some point users of AI coaching services may have the need for more advanced and intelligent human coaching. We believe this broadening awareness of and exposure to coaching through AI could in fact create more opportunities for human coaches. Human coaches should view AI coaching as an opportunity, not a threat, in line with the findings of a recent study [74].

3. The final implication relates to coaches and their praxis. The efficacy of the AI coach in this study suggests that coaches who operate at a low level of coach maturity [73, 75] could be

Here's the cleaned Markdown:

## Limitations and future research

Participants in both studies were undergraduate students. This implies that the results may not generalize to other populations; however, the effects observed are still valid given that similar groups of participants were used in both studies. Measurements were performed by means of self-scores by participants, which may introduce the possibility of self-score bias. These limitations are offset to some degree by the relatively large sample size and the longitudinal, RCT research design.

In terms of future research, other narrowly focused AI coaches, who specialise in one specific coaching aspect such as wellness, self-awareness or emotional intelligence, should be created and used in a replication study similar to this goal-attainment AI coach. This would help us understand what other coaching aspects can be automated. Should some of these other coaching aspects yield positive results in an AI implementation, the possibility of creating a composite AI coach consisting of an amalgamation of these narrow AI capabilities should be researched. While general AI is not yet possible, perhaps the sum of numerous narrow AI coaching capabilities could create a synergetic AI coaching effect.

## Conclusion

Uniquely human characteristics such as emotional intelligence and empathy allows human coaches to build bonds with their clients that no AI can currently rival. This comparison study however shows that AI coaches that focus on a narrow aspect of coaching and are based on fundamental, proven theories may very well rival human coaches in that specific coaching aspect. While AI coaches will not out-perform human coaches as a whole any time soon, these specific applications of coaching could democratize coaching and make its benefits available to a much wider audience, while at the same time potentially growing the demand for human coaches through exposing more people to the benefits of coaching.

## Supporting information

- S1 Data. (XLSX)
- S1 File. (DOCX)

## Author Contributions

- Conceptualization: Nicky Terblanche, Joanna Molyn, Erik de Haan.
- Data curation: Joanna Molyn, Viktor O. Nilsson.
- Formal analysis: Viktor O. Nilsson.
- Investigation: Nicky Terblanche.
- Project administration: Joanna Molyn.
- Software: Nicky Terblanche.
- Writing – original draft: Nicky Terblanche.
- Writing – review & editing: Joanna Molyn, Erik de Haan, Viktor O. Nilsson.

## References

1. Haenlein M, Kaplan A. A brief history of artificial intelligence: On the past, present, and future of artificial intelligence. Calif Manage Rev. 2019; 61(4):5–14. https://doi.org/10.1177/0008125619864925

2. Gaffney H, Mansell W, Tai S. Conversational agents in the treatment of mental health problems: mixed-method systematic review. JMIR mHealth. 2019; 6(10):e14166. https://doi.org/10.2196/14166 PMID: 31628789

[References 3-19 continue in same format]

19. controlled feasibility trial. JMIR mHealth and uHealth 2019; 7(10):e15018. https://doi.org/10.2196/15018 PMID: 31674920

20. Grant AM. An integrated model of goal-focused coaching: An evidence-based framework for teaching and practice. Int Coach Psychol Rev. 2012; 7(2):146–65.

21. Grant AM. Autonomy support, relationship satisfaction and goal focus in the coach-coachee relationship: Which best predicts coaching success? Coaching. 2014; 7(1):18–38. https://doi.org/10.1080/17521882.2013.850106

22. French RM. The Turing Test: the first 50 years. Trends Cogn Sci. 2000; 4(3):115–22. https://doi.org/10.1016/s1364-6613(00)01453-4 PMID: 10689346

23. Triberti S, Durosini I, Pravettoni G. A "third wheel" effect in health decision making involving artificial entities: A psychological perspective. Front public health, 2020; 8:117. https://doi.org/10.3389/fpubh.2020.00117 PMID: 32411641

24. Bughin J, Hazan E. The new spring of artificial intelligence: A few early economies. VoxEU.org. [Internet]. 2017, August 21. Available from: https://voxeu.org/article/new-spring-artificial-intelligence-few-early-economics

25. Bostrom N. Superintelligence: Paths, Dangers, Strategies. Oxford: Oxford University Press; 2014.

26. Shanahan M. The Technological Singularity. Cambridge, Massachusetts: MIT Press; 2015.

27. Siau KL, Yang Y. Impact of Artificial Intelligence, Robotics, and Machine Learning on Sales and Marketing. Midwest United States for Information Systems Conference Proceedings (MWAIS 2017), 48. [Internet]. Available from: http://aisel.aisnet.org/mwais2017/48; 2017.

28. Panetta K. Widespread artificial intelligence, biohacking, new platforms and immersive experiences dominate this year's Gartner Hype Cycle. Gartner. [Internet]. 2018. Available from: https://www.gartner.com/smarterwithgartner/5-trends-emerge-in-gartner-hype-cycle-for-emerging-technologies-2018/

29. Silver D, Schrittwieser J, Simonyan K, Antonoglou I, Huang A, Guez A, et al. Mastering the game of go without human knowledge. Nature. 2017; 550(7676):354. https://doi.org/10.1038/nature24270 PMID: 29052630

30. Xu W, Dainoff M, Ge L, Gao Z. Transitioning to human interaction with AI systems: New challenges and opportunities for HCI professionals to enable human-centered AI. Int J Hum-Comput Interact. 2021. https://doi.org/10.13140/RG.2.2.20638.46403

31. Sundar SS. Rise of machine agency: A framework for studying the psychology of human-AI interaction (HAII). J Comput-Mediat Commun. 2020; 25(1):74–88. https://doi.org/10.1093/jcmc/zmz026

32. Xu W. Toward human-centered AI: A perspective from human-computer interaction. Interactions. 2019;

Here's the cleaned Markdown of the references section:

43. Lee S, Choi J. Enhancing user experience with conversational agent for movie recommendation: Effects of self-disclosure and reciprocity. Int J Hum Comput Stud. 2017; 103:95-105. https://doi.org/10.1016/j.ijhcs.2017.02.005

44. Neururer M, Schlögl S, Brinkschulte L, Groth A. Perceptions on authenticity in chat bots. Multimodal Technol Interact. 2018; 2(3). https://doi.org/10.3390/mti2030060

45. Sjödén B, Silvervarg A, Haake M, Gulz A. Extending an Educational Math Game with a Pedagogical Conversational Agent: Facing design challenges. In: De Wannemacker S, Clarebout G, De Causmaecker P, editors. Interdisciplinary Approaches to Adaptive Learning: A Look at the Neighbours. Berlin: Springer; 2011. p.116-30.

46. Chaves AP, Gerosa MA. Single or Multiple Conversational Agents? An Interactional Coherence Comparison. Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, 2018 April; Montreal, Canada; 2018.

47. Geissler H, Hasenbein M, Kanatouri S, Wegener R. E-Coaching: Conceptual and empirical findings of a virtual coaching programme. International Journal of Evidence Based Coaching and Mentoring. 2014; 12(2):165-86. Available from: https://radar.brookes.ac.uk/radar/items/585eb4f9-19ce-49e1-b600-509fde1e18c0/1/

48. Poepsel MA. The impact of an online evidence-based coaching program on goal striving, subjective well-being, and level of hope. Capella University. 2011. Available from: https://pqdtopen.proquest.com/doc/872553863.html

49. Tallyn E, Fried H, Gianni R, et al. The Ethnobot: Gathering Ethnographies in the Age of IoT. CHI '18: CHI Conference on Human Factors in Computing Systems, 2018 April; Montreal, Canada. 2018.

50. Jain M, Kumar P, Kota R, Patel SN. Evaluating and Informing the Design of Chatbots. DIS '18: Designing Interactive Systems Conference, 2018 June; Hong Kong, China. 2018.

51. Fiske A, Henningsen P, Buyx A. Your robot therapist will see you now: Ethical implications of embodied artificial intelligence in psychiatry, psychology, and psychotherapy. J Medical Internet Res. 2019; 21(5):e13216. https://doi.org/10.2196/13216 PMID: 31094356

52. Terblanche N, Passmore J, Myburgh J. African organisational coaching practice: Exploring approaches used, and the factors influencing coaches' fees. S Afr J Bus Manag. 2021; 52(1):a2395. https://doi.org/10.4102/sajbm.v52i1.2395

53. International Coach Federation (ICF). 2020 ICF Global Coaching Study: Executive summary. 2020. Available from: https://coachfederation.org/app/uploads/2020/09/FINAL_ICF_GCS2020_ExecutiveSummary.pdf

54. Shoukry H, Cox E. Coaching as a

Here are the references cleaned and normalized in Markdown format:

65. Carver CS, Scheier MF. On the self regulation of behaviour. Cambridge, UK: Cambridge University Press; 1998.

66. Harkin B, Webb TL, Chang BPI, Prestwich A, Conner M, Kellar I, et al. Does monitoring goal progress promote goal attainment? A meta-analysis of the experimental evidence. Psychol Bull. 2016; 142(2):198-229. https://doi.org/10.1037/bul0000025

67. Grant AM, Curtayne L, Burton G. Executive coaching enhances goal attainment, resilience and workplace well-being: a randomized controlled study. J Posit Psychol. 2009; 4(5):396-407. https://doi.org/10.1080/17439760902992456

68. Zimmermann LC, Antoni CH. Problem-specific coaching interventions influence goal attainment via double-loop learning. Zeitschrift für Arbeits-und Organisationspsychologie A&O. 2018(September). https://doi.org/10.1026/0932-4089/A000281

69. Losch S, Traut-Mattausch E, Mühlberger MD, Jonas E. Comparing the effectiveness of individual coaching, self-coaching, and group training: How leadership makes the difference. Front Psychol. 2016; 7:629. https://doi.org/10.3389/fpsyg.2016.00629

70. Terblanche NHD, Jock RJ, Ungerer M. Creating and maintaining a commercially viable executive coaching practice in South Africa. South Afr J Entrep Small Bus Manag. 2019; 11(1):a192. https://doi.org/10.4102/sajesbm.v11i1.192

71. Bozer G, Sarros JC, Santora JC. Academic background and credibility in executive coaching effectiveness. Personnel Review. 2014; 43:881-97. https://doi.org/10.1108/PR-10-2013-0171

72. Bachkirova T, Smith CL. From competencies to capabilities in the assessment and accreditation of coaches. Int J Mentor. 2015; 13(2):123-40.

73. Megginson D, Clutterbuck D. Further techniques for coaching and mentoring. New York: Routledge; 2010.

74. Bhargava A, Bester M, Bolton L. Employees' perceptions of the implementation of robotics, artificial intelligence, and automation (RAIA) on job satisfaction, job security, and employability. J Technol Behav Sci. 2021; 6(1):106-13. https://doi.org/10.1007/s41347-020-00153-8

75. Drake DB. What do coaches need to know? Using the Mastery Window to assess and develop expertise, Coaching. 2011; 4(2):138-55. https://doi.org/10.1080/17521882.2011.596486

76. Schulz KF, Altman DG, Moher D. CONSORT 2010 statement: updated guidelines for reporting parallel group randomised trials. Trials. 2010; 11(1):1-8. https://doi.org/10.1136/bmj.c332

77. Wampold BE, Imel ZE. The great psychotherapy debate: The evidence for what makes psychotherapy work. 2nd ed. New York: Routledge; 2015.

78. Colagiuri B, Smith CA. A systematic review of the effect of expectancy on treatment responses to acupuncture.