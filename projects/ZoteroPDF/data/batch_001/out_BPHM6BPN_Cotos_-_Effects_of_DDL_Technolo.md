# Effects of DDL technology on genre learning

Elena Cotos, Iowa State University Stephanie Link, Oklahoma State University Sarah Huffman, Iowa State University

# Abstract

To better understand the promising effects of data-driven learning (DDL) on language learning processes and outcomes, this study explored DDL learning events enabled by the Research Writing Tutor (RWT), a web-based platform containing an English language corpus annotated to enhance rhetorical input, a concordancer that was searchable for rhetorical functions, and an automated writing evaluation engine that generated rhetorical feedback. Guided by current approaches to teaching academic writing (Lea & Street, 1998; Lillis, 2001; Swales, 2004) and the knowledge-telling/knowledge-transformation model of Bereiter and Scardamalia (1987), we set out to examine whether and how direct corpus uses afforded by RWT impact novice native and non-native writers’ genre learning and writing improvement. In an embedded mixed-methods design, written responses to DDL tasks and writing progress from first to last drafts were recorded from 23 graduate students in separate one-semester courses at a US university. The qualitative and quantitative data sets were used for within-student, within-group, and between-group comparisons—the two independent variables for the latter being course section and language background. Our findings suggest that exploiting technology-mediated corpora can foster novice writers’ exploration and application of genre conventions, enhancing development of rhetorical, formal, and procedural aspects of genre knowledge.

Keywords: DDL, Disciplinary Corpus, Genre, Writing

Language(s) Learned in this Study: English

APA Citation: Cotos, E., Link, S., & Huffman, S. (2017). Effects of technology on genre learning. Language Learning & Technology, 21(3), 104–130. Retrieved from   
http://llt.msu.edu/issues/october2017/cotoslinkhuffman.pdf

# Introduction

In the past few decades, language pedagogy has undergone major transformations due to the use of corpora by teachers and learners. A common distinction is made between direct and indirect uses of corpora (Leech, 1997). Indirect uses draw on corpus findings to inform the content of reference materials as well as various pedagogical decisions including selection, sequence, and form of presentation of language phenomena to be included in instruction. Direct uses often rely on constructivist views and are best represented by datadriven learning (DDL), an approach that promotes learner-centered autonomous environments. The term DDL, coined by Johns (1990), originally referred to “the use in the classroom of computer-generated concordances to get students to explore the regularities of patterning in the target language, and the development of activities and exercises based on concordance output” (Johns & King, 1991, p. iii). The learners are thus confronted with the corpus data as directly as possible (Johns, 2002), while the instructor adopts the role of a coordinator who mediates learners’ interaction with the corpus for reference or demonstration purposes.

DDL has been used in the classroom to introduce “the use of authentic language, make students more active and independent analysers of language, and provide empirical evidence about language use” (Conrad, 1999, p. 2). Comprehensive overviews tackle the controversy in the application of DDL and elaborate on its benefits (e.g., Boulton, 2012; Boulton & Cobb, 2017), confirming that learners’ exposure to authentic corpus input and to multiple examples of target language features is indeed a major advantage (Gilquin & Granger, 2010). A number of empirical studies, experimental and longitudinal, provide evidence of positive outcomes in terms of learning, improvement, and enhanced awareness (e.g., Boulton, 2010b; Chambers & O’Sullivan, 2004; Charles, 2014; Cotos, 2014a; Henry, 2007; Tono, Satake, & Miura, 2014; Vyatkina, 2016). Because of easy retrieval of representative linguistic data, DDL is considered highly accessible to language learners (Fox, 1998), although it may also be viewed as difficult, irrelevant, or inefficient (see Boulton, 2010a). The exploratory experience is recognized by students as presenting a more natural approach to language learning, increasing their curiosity about the target language, and boosting their motivation (Aston, 2001).

As Boulton (2011) argues, the principles of DDL do not constitute “an all-or-nothing affair” (p. 575). Its fuzzy boundaries in fact invite methodological creativity and pedagogical innovation that integrate existing and new resources. With exploration of corpus data as its core, DDL welcomes a variety of context- and needs-responsive pedagogical techniques, which have become increasingly eclectic due to advances in technology. Interactive, intelligent, and semi-intelligent computer-assisted learning applications have made headway across learning environments and language skills, drawing on multi-purpose, specialized, inhouse, monolingual, bilingual, and learner corpora to enable teacher-led and student-initiated activities for inductive and deductive learning. Therefore, it is of utmost importance to understand the effects of such interactive learning technologies in order to further consolidate the manifold thrusts of DDL research and practice, which are becoming more theoretically inclusive and methodologically heterogeneous.

In support of a theoretically and empirically grounded paradigm, this article presents and evaluates a technology-enhanced DDL model for mainstream writing pedagogy for native speakers (NSs) and nonnative speakers (NNSs) of English that draws on genre theories oriented towards text features and social practices, as well as on the knowledge-telling/knowledge-transformation model representing the cognitive dimension of writing as a language skill (Bereiter & Scardamalia, 1987). What sets this study apart from other work is that the DDL tasks were completed using a web-based platform containing a specialized, multi-disciplinary corpus annotated with genre conventions for the purpose of input enhancement; a concordancer searchable for rhetorical functions; and an interactive module that generated automated rhetorical feedback. We explored direct corpus uses integrated into the curriculum of a genre-based course in research article (RA) writing. In this article, we focus on the Introduction section unit. Adopting an embedded mixed-methods design, we aimed to examine whether and how corpus uses enabled by this platform impacted novice writers’ genre awareness and helped improve their writing. The term novice here refers to student writers who were aspiring to enter a disciplinary discourse community (see Swales, 1990). Written performance obtained from two groups, each consisting of NSs and NNSs, was analyzed at three levels: within individual students, among students within each group, and between students in the two groups. The between-group comparison was based on course section and NS or NNS status as the independent variables. Our findings suggest that exploiting technology-mediated corpora can foster novice NS and NNS writers’ exploration, application, and production of genre artifacts, enhancing the rhetorical, formal, and procedural aspects of genre knowledge.

# Literature Review

# Theoretical Foundations for Genre Writing Pedagogy

Genre writing theory and pedagogy have historically engaged different schools of thought; some are textoriented and some writer-oriented theories. The former focus on text in context and underlie explicit pedagogies that incorporate attention to the communicative purposes of genres, as with English for academic purposes (EAP), or to the characteristic linguistic features of texts, as with systemic-functional linguistics (SFL). Writer-oriented traditions such as new rhetoric (NR) and academic literacy (AL)1 emphasize social practices and socio-political contexts of texts, voicing a disagreement with what they consider text-biased prescriptiveness of the above-mentioned linguistic approaches.2 As Wingate and Tribble (2012) point out, the concept of writing as social practice substantiates much of the EAP genre work, and thus it might seem that pedagogical integration of these perspectives should not raise questions regarding theoretical integrity and pedagogical compatibility. However, such integration has not been accomplished partly because EAP has been concerned with L2 learners rather than “the ‘traditional’ home students whose problems are not that obvious” (p. 492). AL, on the other hand, has not provided applicable pedagogical guidelines, rather serving as a “design frame with a focus on pedagogy” (Lea & Street 2006, p. 369). In short, neither the text-oriented nor the writer-oriented tradition “has made sufficient impact in terms of offering a mainstream pedagogy” (Tribble & Wingate, 2013, p. 308). Wingate (2012) argues that writing pedagogy “must consist of a package of various approaches and methods” (p. 27). Therefore, regardless of their epistemological and conceptual differences, we attempt to bring text-oriented and writeroriented perspectives into closer contact in our pursuit of a mainstream NS and NNS genre writing pedagogy in higher education contexts. With this conceptual framework, we envision technology-enhanced DDL as an essential operational paradigm in the package that can translate appropriate theoretical tenets into effective practices.

Arguably, genre-based writing instruction must combine focus on the text, the writer, and the discourse community (Tribble & Wingate, 2013), for these dimensions are reflected in the interactive facets of genre knowledge: formal knowledge, rhetorical knowledge, and process knowledge (Tardy, 2009).3 Figure 1 depicts the conceptual framework, which shows the connections that need to be made between theoretical traditions and DDL practices to achieve the teaching and learning goal of developing genre knowledge. From a theoretical standpoint, EAP and SFL support the development of formal knowledge focusing on discourse form, lexicogrammatical patterns, and structural conventions of texts. Both EAP and the writeroriented perspectives emphasize the importance of context in developing rhetorical knowledge, which is defined as an understanding of the genre’s intended purposes and an awareness of the socio-rhetorical context (Tardy, 2009, p. 21). EAP addresses socio-rhetorical purposes with insights about communicative moves (Swales, 1981, 2004). NR and AL also acknowledge the role of texts and linguistic descriptions (Baynham, 2000) in an attempt to induct students into the culture of academic contexts through participation in and critique of writing practices (Lea & Street, 1998; Lillis, 2001). Given that purely writer-oriented methods pose challenges for direct application in classroom practice (Lillis & Scott, 2007) and that corpora “could provide a compelling and genuinely inclusive response to the needs of learners across higher education” (Wingate & Tribble, 2012, p. 492), we propose that discipline-specific corpora can be exploited for bottom-up explorations of how genre as a form of social action enables and constrains linguistic choices, as well as for top-down DDL to engage students in a critical analysis of the discourse of their target disciplinary communities.

Furthermore, the process knowledge of composing the genre can be accounted for from the perspective of the knowledge-telling/knowledge-transformation cognitive model (CM; Bereiter & Scardamalia, 1987), which describes writing strategies as interpreted by cognitive writing theory (e.g., Hayes, Flower, Schriver, Stratman, & Carey, 1987). Knowledge-telling is characteristic of novice writers, who produce content based on their knowledge of the topic and move from one idea to the next without attempting to shape that knowledge in view of their writing goals or readers’ expectations. Also, they are not able to detect and diagnose problems, especially higher-level rhetorical problems. Expert writers, on the other hand, transform what they know, which entails developing both elaborate content and rhetorical goals. They problematize the writing task in that they analyze their writing to identify and solve task-related content and rhetorical problems. In the case of academic genres, for instance, the content problem space refers to disciplinary knowledge. The rhetorical problem space refers to constructing argumentation as expected by the discourse community, which the writer often reflects upon stimulated by the need to make appropriate language choices. The novice versus expert distinction may be as important as the NS versus NNS distinction (see for example Hulstijn, 2015; Ortega, 2013). Therefore, interactive DDL should create opportunities for learners to engage in cognitive processes similar to skilled writers and help them learn how to freely combine knowledge-telling and knowledge-transforming strategies when writing and revising.

![](img/d06b070253baaf4289a3c17249d3752b12758115f78493987ed926d44fef851f.jpg)  
Figure 1. Conceptual framework for genre writing pedagogy

# Effects of DDL

Pedagogical implementations of DDL draw on the tools and methods developed in corpus linguistics. Bottom-up corpus analysis underlies students’ vertical and horizontal reading of lexicogrammatical features exhibited in concordance lines in order to determine patterns of language use (Braun, 2005). Top-down DDL tasks, which generally draw on move analysis, focus on the macro-structure of corpus texts (Swales & Feak, 2012). Students identify organizational and discursive patterns as well as variation in the use of the genre conventions by the target discourse community. The bottom-up and top-down approaches have been paired in the design of semi-intelligent and intelligent computer-based systems that engage students in different levels of interaction with NS and learner corpus data and stimulate their cognitive involvement (e.g., Anthony & Lashkia, 2003; Cotos, 2012).

A wealth of publications present bottom-up uses of corpora of academic genres in graduate-level writing courses. Lee and Swales (2006) describe a “technology enhanced rhetorical consciousness-raising” approach using specialized corpora of discipline-specific expert writing and a learner corpus of students’ own writing (p. 72). The learning outcomes of this concordancing-intensive work focusing on lexicogrammatical features were positive, and the students “found the use of corpora confidence-building and empowering” (p. 71). Exploring corpus data to identify the language used by experts appeared to engender a sense of empowerment for the students in Starfield’s (2004) thesis-writing course as well. With a focus on selected linguistic features, Friginal (2013) got his forestry students to use a concordancer for the development of genre writing. Comparative analyses of frequencies and distribution data of linguistic features indicated that the students produced patterns similar to articles published in their field.

Applying the top-down move-analysis approach, Tribble and Wingate (2013) presented and evaluated materials that were developed using disciplinary corpora of student writing, which students used for deconstruction and joint construction tasks. Their results suggested a positive impact in terms of learners’ perceptions and genre awareness as well as improvement in independent construction of their texts. Improvement in research writing was also reported by Bianchi and Pazzaglia (2007), whose students worked with a corpus of psychology texts. Similarly, in Charles’ (2007) and Cortes’ (2007) courses, students’ awareness of communicative purposes and rhetorical functions increased as a result of their topdown exploration of macro-discourse patterns. Later transitioning to a bottom-up analysis, their students conducted concordance searches of specific lexicogrammatical items. This combination made “the best of both worlds” (Charles, 2014, p. 299).

The effectiveness of interactive corpus-based computer applications has also been investigated, with positive evaluations of techniques for providing concordance-derived writing feedback (Gaskell & Cobb, 2004; Todd, 2001). Additionally, autonomous uses of corpora and corpus-based automated feedback have been considered from the perspective of learner strategies (Cotos & Huffman, 2013), learners’ perceptions of usefulness of corpora (Rodgers, Chambers, & Le Baron-Earle, 2011), and changes in learners’ skills development (Cotos, 2011; Yoon, 2008). Another angle in DDL evaluation recommends hands-on uses of corpora in conjunction with other web-based applications such as Google and online dictionaries (PérezParedes, Sánchez-Tornel, & Alcaraz Calero, 2012).

While previous research has accumulated a wealth of evidence supporting the value of DDL for academic writing, more work is needed to understand the potential effects of technology-enhanced DDL on the development of genre knowledge. Building on previous work, we conducted a study in the context of a genre-based research writing course. The course integrates students’ indirect and direct uses of corpus data through a computer-assisted writing platform called the Research Writing Tutor (RWT). The twofold purpose of this study was to determine the following:

1. Do DDL learning events enabled by RWT contribute to genre awareness? How? 2. Do DDL learning events enabled by RWT contribute to improvement in the quality of genre writing? How?

# Methodology

# Instructional Context and Corpus-Based Materials

The environment in which the study unfolded was a Writing for Academic Publication course offered at the Iowa State University of Science and Technology (ISU) in the United States. This course prepared students in various disciplines to produce the Introduction, Methods, Results, and Discussion (IMRD) structure in RAs of publishable quality. The pedagogy was largely anchored in the EAP tradition of genre analysis, embodying indirect and direct corpus uses, utilizing instructional materials drawing on corpusbased research, and being designed as multi-modal modules in RWT: understand writing goals, explore published writing, and analyze my writing. Descriptive details about RWT4 can be found in Cotos (2014b, 2016). Here, we highlight its affordances vis- $\grave { \mathbf { a } }$ -vis direct and indirect corpus uses as depicted in Figure 2.

In short, RWT offered different representations of a multi-disciplinary corpus (900 published RAs in 30 disciplines) in order to enable instructional, learning, and assessment events.5 Indirect uses of the corpus were realized through instructional events based on video-lectures and readings contained in the Understand writing goals module. The Introduction section materials defined, described, and explained the Create A Research Space model adapted from Swales (1981; see Figure 3).

![](img/c6acc71124406b7bebb04fc615cf149e4f1ea4df515043f26d0bb95e0540b764.jpg)  
Figure 2. Direct and indirect corpus uses with RWT

![](img/2c6c26f37f7f7b6c89e012e3795c43e93e4202ffc79b9acbf7a520ade29865a0.jpg)  
Figure 3. Introduction moves and steps.

Direct uses of the corpus were realized through DDL learning events facilitated by the Explore published writing module, which displayed each text in the corpus annotated for moves and steps (for details on corpus annotation and reliability, see Cotos, Huffman, & Link, 2015). The annotations were color-coded for moves (Move 1 was blue, Move 2 red, Move 3 green) and glossed for steps, thus visually depicting the rhetorical composition of individual IMRD sections (see Figure 4). This module also featured a concordancer that could be queried by move or step and by discipline, showing examples of functional language indicative of the step’s rhetorical meaning (see Figure 5).

![](img/fbc1d8e6497f21e9fa6c266a66f08760a9ea8c0dc8f1e74c1c70cab24792be21.jpg)  
Figure 4. Screenshot of text from the annotated corpus

![](img/d8c4d752b1f1563506060a92115c36e7081bbc84ebe85d01bfde322f40bb01f7.jpg)  
Figure 5. Screenshot of concordancer examples of the Claiming centrality step, Move 1

The Analyze my writing module contained an automated writing evaluation engine, which generated different types of macro- and micro-level feedback based on automated move or step analysis and comparison of students’ drafts with the disciplines of their choice.6 This immediate formative feedback created conditions for assessment events through computer-assisted self-analysis. Attending to RWT’s feedback was expected to stimulate students’ cognitive capacity through iterative revision. Because the students did not engage in direct corpus exploration, but rather revised their writing guided by corpus-based feedback (see examples in Figure 6), the interaction could be considered an indirect use of the corpus. The effects of student interaction with automated feedback are reported elsewhere (e.g., Chapelle, Cotos, & Lee, 2015; Cotos, 2014b, 2016; Cotos & Huffman, 2013). In this study, the primary focus was on the students’ engagement in top-down and bottom-up DDL learning events using the Explore published writing module.

![](img/5e168ec437bc68479e67247b4ea52c0ce972c7e6e7769e3bab0c7641d627fe95.jpg)  
Figure 6. Screenshot of RWT feedback

# DDL Learning Events

As shown in Figure 7, the students completed two DDL tasks after they wrote their first Introduction draft (prior to instructional events) and before they revised their draft scaffolded by RWT’s automated feedback. The first was a top-town analysis of the rhetorical composition of the annotated Introduction sections in their discipline. The students were guided by the following questions, which they were asked to respond to in writing for each of the three moves in the Introduction:

Q1 How is [Move] distributed in the Introduction? Q2: Do all the three steps appear in [Move]? If yes, in what order? Q3: Which step is the most extensive? Q4: Are there sentences that represent more than one step in [Move]?

The second DDL task was a bottom-up analysis using the move or step concordancer in RWT. The students were asked to examine the concordance lines showing sentences annotated as particular steps and to identify expressions indicative of their functions. They compiled their lexicogrammatical findings into a list of move or step examples of functional language use. After completing each of these two tasks, the students revised their Introduction drafts based on their observations of the annotated discipline-specific corpus data.

# Participants

Two groups of graduate students enrolled in the course participated in the study over the period of two academic semesters (one group in each semester). Group 1 had 9 NNSs and 3 NSs, and Group 2 had 7 NNSs and 4 NSs. The NNSs spoke Mandarin (5), Korean (3), Turkish (3), Spanish (2), Farsi (1), Arabic (1), or Malay (1) as their first language. All the NNS participants could be considered intermediate or upperintermediate, having been admitted to ISU based on the following cut-off scores for proficiency in English: TOEFL iBT, 79; TOEFL PBT, 550; IELTS, 6.5; or Pearson Test of English, 53. They also passed the institutional English Placement Test upon arrival at the university, which assessed incoming students’ academic listening, reading, and writing abilities and served the purpose of placing students who do not pass the test in respective English courses. All 23 participants were pursuing a masters or doctoral degree in a range of disciplines (e.g., chemical engineering, mechanical engineering, curriculum and instruction, sociology, or applied linguistics), and all had completed a research study that they were ready to report in writing, though none of them had previously written a RA intended for publication.

# Study Design and Data Analysis

Because the study aimed to gauge evidence of genre learning as reflected in students’ corpus observations as well as in their texts, we combined the collection and analysis of qualitative and quantitative data in an embedded mixed-methods design (Cresswell & Clark, 2011). A key premise of the embedded design was that different strands of inquiry within a study required different types of data, and that one data set was used to provide supportive evidence. As shown in Figure 7, in our study quantitative data played a supportive role within the overall design, where we implemented parallel tracks to collect and integrate the data. Quantitative analysis was conducted after the qualitative data collection procedure, quantifying qualitative data through coding to provide supportive evidence needed to make comparative connections within and between participants and groups. The instructional and data-collection procedures were the same for both groups, thus yielding a similar dataset for each group. The rationale for keeping the two datasets separate was that we wanted to determine whether the effects of RWT-enabled DDL would be similar in individual course sections, which contained both NS and NNS students in an authentic learning context. Therefore, course section and language background served as the two independent variables for withingroup and between-groups comparisons. To examine the overall NS and NNS distinction, however, data from all NSs were juxtaposed with data from all NNSs, which was possible because the data were collected in identical conditions.

![](img/007ae07a8af931581dd2145c0979a9fc9e9f7439b9cb29542dc9f1712e1021fa.jpg)  
Figure 7. Study design

# Student Responses Dataset

When completing the rhetorical composition analysis task, the students were asked to record their corpus observations based on the guiding questions listed above. The questions were designed to elicit students’ observations of four types of possible move or step patterns: distribution (Q1), order and occurrence (Q2), amount (Q3), and rhetorical overlap (Q4). Students’ responses to these questions were first analyzed in terms of pattern noticing—that is, whether a response indicated an attempt to generalize an observation. Three codes were used: no pattern, one pattern, two or more patterns. Pattern-indicative responses were further assigned a code for the following pattern types, as in the examples shown in Table 1. Analysis was also conducted on students’ lists of step-specific examples of functional language compiled during the language use analysis task. Each example was coded as being representative, indicative, or nonrepresentative (see Table 2). All the discourse-pattern codes and language-pattern codes were then quantified.

Table 1. Discourse Patterns and Examples   

<html><body><table><tr><td>Pattern</td><td>Example</td></tr><tr><td>Distribution (move location)</td><td>&quot;Move 1 frequently distributed at the beginning and middle part of Introduction section.&quot; (Gr1_3_NNS)</td></tr><tr><td></td><td>Order (step sequence) *The order is claiming centrality, providing general background and reviewing previous research.&quot; (Gr2_4_NNS)</td></tr><tr><td>Occurrence (step) presence, absence)</td><td>&quot;I was able to detect all three steps in most papers; however, claiming centrality seems to only show up once, if at all. (Gr2_6_NS).</td></tr><tr><td>Amount (step extent, quantity)</td><td>&quot;There is not a single extensive step in Move 3. But purpose and description appear really frequently. Hypotheses is also one of the steps that appears frequently.&quot; (Gr1_2_NNS)</td></tr><tr><td>Rhetorical overlap (multiple step functions in the same stretch of text)</td><td>&quot;In general there is overlay between generalization and review. Centrality is in most cases only one phrase. Yes, especially with general background and review, because when providing background it is necessary to provide support for the claim which then brings review.&#x27; (Gr1_10_NNS)</td></tr></table></body></html>

Table 2. Language Use Patterns and Examples   

<html><body><table><tr><td>Pattern</td><td>Example</td></tr><tr><td>Representative (represents the step accurately)</td><td>Move 2, Step indicating a gap: &quot;Data on ... were limited and restricted to a few varieties of... (Gr2_6_NS)</td></tr><tr><td>Indicative (contains linguistic cues indicative of the step, but has a different discussed further in this paper&quot; (Gr2_10_NS) function in the given context)</td><td>Move 2, Step highlighting a problem: &quot;...an issue that will be</td></tr><tr><td>Non-representative (contains no linguistic cues indicative of the step, is another step)</td><td>Move 1, Step claiming centrality: &quot;Developing readers must learn to recognize recurrent spelling patterns within words.&quot; (Gr2_9_NNS)</td></tr></table></body></html>

# First–Last Drafts Dataset

The first–last drafts dataset contained 44 drafts (Group 1, $N = 2 2$ ; Group 2, $N = 2 2$ ; NNSs, $N = 3 2$ ; NSs, $N$ $= 1 2$ ). One NS student in Group 1 did not submit the last draft and was thus excluded from the analysis of writing improvement. The corpus in RWT was annotated at sentence level, and the move or step feedback generated by RWT was also provided at sentence level. Therefore, for the purpose of maintaining consistency between the learning and assessment events and data analysis, the first and last drafts were also analyzed at sentence level using RWT’s automated move or step classification (i.e., each sentence was coded for a move and a step). The codes for each sentence were counted per student and per draft to calculate the number of move or step occurrences. Improvement in the writing quality was operationalized based on the total number of occurrences of moves and steps in first and last drafts.

To determine differences in move or step occurrences from first to last draft between groups and between NSSs and NSs, we performed Mann-Whitney U-tests. Furthermore, the move and step occurrences were used in a series of Wilcoxon Signed-Ranks tests to determine whether and how the RWT-enabled DDL learning events contributed to improved quality of writing. The tests were appropriate for within-groups comparisons of two dependent groups to account for changes in occurrences from first to final draft when our $N .$ -size was relatively small. Effect sizes were calculated by dividing the $z \cdot$ -value by the square root of $N _ { : }$ where $N$ was the number of occurrences over the two drafts (Pallant, 2007). Effect size values ranged from .12 to .63, and were assessed against criteria for L2 research by Plonsky and Oswald (2014) where .25 was a small effect, .40 was a medium effect, and .60 was a large effect.

Next, the drafts classified into moves and steps were aligned such that the sentences in the first draft were parallel with sentences in the last draft. This alignment allowed a qualitative analysis and tallying of text modifications, which were categorized into the following:

Content (e.g., additions, deletions, modified ideas)   
Lexis (e.g., move-specific, non-move-specific)   
Grammar (e.g., verb tense or form, subject-verb agreement, plurals, etc.)   
Structure (e.g., paragraph, structure)   
Mechanics (e.g., punctuation, citation format)

# Reliability Measures

Two researchers coded the data sets. Inter-coder reliability was measured using Cohen’s Kappa (Cohen, 1988) to determine consistency between the two coders while accounting for chance agreement. For the coding of discourse patterns, the coefficient was .95; for language patterns, it was .85; for text modifications, it was .79. All coefficients were in the range of substantial to almost perfect agreement following the criteria by Landis and Koch (1977).

In a concurrent study, which is work in progress, we measured the level of agreement between RWT’s move or step automated classification and human annotation. On a set of 15 learner and 15 published Introduction texts (505 and 435 sentences, respectively), Cohen’s Kappa coefficients for moves were .89 (published) and .84 (learner), and for steps .76 (published) and .71 (learner). We are drawing on these human-computer reliability results because the learner texts were randomly extracted from the first and last drafts used in this study.

# Results and Discussion

# Genre Awareness

The first strand of our inquiry centered on RWT-enabled DDL activities as a means of enhancing the awareness needed for the learning of genre constructs. Two learning events were created through DDL tasks: rhetorical composition analysis and language use analysis. Student output produced in response to these tasks was examined in terms of noticing of rhetorical patterns and ability to identify linguistic signals indicative of rhetorical intent.

Students’ open-ended responses to the questions guiding their top-down exploration of the annotated corpus contained a total of 430 pattern-related observations (distribution, 65; order, 86; occurrence, 108; amount, 111; rhetorical overlap, 60). Of the total, $40 \%$ of the patterns were noted by Group 1 and $60 \%$ by Group 2; $54 \%$ by NNSs ( $76 \%$ in Group 1; $40 \%$ in Group 2) and $4 6 \%$ by NSs $24 \%$ in Group 1; $60 \%$ in Group 2). As shown in Figure 8, both groups and NNSs and NSs alike noted all five types of patterns, and the differences in percentages for each type were not significant. These results, showing similarity between NSs and NNSs, seem to reinforce the theoretical argument that the novice-expert distinction may be more important than

the NS-NNS distinction.

![](img/467115454fcf88bdeae175cf850f122edff72ec395cebff402a9ae27f61efdbf.jpg)  
Figure 8. Rhetorical composition patterns per group and language background

Figure 9 depicts students’ noting of these patterns per move, with similar observations within each group as well as some perceptible differences. In Move 1, more prominent is the amount pattern noted by both NNSs and NSs in both groups. In Move 2, the occurrence pattern was largely noted by all students, with NNSs in Group 2 paying much less attention to step amount and more to order. In Move 3, the NNSs in Group 1 noticed rhetorical overlap the most. Interestingly, the NSs in Group 1 focused on distribution more than their NS peers in Group 2.

![](img/d3a40ec54cc5e11007d5b5edd1e4252ed43597cd21b7f6a44466e2225cc17b02.jpg)  
Figure 9. Rhetorical composition patterns within groups per move

The comparable frequencies with which the students reported having noticed these discourse patterns is an important finding because it suggests that they were not simply looking at the color enhancements for the moves, but that they were attending to the glosses specifying the steps and thus becoming more cognitively engaged. As a result, they were able to note the presence or absence of steps, as well as their sequence. Because the move colors visualize the overall composition of annotated texts opened side by side, the distributional patterns were likely easier to detect and thus less challenging. Focusing on rhetorical intent, on the other hand, required more cognitive effort in order to understand where the overlap occurs. Some lower percentages for this category could also be because functional meanings are not present in every

single sentence of a text.

Accompanying students’ descriptions of rhetorical patterns in the annotated corpus was their unsolicited rationalization (italicized in the examples below), reflecting on why published authors may have constructed their arguments through the use of particular moves and steps. The students also commented on how effective these strategies were at achieving authorial goals. Below is a selection of examples of this commentary.

“Claiming centrality is the most important part. This is the part that you catch the reader’s attention. If you cannot catch their attention; nothing is valuable.” (Gr2_4_NNS)

“That said, the interest is identified by the numerous citations, which serves to illustrate prominence. The authors can use this to be more efficient in word count, but also to illustrate how the interest of a few flourished into a topic of prominence of many.” (Gr2_10_NS)

“Overlaps [of steps and moves] are normal. To back up an idea or to make your claim stronger you may use the other steps like giving information from the previous work.” (Gr1_2_NNS)

“There were a few times where steps were combined into a sentence. This is done because it is more clear and concise when you can use less words to accomplish more than one step.” (Gr1_4_NS)

The novice writers’ attempts to expound on rhetorical functions in Introduction sections constituted evidence of deeper engagement with the annotated texts, which suggested that they thought beyond content (i.e., what knowledge the writers told) to consider how expert writers conveyed content strategically in an argumentative way (i.e., transformed knowledge). In other words, not only were students learning the generic conventions and pinpointing structural patterns in expert usage of rhetorical functions, but they were also dissecting the strategic effectiveness of argument development. Additionally, the annotated corpus affordance of RWT stimulated students’ immersion in macro- and micro-level analysis of disciplinary texts, which has been recognized as critical for novices’ connection to their disciplinary communities (Bernardini, 2004). This immersion also helped them understand the important relationship between texts, writers, and audience, thus enhancing the dimensions of genre knowledge they were acquiring through corpus exploration. On a broader scale, this also lended support to the value of conceptualizing technology-enhanced DDL as a paradigm for genre writing pedagogy guided by linguistic, rhetorical, and cognitive writing theories (see Figure 1).

Furthermore, to establish whether the language use analysis task was conducive to the noticing of language patterns, we examined the step-specific examples of functional language that the students extracted while concordancing in RWT. The students in Group 1 compiled a total of 759 examples (125 for Move 1; 152 for Move 2; 193 for Move 3), and Group 2 students compiled 815 examples (163 for Move 1; 137 for Move 2; 200 for Move 3). Figure 10 shows the percentages of representative, indicative, and non-representative language use examples.

![](img/c1364dad6eb7587727aa0639e115fe98e869446dae1be1af05e6a9cb50d6148d.jpg)  
Figure 10. Analysis of language use patterns per group and language background

Figure 11 shows that the examples of language use compiled by each group were mostly representative (for samples of representative linguistic signals for each step, see Appendix). A similar level of comparability can be claimed between NNSs and NSs in both groups, who were able to select representative examples of all the steps. Assuming that the participants, as novice research writers, had no explicit knowledge of the lexicogrammatical conventions of the genre before they undertook the DDL tasks, it can be inferred that RWT’s concordancer may have enhanced their noticing of appropriate functional language. The overwhelming proportion of representative examples identified by all students suggests their ability to recognize functional language indicative of specific rhetorical intent. Identifying indicative and representative linguistic choices can be particularly beneficial to NNSs learning a genre, as confirmed by Lax (2002). Essentially, this can enable students to populate a linguistic toolbox of lexis specific to different rhetorical functions from which they may draw in drafting their own texts. Similarly, NSs can apply such move- or step-specific phraseology to ensure the explicitness of their rhetorical intent.

![](img/d8bd80d880902ac8c133326b1c627f7aa4b953ebe2aec51d8f7f348d3146120d.jpg)  
Figure 11. Analysis of language use patterns within groups per move

In general, identifying illustrative authentic examples allows student-researchers to observe generalizable linguistic patterns (Baker, 2006), to devise more accurate explanations of uses and linguistic discourse forms not provided in traditional intuition-based descriptions (Kennedy, 2003), and to extend potential knowledge gain beyond the rules or patterns the teachers may possibly offer (Johns, 1991). Aside from that, recognition of functional language may also stimulate procedural aspects of genre learning. Previous DDL research has revealed that completing linguistic analyses such as those described in this study encourages learner autonomy, as students become independently responsible for what they take home from the data— a factor that increases their language awareness (Boulton, 2009).

# Improvement in Genre Writing

For the second strand of our inquiry, we aimed to determine whether the DDL learning events facilitated by RWT contributed to improvement in the quality of students’ genre writing. Move or step occurrences in first and last drafts were juxtaposed for between- and within-groups comparisons as well as for individual students. The Mann-Whitney U tests showed no statistically significant difference in move or step occurrences between Group 1 $( M d n = 1 0 . 5 )$ and Group 2 $( M d n = 4 )$ , $U = 1 6 3 . 5 , p = . 3 2 1$ , $r = . 1 6 .$ . However, there was a significant difference with a low effect size between NNSs $( M d n = 1 0 . 5 )$ and NSs $( M d n = 3 )$ , $U = 1 2 7 . 5 , p = . 0 4 9$ , $r = . 3 1$ . Furthermore, there was no statistical difference between the first drafts of NSs and NNSs, indicating that they did not start off differently. These results suggest that the DDL learning events did not impact the students in the two groups differently, but did seem to impact NNSs more than NSs. One possible explanation could be that we only had 6 NSs for this comparison in the sample versus 16 NNSs. It may also be that explicit instruction and compiling language resources for writing in the genre motivated the NNSs as language learners to exercise different rhetorical strategies in order to practice using various linguistic means.

To determine whether there was improvement within each group, a Wilcoxon Signed-Ranks test was performed, indicating that within Group 1, move or step occurrences in the final draft $( M d n = 1 0 . 5 )$ were significantly higher than in the first draft $M d n = 6$ ; $z = - 2 . 6 5 4$ , $p = . 0 0 8 )$ with a medium effect size $( r = . 5 9 )$ . For Group 2, move or step occurrences in the final draft $( M d n = 4 )$ were not significantly higher than in the first draft $( M d n = 2$ ; $z = - 1 . 8 5 8$ , $p = . 0 6 3$ , $r = . 4 2 )$ ). This is not entirely unexpected, given that Group 2 contained more native speakers $( n = 4 )$ than Group 1 $( n = 2 )$ who may have used more appropriate functional language in both drafts. The within-groups comparisons showed that the move or step occurrences in the final drafts of NNSs $M d n = 6 4 { \cdot }$ were significantly higher than in their first drafts $M d n = 5 1$ ; $z = - 2 . 6 9 9 , p$ $= . 0 0 7 , r = . 7 )$ , whereas the final drafts of NSs $M d n = 7 1$ ) were not significantly different than their first drafts $( M d n = 6 6$ ; $z = - . 6 7 7$ , $p = . 4 9 8$ , $r = . 2 8 )$ . This result may derive from individual student differences. For example, Group 1 had mostly doctoral students, two of whom were applied linguists, so a somewhat higher uptake for students at a more advanced academic level and with greater linguistic awareness is not surprising.

The occurrences of each move and step in first and final drafts were then compared for individuals. Table 3 presents the results of the within-student comparison based on the Wilcoxon Signed-Rank test. 13 students from both groups, both NNSs and NSs, showed statistically significant improvement in rhetorical composition from first to last draft. 11 of those students were NNSs. These results are in line with writing improvement found by Tribble and Wingate (2013) and Bianchi and Pazzaglia (2007).

Table 3. Wilcoxon Signed-Ranks Test for Individual Differences in Rhetorical Composition   

<html><body><table><tr><td>Student ID</td><td></td><td>p</td><td>r</td></tr><tr><td>Gr1 1 NNS</td><td>-2.30</td><td>.022*</td><td>-.51</td></tr><tr><td>Gr1 2 NNS</td><td>-0.78</td><td>.438</td><td>-.17</td></tr><tr><td>Gr1 3 NNS</td><td>-1.98</td><td>.048*</td><td>-.44</td></tr><tr><td>Gr1_4_NS</td><td>-0.54</td><td>.589</td><td>-.12</td></tr><tr><td>Gr1_5_NS</td><td>-0.80</td><td>.422</td><td>-.18</td></tr><tr><td>Gr1 6 NNS</td><td>-2.32</td><td>.021*</td><td>-.52</td></tr></table></body></html>

<html><body><table><tr><td>Gr1 7 NNS</td><td>-0.98</td><td>.327</td><td>-.22</td></tr><tr><td>Gr1 9 NNS</td><td>-2.50</td><td>.012*</td><td>-.56</td></tr><tr><td>Gr1 10 NNS</td><td>-2.57</td><td>.010**</td><td>-.57</td></tr><tr><td>Gr1 11 NNS</td><td>-1.41</td><td>.157</td><td>-.32</td></tr><tr><td>Gr1 12 NNS</td><td>-2.14</td><td>.032*</td><td>-.48</td></tr><tr><td>Gr2 1 NNS</td><td>-2.56</td><td>.011*</td><td>-.57</td></tr><tr><td>Gr2_2_NNS</td><td>-2.30</td><td>.022*</td><td>-.51</td></tr><tr><td>Gr2 3 NNS</td><td>-1.38</td><td>.168</td><td>-.31</td></tr><tr><td>Gr2 4 NNS</td><td>-2.06</td><td>.040*</td><td>-.46</td></tr><tr><td>Gr2 5 NNS</td><td>-1.99</td><td>.047*</td><td>-.44</td></tr><tr><td>Gr2 6 NS</td><td>-2.61</td><td>.009**</td><td>-.58</td></tr><tr><td>Gr2 7 NS</td><td>-0.48</td><td>.630</td><td>-.12</td></tr><tr><td>Gr2 8 NS</td><td>-0.80</td><td>.423</td><td>-.18</td></tr><tr><td>Gr2 9 NNS</td><td>-2.41</td><td>.016*</td><td>-.54</td></tr><tr><td></td><td>-2.82</td><td>.005**</td><td>-.63</td></tr><tr><td>Gr2 10 NS</td><td></td><td></td><td></td></tr><tr><td>Gr2 11 NNS</td><td>-0.90</td><td>.369</td><td>-.20</td></tr></table></body></html>

Note. \* significant at $p < . 0 5$ , \*\* Significant at $p < . 0 I$

In both groups, students’ distribution of moves mirrored their pattern noticing in the rhetorical structure analysis, similar to the participants in Friginal (2013). For example, all moves occurred in their last drafts, but Move 1 was most extensive. More noteworthy is the step-level comparison between first and last drafts. Figure 12 shows that all the students included a lot of Move 1, Step providing general background, in their first drafts, and balanced that with more Move 1, Step reviewing previous research, in their last drafts. The students whose drafts improved significantly reconsidered the extent of some steps and added new steps that they observed in the annotated disciplinary texts. In particular, Move 3 steps occurred more frequently and at a higher rate in the last drafts of students who showed significant improvement (see more spikes in the middle of the respective graph). More extended and varied use of steps can be considered a positive outcome, for it suggests that the students were able to apply the rhetorical patterns they identified in the corpus. Indirectly, this result also speaks to the usefulness of RWT feedback, which guided the students towards exercising discipline-specific conventions by comparing their drafts with a disciplinary corpus and pinpointing the steps that are commonly used in the discipline but were either lacking or insufficiently developed by the student. When conducting manual analysis, we also noted changes in distribution, order, and rhetorical overlap indicative of conscious attempts to reshape and transform their empirical knowledge.

Figure 12. Significant and non-significant step-level improvement from first to last drafts   

<html><body><table><tr><td>G2_10_NS G2_9_NNS 40% G1_6_NNS 36</td><td>First drafts G1_1_NNS 70% G1_3_NNS 60%</td><td>Last drafts G1_1_NNS 70% G2_10_NS G1_3_NNS 60% G2_9_NNS 40%</td></tr><tr><td>First drafts Last drafts G1_2_NNS G1_2_NNS 90% 80% 80% 70% G2_11_NNS 70% G1_4_NS G2_11_NNS 60% 60% 50% 50% G2_8_NS G1_5_NS G2_8_NS 0% G2_7_NS G1_7_NNS G2_7_NS G2_3_NNS G1_11_NNS G2_3_NNS M1_Step:Claiming centrality M1_Step:Review previous research M1_Step:Providing general background M2_Step: Indicating a gap M2_Step:Highlighting a problem M2_Step: Raising general questions M2_Step:Proposing general hypotheses M2_Step: Presenting justification M3_Step: Introducing present research descriptively M3_Step:Introducing present research purposefully =M3_Step:Presenting research questions M3_Step:Presenting research hypotheses M3_Step:Clarifying definitions M3_Step:Summarizing methods =M3_Step:Announcing principal outcomes M3_Step:Stating the value of present research M3_Step:Outlining the structure of the paper</td></tr></table></body></html>

The next level of analysis extended from move or step occurrences to actual text changes made to improve the drafts. The students made text modifications in content, lexis, grammar, structure, and mechanics (italicized in the examples given in Table 4), which is similar to Cotos (2014b) where students used the prototype of RWT’s Analyze my writing module for revision based on automated rhetorical feedback.

Table 4. Text Modifications and Examples   

<html><body><table><tr><td>Text modifications</td><td>First draft</td><td>Final draft</td></tr><tr><td>Content [Gr2_1_NNS]</td><td>&quot;However, there are no studies which. have investigated the effect of corpus- based activities on students&#x27; use of transitional words in academic writing.&quot;</td><td>&quot;So far, research on the acquisition of. transitional words only focused on the use of transitional words in research articles (Cresswell, 2007; Shaw, 2009), but no studies have investigated the effect of corpus-based activities on students&#x27; use of transitional words in</td></tr></table></body></html>

<html><body><table><tr><td>Lexis [Gr1_10_NNS]</td><td>&quot;Nevertheless, there are studies analyzing&quot;Despite numerous literature on peer the effects of keeping classmates peers together in elementary school.&quot;</td><td>effects in general and on education in particular, the study of the effects of keeping classmates peers together during elementary school has been neglected&quot;</td></tr><tr><td>Grammar [Gr2_6_NS]</td><td>DHA on memory and learning. strongly associated with cognitive function than were either EPA or ALA (6).&quot;</td><td>&quot;In a study that examined influences of&quot;In a study that examined influences of DHA on memory and learning throughout the lifespan, DHA was more throughout the lifespan, DHA was more strongly associated with cognitive function than was either EPA or ALA (6).&quot;</td></tr><tr><td>Structure [Gr2_11_NNS]</td><td>&quot;Based on these analyses, this literature review will be organized in two parts. The first is the review of influence from the resource mobilization on the strike-. prone.&quot;</td><td>&quot;The remainder of the paper is. organized as follows: section 2 includes a comprehensive literature review including the labor process theory related to job autonomy and employee participation, and section 3 describes the methodology and concrete</td></tr><tr><td>Mechanics [Gr1_7_NS]</td><td>14N and 15N, which both have potential 14N and 15N, both of which have both have shortcomings and neither has  however, both have shortcomings and become apparent as the predominant nuclei for magnetic detection in solids. predominant nuclei for magnetic</td><td>variables.&quot; &quot;Nitrogen has two NMR active isotopes, &quot;Nitrogen has two NMR active isotopes, for spectroscopic investigation, however, potential for spectroscopic investigation, neither has become apparent as the detection in solids.&quot;.</td></tr></table></body></html>

As further shown in Figure 13, in our study, most modifications were in content, which presents a special interest. Even though the DDL tasks did not draw students’ attention to the content realizations of moves, they did seem to have noticed the types of information that contribute to expert knowledge-building when accomplishing move goals. This indicates that their close reading, as well as their reflections mentioned above, enhanced the procedural aspect of genre knowledge.

![](img/63d32f62f156d5a7ca0fd76e8215dacf39981b25c0efba7a18c95eb7f2ea497e.jpg)  
Figure 13. Text modifications per group and language background

Overall, based on first–last draft differences, we can claim that students’ interaction with RWT during DDL learning events enhanced the quality of their genre writing. Importantly, evidence from learners’ noticing of compositional and linguistic patterns and the transfer of students’ corpus observations to their own writing reinforces our assumption that DDL can contribute to genre learning across student groups and language backgrounds.

# Conclusion

Helping novice writers to transition from knowledge-telling to knowledge-transforming proves a continuing challenge for educators of NS and NNS students alike. In this mixed-methods investigation of uses of DDL through RWT, results of multi-level comparisons corroborate the enormous potential for combining the top-down and bottom-up approaches explored by Charles (2014) and Cortes (2007). Our participants demonstrated the ability to tease out conventional patterns of rhetorical composition and functional language use, and then applied them when revising their drafts. These processes are indicative of the development of rhetorical, formal, and procedural aspects of genre knowledge, which we initially aimed to foster through our DDL approach. These results provide confirmation of DDL’s suitability for both NNSs and NSs, and also lend credence to uses of complex corpus-based platforms that extend beyond stand-alone concordancers.

While the results are encouraging, some methodological limitations should be acknowledged. First, we could not compare control and experimental groups, as only one section of the course was offered per semester. While this allowed us to see whether our approach yielded the same effects for different groups of students, a direct control versus experimental-groups design in future iterations of the course should provide a better appreciation of the impact of the approach, serving to strengthen validity and potentially permit more confident generalization. In further research, it would be interesting to examine not only first and last drafts, but also the multiple iterations of student drafts submitted to RWT for automated rhetorical feedback. Future studies should also include perception and introspection data to help explain students’ choices in revision and thus provide a clearer picture of how knowledge is acquired through interactive DDL.

Despite these limitations, this study enriches understanding of DDL as a means of developing genre writing. Through the application of a corpus-based platform to facilitate NNS and NS writers’ awareness and composition of the target genre, we have highlighted possible ways to deepen cognitive involvement and improve writing strategies. With our adoption of combined theoretical views and techniques that attend to the spectrum of constructs of genre knowledge, we hope to lay the ground for a DDL-substantiated conceptual framework that could guide genre-writing pedagogy and empirical inquiry.

# Acknowledgements

We gratefully acknowledge the editors’ and the anonymous reviewers’ insightful comments and recommendations. We also thank the students who agreed to participate in our study. The development of the RWT was financially supported by the Computational Advisory Committee, Graduate College, College of Engineering, and the College of Liberal Arts and Sciences at Iowa State University, USA.

# Notes

1. AL has been highly influential in literacy research and pedagogy in higher education. For an insightful overview of the approaches to academic English and perspectives on English as a lingua franca, see Jenkins (2014).   
2. Elaborating on this debate is outside the scope of this article, but it should not escape our notice that different scholars challenge this criticism and highlight clear points of overlap among these perspectives (e.g., Bawarshi & Reiff, 2010; Coffin & Donohue, 2012; Cotos, 2014b; Ramanathan & Kaplan, 2000).   
3. Tardy (2009) also includes subject-matter knowledge.   
4. The intention is to make RWT available to educators and researchers upon request, in compliance with university terms of agreement.   
5. The instructional, learning, and assessment events are defined in the knowledge-learning-instruction framework, which offers a systematic approach to applying research to educational practice (Koedinger, Corbett, & Perfetti, 2012).   
6. RWT accuracy measures are reported in Cotos and Pendar (2016).

# References

Anthony, L., & Lashkia, G. (2003). Mover: A machine learning tool to assist in the reading and writing of technical papers. IEEE Transactions on Professional Communication, 46(3), 185–193.   
Aston, G. (Ed.). (2001). Learning with corpora. Houston, TX: Athelstan.   
Baker, P. (2006). Using corpora in discourse analysis. New York, NY: Continuum.   
Bawarshi, A. S., & Reiff, M. J. (2010). Genre: An introduction to history, theory, research, and pedagogy. West Lafayette, IN: Parlor Press.   
Baynham, M. (2000). Academic writing in new and emergent discipline areas. In M. Lea & B. Stierer (Eds.), Student writing in higher education: New contexts (pp. 17–31). Buckingham, UK: Open University Press.   
Bereiter, C., & Scardamalia, M. (1987). The psychology of written composition. Hillsdale, NJ: Lawrence Erlbaum Associates.   
Bernardini, S. (2004). Corpora in the classroom: An overview and some reflections on future development. In J. Sinclair (Ed.), How to use corpora in language teaching (pp. 15–36). Amsterdam, Netherlands: John Benjamins.   
Bianchi, F., & Pazzaglia, R. (2007). Student writing of research articles in a foreign language: Metacognition and corpora. In R. Fachinetti (Ed.), Corpus linguistics 25 years on (pp. 259–287). Amsterdam, Netherlands: Rodopi.   
Boulton, A. (2009). Testing the limits of data-driven learning: Language proficiency and training. ReCALL, 21(1), 37–54.   
Boulton, A. (2010a). Data-driven learning: On paper, in practice. In T. Harris & M. Moreno Jaén (Eds.), Corpus linguistics in language teaching (pp. 17–52). Bern, Switzerland: Peter Lang.   
Boulton, A. (2010b). Learning outcomes from corpus consultation. In M. Moreno Jaén, F. Serrano Valverde, & M. Calzada Pérez (Eds.), Exploring new paths in language pedagogy: Lexis and corpusbased language teaching (pp. 129–144). London, UK: Equinox.   
Boulton, A. (2011). Data-driven learning: The perpetual enigma. In S. Gozdz-Roszkowski (Ed.), Explorations across languages and corpora (pp. 563–580). Frankfurt, Germany: Peter Lang.   
Boulton, A. (2012). Corpus consultation for ESP: A review of empirical research. In A. Boulton, S. Carter-Thomas, & E. Rowley-Jolivet (Eds.), Corpus-informed research and learning in ESP: Issues and applications (pp. 263–293). Amsterdam, Netherlands: John Benjamins.   
Boulton, A., & Cobb, T. (2017). Corpus use in language learning: A meta-analysis. Language Learning, 67(2), 348–393.   
Braun, S. (2005). From pedagogically relevant corpora to authentic language learning content. ReCALL, 17(1), 47–64.   
Chambers, A., & O’Sullivan, Í. (2004). Corpus consultation and advanced learners’ writing skills in French. ReCALL, 16(1), 158–172.   
Chapelle, C. A., Cotos, E., & Lee, J. (2015). Validity arguments for diagnostic assessment using automated writing evaluation. Language Testing, 32(3), 385–405.   
Charles, M. (2007). Reconciling top-down and bottom-up approaches to graduate writing: Using a corpus to teach rhetorical functions. Journal of English for Academic Purposes, 6(4), 289–302.   
Charles, M. (2014). Getting the corpus habit: EAP students’ long-term use of personal corpora. English for Specific Purposes, 35(1), 30–40.   
Coffin, C., & Donohue, J. (2012). Academic literacies and systemic functional linguistics: How do they relate? Journal of English for Academic Purposes, 11, 64–75.   
Cohen, J. W. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum.   
Conrad, S. (1999). The importance of corpus-based research for language teachers. System, 27(1), 1–18.   
Cortes, V. (2007). Genre and corpora in the English for academic writing class. ORTESOL Journal, 25, 9–16.   
Cotos, E. (2011). Potential of automated writing evaluation feedback. CALICO Journal, 28(2), 420–459.   
Cotos, E. (2012). Towards effective integration and positive impact of automated writing evaluation in L2 writing. In G. Kessler, A. Oskoz, & I. Elola (Eds.), Technology across writing contexts and tasks, CALICO Monograph Series (Vol. 10, pp. 81–112). San Marcos, TX: CALICO.   
Cotos, E. (2014a). Enhancing writing pedagogy with learner corpus data. ReCALL, 26(2), 202–224.   
Cotos, E. (2014b). Genre-based automated writing evaluation for L2 research writing: From design to evaluation and enhancement. Basingstoke, UK: Palgrave Macmillan.   
Cotos, E. (2016). Computer-assisted research writing in the disciplines. In S. A. Crossley & D. S. McNamara (Eds.), Adaptive educational technologies for literacy instruction (pp. 225–242). New York, NY: Taylor & Francis, Routledge.   
Cotos, E., & Huffman, S. (2013). Learner fit in scaling up automated writing evaluation. International Journal of Computer-Assisted Language Learning and Teaching, 3(3), 77–98.   
Cotos, E., Huffman, S., & Link, S. (2015). Furthering and applying move/step constructs: Technologydriven marshalling of Swalesian genre theory for EAP pedagogy. Journal of English for Academic Purposes, 19, 52–72.   
Cotos, E., & Pendar, N. (2016). Discourse classification into rhetorical functions for AWE feedback. CALICO Journal, 33(1), 92–116.   
Cresswell, J., & Clark, V. (2011). Designing and conducting mixed methods research (2nd ed.). Thousand Oaks, CA: Sage Publications.   
Fox, G. (1998). Using corpus data in the classroom. In B. Tomlinson (Ed.), Materials development in language teaching (pp. 25–43). Cambridge, UK: Cambridge University Press.   
Friginal, E. (2013). Developing research report writing skills using corpora. English for Specific Purposes, 32(4), 208–220.   
Gaskell, D., & Cobb, T. (2004). Can learners use concordance feedback for writing errors? System, 32, 301–319.   
Gilquin, G., & Granger, S. (2010). How can DDL be used in language teaching? In A. O’Keeffe & M. McCarthy (Eds.), The Routledge handbook of corpus linguistics (pp. 359–369). London, UK: Routledge.   
Hayes, J. R., Flower, L., Schriver, K. A., Stratman, J. F., & Carey, L. (1987). Cognitive processes in revision. In S. Rosenberg (Ed.), Advances in applied psycholinguistics (Vol. 2, pp. 176–241). New York, NY: Cambridge University Press.   
Henry, A. (2007). Evaluating language learners’ response to web-based, data-driven, genre teaching materials. English for Specific Purposes, 26, 462–484.   
Hulstijn, I. (2015). Language proficiency in native and non-native speakers: Theory and research. Amsterdam, Netherlands: John Benjamins.   
Jenkins, J. (2014). English as a lingua franca in the international university. Abingdon, UK: Routledge.   
Johns, T. (1990). From printout to handout: Grammar and vocabulary teaching in the context of datadriven learning. CALL Austria, 10, 14–34.   
Johns, T. (1991). Should you be persuaded: Two examples of data-driven learning materials. English Language Research Journal, 4, 1–16.   
Johns, T. (2002). Data-driven learning: The perpetual challenge. In B. Kettemann, & G. Marko, (Eds.), Teaching and learning by doing corpus analysis (pp. 107–117). Amsterdam, Netherlands: Rodopi.   
Johns, T., & King, P. (1991). English Language Research Journal Vol. 4: Classroom Concordancing. Birmingham, UK: The University of Birmingham.   
Kennedy, G. (2003). Amplifier collocations in the British National Corpus: Implications for English language teaching. TESOL Quarterly, 37(3), 467–487.   
Koedinger, K. R., Corbett, A. C., & Perfetti, C. (2012). The knowledge-learning-instruction (KLI) framework: Bridging the science-practice chasm to enhance robust student learning. Cognitive Science, 36(5), 757–798.   
Landis, J. R., & Koch, G. G. (1977). The measurement of observer agreement for categorical data. Biometrics, 33(1), 159–174.   
Lax, J. (2002). Academic writing for international graduate students. Paper presented at the American Society for Engineering Education and Institute for Electrical and Electronics Engineers Frontiers in Education Conference, Boston, MA.   
Lea, M. R., & Street, B. (1998). Student writing in higher education: An academic literacies approach. Studies in Higher Education, 23(2), 157–172.   
Lea, M. R., & Street, B. (2006). The ‘academic literacies’ model: Theory and applications. Theory into Practice, 45(4), 368–377.   
Lee, D., & Swales, J. (2006). A corpus-based EAP course for NNS doctoral students: Moving from available specialized corpora to self-compiled corpora. English for Specific Purposes, 25(1), 56–75.   
Leech, G. (1997). Teaching and language corpora: A convergence. In A. Wichmann, S. Fligelstone, A. M. McEnery, & G. Knowles, (Eds.), Teaching and language corpora (pp. 1–23). New York, NY: Addison Wesley Longman.   
Lillis, T. M. (2001). Student writing: Access, regulation, desire. London, UK: Routledge.   
Lillis, T. M., & Scott, M. (2007). Defining academic literacies research: Issues of epistemology, ideology, and strategy. Journal of Applied Linguistics, 4(1), 5–32.   
Ortega, L. (2013). SLA for the 21st century: Disciplinary progress, transdisciplinary relevance, and the bi-multilingual turn. Language Learning, 63, 1–24.   
Pallant, J. (2007). SPSS survival manual: A step by step guide to data analysis using SPSS for Windows (3rd ed.). Glasgow, UK: Bell & Brain.   
Pérez-Paredes, P., Sánchez-Tornel, M., & Alcaraz Calero, J. M. (2012). Learners’ search patterns during corpus-based focus-on-form activities: A study on hands-on concordancing. International Journal of Corpus Linguistics, 17(4), 482–515.   
Plonsky, L., & Oswald, F. L. (2014). How big is ‘big’? Interpreting effect sizes in L2 research. Language Learning, 64(4), 878–912.   
Ramanathan, V., & Kaplan, R. B. (2000). Genres, authors, discourse communities: Theory and application for (L1 and) L2 writing instructors. Journal of Second Language Writing, 9(2), 1–5.   
Rodgers, O., Chambers, A., & Le Baron-Earle, F. (2011). Corpora in the LSP classroom: A learnercentred corpus of French for biotechnologists. International Journal of Corpus Linguistics, 16(3), 391–411.   
Starfield, S. (2004). Why does this feel empowering? Thesis writing, concordancing and the ‘corporatising’ university. In B. Norton & K. Toohey (Eds.), Critical pedagogies and language learning (pp. 138–157). Cambridge, UK: Cambridge University Press.   
Swales, J. M. (1981). Aspects of article introductions. Birmingham, UK: University of Aston, Language Studies Unit.

Swales, J. M. (1990). Genre analysis: English in academic and research settings. Cambridge, UK: Cambridge University Press.

Swales, J. M. (2004). Research genres: Explorations and applications. Cambridge, UK: Cambridge University Press.

Swales, J. M., & Feak, C. B. (2012). Academic writing for graduate students: Essential tasks and skills (3rd ed.). Ann Arbor, MI: University of Michigan Press.

Tardy, C. M. (2009). Building genre knowledge. West Lafayette, IN: Parlor Press.

Todd, R. W. (2001). Induction from self-selected concordances and self-correction. System, 29(1), 91– 102.

Tono, Y., Satake, Y., & Miura, A. (2014). The effects of using corpora on revision tasks in L2 writing with coded error feedback. ReCALL, 26(2), 147–162.

Tribble, C., & Wingate, U. (2013). From text to corpus: A genre-based approach to academic literacy instruction. System, 41, 307–321.

Vyatkina, N. (2016). Data-driven learning of collocations: Learner performance, proficiency, and perceptions. Language Learning & Technology, 20(3), 159–179. Retrieved from http://llt.msu.edu/issues/october2016/vyatkina.pdf

Wingate, U. (2012). Using academic literacies and genre-based models for academic writing instruction: A ‘literacy’ journey. Journal of English for Academic Purposes, 11, 26–37.

Wingate, U., & Tribble, C. (2012). The best of both worlds? Towards an English for academic purposes/academic literacies writing pedagogy. Studies in Higher Education, 37(4), 481–495.

Yoon, H. (2008). More than a linguistic reference: The influence of corpus technology on L2 academic writing. Language Learning & Technology, 12(2), 31–48. Retrieved from http://llt.msu.edu/vol12num2/yoon.pdf

Appendix. Samples of Representative Linguistic Signals for the Steps of Each Move Compiled by Students   

<html><body><table><tr><td>Steps in Move 1</td><td>Examples of Language Use</td></tr><tr><td>Claiming centrality</td><td>Current research affirms the importance of, receiving increasing attention worldwide; has been at the center of discussion in all of, have been documented in a considerable body of research; have recently gained more popularity</td></tr><tr><td>Providing general background</td><td>It is commonly known; nearly all cases; Such requirements are generally; it is a widely recognized fact</td></tr><tr><td>Reviewing previous research</td><td>Researchers have previously reported; finding was that; [author] conducted a similar study,; Similar results were reported by; [author] measured ... and inferred that...</td></tr></table></body></html>

<html><body><table><tr><td>Steps in Move 2</td><td>Examples of Language Use</td></tr><tr><td>Indicating a gap</td><td>has been limited; Unfortunately... does not exist; within this body of literature, However, the literature is less clear about; No studies have investigated; have not been explicitly explored</td></tr></table></body></html>

<html><body><table><tr><td>Highlighting a problem.</td><td>there were several major drawbacks; It is difficult to determine; There is controversy among; particularly daunting; have limited or no validity; faces large opposition; is constrained by</td></tr><tr><td>Raising general questions</td><td>But is this truly...?; What related issues press for...?; One question that arises is how..., Should the company develop...? Or perhaps...? How is... extracted from and returned to...?</td></tr><tr><td>Proposing general hypotheses</td><td>understanding of relationship may also enable the development of, may have a great influence on; These... may relate, in part, to; are expected to</td></tr><tr><td>Presenting justification</td><td>have an influence on; One possibility is that Investigation of... is necessary for us to discover; It is important to</td></tr><tr><td></td><td>understand... in order to; have resulted in the need to; needs to be studied systematically; Therefore it is very necessary to study the reasons for; should be subjected to closer scrutiny</td></tr></table></body></html>

<html><body><table><tr><td>Steps in Move 3 Examples of Language Use</td><td></td></tr><tr><td>Introducing present research descriptively</td><td>The present study reports data from an investigation of, This paper is an evolving description of, In this article, we focus on; Our attention centers</td></tr><tr><td>Announcing present. research purposefully</td><td>on; This study concerns the One goal of this study was to find evidence of, The primary aim of this study is to evaluate whether; This study set out to explore; The aim is to</td></tr><tr><td>Presenting research questions</td><td>investigate (1)...(2)...(3); in order to validate the model Two research questions I want to raise in this article are; The research questions that guided this study were; whether the positive associations</td></tr><tr><td>Presenting research hypotheses</td><td>between... differ in strength depending on in which we assume that... are possible; The working hypotheses of this. experiment were; Given the history of research, we predicted that;</td></tr><tr><td>Clarifying definitions</td><td>Assuming that... is the.... outcome is defined in terms of, In this article, we will follow X&#x27;s notion of, As in...</td></tr><tr><td>Summarizing methods</td><td>study, [term] will be used to refer to; I am using the term &quot;...&quot; in the sense of, For brevity, we henceforth refer to the &quot;... &quot; as [term] In our research project we observed and videotaped; A comparison was</td></tr><tr><td>Announcing principal outcomes</td><td>made between; was conducted under simplified conditions; We utilize the... method; was evaluated through The findings reveal; we detect the characteristic; The findings indicate that; The experimental results agree satisfactorily with; In regard to #3,</td></tr><tr><td>Stating the value of present research</td><td>the results demonstrate; The most abundant were shown to be; We show that; This study contributes to disentangling the question; This work marks the first time multiple... have been used; The experimental results that we</td></tr><tr><td>Outlining the structure of the paper</td><td>report here provide an insight into; This article is one of the first to provide; can be of value to This paper is organized as follows; The article begins with; The results are presented, followed by; To this end, we first discuss... We then present; In</td></tr></table></body></html>

# About the Authors

Elena Cotos is an Assistant Professor of Applied Linguistics and the Director of the Center for Communication Excellence of the Graduate College at Iowa State University. She investigates genre writing in the disciplines, corpus and genre-based writing pedagogy, automated writing evaluation, and linguistic realizations of academic discourse for applied natural language processing applications.

# E-mail: ecotos@iastate.edu

Stephanie Link is an Assistant Professor of TESL and Applied Linguistics at Oklahoma State University. Her primary research interests are in the development and evaluation of emerging technologies for computer-assisted language learning with a special focus on L2 writing, genre analysis, and systemic functional linguistics for language analysis and second language pedagogy.

E-mail: steph.link@okstate.edu

Sarah Huffman is the Assistant Director of the Center for Communication Excellence of the Graduate College at Iowa State University. Her research interests include genre analysis, academic writing pedagogy, graduate writing tutor training, and systemic functional linguistic approaches to language development.

E-mail: shuffman@iastate.edu