# Understanding teachers’ written feedback practices in Hong Kong secondary classrooms

Icy Lee \*

Ho Tim Building, Faculty of Education, The Chinese University of Hong Kong, Hong Kong, China

# Abstract

Much of L2 teacher feedback research is conducted with advanced students in process-oriented classrooms in the United States. There is less published research about how school teachers in EFL contexts respond to student writing. Specifically little is known about why teachers respond to writing in the ways they do, and if discrepancies exist between teachers’ feedback practices and recommended principles, the reasons that may account for the disjuncture. The present study serves to fill these gaps by examining the written feedback provided by 26 Hong Kong secondary English teachers to 174 student texts, followed up by interviews with 6 of the teachers to find out the factors that have influenced their responding practices. The findings indicate that teachers’ written feedback occurred in single-draft classrooms and was primarily error-focused, contravening the principles recommended in local curriculum documents. The interview data highlight four important issues that shed light on teachers’ feedback practices: accountability, teachers’ beliefs and values, exam culture, and (lack of) teacher training. It is concluded that teachers’ feedback practices are influenced by a myriad of contextual factors including teachers’ beliefs, values, understandings, and knowledge, which are mediated by the cultural and institutional contexts, such as philosophies about feedback and attitude to exams, and socio-political issues pertaining to power and teacher autonomy.

$©$ 2007 Elsevier Inc. All rights reserved.

Keywords: L2 writing; Feedback in writing; Teachers’ feedback practices

# Introduction

The bulk of L2 teacher feedback research is conducted with advanced students in North American college contexts where process pedagogy permeates, and as a result, published advice about feedback is primarily drawn from this center of research (e.g., Ferris, 2002, 2003;

Goldstein, 2005). There is less published research about how teachers working in other contexts, such as EFL school context, respond to student writing. Scant attention, in particular, has been paid to why teachers respond to student writing in the ways they do, and if discrepancies exist between teachers’ feedback practice and recommended principles, the reasons that may account for the disjuncture. This article helps to fill these gaps by investigating how secondary teachers in Hong Kong respond to student writing, the extent their feedback practices correspond with recommended principles, and the factors that have influenced their feedback practices. In this study, the focus is on teacher-written feedback (though feedback research also includes peer feedback, computer-mediated feedback, and writing conferences).

# Published feedback research and advice

What does the literature say about how teachers give feedback to student writing and the reasons that influence their practice, and what feedback principles emerge from recent feedback research? This section reviews L2 feedback research and the recommended principles in three main areas: focus of teacher feedback, error correction, and written commentary.

# Focus of teacher feedback

Some earlier studies of teacher feedback showed that teachers focused predominantly on language errors in student writing (e.g., Cumming, 1985; Zamel, 1985). This is because writing was primarily treated as a product, and teachers tended to see themselves as language teachers rather than writing instructors (Ferris, 2003; Zamel, 1985). With the advent of process approaches to writing instruction, there are more studies that report a shift in teachers’ focus from form to other issues such as content and organization (e.g., Caulk, 1994; Cohen & Cavalcanti, 1990; Conrad & Goldstein, 1999; Ferris, 1995a; Saito, 1994). In Ferris’ (1997) study, for example, it was found that $15 \%$ of teachers’ comments focused on grammar and mechanics, while $85 \%$ addressed students’ ideas and rhetorical development (Ferris, 1997; Ferris, Pezone, Tade, & Tinti, 1997). It is recommended that teachers provide balanced coverage in their written feedback, focusing on issues relating to content, structure, organization, language, and style (Ferris, 2003; Hyland & Hyland, 2006a; Zamel, 1985). Since a focus on the written product instead of writing process could divert teachers’ and students’ attention to form, teachers are advised to give feedback to multiple rather than single drafts (Ferris, 1997; Hyland & Hyland, 2006a).

# Error correction

A substantial amount of teacher feedback research is concerned with error correction, such as the types and extent of error feedback and their effects on student accuracy. When responding to errors, L2 teachers use direct and/or indirect feedback—direct referring to teachers’ provision of correct answers in response to student errors, and indirect to teachers’ indication of errors (e.g., by means of a circle, an underline, a code or a mark) with correction by students required. These strategies are used for different reasons. Direct feedback is used when teachers feel the error in question is complex and beyond students’ ability to self-correct (Ferris, 1999; Frodesen, 1991), whereas indirect feedback is used when teachers want to engage students in problem-solving and develop their independent editing skills (Ferris, 2002; Ferris & Hedgocok, 2005; Lalande, 1982). For indirect feedback, which can be coded (i.e., indicating error types such as ‘‘tense’’ and ‘‘preposition’’) or uncoded (i.e., simply underlining or circling an error without indicating error types), there is some evidence suggesting that teachers and students prefer coded feedback (Ferris & Roberts, 2001; Komura, 1999; Roberts, 1999), since it is believed that a higher level of explicitness is more conducive to reflection and cognitive engagement on the part of students (Ferris, 2002). Regardless of the error feedback strategies, some L2 teachers prefer marking all student errors to prevent fossilization (e.g., Lee, 2004; Higgs & Clifford, 1982; Lalande, 1982), while others have a preference for selective marking so that error correction is more manageable for students (Bates, Lane, & Lange, 1993; Ferris, 1995b; Hendrickson, 1978).

While teachers are free to use a combination of error feedback strategies, several principles have become prominent in recent literature. First, teachers are reminded that indirect error feedback is more beneficial to students’ long-term writing development than direct feedback (Ferris, 2003; Frantzen, 1995; Lalande, 1982), though teachers should still provide direct and indirect feedback judiciously according to error type and student needs (Ferris, 2006). Second, since codes can be obfuscating and cumbersome for both teachers and students (e.g., Ferris, 2002; Robb, Ross, & Shortreed, 1986), it is recommended that when codes are used they should be part of a consistent system of coded feedback that is supported by systematic grammar instruction, and they should be used judiciously (Ferris, 2002, 2003). Third, selective error feedback is generally more productive than marking of all errors, since comprehensive error feedback is exhausting for teachers and overwhelming for students (Ferris, 2002; Mantello, 1997).

# Written commentary

Apart from error feedback, research has looked into the nature of teachers’ written comments, such as their form and functions (see e.g., Ferris, 1995a, 1997; Hyland & Hyland, 2001). Earlier studies demonstrated that teachers gave vague, non-text specific and mostly negative comments (Cumming, 1985; Semke, 1984; Zamel, 1985), as teachers appeared to wear the hat of an evaluator judging student papers more or less in a vacuum. Teachers were found to appropriate student texts (Reid, 1994; Zamel, 1985), misinterpreting student meanings, and consequently confusing students through their written comments. However, more recent studies have shown that some teachers begin to be aware of the importance to shift away from a decontextualized approach in giving written commentary, as they realize that it is crucial to take into account the contextual factors, such as student characteristics and institutional requirements, and to build an interpersonal relationship with students through written commentary (Conrad & Goldstein, 1999; Goldstein, 2004; Hyland, 1998; Hyland & Hyland, 2001). It is recommended that teachers give clear, concrete and text-specific comments, including both praise and constructive criticism (Goldstein, 2004; Hyland & Hyland, 2001; Zamel, 1985), but more importantly do so through engaging with students and building relationships with them, giving helpful intervention to avoid appropriation (Goldstein, 2004, 2006; Hyland & Hyland, 2006b). Such advice, it must be noted, is relevant in process-oriented classrooms where students are required to act upon teacher commentary and revise their writing.

# Feedback in Hong Kong secondary context

# Recommended feedback principles

Apparently, published advice about feedback has made a direct impact on the Hong Kong secondary English curriculum. An examination of two central English language curriculum documents (CDC [Curriculum Development Council], 1999; CDC; HKEAA [Hong Kong Examinations and Assessment Authority], 2007) issued by the education authority, i.e., Education Bureau (EDB), which was, renamed from Education and Manpower Bureau (EMB) in July 2007 shows that the feedback guidelines are very much in line with the advice provided in the research literature. There is, however, not a specific section addressing the issue of feedback in the documents. Rather, the feedback guidelines are interspersed among the principles for the teaching of writing in both documents. They are extracted and categorized below.

Focus of feedback:

- Teachers ‘‘must avoid providing detailed editing comments on the surface form without paying attention to organizational and content issues’’ (CDC, 1999, p. 94). ‘‘Teachers should give comments on the drafts they have collected from learners. . .They should make suggestions which will enable learners to carry out revisions in the areas of organization, grammar and mechanics’’ (CDC & HKEAA, 2007, p. 83). - ‘‘Methodologies entirely focusing on language errors are hardly adequate in improving learners’ abilities’’ (CDC, 1999, p. 95).

Error correction:

- ‘‘Teachers need not correct all the mistakes in learners’ work. Total correction is timeconsuming for the teacher and discouraging for the learners, particularly when the latter see their papers full of red ink’’ (CDC, 1999, p. 95).   
- ‘‘Indicate mistakes so that learners can correct them’’ (CDC, 1999, p. 96).   
- ‘‘Using the same list of editing symbols supplied by the teacher earlier on, learners, either individually or in groups, will attempt to identify and correct some if not all of the mistakes for themselves’’ (CDC, 1999, p. 96).

Written commentary:

- ‘‘It is important that when evaluating a piece of learner writing, teachers do not just indicate its weaknesses but its strengths as well’’ (CDC, 1999, p. 95).   
‘‘When giving comments, teachers should offer positive support by praising what learners have   
done well in their drafts’’ (CDC & HKEAA, 2007, p. 86).

It is clear from the above that the EDB feedback guidelines provided for Hong Kong secondary teachers are largely consistent with the published feedback advice reviewed in the preceding section, though there is little emphasis on the issue of context like the student factor, that is, how teachers should gear commentary towards student needs. There is also no specific guidance about the combination of error feedback strategies, except that teachers are advised against comprehensive error feedback and over-reliance on direct error feedback.1

# Teachers’ practice

Of the limited existing evidence about Hong Kong secondary teachers’ feedback practice, there is some evidence suggesting a gulf between the recommended feedback advice and teachers’ practice. For example, local research has demonstrated that process pedagogy, on which effective feedback practices depend, is not being adopted in most Hong Kong secondary classrooms, and the exam-oriented context is found to be a major stumbling block for its implementation (Brock, 1995; Curtis, 2001; Curtis & Heron, 1998; Hamp-Lyons, 2006; Brock, Pennington, & Yue, 1996). This is borne out in the recent experience of Chen, Hamp-Lyons, and Mok (2001) in their attempt to develop materials to support secondary teachers’ use of process pedagogy. The results of their collaboration with frontline teachers have demonstrated that, apart from the dominant exam culture, it is the lack of support from school leaders that poses obstacles to more innovative pedagogy. Some teachers in the study admitted that they had to revert to the more traditional approach to protect themselves from criticism by department heads or principals, for fear that they might be blamed for students’ less exemplary exam results because of their involvement in innovative practices.

# Context and feedback

Feedback, therefore, does not occur in a vacuum but within a hierarchy of interrelating subsystems (Brock, 1995). Of all the subsystems, Kennedy (1988) thinks that the cultural and political systems exert the greatest influence on teachers’ practice. This has support from sociocultural theory, which maintains that human activities are embedded in particular cultural, historical, and institutional settings (Leontiev, 1981). Teachers’ response to student writing, specifically, is ‘‘laden with political content’’ (Leki, 1992, p. 125). More recently, Hyland and Hyland (2006b) reiterate that feedback practices are influenced by personal beliefs and mediated by the institutions and cultures in which teachers operate. Thus, context is increasingly acknowledged as a crucial factor in feedback.

Existing teacher feedback research, however, is mostly acontextual and non-social (Goldstein, 2001, 2006), drawing attention to how teachers (should) respond to student writing without looking into the ways teachers’ feedback practices reflect their personal belief systems and are constrained and/or influenced by their educational contexts. There certainly appears to be a gap in the current teacher feedback literature which fails to situate feedback in teachers’ specific contexts (especially in EFL school context), and to relate the ‘‘what’’ of teacher feedback to the bigger question of ‘‘why’’ to throw light on the mismatches, if any, between recommended feedback principles and teachers’ practices.

# The study

# Purpose of study

The present study was undertaken to fill the research gaps identified and answer the following research questions:

(1) How do Hong Kong secondary English teachers respond to student writing, and to what extent do the teachers’ feedback practices correspond with the recommended principles? (2) What factors have influenced the teachers’ feedback practices?

# Context of study

Given that the study focuses on the context as a possible factor in influencing teachers’ feedback practice, this section provides a backdrop against which subsequent data about teachers’ feedback practices can be interpreted.

In Hong Kong schools, English is a compulsory subject from kindergarten. There are two high-stakes public examinations at the end of Secondary 5 (Grade 11) (Hong Kong Certificate of Education Examination [HKCEE]) and Secondary 7 (Grade 13) (Hong Kong Advanced Level Examination [HKALE]), where English language is a compulsory subject for examination. HKALE is the territory’s university-entrance examination. For both HKCEE and HKALE, writing is a compulsory component in the English exam, where students are required to write essays of about 300 and 500 words respectively. Student papers in HKCEE and HKALE are scored holistically on a 6-point scale2 and 9-point scale,3 respectively, by markers recruited from practicing teachers. A pass in HKALE English is essential for entry into university. The status of English has not changed much in post-1997 Hong Kong (i.e., after turnover to China), since a good command of English is still considered a gateway to success (Lin, 1999; Tsui, 2004). A facility for written English, in particular, is deemed crucial as students enter tertiary education and the workplace. In Hong Kong universities, students are generally expected to write their assignments and exams in English, except for Chinese subjects. In the government and commercial sectors, although Chinese may be used in less formal levels of communication such as in-house memos, English is often used at more formal levels, for example, in external correspondences and business contracts.

When it comes to secondary English teaching, the local education authority EDB publishes guidelines for teachers in various curriculum documents (e.g., CDC, 1999, 2002, 2006). Schools are usually given one copy of each curriculum document, to be shared among more than 10 English teachers in each school. It is not uncommon to find these documents locked in bookcases or stored in remote English resource corners in schools, and it is uncertain how often busy English teachers in Hong Kong access these documents. In spite of the principles for English language teaching issued by the EDB, how teachers go about teaching in their own classroom is not mandated. In reality, more conventional teaching methods still prevail in Hong Kong schools, which are often attributed to the traditional school culture and domination of an exam culture (Evans, 1996; Davison, 2007; Hamp-Lyons, 2006).

Nevertheless, teachers are held accountable to the EDB, which has, in recent years, put in place a quality assurance system to monitor school performance. Since 2003/04, the EDB has required schools to evaluate their own performance according to some performance indicators4 and to report to the EDB annually. Information about school performance is also released to parents. To validate schools’ self-evaluation, the EDB has conducted External School Review (ESR) of schools since 2004 (see EMB, 2006 [Education and Manpower Bureau] EDB, previously called Education and Manpower Bureau (EMB), used to be responsible for both the formulation of polices and human resources planning and development to make sure that the manpower needs of different sectors of the community were well taken care of. Since July 2007, EMB was renamed as EDB, which continues to be responsible for the policy portfolio of education, while the policy responsibility of manpower previously undertaken by the EMB is now taken up by another government body called Labour and Welfare Bureau). Because of the dominant exam culture, there is a strong tendency to view school performance in terms of students’ performance in public examinations. In Hong Kong, examination policies are formulated by the Hong Kong Examinations and Assessment Authority (HKEAA). As an independent organization, the HKEAA has little to do with teaching and learning in schools per se, but it appears to exert a tremendous influence on Hong Kong teachers. This is because in an exam-dominated culture, teachers often teach to the test, feeling pressured to drill students to meet the requirements of public exams. Thus, the issue of accountability is an intricate one in Hong Kong schools; it is uncertain if schools are accountable to themselves (given the selfevaluation they are required to conduct on a yearly basis); parents (who may choose the school they want their children to go to based on information about the school’s effectiveness); the EDB (which oversees quality assurance); or the larger exam system administered by the HKEAA (given the exam culture in Hong Kong). Often there are conflicting demands and expectations from different stakeholders. It can be imagined that the issue of feedback can be very interesting as we examine it in the context of the school in which teachers work, from the vantage point of quality assurance (but assurance for whom – EDB, school, or parents?), and within the exam culture that dominates Hong Kong schools.

# Method of study

In Hong Kong, getting busy teachers to involve themselves in or provide assistance with research projects is becoming more and more difficult. To facilitate access to data, therefore, convenience sampling was adopted—mainly through a number of contact teachers working in secondary schools. In the end, 26 Cantonese-speaking secondary teachers of English from 15 different secondary schools (from all the three bands: Band 1 being the top in terms of overall academic performance, and Band 3 the weakest) expressed willingness to participate in the project. They were told to provide 5–6 essays randomly selected from three different abilities (i.e., high, average and low) to make sure that the feedback they provided was representative of their responding behavior. A total of 174 compositions were collected from different levels ranging from Secondary 1–5 (i.e., Grades 7–11). About $8 5 \%$ of the teachers are subjecttrained, with a qualification in English subject knowledge, and all of them have a professional teaching qualification (i.e., a Diploma/Certificate in Education) majoring in English. The teachers had 2–15 years of teaching experience at the time of the study. When they submitted the student essays, the teachers also completed a short questionnaire asking them to indicate (1) if the student texts were from one-shot writing (involving only one draft) or multiple drafting; and (2) if they had responded to errors comprehensively (i.e., all errors). All the 26 teachers said the student texts reflected one-shot writing, and they had all marked errors comprehensively.

To find out the factors that had influenced teachers’ feedback practices, follow-up individual interviews (see interview guide in Appendix A) were conducted with six of the teachers selected from six different schools to represent (1) all the three bandings; and (2) a range of teaching experience (2–15 years). The interviews, which were semi-structured, aimed to seek information about the teachers’ contexts of work and their beliefs to elucidate their feedback practices. Since the researcher and the teachers are Cantonese speakers, to facilitate communication and put teachers at ease all the interviews were conducted in Cantonese.

The student texts were read by a research assistant (who was then a full-time Master of Philosophy student at a local university with two years’ English language teaching experience and a Postgraduate Diploma in Education majoring in English) to identify the feedback points. A feedback point refers to any comment, underlining, or correction made on the student text, such as, a written intervention by the teacher (Hyland, 2003). Feedback given to a written error or comment that constituted a meaningful unit was considered one feedback point, for example, has went (one feedback point comprising underlining); or Good try to provide an introduction to your leaflet in your own words (one written comment). The feedback analysis covered the following areas:

(1) Focus of feedback: Whether it was on form (i.e., language use); content (i.e., ideas); organization (i.e., development of ideas, paragraphing, and overall organization); or others (e.g., handwriting).   
(2) Error feedback: Feedback that addressed student written errors was singled out for further analysis to find out the error correction strategies used.   
(3) Written commentary: Given the EDB guideline about the importance to comment on the positive aspects of student writing (apart from indicting weaknesses), the focus of the analysis was on the amount of praise vis-a\`-vis negative comments. (And since all student texts collected were single drafts with no revision requirement, a detailed analysis of the types and functions of teacher commentary was deemed unnecessary).

As for the interview data, they were translated from Cantonese to English and transcribed by the research assistant. To enhance the reliability of the findings, the interviewees were asked to read the interview transcripts to verify their accuracy (Merriam, 1998). In interpreting the interview data, subjectivity was inevitably involved, especially because some of the factors that emerged as influencing teachers’ feedback practices were implicit rather than explicitly stated by the interviewees. To further enhance the trustworthiness of the data analysis, the preliminary analysis pertaining to the factors that influenced teachers’ feedback practices was also read by the interviewees to ensure that they matched their interpretations.

# Teacher-written feedback

This section describes the teachers’ written feedback based on results of the feedback analysis. In total, there were 5353 feedback points in the 174 essays, 462 $( 8 . 6 \% )$ of which were written comments, all the rest (4891) being error feedback comprising underlining, circling, and codes.

# Focus of feedback

Table 1 shows that $9 4 . 1 \%$ of the teacher feedback focused on form (grammar and vocabulary), $3 . 8 \%$ on content, $0 . 4 \%$ on organization, and $1 . 7 \%$ on other aspects (such as general comments on student writing). Organization, in particular, was found to receive the least attention.

Table 1 Focus of written feedback   

<html><body><table><tr><td>Focus</td><td>Percentage (Total)</td></tr><tr><td>Form</td><td>94.1% (5034 = 4891 error feedback marked on student texts + 143 written comments)</td></tr><tr><td>Content</td><td>3.8% (206)</td></tr><tr><td>Organization</td><td>0.4% (24)</td></tr><tr><td>Others</td><td>1.7% (89)</td></tr></table></body></html>

# Error feedback

Table 2 shows that of the 4891 error feedback points marked on student texts, direct error feedback (i.e., locating and correcting errors) was the most prevalent strategy $( 7 1 . 5 \% )$ , followed by coded feedback (i.e., locating errors and indicating error types) $( 2 1 . 6 \% )$ . Only $6 . 9 \%$ of the feedback was uncoded (i.e., simply locating errors).

# Written commentary

Table 3 shows that about $38 \%$ of the written comments were praises (e.g., It’s good that you have a wide variety of vocabularies that you can use in writing, e.g., valuable, malefactor). Negative comments included those on grammar and mechanics $( 2 5 \% )$ (e.g., Please pay attention to tenses) and other negative comments not related to grammar and mechanics $( 9 \% )$ (e.g., Some of the arguments do not stand). The rest of the comments comprised giving information and direction (see Ferris, 2003), which was not the focus of the data analysis. Given that there were only 177 positive comments out of the total 5353 feedback points (the bulk of which consisted of error feedback, which was primarily negative in orientation), positive commentary accounted for only $3 . 3 \%$ of the total feedback, which was rather minimal.

When teachers’ feedback practices are juxtaposed against the feedback principles recommended in local curriculum documents, mismatches are found as follows:

- Focus of feedback. The EDB guidelines warn teachers against providing detailed editing comments on the surface form without paying attention to organizational and content issues, but the large majority of the feedback in the study was on language errors. It is recommended that teachers comment on student drafts, but in the study, only single drafts were required.

Table 2 Error feedback   

<html><body><table><tr><td>Direct error feedback.</td><td>71.5% (3,498)</td></tr><tr><td>Coded feedback (indirect)</td><td>21.6% (1,056)</td></tr><tr><td>Uncoded feedback (indirect)</td><td>6.9% (337)</td></tr></table></body></html>

Table 3 Written commentary   

<html><body><table><tr><td>Comment type</td><td>Percentage</td></tr><tr><td>1. Positive comments</td><td>38.3% (177)</td></tr><tr><td>2. Negative comments</td><td>33.9% (157)</td></tr><tr><td>Comments on grammar and mechanics</td><td>24.6% (114)</td></tr><tr><td>Other negative comments</td><td>9.3% (43)</td></tr><tr><td>3. Others</td><td>27.8% (128)</td></tr></table></body></html>

- Error feedback. The EDB recommends selective marking of errors and a combination of error feedback strategies, especially indirect feedback. However, all the teachers in the study said they marked errors comprehensively, and the strategy they mainly used was direct error feedback.

- Written commentary. While the EDB recommends teachers indicate both weaknesses and strengths in student writing, teachers in the study focused primarily on student errors, such as their weaknesses in writing. Only $3 . 3 \%$ of the total feedback was positive. (When we look at written commentary alone, however, there was a fair amount of positive comments, as $38 \%$ of it was praise.)

Why did the teachers respond to student writing in the ways they did, pretty much against the advice of the EDB? Drawing upon the interview data, the next section attempts to answer this intriguing question.

# Factors influencing teacher written feedback

Before discussing the factors that have influenced teachers’ feedback practices, this section begins by situating teachers’ feedback practices in the overall context of their work, highlighting some salient features that characterized the context based on the interview data. It then proceeds to discuss four major factors that appeared to play a significant role in influencing teachers’ feedback practices: accountability, teachers’ beliefs and values, examination culture, and (lack of) teacher training.

# Overall context of teachers’ work

All the six teachers interviewed disclosed similar practices in their schools. They all used the term ‘‘detailed marking’’ (i.e., marking every single written error) to describe the feedback policy stipulated by the English panel (i.e., English department comprising panel chair and other English teachers). In one school, selective marking of errors was allowed for some student compositions. All the schools encouraged teachers to use correction symbols (apart from underlining or circling errors) and suggested they provide correct answers when they think students are incapable of self-correction. In one school, simply indicating errors without symbols or corrections (i.e., uncoded feedback) was not allowed. Although detailed written comments were not compulsory, teachers were encouraged to write general comments about students’ performance. Giving student writing scores/grades was deemed highly important, as these counted (about $20 \mathrm { - } 3 0 \%$ ) towards students’ overall writing scores for the school year. After returning the feedback to students, the general policy was to ask students to correct sentences that contained errors (without having to revise content), while the scores/grades remained unchanged. The importance of an error-free corrected version was emphasized. The most telling interview finding is that there was an inspection policy in each of the schools, involving checking of student compositions and teachers’ written feedback by the English panel chair once or twice a year, as part of teacher appraisal. One performance indicator, explicitly stated in some schools, was the way the teacher responded to student writing. In one school, the teacher appraisal form consisted of one section on ‘‘marking status,’’ which contained sub-items like ‘‘marking quality of teacher,’’ ‘‘marking behavior of teacher,’’ and ‘‘feedback to students,’’ with ‘‘feedback to students’’ evaluated in terms of ‘‘much,’’ ‘‘average,’’ ‘‘little,’’ and ‘‘none.’’ Detailed error feedback plus a variety of written comments on student texts was likely to be evaluated positively.

# Accountability

What was brought to light by the interview data is that, when there was a school policy that required teachers to respond to student writing in certain ways, teachers were accountable. If they deviated from the established practice, they had to justify it. Essentially, teachers were accountable to the school administrator, as their written feedback was used by the principal to evaluate their performance and competence as a language teacher. Whether a teacher was ‘‘good’’ or not partly depended on the extent to which s/he marked student writing according to the panel policy. One teacher interviewed said bitterly that in her first year she marked errors only selectively, but after inspection by the panel chair, she was evaluated negatively. Awarning letter was even issued suggesting that she had not fulfilled the fundamental duty of a language teacher. This teacher said, ‘‘I hate marking student writing. I do it for the panel chair and principal. I do not think it is benefiting my students.’’ When teacher beliefs were incongruent with the school policy, teachers felt disempowered to act against the system. Another teacher said, ‘‘I have my own thoughts, but I must follow the panel policy. I have once argued with the panel chair that underlining errors without using symbols is good enough, but she was not convinced.’’ Like it or not, teachers responded to student writing by complying with the panel policy, as the consequence of not conforming was very likely an unfavorable appraisal from the principal, as well as an accusation that one had not discharged one’s responsibility as a teacher satisfactorily.

Moreover, teachers were held accountable to their students (and parents) who wanted and expected teachers to give detailed response to their writing. If marking was not detailed enough, according to the teachers, they were considered ‘‘lazy and irresponsible.’’ Detailed marking was also used to do justice to student efforts and to provide incentives for further efforts from students. One teacher believed that if teachers did not provide detailed feedback, it was hard to ask students to put effort in their writing. Thus, it was not only accountability but also a matter of equity. The teacher said, ‘‘As students know how much effort their teachers have put into marking their writing, they are reminded that they should put equal if not more effort in their writing.’

Under the accountability system, teachers were careful in shielding themselves from criticisms. Even if they were unable to demonstrate the quality of their feedback, that is, whether it was helping students improve their writing, at least they were accountable for the quantity of their work. One teacher said that in her school, some teachers on the English panel once raised the possibility of selective marking of errors. After discussion, it was concluded that if selective marking was to be adopted, the number of student compositions would have to double the existing amount, for example, from 8 to 16 per year. Otherwise, teachers would be perceived as doing less work, and hence ‘‘lazier.’’ In the end, selective marking was not adopted. This little episode illustrated a school culture that valued quantity more than quality—a perception that more was better. One teacher said, ‘‘My panel chair thinks we cannot do less work or else we will be criticized.’’

How about accountability to the EDB? This seemed much more remote. According to the teachers, the EDB quality assurance process appeared to have little to do with teacher written feedback. Two teachers said that the EDB focused more on how lessons were conducted and documentary evidence in support of school performance. One teacher said, ‘‘EDB inspectors mainly focus on classroom teaching. . .They believe the 30-minute lesson can show everything.’’ Another teacher said, ‘‘In our self-evaluation and [EDB] quality assurance inspection this year, the marking of compositions was never mentioned.’’

# Teachers’ beliefs and values

The issue of whether teachers marked student working according to the panel policy, to satisfy students, or in response to their own beliefs became somewhat blurred, especially when the teachers’ beliefs and values appeared to converge with institutional values about feedback. The emphasis on written accuracy was supported by two teachers, who believed that writing served the primary purpose of reinforcing language structures, as illustrated in the following quotes: ‘‘The panel chair often reminds us that we are teachers of English, and, therefore, we should put more emphasis on grammar and vocabulary,’’ and ‘‘students write to practice the grammar and vocabulary they have learnt.’’ Four of the teachers interviewed felt that student written errors need to be pointed out and/or corrected; otherwise, students cannot ‘‘learn’’ from their mistakes. The belief was one of ‘‘tell them, and they will learn.’’ This could explain why some teachers felt it was important to respond to every single error. In the words of one teacher: ‘‘We have to tell students what mistakes they have made in their writing so that they will avoid making the same mistakes.’’

Although teachers acknowledged the importance of content and organization in writing, they considered these to be less urgent issues in feedback. One reason, as put by a teacher, was that ‘‘students usually do not have many problems in content.’’ As for organization, the same teacher said, ‘‘Lower form students have fewer problems in organization as the text patterns are limited, and they are taught in the textbook.’’ Some teachers thought that students did exhibit problems in content and organization; however, responding to errors had taken up so much of their energy that there was little time left for issues other than grammar and vocabulary. One teacher said, ‘‘There is not enough room for us to mention content.’’ Another teacher said, ‘‘I, of course, also emphasize content and organization, but I put more emphasis on the accuracy of basic elements first.’’ Thus, it was a matter of priority—grammar being more important than other issues.

# Examination culture

Teachers’ feedback practices, as well as their beliefs and values, appeared to be deeply affected by the exam orientation in the education system. One teacher said, ‘‘Writing practice is for exam preparation.’’ In an exam-oriented culture, time is perceived as a major constraint in teachers’ feedback practices (see Curtis, 2001). When asked why they did not require students to produce multiple drafts, the answer was that they ‘‘could not afford the time’’, since students had to learn to practice writing a great variety of text types to prepare for public examinations. The exam culture also influenced the criteria teachers used to mark student writing. They focused mainly on accuracy because, according to them, this was the major focus of the exams authority in marking student writing. One teacher said, ‘‘We should focus on the accuracy of writing so that in public exams, the markers can understand what students are saying and they can get a pass.’’ Another teacher said, ‘‘In HKCEE, compositions with good grammatical accuracy are rated highly, irrespective of content, so it is important to help students avoid the basic errors in writing, since this is totally unacceptable in public exams.’’

# (Lack of) teacher training

The interview data reveal a lack of training among teachers in the area of assessing and responding to student writing. Four of them confessed that their previous training had not exposed them to any ‘‘new’’ idea about teacher feedback. One teacher commented, ‘‘The Diploma in Education program had microteaching practice and lectures on lesson planning, etc., but not on feedback strategies in writing.’’ Another teacher responded, ‘‘I think I actually learnt most from my colleagues.’’ The two teachers who thought that they had received some training on feedback attributed it to their master’s studies. One teacher said she learnt about the benefits of selective marking, and the other specifically pointed out the importance to avoid using choppy phrases in written comments (e.g., Good work) while demanding students to write in complete sentences.

On the whole, the teachers thought that the ‘‘training’’ they received in the area of feedback was mostly from the more experienced teachers within the English panel. In the words of one teacher, ‘‘There are seniors to teach us what to do when it comes to marking student writing.’’ It can be imagined that the school’s feedback policy was formulated by the more experienced teachers, mainly based on their prior experiences (i.e., how their own writing was marked by their teachers), handed down from generation to generation. Detailed marking of student writing was gradually established as a normative practice, adopted in most schools in Hong Kong. One teacher said, ‘‘It’s hard to change the conventional practice of detailed marking. I think students, parents, and teachers are all used to it, plus other schools are practicing it.’’ Ironically, though, all teachers admitted that their current feedback practices were not producing the desired results.

Rather surprisingly, all of the teachers interviewed were unaware of the EDB’s recommendation of selective marking. One teacher, with five years’ teaching experience, thought that the EDB recommended detailed marking, two teachers said they had forgotten, two did not know, and the other teacher did not care: ‘‘I do not pay much attention to the contents of the syllabus, but I know the requirements of the public exams. I think the EDB stuff is impractical, rather remote from reality.’’ The results suggest that despite the EDB guidelines, there has been a lack of training to disseminate the ideas.

To sum up, the study has indicated great discrepancies between teachers’ written feedback on the one hand, which occurred in single-draft classrooms and was largely error-focused, and the principles recommended by the EDB on the other. The study has also attempted to discover the reasons for teachers’ practices, highlighting issues relating to accountability, teachers’ beliefs and values, exam culture, and lack of training. By going beyond the act of feedback through investigating both the ‘‘what’’ and ‘‘why’’ of teacher feedback, the study reveals that teachers’ feedback practices are influenced by a myriad of contextual factors (Goldstein, 2004, 2005; Hyland & Hyland, 2006b) including teachers’ beliefs, values, understandings, and knowledge, which are mediated by the cultural and institutional contexts, such as philosophies about feedback and attitudes to exams, and socio-political issues pertaining to power relations and teacher autonomy. Indeed teachers’ feedback practices are socially and politically situated, shaped by unequal power relations and complex interactions among the stakeholders (see Casanave, 2003). Although some teachers in the study had their own beliefs about feedback, like selective marking of errors and multiple drafting (which are consistent with recommended principles, e.g., Ferris, 2002), they were frustrated and hamstrung by a socio-political climate that did not allow them the autonomy to practice what they believed. Within the school system, teachers felt they had to be accountable to students, parents, and school administrators, whose expectations of teacher feedback tended to conflict with good feedback practices, let alone the appraisal system which placed explicit demands on their responding behavior. For those who were less accepting of the school’s feedback policy, they felt powerless to mark student writing in their own preferred ways. For others, ingrained attitudes to feedback and lack of training made them continue with conventional practices rather uncritically. Although the EDB has a set of guidelines on feedback, institutional polices and requirements have made it almost impossible for teachers to adhere to the recommended principles. Moreover, in Hong Kong, the pervasive examination culture poses obstacles to innovative practices, driving teachers to focus primarily on improving examination performance (Davison, 2004; Hamp-Lyons, 1999). Within an exam culture, feedback inevitably serves summative rather than formative functions, particularly when school performance largely hinges on student performance in public exams. Hyland and Hyland (2006b) remind us that feedback is a form of social action that occurs in specific cultural and institutional contexts. Changing teachers’ feedback practices would therefore entail change not only in teachers’ beliefs and knowledge (Ferguson, 1993), but also in the cultural and political systems that shape teachers’ work.

# Implications

# Implications for teachers’ feedback practices

Although it is impossible to generalize the findings based on teacher feedback gathered from a small sample in a single context, several important implications can be drawn, which may be applicable to similar contexts. First, the study has demonstrated that teachers’ feedback practices can be debilitated by a socio-political climate that requires teachers to play a highly subservient role. A feedback revolution is possible only when teachers can ‘‘self-actualize a new and more autonomous, responsible role for themselves’’ (Hamp-Lyons, 2006, p. 495). Second, to bring improvement to teachers’ feedback practices and to empower teachers, school leaders and administrators should be involved in the process of change. There should be opportunities for them to participate in school-based seminars, in conjunction with frontline teachers, where they critique the institutional polices regarding feedback vis- $\grave { \mathbf { a } }$ -vis effective feedback principles, preferably with the presence of critical friends (e.g., university academics), so that together they come up with suggestions (not restricted to written feedback but including other forms of feedback like peer feedback) that contribute to more productive feedback practices. They should also be mindful of the fact that writing pedagogy and feedback principles imported from the west may not entirely suit their own context so modifications may be necessary (see Leki, 2001). Whatever feedback policy schools formulate, it is important that school leaders and administrators be flexible and supportive. Finally, the study has suggested that it is the dominant exam culture in Hong Kong, as in some other contexts, that makes it difficult for good feedback practices to develop. How to reconcile the exam and learning culture is a thorny issue, but the key may lie in teachers’ professional development. Without professional development effort to develop in teachers a vision about what they want to achieve through feedback and to equip them with effective feedback strategies, recommended principles (e.g., from the education ministry) can remain unread and unreal and have no impact whatsoever on teaching and learning. Continuous professional development in terms of training and support is therefore necessary. Teachers should also be encouraged to undertake action or classroom-based research and to share good feedback practices. Entrenched feedback practices are difficult to change, but if teachers’ classroom research shows that alternative feedback practices can lead to better student motivation, more effective learning, and even improvement in student writing, teachers may gradually deconstruct their preferred ways of feedback. In Hong Kong, and perhaps in many similar contexts, however, professional development work on feedback is in its infancy. There is a long way to go.

# Implications for further research

The study has underlined the pivotal role context plays in feedback research. Future investigations should examine in greater depth the overall context and the circumstances that govern teachers’ work, teachers’ beliefs about and approaches to writing, instruction and assessment, students that constitute the pedagogical context, and how teacher feedback can be better understood and enhanced within their contexts. The roles of different stakeholders (including school principals and parents) in shaping feedback practices would be an interesting avenue for further research.

# References

Bates, L., Lane, J., & Lange, E. (1993). Writing clearly: Responding to ESL compositions. Boston: Heinle & Heinle.   
Brock, M. (1995). Resistance and change: Hong Kong students and the process approach. Perspectives, 7(2), 53–69.   
Casanave, C. P. (2003). Looking ahead to more sociopolitically-oriented case study research in L2 writing scholarship (but should it be called ‘‘post-process’’?). Journal of Second Language Writing, 12(1), 85–102.   
Caulk, N. (1994). Comparing teacher and student responses to written work. TESOL Quarterly, 28, 181–188.   
Curriculum Development Council (CDC). (1999). Syllabuses for secondary schools: English language Secondary 1–5. Hong Kong: Hong Kong Government Printer.   
Curriculum Development Council (CDC). (2002). English language education: Key learning area curriculum guide (Primary 1–Secondary 3). Hong Kong: Hong Kong Government Printer.   
Curriculum Development Council (CDC). (2006). English language education key learning area: New senior secondary curriculum and assessment guide (Secondary 4–6). Hong Kong: Hong Kong Government Printer.   
Curriculum Development Council & Hong Kong Examinations and Assessment Authority (CDC and HKEAA). (2007). English language curriculum and assessment guide (Secondary 4–6). Hong Kong: Hong Kong Government Printer.   
Cohen, A. D., & Cavalcanti, M. C. (1990). Feedback on written compositions: Teacher and student verbal reports. In B. Kroll (Ed.), Second language writing: Research insights for the classroom (pp. 155–177). Cambridge: Cambridge University Press.   
Conrad, S., & Goldstein, L. (1999). ESL student revision after teacher written comments: Texts, contexts and individuals. Journal of Second Language Writing, 8, 147–180.   
Cumming, A. (1985). Responding to the writing of ESL students. Highway One, 8, 58–78.   
Curtis, A. (2001). Hong Kong student teachers’ responses to peer group process writing. Asian Journal of English Language Teaching, 11, 129–143.   
Curtis, A., & Heron, A. (1998). On being less innovative: Peer groups and process writing in Hong Kong. Asia Pacific Journal of Language in Education, 8, 99–117.   
Davison, C. (2004). The contradictory nature of teacher-based assessment: ESL teacher assessment practices in Australian and Hong Kong secondary schools. Language Testing, 21(3), 305–334.   
Davison, C. (2007). Views from the chalkface: English language school-based assessment in Hong Kong. Language Assessment Quarterly, 4(1), 37–68.   
Education and Manpower Bureau (EMB). (2006). Quality assurance in school education: Handbook on external school review (for schools). Hong Kong: Hong Kong Government Printer.   
Evans, S. (1996). The context of English language education: The case of Hong Kong. RELC Journal, 27, 30–55.   
Ferguson, G. (1993). Implementing innovation in language education. Edinburgh Working Papers in Applied Linguistics, 4, 27–39.   
Ferris, D. R. (1995a). Student reactions to teacher response in multiple-draft composition classrooms. TESOL Quarterly, 29, 33–53.   
Ferris, D. R. (1995b). Teaching ESL composition students to become independent editors. TESOL Journal, 4(4), 18–22.   
Ferris, D. R. (1997). The influence of teacher commentary on student revision. TESOL Quarterly, 31, 315–339.   
Ferris, D. R. (1999). The case for grammar correction in L2 writing classes: A response to Truscott (1996). Journal of Second Language Writing, 8, 1–10.   
Ferris, D. R. (2002). Treatment of error in second language student writing. Ann Arbor: University of Michigan Press.   
Ferris, D. R. (2003). Response to student writing: Implications for second language students. Mahwah, NJ: Lawrence Erlbaum.   
Ferris, D. R. (2006). Does error feedback help student writers? In K. Hyland & F. Hyland (Eds.), Feedback in second language writing: Contexts and issues (pp. 81–104). Cambridge: Cambridge University Press.   
Ferris, D. R., & Hedgocok, J. S. (2005). Teaching ESL composition: Purpose, process, and practice (2nd ed.). Mahwah, NJ: Lawrence Erlbaum.   
Ferris, D. R., & Roberts, B. (2001). Error feedback in L2 writing class: How explicit does it need to be? Journal of Second Language Writing, 10(3), 161–184.   
Ferris, D. R., Pezone, S., Tade, C. R., & Tinti, S. (1997). Teacher commentary on student writing: Descriptions and implications. Journal of Second Language Writing, 6, 155–182.   
Frantzen, D. (1995). The effects of grammar supplementation on written accuracy in an intermediate Spanish content course. Modern Language Journal, 79, 244–329.   
Frodesen, J. (1991). Grammar in writing. In M. Celce-Murcia (Ed.), Teaching English as a second language (2nd ed., pp. 264–276). Boston: Heinle & Heinle.   
Goldstein, L. M. (2001). For Kyla: What does the research say about responding to ESL writers. In T. Silva & P. Matsuda (Eds.), On second language writing (pp. 73–90). Mahwah, NJ: Lawrence Erlbaum.   
Goldstein, L. M. (2004). Questions and answers about teacher written commentary and student revision: Teachers and students working together. Journal of Second Language Writing, 13(1), 63–80.   
Goldstein, L. M. (2005). Teacher written commentary in second language writing classrooms. Ann Arbor: The University of Michigan Press.   
Goldstein, L. M. (2006). Feedback and revision in second language writing: Contextual, teacher, and student variables. In K. Hyland & F. Hyland (Eds.), Feedback in second language writing: Contexts and issues (pp. 185–205). Cambridge: Cambridge University Press.   
Hamp-Lyons, L. (1999). Implications of the ‘‘examination culture’’ for (English language) education in Hong Kong. In V. Crew, V. Berry, & J. Hung (Eds.), Exploring diversity in the language curriculum. Hong Kong: Hong Kong Institute of Education.   
Hamp-Lyons, L. (2006). The impact of testing practices on teaching: Ideologies and alternatives. In Cummins, J., & Davison, C. Eds. International handbook of English language teaching. Vol. 1 (pp.487–504).Norwell, MA: Springer.   
Hamp-Lyons, L., Chen, J., & Mok, J. (2001). Introducing innovation incrementally: Teacher feedback on student writing. ThaiTESOL Bulletin: Selected papers from the 21st Annual ThaiTESOL International Conference, vol. 14, no. 2 (pp. 59–66).   
Hendrickson, J. M. (1978). Error correction in foreign language teaching: Recent theory, research, and practice. Modern Language Journal, 62, 387–398.   
Higgs, T., & Clifford, R. (1982). The push toward communication. In T. Higgs (Ed.), Curriculum, competence, and the foreign language teacher (pp. 57–79). Skokie, IL: National Textbook Company.   
Hyland, F. (1998). The impact of teacher written feedback on individual writers. Journal of Second Language Writing, 7(3), 255–286.   
Hyland, F. (2003). Focusing on form: Student engagement with teacher feedback. System, 31, 217–230.   
Hyland, F., & Hyland, K. (2001). Sugaring the pill: Praise and criticism in written feedback. Journal of Second Language Writing, 10, 185–212.   
Hyland, K., & Hyland, F. (2006a). State-of-the-art review on ‘‘Feedback in second language students’ writing’’. Language Teaching, 39(2), 83–101.   
Hyland, K., & Hyland, F. (2006b). Contexts and issues in feedback on L2 writing: An introduction. In K. Hyland & F. Hyland (Eds.), Feedback in second language writing: Contexts and issues (pp. 1–19). Cambridge: Cambridge University Press.   
Kennedy, C. (1988). Evaluation of the management of change in ETL projects. Applied Linguistics, 9, 329–342.   
Komura, K. (1999). Student response to error correction in ESL classrooms. Unpublished master’s thesis. Sacramento: California State University.   
Lalande, J. F., II (1982). Reducing composition errors: An experiment. Modern Language Journal, 66, 140–149.   
Lee, I. (2004). Error correction in L2 secondary writing classrooms: The case of Hong Kong. The Journal of Second Language Writing, 13, 285–312.   
Leki, I. (1992). Understanding ESL writers: A guide for teachers. Portsmouth, NH: Boynton/Cook Publishers.   
Leki, I. (2001). Material, educational and ideological challenges of teaching EFL writing at the turn of the century. International Journal of English Studies, 1(2), 197–209.   
Leontiev, A. N. (1981). The problem of activity in psychology. In J. V. Wertsch (Ed.), The concept of activity in Soviet psychology (pp. 37–71). Armonk, NY: Sharpe.   
Lin, A. (1999). Doing-English-lessons in the reproduction or transformation of social worlds? TESOL Quarterly, 33(3), 393–412.   
Mantello, M. (1997). Error correction in the L2 classroom. Canadian Modern Language Review, 54, 127–131.   
Merriam, S. B. (1998). Qualitative research and case study applications in education. San Francisco, CA: Jossey-Bass Inc Publishers.   
Pennington, M., Brock, M. C., & Yue, F. (1996). Implementing process writing in Hong Kong secondary schools: What the students’ responses tell us. Perspectives, 8(1), 150–217.   
Reid, J. (1994). Responding to ESL students’ texts: The myths of appropriation. TESOL Quarterly, 28, 272–292.   
Robb, T., Ross, S., & Shortreed, I. (1986). Salience of feedback on error and its effect on EFL writing quality. TESOL Quarterly, 20, 83–93.   
Roberts, B.J. (1999). Can error logs raise more than consciousness? The effects of error logs and grammar feedback on ESL students’ final drafts. Unpublished master’s thesis, California State University, Sacramento.   
Saito, H. (1994). Teachers’ practices and students’ preferences for feedback on second language writing: A case study of adult ESL learners. TESL Canada Journal, 11(2), 46–70.   
Semke, H. D. (1984). Effects of the red pen. Foreign Language Annals, 17, 195–202.   
Tsui, A. B. M. (2004). Medium of instruction in Hong Kong: One country, two systems whose language? In J. Tollefson & A. B. M. Tsui (Eds.), Medium of instruction policies: Which agenda? Whose agenda? (pp. 97–106). Mahwah, NJ: Lawrence Erlbaum.   
Zamel, V. (1985). Responding to student writing. TESOL Quarterly, 21, 697–715.

# Appendix A. Interview guide

1. Feedback practice: How do you mark student writing? Why do you mark student writing in the ways you do?   
2. ‘‘Good’’ feedback practice: What is considered ‘‘good’’ feedback practice by the principal, panel chair, students, parents and the EDB? Do you agree?   
3. Focus of feedback: What areas do you focus on in your written feedback? Why?   
4. Error feedback: Do you mark errors selectively or comprehensively? Why? Can you also describe and explain your preferred error feedback strategies.   
5. Written comments: Do you write comments on student writing? Are you aware of the range of comments you write? How do you see the functions of your comments? What do you expect students to do afterwards? Explain your answers.   
6. Grading/scoring: Do you give student writing a grade/score? Why? What criteria is the grade/score based on? Explain.   
7. Student writing: Is student writing done in class? Is it timed? How many drafts are collected? Explain your answers.   
8. Upon receiving feedback: What happens after students have received your feedback? What do you ask them to do? Explain.   
9. Training: Has your previous training given you any idea about how to provide feedback on student writing? What do you know about ‘‘effective’’ feedback? Do you know what the English syllabus recommends?   
10. Effectiveness of feedback: How would you assess the effectiveness of your own feedback practices?