# A ghostwriter in the machine? Attitudes of academic staff towards machine translation use in internationalised Higher Education

Mike Groves a , Klaus Mundt b, \*

a Surrey International Institute, University of Surrey, United Kingdom b University of Nottingham, United Kingdom

# a r t i c l e i n f o

Article history:   
Received 16 July 2020   
Received in revised form 23 December 2020   
Accepted 31 December 2020   
Available online 15 January 2021

Keywords: Higher education Academic integrity Policy: internationalisation Machine translation

# a b s t r a c t

Online translation has been freely available since the 1990s. In recent years its quality has been significantly improving, leading to instant translation which can easily be used as a reading or writing tool by students whose first language is not that of the institution where they study. For instance, students might use it to facilitate the composition of their essays in the language of instruction. However, such student use of online translation tools raises a number of important questions about their acceptability in Higher Education. As these questions remain unaddressed in the current literature, this paper presents novel findings from interviews with academic staff at two UK universities and examines the emerging themes. These include academic integrity, the meaning of the university brand and the need for language development. It then suggests that Higher Education Institutions need to engage in an informed and robust discussion of these issues to provide a consistent position on the place of Machine Translation in Higher Education.

$^ ©$ 2021 Elsevier Ltd. All rights reserved.

# 1. Introduction

1.1. What is online translation?

Online translation is a freely accessible automated system which translates between various languages instantly and free of charge. There are various systems available, and a key player in the field is Google Translate (GT), which Google has claimed translates 100 billion words in a day (Turovsky, 2016). Google uses a computing system based on our understanding of the human brain, known as a “Neural Network”, to enhance the capabilities of its translation engine; and this, and similar technologies, are growing in ubiquity. Its reach includes, among many other things, an academic journal database which has embedded a GT widget that allows instant and local translation of academic content. Taylor and Francis have stated that this widget was used 1.2 million times in the first 18 months after its implementation (Barrett, 2015). Given the large numbers of students on Anglophone campuses whose first language is not English (UKCISA, 2019), and also the spread of this technology, it seems uncontroversial to argue that online translation tools will have an impact on the delivery of academic courses where students from diverse language backgrounds mingle.

# 1.2. Absolute versus relative quality

Although the quality of GT text has improved dramatically, it still remains an issue. For instance, when it comes to the precision required for academic texts, there is near universal agreement that machine translation (MT) is at present unable to provide the quality and polish expected of a trained, expert human translator without extensive post-editing (cf Cronin, 2013; Garcia, 2011; Guerberof Arenas & Moorkens, 2019). However, it must be remembered that students might reasonably conclude that the programme can, in many circumstances, produce higher quality output than they can (Groves & Mundt, 2015), without significant effort. This is particularly true of students at the threshold level for university entrance.

# 1.3. Research questions

We believe that there can be little doubt that students studying, and thus reading and writing, in a language that is not their first will draw upon technology to facilitate language processing e this may be the use of a dictionary or the use of GT to produce an English text that the student has written in their L1. After all, these students face the dual challenge of not only learning the content of their degree courses, but also receiving and conveying information (often for assessment) in a language that is not their first.

Research on language instructors’ and language learners’ views of MT (e.g. Clifford et al., 2013; Jolley & Maimone, 2015) has shown that students tend to embrace the technology, albeit selectively, and that teachers tend to view it with caution, in particular in terms of acceptability of its use, while acknowledging that it can be a useful tool in language acquisition. However, there is, as of yet, no research that has investigated the important question of the position of HEIs more generally on this practice. In 2016, Mundt and Groves argued that the use of translation technology in HE needs to be legislated, but to our knowledge, no such legislation has been forthcoming.

To move this issue forward, the present study examines perceptions on the use of GT and other freely available online translation tools by university students as reading and writing aid. This was done by interviewing academic staff at various levels of two UK universities, and asking questions informed by the following overarching research questions:

1. To what degree do academic staff see the use of MT by students for their academic work as acceptable?   
2. Is use of MT as an aid for academic reading and writing considered academic misconduct; and, if so, under what circumstances?   
3. Is there currently a university policy on student use of MT? Should there be?

# 2. Technology and translation in academia

# 2.1. Recent history of GT

MT has existed in some form since the Second World War. However, it is only more recently that the advent of high bandwidth, ubiquitous devices and enormous linguistic databases have made it accessible and useable for the general population. According to Ghasemi and Hashemian (2016), the system used by Google has evolved from a rule-based system to a statistical-based one. More recently, in 2016, Google reported that it has introduced a new Neural Network system, which enables a higher quality of translation (Turovsky, 2018). Neural translation is widely seen to be an impressive improvement in the quality of MT (Castilho et al., 2017).

The reaction to GT in the academic literature has been limited and often critical (see, e.g., Bowker & Ciro, 2019; Tsai, 2020). In addition, since it is a relatively recent technological development, there is not much academic literature concerning the use of GT and its place in HE. However, a reflection of the improvement in the quality can be perceived. Early voices such as Sheppard (2011) stressed the low quality of the service at that time, as well as issues to do with confidentiality, given that all data was submitted through Google’s server. van Rensburg et al. (2012) were among the first to investigate the output in detail, finding that significant post-editing was needed to produce a text of acceptable quality. Precup-Stiegelbauer (2013) examined some literary texts which had been translated by Google, and found the quality distinctly lacking.

However, as the technology developed, voices more supportive of GT in the academic space began to emerge. Garcia and Pena (2011) concluded that novice students’ use of the technology is more complex than simple click and translate use: It can help them communicate better and more, but it can also lower the level of cognitive engagement when writing. Groves and Mundt (2015) examined automated translations of student writing from Malay and Chinese into English, and through an error count, suggested that the technology was capable of producing text of the grammatical quality as the lower IELTS proficiency scores needed for entrance to some university programmes.

Later papers, for example Bahri and Sepora Tengku Mahadi (2016), explored how the software can be exploited as a richer resource than conventional dictionaries. Lee (2019) goes as far as to use GT as a way for students to notice errors in their own output.

However, there are very few studies, as yet, which suggest a rigorous, replicable and scalable use of GT and which explore how the technology can be used to enhance or supplement traditional language teaching and learning.

# 2.2. Academic integrity and technology

There is an understandable tension when new technologies threaten to undermine or disrupt standard and long-held academic traditions. However, a review of the literature on this subject suggests that the nature of academic integrity is often more complex and nuanced than is first suggested. For example, Flowerdew and Li (2007) describe how the understanding of the nature of plagiarism is often fundamentally based in Anglo-centric institutions and patterns of thought.

More nuanced thinking in the area of copy-paste plagiarism has led to a better understanding of how patch writing can, for many students, be an essential part of the process of becoming effective academic writers (Ivanic, 1998; Pecorari, 2003). In addition, there is now an understanding that not all unoriginality, or intertextuality, is in fact transgressive (Chandrasoma et al., 2004), and students are often encouraged to incorporate generic academic language into their own output (Davis & Morley, 2018).

# 2.3. University entry requirements and graduate expectations

Related to the acceptability of student use of MT in Anglophone HE, there might be a concern regarding the implications of such practice for the value of the degree awarded, since the degree may imply proficiency in English. However, this is a fuzzy area, where entry requirements are fixed by means of IELTS or TOEFL scores, whereas exit expectations remain very vague, e.g. native-speaker level (Benzie, 2010). Yet, a native speaker of any language is not inherently proficient in academic or professional registers without being taught what this entails (Murray, 2013). This implies that it is not solely the student’s responsibility to develop their communicative competence for general and specific purposes. This responsibility should be shared between the institution and the student. Thus, ample opportunity to develop discourse abilities needs to be embedded in the curriculum. Should that not be the case, students may more likely resort to technology such as MT to facilitate their language production to cope with the high demands of HE. They may even do so if they are uncertain whether this is acceptable (Garcia & Pena, 2011).

# 2.4. The status of translation in academia

One of the main drivers of translation has always been the demand for knowledge exchange and learning (cf Robinson, 2002). Thus, translation has been linked with scientific exchange, e.g. from ancient Greece into Islamic traditions (Kennedy, 2000) or into European scholarship, the spread of Buddhist philosophy into Southeast and East Asia (Wakabayashi, 2005), and the dissemination of influential work by scholars such as Newton, Kant, Freud, Derrida, Vygotsky or Bourdieu, to name but a few, into academia beyond the language their work was initially written in. The massive influence of such knowledge exchange has been strongly facilitated by the translation of the originals. Even scholars such as Derrida (1979) or Spivak (2000) who argued that translation may indeed be impossible or at least highly problematic have thrived because their work has been translated; or they themselves were engaged in translation activity. Despite their apparent doubts regarding the general feasibility of translation, they never seem to have been too concerned about the proliferation of their own ideas through translation. Thus, arguably, even scholars questioning the very undertaking of translation have seemed quite content with its use to make their voices heard (Mundt, 2018). More importantly, scholars who are unable to read the originals seem quite comfortable working with translations as sources for their own work. We may, thus, encounter academics lecturing about Confucius, Freud or Vygotsky without ever having read them in the original e and this appears to be perfectly acceptable academic practice.

In a similar vein, Luo and Hyland (2019) have recently suggested that translation can be very empowering for scholars who are not conversant in English but want to publish their research for an international audience; however, they also point out that it seems only fair to give the translator due credit for the resulting target text, as they had an active hand in writing it. A similar point has been put forward by Bowker and Ciro (2019) regarding the use of MT. They rightly point out that there may be the common misinformed assumption that MT is detached from human input, while in reality MT would not be possible without human-generated training data.

Translation has played an important role in the dissemination of knowledge for millennia. It can be used for assimilation and dissemination of knowledge, i.e. as facilitator for reading and writing. This is a choice that scholars have, and nobody would dispute this right. That is why this study approaches the issue from the angle of student use of MT, which some might perceive as more controversial.

# 2.5. Technology acceptance model

The present paper is rooted in the suggestions made by the technology acceptance model (TAM), which suggests that perceived usefulness and ease of use are contributors to the intention to use a technology (cf Davis, 1989). Given that ‘TAM is a powerful and robust predictive model’ (King & He, 2006, p. 751), and given that GT has been continuously and significantly improving in output quality and is extremely easy to use, we assume that students who perceive the technology as potentially useful will in some form make use of it. We did not attempt to test this assumption but rather took it as a starting point to investigate the views of university staff on student use of MT.

# 3. Methodology

# 3.1. Theoretical framework

This study adopted a qualitative approach, using semi-structured interviews. While a purely qualitative approach brings with it clear limitations in terms of generalisability of the findings and sample size, it allows for a more detailed exploration of individual opinions, thus adding a degree of depth to the available data and its analysis that facilitates ‘collecting stories, analysing their contents, finding patterns and sharing what is learned’ (Mears, 2012, p. 175). For a discussion that is in its infancy, it was felt suitable to start with a small-scale study and take the opportunity to have professional discussions that might stimulate further debate in HE and be used as a basis for future larger-scale research. Further, qualitative work allows for the deeper exploration of themes as they emerge during the interviews, which proved to be a fruitful activity during this study.

# 3.2. Sampling

Participants were recruited at two UK universities, resulting in data being collected from eleven members of staff (five from one university, six from the other). The universities are members of the Russell Group, a coalition of high-ranking UK universities. After ethical approval was granted by the ethics committee at both universities, the researchers used their professional networks to identify potential participants. Obtaining informed consent from the participants involved a written introduction of the aims and processes of the research, along with the assurance of anonymity of the participants and the option to withdraw from the study at any time.

Staff from language departments and EAP units were deliberately excluded, since it was anticipated that their take on student use of MT would be affected by their specific interest in language acquisition. Their opinions would warrant a separate study taking into account their specific interests and teaching and learning aims. Table 1 shows the departmental affiliations of each participant within the university:

To ensure anonymity of the persons and their university affiliations (with different role labels across different universities), only their title (e.g. professor etc.) is disclosed here. The two universities have different titles for equivalent academic ranks. Only one is used here. ‘Academic Services’ here means that these are non-teaching staff (without an academic title like teaching staff, hence $\boldsymbol { \mathrm { n } } / \boldsymbol { \mathrm { a } }$ ), but are closely involved in assessment procedures, quality assurance and policy making.

# 3.3. Data collection

The research was conducted by means of semi-structured interviews (Dornyei, 2007€ ). All interviews were audio-recorded and later transcribed for data analysis.

The five main interview questions were as follows:

1. Would you regard it as acceptable for students to translate reading for their studies using GT?   
2. Would you encourage students to use GT in their studies?   
3. Would you welcome the teaching of/about GT as a tool for effective study?   
4. Would you regard it as acceptable, in terms of Academic Integrity for a student to submit work which they have written in their own language and translated using GT?   
5. Could you envisage a situation where GT substituted for a student’s English skills entirely (e.g. use of headphones with built-in translation capability for lectures/seminars/tutorials)?

Table 1 Participant details.   

<html><body><table><tr><td>Participant</td><td>Department</td><td>Academic rank</td></tr><tr><td>Participant 1</td><td>Education</td><td>Professor</td></tr><tr><td>Participant 2</td><td>Education</td><td>Associate Professor</td></tr><tr><td>Participant 3</td><td>Academic Services</td><td>n/a</td></tr><tr><td>Participant 4</td><td>Academic Services</td><td>n/a</td></tr><tr><td>Participant 5</td><td>Education</td><td>Professor</td></tr><tr><td>Participant 6</td><td>Engineering</td><td>Assistant Professor</td></tr><tr><td>Participant 7</td><td>Humanities</td><td>Assistant Professor</td></tr><tr><td>Participant 8</td><td>Law</td><td>Assistant Professor</td></tr><tr><td>Participant 9</td><td>Biosciences</td><td>Associate Professor</td></tr><tr><td>Participant 10</td><td>Biosciences</td><td>Associate Professor</td></tr><tr><td>Participant 11</td><td>Medicine</td><td>Associate Professor</td></tr></table></body></html>

These formed the basis for individual follow-up questions. In particular interview questions 1 and 4 aimed at finding answers to the first two research question, namely:

To what degree do academic staff see the use of MT by students for their academic work as acceptable? Is use of MT as reading and writing aid considered academic misconduct; and, if so, under what circumstances?

The third research question was:

Is there currently a university policy on student use of MT? Should there be?

Some answers to this question were found in the themes that emerged during the data analysis. Interviews lasted between 15 and $3 0 ~ \mathrm { { m i n } }$ . It should be noted that all participants were either native speakers of English, or had reached a level of proficiency in the English language that enabled them to communicate their work in English at a professional level. This may have influenced the way they perceived the use of MT as communication aid.

# 3.4. Data analysis

The interviews were transcribed by the researchers and then coded in NVivo 12 and subjected to content analysis (cf Cohen et al., 2011). Coding occurred at three levels, with both researchers coding the data independently to ensure a higher degree of coding reliability. First, the data were coded according to question and sentiment expressed by the participants (e.g. accept, reject, uncertain). This led into a more detailed thematic analysis and coding, with four main themes emerging. That is to say, the first level was conducted deductively according to overarching anticipated sentiments; and the second level was inductive, as the data yielded more granular themes and nuanced opinions. As a third step, the emerging themes were then confirmed and streamlined through axial coding, which serves to confirm recurring similarities and patterns (cf Dornyei,€ 2007) and establish a clear narrative direction, and then subjected to a quantitative treatment to establish trends within the participant group. At each level of coding, the researchers compared their results and resolved discrepancies through detailed case-by-case discussion.

# 4. Results

Four main themes arose from the data, alongside numerous smaller side points around language learning, internation alisation and the nature of authorship. Here, we deal with the four most prominent emergent themes, namely ‘policy’, ‘academic integrity’, ‘the university brand and employability’ and ‘linguistic development’.

# 4.1. Policy

One theme that arose early in most of the interviews was the need for policy in this area. This is not to say that there was a widespread desire to ban or censure the use of the technology, but it was clear that this was an issue that had not been widely discussed from a policy point of view. Indeed, many of the participants expressed sentiments that it was an “interesting” (Participant 9) or “tricky” (Participant 7) topic. On the other hand, none of the participants were able to point to a clear regulation on the use of MT at school, faculty or university level. Participant 3 stated that all relevant policy “predated” the recent developments in MT, which seems to confirm that this is an issue requiring urgent discussion. In total, only three participants did not mention policy, while the remaining eight indicated that policy on the use of MT was non-existent. In this light, most $\mathbf { \dot { n } = 7 }$ ) participants recognised the need for a discussion about this issue, for example:

I think I’d want a broader discussion on this with colleagues (Participant 9).

Despite the desire for discussion, the desire for prescriptive regulation was far from universal. Participant 1 made the connected points that this form of regulation would be difficult to enforce, but also that it could undermine students’ confidence in the wider academic endeavour.

It feels to me that if you have too many academic integrity prescriptions about these things, then you just risk losing respect of the students because you kind of undermine things that feel quite natural and so on.

In summary, it transpired that there was no clearly articulated policy around student use of MT, but there was a perceived need to at least discuss the acceptability of its use.

# 4.2. Academic integrity

The theme of the use of MT in terms of academic integrity was one of the key points to emerge from this study. Participants were asked for their opinions on student use of MT as reading and writing aid, in particular given the evident absence of

university policy. The main objective here was to try and identify what might constitute acceptable or unacceptable practice in the eyes of individual members of university staff.

Responses, somewhat unsurprisingly, were varied. Also, there was an evident difference between how GT was perceived as reading aid and as writing aid. It seemed that the participants were at relative ease with students using it as a reading aid, so for receptive purposes, while there was overall more concern regarding the use of GT for productive purposes.

# 4.2.1. MT use for reading

Generally, the data indicates that the participants found the use of GT acceptable as a reading tool. For instance, Participant 1 was quite positive about its use:

Yes, very wise if they don’t read the native language of the author, yeah. I certainly do it myself.

Participant 2 pointed out:

I kind of think it’s not any of our business. I think sure it’s acceptable, but I think, what I’d like to see us doing, we don’t do this, is giving some kind of guidance or talking to students.

he use of GT for reading was also likened to the use of dictionaries, as exemplified in a statement by Participant 3:

Yes, I don’t see why not. Obviously at the moment they might be using a foreign language dictionary for that purpose and I’m unaware that we’ve ever criticised that.

In sum, there was no indication in the data that any participant considered the use of GT as a reading tool questionable from the perspective of academic integrity. In other words, none of the participants seemed to consider using GT for reading as academic misconduct.

# 4.2.2. MT use for writing

Participants were also asked whether they would regard it as acceptable in terms of academic integrity if students submitted written work for assessment that had been written by them in their first language and then machine translated (either in part or as a whole) into English. Compared to the findings about reading, the participants were clearly more reserved and tentative. Three of the participants did not give a decisive answer, seven indicated the use of GT as writing tool would not constitute academic misconduct (although they voiced a number of concerns, see ‘brand & employability and ‘language development’ below), and one participant indicated that it would be misconduct.

Participant 1, with reference to the absence of policy and of clear guidance, very concisely summarised the issue:

Well, I think this is a minefield. […] So, I think I’m just going to be evasive and say you are identifying a very significan problem.

Participant 2, on the other hand, had a very clear opinion on whether the use of GT for writing constitutes academic misconduct:

It doesn’t fall under academic misconduct. Technically it’s not seen as a breach in academic integrity by the university […] the sort of classic thing in academic misconduct, we’ve got suspicions of false authorship, which this clearly isn’t.

Participant 5 provided a more detailed explanation of why and how the use of GT as a writing tool was, in their view, not academic misconduct:

… it’s happening now […] if you’re a research supervisor, I’m sure that sometimes you’re saying to your students, you know, transcribe your interviews in Thai or Mandarin or whatever it might be, and then use a tool or a person and only translate the bits that you need to actually put into your PhD. […] and if we’re allowing research students to do it, why would we not allow undergrads to do it as well? […] so if they are following standard academic practice but also acknowledging that additional layer of using Google Translate, then that would be good academic practice.

The main tentative direction emerging from the data above was that if students had written their papers themselves and then used GT to change the language, this was not considered to constitute academic misconduct. However, this view was by no means universal among the participants.

In fact, the complexity of the issue was illustrated by Participant 6. On the one hand, Participant 6 did not consider MT use as writing tool a form of plagiarism:

Is it the students own work? Has the student written themselves? It’s not plagiarism. So, Participant 6 acknowledged that a student text written in L1 and translated via MT was indeed their own intellectual achievement. At the same time, however, Participant 6 raised another issue:

Is it their own writing in English? That’s where it gets questionable, and it’s no.

Participant 3 made a similar point. While acknowledging that a machine translated text may well be a student’s own intellectual achievement, Participant 3 stated that

… the English text, nevertheless will have been produced for them in that it is a translation. And, therefore, they would be submitting something that is not their own work in the sense that the English words that had been selected would not have been their own creation.

In essence, the data shows that there is no agreement amongst university staff regarding whether using GT as a writing tool is acceptable practice or not. While most participants appeared to be comfortable with GT as a reading facilitator, there was far less agreement regarding GT as a writing tool, with clearly diverging opinions and concerns about the implications for the status of university degrees, the university itself and students’ development.

# 4.3. The university brand and employability

Among the participants, there was a clear awareness that the degree that the students earn at UK universities carries a good deal of weight in the employment marketplace. There was a clear concern that the degree from a UK university carried, at least implicitly, the understanding that the holder was able to communicate in English at a high level. This is perhaps best expressed as follows:

At the exiting of a degree they should be able to deal with English as a native English speaker can. An assessment must somehow capture that whole range of skills and aptitudes that you expect from a [University name] graduate and I believe the ability to hold a conversation in English and to write a reasoned report or essay in English are inherent. (Participant 11).

Views expressed with regard to the job market tended to fall into three main areas. The first was that English is the established lingua franca, particularly in academia, and therefore graduates wishing to pursue a career would need to have competence in the language. This is exemplified by the following comment by Participant 7:

If somebody is a researcher […] they will always want to take part in the academic community and academic discourse is in English, not in […] whatever other language, so if he or she wanted to participate in this discourse he or she has no other choice.

In addition to this, there was concern $\langle \mathtt { n } = 7 \cdot$ ) about protecting the reputation, or brand, of the university, in the employment market place, and that if a degree were awarded on the basis of work produced through GT, then the lack of demonstrable English language skills may erode a much-cherished reputation:

Well, in terms of the status of our degrees, it’s protecting a particular brand in a sense. And I think at the moment people have the reasonable expectation that somebody with a [University name] degree could perform in English in particular ways, and we wouldn’t want to undermine that confidence. (Participant 3)

Two participants also raised the point that perhaps the value of the degree as a tool to employment is not best judged from within the academy. Rather, this value is to be determined by the market, and it is possible that this determination will, in turn, reflect the widespread availability and increasing quality of MT.

If the end employer doesn’t really care about the ability to formulate an argument in English in your own head then maybe the market will decide what a degree is. (Participant 11)

We’ve got to look at what the external recipients of students actually need. What skills do they need? So, I think that what they need is, they need, me, if I’m the student, they need me to know how to learn. They don’t need me to know everything. Again, because I can go to GT to translate from English into German and vice versa. (Participant 5)

This notion seems to suggest that the acceptability of the use of technologies (and by extension other practices) is not solely determined by the universities themselves, but also by external factors, such as the employment market.

# 4.4. Language development

The majority $( \mathtt { n } = 9 )$ ) of the participants also touched upon the topic of the development of students’ language proficiency. This is connected to the area of employability, in the sense that they felt that students should be able to function effectively without automated language assistance by the time of graduation, but that a certain, decreasing level of assistance would be acceptable as they progressed through their studies. In the context of a Master’s degree, for example, Participant 9 opined

I also think in the first few weeks it’s like anything, it’s transition, so in the first few weeks so if they’re putting all of their stuff into Google Translate in order to basically stay on top of the work while they’re developing the English, I couldn’t see a problem. What you wouldn’t want them to be doing is by the end of semester 2 to be doing it routinely …

It can be seen here that concerns about MT as writing tool are not only related to legal aspects (i.e. policy and misconduct), but also to concerns regarding the intended/expected learning outcomes of UK degrees and the development of students to function successfully in a professional environment.

# 5. Discussion

The following discussion is based on a number of assumptions.

1. Firstly, while English is the current academic lingua franca, and an essential competence in English is needed for academics aiming to publish beyond their home country, this is not necessarily immune to change.   
2. This dominance is a result of a set of historical situations, and there is nothing intrinsic in the English language itself that makes it more suitable than many other languages to play this role.   
3. Students hoping to study in a language environment in which they are not fully competent are at a disadvantage, when compared to the native speakers of that language.   
4. Online translation only works at the level of the sentence. This means that it is increasingly able to transfer grammatical and lexical content. However, it is at present unable to deal with different conventions of language use, such as the organisation of argument, use of metadiscoursal features and other rhetorical concerns (authors).

# 5.1. Overall acceptability of MT

From the data presented here, it would seem that academic staff are generally, but guardedly, not opposed to the use of MT by students who find it helpful. The question of authorship does not seem to be of major concern, since there is a clear view that if students are demonstrating their understanding and argumentation, there is little reason to insist that they use flawed language skills to present this, if there is a clear and effective alternative. However, to go some way to remove doubt, there is a case that students should be asked to declare the level of technological intervention that they have employed in order to create their work.

More troubling to the participants, however, is the idea that students would be able to graduate with a degree from their university and take this into the job market without having demonstrated the ability to communicate effectively in the language of instruction. This is clearly a concern worth examining. While this is clearly an issue, it is also reasonable to argue that, just as academia is having to adjust itself to the advent of MT, so the world of work will also adjust, if not more so. The internationally-oriented office of the future is just as likely to embed computer-mediated translation into its practice as a university, and a potential employee who can demonstrate MT literacy in a complex environment could be argued to be a stronger candidate than one who relies on competent but flawed conventional language skills, but without the extra assistance of MT.

A further complication is the student experience. While avoiding the need to develop language skills will presumably be attractive to some students, it must be borne in mind that this could directly impact the ability of the students to thrive while studying at university. Students without language skills beyond computer-mediated academic reading and writing would be unable to participate in many of the activities of the university not directly related to gaining credits, from social activities to incidental learning.

One potential strategy that can be adopted to ameliorate the potential negative effects of this technology is to examine the assessment structures of university degrees, and ensure that there is unassisted spontaneous language use which is assessed as well as more conventional essays and dissertations. This might include traditional exams, as well as more innovative assessment such as assessed discussions or viva-style oral exams. Clearly, the universities would also have to maintain a high level of commitment to insessional language support (i.e. courses that support the development of academic communication skills over the duration of degree courses). This would, of course, also help combat contract cheating,1 and would give students a clear and strong incentive to continuously improve their language abilities.

# 5.2. Tension between individual assessment and degree level outcomes

There is clearly a tension in the respondent answers over at what point the acceptability of students’ use of technology should be called into question. No participant opposed the use of MT as a substitute for a dictionary, or to expand conventional dictionary use, for example for understanding or even creating complex academic terminology. There was less consensus on the acceptability of the students’ use of the technology to write whole texts or more extensive parts of texts; but most participants were cautiously accepting of this, generally indicating that this is not optimal, but at the same time not transgressive of normal academic integrity practises. This perhaps reflects the nuances of student technology use discussed in more depth by Garcia and Pena (2011). Their findings indicate that students found writing with MT easier and generally scored higher. However, both students and tutors indicated different degrees of concern about the acceptability of the technology for language learning. So, users found the use of MT helpful, but not entirely unproblematic.

There was, on the other hand, a clear feeling among our participants that students should leave their degrees with strong and demonstrable English language communication skills. This was most commonly articulated as part of the university brand. However, there was little discussion of what, if any, the dividing line should, or even could be.

This gap was exacerbated by the very common idea of language development. This idea was mentioned by a number of participants. The general idea is that students could use MT at the start of a degree, but by the end of the degree, should have somehow weaned themselves of its use. However, this does contain an inherent contradiction, as pointed out by one of the participants. This is that, unlike a dictionary, for example, heavy use of MT does not necessarily lead to the development of language skills, which requires sustained and focused effort. Therefore, a reliance on MT at the start of the degree may be likely to exacerbate the problem, not solve it. This is not to suggest that there is no place for MT in the development of students’ language skills. There is a growing strand in the literature exploring how the use of MT can enhance the learning process, instead of replacing it (El-Banna & Naeem, 2016; Tsai, 2019).

# 5.3. Expected entrance and exit language competence

When discussing participants’ expected language level upon graduation, academic staff referred the ability to “perform in English in particular ways” (Participant 3). In other words, there is an expectation that students have a certain level of English to draw upon when faced with intellectually challenging situations. Although, at first consideration, this seems to be a reasonable expectation, it must be compared against entrance requirements, which are usually in the region of 6.0e6.5 in IELTS. This is fairly effective, but not sophisticated. Therefore, it is clear that there is a mismatch between students’ linguistic entrance requirements and the exit expectations on the part of the university regarding their language ability as expressed in the graduate attribute documentation. It has also been demonstrated that students’ language does not necessarily improve dramatically simply by dint of being on an English-speaking campus (Groves, 2013; O’Loughlin and Arkoudis, 2009). Therefore, in order to improve their language skills to match those whose first language is English, students are expected to undertake an additional workload. How explicit this expectation is made to students during recruitment activity is unclear. This leads to a dichotomy when seen through the lens of MT. While the technology could be seen as a levelling mechanism during a student’s degree, which could potentially go some way to remove the extra burden on those who are studying challenging degrees in an additional language, it also would mean that these students will not have gained the skills to reflect universities’ lofty rhetoric promoting their students’ communication skills, at least not as traditionally measured.

We see two ways to move beyond this issue. The first is to ensure that students do, in fact, improve their language skills during their studies and to assess them in a combination of ways. Some of these can be open to computer-mediated language, while others will demand spontaneous and unassisted production of language to engage with and express complex academic concepts. However, it must be recognised at all levels of university teaching and administration that language improvement while studying requires significant effort on the part of the student and significant resources on the part of the institution. The other way would be to recognise that this technology has arrived and is highly unlikely to do anything other than improve in quality. The university could award degrees on the strength of students’ computer mediated language skills, and not their ability in the lingua franca. Whether or not this would be acceptable, or even desirable within the job market is likely to take time to assess, and is more likely still to show a patchy, diverse demand across professions and countries.

# 5.4. Need for policy

There is also a clear need for policy within this area, and we strongly believe that this should be institutional level, rather than a patchwork of departmental regulations, which can be inconsistent and contradictory. This is necessary because, even in the small sample of academic staff interviewed for this article, there was no unanimous agreement over the acceptability of the use of the technology. In addition, given the concerns over the dilution of the university brand, there needs to be a robust discussion around the area of language ability in graduate attributes, and whether or not this is assumed to be unassisted or computer mediated language.

The questions that are in need of legislation are as follows:

1. Are universities happy for students to use this technology when developing their written work? If this is the case, it must be recognised that it would not be practical to distinguish between the use of MT for individual words and phrases and its use for writing longer stretches of text. There needs to be a decision about whether academic authorship of work written in another language and translated automatically into the language of an HEI belongs to the student, or is shared between author and the technology. There is plenty of precedent in the literature around human translation to inform this discussion. However, it must also be recognised that if the decision were taken to ban the use of MT, policing would become extremely challenging. It may be possible to require students to declare the use of MT, but the utility of such a system is open to question.

2. When students graduate, are they assumed to have a high level of competence in the language of the HEI where they studied, given that it may be possible to pass all coursework with computer-mediated language skills? Should language skills remain an explicit part of the graduate identity, then these skills, and assessment through, and potentially of, these skills needs to be embedded in the curriculum, at all levels, not as an assumed by-product of the students’ work on their content modules. Universities would need to stipulate that a certain amount of the credit load will be assessed through spontaneous and unassisted language use. However, by doing so, they would need to recognise that they would be laying a heavier burden of assessment on students whose first language is not that of the HEI, and would need to decide if this was a fair and equitable treatment of a large section of their student body. Even if HEIs are content with this disparity, there would need to be a high level and consistent investment in language-based resources in order to support the students in need.

3. There should also be a discussion about whether or not to teach MT literacy (cf Bowker & Ciro, 2019) as an embedded part of the curriculum, or through various support services, such as EAP departments, library training and other student support. This should bear in mind that the English language is the medium of academic exchange, not the purpose, and that even if HEIs decide to limit the students’ access to MT, it will not be limited in the same way in the world into which the students will be moving after graduation.

# 6. Conclusion

There are two factors which have brought the issue of MT in HE to the fore. The first is the undoubted improvement in quality, at the sentence level, of online MT. This is free of cost, widely available and virtually effort free. The second is the fact that this has become a part of an internationalised sector, with large numbers of students travelling to countries where they do not share expertise in the language of the institution.

In response to the research questions, among the academic staff interviewed for this paper there was some consensus on the academic appropriacy of the use of this technology by students, but this is far from universal. The use of MT as a writing aid seems to be viewed as more controversial than as a reading aid. Overall, there seemed to be the tendency to not view the use of MT as academic misconduct. However, our findings suggest that there is a clear and urgent need for university policy makers to engage with this issue and offer guidelines that are robust, realistic and in line with the wider values of these institutions.

It should also be noted that it would be a mistake to consider this issue only relevant to Anglosphere universities. It is perhaps more pressing and may have greater impacts in HEIs and other similar institutions with EMI programmes outside of the English L1 countries, since their reasons for providing EMI programmes and their views of the status of English may be fundamentally different to those of, for instance, UK institutions.

Further, MT would provide a solution to many of the issues that international students face in their learning and assessment, by to some degree levelling the playing field and allowing students to focus their energy on their academic endeavours, not on improving their expertise in a challenging language. From another point of view, this also puts the primacy of many universities at risk, if it is to be believed that the English language is a selling point for prospective students and also prospective graduate employers. Given the advantages that universities have when they are based in the Englishspeaking world, the equity and justness of this primacy is open to question.

# Author statement

Klaus Mundt: Conceptualization, Methodology,Software, Validation,Investigation, Formal analysis, Resources, Data Curation, Writing Original Draft, Writing Review and Editing, Visualization,Supervision, Project administration, Funding acquisition.

Michael Groves: Conceptualization, Methodology,Software, Validation,Investigation, Formal analysis, Resources, Data Curation, Writing Original Draft, Writing Review and Editing, Visualization,Supervision, Project administration, Funding acquisition.

# Declaration of competing interest

None.

# References

Bahri, H., & Sepora Tengku Mahadi, T. (2016). Google translate as a supplementary tool for learning Malay: A case study at universiti sains Malaysia. Advances in Language and Literary Studies, 7(3). Retrieved from https://www.journals.aiac.org.au/index.php/alls/article/view/2305.   
Barrett, L. (2015). Embedding the google translate widget on taylor & Francis online. Editors’ Bulletin, 10(3), 48e50. https://doi.org/10.1080/17521742.2015. 1013790   
Benzie, H. J. (2010). Graduating as a ‘native speaker’: International students and English language proficiency in higher education. Higher Education Research and Development, 29(4), 447e459. https://doi.org/10.1080/07294361003598824   
Bowker, L., & Ciro, J. B. (2019). Machine translation and global research: Towards improved machine translation literacy in the scholarly community. Bingley: Emerald Publishing Limited.   
Castilho, S., Moorkens, J., Gaspari, F., Calixto, I., Tinsley, J., & Way, A. (2017). Is neural machine translation the new state of the art? The Prague Bulletin of Mathematical Linguistics, 108(1), 109e120. https://doi.org/10.1515/pralin-2017-0013   
Chandrasoma, R., Thompson, C., & Pennycook, A. (2004). Beyond plagiarism: Transgressive and nontransgressive intertextuality. Journal of Language, Identity and Education, 3(3), 171e193. https://doi.org/10.1207/s15327701jlie0303_1   
Clifford, J., Merschel, L., & Munne, J. (2013). Surveying the landscape: What is the role of machine translation in language learning? - $@$ tic. Revista D’innovacioEducativa, (10), 108e121.   
Cronin, M. (2013). Translation in the digital age. Abingdon: Routledge.   
Davis, F. (1989). Perceived usefulness, perceived ease of use, and user acceptance of information technology. MIS Quarterly, 13(3), 319e340. https://doi.org/ 10.2307/249008   
Davis, M., & Morley, J. (2018). Facilitating learning about academic phraseology: Teaching activities for student writers. Journal of Learning Development in Higher Education, Special Edition, 1e17.   
Derrida, J. (1979). Living on: Border lines. In H. Bloom (Ed.), Deconstruction and criticism (pp. 75e176). New York: Continuum.   
Dornyei, Z. (2007). € Research methods in applied linguistics. Oxford: Oxford University Press.   
El-Banna, A., & Naeem, M. (2016). Machine translation as a model for overcoming some common errors in English-into-Arabic translation among EFL university freshmen (Non Journal) https://eric.ed.gov/?id ED580942.   
Flowerdew, J., & Li, Y. (2007). Language Re-use among Chinese apprentice scientists writing for publication. Applied Linguistics, 28(3), 440e465. https://doi. org/10.1093/applin/amm031   
Garcia, I. (2011). Translating by post-editing: Is it the way forward? Machine Translation, 25(3), 217e237. Retrieved September 28, 2020, from http://www. jstor.org/stable/41487495.   
Garcia, I., & Pena, M. I. (2011). Machine translation-assisted language learning: Writing for beginners. Computer Assisted Language Learning, 24(5), 471e487. https://doi.org/10.1080/09588221.2011.582687   
Ghasemi, H., & Hashemian, M. (2016). A comparative study of google translate translations: An error analysis of English-to-Persian and Persian-to-English translations. English Language Teaching, 9(3), 13e17.   
Groves, M. (2013). An investigation of students’ grammatical ability in an international university branch campus. Malaysian Journal of ELT Research (MaJER), 9(1).   
Groves, M., & Mundt, K. (2015). Friend or foe? Google translate in language for academic purposes. English for Specific Purposes, 37, 112e121. https://doi.org/ 10.1016/j.esp.2014.09.001   
Guerberof Arenas, A., & Moorkens, J. (2019). Machine translation and post-editing training as part of a master’s programme. The Journal of Specialised Translation, 31, 217e238.   
Ivanic, R. (1998). Writing and identity: The discoursal construction of identity in academic writing. Amsterdam: John Benjamins.   
Jolley, J. R., & Maimone, L. (2015). Free online machine translation: Use and perceptions by Spanish students and instructors. Learn languages, explore cultures, transform lives, 181-200. Lincoln: University of Nebraska. Retrieved from https://digitalcommons.unl.edu/cgi/viewcontent.cgi?article¼1298&amp; context¼teachlearnfacpub#page¼202.   
Kennedy, H. (2000). Intellectual life in the first four centuries of islam. In F. Daftary (Ed.), Intellectual traditions in islam (pp. 17e30). London: I.B. Tauris.   
King, W. R., & He, J. (2006). A meta-analysis of the technology acceptance model. Information & Management, 43(6), 740e755. https://doi.org/10.1016/j.im. 2006.05.003   
Lee, S. M. (2019). The impact of using machine translation on EFL students’ writing. Computer Assisted Language Learning, 1e19. https://doi.org/10.1080/ 09588221.2018.1553186   
Luo, N., & Hyland, K. (2019). “I won’t publish in Chinese now”: Publishing, translation and the non-English speaking academic. Journal of English for Academic Purposes, 39, 37e47. https://doi.org/10.1016/j.jeap.2019.03.003   
Mears, C. L. (2012). In-depth interviews. In J. Arthur, R. Coe, L. V. Hedges, & M. Waring (Eds.), Research methods & methodologies in education (pp. 170e176). London: Sage.   
Mundt, K. (2018). Against the “un-” in untranslatability: On the obsession with problems, negativity and uncertainty. In D. A. Large, M. Akashi, W. Jozwikowska, & E. Rose (Eds.), - Untranslatability: Interdisciplinary perspectives (pp. 64e79). Abingdon: Routledge.   
Mundt, K., & Groves, M. (2016). A double-edged sword: The merits and the policy implications of google translate in higher education. European Journal of Higher Education, 6(4), 387e401. https://doi.org/10.1080/21568235.2016.1172248   
Murray, N. (2013). Widening participation and English language proficiency: A convergence with implications for assessment practices in higher education. Studies in Higher Education, 38(2), 299e311. https://doi.org/10.1080/03075079.2011.580838   
O’Loughlin, K., & Arkoudis, S. (2009). Investigating IELTS exit score gains in higher education. International English Language Testing System (IELTS) Research Reports, 10, 1, 2009.   
Pecorari, D. (2003). Good and original: Plagiarism and patchwriting in academic second-language writing. Journal of Second Language Writing, 12(4), 317e345. https://doi.org/10.1016/j.jslw.2003.08.004   
Precup-Stiegelbauer, L.-R. (2013). Automatic translations versus human translations in nowadays world. Procedia - Social and Behavioral Sciences, 70, 1768e1777. https://doi.org/10.1016/j.sbspro.2013.01.252   
van Rensburg, A., Snyman, C., & Lotz, S. (2012). Applying Google Translate in a higher education environment: Translation products assessed. Southern African Linguistics and Applied Language Studies, 30(4), 511e524. https://doi.org/10.2989/16073614.2012.750824   
Robinson, D. (2002). Western translation theory: From herodotus to nietzsche. Abingdon: Routledge.   
Sheppard, F. (2011). Medical writing in English: The problem with google translate. La Presse M-edicale, 40(6), 565e566. https://doi.org/10.1016/j.lpm.2011. 02.024   
Spivak, G. C. (2000). Translation as culture. Parallax, 6(1), 13e24. https://doi.org/10.1080/135346400249252   
Tsai, S. C. (2019). Using google translate in EFL drafts: A preliminary investigation. Computer Assisted Language Learning, 32(5e6), 510e526. https://doi.org/ 10.1080/09588221.2018.1527361   
Tsai, S. C. (2020). Chinese students’ perceptions of using Google Translate as a translingual CALL tool in EFL writing. Computer Assisted Language Learning. https://doi.org/10.1080/09588221.2020.1799412   
Turovsky, B. (2016). Found in translation: More accurate, fluent sentences in Google Translate. Retrieved from https://www.blog.google/products/translate/ found-translation-more-accurate-fluent-sentences-google-translate/.   
Turovsky, B. (2018). Ten years of Google translate. Retrieved from https://www.blog.google/products/translate/ten-years-of-google-translate/.   
UKCISA. (2019). International student statistics: UK higher education. Retrieved from https://www.ukcisa.org.uk/Research-Policy/Statistics/Internationalstudent-statistics-UK-higher-education.   
Wakabayashi, J. (2005). Translation in the East asian cultural sphere. In H. Hung, E. Tsoi, & J. Wakabayashi (Eds.), Asian translation traditions (pp. 17e65). Abingdon: Routledge.

Mike Groves has been involved in the teaching of English language for over 20 years, and the teaching of University English for approaching 10 of those. He is the director of the Centre for Academic English Studies, Surrey International Institute, The University of Surrey. He is interested in how technology works for and against the interests of students, instructors and institutions.