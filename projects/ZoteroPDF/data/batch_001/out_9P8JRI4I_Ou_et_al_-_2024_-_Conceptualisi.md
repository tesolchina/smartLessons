# Conceptualising and cultivating Critical GAI Literacy in doctoral academic writing

Amy Wanyu Ou a,\* , Baraa Khuder b , Sindija Franzetti b , Raffaella Negretti b

a Department of Languages and Literatures, University of Gothenburg, Sweden b Department of Communication and Learning in Science, Chalmers University of Technology, Sweden

# A R T I C L E I N F O

# A B S T R A C T

Keywords: Artificial intelligence Academic writing Critical GAI Literacy Self-regulated learning Doctoral education

Generative artificial intelligence (GAI) has revolutionised the landscape of academic writing, presenting both advantages and risks to learning for L2 writers. It is thus imperative that L2 writers, especially at advanced academic levels, develop the critical skills necessary for employing GAI tools ethically and effectively in their writing processes. Our study addressed this need by 1) conceptualising Critical GAI Literacy based on current research and our collected data, and 2) developing a self-regulated learning-based micro-curriculum for L2 doctoral students to cultivate knowledge and skills using GAI for academic writing. We collected interactive and reflective data in an introductory-level academic writing course at a Swedish university enrolled with $6 0 \ \mathrm { P h D }$ students from diverse backgrounds and examined their evolving perspectives and strategies for engaging in GAI-mediated writing. Findings show a spectrum of initial attitudes among students and limited knowledge of GAI use. Final reflections illustrate de-enchantment with GAI, recali brated and enhanced understanding of ethical issues, developed prompting methods, and increased awareness of text ownership through the self-directed learning process. Furthermore, students demonstrated a discerning approach in evaluating GAI-generated suggestions and so ciolinguistic impacts, indicating a growing criticality in L2 writing practices.

# 1. Introduction

The advent of generative artificial intelligence (GAI) tools has revolutionised the landscape of academic writing, transforming the conventional challenges faced by L2 writers. For example, Cornell University’s recent AI guidelines highlight that L2 writers might lack the expertise to make “synthetic language” appear natural, thereby facing potential accusations of unethical behaviour (English Language Support Office, 2024). Recent research has debated the sociocultural implications of GAI tools for L2 writers with some emerging research (e.g., Sasaki et al., 2024) suggesting that GAI tools can empower L2 writers by translating their L1 voice into English. On the other hand, concerns remain regarding the negative effects on L2 writers’ voice and identity (Kubota, 2023; War schauer et al., 2023) and the risk of GAI fabricating claims that are difficult for novice researchers to detect (e.g., Faber et al., 2022; Pividori & Greene, 2023). In this dynamic environment, the focus of research needs to shift towards the critical skills necessary for interacting with GAI tools in a way that promotes learning. This means L2 writers need both traditional forms of literacy to create scientific written products and the literacy to engage with GAI tools for academic writing. Even seasoned writers, such as faculty members, find themselves lacking in these emerging competencies (Titko et al., 2023), and students may feel adrift in this evolving

writing paradigm (Ou et al., 2024).

Extant research on GAI and L2 academic writing has discussed various aspects such as comparing L2 learner- and GAI-produced texts (e.g., Casal & Kessler, 2023), prompting GAI (e.g., Nguyen et al., 2024), and language teachers’ perceptions on the use of GAI tools (e.g., Xu and Tan, 2024). The research emphasises the importance of teaching GAI literacy and calls for pedagogical renovations in L2 writing classrooms that enable learners to draw on their existing knowledge and develop according to their own pace and in terests (Pecorari, 2023). It also highlights the need to critically engage with GAI (Anderson, 2023) to prevent “enchanted determinism” (Campolo & Crawford, 2020), which refers to an uncritical optimism in the power of technology without carefully considering the possible unintended consequences of technology and human-directed implementation. Despite the urgent demand for GAI literacy education for L2 writers, current scholarship still lacks a comprehensive conceptualisation of its content and an effective approach to teaching it.

Our study addresses the knowledge gap and the imperative need for the next generation of L2 writers and researchers to develop necessary skills to use GAI tools ethically and effectively in their writing. Building on intellectual sources from digital literacy, (critical) AI literacy, and self-regulated learning, we propose the concept of Critical GAI Literacy (hereafter C-GAI-L). This conceptualisation goes beyond mere proficiency in using GAI tools; it encompasses multi-dimensional critical competencies that L2 writers require to communicate and collaborate with GAI, evaluate GAI ethics, values and limitations, and equally important, self-direct their C-GAI-L development. To effectively foster C-GAI-L in doctoral L2 writing and enrich the conceptualisation of C-GAI-L based on real-life teaching experience, we implemented a micro-curriculum grounded in self-regulated learning theory (Zimmerman, 2000), which allows for “meeting the learners where we find them” (Pecorari, 2023, p.2) and students’ critical engagement with GAI as a lifelong learning skill. The study is guided by the following two research questions:

RQ1: How should Critical GAI Literacy be conceptualised in the context of academic writing?

RQ2: How does the Critical GAI Literacy micro-curriculum foster PhD students’ ability to self-regulate their use of GAI tools for academic writing?

# 2. Theoretical and pedagogical framework

# 2.1. Digital literacy and (critical) AI literacy

Digital literacy, first introduced by Paul Gilster in 1997, is the precursor of AI literacy. Over the decades, it has evolved into a comprehensive set of skills and competencies for people to function effectively in the digital age, including the technical, cognitive, socioemotional, sociocultural and ethical aspects (e.g., Ng, 2012; van Laar et al., 2017). In the field of language education, digital literacy is viewed as a socially situated activity (Barton & Potts, 2013) and researchers emphasise the importance of teaching students relevant language skills for navigating digitally mediated contexts, such as the ability to search for and evaluate online information, engage in meaningful reading and writing, and collaborate with others online for knowledge construction (Hafner et al., 2013). Existing digital literacy models mostly focus on human interactions in online communities, but some research has also examined the skills required for interacting with AI. For example, the latest EU framework of digital competence (Vuorikari, Kluzer, & Punie, 2022) incorporates competence in AI. Despite its ad hoc nature, this study offers important insights into the knowledge, skills, and attitudes that people need to engage with AI, including the skills to formulate search queries and evaluate the (dis)advantages of using AI, the knowledge of AI biases, data privacy, and ethical implications on environment and minority language users. This framework also emphasises the attitudes of open-mindedness and curiosity, encouraging people to be “open to AI systems supporting humans” (Vuorikari, Kluzer, & Punie, 2022, p.16) and to have “a disposition to keep learning, to educate oneself and stay informed about AI” (p.50).

As AI technologies advanced, the term AI literacy emerged (Kandlhofer et al., 2016) and has become increasingly recognised in recent years. AI literacy, commonly defined as “a set of competencies that enables individuals to critically evaluate AI technologies, communicate and collaborate effectively with AI, and use AI as a tool online, at home, and in the workplace” (Long & Magerko, 2020, p.2), underscores the importance of educating students, and the general public, to competently, responsibly, and critically engage with AI technologies. Studies of AI literacy have mainly explored the concept of AI literacy, often in relation to other literacy concepts and pedagogical methods to teach AI to non-experts (see a systematic review in Laupichler et al., 2022). Despite the significant growth of the field, scholars note that the conceptualisation of AI literacy, particularly in educational contexts, remains in its infancy. Most relevant studies predominantly concentrate on identifying content and pedagogical methods for teaching the technical dimensions of AI (Sperling et al., 2024).

Cetindamar et al. (2024) also contribute to developing the concept of AI literacy by delineating four distinct sets of capabilities. Apart from AI technology-related capabilities (data and technical skills), they underscore work-related capabilities (skills supporting the general use of AI in workplace, like AI ethics and problem solving), human-machine-related capabilities (human-AI interaction skills, like prompt engineering), and learning-related capabilities (life-long learning and self-learning skills). Similarly, Yi (2021) emphasises the significance of self-learning in the AI era, accentuating the role of metacognition as a pivotal component of AI literacy. Therefore, education initiatives aimed at cultivating AI literacy in academic writing should not only impart multifaceted AI-related knowledge and skills but also foster students’ metacognitive awareness to regulate their cognitive processes, facilitating more effective engagement with AI for lifelong learning. This makes self-regulated learning a relevant pedagogical method for teaching C-GAI-L (see below).

# 2.1.1. Criticality in AI literacy

Although the word “critical” has been frequently mentioned in AI literacy literature, Strauß (2021) appears to be the first to combine it with “AI literacy.” Strauß (2021) used “critical” in the context of critical AI literacy to emphasise a deep understanding and analytical perspective on AI-based automation bias to address the societal impacts, ethical implications, and potential risks associated with it. Later, Bali (2023) in her definition of “critical AI literacy” argues that “critical” has three layers of meaning:

One is critical as in critical thinking, as in skepticism and questioning. The other is critical as in critical pedagogy, so focusing on social justice dimensions and inequalities something may exacerbate, reproduce or create. Another is critical, as in, critique it for its potential harms, and critique the credibility/accuracy of its outputs/outcomes.

Teaching this critical perspective means “helping students recognizing the limitations and potential of AI – what they gain or potentially lose when using it.” For Bali (2023), literacy is not only about the ability of knowing when and how to use AI but is also knowing when not to use it.

# 2.2. Self-regulated learning

The theory of Self-Regulated Learning (SRL) (Zimmerman, 2000) is particularly useful to frame a pedagogical sequence that aims to foster strategic and metacognitive development. SRL is defined as “the process whereby learners personally activate and sustain cognitions, affects, and behaviours that are systematically oriented toward the attainment of learning goals” (Zimmerman & Schunk, 2011, p.1). It is important to note that SRL is not only cyclical, with learners engaging in loops of these phases in each study session, but it is always contextualised, which means that no strategy or approach is universally useful for all learners in all situations. Rather, promoting SRL means helping learners identify how strategies can be adapted to each different situation (cf. Panadero, 2017). SRL is also best developed through interaction rather than individual trial and error (Zimmerman, 2000), meaning that GAI can be a useful tool to stimulate the interaction needed to develop SRL: try things, get feedback, ask questions, evaluate outcomes and alternatives vis-a-vis one’s goals, and reflect on learning.

SRL is a cyclical process with three recursive phases: 1) Forethought, 2) Performance control, and 3) Self-reflection/Evaluation (Zimmerman, 2000). The Forethought phase involves both task analysis and self-motivation beliefs: learners activate relevant knowledge of the learning activity, envision possible goals, and decide what strategies are best suited for approaching the task. Learners may also engage with self-motivation beliefs like assessing their own efficacy by thinking about outcome expectations and the intrinsic value of the task for them. In other words, the Forethought phase sets the stage for a learning task before it is executed and influences how the task is carried out in the second phase. In the Performance or volitional control phase, learners execute a task while monitoring their progress, a fundamentally metacognitive process (Winne, 2015). In this phase, learners may be focusing their attention to monitor “specific aspects of [one’s] own performance, the conditions that surround it, and the effects that it produces” (Zimmerman, 2000, p. 19), for instance monitoring their interaction with GAI and adjusting it to align with their goals. The Self-reflection/Evaluation phase involves “processes that occur after performance efforts and influence a person’s response to that experience” (p. 16). Typically, during this phrase, learners reflect on their success or failures by attributing them to various factors. These attributions can lead to new goals and strategies for future performances.

# 2.3. Theorising C-GAI-L

Informed by the above reviewed discussions around digital literacy, critical AI literacy and self-regulated learning, we provisionally conceptualised Critical GAI Literacy (C-GAI-L) as a complex of knowledge and skills that L2 writers need in order to engage responsibly and effectively with GAI in their daily academic writing processes . Specifically, we considered the following four areas of essential competence for L2 writers in academic contexts: (1) interaction with GAI, (2) GAI ethics in academic writing, (3) technical value and limitations of GAI, and (4) self-learning. We adopted Bali (2023) notion of “criticality” in the concept of C-GAI-L and curriculum design, highlighting the elements of critical thinking, critical pedagogy, and critique in all four aspects of C-GAI-L. This means, students are expected to critically examine and reflect on the GAI interaction outcomes, ethical impacts for themselves and the society, GAI functions and usefulness, and their own cognitive processes and learning experiences.

Following previous research (e.g., Cetindamar et al., 2024), our operationalisation emphasises self-learning as a core component of C-GAI-L for junior researchers and academic writers. In particular, we highlight that an open attitude towards GAI is an important part of students’ problem-solving competence (Vuorikari, Kluzer, & Punie, 2022) that enables them to take initiatives to identify their own knowledge gaps and keep staying informed about GAI in their academic careers.

# 3. Design and research methodology

# 3.1. The micro-curriculum

The C-GAI-L micro-curriculum was imbedded in a PhD-level course on academic writing for publication. The course is built on SRL, which requires students to self-assess their writing situations, and based on that, self-direct their learning. It includes three four-hour online workshops guiding students in collaborative group tasks with instructors providing support. The course is a Pass/Fail course. Student learning outcomes are assessed based on their completion of all assignments, including a self-assessment plan (at the beginning f the course) and a comprehensive writing portfolio (at the end of the course)

The three phases of the micro-curriculum (Forethought, Performance-control, and Self-reflection) were seamlessly integrated into the course’s learning flow. Students engaged with three core activities: (1) initial self-assessment of C-GAI-L (integrated as part of the self-assessment plan), (2) hands-on interaction with ChatGPT (integrated as one learning task during the third workshop), and (3) selfreflections (documented in the writing portfolio assignment). The curriculum design is illustrated in Fig. 1.

The first activity, initial self-assessment of C-GAI-L, set the stage for later phases. In the self-assessment plan, students evaluated themselves on seven criteria related to academic writing, including one on C-GAI-L.1 Specifically, students rated two statements about their familiarity with GAI tools and their considerations of GAI limitations and ethics in research, followed by a comment section where they shared their thoughts and ratings for the statements (Fig. 2). A link in this section directed students to the course’s webpage, specifically a curated collection of learning resources on the use of GAI in academic writing. These resources include (1) reputable blog posts introducing the concept of C-GAI-L, (2) current university and publisher policies about the use of GAI, (3) other ethical and environment issues connected to GAI, and (4) critical issues about prompting methods and technical limitations of GAI, covering knowledge of all C-GAI-L dimensions we proposed above.

Aligning with the design of the whole self-assessment plan, student statements and comments on C-GAI-L aim to encourage activating their prior knowledge of and experience with GAI usage in academic writing, evaluate their strengths and weaknesses, and set personal learning goals for improvement. Through the resources, students were also scaffolded to conduct the hands-on GAI interaction activity in the next phase (Performance-control).

The second activity involved interaction with ChatGPT for personalised writing tasks. Initially, students spent 25 minutes writing a text (e.g., an abstract) with no assistance. Then, the activity began with a 15-minute mini-lecture to introduce C-GAI-L, review aca demic policies, discuss ethical difficulties, and explore principles for effective prompt methods. Afterwards, students were instructed to try ChatGPT to improve their texts (15 mins) and revise their prompts based on the output, considering their specific writing goals, the perceived helpfulness of ChatGPT suggestions, and the accuracy of the information. For the second part of the activity, students engaged in a group discussion (25 minutes) about their interaction experiences, discussing the effectiveness of their prompts and their ethical implications. Students were asked to record their observations and reflections in a discussion forum.

In the third activity, students engaged in self-reflection as part of their comprehensive learning portfolio – a record documenting all learning activities they completed throughout the course and their reflections on learning outcomes. Specifically, students were required to include a critical GAI literacy section in the portfolio where they documented their interactions with ChatGPT during the third workshop and reflected on the learning process of C-GAI-L through this course. Students were instructed to include the original text (before editing) and the revised text (after using ChatGPT), and provide the full interaction history with ChatGPT, highlighting the prompts used and the responses received for text improvement. In the reflection, students evaluated the effectiveness of their prompts, considered GAI ethical issues in academic writing, and shared key insights or challenges encountered during the learning process.

# 3.2. Context and participants

The study was conducted at a technology university in Sweden. The operating course is obligatory for all PhD students enrolled at the university and runs four times per academic year. The specific course under investigation was taken by 67 students, all in their first or second year of a 5-year PhD programme. These students represent various disciplines, including chemistry, physics, mathematics, computer science, and industrial management. Most students were L2 English users from diverse nationalities such as India, Mexico, Spain, Germany, Greece, Italy, and China.

Out of the initial group, 60 students consented to participate in the study. The participation group consisted of 20 females and 40 males. In their initial self-assessment plans, most students reported experience in writing course assignments and scientific reports, but not articles for academic publication, except for 7 students who each had published at least one article. At the course’s outset, students were informed that their data would only be used for research purposes, and their participation was voluntary. Data from participating students were anonymised for analysis and publication.

# 3.3. Data collection

The data collected in this study were primarily textual, including the self-assessment, GAI interaction, and reflective texts. Selfassessment data were gathered through the self-assessment plan survey that included self-ratings and comments. Human-GAI inter action and self-reflection data were obtained from the students’ writing portfolios. The interactive data included in this study focused on the human part of the interaction only, i.e., the prompts the students used with ChatGPT. 51 full ChatGPT interaction records were collected, upon which three types of data were consolidated into a single file and organised by the order of student code numbers. This arrangement facilitated cross-case comparisons among students for each phase of learning and longitudinal comparisons of each student’s learning and cognitive process before and after the learning activities.

![](img/629fde9e92cc7ddbb9bb63128c40514915b4d14a090c264f6d4f52d0927a8c97.jpg)  
Fig. 1. The teaching phases of C-GAI-L micro-curriculum.

# 3.4. Data analysis

We employed thematic analysis to examine the data, using a multiple cycle inductive process (Saldana, ˜ 2021) as shown in Fig. 3. We began with a preliminary phase of individual open-coding of the data to identify patterns and themes emerging directly from the content without any preconceived categories. At the end of this stage, the four researchers discussed their preliminary coding and then agreed on the coding scheme for the next analytical steps. Specifically, our coding strategy considered: (1) the patterns of the doctoral students’ performances and thoughts on each stage of SRL, and (2) each student’s competence development process and outcome regarding the four aspects of C-GAI-L we provisionally conceptualised, i.e., interaction with GAI, GAI ethics in academic writing, technical value and limitations of GAI, and self-learning.

In Step 2, each of the four researchers—working in pairs on the same datasets—applied the preliminary coding scheme and generated further codes independently. After discussion and comparison of the preliminary coded data, the coding scheme was developed, and codes were grouped to form potential themes. A shared code book (see Appendix) was used for the researchers to document their codes, sub-codes and example quotes from raw data. In Step 3 the paired researchers met and worked collaboratively to review and discuss each other’s codes and themes in depth. The coders discussed their coding until they reached final agreement and documented the integrated codes in the shared code book. Finally, all the researchers met again to conduct a reliability check, where they discussed all the findings again and generated the final interpretations and major arguments. At this stage, we collaboratively engaged in the conceptualisation process to address RQ1 by integrating the themed findings from all three phases of doctoral students’ self-regulated learning. We compared these findings with the provisional C-GAI-L theoretical framework used for curriculum design, resulting in an enriched, evidence-based, four-dimensional framework of Critical GAI Literacy in academic writing, discussed in Section 5.

Coding as a “joint collaborative effort” (Saldana, ˜ 2021, p. 52) enhanced the coding reliability of the thematic analysis and enriched the data interpretation by incorporating diverse perspectives. Throughout, we shared our interpretation by keeping a shared analytic memo (Project log in Fig. 3 below) to ensure reflection and systematicity in our coding.

<html><body><table><tr><td colspan="6">G. Critical AI literacy Critical Al literacy refers to the ability to critically use available AI tools in the different stages of the research process. This involves both the ability to efectively engage with the tools, as well as the awareness of their limitations and the ethical considerations surrounding them.</td></tr><tr><td colspan="6">1. I am familiar with using AI tools in the different stages of the research process (such as reading and editing).</td></tr><tr><td>1 Never true</td><td>2 Usually not true</td><td>3 Somewhat true</td><td>Usually true</td><td>4</td><td>5 Always true</td></tr><tr><td colspan="6">2. I am actively considering the limitations, potential biases, and ethical considerations (such as data privacy and fairness) when incorporating AI tools into my research</td></tr><tr><td>1 Never true</td><td>2 Usually not true</td><td>3 Somewhat true</td><td>Usually true</td><td>4</td><td>5 Always true</td></tr><tr><td colspan="6">Comments:</td></tr><tr><td colspan="6">Resources on Canvas: Critical AI Literacy</td></tr></table></body></html>

![](img/f06c3360d65a209e72eca01ad3893dcaa14792e82eec73865211b4f99e826bfb.jpg)  
Fig. 2. Self-assessment of C-GAI-L.   
Fig. 3. Steps of data analysis.

# 4. Findings

# 4.1. Forethought: Activating prior knowledge and goal setting

Through the self-assessment survey, students activated their existing knowledge about GAI, assessed their self-efficacy about using these tools, and envisioned possible learning goals.

# 4.1.1. Experiences of GAI use in academic communication

The findings from students’ self-assessment survey suggest a diverse range of prior experiences regarding use of GAI in research and academic communication. Firstly, the student responses for Statement G1 “I am familiar with using AI tools in the different stages of the research process (such as reading and editing)” show a balanced distribution with moderate variability $( \mathbf { A V } { = } 2 . 8 8 1$ , $\scriptstyle \mathbf { M } = 3 . 0 0 0$ , $\scriptstyle { \mathrm { S D } } = 1 . 2 1 9$ ). This indicates that an equal number of students rated themselves below and above the midpoint of familiarity, and while some students felt quite familiar with AI in research, many had a very low level of familiarity. Consistently, in the student comments, a comparable number of students described prior experience of using GAI in academic communication (26) and claimed they had not used (or had no intention to use) GAI in the academic process (20).

Most students used GAI mainly for editing purposes, including grammar and spell-checking, improving language, suggesting synonyms, paraphrasing, and (re)structuring texts, as in the example comment below:

S27: I tend to use AI tools for improving on my text. Prompting something along the lines of “how can I write this better” or “are there any mistakes in my text”.

Additionally, some mentioned used GAI for brainstorming and information retrieval, coding, article summarisation, and note organisation. Only one student demonstrated familiarity and practical expertise with several GAI technologies:

S45: I use too many AI tools- for finding relevant papers (Research rabbit, litmaps), organizing notes (Obsidian), refining the structure of my writing (ChatGPT, Elicit, Consensus).

The students who admitted no or little experience with using GAI expressed different types of motivation, showing that the use of GAI may have different intrinsic value for them (Zimmerman, 2000). For example, a larger group of students (20) showed curiosity and openness towards the use of GAI, despite having little familiarity and expertise:

S11: I have very limited experience with using AI in different stages of the research process. I understand that it is a very powerful tool though, so I think it would be beneficial to start using it.

These students tended to motivate themselves to learn more about GAI through the course:

S20: I am not familiar at all with AI tools. I just experimented with ChatGPT, as everybody else, but I would love to know more about AI tools applied to research and academic writing.

By contrast, a smaller number of students showed no intention to use any GAI tool in research, mainly due to their scepticism abou the ethics of GAI in academia:

S10: Ironically, being from Applied AI, I have not really considered using AI to help write scientific articles, as in my mind, I feel it is a form of plagiarism.

S36: I have avoided using AI tools for writing and reading. The foremost reason for this is trust and the risk of “plagiarism”.   
There have been many debates regarding the use of AI tools, especially in academia, so it has been safer to just avoid it.

As shown in the above extracts, several doctoral students might hold an untested belief that using GAI in academic writing might constitute plagiarism. Overall, our participants showed limited knowledge and experience regarding the use of GAI, leading to a cautious approach.

4.1.2. Ability to evaluate AI limitations and ethics in research writing

The second self-assessment statement asked students to assess their ability to critically evaluate GAI limitations, biases, and ethics in research practices. Self-rating scores show relatively high self-efficacy with moderate variability $\scriptstyle ( \mathbf { A V } = 3 . 6 1 0$ , $\mathbf { M } { = } 4 . 0 0 0$ , $\mathrm { S D } { = } 1 . 1 7 5$ ). This indicates that most students believed that they had actively considered the technical limitations and ethical issues of GAI in their research practices. Interestingly, however, student comments suggest that this self-efficacy was not always linked to a strong knowledge foundation. Specifically, the students who claimed familiarity with GAI limitations and ethics described them in a generic manner, often mixing the two aspects. Only fourteen students explicitly discussed their ethical concerns of using GAI in academic practice, most of whom did so without mentioning the word “ethics”. Therefore, the meaning of “ethical” appears to be rather ambiguous in the students’ prior knowledge of GAI, for example:

S44: I am highly skeptical of the large language models that are available to the general public. Not only the lack of model transparency and privacy issues concern me, also the potential for the generation of very convincing outputs that are completely erroneous worries.

While GAI limitations were frequently addressed in the self-assessment comments, only five students separated it from ethical aspects and talked about specific technical constraints from personal experiences, such as hallucinations and the lack of domainspecific knowledge data, for example:

S30: I played around with ChatGPT a bit and the answers did not convince me. The tool invented literature which did not exist, gave wrong explanations, or was not able to find literature which was out. This makes me critical about using it during reading and editing because I cannot trust the information I got.

A few students also acknowledged having considered GAI limitations but admitted giving little or no thought to GAI ethics before:

S49: Limitations of AI I am well aware of, but I do not think much about any ethical considerations, only to never just copy paste generated texts.

In addition, some students showed an oversimplified view of GAI and its role in academic writing, for instance:

S42: Another problem stems from using AI tools for editing manuscripts is plagiarism. AI tools suggest information in their databases. I think that if I depend on AI tools for editing, they will create another manuscript full of suggestions based on previous papers.

The student seemed to believe that using GAI tools for editing manuscripts will automatically result in the generation of content from other authors, thus leading to unintentional plagiarism. This assumption suggests that academic writers’ responsibility to engage with suggestions from other sources was not considered part of the ethical issues connected to GAI use.

Overall, these findings indicate a rather limited prior knowledge of the ethical dimension of GAI usage in academic writing. In our micro-curriculum, the self-assessment task seemed to effectively scaffold forethought: students’ awareness about previous experiences, attitudes, and knowledge gaps about GAI.

# 4.2. Performance-control: student engagement with ChatGPT

In the Performance-control phase, students were asked to use a GAI tool to revise a short text they had just written during the workshop with personally identified goals. Data comprised all their prompts: we analysed 142 prompts, mapping in our thematic analysis types of inquiries, linguistic properties of the inquiries, and the prompt sequences.

# 4.2.1. Types of inquiries

From the analysis of students’ prompts, the most used type of inquiry was asking ChatGPT to make direct changes (104/142 prompts). The primary requests involved enhancing the text to make it “more readable” (18 prompts) and “publishable,” “academic,” and/or “professional” (23 prompts). General requests may indicate insufficient initial engagement with the tool and/or text. However, because such general requests often yielded poor results, they typically led to follow-up prompts where students provided more specific feedback on tone, for example:

S5: Don’t add any sensationalistic words please. S6: Can you write this using less bombastic language?

The struggle to fine-tune tone and voice is evident in the following interaction by S14, who fluctuated between asking ChatGPT to “tone the text up” then “down,” and finally requested:

S14: Can you provide a text with a scientific level somewhere in between your 1st revision and your 2nd revision?

Similarly, S5 asked for $\ " 1 0 \%$ fewer technical words” and noted “the second paragraph became too informal now, please change it to a middle ground.” These interactions suggest that students perceived GAI tools as capable of discerning and enhancing readability yet they sometimes lacked the precise linguistic cues to articulate their needs effectively.

The second most frequent type of inquiry was seeking feedback (30/142 prompts). Students asked broad questions such as “What was the weaknesses with my abstract?” (S10). Some sought advice on structuring text for readability:

S34: I need help in formatting an introduction to a paper. Can you analyze it for me and determine what needs to be adjusted for readability?

Similar to the abovementioned general prompts, asking broad questions reflected students’ lack of engagement with the GAI. In contrast, other instances showed more specific, even discipline-focused feedback requests, which were cautiously followed up with a prompt for ChatGPT to explain its response:

S53: Do you think that it is reasonable to say that the patients in this branch should be analyzed further? And can you explain your answer?

One of the least used categories was asking GAI to generate content, with only 5 out of 142 prompts. In these few cases, students requested ChatGPT to generate specific types of content, such as expanding the existing text to a desired word count, adding back ground information, an engaging hook, concluding remarks, and titles. Only 3 prompts provided GAI with feedback, such as “the last paragraph is redundant” (S24). Unsurprisingly, ChatGPT agreed with the student and suggested deletion.

# 4.2.2. Linguistic properties of the inquiries

The linguistic properties of the prompts students used to interact with the GAI suggest a personification of this tool (51/142 prompts), which means students addressed ChatGPT as a human-being (e.g., peer) by including greetings and politeness in their prompts, like:

S3: Hello, I have a draft for the introduction section of my upcoming paper. I need help refining it for publication.

S55: Can you please review and improve the text below in more scientific terms?

Such interactions typically led to longer prompts. For example:

S47: Hi, dear virtual assistant! Today I am taking a graduate-level course titled… Please act as a thoughtful and helpful editor and provide some feedback on the style, content, and structure of the text presented below. Please feel free to ask specific questions about any detail you need additional feedback about

Conversely, some students seemed to attribute expertise to the GAI, asking it to make autonomous decisions as evidenced in their more generic requests, such as “Revise this text as you see fit” (S7). In general, personification did not seem to impact the level of trust or engagement students exhibited towards the tool. The examples in this section illustrate a range of approaches: some students provided explicit context and sought detailed feedback, while others placed full trust in the tool, indicating a tendency to over-rely on GAI’s assumed expertise.

# 4.2.3. Prompts sequence

The sequence of prompts was also of interest. The 142 analysed prompts were distributed across different stages of interaction with GAI: 51 for Prompt 1, 39 for Prompt 2, 29 for Prompt 3, and 23 for Prompt $^ { 4 + }$ . The first prompt often focused on general aspects like readability (10 prompts) and publishability (7 prompts). Another common request targeted the coherence and clarity of texts (8 prompts). Less frequent were prompts asking for feedback (3 prompts), while non-specific requests such as “edit” and “revise this text” were also notable (9 prompts).

The second prompt showed a marked increase in specific requests, yet students often repeated or slightly modified their initial prompts. The most prevalent category was “make it publishable.” For example, S8 prompting sequence was:

Prompt 1: improve the quality of the language in this text.

Prompt 2: improve the quality of the language of this text making it suitable to be in the introduction of a scientific journal.

In later prompts, there was a noticeable shift towards seeking feedback on coherence and clarity (5 in Prompt 3), readability (3 prompts), and specific disciplinary information (3 in Prompt 3 and 2 in Prompt $^ { 4 + ) }$ . Common inquiries included some form of feedback to GAI, such as:

S27: Change exploring to reading. Also, please make the second paragraph a little bit less formal.

Thus, through continued interaction with the GAI, students became more specific in their requests, even though we can still see a lack of precise queries that might make the request more effective. Overall, the data suggest students lack prior knowledge in prompting methods.

# 4.3. Self-reflection

Three major themes emerged from student self-reflections: (1) increased critical understanding of prompting methods, (2) exploring GAI and gaining critical insights into its benefits and limitations, and (3) critical evaluation of GAI ethics, its sociolinguistic impacts, and human agency in academic writing.

# 4.3.1. Critical understanding of prompting methods

The majority of students (46 out of 60) reported having an increased understanding of prompting methods/strategies. As exem plified by the following student reflection, many learned that prompt specificity is vital, including providing detailed and adequate contextual information:

S40: With this workshop, it became clear that the use of effective and specific prompts is a key aspect and generic instructions will result in repetitive texts with no real improvement.

After testing various prompts and evaluating their outcomes, some students found it was more effective to prompt GAI to reflect on or provide feedback on their own texts rather than generating new content, and they underscored the need for authorial evaluation of the generated text:

S9: I learned that the best strategy would be to use AI tools for getting feedback for our own texts and to rephrase them for better clarity. Using a text where the content itself is generated by AI doesn’t seem appropriate to use. It is also important to evaluate the generated texts before we use it as it cannot be $1 0 0 ~ \%$ accurate.

Some students emphasised the need for sequencing prompts in a systematic way, such as following a step-by-step technique:

S37: It can, however, not do so unsupervised or with much “editing authority”. ChatGPT seems quite eager to rephrase, often to the detriment to the text. Even if the result would be factually accurate, it is unlikely that the new text is written in a way that matches the rest of your text. Breaking it up into smaller parts, limiting the amount of changes ChatGPT is allowed to make, and only keeping what you think works better is a good way to go about it.

This strategy allows students to hold better control over the changes made by GAI, ensuring that the final text conform to the style and coherence of the original text. One student called this method “iterative refinement”:

S32: instead of issuing one-time demands, sequential, iterative conversation seems more effective.

Overall, student reflections about prompting strategies indicate a realisation that GAI is never a quick solution for producing better or well-crafted academic texts. Below is a representative comment:

S3: … The quality of responses is entirely up to how well thought-out a prompt is. Furthermore, ChatGPT is not typically capable of asking for clarifications to improve its responses, meaning that the initial prompt needs to be of good quality. As a result, one might spend way too much time crafting suitable prompts, when it would take the same amount of time to simply do the work yourself.

As this student suggests, quality monitoring of both prompts and output in an iterative process seems crucial for obtaining good results. Therefore, effective prompting can be time-consuming and may not result in considerable time savings.

4.3.2. Exploring GAI and gaining critical insights into its benefits and limitations

The second theme identified addresses student self-reactions and affective responses to their own learning experience with GAI. Over half of the students, particularly those with limited prior exposure to GAI, expressed a feeling of self-satisfaction in their re flections. They valued the micro-curriculum as it provided them with a learning opportunity to experiment and obtain first-hand insight into GAI’s usefulness (or not):

S17: I have never used AI for writing assistance before this course, and I am pleasantly surprised by how helpful it can be in developing my ideas.

For these students, the experience seemed to help demystifying GAI. For instance, S10, who initially expressed concerns about plagiarism (Section 4.1.1), suggested that the course corrected this assumption. The SRL ground of the micro-curriculum motivated hesitant students to explore GAI, helping them develop a deeper understanding of GAI ethics in academic writing and eliminating the unwarranted fear of engaging in plagiarism:

S36: There seems to be a learning curve regarding how to use these tools and this was a good and safe way to start that process … The biggest thing is that this course made me finally try these tools out.

As a result, many students recognised both the benefits and technical limitations of GAI in their self-reflections:

S20: ChatGPT excels in rephrasing, maintaining the same verbal tense, condensing text, and enhancing its flow. However, it faces some issues with instructions, often interpreting them too literally. For instance, when asked to rephrase, it operates on a phrase-by-phrase, word-by-word basis, occasionally resulting in subpar outcomes.

Specifically, students found GAI to be useful in various stages of academic writing: (1) during the writing process, for grammar correction and enhancing their vocabulary, syntax, and style; (2) in the brainstorming process, for clarifying basic concepts and understanding terminology; and (3) in the editing process, for shortening texts, creating summaries, and improving conciseness, coherence, and clarity.

Conversely, several technical constraints were also lifted. Firstly, ChatGPT was limited in correctly understanding the author’s meaning, as noted by S20 and several others. Secondly, GAI’s word choices often resulted in an incorrect voice that was either too formal or too casual for the target disciplinary writing style. Some students noticed distinctive language patterns that they described as “the impression of artificial” and “typical of ChatGPT” (e.g., S29, S35, S56), and indeed 20 student prompts addressed this limitation, asking GAI to change its tone/register.

Moreover, many students (18 responses) recognised GAI’s potential for use in general writing but underscored its limitations with technical research genres. They pointed out the mismatch between the language generated by GAI and disciplinary discourses and its inaccuracies in terms of content, concluding that GAI could not meet the specialised requirements of advanced research writers:

S13: I mainly use AI tools to recap some basic concepts or in order to understand the meaning of some terminology. I belong to the Quantum Computing research field which is a very new field. Therefore sometimes it does not give full information or wrong information. According to me, we can use AI tools during writing as minor tools but not as major. Because the answers provided by these tools are not exactly correct according to our needs.

4.3.3. GAI ethics, human agency in academic writing, and GAI’s sociolinguistic impact

Students’ self-reflections both elicited and illustrated a developed understanding and a more nuanced perspective on the ethical issues tied to GAI use in academic writing. In particular, students developed a more precise understanding of which actions may constitute plagiarism and how to avoid ethical pitfalls using GAI, for example:

S34: From the ethical perspective, the important thing is not to ask ChatGPT their thoughts for brainstorming and directly use it in the text, rather feed them thoughts or iterate more times when new ideas are given by AI. For example, during my prompt b, ChatGPT suggests me two scenarios from its own database, and I have to be really careful about this part and make it tentative in my content, since it is not verified to be right or belong to my cognitive activity. Besides, it is very important to make sure the content we feed in AI is generated from our own, which is not borrowed from someone else’ work and just ask AI for rewriting and overlay the work on others’ original work.

The students examined the ethical considerations of GAI in both text uploading and generating processes, highlighting the importance of verification, source validation, and iterative refinement of GAI-generated texts. In terms of GAI ethics, our data emphasise the role of human (author) agency, describing writing as a crucial part of knowledge construction and taking “full ownership of the text” (S8). Students stressed the need to maintain the originality of their thoughts and avoid GAI interference:

S14: For most publications and academic text that I produce I would like to be in full control of the text and would rather use it only as a spell check not to interfere with the language and the content of the text.

Some students went even further to highlight the necessity of preserving personal voice in their writing (e.g., S51: “should read like my own text”). For these students, authorial ownership was achieved by maintaining human oversight over GAI outputs, making final decisions themselves (S8), and verifying and modifying the responses given by GAI (S16, S39).

Finally, a few students (8 out of 60) extended the discussion of ethics to the sociolinguistic impact of GAI on academic writing, L2 riters, and scholarship at large. For example, S19 commented on writing excellence in the AI era:

S19: The course has brought some reflections about the use of AI in academic writing. We have debated a number of aspects so that we can write better, but can AI write better than us? What does “better” mean in this context?

By questioning the meaning of “better writing” and asking whether GAI can surpass human capabilities, this student engaged in a critical inquiry about the influence of GAI on academic language norms.

Moreover, students reflected on the potentially contradictory effects of GAI use for L2 writers. On the positive side, when used properly, GAI could be a valuable tool for L2 writers to overcome language barriers, notice mistakes, and overall improve academic communication performance. For instance:

S47: Reflecting on the ethical implications, the tool’s potential as an equalizing force in overcoming language barriers stood out.   
This aligns with the broader question of whether our objective is to excel in writing or to effectively communicate ideas.

S56: When it comes to language, I would argue that AI is very helpful for researchers, especially the once whose mother tongue is not English.

However, adverse effects from GAI on the development of an academic writer identity were also recognised:

S38: While taking this writing course, a conversation happened between me and one of my colleagues might be interesting here (The context: we need to read each other’s research proposal to ask questions as opponents for another course):

The colleague: Hey! you used ChatGPT, right?

Me (felt a bit shocked to be pointed out directly, since I already replaced some absurd words): how do you know?

The colleague: there are some words indicating that obviously, like ‘in the realm of’, ‘underscore’, ‘frontrunner’…

Me: Okay, I did use ChatGPT to help modify the language, but in my eyes, they are just some common words in scientific articles, that’s why I do not even think about replacing them.

As shown in the conversation, the recognition of so-called absurd words can also be biased, hence the efforts put into replacing them might just be in vain. In addition, why do I feel shocked to be found out that I used ChatGPT?

While S38 had exercised human oversight on the GAI-generated text, its usage was still detected by a colleague, causing the student surprise (and maybe discomfort). This student seemed to realise that a competent academic writer should be able to detect GAI’s inappropriate wording suggestions and adjust them to fit the disciplinary discourse. The feeling of discomfort might stem from the fear of being perceived as an incompetent academic writer by her peer. This student’s experience reflects the risk of GAI “dehumanising” an L2 user’s academic writing (Payne et al., 2024), assuming GAI usage in the evaluation of their texts.

# 5. Discussion and pedagogical implications

This study investigated teaching C-GAI-L in academic writing from a doctoral L2 writers’ perspective. We aimed to develop the conceptualisation of C-GAI-L and introduce a micro-curriculum to support PhD students in self-regulating their critical engagement with GAI in academic writing. To address RQ1, we first drew on existing literature on digital literacy and (critical) AI literacy to conceptualise C-GAI-L as a four-dimensional construct encompassing critical competencies for (1) interacting with GAI, (2) under standing GAI ethics in academic writing, (3) evaluating GAI values and limitations, and (4) engaging in self-learning. Upon implementing the micro-curriculum and examining interactive and reflective data from the 60 PhD participants, we developed a comprehensive theoretical framework of C-GAI-L as a complex of knowledge and skills required by the doctoral students (L2 academic iters) in each of the four aspects mentioned above. The framework is presented below (Table 1)

We would like to highlight that the concept of “critical”—in terms of critical thinking, critical pedagogy, and critique (Bali, 2023)— is integrated into all four aspects of C-GAI-L and is transmitted to students through an SRL approach. Our teaching aimed to provide a supportive learning environment to make space for critical exploration of multiple dimensions of knowledge and skills of C-GAI-L and metacognitive awareness of individual learning. Instead of lecturing or policing students about what they should and should not do with GAI in their academic writing practices, we encouraged students to set personal learning goals based on self-assessment, explore open resources, engage with their own texts, and reflect on their own learning.

Moving to RQ2, student self-reflections indicate the overall efficacy of this micro-curriculum and our teaching approach. Firstly, our analysis shows that the students demonstrated limited initial capacity for critical thinking about GAI, meaning they held shallow opinions and scepticism based on limited knowledge, particularly regarding its ethical aspects and prompting methods. Through a few self-directed learning tasks, the micro-curriculum successfully recalibrated some students’ understanding of GAI ethics in academic discourses (e.g., S10, S36) and motivated them to take on a self-educating disposition to obtain first-hand experience and insight into GAI usage in L2 academic writing. Our findings confirm the claim made in previous studies (e.g., Wang et al., 2023) that creating a supportive environment is essential to assisting student learning about GAI. With an open and encouraging learning environment, the students were able to develop critical thinking by freely engaging with GAI in their own writing, exploring how GAI works and its applicability, questioning the quality of GAI outputs, and discussing its ethical impacts with peers.

Secondly, our micro-curriculum enhanced critical pedagogy by engaging the students in self- and peer-reflections on GAI ethics. Student reflections show a noticeable improvement in comprehension of GAI policies and ethical conduct in academic writing and research contexts. The students demonstrated their ability to analyse personal GAI experiences and contribute to the ongoing debates surrounding GAI usage in research and L2 writing by clearly specifying and reasoning with what they considered to be ethical use of GAI. In particular, despite the modest number (8 students), a group of our PhD students displayed a critical reflection on the sociolinguistic impacts of GAI on academic language norms and L2 writer identity. Such student reflections further the current discourse on the double-sided effects of GAI on L2 writers’ voice (e.g., Kubota, 2023; Sasaki et al., 2024) and raise concerns about its potential dehumanising effect (Payne et al., 2024), which might confuse L2 learners acquiring the necessary abilities to become competent academic writers. It is imperative for L2 writing education to address these concerns to ensure the legitimacy and equality of L2 writers’ English language.

Finally, as per our intentions, students demonstrated the critical capacity to reflect on if, when and how to use GAI, which helped them develop author agency and sense of text ownership. Doctoral writing is always disciplinarily and contextually embedded, as we emphasised throughout our course. Our findings suggest that this awareness came into play in our students’ critical evaluation of GAI suggestions, which were often rejected on the basis of not being in alignment with disciplinary discourses and styles (see Section 4.3.2). In this sense, our findings also demonstrate how the SRL process “de-enchanted” GAI (Campolo & Crawford, 2020) for PhD students. Through hands-on GAI interaction and reflection, they realised GAI was not a quick fix for creating high-quality academic texts. They critically assessed the advantages and drawbacks of GAI, devised effective prompting methods to cope with these limitations, and recognised the importance of human oversight on GAI outputs and retaining ownership of their texts. Arguably, such critical engagement with GAI was an empowering experience for these junior academic writers because it enabled “noticing” (Schmidt, 1990), a key motor of language learning: the students gained awareness of aspects of language such as their own voice, vocabulary, style, and the limitations of GAI in providing support in these areas. This indicates that interacting with GAI could help L2 learners gain con sciousness of L2 and/or academic writing and develop ownership of their disciplinary voice, which they found challenging in some peer review contexts (e.g., Prior, 1998).

The study has several pedagogical implications for L2 academic writing. First, our C-GAI-L conceptual framework can act as a roadmap for teachers to design their curriculum and tasks that promote student self-regulated learning for effective and responsible use of GAI in their writing. Specifically, for L2 writers, it is imperative to de-enchant GAI as either a magical solution or a threat to ac ademic writing and writer identity. This requires creating an open and supportive learning environment with concrete tasks and practice that facilitate personalised GAI experience and reflection on what it can offer for writing and language learning. From our experiences as teachers, this micro-curriculum certainly has space for improvement. For example, our students (e.g., S51) reflected that prior knowledge of GAI was unevenly distributed among PhD students from different disciplines and that more scaffolding on the knowledge aspect of C-GAI-L (e.g., how GAI is developed and works) could make some students feel more prepared for the self-directed learning tasks to interact with GAI in a more informed manner.

Table 1 A four-dimensional framework of Critical GAI Literacy in academic writing.   

<html><body><table><tr><td>Dimensions of C-GAI-L</td><td>Description</td><td></td></tr><tr><td>Interaction with GAI</td><td>Knowledge</td><td>: different GAI tools and their appropriate use contexts : interaction strategies with GAI that emphasise the writer agency</td></tr><tr><td></td><td>Skills</td><td>: critically evaluate GAI results and integrate own knowledge to create solutions : develop effective prompting methods (e.g., iteration refinement)</td></tr><tr><td>GAI ethics in academic writing</td><td>Knowledge</td><td>: major ethical issues of GAI (e.g., automation bias, data privacy, consequences on human and environment) : policies and perspectives about GAI usage in academic writing (e.g., university regulations, publication policies, research ethics, GAI and ownership of text)</td></tr><tr><td></td><td>Skills</td><td>: Awareness of the sociolinguistic impact of GAI tools on academic language and the writer : problematise GAI ethical issues and make informed decisions about their writing : critically reflect on broader sociotechnical realties and take social responsibilities</td></tr><tr><td>Technical value and limitations of GAI</td><td>Knowledge</td><td>. how GAI is developed, how it works, its applicability potential and limitations</td></tr><tr><td></td><td>Skills</td><td>: critically evaluate GAI functions and usefulness in research processes and writing : problem-solve for situations due to GAI limitations</td></tr><tr><td> Self-learning</td><td>Knowledge</td><td></td></tr><tr><td></td><td></td><td>: Understanding of their development in critical GAI literacy.</td></tr><tr><td></td><td></td><td>: metacognitive awareness of own communicative goals and disciplinary communities and expectations</td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td>Skills</td><td></td></tr><tr><td></td><td></td><td></td></tr></table></body></html>

Another aspect to emphasise in tasks involving potential use of GAI, and not just for doctoral students, is to further foreground the role of writing as a means of thinking (Halliday, 1989): a process by which we conceptualise, articulate, reflect upon, and make meanings. In this process, interaction with GAI might lead to a loss of learning, but it might also provide opportunities to for metacognitive engagement with the text, which is a mark of authorship and a key aim of teaching writing: “the objective is not just to have our students produce effective writing … We also want our students to demonstrate consciousness of process that will enable them to reproduce success. Metacognition is not cognition” (Tinberg, 2016, p. 75). Our curriculum implicitly promoted this dimension of writing, as well as the hazards—and possibilities—of using GAI. Nevertheless, further discussions on this matter may be needed in other classroom settings.

# 6. Conclusion

The recent debate around the sociocultural implications of GAI tools for L2 writers has lifted both concerns (e.g., Kubota, 2023) and possibilities (e.g., Sasaki et al., 2024). L2 writing teachers are now challenged to translate these debates into classroom practices and meet the learners where they find them (Pecorari, 2023). Our study showed that L2 writers with diverse backgrounds could be scaffolded meaningfully when critical literacy and self-learning were implemented and provided an example of a micro-curriculum of such nature. Through this micro-curriculum, students recalibrated their interpretations of GAI ethics in academic discourse and developed an increased understanding of prompting methods, critical knowledge of GAI benefits and limitations, and awareness of the meaning of text ownership and the broad impacts of GAI on academia and society. In line with critical engagement that was advocated by scholarship (e.g., Anderson, 2023), this study contributes an evidence-based conceptualisation of C-GAI-L that can guide L2 aca demic writing pedagogical practice in higher education and further research.

# CRediT authorship contribution statement

Raffaella Negretti: Writing – review & editing, Writing – original draft, Validation, Resources, Project administration, Investi gation, Funding acquisition, Formal analysis, Data curation. Amy Wanyu Ou: Writing – review & editing, Writing – original draft, Visualization, Validation, Project administration, Methodology, Investigation, Funding acquisition, Formal analysis, Data curation, Conceptualization. Sindija Franzetti: Writing – review & editing, Writing – original draft, Validation, Investigation, Formal analysis, Data curation. Baraa Khuder: Writing – review & editing, Writing – original draft, Validation, Methodology, Investigation, Formal analysis, Data curation.

# Conflict of Interest

We have no conflicts of interest to disclose. We thank Chalmers Foundations’ Digitalisation Initiative for funding this research (C 2024–0448).

Appendix. : Shared code book   

<html><body><table><tr><td>Researchers</td><td>Theme</td><td>Sub-theme/code</td><td>Example from raw data</td></tr><tr><td colspan="4">Forethought phase</td></tr><tr><td rowspan="8">R1+R3</td><td>Prior-experience: ways of using Gen-AI in academic</td><td>a. Student score S.G1 (AV, M, SD) b. In what ways: improving language/editing,</td><td>S25: &quot;I am using AI sometimes just to correct the</td></tr><tr><td>communication</td><td>information seeking, paraphrasing, coding, summarizing articles, structuring texts, others</td><td>awkward phrasing and sometimes make a part of the text smaller and sounded in better way.</td></tr><tr><td>Prior-experience: not using AI in academic writing</td><td>a. Unfamiliar and little use - but they have intention to use it; needs scaffolding</td><td>S11: &quot;I have very limited experience with using AI in different stages of the research process. I understand that it is a very powerful tool though, so I think it</td></tr><tr><td></td><td>b. No intention to use it, because they believe it is</td><td>would be beneficial to start using it.&quot; S10: Ironically, being from Applied AI, I have not really</td></tr><tr><td></td><td>plagiarism a. Student score S.G2 (AV, M, SD)</td><td>considered using AI to help write scientific articles, as in my mind, I feel it is a form of plagiarism.</td></tr><tr><td>Understanding GAI limitations and ethics</td><td>b. Claimed familiarity - talk about limitation and</td><td>S3: My research revolves around the lack of</td></tr><tr><td></td><td>ethics together and in general, but unclear discussion on how exactly</td><td>interpretability of LLMs so I am familiar with most limitations, biases and ethical concerns of</td></tr></table></body></html>

(continued on next page)

(continued on next page)

<html><body><table><tr><td></td><td>c. Clearly state that never/limited thought about GAI</td><td>incorporating AI tools in application. research.</td></tr><tr><td></td><td>ethics</td><td>S6: However, I haven&#x27;t given any act ethical considerations.</td></tr><tr><td>formance-control phase Types of inquiries</td><td>a. Direct changes:</td><td>S2: Hi! I need to make this text more</td></tr><tr><td>+ R3</td><td>(1) coherence and cohesion (2) language issues (grammar, vocabulary)</td><td>clear.</td></tr><tr><td></td><td></td><td>S4: Improve the quality of the langu.</td></tr><tr><td></td><td>(3) publishability</td><td>S10: Can you rewrite the above text</td></tr><tr><td></td><td>(4) readability</td><td>suitable to a scientific paper&#x27;s metho</td></tr><tr><td></td><td>(5) revise content</td><td> S41: Now I want you to improve on</td></tr><tr><td></td><td>(6) structure and organisation</td><td> paragraphs. I want it to be clearer th</td></tr><tr><td></td><td>(7) tone</td><td>response of different nanoparticles </td></tr><tr><td></td><td>(8) unspecific</td><td>compositions</td></tr><tr><td></td><td></td><td>S5: Can you improve the structure oi</td></tr><tr><td></td><td></td><td> S12: please make the second paragra</td></tr><tr><td></td><td></td><td>formal S22: Revise this text as you see fit.</td></tr><tr><td></td><td>b. Asking for feedback:</td><td> S13: How can I improve the coheren</td></tr><tr><td></td><td>(1) coherence (2) language issues (grammar, vocabulary)</td><td>the text? S16: Please act as a thoughtful and </td></tr><tr><td></td><td>(3) readability, sophistication</td><td>provide some feedback on the style c</td></tr><tr><td></td><td>(4) disciplinary-specific content (5) tone</td><td>presented below.</td></tr><tr><td></td><td>(6) unspecific</td><td>S17: do you think that it is reasonab patients in this branch should be anal</td></tr><tr><td></td><td></td><td>can you explain your answer?</td></tr><tr><td></td><td></td><td>S53: What is the tone of this text?</td></tr><tr><td></td><td>c. Generating content:</td><td>S7: Give me feed back about the arti S39: Expand the background inform:</td></tr><tr><td></td><td>(1) asking for expansion (non-specific)</td><td> following paragraph:</td></tr><tr><td></td><td>(2) asking for expansion with specific disciplinary</td><td> s30: find some mathematical formul</td></tr><tr><td></td><td>information</td><td>above paragraph</td></tr><tr><td>Linguistic properties</td><td>d. Giving ChatGPT feedback a. Personification (peer, expert)</td><td>S4: Now it&#x27;s too short in the method</td></tr><tr><td>Sequence of inquiries</td><td>b. Non-personification</td><td>S6: This looks great. Thank you for y S55: Write an introduction to the tex</td></tr><tr><td></td><td>a. Prompt 1: general aspects</td><td></td></tr><tr><td></td><td>b. Prompt 2: specific requests (modify Prompt 1) c. Prompt 3: seeking feedback</td><td></td></tr><tr><td>f-reflection phase</td><td>d. Prompt 4+: disciplinary info</td><td></td></tr><tr><td>+ R4 Increased understanding of prompting methods</td><td>a. Prompt specificity is important, especially</td><td> S40: With this workshop, it became cl</td></tr><tr><td></td><td>providing contextual information</td><td>effective and specific prompts is a ke generic instructions will result in rep</td></tr><tr><td></td><td>b. Prompt to feedback/reflect rather than generating</td><td>no real improvement. S9: I learned that the best strategy w</td></tr><tr><td></td><td>new content</td><td>tools for getting feedback for our ow rephrase them for better clarity.</td></tr><tr><td></td><td>c. Sequence the prompts, step-by-step</td><td>S37: .. Breaking it up into smaller p amount of changes ChatGPT is allow</td></tr><tr><td></td><td></td><td>only keeping what you think works I way to go about it.</td></tr><tr><td></td><td>d. Quality monitoring of prompts is important but it&#x27;s a process</td><td>S3.: [...] I believe prompting is a huge comes to generative AI. [.] the initi</td></tr><tr><td></td><td></td><td>be of good quality. As a result, one n too much time crafting suitable pron</td></tr><tr><td>Explored GAI and reflect on</td><td></td><td>would take the same amount of time work yourself.</td></tr><tr><td>both benefits and limitations</td><td>a. Self-satisfaction of the opportunity to try</td><td>S29: During the course, I had the opj</td></tr><tr><td></td><td></td><td>write a text with AI for the first time</td></tr><tr><td></td><td></td><td>process, I got familiar with the inter!</td></tr><tr><td></td><td></td><td>that it operates...</td></tr><tr><td></td><td>b. A critical and dialectical view on the function of</td><td> S20: ChatGPT excels in rephrasing, r</td></tr><tr><td></td><td>GAI: talking about both benefits and limitations</td><td>same verbal tense, condensing text, :</td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td>flow. However, it faces some issues t</td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td>often interpreting them too literally</td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td>S15: Generally, I think it can be a ve</td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td>help with grammatical mistakes</td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td>c. Specific benefits at different writing phases:</td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td>S8: I mainly use AI tools to recap sor</td></tr><tr><td>(1) writing: grammar correction with the right</td><td></td></table></body></html>

(continued )   

<html><body><table><tr><td> Researchers</td><td>Theme</td><td>Sub-theme/code</td><td>Example from raw data</td></tr><tr><td rowspan="3">Increased awareness of the</td><td rowspan="3"></td><td>(2) brainstorming: understanding concepts (3) editing: summarizing, making a text more concise, improve coherence or clarity d. Specific technical limitations: (1) misinterpreting author&#x27;s message (2) voice not correct</td><td>S5: Use ChatGPT to review text and to make pieces of text clearer. S27: It&#x27;s hard to make a concise text about what I want to convey, and ChatGPT probably misinterpreted it and</td></tr><tr><td>(3) style not aligned with disciplinary discourse (4) typical GAI language patterns</td><td>continued with writing some things that don&#x27;t make much sense. S42: AI tools show various drawbacks in their editing process [...] by using unnecessary words, misplaced tone, and digressive topics. S8: I belong to the research field which is a very new field. Therefore, sometimes it does not give full</td></tr><tr><td>a. Detailed GAI ethics: plagiarism, crediting of sources b. Emphasise human agency and oversight academic writing, the ownership of writing and knowledge construction c. Consider sociolinguistic impacts: S19: The course has brought some reflections about the</td><td>information or wrong information S5: Do not copy paste everything but it is alright to rewrite some parts to use. S8: Do it in such a way that you still have full- ownership of the text, making the final decision on each specific sentence.</td></tr></table></body></html>

# Data availability

The authors do not have permission to share data.

# References

Anderson, S. S. (2023). Places to stand”: Multiple metaphors for framing ChatGPT’s corpus. Computers and Composition, 68, Article 102778. https://doi.org/10.1016/ J.COMPCOM.2023.102778   
Bali, M. (2023, April 1). What I mean when I say Critical AI Literacy. 〈https://blog.mahabali.me/educational-technology-2/what-i-mean-when-i-say-critical-ailiteracy/〉.   
Barton, D., & Potts, D. (2013). Language learning online as a social practice. TESOL Quarterly, 47(4), 815–820. https://doi.org/10.1002/tesq   
Campolo, A., & Crawford, K. (2020). Enchanted determinism: Power without responsibility in artificial intelligence. Engaging Science, Technology, and Society, 6, 1–19. https://doi.org/10.17351/ests2020.277   
Casal, J. E., & Kessler, M. (2023). Can linguists distinguish between ChatGPT/AI and human writing?: A study of research ethics and academic publishing. Research Methods in Applied Linguistics, 2(3), Article 100068. https://doi.org/10.1016/J.RMAL.2023.100068   
Cetindamar, D., Kitto, K., Wu, M., Zhang, Y., Abedin, B., & Knight, S. (2024). Explicating AI literacy of employees at digital workplaces. IEEE Transactions on Engineering Management, 71, 810–823. https://doi.org/10.1109/TEM.2021.3138503   
English Language Support Office. (2024). ELSO position statement on generative AI, language learning, and writing. Cornell University.   
Faber, H. C. L., Gasparini, A. A., & Grote, M. (2022). Artificial Intelligence-based tools in the context of Open Science: PhD on Track as a resource. Septentrio Conference Series, (1)https://doi.org/10.7557/5.6636   
Gilster, P. (1997). Digital literacy. Wiley Computer Pub.   
Hafner, C. A., Chik, A., & Jones, R. H. (2013). Engaging with digital literacies in TESOL. TESOL Quarterly, 47(4), 812–815. 〈https://www.jstor.org/stable/43267930〉.   
Halliday, M.A.K. (1989). Spoken and written language. Oxford University Press.   
Kandlhofer, M., Steinbauer, G., Hirschmugl-Gaisch, S., & Huber, P. (2016). Artificial intelligence and computer science in education: From kindergarten to university. IEEE Frontiers in Education Conference (FIE), 2016, 1–9. https://doi.org/10.1109/FIE.2016.7757570   
Kubota, R. (2023). Another contradiction in AI-assisted second language writing. Journal of Second Language Writing, 62, Article 101069. https://doi.org/10.1016/J. JSLW.2023.101069   
Laupichler, M. C., Aster, A., Schirch, J., & Raupach, T. (2022). Artificial intelligence literacy in higher and adult education: A scoping literature review. Computers and Education: Artificial Intelligence, 3, Article 100101. https://doi.org/10.1016/j.caeai.2022.100101   
Long, D., & Magerko, B. (2020). What is AI Literacy? Competencies and Design Considerations. Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, 1–16. https://doi.org/10.1145/3313831.3376727   
Ng, W. (2012). Can we teach digital natives digital literacy? Computers Education, 59(3), 1065–1078. https://doi.org/10.1016/j.compedu.2012.04.016   
Nguyen, A., Hong, Y., Dang, B., & Huang, X. (2024). Human-AI collaboration patterns in AI-assisted academic writing. Studies in Higher Education, 1–18. https://doi. org/10.1080/03075079.2024.2323593   
Ou, A. W., Stohr, ¨ C., & Malmstrom, ¨ H. (2024). Academic communication with AI-powered language tools in higher education: From a post-humanist perspective. System, 121, Article 103225. https://doi.org/10.1016/j.system.2024.103225   
Panadero, E. (2017). A review of self-regulated learning: Six models and four directions for research. Frontiers in Psychology, 8, 1–28. https://doi.org/10.3389/ fpsyg.2017.00422   
Payne, A.L., Austin, T., & Clemons, A.M. (2024). Beyond the front yard: The dehumanizing message of accent-altering technology. Applied Linguistics, amae002. https://doi.org/10.1093/applin/amae002.   
Pecorari, D. (2023). Generative AI: Same but different? Journal of Second Language Writing, 62, Article 101067. https://doi.org/10.1016/J.JSLW.2023.101067   
Pividori, M., & Greene, C.S. (2023). A publishing infrastructure for AI-assisted academic authoring. BioRxiv, 2023-01. [Preprint]. 〈https://doi.org/10.1101/2023.01. 21.525030〉.   
Prior, P. (1998). Writing/disciplinarity: a sociohistoric account of literate activity in the academy. L. Erlbaum Associates.   
Saldana, ˜ J. (2021). The coding manual for qualitative researchers. Sage.   
Sasaki, M., Mizumoto, A., & Matsuda, P. K. (2024). Machine translation as a form of feedback on L2 writing. International Review of Applied Linguistics in Language Teaching. https://doi.org/10.1515/iral-2023-0223   
Schmidt, R. W. (1990). The role of consciousness in second language learning. Applied Linguistics, 11(2), 129–158. https://doi.org/10.1093/applin/11.2.129   
Sperling, K., Stenberg, C. J., McGrath, C., Åkerfeldt, A., Heintz, F., & Stenliden, L. (2024). In search of artificial intelligence (AI) literacy in teacher education: A scoping review. Computers and Education Open, 6, Article 100169. https://doi.org/10.1016/j.caeo.2024.100169   
Strauß, S. (2021). Don’t let me be misunderstood": Critical AI literacy for the constructive use of AI technology. Journal for Technology Assessment in Theory and Practice, 30(3), 44–49. https://doi.org/10.14512/tatup.30.3.44   
Tinberg, H. (2016). Metacognition is not cognition. In L. Adler-Kassner, & E. Wardle (Eds.), Naming what we know: Threshold concepts of writing studies (pp. 75–76). Utah State University Press. https://doi.org/10.7330/9780874219906.   
Titko, J., Steinbergs, K., Achieng, M., & Uzule, K. (2023). Artificial intelligence for education and research: Pilot study on perception of academic staff. Virtual Economics, 6(3), 7–19. https://doi.org/10.34021/ve.2023.06.03(1)   
van Laar, E., van Deursen, A. J., van Dijk, J. A., & De Haan, J. (2017). The relation between 21st-century skills and digital skills: A systematic literature review. Computers in Human Behavior, 72, 577–588. https://doi.org/10.1016/j.chb.2017.03.010   
Vuorikari, R., Kluzer, S., & Punie, Y. (2022). DigComp 2.2: The Digital Competence Framework for Citizens-With new examples of knowledge, skills and attitudes (No. JRC128415). Joint Research Centre (Seville site). https://dx.doi.org/10.2760/115376.   
Wang, F., King, R. B., Chai, C. S., & Zhou, Y. (2023). University students’ intentions to learn artificial intelligence: The roles of supportive environments and expectancy–value beliefs. International Journal of Educational Technology in Higher Education, 20(1), 51. https://doi.org/10.1186/s41239-023-00417-2   
Warschauer, M., Tseng, W., Yim, S., Webster, T., Jacob, S., Du, Q., & Tate, T. (2023). The affordances and contradictions of AI-generated text for writers of English as a second or foreign language. Journal of Second Language Writing, 62, Article 101071. https://doi.org/10.1016/J.JSLW.2023.101071   
Winne, P. H. (2015). Self-regulated learning. In J. D. Wright (Ed.), International Encyclopedia of the Social & Behavioral Sciences (pp. 535–540). Amsterdam: Elsevier. https://doi.org/10.1016/B978-0-08-097086-8.25091-5.   
Xu, W., & Tan, X. (2024). Beyond words: L2 writing teachers’ visual conceptualizations of ChatGPT in teaching and learning. Journal of Second Language Writing, 64, Article 101110. https://doi.org/10.1016/J.JSLW.2024.101110   
Yi, Y. (2021). Establishing the concept of AI literacy. Jahr–European Journal of Bioethics, 12(2), 353–368. https://doi.org/10.21860/j.12.2.8   
Zimmerman, B. J. (2000). Attaining self-regulation: A social cognitive perspective. In M. Boekaerts, P. R. Pintrich, & M. Zeidner (Eds.), Handbook of self-regulation (pp. 13–39). Burlington: Academic Press. https://doi.org/10.1016/B978-012109890-2/50031-7.   
Zimmerman, B. J., & Schunk, D. H. (2011). Self-regulated learning and performance. In B. J. Zimmerman, & D. H. Schunk (Eds.), Handbook of self-regulation of learning and performance (pp. 1–12). New York: Routledge.

Baraa Khuder is Senior Lecturer at Chalmers University of Technology, Department of Communication and Learning in Science. Her major interests are in collaborative writing and writing for publication.

Sindija Franzetti is Senior Lecturer at language and communication at Chalmers University of Technology, Department of Communication and Learning in Science. She teaches academic writing in English and Swedish at the undergraduate level, emphasizing writing as a process and focusing on reading and writing for specific purposes. Her background is in English, specifically in literary studies. Currently, she is conducting research at the intersection of literary studies and writing pedagogy. She has a particular interest in collaborative writing and the use of AI in writing instruction.

Raffaella Negretti is Professor in educational psychology and applied linguistics at Chalmers University of Technology, Department of Communication and Learning in Science (Sweden). Her research is interdisciplinary, spanning (L2) academic writing, writing for research purposes, genre pedagogy, and self-regulation/metacognition. Her work explores how students develop as writers and learners, and how writing stimulates cognitive development, critical thinking, and creativity, appearing in outlets such as Journal of Second Language Writing, English for Specific Purposes Journal (ESPJ), Applied Linguistics, Written Communication, and Higher Education.