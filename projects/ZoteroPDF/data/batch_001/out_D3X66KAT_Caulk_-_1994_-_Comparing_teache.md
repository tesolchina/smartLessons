Comparing Teacher and Student Responses to Written Work

Author(s): Nat Caulk

Source: TEsOL Quarterly, Spring, 1994, Vol. 28, No. 1 (Spring, 1994), pp. 181-188

Published by: Teachers of English to Speakers of Other Languages, Inc. (TESOL)

Stable URL: https://www.jstor.org/stable/3587209

# REFERENCES

Linked references are available on JSTOR for this article: https://www.jstor.org/stable/3587209?seq=1&cid $\underline { { \underline { { \mathbf { \Pi } } } } } =$ pdfreference#references_tab_contents You may need to log in to JSTOR to access the linked references.

# BRIEF REPORTS AND SUMMARIES

The TEsOL Quarterly invites readers to submit short reports and updates on their work. These summaries may address any areas of interest to Quarterly readers. Authors' addresses are printed with these reports to enable interested readers to contact the authors for more details.

Edited by GRAHAM CROOKES and KATHRYN A. DAVIS University of Hawaii at Manoa

# Comparing Teacher and Student Responses to Written Work

NAT CAULK Leipzig University

In the past 2 decades, ESL writing instructors have become interested in the process approach to writing, which they borrowed from their colleagues in L1 writing. The process approach argues that writers create and change their ideas as they write and that writing is recursive: When and how often writers rework things depends on their personal writing style as well as the writing task and context. Early proponents of the process approach asserted that the most important task of writing instructors was helping students develop the skills needed to come up with ideas, explore ways of expressing them, and examine and refine their writing. In practice, this meant working on prewriting, drafting, and analyzing and rewriting techniques, including peer response (where students read and comment on each other's papers.)

In the mid-1980s, the process approach came under attack from professionals who claimed that due to the emphasis laid on the students' discovery of their personal ideas and the neglect of the "sociocultural context" (Silva, 1990), it did not prepare students for academic work. Critics responded by offering English for academic purposes (EAP) courses which aimed to give students skills in "finding out what is expected and trying to approximate it" (Silva, 1990, p. 17) and content-based ESL courses focusing on reporting and commenting on academic material rather than personal discovery (Raimes, 1991). However, this was not a rejection of the ideas of the process approach but a shift in focus, and process writing techniques are used by most writing instructors and EAP textbooks (e.g., Brookes & Grundy, 1990; Leki, 1989; & Reid, 1985).

Although there has been a significant amount of research on the processes individual writers go through (for summary, see Krapels, 1990), an important but neglected area of study concerns what goes on between students in process approach exercises, especially in peer response activities. Writing instructors must also understand this to judge if these activities are helpful in developing students' writing processes. Some work has already been done: Mittan (1989) spelled out the reasons for using peer response; Allaei and Connor (1990) discussed the problems that can arise from using peer response in classes with students from a variety of cultural backgrounds; Keh (1990) compared the advantages and disadvantages of peer feedback, teacher-student conferences, and written comments; Mangelsdorf (1992) reported on students' attitudes toward peer response; and Nelson and Murphy (1992) investigated how the social behavior of the students toward one another can affect the quality of peer review sessions and explored what factors make students more open to accepting suggestions from their peers (Nelson & Murphy, 1993).

However, there remains a need for studies on the quality or content of L2 peer response; this information is vital for accessing the efficacy of peer response in writing instruction. The study described below, which I conducted as both teacher and researcher, is an attempt to fill this gap.

# THE STUDY

The purpose of this study was to deepen our understanding of what happens in peer response activities as well as to provide specific information for writing instructors on which to base decisions. To do this, two questions were posed. The first question was, Do students give good advice to their peers? I looked at the quality of the peer responses in comparison with teacher comments and assessed whether peer responses approached the quality and range of typical comments by teachers, which would make teacher comments unnecessary, or whether students only made suggestions the teacher considered unimportant or misleading, which would call into question the use of peer responses. The second question was, What are the differences between teacher and student comments, and why do these differences exist? Here I examined the functions teacher and student comments served in the writing classroom.

# The Writing Class

The participants, 18-25 years of age and ranging from intermediate to advanced proficiency (meaning an approximate Foreign Service Institute [FSI] rating of $2 -$ to $3 + { }$ , were either studying English or studying to be English teachers. They were enrolled in one of three sections of a semester-long writing course $( 1 \% \ \mathbf { h r / w } \mathbf { k } )$ at a large metropolitan university in Germany. The main aim of the course was to enable students to write well-organized, focused essays. As the instructor, I taught the class using a process approach, which I have used for this and other writing classes since 1990. Among other activities, students wrote three essays during the semester, rewriting each once. They distributed copies of their first drafts to other members of their writing group and for homework, wrote comments on the other students' drafts, guided by a set of questions I provided. I also wrote comments on each first draft. The students received the comments on their papers the next week, had $1 0 { - } 1 5 \ \mathrm { m i n }$ to read through them and question me or student commenters, then used the comments to rewrite their papers for the next class. Each student also wrote a self-analysis of her/his paper, guided by a set of questions I had given them.

# Procedure

Thirty papers, 15 from the second assignment and 15 from the third, were randomly selected from three different writing classes which had a total of 43 students. Photocopies were made of the papers, their peer responses, my comments, and each student's self-analysis. Photocopies from two of the papers were unreadable because of the type of pen used and were dropped from the study. Because the papers were randomly selected for both the second and the third assignments, there were three pairs of papers with the same author, meaning that in the end there were 28 papers by 25 different authors in the study. Not all papers had the same number of peer responses due to absences the day the papers were handed out or the day the comments were due or because of students dropping the class late in the semester. Three papers had four peer responses, 10 papers had three peer responses, 8 papers had two peer responses, and 7 papers had only one peer response each.

# Data Analysis

First, the students' and my suggestions for improving each paper were coded into summarized "points." My comments on and the peer responses to each paper were compared to see what percentage of my points were mentioned in at least one of the peer responses. Each student's self-analysis was also coded and compared with my comments on her/his paper to see whether students could anticipate weaknesses in their own papers. Then, as the teacher, I coded each suggestion made by students as a valid or invalid suggestion. Finally, the peer responses were examined to see (a) how many points or suggestions they made which I considered valid, but I had not included in my comments; (b) how many peer responses contained points that I did not consider valid; and (c) how many peer responses contained no suggestions for improving the paper.

Second, comments were divided into six categories-form: suggestions to change introductions, conclusions, and paragraphs so they would be closer to typical English form (e.g., making the general point clear in the introduction, not bringing up new arguments in the conclusion, etc.); reorganization: suggestions to change the order of words, phrases, sentences, and paragraphs for reasons not due to form; more information: suggestions to write more detailed information about one aspect of the paper; write less: suggestions to write less information about one aspect of the paper; clarity: statements that the meaning of a particular sentence, point, or paragraph is unclear to the reader and suggesting it be made clearer; and style: suggestions that the style of a particular sentence or passage is not the most effective for that particular writing task. The percentage of my comments and student comments in each category were then compared. Finally, the comments were examined more closely to discern the differences in substance and style between my comments and those of the students.

# RESULTS AND DISCUSSION

# Do students give good advice to their peers?

The peer responses clearly did provide students with information helpful for rewriting their papers; $89 \%$ of students (25 out of 28) made suggestions I considered valid. Furthermore, $6 0 \%$ of the students brought up valid suggestions which I had not mentioned in my comments, for instance, "Besides this, if I were the intended audience I would wish to hear a little more about the difficulties which are connected with the rebuilding of this church and about its former meaning in Dresden"; "Maybe she could have explained the importance of the reconstruction more in detail, what she feels when something is rebuild what used to be a memorial"; or "Besides I want to know if the reconstruction of the 'Frauenkirche' has been started yet." Students also got very little bad advice from other students; only $6 \%$ of the peer responses contained advice that I did not agree with, for example, "Why don't you combine your $\mathrm { 2 n d + 3 r d + 4 t h + 5 t h + 6 t h }$ paragraphs? They are all about improving the situation."

Although the peer responses did give students good advice, they did not substitute for my comments. Only $1 9 \%$ of my suggestions were mentioned in the peer responses of papers with only one peer response, $2 2 \%$ for papers with two peer responses, and $4 0 \%$ for papers which had three peer responses. Eighty-seven percent of my suggestions were mentioned by at least one student for papers which had four peer responses, but there were only three papers in this group, so this is probably not typical. This is further supported by the data on the students' self-analyses; only $1 6 \%$ of students were able to anticipate at least one of my suggestions on their own papers.

# What are the differences between student and teacher comments?

My comments tended to be general and were often aimed at the whole piece of writing, rather than one part. The students' comments, on the other hand, tended to be very specific and rarely contained suggestions for the whole piece of writing. For a fictitious job application letter I wrote,

You might have more success convincing them to hire you if you explain why you are good for them, rather than why they are good for you . . Also, arguing that you are the right person for the job might be more convincing than simply telling stories about yourself. Perhaps you can use your stories to support your arguments..

Students tended to write comments such as "Have you taught [only] English and German or Mathematics as well?" and "Your sentence--If you ask you will get the answer-really confused me as I didn't know what to ask .... Perhaps it's more understandable if you explain the situation first."

Even when a student and I made the same comment, as the teacher, I phrased it as generalizable advice. Where a student said, "Divide this paragraph into one about your education and one about your experience," I wrote, "Your third paragraph seems to have more than one point. Perhaps you should divide it." For another paper a student wrote, "I'd like to hear more about your former activities and personal details," whereas I wrote, "I would suggest more explanation about why you are the best. Perhaps you could add a few sentences beginning I can, I have, I am."

Upon reflection, I felt that I had tried to be general and had avoided making the types of specific suggestions that the students made, even though I had agreed with them, because I did not want to interfere with the content of students' papers. Instead, I wanted the students to concentrate on what they wanted to say, not on what they thought I wanted them to say. I felt that if I made specific suggestions, some students would follow them without thinking about whether they agreed or not. In my opinion, wording comments more generally also forced the students to think and to understand the comment. The student may know that the third paragraph should be divided but not know where or why and must discover this for her/himself. Even when I made a specific suggestion such as "Add a few sentences beginning with I can," the student is still forced to consider how to end the sentences and where to put them. The students, on the other hand, did not appear afraid to suggest specific changes. Moreover, they acted more like normal readers, reacting to the part they were reading at the moment, instead of behaving like writing evaluators. This might also have been a result of their lack of experience writing essays in English.

The students and I generally commented on the same types of things. I wrote a greater percentage of my comments on problems with form $8 \%$ more often than students) and clarity $7 \%$ more). One reason for this could be my desire to avoid commenting on the content, and both these categories represent comments made about how something was said, not what was said. I also focused on form because this was an EAP class, and as the teacher, I felt that it was important to guide the students toward writing in a rhetorical form more acceptable to academic readers, for example, "You seem to have a lot of tiny paragraphs about the furniture you would order. Why not combine them?" The reason I focused more on clarity than did the students might be because I commented on potential problems with clarity even when I thought I understood what the writer was trying to communicate, and the students did not. For example, "Your introductory sentences are good, but a bit vague. Smoking is a signal for insecurity could mean a lot of different things. Maybe starting off by saying, Smoking shows ... would help you make your idea clearer."

The students made more suggestions concerning what should be added $( + 3 \% )$ or removed $( + 7 \% )$ from the essay, for example, "Don't repeat about burning your hands in the 4th paragraph" or "Leave out facts as your birthplace, your unemployment because you have to add to an application a curriculum vitae including all the necessary dates." This is likely because these elements are more tangible, do not require composition skills, and are easier for people who are novice writers in English.

# IMPLICATIONS FOR TEACHING

Although the peer responders in this study did not usually make the same types of comments as the teacher, they made many suggestions the teacher did not make but considered valuable. In this case, the two kinds of responses seem complementary rather than redundant. Furthermore, because student responses were not written by an authority figure, they may have provided students with specific feedback without giving them the feeling that they are obliged to take the suggestion. In this study, they provided the student writer with feedback from people who reacted like real readers, rather than global writing assessors.

A further advantage of peer responses was that even when students made the same point as the teacher, they phrased it differently or from a different perspective, giving the writer different ways to think about the suggestion. For example, one student paragraph began:

Before I tell my opinion I would like to give some background information from the historical point of view. Upon a plaque in front of the ruin stands that this church was built by George Bahr in the period from 1726 till 1743

I commented, "Are you sure the information in your second paragraph is necessary? How does it show that rebuilding the 'Frauenkirche' is a good idea?" A student wrote, "It is a bit confusing, because at the beginning of the second paragraph it seems as if you want to withhold your opinion from us."

Teacher and student responses give students alternative ways to think about and understand the problem, which may make it easier for students to understand the point. Because students are sometimes confused by teachers' comments (Zamel, 1985), multiple comments may help give the student a fuller understanding of the suggestion.

A final point is that the quality of the feedback students in this study received rose with the number of students giving feedback to each student. Therefore, writing instructors using peer response activities might want to make sure that each student receives comments from more than two peers.

# CONCLUSION

This case study of teacher and peer responses to student writing suggests that each serves important and complementary functions in developing writing abilities. The study also indicates the need for research within specific writing classrooms that attempts to determine how well process writing activities fulfill the functions they are theoretically supposed to fill. I would suggest that the unstated attitudes and roles of both teachers and students which underlie how they act in different activities and how these change over time warrant special attention.

# ACKNOWLEDGMENTS

An earlier version of this paper was presented at the 1993 IATEFL Conference in Swansea, Wales. I would like to thank the Brief Reports and Summaries editors, Kathryn Davis and Graham Crookes, for pushing me to go beyond my initial work and Kathleen Graves for her extremely helpful comments and suggestions on the penultimate draft.

# REFERENCES

Allaei, S. K., & Connor, U. M. (1990). Exploring the dynamics of cross-cultural collaboration in writing classrooms. The Writing Instructor, 10, 19-28.   
Brookes, A., & Grundy, P. (1990). Writing for academic purposes. Cambridge: Cambridge University Press.   
Keh, C. (1990). Feedback in the writing process: A model and methods for implementation. ELT Journal, 44, 294-304.   
Krapels, A. R. (1990) An overview of second language writing research. In B. Kroll (Ed.), Second language writing: Research insights for the classroom (pp. 37-56). Cambridge: Cambridge University Press.   
Leki, I. (1989). Academic writing: Techniques and tasks. New York: St. Martin's Press.   
Mangelsdorf, K. (1992). Peer reviews in the ESL classroom: What do the students think? ELT Journal, 46, 274-293.   
Mittan, R. (1989). The peer review process: Harnessing student's communicative power. In D. Johnson & D. Roen (Eds.), Richness in writing: Empowering ESL students (pp. 207-219). New York: Longman.   
Nelson, G., & Murphy, J. (1992). An L2 writing group: Task and social dimensions. Journal of Second Language Writing, 1, 171-i93.   
Nelson, G., & Murphy, J. (1993) Peer response groups: Do L2 writers use peer comments in revising their drafts? TEsOL Quarterly, 27(1), 135-141.   
Raimes, A. (1991). Out of the woods: Emerging traditions in the teaching of writing. TESOL Quarterly, 25(3), 407-430.   
Reid, J. (1985). The process of paragraph writing. Englewood Cliffs, NJ: Prentice Hall.   
Silva, T. (1990). Second language composition instruction: Developments, issues

and directions in ESL. In B. Kroll (Ed.), Second language writing: Research insights for the classroom (pp. 1123). Cambridge: Cambridge University Press. Zamel, V. (1985). Responding to student writing. TEs0L Quarterly, 19(1), 79-101.

Author's Address: School for International Training, Kipling Road, P.O. Box 1313, Brattleboro, VT 05302.

# Implicit and Explicit Learning of L2 Grammar: A Pilot Study

ROBERT DeKEYSER University of Pittsburgh

This is a report of an exploratory study under laboratory conditions aimed at clarifying the role of explicit teaching of different kinds of rules. The report presents the motivation for and the methodology and results of this limited pilot study with 6 students in the hope that it will stimulate other researchers to think about experimental ways of untangling the various factors involved in the controversial issue of the usefulness of teaching and learning rules in an L2.

# BACKGROUND

The teaching of rules has been a controversial issue for a number of reasons, one of the most important of which is probably the fact that so many different variables tend to be confounded in pedagogical discussions: the role of instruction in general (e.g., Krashen, 1982; Long, 1988; and especially the June 1993 theme issue of Studies in Second Language Acquisition), focus on form (Long, 1991), input enhancement (White, Spada, Lightbown, & Ranta, 1991), analytical versus experiential learning (Stern, 1992), inductive versus deductive learning (Shaffer, 1989), implicit versus explicit learning (Levin, 1969; Scott, 1989).

The last two pairs of terms are particularly problematic. Deductive means that the rules are given before any examples are seen; inductive means that rules are inferred from examples presented (first). Implicit means that no rules are formulated; explicit means rules are formulated (either by the teacher or the student, either before or after examples/practice). Thus, whereas the two dichotomies are clearly independent in principle, they tend to coincide in practice (deductive and explicit vs. inductive and implicit) because explicit learning is almost always the result of deductive teaching, given that encouraging students to formulate their own explicit rules by inducing them from a set of examples seldom works well (Ausubel, 1963; Carroll, 1964; pace Shaffer, 1989; cf. also Fotos & Ellis, 1991) and