# The effect and affect of peer review in electronic versus traditional modes on L2 writing

Jun Liu\*, Randall W. Sadler

Department of English, University of Arizona, Modern Languages 488, PO Box 210067, Tucson, AZ 85721, USA

# Abstract

This study1 investigates whether differences in mode of commenting and interaction (i.e. technology-enhanced versus traditional) result in differences in the area (global versus local), the type (evaluation, clarification, suggestion, and alteration), and the nature (revision-oriented versus non-revision-oriented) of comments produced by peer reviewers in second language (L2) writing, and what impact the observed differences have on students’ revisions. The findings show that the overall number of comments, the percentage of revision-oriented comments, and consequently the overall number of revisions made by the technology-enhanced group were larger than those by the traditional group. While the participants in the technology-enhanced group tend to find MOO interaction affectively more appealing, a closer look at the interaction modes suggests that face-to-face communication is more effective than MOO communication because of the nonverbal communication feature that is indispensable in intercultural communication in a peer review setting. In light of the differential effects within each commenting mode (Microsoft Word editing versus pen and paper) and interaction mode (MOO versus face-to-face), we suggest that the use of Word editing in an electronic peer review mode combined with face-to-face interaction in the traditional peer review mode may serve as a two-step procedure for effective peer review activities in L2 writing classrooms.

$©$ 2003 Elsevier Science Ltd. All rights reserved.

Keywords: Peer review; Second language writing; Computer mediated communication; Face-to-face interaction; Revision; Feedback

# 1. Introduction

Over the past decade, the biggest concern second language (L2) writing teachers have expressed about using peer review activities is whether peer comments in fact help students write better papers. This concern raises two fundamental questions: First, do L2 writing students have sufficient linguistic, content, and rhetorical knowledge to give their peers constructive feedback on their drafts? Second, are these students able to modify their texts based on their peers’ comments?

Some researchers (Amores, 1997; Leki, 1990; Nelson & Murphy, 1992, 1993) have stated that peer review is a problematic task for many L2 writers for a number of reasons. First, students sometimes focus too heavily on ‘‘surface concerns’’ (Leki, 1990, p. 9); they tend to neglect larger revising issues and provide vague and unhelpful comments. Second, students sometimes can be hostile, sarcastic, overly critical, or unkind in their criticisms of their classmates’ writing. Interactions of the group are at times unpleasant, with students being overly critical of each other’s writings (Nelson & Murphy, 1992). In fact, the nature of responding to peers’ drafts sometimes generates a sense of discomfort and uneasiness among the participants. Generally speaking, the students can become rather defensive when their work is criticized, especially by their peers (Amores, 1997). In doing peer response activities, some students might feel uncertain about the validity of their classmates’ responses, and some might struggle with their own listening comprehension skills due to the accents of their peers. Because of the lack of L2 formal (rhetorical) schemata, some students might have inappropriate expectations about the content and structure of peers’ texts, resulting in counterproductive feedback that leads writers further away from the expectations of their teachers.

On the other hand, some L2 writing researchers have found that peer comments ‘‘enhance a sense of audience, raise learners’ awareness of their own strengths and weaknesses, encourage collaborative learning, and foster ownership of text’’ (Tsui & Ng, 2000, p. 147). Some researchers have found that students, especially those who have been trained in peer review, are quite capable of making useful suggestions about their peers’ drafts (e.g. Berg, 1999; Hedgcock & Lefkowitz, 1992; Paulus, 1999; Stanley, 1992; Villamil & de Guerrero, 1998). Students, especially those who have been trained in peer review, are able to give specific comments and advice on their peers’ writing and to point out problems with content and rhetoric (Berg, 1999; Hedgcock & Lefkowitz, 1992; Lockhart & Ng, 1995; Mendonc¸ a & Johnson, 1994; Stanley, 1992; Villamil & de Guerrero, 1998). Analysis of the interactions in peer response groups has shown that students actively ask questions (requests for both information and comprehension checks), give and ask for explanations (unclear points, opinions, and content), restate, give suggestions, and correct grammar mistakes (Mendonc¸ a & Johnson, 1994). In fact, peers may give better content feedback than teachers if the students are paired based on their fields of study (Belcher, 1990). In addition, peer response groups can be a fruitful environment for students to negotiate meaning and practice a wide range of language skills (Lockhart & Ng, 1995) which are integral to their development not only as L2 writers, but also for the development of all four language skills in a collaborative environment (Vygotskii, 1978).

In spite of the controversies, a fundamental question all L2 writing researchers and teachers have about peer review activities is: Will students be able to incorporate peer comments into their revisions? There is no definitive answer to this question. Some research indicates that students utilize only a small percentage of their peers’ comments in revision (e.g. $5 \%$ for the students in Connor & Asenavage’s 1994 study; see also Nelson & Murphy, 1993; Partridge, 1981; Tsui, 1999). However, much of the research has shown that students utilize all three types of feedback: self, peer, and teacher (e.g. Caulk, 1994; Chaudron, 1984; Cheong, 1994; Mendonc¸ a & Johnson, 1994; Paulus, 1999) even if they at times rely more on their teacher’s feedback for revision (Cheong, 1994). In fact, research on revisions based on teacher versus peer feedback has shown that both helped (Caulk, 1994; Chaudron, 1984; Paulus, 1999), especially since peer feedback seemed to be more focused on specific concerns, whereas teacher feedback was more global. A study comparing the revisions of one group with teacher feedback only and one group with peer feedback only found that there were no significant differences in the revisions made—both groups performed equally well (Hedgcock & Lefkowitz, 1992). In addition, peer feedback has also been found to instigate further revision after the peer response activities ended (Paulus, 1999; Villamil & de Guerrero, 1998) indicating that students keep considering their peers’ comments when revising their drafts on their own.

Another interesting area of research on peer review which is directly related to the effects of peer review activities and the extent to which students’ drafts are revised is computer mediated communication (CMC). CMC refers to both asynchronous communication such as e-mail and virtual synchronous conversation in multi-user domains object-oriented (MOO’s).2 CMC offers an additional and possibly less anxiety-provoking means of learner-to-learner communication within language classrooms than face-to-face interaction. In addition, it extends the interaction possibilities beyond the classroom walls, hence ‘‘beyond its time constraints and the usual limited circle of interlocutors of classroom pair and group work’’ (Belcher, 1999, p. 255). This aspect of convenience is often cited as being an important advantage of MOO’s for classroom communication, as it enables participants to collaborate outside the classroom on their own time (Egbert, Chao, & HansonSmith, 1999; Snookes, 1995). Research in L2 classrooms indicates that networked computers do indeed enhance opportunities and motivation for authentic interaction and meaningful negotiation (Kern, 1995); reduce anxiety and produce more talk (Fanderclai, 1995; Harris, 1995; Kern, 1992; Reid, 1994); and improve linguistic proficiency and increase self-confidence (Beauvois & Eledge, 1996). In ESL/EFL writing classes, observations of the use of CMC in various formats also indicate students’ enhanced confidence in writing and increased quantity in both peer and teacher feedback (Braine, 1997). Researchers (Sproull & Kiesler, 1991; Rheingold, 1993) also suggest that CMC has great potential for leveling the playing field in the multilinguistic, multicultural classroom, thus empowering minority students or nonnative English-speaking students in composition classrooms with linguistically and culturally diverse backgrounds (Belcher, 1990). As oral classroom participation is not encouraged in many countries where attentive listening and students’ silence are expected (Liu, 2000), peer review via CMC seems greatly facilitated by synchronized interaction. Warschauer (1996) found much more equitable conversations in the CMC mode than in face-to-face interactions as the less vocal students seemed to participate more. This finding of increased participation was confirmed by Sullivan and Pratt (1996) whose study showed full student participation in electronic discourse as compared with $50 \%$ participation in face-to-face interaction. In terms of the quality of interaction, Warschauer (1996) reported that the participants in his study tended to express their own ideas during electronic communication rather than directly answering questions posed to them, suggesting increased creativity. Also, the electronic discussions involved significantly more complex sentence structures than face-to-face discussions.

In the latest work on peer response, Liu and Hansen (2002) conclude that research in this area thus far has already observed and identified both quantitative and qualitative differences between electronic interactions and face-to-face interactions in peer review activities. What is needed is a close examination of whether the differences in peer review activities in both commenting modes (technology-enhanced versus face-to-face) will lead to differential effects on students’ revisions. To address this issue, the present study investigates whether differing commenting modes make a difference in the area, the type, and the nature of comments made and how these comments affect revisions.

# 2. The study

As mentioned earlier, CMC is a rapidly growing tool used for peer review in L2 writing. There has been little research, however, that directly compares the effectiveness of traditional peer review with that of the electronic format. Given the rapid increase in computerized classrooms at universities across the nation and the increasing numbers of courses which rely on distance learning, the use of CMC in performing peer review is becoming a crucial tool for the teaching of ESL writing. The purpose of this study is to directly compare the effectiveness of traditional peer review (i.e. students writing their peer comments on their partners’ papers and then meeting face-to-face in class to discuss those comments) versus electronic peer review (i.e. students making comments on computers using features of Microsoft Word [discussed further in data description section] and then communicating electronically via a MOO). The rationale for examining asynchronic (either paper or electronic) and synchronic (either face-to-face or MOO) peer review is that this study seeks to reflect the usual classroom procedure for peer response that does not normally use either asynchronic or synchronic peer review in isolation.

To evaluate the extent to which students make revisions on their drafts as a result of peer comments given in either the electronic mode or the traditional mode, we must first bear in mind that to quantify only the ratio of overall comments versus overall revisions is misleading as students’ revisions of their drafts are constrained by a number of factors, such as the area in which the comments are made (global versus local) and the type of comments made in each area (evaluation, clarification, suggestion, and alteration). Some comments (e.g. ‘‘This is a good thesis.’’) are not revision-oriented, and some comments might be too vague to be taken into account (e.g. ‘‘I’m not sure what this means but it is probably o.k.’’). Therefore, we should not only identify and describe the area and the type of comments made in peer review, but also differentiate the nature of comments (revision-oriented versus nonrevision-oriented). Only in this way can we examine the effects of peer comments on revisions with great precision. This study investigated how the different commenting modes (technology-enhanced versus traditional) affect the nature of comments made in both areas across all types, and how the differential comments affect the revisions. We examined the following three research questions:

1. Does the use of a technology-enhanced asynchronic commenting mode (Word editing) versus a traditional commenting mode (pen and paper) result in a differential distribution of peer comments in the area (global versus local), the type (evaluation, clarification, suggestion, alteration), and the nature of comments (i.e. revision-oriented versus non revision-oriented)?   
2. Does the use of a technology-enhanced synchronic interaction mode (MOO) versus a traditional synchronic interaction mode (face-to-face) result in a differential distribution of peer comments in the area (global versus local), the type (evaluation, clarification, suggestion, alteration), and the nature of comments (i.e. revision-oriented versus non revision-oriented)?   
3. To what extent do students revise their papers based on peer comments made in the traditional versus technology-enhanced commenting and interaction modes?

# 3. The participants

The participants for this study consisted of 48 students taking second semester freshman composition at a large southwestern university in the United States during the spring semester of 2000. The age of the students ranged from 17 to 28 years, with the average age being 20. Two classes, each with 24 students, took part in the study. The first class (traditional group) contained only non-native speakers of English, while the second class (technology-enhanced group) was a mixed section containing seven native speakers of English (all from the United States) and 17 non-native English speakers. Combined, the group represented 16 different languages and 17 countries. The non-native English-speaking students had studied English for an average of 9 years, and all of the students had attended university in the previous semester. The same instructor taught both sections involved in the study and used the same readings, assignments, and grading rubrics for both groups. The instructor was a PhD student specializing in teaching English as a second language and had taught writing at the university for 3 years.

In each class, students were divided into six peer review groups. In the traditional class, all the students were non-native English speakers. In the technology-enhanced class, only two groups consisted of all non-native English speakers. While complete data was gathered from all 48 students throughout the semester, we only focused on eight non-native English-speaking students (1 group of 4 from each class) for this study in order to obtain more in-depth data for analysis. The two groups were purposefully chosen to reflect the diversity of the overall non-native population, with each group having both males and females and each student coming from a different language background. The traditional group consisted of three females (Japanese, Indonesian, and Singaporean) and one male (Mexican), while the technologyenhanced group contained two females (Indonesian and Sri Lankan) and two males (Peruvian and Greek). Though the number of years the participants had studied English varied, they were all placed into the class based on their performance in a university-specific writing placement exam. In addition, all students admitted to the university must have a score of at least 500 in the TOEFL exam. The detailed demographic information can be seen in Table 1.

# 4. Data description

This study contains data from multiple sources. First, a personal information sheet was collected from each student at the beginning of the semester. It recorded students’ demographic information, and their attitudes towards peer review and the use of technology in the classroom. Second, data related to one of the three required student essays3 for the course was collected: three drafts from each student, peer review comments made on the initial draft, two follow-up questionnaires, informal interviews with the student, and transcripts of classroom peer review interaction. To ensure that the revisions observed in the second draft were derived only from the peer comments, teacher comments were not made on the paper until the second draft had been turned in.

The peer review for this paper took place in the fifth week of the semester. The students in the technology-enhanced group attended classes in a computer lab throughout the semester (see Illustration 1).

The two groups followed the same basic syllabus, but the activities for the computer-enhanced group were performed on computers, for example, using Microsoft

Table 1 Demographic information of participants   

<html><body><table><tr><td>Group</td><td>Name</td><td>First Language</td><td>Country of origin</td><td>Sex</td><td>Age</td><td>Years of previous English study</td></tr><tr><td>Traditional</td><td>Ayako</td><td> Japanese</td><td>Japan</td><td>F</td><td>25</td><td>12</td></tr><tr><td></td><td>Jane</td><td>Indonesian</td><td> Indonesia</td><td>F</td><td>18</td><td>6.5</td></tr><tr><td></td><td>Orlando</td><td>Spanish</td><td>Mexico</td><td>m</td><td>18</td><td>4</td></tr><tr><td></td><td>Belinda</td><td>English</td><td>Singapore</td><td>F</td><td>19</td><td>15</td></tr><tr><td>Technology-Enhanced</td><td>Christina</td><td> Indonesian</td><td> Indonesia</td><td>F</td><td>18</td><td>11</td></tr><tr><td></td><td>Christian</td><td> Spanish</td><td>Peru</td><td>m</td><td>17</td><td>11</td></tr><tr><td></td><td>Michael</td><td>Greek</td><td>Greece/Cyprus</td><td>m</td><td>20</td><td>9</td></tr><tr><td></td><td>Vayomi</td><td>Singhala</td><td>Sri Lanka</td><td>F</td><td>20</td><td>12</td></tr></table></body></html>

Word for in-class writing assignments, using the commenting features in Word when writing journal assignments, and using a MOO for class discussions. Before the students turned in their rough drafts, they had attended a two-part training session to ensure that they were well informed about the rationale and the procedures of the peer review process. First, there was an in-class discussion for both groups regarding the benefits of peer review. This discussion was based upon the format laid out by Berg (1999). Each group was also given a peer review sheet for this particular assignment devised by the instructor, which included questions on the introduction and thesis statements, organization of the paper, use of topic sentences, idea development, textual evidence used in the paper, and grammar issues. The rationale for the questions on the sheet was discussed with the students by comparing the elements emphasized for peer review with the actual grading rubric utilized for the class. For this section of the training, students were also given a copy of an essay (rough and final draft) written by a student during a previous semester and the peer review comments for that essay. Students were asked to comment on how the essay changed. They also discussed what comments seemed to be useful or not useful, and why they thought so.

![](img/7fc09c10ad2668d835a66fb598348985fc54b7e25a628fffea1d0e74b0649cb4.jpg)  
Illustration 1. A scene of the technology-enhanced group performing peer review tasks.

The second part of the peer review training was customized for each group and took place over a 75-min class period. In the traditional group, a section of a sample essay was photocopied for the students and they were asked to comment on it together with a partner in class. They wrote their answers on the peer essay itself and also on the review sheet provided. The review sheet was identical to the sheet used in part I of the training. The pairs then spent approximately $1 5 \ \mathrm { m i n }$ in class commenting on the sample. Next, the groups shared their answers to the peer review questions, and as a class, they discussed what they believed to be the most useful responses generated. In the technology-enhanced group the same writing sample was used and a peer review sheet with the same questions was utilized, but the writing sample was given to the students on disc, and the training session took place in a computer lab, as seen in Illustration 1.

The students were reminded by the instructor (through the use of a computer projector) how to use the ‘‘track changes’’ and ‘‘insert comments’’ features of Microsoft Word4 and the students then practiced this feature with a partner for several minutes using the writing sample on the disc provided by the instructor. The students were then asked to use the ‘‘track changes’’ and ‘‘insert comments’’ features to answer the questions in the peer review sheet, but this time without a partner, and using the computers in the lab. The students in the technology-enhanced group were instructed to make all comments on the computer. After $1 5 \ \mathrm { m i n }$ of commenting, they exchanged their answers and reflected on the use of technology in peer review.

For the actual assignment in this study, there were three drafts required from each student. In the traditional group the first drafts of the assignment were handed in on paper, while the technology-enhanced group handed in their drafts on a disc. In each case, the students were also required to give their peer review teammates copies of their papers in the appropriate format (i.e. on paper for the traditional group and on disc for the technology-enhanced group). All the students received comments from their peers on their first drafts and used those comments to make their second drafts which then received teacher comments in their respective formats. After the students exchanged their comments with their peers and had a chance to read the comments, they were divided into groups. They then engaged in peer review interactions, with the technology-enhanced group using the MOO, and the traditional group sitting in a circle discussing face-to-face. The students in each class were given a set of three guiding questions related to the peer review sheet as starters, but were encouraged to focus on any elements of the papers which they believed to be important for the assignment. This section of the peer review process took place over a $7 5 \mathrm { - } \mathrm { m i n }$ period. The interactions of the traditional group were tape-recorded and later transcribed (see a segment in Appendix A) while the MOO discussions were recorded and the transcripts were automatically generated for later analysis (see a segment in Appendix B). The peer review process for both groups is summarized in Table 2.

Table 2 Peer review process   

<html><body><table><tr><td>Step and Day</td><td>Traditional group</td><td>Technology-enhanced group</td></tr><tr><td>1 Thursday and following Tuesday</td><td>Students practice peer review in class using sample paper and make comments on sample as guided by peer</td><td>Students practice peer review in computerized class using sample paper provided on disc as guided by peer review sheet</td></tr><tr><td>2 Thursday</td><td>review sheet Students receive hard copies of their peers&#x27; papers and peer review sheet. Have weekend to comment on the papers</td><td>Students receive disc copies of their peer&#x27;s papers and peer review sheet. Have weekend to comment on the papers</td></tr><tr><td>3 Tuesday</td><td>Students get back papers from their peers and read over comments</td><td>Students get papers back on disc from their peers and read over comments</td></tr><tr><td>4 Thursday</td><td>Peer groups meet in class to discuss the comments using guiding questions</td><td>Peer groups meet on the MOO to discuss the comments using guiding questions</td></tr><tr><td>5 Tuesday</td><td>Students turn in hard copies of second drafts to instructor for further review</td><td>Students turn in copies of second draft on disc to instructor for further review</td></tr></table></body></html>

# 5. Data analysis

The overall framework for data analysis in this study is based on the model from Wolcott (1994) on his continuum of data description, analysis and interpretation.

Table 3 Grid for analyzing dataa   

<html><body><table><tr><td>Area Global</td><td colspan="3"></td><td rowspan="2">Non-revision</td></tr><tr><td>Nature</td><td>Revision- oriented</td><td>Non-revision -oriented</td><td>Revision- oriented</td></tr><tr><td>Type</td><td></td><td></td><td></td><td>-oriented I like this</td></tr><tr><td>Evaluation</td><td>This is not a clear thesis statement.</td><td>This is a great thesis statement.</td><td>This sentence does not make sense.</td><td>sentence a lot.</td></tr><tr><td>Clarification</td><td>Could you explain your thesis in greater detail?</td><td>(no example for this category)</td><td>What do you mean by this expression &quot;...?</td><td>(no example for this category)</td></tr><tr><td>Suggestion</td><td>Your thesis should be explained more</td><td>You can keep your thesis as it is.</td><td>You should rephrase this sentence</td><td>(no example for this category)</td></tr><tr><td>Alteration</td><td>clearly. (no example for this category)</td><td>(no example for this category)</td><td>Change &quot;tail&quot; into &quot;tale.&quot;</td><td>Change &quot;lay&quot; to &quot;lain&quot; (but &quot;lay&quot; was correct)</td></tr></table></body></html>

a Please note that each of the statements in the cells is an example of comments in that category.

Our analysis and interpretation focused on how the comments from the students were distributed in both global areas (feedback with regards to idea development, audience and purpose, and organization of writing) and local areas (feedback with regards to copy-editing, such as wording, grammar, and punctuation) (McGroarty & Zhu, 1997); on how the comments in each area were made across four types of comments: evaluation (comments on either good or bad features of writing), clarification (probing for explanations and justifications), suggestion (pointing out the directions for changes), and alteration (providing specific changes); and on the nature of comments in each type and in each area. The following grid for analysis was developed (Table 3).

The analysis procedure consisted of five steps. First, each of the two researchers coded the peer comments made on all eight students’ papers. In the traditional group, this coding covers marginal peer comments written on the papers themselves, end comments, and comments written on the peer review sheet provided by the instructor. In the technology-enhanced group, on the other hand, the coding covers peer comments inserted electronically via Word’s ‘‘insert comments’’ feature, changes made to the papers via Word’s ‘‘track changes’’ feature, marginal comments typed into the paper, and end comments made regarding the paper in the peer review sheet. In order to avoid ambiguities in analysis, the coding was based on sentential meaningful units. When the meaning of a comment was complex, the entry was determined by its meaningful units.5 Second, all occurrences of comments from margins, ends of papers, and peer review sheets were inserted into the analysis grid. Third, comments that both researchers had disagreement on were discussed in order to maintain inter-rater reliability. Kuder–Richardson Approaches (KR21) were used for determining internal consistency between the two raters, and the resulted reliability estimate is 0.90. Fourth, the overall comments made by the students were calculated by both researchers for each section of the grid and the number of revision-oriented comments in each section of the grid was also determined. Finally, the students’ revisions in their later drafts were then compared to the revision-oriented comments in their first drafts. The same analysis procedures were applied to the data collected during the MOO and face-to-face interactions. After transcribing the face-to-face interactions and printing out the MOO transcripts, the comments made during the interactions were coded and put into the analysis grid.

# 6. Findings and interpretation

Based on the earlier analysis grid, findings will be discussed according to the three research questions for this study.

Research Question One: Does the use of a technology-enhanced commenting mode (Word editing) versus a traditional commenting mode (pen and paper) result in a differential distribution of peer comments in the area (global versus local), the type (evaluation, clarification, suggestion, alteration) and the nature of comments (revision-oriented versus non revision-oriented)?

As revealed in Fig. 1, the number of global comments (feedback with regards to idea development, audience and purpose, and organization of writing) made by each group was similar, although global comments were the minority for both as well. The number of local comments (feedback with regards to copy-editing, such as wording, grammar, and punctuation), on the other hand, varied widely between the two groups, with local comments clearly dominating in the technology-enhanced group. As the figure illustrates, although the technology-enhanced group made $7 5 \%$ more comments than the traditional group (316 versus 180), this difference was mostly due to the much larger number of local comments made by the former.

![](img/6f3f8f0e13e4cd022e4c4a6c35a802e09ecd8e21d39314e6e9fb6348280bb4c7.jpg)  
Fig. 1. Percentage of comments by group and by area.

Because the questions on the peer review sheet were primarily global in nature (e.g. Take a look at each paragraph. Does each paragraph introduce and develop one idea?), this suggests that the technology-enhanced group not only made global comments based on the peer review sheet, but they also went beyond that and made substantial local comments on screen due to the convenience of the technologyenhanced commenting features. Many of these local comments in the technologyenhanced group also pertained to problems in grammar and spelling on the papers. It is likely that the automatic grammar and spelling check function provided by Word also contributed to this preponderance of local comments in this group.

As demonstrated in Fig. 2, the largest difference in the types of comments made by the two groups was to do with alteration comments. While this type of comments contributed only $7 . 2 \%$ of the feedback in the traditional group, it accounted for almost $47 \%$ of the comments made by the students utilizing technology-enhanced peer review. As discussed earlier, this difference may be largely due to the influence of the grammar and spelling check function provided by Word on the technologyenhanced group. The traditional group, on the other hand, seemed hesitant to provide alteration comments to their peers, perhaps due to a lack of self-confidence regarding their own grammar and spelling skills. While it certainly would have been possible for the students in the traditional group to check in a dictionary for misspelled words, or a grammar resource for problems at the sentence level, this would have required that they first notice that a problem existed and then they would have needed to consult such outside resources. In contrast, the technology-enhanced group was given guidance (albeit far from perfect) from Word regarding potentially problematic areas at the local level via red underlining (signifying spelling errors) or green underlining (signifying potential grammar problems). Instead of having to consult an outside resource to make changes for these problems, the peers only had to right-click on the mouse to see options for alternative spellings and/or sentence structures. In short, local level alterations were quite easy to make for the technology-enhanced group in comparison with the traditional group.

![](img/ad46e4727e894020d648e1711dbf9130185b45d0f7915b451dba6f3f49522cea.jpg)  
Fig. 2. Percentage of comments by group and by type.

While the percentages of clarification and suggestion comments made by both groups were relatively similar, the other large difference between the two groups was to do with evaluation comments. Whereas nearly $60 \%$ of the comments made by the traditional group were evaluative, only $2 5 \%$ of the technology-enhanced comments fell into this category. This difference could be explained by the fact that the traditional group heavily relied on the peer review sheet which did not require them to ask any clarification questions, and they tended to make fewer specific comments in the text itself, instead, often writing their comments on the peer review sheet. The technology-enhanced group was given the same peer review sheet, but the peers in that group wrote almost none of their comments on the sheet, instead, choosing to type in their answers. Moreover, almost all of the evaluation and suggestion comments made by the traditional group were global in nature. This could also be explained by the fact that the questions in the peer review sheet played an important role in influencing this group in the types of comments they made. For instance, the question ‘‘Does the introduction lead into the thesis well?’’ elicits more global/evaluation comments, while the question ‘‘Is there anything missing? If so, please specify.’’ encourages the reviewers to suggest additions or changes to the introduction. It is interesting to note that neither the technology-enhanced nor the traditional group made any global/alteration comments, suggesting the nature of global comments does not lead itself to alteration because this would require the peer reviewer to rewrite substantial sections of the paper, and this is usually not feasible nor desirable in peer review.

As discussed earlier, the technology-enhanced group made a larger number of comments overall (316 versus 180) and the comments made by the two groups also differed both in the area (global versus local) and the type (evaluation, clarification, suggestion, and alteration). One important question that has usually been ignored in previous studies, however, is the nature (revision-oriented versus non revisionoriented) of the comments made. Some types of comments (e.g. alteration) are by definition revision-oriented, as they involve actually giving the author an alternative word or sentence to replace the original. On the other hand, evaluation comments may easily be revision-oriented (e.g. ‘‘I think that your thesis statement is not clear’’) or non revision-oriented (e.g. ‘‘Yep, really nice introduction’’).

As illustrated in Fig. 3, $9 2 \%$ of the comments made by the technology-enhanced group were revision-oriented in nature, compared to $7 5 . 6 \%$ for the traditional group. As implied earlier, much of this difference is due to the large number of alteration comments made by the technology-enhanced group. As all of the alteration comments for both groups were revision-oriented, and as the technology-enhanced group had a much larger percentage of alteration comments compared to the traditional group $47 \%$ versus $7 \%$ ), this finding should not be surprising. However, if the alteration comments are ignored for both groups, the percentage of revision-oriented comment made by the technology-enhanced group is still $1 1 \%$ larger, as shown in Fig. 4.

As shown earlier, if the alteration comments are eliminated from both groups, the overall number of comments made per group differs by only one (167 versus 168). The $1 1 \%$ difference in the percentage of revision-oriented comments still evident in Fig. 4 may be largely explained by the greater percentage of evaluation comments made by the traditional group. Though a number of the evaluation comments made by both groups were positive in nature, they did not encourage revision.

Research Question Two: Does the use of a technology-enhanced synchronic interaction mode (MOO interaction) versus a traditional synchronic interaction mode (face-to-face interaction) result in a differential distribution of peer comments in the area (global versus local), the type (evaluation, clarification, suggestion, alteration), and the nature of comments (i.e. revision-oriented versus non revisionoriented)?

![](img/4eb3fd91810942266d13e9e42e8aba444b6ffe929faed16449ff70916232ba79.jpg)  
Fig. 3. Percentage of comments by group and by nature.

Although most instructors who use peer review in their classes have two components in the process (i.e. written comments and later face-to-face discussion about those comments), previous research typically only focuses on the written comments. In order to better reflect the peer review process used in the classroom, this study has the traditional group engage in a face-to-face classroom discussion of the peer comments and has the technology-enhanced group participate in a virtual discussion on a MOO regarding their reviewed papers. Table 4 shows the overall quantity of comments made in face-to-face and MOO interactions by nature of turns.

As seen in Fig. 5, the face-to-face interactions produced a larger number of comments overall, with a large majority of the comments being global in area. In the case of the MOO group, the comments were overwhelmingly global in nature, with only two local comments being made. The dominance of global questions in this environment is not surprising given the nature of the communication. As opposed to making written comments in their own time, the students were engaged in active communication—either face-to-face or electronically—and, because of this, focused more on their peers than on the papers they reviewed. Common comments in this situation focused on the thesis statement of the paper (e.g. ‘‘I didn’t really understand what you [sic] thesis statement showed’’) or on large parts of the body of the paper (e.g. ‘‘In paragraph number four you don’t really seem to have any point’’) rather than focusing on smaller details that would have required careful examining of the paper.

![](img/3654ab99d59d6901ca53203ba8ce5a1dbddcee4ce0456722d9b7d392ba2807b7.jpg)  
Fig. 4. Percentage of comments by group and by nature—excluding alteration comments. \*Alteration comments have not been included in the calculation of these results.

Perhaps the most interesting type of communication seen during this stage of the peer review process did not exist in the earlier stage. As the transcripts of the face-toface and MOO conversations were being encoded, a number of turns that did not seem to fall under any of the four types (i.e. evaluation, clarification, suggestion, or alteration) appeared. When these utterances were examined as a group, it was discovered that they all seemed to fulfill the function of conversation maintenance for

Table 4 Comparison between face-to-face and MOO interactions in peer review by nature of turns   

<html><body><table><tr><td>Nature of turns</td><td>Face-to-face</td><td> MOO</td></tr><tr><td>Revision-oriented</td><td>88 (55%)</td><td>51 (24%)</td></tr><tr><td>Non revision-oriented</td><td>71 (45%)a</td><td>157 (76%)a</td></tr><tr><td>Total</td><td>159</td><td>208</td></tr></table></body></html>

a The best explanation for the disparity in non revision-oriented turns is that the MOO conversations contained a large number of turns devoted to conversation maintenance.

![](img/8100b7f1c85f3a87ef4b4ba23a5f929bc1ba03417a9b25b8c1a9bbccb7d7a855.jpg)

Fig. 5. Percentage of peer communication by group and by area.   
\*Please note that these totals are calculated as: total overall comments minus maintenance turns.

![](img/ce044d7f8009f0f2aa11bbfa75a09a162bb05559132333db99604b0612ce2a6b.jpg)  
Fig. 6. Percentage of peer communication by group and by type.

the group. As seen in Fig. 6, this type of communication resulted in over $40 \%$ of the turns in the face-to-face group and nearly $70 \%$ of the turns in the MOO group. Sometimes this took the form of greetings (e.g. ‘‘Hey, what’s up’’), while others were used by students to ‘‘take the floor’’ (e.g. ‘‘OK, lets talk about me’’). In the MOO group, these comments sometimes also dealt with issues of confusion or clarification (e.g. ‘‘who r u talking to?’’). As demonstrated in Table 5, examining the nature of the turns with the conversation maintenance turns deleted for the data gives a different picture.

While these maintenance comments do fulfill an important role in communication, they do not relate to the revision process itself, so this data is not included in the discussion of the comments by area and by nature. The importance of this type of communication, however, must not be underestimated in terms of its impact on the peer review process. In the case of the MOO group, it is evident that the large number of maintenance turns resulted in a smaller number of the other types of comments overall. As the purpose of the MOO conversation was to provide extra feedback on the papers and/or to reinforce the comments already made, the large amount of conversation maintenance likely diminished the effectiveness of this feedback in comparison to the face-to-face group. As seen above, even when the conversation maintenance turns are deleted for each group, a much larger percentage of the comments made by the traditional group were revision-oriented in comparison to the technology-enhanced group.

While the quantitative data in the earlier tables reveals that the face-to-face peer reviews produced more comments in general, and more revision-oriented comments in particular (as seen in Fig. 7), this quantified data is not sufficient to capture the essence of the differences in interaction modes without observing how the students made the comments in group interactions. Observations made in this study indicate that the face-to-face peer review group heavily relied on the peer review sheets and the peer papers while communicating their ideas. Sometimes they referred back to their written comments, read part of it, or reinforced the ideas they had conveyed briefly in the peer review sheets. They tended to skip over the local points (e.g. spelling problems) that were specified on their written sheet. They also seemed to be more structured in their commenting by following a set of questions given by the instructor.

Table 5 Comparison between face-to-face and MOO interactions in peer review by nature of turns (with and without maintenance turns)   

<html><body><table><tr><td></td><td>Face-to-face</td><td>MOO</td></tr><tr><td>Maintenance turns</td><td>68</td><td>141</td></tr><tr><td>(INCLUDING maintenance turns)</td><td></td><td></td></tr><tr><td>Revision-oriented turns</td><td>88 (55%)</td><td>51 (24%)</td></tr><tr><td>Non revision-oriented turns.</td><td>71 (45%)</td><td>157 (76%)a</td></tr><tr><td>Total</td><td>159a</td><td>208a</td></tr><tr><td>(EXCLUDING maintenance turns)</td><td></td><td></td></tr><tr><td>Revision-oriented</td><td>88 (97%)b</td><td>51 (76%)b</td></tr><tr><td>Non revision-oriented</td><td>3 (3%)</td><td>16 (24%)</td></tr><tr><td>Total</td><td>91</td><td>67</td></tr></table></body></html>

a The best explanation for the disparity in non revision-oriented turns is that the MOO conversation contained a large number of turns devoted to conversation maintenance. b Deleting the conversation maintenance results in a higher percentage of revision-oriented comments for the MOO group, but the face-to-face group still has a much more revision-oriented nature of interaction.

![](img/f0ad34f63baec4b1e1689643344bd7b2c05d73cd97d78f8a5e9f2777f9fb9d66.jpg)  
Fig. 7. Percentage of peer communication by group and by nature. \*Please note that these totals are calculated as: total overall comments minus maintenance turns.

The MOO group, on the other hand, seemed to refer to their previous written comments very little during the in-class interactions. There are several possible explanations for this difference. First, this group made their peer review comments on disc using the Word features discussed previously. This means that some students did not have a hard copy of their comments in front of them to refer to. Therefore, while they were doing the MOO interaction, they simply had to rely on their memories to offer comments. Secondly, even those students who did print out a hard copy of their comments or had a copy saved on disc were unable to rely on them heavily during the interactions because they had to focus their attention on the comments scrolling on the screen. Many students had difficulty in reading the comments on the screen and typing in their own comments. They simply did not have time to refer back to their own notes if they had them. Many students also had some difficulty keeping up on the improvised conversation due to deficiencies in typing skills. Some students had to look at the keyboard as they typed, which, once again, made it impossible for them to refer to any written notes they might have used otherwise. This group also seemed to have much less structure in their time management and logical topic progression. The following example illustrates some of the problematic issues in the MOO group’s conversation:

1. Christian says, ‘‘oh oh’’   
2. Michael arrives.   
3. Vayomi says, ‘‘What paragraphs’’   
4. Christian says, ‘‘hi michael’’   
5. Michael says, ‘‘HEY’’   
6. Christian says, ‘‘u wrote aboout Jack’’   
7. Christian says, ‘‘what happened, man?’’   
8. Michael says, ‘‘hey christine’’   
9. Michael says, ‘‘err your paper sucked’’   
10. Vayomi says, ‘‘Hi Michael’’   
11. Michael says, ‘‘hehehe’’

This segment, which took place approximately $5 ~ \mathrm { { m i n } }$ into the discussion of the paper by one of the students, Vayomi, immediately demonstrates several difficulties experienced in the MOO format. First, Michael, as seen in line 2, had difficulty logging on to the MOO and arrived after the other students had already begun the discussion. This resulted in a disruption of the conversation as they greeted each other. In addition, in this 11-line segment none of the comments are revision-oriented, and only two of them in some way refer to Vayomi’s paper at all, with the rest being conversation maintenance. Of the comments related to the paper, one is a request for clarification from Vayomi, who did not understand an earlier comment (line 3), and the other is a joke by the newly arrived Michael, which may very well have caused confusion and/or discomfort for Vayomi (line 9). This is because it is not immediately clear from the MOO interaction that Michael’s comment is a joke. In face-to-face interactions, on the other hand, intonation, facial expressions, and body language would probably have made this very clear. MOO interactions, then, often lack the contextual clues present in face-to-face interactions potentially resulting in communication breakdowns (Kasper & Kellerman, 1997).

Obviously, the findings of peer review interactions are not consistent with those discussed earlier in this paper from the written peer review data. When making comments using the Word editing features, the technology-enhanced group made more comments overall, and more revision-oriented comments, but their follow-up MOO interactions did not seem to reinforce their written comments, and the much reduced amount of revision-oriented comments in the MOO interactions tended to be less effective than traditional face-to-face interactions because of the several difficulties identified above. The inconsistency between written comments and the MOO interactions in the technology-enhanced group could also be explained by the novelty factor. On the other hand, the traditional group seemed to have greatly taken advantage of the face-to-face interaction by clarifying and reinforcing a lot of the comments they made earlier in their peer review sheets.

Research Question Three: To what extent are the peer comments made (in both area and type) in the different commenting and interaction modes taken into consideration by the students in their revisions?

As discussed earlier, the peer review process—as performed in most writing classes—consists of a combination of written feedback (as discussed in research question one) and later conversation (as discussed in research question two) about the paper in question. When examining actual revisions made on second drafts, then, it is important to take both of these steps of the peer review process into account. Therefore, research question three combines the comments made during the written and conversational portions of the peer review process, as shown in Fig. 8.

As demonstrated in Fig. 8, the technology-enhanced group made altogether 316 comments during the two stages of the peer review process (Word versus pen and paper, MOO versus face-to-face) while the traditional group made only 180 comments in both areas across the four types. Moreover, the technology-enhanced group had a larger number and percentage of revision-oriented comments than the traditional group $9 2 \%$ versus $7 6 \%$ ). Even though the percentage of overall revisions in the technology-enhanced group is lower than that in the traditional group $( 2 7 \%$ versus $41 \%$ ), the overall number of revisions in the technology-enhanced group is still larger. This indicates that the technology-enhanced peer review format is advantageous to producing more comments overall and a greater percentage of revision-oriented comments.

In terms of the area in which comments were made by each group, it is clear from Table 6 that the technology-enhanced group made more comments overall in the local area $( n = 2 2 8 )$ ) than in the global area $( n = 8 8 )$ , while the traditional group was more balanced in local $( n = 1 0 4 )$ and global $( n = 7 6 )$ comments. The differential amount of comments made in each group further confirms that the technologyenhanced group tends to be more text-dependent (as demonstrated by the large number of local comments), while the traditional group tend to rely more on the peer review sheet. The technology-enhanced group had a larger number of both local and global comments overall and also had a larger percentage of revisionoriented comments in both of these areas. However, when the actual revisions are cross-checked against the revision-oriented comments, this trend changes in favor of the traditional group. While the technology-enhanced group had a larger number of local revisions made based on local comments $( n = 4 9 )$ ), the traditional group made a greater percentage of changes in both the local and global areas $2 7 \%$ and $6 8 \%$ , respectively).

Although the findings by area gives a broad perspective of the differences in the comments made by the two groups, an examination of the overall comments, the revision-oriented comments, as well as the revisions in each type, as illustrated later, will help further delineate the differences between these two groups.

![](img/3ae58fb2da1d21ee301fc98168f86fe8a5d314d59c98f6ca67e3b502bc20418a.jpg)  
Fig. 8. Comparison of overall comments, revision-oriented comments, and actual revisions.

As Fig. 9 demonstrates, not all the evaluation comments are revision-oriented. For example, the technology-enhanced group made 120 evaluation comments overall, and 79 $( 6 6 \% )$ of those were revision-oriented. Of those 79 revision-oriented comments, 24 $( 3 0 \% )$ actually resulted in revisions. In the traditional group, on the other hand, $6 8 \%$ of the global comments were revision-oriented (99/145) and only $21 \%$ (21/99) of those led to revisions. Overall then, the traditional group produced a larger number of evaluation comments, and had a slightly larger percentage of revision-oriented comments. However, the technology-enhanced group acted $9 \%$ more often on those comments, thus resulting in a larger number of revisions. While the traditional group had a larger percentage of global evaluation comments $( 6 7 \%$ versus $56 \%$ ) the technology-enhanced group produced a larger percentage of local evaluation comments ( $8 5 \%$ versus $70 \%$ ).

Table 6 Percentage of revision-oriented comments leading to revision by group and by area   

<html><body><table><tr><td>Group</td><td>Area of comments</td><td>No. of comments made</td><td colspan="2">No. and % of revision- oriented comments</td><td colspan="2">No. and % of revision- oriented comments leading to revision</td></tr><tr><td>Traditional</td><td>Global</td><td>76</td><td>47</td><td>62%</td><td>32</td><td>68%</td></tr><tr><td></td><td>Local</td><td>104</td><td>89</td><td>86%</td><td>24</td><td>27%</td></tr><tr><td>Technology-</td><td>Global</td><td>88</td><td>69</td><td>78%</td><td>30</td><td>43%</td></tr><tr><td>enhanced</td><td>Local</td><td>228</td><td>222</td><td>97%</td><td>49</td><td>22%</td></tr></table></body></html>

![](img/5bab1d021110b0c88c1664a5fa6cea7a333919afac791fcda896645380d486d8.jpg)  
Fig. 9. Evaluation comments and actual revisions by group and by area.

As seen from Fig. 10, all the clarification comments made by both groups in both global and local areas are revision-oriented, although the students in the technologyenhanced group only chose to revise based upon the clarification comments in six cases. As shown by the earlier figure, the traditional group was consistent in the percentage of revisions made based on revision-oriented comments, with $2 6 \%$ both globally and locally. The technology-enhanced group, on the other hand, made only $1 5 \%$ of the revisions globally and $20 \%$ locally. Since the number of revision-oriented comments was less for the technology-enhanced group both globally (13 versus 19) and locally (20 versus 23), it is clear that technology did not seem to benefit the students in this case.

This lack of revision may be due to the nature of the ‘‘insert comment’’ feature in Word, which used to require that the computer cursor arrow be placed over the commented upon (highlighted) text in order to see the comment. These comments, then, are usually not visible to casual observation.6 With traditional peer review, on the other hand, any written comments are always visible on the page. In the case of the traditional group, a greater percentage of the clarification comments were acted upon for revision $53 \%$ versus $3 5 \%$ ), indicating that their increased visibility of comments on the paper may have resulted in a greater influence on the writer.

![](img/5231c114607c1b66f6b441c8a1b28992c9fb7f896664e364a14f29cb5cf1dd0e.jpg)  
Fig. 10. Clarification comments and actual revisions by group and by area.

As illustrated in Fig. 11, nearly all of the suggestions made by the students, both global and local, were revision-oriented. Interestingly, this is the only area in which the technology-enhanced group made more global comments than the traditional group. This finding may be due to the nature of the Word editing mode. This technology allows the peer reviewer to easily highlight whole paragraphs or sections of the text and to then click on the ‘‘insert comment’’ button. After typing in the comment, the author of the paper can later put the mouse over the highlighted text to see the comment that was made by their peer review partner. A number of the students mentioned that this was a very unobtrusive and non-threatening way to make comments on large sections of their partners’ papers (see Section 7 for further explanation). Unfortunately, this ‘‘unobtrusive’’ nature of the Word comments, as discussed above, may also make it easier for the author of the paper to ignore peer comments.

As seen in Fig. 12, there were no global alteration comments made in either of the groups, suggesting that the students were unwilling to rewrite large sections of the papers they were commenting on. This also means that peers might feel uncomfortable making concrete global changes to papers rather than global suggestions or clarifications. From a sociolinguistic perspective (Brown & Levinson, 1987; Goffman, 1967), changing more than a few sentences within a paragraph might be face threatening for both the reviewer and the writer. Some students may tend to avoid making alteration comments in order to maintain good peer relationships. It is not surprising to notice that students in both groups tended to make more global clarification and suggestion comments. As demonstrated in Fig. 12, the technologyenhanced group made a much larger number of alteration comments (148 versus 15)

![](img/62d88be1f10cb07e28323b2464460adc8eced085d4902510c05440054d3c5dd4.jpg)  
Fig. 11. Suggestion comments and actual revisions by group and by area.

![](img/f9ccc0a9061bb6f7fd0c4aabecc982d87307779d7eb66f2fa3a1a7de666414ab.jpg)  
Fig. 12. Alteration comments and actual revisions by group and by area.

but the traditional group actually made a larger percentage of revisions based on those comments $20 \%$ versus $1 8 \%$ ).

# 7. Discussion

One of the major findings of the study reveals that the overall number of comments made by the technology-enhanced peer review group was larger, and the percentage of revision-oriented comments was larger for this group as well, thus resulting in a larger number of revisions overall. It is important to note that the percentage of revisions made based on revision-oriented comments was much higher for the traditional group $41 \%$ versus $2 7 \%$ ) in comparison to the technologyenhanced group. Therefore, even though the technology-enhanced group did have a larger number of revisions, the comments made do appear to be less effective overall. As this demonstrates, only looking at the number of comments made or the affective variables (e.g. motivation, attitude, anxiety, willingness to participate) of traditional versus technology-enhanced peer review does not give a complete picture of the effect of technology on the peer review process. The issue of affect versus effect is key in this discussion.

Affectively, the students in the technology-enhanced group, in general, liked using the MOO and disliked using the Word editing function for peer review. The students, in general, considered their experience using the MOO to be ‘‘fun.’’ This reaction may be due to the fact that many of the students had already used ‘‘chat rooms,’’ which are simplified forms of MOO’s, in their personal communication with friends and family. This seemed to result in a greater comfort level for them with this method of communication. In addition, the lack of face-to-face interaction seemed to be beneficial for some students whose cultural backgrounds do not encourage such interactions in a classroom environment (Liu, 2000).

In contrast to the use of a MOO, the students in the technology-enhanced group seemed to dislike the Word editing feature, mainly because they found it to be very ‘‘time-consuming.’’ Unlike the MOO activity, which was done entirely during class time, the Word and pen and paper commenting was done entirely in the students’ own time as homework. The amount of work required for the Word commenting was a point often mentioned by the technology-enhanced group in both follow-up questionnaires and interviews. As one of the students mentioned, ‘‘it took much longer than the normal peer review.’’ Part of the reason is the procedure in getting started (e.g. inserting discs, finding the correct files on the disc, waiting for a virus scan, opening Word, opening the insert/comment feature, etc.). In addition, once the students get started, they have to follow certain steps in making their comments (e.g. highlighting the desired text, clicking on the insert/comment button, clicking on the insert/comment text field, and typing the comment). With traditional commenting, on the other hand, only the last step is needed. That is to say, students can write down their comments without going through all these technical procedures. Moreover, several students experienced technical difficulties regarding the use of electronic peer review. Some students received discs from their peer review partners that contained corrupted files. This meant that these students were simply unable to open the documents they were given and had to get another copy from the writer. One student, for example, mentioned in her evaluation of the peer review process that she ‘‘couldn’t open up one file.’’ The instructor received numerous e-mails from frustrated students during the peer review period who expressed similar problems. Many of these students seemed to blame the writer or reviewers who provided them the corrupted files for these technical problems, potentially creating animosities which could affect their entire peer review activity. This, again, resulted in additional time spent on the task, which created anxiety on the part of the students. An additional problem mentioned by students regarding electronic peer review is the necessity for computer access. One student, for example, stated ‘‘I can’t do it during my break at school because it’s not too handy. I don’t have my laptop with me all the time.’’ It is true that a student must have access to a computer to do electronic peer review while the traditional peer review only requires a pen or pencil and may be done anywhere. While it is a fact that students tend to like MOO commenting over Word commenting for the reasons described earlier, the effectiveness of these two modes is the opposite.

The combination of the quantitative and qualitative data that has been generated from the study gives further insight into the effectiveness of peer review in the two modes. The synthesis of data has indicated that technology-enhanced peer review works more effectively in the asynchronic commenting mode (i.e. Word editing) than in the synchronic commenting mode (i.e. MOO), while traditional peer review works more effectively in the synchronic commenting mode (i.e. face-to-face interaction) than in the asynchronic commenting mode (i.e. paper and pen).

In the asynchronic commenting mode, the traditional group tended to heavily rely on the peer review sheet. Some students felt obligated to only address the issues in the sheet, and thus were restricted from offering comments other than what they were supposed to make according to the peer review sheet guidelines. As one student confessed, ‘‘I feel I have to answer the questions in the peer review sheet, such as what the thesis of the paper is, and what sentences I like most and least, etc. By the time I answer these questions, I feel I have completed my comments.’’ While some students tended to make sketchy comments on the paper under review, the majority of them were concerned about making comments in between lines due to space limitations. Therefore, their comments were brief, and they were ‘‘waiting for opportunities to discuss their comments with their peers’’ whose papers had been reviewed. Another disadvantage of the traditional commenting mode is that some hand-written comments are not legible, this being one of the reasons why these comments are sometimes not attended to in revisions.

In the technology-enhanced Word commenting mode, on the other hand, students felt that they could comment as much as they wanted to without being concerned about the space, although it was more time-consuming. One student said that he was very motivated to make comments while reading the paper. ‘‘I can type my comments which won’t be visible until the author clicks the highlighted color.’’ The extra step of clicking the highlighted color on the screen makes comments more face valid.

This is why this mode generates much more comments than the traditional mode of using pen and paper. Another advantage of using Word commenting is that it is less face-threatening than marking a paper in red ink, crossing out sentences, or using question marks in the margins, which may make the student writer feel embarrassed, and resistant to suggestions if some comments are not even correct (e.g. in the case of grammar). But using the Word commenting feature, comments made are more suggestive than directive in nature—with the exception of alteration comments—and these comments will not show on the screen all at the same time, and are therefore less intimidating. Thus each individual comment is likely to receive its due attention. Our interview data suggests that students love using the Word editing feature, and they feel not only comfortable making comments, but also feel comments made in this mode are ‘‘usually thoughtful, and worth considering.’

In the synchronic commenting mode, it is a different picture. Although most students were interested in interacting with each other online, the MOO tended to generate more superficial than substantive comments. Thus, the effectiveness of MOO commenting in peer review is questionable. There are several reasons accounting for this lack of effectiveness: First of all, it is hard to determine turntaking, and each student feels rushed to type his or her comments in order to follow the flow of communication. As one student described in the survey, ‘‘I have some ideas but after I type one sentence, my peers have already switched to the next paragraph. I feel very frustrated, and I simply quit commenting.’’ Secondly, there is an enormous amount of conversation maintenance as revealed in the transcriptions. Sometimes even one off-target comment can distract the students’ attention, and it takes minutes to come back to the topic. Part of the reason for the difficulty of being on target is the lack of nonverbal communication. Everything has to be mediated or negotiated among the group on screen, and the more people in a group, the more likely the task will not get done on time. Our results seem to be contradictory to some of the earlier studies using MOO’s. For instance, Warschauer (1996) found that using CMC can encourage less vocal students to participate in discussion, which was supported by Sullivan and Pratt (1996) whose study also showed more student participation in electronic discourse than student participation in face-toface interactions. But none of the earlier studies in L2 writing classrooms compared the differences in the effectiveness between asynchronic and synchronic interaction modes, instead they focus on affective aspects of the interactions. Also, previous studies have not examined the issue of conversation maintenance turns and how they affect the quality of peer review. Our study suggests that MOO interactions in timed peer review activities need coordination, and perhaps there is a need for a communication protocol by which each student involved is comfortable to abide.

Face-to-face interaction as a synchronic mode of communication in the traditional group received more positive feedback from our students and generated more positive results in revisions. In fact, the majority of the comments generated from this mode were taken into consideration in revision. Students involved in face-to-face interaction appreciated the opportunity for focused and organized discussion. Peer comments on a certain issue can be immediately compared and clarified, and the student writer also has opportunities to ask questions that are answered by peers. As one student commented, ‘‘I did not see the point why my classmates say that my thesis in the introduction is not clear. But after I listened to their explanations in the peer review, I understand why they think so.’’ One of the advantages of face-to-face interaction, which cannot be replaced by technology-enhanced communication such as a MOO, is the nonverbal communication it provides. Sitting in a circle, talking to one another, or being silent (showing approval or disapproval), is, after all, an integral part of human communication. Given that the ESL students come from diverse cultural backgrounds, taking the nonverbal communication away from communication can create potential problems for meaning negotiation. As Liu asserts (2001), ‘‘intercultural communication requires both verbal and nonverbal interaction, and both are greatly influenced by the culture of each speaker. Culture tends to determine the specific nonverbal behaviors that represent or symbolize specific thoughts, feelings, or states of the communicator’’ (p. 28). The increased amount of conversation maintenance in the MOO discussions revealed by this study is partly due to the lack of nonverbal communication, which is indispensable in a culturally diverse peer review group.

# 8. Conclusion

Due to the small sample size of this project, the findings and implications are not meant to be generalized beyond the scope of this study. However, the researchers do want to make a number of observations based upon the preliminary findings. As the overall number of comments made with electronic peer review was larger, and because the percentage of revision-oriented comments was larger for the technologyenhanced group as well, thus resulting in a larger number of revisions overall, it is suggested that the use of electronic peer review may serve as an effective tool for the peer review and revision processes and be worthy of further exploration. Nevertheless, the effectiveness of peer response in different modes is more complicated than previous studies may suggest. First, it is important to note that the effectiveness of the different modes of commenting may not reflect the student’s preferences. In this case, the technology-enhanced group preferred the MOO over Word for making comments, but the MOO was not very effective for peer review in comparison to Word. Second, the use of technology in peer review should not be seen as monolithic. As discussed earlier, the use of MOO versus Word for peer review was quite different in both affect and effect. However, as this study shows, the students’ viewpoint on the different modes of commenting may change once they see the effectiveness of certain features. Although most students disliked the use of Word at the beginning of the study, they did later indicate in exit interviews that they found it to be quite beneficial.

One important pedagogical implication of the current study is that L2 writing teachers could try to combine traditional with technological modes for the most effective peer review to occur. That is, if Word commenting features can be combined with face-to-face interaction as a two-step peer review process; on the one hand, students might be motivated to be careful reviewers, and on the other hand, their needs could be sensitized and they could be given opportunities to understand each other and negotiate their comments. In order to make this happen, L2 writing teachers must be familiar with multiple types of peer review in both traditional and technology-enhanced modes. It is believed that given sufficient training, the combination of technology-enhanced (e.g. Word commenting) and traditional (e.g. face-to-face interaction) peer review modes will likely result in more positive affect (i.e. high motivation, low anxiety, and active participation) and a better effect (i.e. more comments, more revision-oriented comments, and more revisions).

# Appendix A. Face-to-face peer review transcription segment

Feb. 8, 2000 Peer review transcription

Participants: J: Jane—Indonesia O: Orlando—Mexico B: Belinda—Singapore A: Ayako—Japan

Comments on Jane’s paper

B: All right, let’s start with Jane’s paper. The first question is: ‘‘Did the introduction of this paper adequately introduce the body of the paper? ‘‘ So, em. . . I think what Jane did was that she basically says about the moral of the fable. she didn’t go into, like how was it written the way it was written, like, because she did not show the reasons how the fable was interpreted. So I don’t really think you really went into that, so. . .   
O: I also see that in the introduction, it does not introduce the thesis statement that very well, so, I found that she first chose the outline of the fable and then puts the thesis statement. But the introduction is like more work to describe, to. . . let’s see what she talks about in the first paragraph [looking at the paper]. Like the topic sentence is not in the first paragraph. . . so. . .   
A: I thought, yeah, she explained the moral, but. . . yeah, by focusing on each characters. . . also touched on the moral on guard. But I am little bit confused about the thesis and also the moral. . . but it’s fine. The moral is the fable’s thesis, right? You need to explain our thesis. . . but, we could not find your thesis practically, so I am confused, yeah. . . hum. yap.   
O: Did you wrote about. . .hum. . .   
B: I thought you tried to touch upon the religion? I cannot actually tell what you meant by moral. . .   
O: Yes, I couldn’t understand that. . .   
B: OK. What do you have to say. .   
J: Yes, I think, I did not explain my thesis well. . .   
B: The second question: Did the paper answer the question regarding ‘‘why the fable was written as it was written? (If not, how could it be improved?) In your introduction, you did not really need to summarize the plot, you know, I think in your second paragraph can summarize the plot. And again the thesis of your second paragraph just touches too much on the moral of the story, the deeper issues that lie behind. . .why the morals were written. You can go deeper.   
O: I also think that she summaries the story in the introduction, and about the thesis statement she is like. . . . use the plot of the story. . . That’s all I have to say.   
A: Well, in the introduction, I could find the moral, however, I think you did not touch on the thesis, like separate, right, how come you did not write the thesis in the introduction?   
B: Since she included the summary of the plot, and that was not necessary to summarize first. So she did not go straight to the thesis statement. And the third question: How could this paper . . hum, yes, just like put more emphasis on the meaning of the story instead of the moral, I mean, you could talk about the morals, but, how were the particular events of the story, like, meaningful, you know, like how they related to you thesis, rather than stating the moral. For morals are just obvious. . .   
O: In my opinion, I think she needs to improve her introduction, basically the first paragraphs are OK, she used several actual examples and I suggest she just works on the introduction.   
A: I think what don’t you narrow your focus on about one paragraph, yeah, I think it’s better. . . I don’t know, it’s my opinion. . .[laugh]   
B: So now we move to Orlando’s paper.

# Appendix B. MOO interaction transcription segment

– Start log: Monday, February 7, 2000 9:45:45 am OldPuebloMOO time–

Christian arrives.   
Vayomi arrives.   
Christina arrives.   
Christina oks.   
Christina says, ‘‘but i think you should be more careful with the grammar . . . the use of past and future tenses’’   
Christina says, ‘‘hellow?’’   
Christian says, ‘‘hi’’   
Vayomi says, ‘‘Hello’’   
Christina says, ‘‘vayomi i read your paper ’’   
Christian says, ‘‘’what do you mean?’’   
Christian says, ‘‘come on, explain youself’’   
Vayomi says, ‘‘about what’’   
Christina says, ‘‘but there was a problem i saved my review and it couldn’t come up’ Christina says, ‘‘anyway i have some comments on it’’   
Christian says, ‘‘I read your paper Vayomi’’   
Christina says, ‘‘you should pay more attention to the grammar’’   
Vayomi says, ‘‘O.K. so what do u thin’’   
Christian says, ‘‘i think it was ok’’   
Vayomi says, ‘‘tell me what was wrong’’   
Christian says, ‘‘mmm. . ..’’   
Christian says, ‘‘don’t remember’’   
Christina says, ‘‘and there were some paragraphs that need more explanation too’’ Christian says, ‘‘ oyeah’’   
Christian says, ‘‘oh oh’’   
Michael arrives.   
Vayomi says, ‘‘What paragraphs’’   
Christian says, ‘‘hi michael’’   
Michael says, ‘‘HEY’’   
Christian says, ‘‘u wrote aboout Jack’’   
Christian says, ‘‘what happened, man?’’   
Michael says, ‘‘hey christine’’   
Michael says, ‘‘err your paper sucked’’   
Vayomi says, ‘‘Hi Michael’’   
Michael says, ‘‘hehehe’’   
Christina says, ‘‘for example the characterization of hansel . . .. you need to ve more vary at the end of the paragraphs. . .. it sounds like repetition’’   
Michael says, ‘‘ok listen’’   
Michael says, ‘‘i tihnk youre a bit too formal on the whole thing’’   
Christina says, ‘‘thank you michael’’ Christian says, ‘‘who r u talking to?’’   
Michael says, ‘‘umm that was a joke’’   
Christian says, ‘‘give names’’   
Christina says, ‘‘michael i could not even open your file’’   
Michael says, ‘‘ok listen umm nice definitions ’’   
Christina says, ‘‘mike that’s ok ;) ’’   
Michael says, ‘‘you coudlnt?’’   
Michael says, ‘‘oh gee my file is special’’   
Christina says, ‘‘mike: nope. . ..   
Christian says, ‘‘hahaha’’   
Christian says, ‘‘ok, lets talk about christina’’   
Michael says, ‘‘umm whos who in here?’’   
Christina says, ‘‘mike: sure’’   
Vayomi says, ‘‘It was o.k. I thought’’   
Christian says, ‘‘come on girl, how come the author could be influenced by   
feminism?’’   
Christina says, ‘‘vayoumi : your thesis was very clear but it needs more proofs though ’’   
Michael says, ‘‘christine yeah i thought that too’’   
Michael says, ‘‘bout the feminism thing’’   
Michael says, ‘‘GIVE EM HELL’’   
Michael says, ‘‘hehe’’   
Christian says, ‘‘hahahaha’’’’   
Michael says, ‘‘hey vayomi ’’   
Christina says, ‘‘christian: i would say so . . . because you never know it’s just an assumption’’   
Michael says, ‘‘is she in here?’’   
Christian says, ‘‘well, thats true’’   
Michael says, ‘‘HEY VAYOMI’’   
Christina says, ‘‘hmmm don’t you think that could be one of the social influences that might give him some different perspective ?’’   
Michael says, ‘‘EARTH TO VAYOMI’’   
Vayomi says, ‘‘Hey’’   
Michael says, ‘‘ok i think you shouldnt try to define the fable definition at the intro’’ Christian says, ‘‘feminism didnt start ’till the $6 0 \mathrm { { ^ \circ s } }$ ’   
Michael says, ‘‘i thinks its a bit too formal’’   
Christina says, ‘‘christian your paper was ok :) . . .. need to pay attention to tenses . . . grammar past or present ’’   
Michael says, ‘‘the $6 0 \mathrm { { ^ \prime s } }$ ruled’’   
Christian says, ‘‘yeah!’’   
Christian says, ‘‘ok, lets talk about me’’   
Christina says, ‘‘christian it has a lot of cool vocab. . .. nice job’’   
Michael says, ‘‘vayomi i think the many naming things also are a bit off track’’

# References

Amores, M. J. (1997). A new perspective on peer-editing. Foreign Language Annals, 30(4), 513–523.   
Beauvois, M. H., & Eledge, J. (1996). Personality types and megabytes: Student attitudes toward computer mediated communication (CMC) in the language classroom. CALICO Journal, 13, 27–45.   
Belcher, D. (1990). Peer vs. teacher response in the advanced composition class. Issues in Writing, 2(2), 128–150.   
Belcher, D. (1999). Authentic interaction in a virtual classroom: leveling the playing field in a graduate seminar. Computers and Composition, 16, 253–267.   
Berg, E. C. (1999). The effects of trained peer response on ESL students’ revision types and writing quality. Journal of Second Language Writing, 8(3), 215–241.   
Braine, G. (1997). Beyond word processing: Networked computers in ESL writing classes. Computers and Composition, 14, 45–58.   
Brown, P., & Levinson, S. D. (1987). Politeness: Some universals in language usage. Cambridge: Cambridge University Press.   
Caulk, N. (1994). Comparing teacher and student responses to written work. TESOL Quarterly, 28(1), 181–188.   
Chaudron, C. (1984). The effects of feedback on students’ composition revisions. RELC Journal, 15, 1–16.   
Cheong, L. K. (1994). Using annotation in a process approach to writing in a Hong Kong classroom. TESL Reporter, 27(2), 63–73.   
Connor, U., & Asenavage, K. (1994). Peer response groups in ESL writing classes: how much impact on revision? Journal of Second Language Writing, 3(3), 257–276.   
Egbert, J., Chao, C., & Hanson-Smith, E. (1999). Computer-enhanced language learning environments: an overview. In J. Egbert, & E. Hanson-Smith (Eds.), CALL environments (pp. 1–16). Virginia: Alexandria: TESOL Publishers.   
Fanderclai, T. L. (1995). MUDs in education: New environment, new pedagogies. Computer-Mediated Communication Magazine, 2, 8–10.   
Goffman, E. (1967). Interaction rituals: essays on face-to-face behavior. New York: Anchor Books.   
Harris, K. (1995, Autumn). Internet in the classroom: a gold mine or a lot of hype? (15 paragraphs). CALL Review: The Journal of the IATEFL Computer Special Interest Group. Available http://www. iatefl.org/calrevnv.html.   
Hedgcock, J., & Lefkowitz, N. (1992). Collaborative oral/aural revision in foreign language writing instruction. Journal of Second Language Writing, 1, 255–276.   
Kasper, G., & Kellerman, E. (1997). Communication strategies. New York: Longman.   
Kern, O. R. (1992). The use of synchronous computer networks in second language instruction: a preliminary report. Foreign Language Annals, 25, 441–454.   
Kern, R. G. (1995). Restructuring classroom interaction with networked computers: effects on quantity and characteristics of language production. The Modern Language Journal, 79, 457–476.   
Leki, I. (1990). Coaching from the margins: Issues in written response. In B. Kroll (Ed.), Second language writing: research insights for the classroom (pp. 57–68). New York: Cambridge University Press.   
Liu, J. (2000). Understanding Asian students’ oral participation models in American classrooms. Journal of Asian Pacific Communication, 10(1), 155–189.   
Liu, J. (2001). Asian students’ classroom communication patters in US universities: an emic perspective. Westport, CT: Ablex Publishing.   
Liu, J., & Hansen, J. (2002). Peer response in second language writing classrooms. Ann Arbor: University of Michigan Press.   
Lockhart, C., & Ng, P. (1995). Analyzing talk in peer response groups: stances, functions, and content. Language Learning, 45, 605–655.   
McGroarty, M. E., & Zhu, W. (1997). Triangulation in classroom research: a study of peer revision. Language Learning, 47(1), 1–43.   
Mendonc¸ a, C. O., & Johnson, K. E. (1994). Peer review negotiations: Revision activities in ESL writing instruction. TESOL Quarterly, 28(4), 745–769.   
Nelson, G. L., & Murphy, J. M. (1992). An L2 writing group: task and social dimensions. Journal of Second Language Writing, 1, 171–193.   
Nelson, G. L., & Murphy, J. M. (1993). Peer response groups: do L2 writers use peer comments in revising their drafts? TESOL Quarterly, 27, 135–142.   
Partridge, K. L. (1981). A comparison of the effectiveness of peer vs. teacher evaluation for helping students of English as a second language to improve the quality of their written compositions. Unpublished master’s thesis, University of Hawaii at Manoa, Honolulu.   
Paulus, T. M. (1999). The effect of peer and teacher feedback on student writing. Journal of Second Language Writing, 8(3), 265–289.   
Reid, E. (1994). Cultural formations in text-based virtual realities. Unpublished master’s thesis, University of Melbourne, Melbourne, Australia. Available http://people/we.mediaone.net/elizrs/cult-form.html.   
Rheingold, H. (1993). A slice of life in my virtual community. In Linda M. Harasim (Ed.), Global networks: computers and international communication (pp. 57–80). Cambridge, MA: MIT Press.   
Snookes, P. (1995, Autumn). Using the Internet for interactive text-based communication and learning (15 paragraphs). CALL Review: The Journal of the IATEFL Computer Special Interest Grou. Available: http://www.iatefl.org/calrevnv.html.   
Sproull, L., & Kiesler, S. (1991). Connections: New ways of working in the networked organization. Cambridge, MA: MIT Press.   
Stanley, J. (1992). Coaching student writers to be effective peer evaluators. Journal of Second Language Writing, 1, 217–233.   
Sullivan, N., & Pratt, E. (1996). A comparative study of two ESL writing environments: a computerassisted classroom and a traditional oral classroom. System, 29, 491–501.   
Tsui, A. (1999). Young ESL writers’ responses to peer and teacher comments in writing. The Proceedings of the Eighth International Symposium on English Teaching (pp. 95–109). Taipei, Taiwan: The Crane Publishing Co. Ltd.   
Tsui, A., & Ng, M. (2000). Do secondary L2 writers benefit from peer comments? Journal of Second Language Writing, 9(2), 147–170.   
Villamil, O. S., & de Guerrero, M. C. M. (1998). Assessing the impact of peer revision on L2 writing. Applied Linguistics, 19(4), 491–514.   
Vygotskii, L. S. (1978). Mind in society: the development of higher psychological processes. Cambridge: Harvard University Press.   
Warschauer, M. (1996). Comparing face-to-face and electronic discussion in the second language classroom. CALICO Journal, 13, 7–26.   
Wolcott, H. F. (1994). Transforming qualitative data: Description, analysis, and interpretation. Thousand Oaks, CA: Sage Publications.

Jun Liu is assistant professor in the Department of English at the University of Arizona, where he teaches in the English Language/Linguistics MA Program and the Second Language Acquisition and Teaching Interdisciplinary Doctoral Program. His research interests include classroom SLA research, L2 writing, language and intercultural communication, and language teaching methodology.

Randall Sadler is a PhD candidate in the Second Language Acquisition and Teaching Program at the University of Arizona. His research interests include L2 writing, the use of technology in the classroom, and qualitative research in the classroom. He is the co-editor of A Student’s Guide to First-Year Composition.