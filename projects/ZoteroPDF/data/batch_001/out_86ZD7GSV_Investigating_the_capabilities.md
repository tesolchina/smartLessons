# Journal Pre-proof

Investigating the capabilities of large language model-based task-oriented dialogue chatbots and the impact of "suggest replies" function from a learner's perspective Jang Ho Lee, Dongkwang Shin, Yohan Hwang

PII: S0346-251X(24)00320-8   
DOI: https://doi.org/10.1016/j.system.2024.103538   
Reference: SYS 103538

To appear in: System

Received Date: 22 November 2023

Revised Date: 1 October 2024

Accepted Date: 3 November 2024

# Investigating the capabilities of large language model-based taskoriented dialogue chatbots and the impact of "suggest replies"' function from a learner's perspective

Jang Ho Leea, Dongkwang $\operatorname { S h i n } ^ { \mathrm { b } * }$ and Yohan Hwangc

"Department of English Education, Chung-Ang University, Seoul, Republic of Korea; Department of English Education, Gwangju National University of Education, Gwangju, Republic of Korea; Department of English Language and Literature, Jeonbuk National University, Jeonju, Republic of Korea

\*Corresponding Author

Credit

Jang Ho Lee: Data Curation, Conceptualization, Investigation, Writing - Original Draft Preparation, Writing - Review & Editing

Dongkwang Shin: Conceptualization, Methodology, Resources, Writing - Original Draft Preparation

Yohan Hwang: Writing - Original Draft Preparation, Writing - Review & Editing, Visualization

ORCID of all authors Jang Ho Lee: 0000-0003-2767-3881 Dongkwang Shin: 0000-0002-5583-0189 Yohan Hwang: 0000-0003-3688-4779

# Acknowledgements

This manuscript has not been published or presented elsewhere in part or in entirety and is not under consideration by another journal. All study participants provided informed consent. We have read and understood your journal's policies, and we believe that neither the manuscript nor the study violates any of these. There are no conflicts of interest to declare. We used AI tool Poe, to generate the research materials for the present study. There is no funding to report.

# Author biographies

Jang Ho Lee received his DPhil in education from the University of Oxford, and is presently a Professor at Chung-Ang University, South Korea. His areas of interest are CALL, L1 use in L2 teaching, and vocabulary acquisition.

E-mail: jangholee@cau.ac.kr

Dongkwang Shin received his PhD in Applied Linguistics from Victoria University of Wellington and is currently a Professor at Gwangju National University of Education, South Korea. His research interests include corpus linguistics, CALL, and AI-based language learning. All correspondence regarding this publication should be addressed to him.

E-mail: sdhera@gmail.com

Yohan Hwang is an assistant professor of Department of English Language & Literature at Jeonbuk National University in South Korea. He holds a Ph.D. in Language and Literacy Education with a specialization of TESOL and World Language Education from the University of Georgia. His research interests include AI-based language instruction and prompt literacy development.

E-mail: baseble@naver.com

# Investigating the capabilities of large language model-based taskoriented dialogue chatbots and the impact of "suggest replies" function from a learner's perspective

# ABSTRACT

Second language (L2) learning has explored ways to maximize the benefits of using chatbots as a pedagogical resource for language practice and development. Given the growing consensus regarding the need to develop task-oriented dialogue (TOD) chatbots specifically designed for language learning purposes and recent advances in large language models (LLMs), the present study investigates the capabilities of LLM-based TOD chatbots from L2 learners' perspectives. To this end, we developed two TOD conversational agents using Poe Artificial Intelligence (AI), which provides easy-to-use LLM-based chatbot-building tools. South Korean undergraduate L2 students were asked to engage in two chatbot-based linguistic tasks and complete a survey regarding their perceptions of LLM-based TOD chatbots. The results showed that the utterances generated by these state-of-the-art chatbots were perceived as very natural, and they were found to be highly capable of understanding dialogues in context and keeping track of the progress of the conversation to produce contextually appropriate responses to the user's input. These chatbots were rated positively overall in terms of their usefulness as a resource for L2 learning, as learners are motivated and remain interested in engaging in conversations with chatbots, thus maximizing learning effects.

Keywords: artificial intelligence, ChatGPT, large language model, second language learning, task-based learning, task-oriented dialogue chatbots

# 1. INTRODUCTION

For more than a decade, the field of second language (L2) teaching and learning has welcomed chatbots as a potential pedagogical tool, with this resource being proposed to expand the L2 teaching paradigm (e.g., Fryer et al., 2020; Jeon, 2021; Lee et al., 2020). Since their inception, chatbots have been proposed as a method to assist L2 learners with language practice. Several studies have revealed that chatbots aid L2 learners with communication opportunities (e.g., Ji et al., 2023; Fryer & Carpenter, 2006), motivation and speaking anxiety (e.g., Chien et al., 2022; Jeon, 2022), language-related feedback (e.g., Hew et al., 2022), and language assessment (e.g., Jeon, 2021). When chatbots are integrated with goal-oriented and task-based language learning, they are expected to have a greater educational impact (Hew et al., 2022; Jeon, 2022). Under these circumstances, there are cases where general-purpose chatbots are available online (e.g., Kuki, Cleverbot, and Mondley) or via speech-recognition devices (e.g., Amazon Alexa, Google Home, and Apple Siri) (Dizon, 2020; Xu et al., 2021). Additionally, cases in which teachers develop chatbots suitable for lesson objectives using user-friendly chatbot application programming interface (API) programs exist (e.g., Dialogflow, Clova) (Jeon, 2022; Yang et al., 2022).

Both cases have their advantages and disadvantages. Standard non-educational conversational chatbots have limitations in representing learning situations specifically tailored to student needs. Because they rely on scripted inputs and pre-stored response databases, they cannot provide the feeling of conversing with a real person (Jeon & Lee, 2023). From this perspective, a more recent strand of L2 research has focused on the need to develop TaskOriented Dialogue (TOD) chatbots specifically designed for L2 learning (e.g., AUTHOR, 2022). The recent meta-analyses results (e.g., Jeon et al., 2023; AUTHOR, 2022; S. Zhang et al., 2023) and learner perception studies (e.g., Jeon, 2022; Yang et al., 2022) add credibility to the proposition that purpose-built TOD chatbots have significant potential in L2 teaching and learning. According to AUTHOR (2022), the educational effect of TOD chatbots is greater than that of standard chatbots. However, chatbots created by teachers for specific lessons have limitations in recognizing contexts outside the preset scenarios. Dialogue is only possible within a confined context, depriving learners of autonomy in driving conversations and thereby limiting learner participation and engagement (AUTHOR, 2022). This emphasizes the importance of the human teacher's role, which provides additional help in a complementary manner, even when using TOD chatbots (Ji et al., 2023).

However, the recent emergence of large language models (LLMs) has overcome the limitations of traditional chatbot use (Zhai, 2022), offering a new chatbot-human communication experience (Jeon & Lee, 2023; Kasneci et al., 2023). Thus, an increasing interest exists in using Open's GPT series and other text-based generative Artificial Intelligence (AI) in English classrooms (Kohnke et al., 2023; Liu & Ma, 2023). However, this approach has some limitations, such as issues related to trustworthiness, dependability, and excessive student dependence (Ulla et al., 2023). More importantly, teachers cannot directly control the conversation scope, and chatbot responses can sometimes diverge from the lesson topic (AUTHOR, 2022). Therefore, to maximize the benefits of both conventional and generative AI chatbots, researchers have recently attempted to develop TOD chatbots suitable for educational purposes using LLM models (Cao, 2023; Stasaski & Ramanarayanan, 2020; Q. Zhang et al., 2023). While these studies have paved the way for more effective chatbot integration in task-oriented learning, few have validated the efficacy of LLM-based TOD chatbots and how they assist L2 learners in language classrooms. To this end, this study aims to examine users' perspectives of LLM-based chatbots by building two TOD conversational agents and administering them to undergraduate English as a Foreign Language (EFL) learners to understand their perceptions.

The remainder of this paper is as follows. Section 2 provides a brief background of AI chatbots. Section 3 presents Poe AI as the task-based chatbot employed, as well as the methods used in this study. Section 4 demonstrates the results derived from our study and the analysis. Section 5 provides the conclusions and limitations.

# 2. LITERATURE REVIEW

Given that chatbots are a potential pedagogical resource in language learning (Walker & White, 2013), early research on chatbots in the language learning domain has mostly examined chatbots built for non-educational purposes (e.g., Coniam, 2008, 2014; Fryer & Nakao, 2009). Notable examples include Apple's Siri, functioning as a virtual personal assistant on smartphones, and Kuki, a social chatbot developed as a conversation partner. These chatbots are rule-based because they predict responses based on scenarios or specific keywords and are, therefore, limited in understanding human context and do not act as natural conversational partners. For example, Coniam's (2014) study of five chatbots showed that despite their ability to generate grammatically correct sentences, these chatbots were unable to understand learners' utterances in context and thus respond appropriately. Furthermore, because these chatbots were not designed for language learning purposes, their application in L2 instruction is severely limited.

The aforementioned limitation has given rise to developing chatbots built specifically for language learning purposes using user-friendly APIs, with Google's Dialogflow being widely used to this end. In the context of compulsory courses for English for Academic Purposes (EAP) in an English-medium institution in Hong Kong, Kohnke (2022) developed a chatbot using Dialogflow designed to assist undergraduate students in engaging in tasks and searching for resources. Although this chatbot was not designed for language practice but to support students' task completion, it was considered more useful for this purpose than other existing chatbots because of the researcher's commitment to developing this chatbot with an understanding of the pedagogical contexts and students' needs. Ellie (AUTHOR, 2022) is another example specifically developed for EFL instruction using the Dialogflow platform. Ellie can employ a TOD system to help users achieve specific goals by considering their requirements, keeping track of the conversation's progress, and generating appropriate responses accordingly. It is designed to enable L2 learners to engage in various linguistic tasks, each with a specific mission. While Kohnke's chatbot and Ellie can be employed for language teaching and learning purposes, they have a similar limitation to scenario-based chatbots in that they may not respond well to utterances outside of the predefined conversation flow (AUTHOR, 2022).

LLMs (e.g, OpenAI's ChatGPT, Anthropic's Claude-3, and Meta's Llama) have revolutionized the field of chatbot applications by addressing the previously encountered challenges. These models have enabled conversational system creation that can leverage vast amounts of knowledge to generate humanlike responses (Kasneci et al., 2023). Moreover, they have been proven to be highly effective in analyzing the conversation context and providing relevant and coherent responses based on pre-trained data. Particularly, ChatGPT--the most popular example of LLM-based chatbots-can process and interpret user input, considering previous dialogue or prompts to generate contextually appropriate responses. This capability has led to the development of effective domain-specific question-answering chatbots (Zhai, 2022). However, without the developer's implementation of further modifications, these chatbots may have several degrees of freedom and limited pedagogical value. Thus, recent efforts have integrated TOD systems into LLM-based chatbots. Previous studies merging LLM and TOD employed the Bidirectional Encoder Representations from Transformers (BERT) language model, which have primarily focused on accurately understanding the meanings of words within sentences for natural language processing (Stasaski & Ramanarayanan, 2020). However, attention has now shifted to GPT models that understand the context of prior sentences and generate new texts, thus providing a more natural and sophisticated TOD experience. For example, Q. Zhang et al. (2023) proposed the "Ask an Expert' framework, allowing the GPT models to consult an expert during each turn, thus enhancing the fine-tuning of small models in TOD. Similarly, Cao (2023) developed DiagGPT, an AI-based chatbot comprising several modules in collaboration, including the chat agent, topic manager, topic enricher, and context manager, to provide accurate diagnostics and prescriptions to its users. DiagGPT can actively engage in professional consultations and functions as an intelligent and sophisticated LLM (GPT)-based TOD chatbot.

Based on the above review, GPT- and TOD-based chatbots can compensate for the limitations of previous chatbots based on: (1) rule-based systems; that is, the inability to understand the dialogue in context, and (2) those based on LLMs (e.g., ChatGPT) but lacking a TOD system--lack of pedagogical applications owing to various degrees of freedom. The development of such chatbots requires a considerable amount of computer programming knowledge. However, recently, OpenAI, the creator of ChatGPT, released My GPTs, a customizable up-to-date chatbot builder (OpenAI, 2023). It is designed to develop chatbots in much the same way as Poe AI's chatbot builder, allowing users to develop the chatbot they want by asking for it like a natural language conversation, and machine learning is also achieved by uploading the data needed for learning as a file, allowing for true no-code programming without complicated procedures like coding. At the time of the experiment in this study, Poe AI (https://poe.com/) was the only platform that could develop LLM-based chatbots in this way, so My GPTs could not be applied to the experiment. The release of My GPTs will undoubtedly be a catalyst to advance the era of Personal AI Assistant (PAA), but My GPTs are paid, while Poe AI is free, making it more accessible for use in the classroom. LLM-based TOD chatbots have the potential to rectify the shortcomings of traditional chatbots by providing humanlike, dialogue-driven, and task-oriented learning experiences. To provide empirical data, this study examines the experiences of undergraduate EFL learners using two TOD agents created via Poe AI as mentioned above. The primary research question of this study is as follows: What are L2 learners' perceptions of LLM-based TOD chatbots in terms of the naturalness of their language, their ability to understand dialogues in context, and their usefulness as L2 learning tools?

# 3. METHOD

# 3.1. Participants

Twenty-two undergraduate students majoring in English or general education at a private university in Seoul, South Korea participated in the study. They were registered in an English linguistics course and were either junior or senior students during the time of the study. According to the background survey questionnaire items (see Instrument for details), most participants $n = 1 7$ ) had taken a course on computer-assisted language learning in the current academic year in which they had been allowed to build their own chatbot for English learning via Dialogflow. The remaining participants had previous experience using virtual assistant software applications such as Apple's Siri and Google's Google Assistant. Participants were given detailed instructions about the study's purpose and informed that their identities would remain anonymous. They were also informed that they could opt out of the study without any disadvantages and would receive extra credit for their participation.

# 3.2. Building task-based chatbot activities using Poe AI

For this study, we developed two conversational agents (i.e., chatbots) for which participants were asked to complete two chatbot-based tasks. We decided to build two agents that differed in terms of the goal of the target task and the assumed relationship between the chatbot and the user, so that the idiosyncrasies of a particular conversational agent would not determine participants' overall perceptions of LLM-based chatbots. With the first agent, participants were expected to engage in a more routinized conversation in the situation of purchasing an airline ticket from the airline's agent, while they were asked to engage in a more free-form conversation seeking advice about insomnia with the second chatbot assuming the role of the participant's friend. Our decision to include these two different types of chatbots was based on the recently proposed design principle of L2-specific chatbots (Kim et al., 2022; Yang et al., 2022), which suggests that chatbot tasks consist of both more controlled and goal-specific ones (e.g., buying an airline ticket in our study) and less controlled and free-conversation-like ones (e.g., talking to one's friend about a concern in our study). It is also noteworthy that since previous chatbots of the latter type have been shown to have more limitations in general (e.g., communication breakdowns when unexpected utterances occur) (Fryer et al., 2020), the inclusion of these two types of chatbots may further reveal the potential of LLM-based chatbots compared to previous ones.

The first chatbot task involves the National Curriculum of English in South Korea (Ministry of Education, 2022), which is based on the model of the Notional-Functional Syllabus (van Ek & Alexander, 1975), where topics such as booking tickets are typical communicative functions and are very familiar to learners to practice communication patterns. The second task aims to motivate students to engage in conversations with the AI by addressing physical and mental health advice through human-chatbot interactions. This approach aims to help digital nagtive students who suffer from insomnia due to academic stress and smartphone addiction (Leow et al., 2023).

To create these conversational agents, we used Poe AI, which provides LLM-based chatbotbuilding tools. Unlike ChatGPT, Poe AI has the advantage of easily developing TOD chatbots for language learning using a no-code, prompt-only approach. We followed the procedure described below to create two conversational agents (Figure 1).

![](img/d579036b441a4631a6986d3accebdd19957ee551dd6ab4dade0d105b11447a80.jpg)  
Figure 1. The process of creating AirlineTicketingBot

The first conversational agent, named "AirlineTicketingBot,' was designed to engage English learners in practicing a dialogue about purchasing an airline ticket from the airline company's agent. In this task, participants were asked to provide details about their travel itinerary (e.g., destination and time of travel) and select the tier (or class) of the seat they wanted when asked by the agent. The following prompt was typed to create this agent:

PROMPT: You are a chatbot for learning English, and you play the role of a ticketing agent for Kor Airline. You can suggest differently priced tickets for different dates, and you can also consult on seat assignments. You can also create a scenario to explain Kor Airlines' rules for baggage weight. Never use obscene language. Never curse during the chat. However, please do not make your answer too long (e.g., within two sentences) and use an English level of K-10 (17 years old) or below.

In addition, we activated one of the functions in Poe called "Suggest replies," through which the agent offers a range of responses that a user can choose, given that the participants may be unfamiliar with expressions used when purchasing airline tickets (see Figure 2 for this function in the actual dialogue).

# AlrlineTicketingBot

Operated

ted by @OrderingBOT

6 monthly users2 followers

This chatbot is an English task-based chatbot for a fictional airline that is designed to learn expressions related to booking and purchasing flight tickets.

AlrlineTicketingBot P

Hello, welcome to Kor Airline! What can I help you?

![](img/37a5b01ca6fe2081dcd090d61a5aac4960e912f1adf20fcc84f8936325317f54.jpg)  
Figure 2. "Suggest Replies" Function in POE

With the second conversational agent, "InsomniaBot," the participants were asked to converse about seeking advice about insomnia. The instructions for this task were as follows: (1) tell the chatbot that you are suffering from insomnia, (2) ask for different methods to deal with insomnia, and (3) choose one method that you like and thank the chatbot for suggesting that method. The prompt used to build the agent was as follows:

PROMPT: You are a chatbot for learning English, and you play the role of a friend who helps the user sleep better. You can suggest different ways to sleep better. You should sound like you really care about your friend's concern. Never use obscene language. Never curse during the chat. Limit your sentences to two sentences per turn. Use an English level of K-10 (17 years old) or below.

# 3.3. Instrument

With the participant survey being the primary instrument for the present study, both previous survey-based studies on chatbots for L2 purposes (e.g., AUTHOR, 2022; Gallacher et al., 2018) and those evaluating the linguistic output of LLM-based agents (e.g., AUTHOR, 2023) were considered when designing the questionnaire items to be included in the manuscript (see Appendix for the questionnaire items included in the participant survey). We used Google Forms, through which we accessed the web addresses of conversational agents and posted the participant questionnaire.

The first section of the questionnaire asked about the participants' background information, including their previous experience of engaging in conversations with chatbots. In the second section of the first chatbot-based task (i.e., purchasing an airline ticket), the first conversational agent' address was given, and participants were asked to copy and paste their dialogue with the agent. This section also included three Likert-scale questionnaire items and paired open-ended responses for each item, where participants were asked to provide a rationale for choosing a particular scale. These three 5-point Likert-scale questionnaire items concerned the participants' perceptions of the naturalness of chatbot expressions, chatbots' comprehension level of conversation in contexts, and usefulness of the target chatbot-based task for English learning. The third section concerned the second chatbot-based task (i.e., seeking advice about insomnia). Cronbach's alpha values were calculated for the Likert-scale items, and were .62 for the items related to the naturalness of the chatbots' expressions (2b in Section 2 and 3b in Section 3 in the participant survey), .68 for the items related to the comprehension level of chatbot conversations in context (2c in Section 2 and 3c in Section 3 in the participant survey), and .71 for the items related to the usefulness of the target chatbots for English learning (2d in Section 2 and 3d in Section 3 in the participant survey). These relatively low Cronbach's $\alpha$ values may be due to too few items for each construct (e.g., Cortina, 1993; Tavakol & Dennick, 2011); there were only two - one for each chatbot task. Another possible explanation would be the low variability in the participants' responses (e.g., DeVellis & Thorpe, 2021; Kline, 2015), with most participants responding positively to the items (see 4. Results and Discussion). It is also possible that these values are the result of a rather poor internal consistency (which can sometimes be caused by a low interrelationship between items) (e.g., DeVellis & Thorpe, 2021; Tavakol & Dennick, 2011). Regarding this explanation, it is possible that the participants perceived the two chatbots as distinct entities despite similar questionnaire items being asked. Since the tasks performed by AirlineTicketingBot and InsomniaBot are inherently different, participants may have evaluated them based on different criteria, leading to variations in their responses. This may have contributed to the lower internal consistency between the items.

In the final section, through a checkbox question, participants were asked to provide their thoughts on the advantages (e.g., conversation opportunities, acquisition of chatbots' vocabulary and expressions, less tension and anxiety when communicating, interest in talking with the new technology) and disadvantages (e.g, the unnaturalness of conversation, contextually inappropriate responses, not comprehending the user's utterances, limitation of follow-up questions) of learning with the LLM-based TOD chatbot. Further, they were asked to reflect on what they found beneficial or lacking in using chatbots as an English learning resource compared with traditional methods of English conversation learning.

# 3.4. Data analysis

The participants' responses were recorded online and stored in CSV format.  First, we conducted a descriptive analysis of the Likert-scale items to gain a quantitative understanding of participants' reactions. Then, we conducted a comprehensive thematic analysis on the responses to open-ended questions, such as reasons for selecting a particular scale. This ensured a nuanced interpretation of the qualitative data. To address potential issues of researcher reflexivity and bias, three researchers independently coded the open-ended responses, which helped reduced personal biases and allowed for cross-verification of thematic interpretations. As recommended by Chandra and Shang (2022), we adopted inductive coding which allowed for the identification of emerging themes directly from the data. This approach ensured that the analysis was firmly rooted in participant responses.

Furthermore, to integrate the quantitative and qualitative findings and provide a comprehensive understanding of participants' perceptions of LLM-based TOD chatbots, we adopted a sequential explanatory strategy (Terrell, 2012). Quantitative data were first analyzed to establish patterns among the participants' perception, followed by a qualitative analysis that explored these patterns in depth. This method enabled us to map out how specific themes related to quantitative outcomes, enhancing the contextual richness of our findings. This mixed method helped clarify ambiguities in the open-ended responses and provided additional insights into participants' perceptions and experiences with chatbots.

# 4. RESULTS AND DISCUSSION

4.1. Naturalness of the LLM-based chatbot language

The first Likert-scale item asked about the participants' perception of the naturalness of the LLM-based TOD chatbot language. Overall, their evaluation of this aspect of chatbots was very positive $( M = 4 . 6 8 , S D = 0 . 4 8$ for AirlineTicketingBot, and $M = 4 . 7 7$ $S D = 0 . 5 3$ for InsomniaBot), with no participant opting for 1 (strongly disagree) or 2 (disagree) scales. This finding aligns with that of a recent study (AUTHOR, 2023), in which the naturalness of GPTgenerated reading passages was evaluated positively among South Korean pre- and in-service English teachers. The study findings further suggest that LLM-based TOD chatbots' language in dialogue can also be perceived as natural by L2 learners. As it can provide spontaneous and flexible responses, L2 learners transitioning from scripted inputs and pre-stored responses are likely to feel as if they are conversing with a real person (Jeon & Lee, 2023). Some of the participants' open-ended responses were as follows:

The [chatbot] language was easy to understand and natural, and it felt like chatting in a real-life situation. (Participant 5).

I felt like I was communicating with a native speaker [of English], and the chatbot's language sounded like what an airline employee would say. (Participant 8).

Unlike the first chatbot [AirlineTicketingBot], talking to this chatbot [InsomniaBot] was like a conversation between friends. (Participant 2).

The chatbot [InsomniaBot] didn't use any difficult words, and its language was very natural. (Participant 21).

In addition to the above comments, Participant 18 noted that the InsomniaBot's expressions, such as decaf (as in Try switching to decaf or herbal tea instead') and memory foam (as in "Experimenting with different pillow types, such as memory foam...") in providing better sleep recommendations, made her feel like she was talking to a real person.

# 4.2. Chatbots' comprehension of dialogue in contexts

The second Likert-scale item concerned the LLM-based TOD chatbots' comprehension of dialogue in context. This aspect was considered an important dimension for improvements in chatbot technology in L2 learning (Gallacher et al., 2018) and a limitation of non-LLM chatbots, such as a confined context outside of the preset scenarios (AUTHOR, 2022). The LLM-based TOD chatbots were perceived positively by the participants, with the majority of them either agreeing or strongly agreeing with the LLM-based TOD chatbots' capability to cope with various participants' responses in context ( $M = 4 . 6 4$ $S D = 0 . 9 0$ for AirlineTicketingBot, and $M$ $= 4 . 5$ $S D = 0 . 9 1$ for InsomniaBot). A relatively similar rating of two different types of chatbots here illustrates the improved conversational ability of LLM-based chatbots, especially in the less controlled and free-conversational mode (i.e., Insomniabot), which has been suggested to cause several communication breakdowns due to the earlier chatbot's lack of understanding of dialog in context. The following excerpts illustrate that participants perceived both types of chatbots to be well accommodating in the interaction:

I tried to create different problem situations [when booking an airline ticket], but in most cases, he [AirlineTicketingBot] was flexible enough to offer different suggestions. (Participant 12).

The chatbot [AirlineTicketingBot] was very understanding and accommodating when I asked questions other than the usual questions that you would ask. (Participant 22).

Although I purposely grumbled and argued back with silly responses to his [Insomnia Bot's] recommendations to deal with insomnia, he was sympathetic to what I had to say. Overall, I could tell he [InsomniaBot] had a good grasp of the context because he quickly came up with an appropriate answer. (Participant 2).

He [InsomniaBot] never once went off-topic and provided great answers that kept the conversation on track (Participant 8).

A careful examination of the dialogues revealed two excerpts, among which communication breakdown would occur if the chatbot was not based on an LLM. In Figure 3, instead of accepting the chatbot's offer of an airline ticket to complete the task, Participant 7 attempted to create a situation in which the chatbot would have to consider the user's budget and make arrangements accordingly. As shown in Figure 3, AirlineTicketingBot accommodated the participants' questions effectively without causing communication breakdown. Dizon and Tang (2020) discovered that EFL students often become discouraged and cease interacting when communicating with faltered chatbots. This finding can provide additional support for previous research that has examined the problems and limitations of communication breakdowns in human-chatbot communication (Dizon et al., 2022; Moussalli & Cardoso, 2020).

![](img/b6b76108dd8e9271ab1a52a16aedbe3a7d067ed88e15f6e46a0218b89f521d1c.jpg)  
Figure 3. Sample conversation between Participant 7 and AirlineTicketingBot

Ok I'll take that one then.

In another excerpt, Participant 4 attempted to construct a complex situation in which her insomnia was related to the upstairs noise. In this case, it can be expected that the chatbot's inability to understand dialogue in context would easily lead to communication breakdown. However, Figure 4 shows that InsomniaBot was able to consider Participant 4's previous utterance and the given complex situation when making another recommendation, thus demonstrating the remarkable ability of the LLM-based chatbot in this regard. Taken together, these examples show that communication breakdowns and low error tolerance, which would demotivate learners in terms of their engagement with the chatbot for their L2 learning and practice, as observed in previous chatbot research (e.g., Gallacher et al., 2018; Shin et al., 2021), can be largely remedied when using LLM-based chatbots. For EFL learners with limited English proficiency, engaging in real-life conversations that require specialized knowledge to be understood often requires relatively long pauses to allow time to think before speaking, which often leads to conversation breakdowns (van Lier, 1996). It is also common for chatbots that are limited in their ability to understand the context of a conversation, such as traditional chatbots, to break off the conversation if the learner's utterance is not presented immediately or is presented out of context (Hew et al., 2022; Kim et al., 2022). However, not only do LLMbased chatbots have superior contextual comprehension, but their chatbot nature also reduces learner anxiety associated with immediate response demands, as if they were communicating with a human interlocutor. Furthermore, given a certain amount of lexical and grammatical errors made by such learners could be tolerated by LLM-based chatbots, chatbot developers would no longer have to worry about a range of possible learner errors that had to be taken into account when building earlier chatbots not based on LLM technology, so that chatbots would be able to understand learner utterances as much as possible without causing communication breakdowns.

![](img/fee50507cb7b08fcf25fb5f6cb547561c3bcdb884b0357a7e467797057790fa4.jpg)  
Figure 4. Sample conversation between Participant 4 and InsomniaBot

# 4.3. Usefulness of LLM-based chatbots

Another Likert-scale item asked about participants' perception of the usefulness of LLMbased TOD chatbots in L2 instruction. Aligning with previous findings (e.g., Kohnke, 2023; Yang et al., 2023), the chatbots as a resource for L2 learning were evaluated positively by the participants in the current study ( $M = 4 . 3 2$ $S D = 0 . 7 2$ for AirlineTicketingBot, and $M = 4 . 2 7$ $S D = 1 . 0 3$ for InsomniaBot).

One of the strengths of the chatbots, as revealed in the participants' open-ended responses, was their ability to offer an authentic feeling of chatting in English due to LLM-based engines. Examples of the relevant responses are as follows:

I think this chatbot [AirlineTicketingBot] is able to respond to students' utterances in a variety of ways, reducing the number of errors and thus allowing students to focus on practicing English without any problems. (Participant 2).

The context of the conversation [with InsomniaBot] felt so authentic. (Participant 8). In the case of Insomniabot, I think it can have a positive effect on English learning by giving learners the feeling of talking to a real native speaker friend. (Participant 12).

For some participants, the aforementioned feelings of authenticity appeared to stem from the chatbot's capability to understand users' ungrammatical and incomplete utterances and respond properly without making errors.

This chatbot does not say, "I do not understand what you say," like other chatbots.   
(Participant 3).   
I made some errors, obviously, but somehow the chatbot understood what $I$ meant.   
(Participant 16).

This finding underscores the importance of integrating chatbots into both LLM and TOD systems. This integration can compensate for the limitations inherent in rule-based systems and pedagogical applications arising from excessive degrees of freedom (Cao, 2023; Zhai, 2022). By carefully examining all dialogues between the two task-based chatbots and the participants, we identified only one occasion of communication breakdown, as illustrated in Figure 5.

![](img/9267677b9dbe8fc45260b659733c5ba1fb87510766246750b3f0bc19b01d9f11.jpg)  
Figure 5. Sample conversation between Participant 3 and AirlineTicketingBot

In Figure 5, Participant 3 aimed to convey, I want to book my own ticket," after receiving sufficient information about his ticket to New York City from AirlineTicketingBot. However, the participant misspelled "want' as "went." AirlineTicketingBot appeared to take this participant's utterance (I want to book my own ticket') as a cue for initiating the conversation and gave a general introduction message, as shown above. Notably, however, this was the only case highlighting a communication breakdown out of the 44 dialogues (22 participants engaged in two chatbot-based tasks).

Moreover, we found that the LLM-based chatbot could understand the user's intended words or phrases, even if the user misspelled them (Fig. 6).

![](img/0523ef8a8692d1c90b109ecad13866dee8a170777b568c2f110d09a214cc2276.jpg)  
Figure 6. Sample conversation between Participant 1 and AirlineTicketingBot

Although Participant 1 misspelled "Dokyo" in Figure 6, AirlineTicketingBot was able to   
correct this typographical error. The chatbot understood the user's intended meaning, which   
was "Tokyo,' Japan's capital city and asked for clarification, Did you mean Tokyo?. This is   
a clear demonstration that LLM-based TOD chatbots clearly comprehend user utterances in   
context, pointing to an improvement over rule- or scenario-based chatbots, which may result   
in unsuccessful task completion owing to learners' ungrammatical or inappropriate responses   
(Yang et al., 2022). Another group of students cited the value of chatbots in providing several   
English expressions that might not have been available in formal instruction based on textbooks. $I t$ [chatbot] would be useful for English learning because it could allow students to learn English expressions by talking in different ways. (Participant 18).

First of all, I felt that I could learn a variety of English expressions because I didn't feel that the chatbot's responses were fixed like in textbooks or general English books. I also felt that I could learn more practical expressions by asking further questions to the chatbot. (Participant 19).

By reading the answers [given by AirlineTicketingBot], I think students can learn various vocabulary and expressions needed to book an airplane. (Participant 20).

Some participants suggested that the usefulness of task-based chatbots may depend on students' English proficiency levels, which could affect the quality and quantity of chatbot input (Fryer et al., 2020). Relevant excerpts are provided below.

I would expect the student to have some level of English proficiency for the chatbot-based language learning to be useful. (Participant 15).

Compared to previous ones, these chatbots are far better in terms of their communication ability. However, due to the nature of the chatbot itself, it is expected that the educational effect will vary depending on the learner's proficiency level as well as willingness to communicate [with chatbots]. (Participant 22).

Thus, aligning with previous studies (e.g., Jeon, 2022; Yang et al., 2022), the chatbot could be used more effectively when learners have passed a certain threshold level of English proficiency.

When comparing participants' responses regarding the usefulness of AirlineTicketingBot and InsomniaBot, different types of usefulness were pointed out by the participants. The usefulness of the former was related to providing a specific situation through which students could practice context-specific expressions, as illustrated in the following excerpts:

[With AirlineTicketingBot] It was useful to experience what phrases are used in a specific situation and how the conversation takes place in that context (Participant 7)

It was useful to experience specific real-life situations with AirlineTicketingBot'. (Participant 13)

Meanwhile, learners valued a less-controlled chatbot like InsomniaBot highly because it allowed them to practice expressions used in everyday communication, making them feel like they were talking to friends:

When I talked to the bot [InsomniaBot], it felt like talking to a friend, and thus practicing everyday conversation. (Participant 2)

I thought talking to the bot [InsomniaBot] was very useful because you can practice everyday conversational expressions. (Participant 10)

This finding suggests that different types of chatbots can be useful for different purposes. Structured chatbots like AirlineTicketingBot are effective for practicing specific, contextdependent language use, which is valuable for students in practicing particular communicative functions. On the other hand, less-controlled chatbots like InsomniaBot offer students the opportunity to engage in more natural and spontaneous interactions, which is essential for developing fluency and the ability to manage everyday conversations.

# 4.4. Advantages and disadvantages of LLM-based TOD chatbots

The participants were additionally asked to provide their thoughts on the advantages and disadvantages of chatbot-based language learning. Regarding advantages, the options mostly selected by the participants were "conversation opportunities" $( n \ = \ 1 7$ , "acquisition of chatbot's vocabulary and expressions" $( n ~ = ~ 1 7 )$ , and "less tension and anxiety when communicating" (compared to teacher or peer interaction) ${ \mathit { n } } = 1 5 $ . Although not a novel observation, given those presented in previous studies (e.g., Kohnke, 2023; Yang et al., 2022), some participants' open-ended responses offer new insights into the value of LLM-based chatbots, evident in the following excerpts:

I thought that ChatGPT uses a relatively consistent pattern of expression, but this chatbot seemed to use more realistic language and diverse patterns, so the conversation did not feel awkward and was interesting. (Participant 5).

It was good that the chatbot rarely failed to understand what I was saying. (Participant 13).

The chatbot's responses are incredibly natural and contextually accurate. (Participant 14).

Overall, these responses highlighted the enhanced capacity of LLM-based TOD chatbots as conversational partners in language learning contexts, given the findings related to the previous chatbots examined in earlier studies (Dizon, 2020; Kohnke, 2023), which often failed to comprehend users' utterances and made contextually inappropriate responses.

Despite such responses, some participants pointed to "unnaturalness of conversation" $\scriptstyle ( n =$ 14), "not comprehending my utterances $( n = 8 )$ , and "contextually inappropriate responses" $( n = 7 )$ , as the disadvantages of using chatbots in language learning. Thus, in view of the findings related to the questionnaire items on the advantages and disadvantages of using chatbots, we found some contrasting ideas about the value of LLM-based chatbots among the participants; some have spoken highly of the chatbots' communication capacity compared to earlier ones, whereas others have suggested otherwise. Such a difference among the participants' perceptions may have stemmed from differences among the participants' communicative competence levels; those with higher levels were more capable in engaging with the chatbot by making use of more comprehensible utterances and maintaining a conversation when the chatbot makes contextually inappropriate responses.

One of the participants' open-ended responses further revealed the need to develop chatbots that were visualized and animated (see AUTHOR, 2022 for a similar argument) and have a more realistic (informal) way of uttering:

However, since it's [the chatbot is] not a real person, you can't learn the accents, facial expressions, pauses, and speed of speech, all of which you can learn when talking to a real person. (Participant 20).

I wish the chatbot would use more informal expressions. (Participant 19)

In real conversations, when we talk, we often don't speak in sentences. I was disappointed that we [the participants and chatbots] only conversed in sentences. (Participant 7).

# 5. CONCLUSIONS

We implemented LLM-based TOD chatbots to engage learners in L2-specific tasks and examined L2 learners' perceptions of such chatbots. In the present study, LLM-based TOD chatbots were perceived very positively in terms of the naturalness of their linguistic expressions, as well as their ability to understand dialogues in context. With respect to the latter in particular, the ability of this cutting-edge chatbot to tolerate user errors, whether linguistic or contextual, is its significant advance over previous chatbots, which were rather fragile in terms of error tolerance and consequently caused communication breakdowns frequently (e.g., AUTHOR, 2022; Gallacher et al., 2018). Finally, these chatbots were positively evaluated by the participants as a resource for L2 instruction, although some suggestions for improvement were also made.

Based on the aforementioned findings, we suggest that LLM-based TOD chatbots could be an important pedagogical addition to L2 instruction. Primarily, as a strength of LLM-based chatbots, learners can freely learn the authentic expressions required in a specific domain without scenarios simply by specifying a specific situation and the role of interlocutors. Second, it effectively stimulates learner interest and motivation through conversations with chatbots whose language skills are indistinguishable from those of humans. Finally, as a goal-oriented chatbot that can utter expressions corresponding to performance standards, it can maximize learning effects even in natural conversations.

Based on these findings, we provide some considerations when using Poe AI. Given their ease of use, L2 teachers can access Poe and create their own chatbots using prompts once they have a specific L2 target task that can be used by their learners. In doing so, they are encouraged to explore the "Suggest replies' function in Poe, which can be activated if the teacher believes that his or her students have limited L2 proficiency in forming complete sentences. Moreover, it could be used by the learner in maintaining the conversation with the target chatbot by selecting one of the options suggested by the chatbot, especially if they cannot provide an appropriate response. In addition, given the participants' open-ended responses, instructors were encouraged to ensure that chatbot utterances were limited to two or three sentences per round; otherwise, the chatbot might have a verbose speaking style. Additionally, some participants stated that the chatbots felt like non-humans when they responded like "Is there anything else I can do for you?" in successive turns. Notably, all aspects can be controlled by phrases in the prompts.

The four limitations of this study should be considered in future L2 research on LLM-based chatbots. First, this study was a small-scale exploratory study with only two chatbot-based tasks. Future studies should consider more diverse types of chatbot-based tasks, which may reveal the technical and pedagogical limitations of LLM-based chatbots. Second, our study focused on learners' perceptions of the various aspects of LLM-based chatbots but did not measure the effects of such chatbots on L2 learning. A longitudinal study based on pre- and post-test designs is expected to further validate the usefulness of LLM-based chatbots in L2 instruction. Third, the reliability analysis of the Likert-scale items showed relatively low Cronbach's alpha values, which we acknowledge as another limitation of the study. As discussed above (see 3.3. Instrument section), there could be several explanations for this finding, and researchers are encouraged to pilot test, expand and refine our questionnaire when adapting it for their study. Finally, the study participants had relatively high levels of English proficiency and sufficient knowledge about computer-assisted language learning, and the extent to which these chatbots could accommodate learners with different profiles in these aspects remains unexplored (e.g., do students with lower levels of English proficiency and less experience with computer-assisted learning experience conversation breakdown more than others?). Therefore, future research should include learners with different learner profiles in these aspects and examine their interactions with LLM-based chatbots. Despite these limitations, future research with a larger number of participants and diverse types of task-based chatbots would strengthen our proposition.

# References

AUTHOR. (2022).   
AUTHOR. (2023).   
Cao, L. (2023). DiagGPT: An LLM-based chatbot with automatic topic management for taskoriented dialogue. arXiv. 2308.08043. https://doi.org/10.48550/arXiv.2308.08043   
Chandra, Y., & Shang, L. (2019). Qualitative Research Using R: A Systematic Approach. Springer: Singapore.   
Chien, Y., Wu, T., Lai, C., & Huang, Y. (2022). Investigation of the influence of artificial intelligence markup language-based LINE ChatBot in contextual English learning. Frontiers in Psychology, 13, 785752. https://doi.org/10.3389/fpsyg.2022.785752   
Coniam, D. (2008). Evaluating the language resources of chatbots for their potential in English as a second language. ReCALL, 20(1), 98-116. https://doi.org/10.1017/S0958344008000815   
Coniam, D. (2014). The linguistic accuracy of chatbots: usability from an ESL perspective. Text & Talk, 34(5), 545-567. https://doi.org/10.1515/text-2014-0018   
Cortina, J. M. (1993). What is coefficient alpha? An examination of theory and applications. Journal of Applied Psychology, 78(1), 98-104. https://doi.org/10.1037/0021- 9010.78.1.98   
DeVellis, R. F., & Thorpe, C. T. (2021). Scale development: Theory and applications. Sage.   
Dizon, G. (2020). Evaluating intelligent personal assistants for L2 listening and speaking development. Language Learning and Technology, 24(1), 16-26. https://doi.org/10125/44705   
Dizon, G., & Tang, D. (2020). Intelligent personal assistants for autonomous second language learning: An investigation of Alexa. JALT CALL Journal, 16(2), 107-120. https:/doi.org/10.29140/jaltcall.v16n2.273   
Dizon, G., Tang, D., & Yamamoto, Y. (2022). A case study of using Alexa for out-of-class, self-directed Japanese language learning. Computers & Education: Artificial Intelligence, 3, 100088. https://doi.org/10.1016/j.caeai.2022.100088   
Fryer, L. K., & Carpenter, R. (2006). Emerging technologies - bots as language learning tools. Language Learning & Technology, 10(3), 8-14. http://dx.doi.org/10125/44068   
Fryer, L., Coniam, D., Carpenter, R., & Lapusneanu, D. (2020). Bots for language learning now: Current and future directions. Language Learning & Technology, 24(2), 8-22. http://hdl.handle.net/10125/44719   
Fryer, L., & Nakao, K. (2009). Assessing chatbots for EFL learner use. In A. Stoke (Ed.), JALT2008 conference proceedings (pp. 849-857). JALT.   
Gallacher, A., Thompson, A. & Howarth, M. (2018) "My robot is an idiot!" - Students' perceptions of AI in the L2 classroom. In P. Taalas, J. Jalkanen, L. Bradley & S. Thouesny (Eds.), Future-proof CALL: Language learning as exploration and encounters: Short papers from EUROCALL 2018 (pp. 70-76). Researchpublishing.net. https://doi.org/10.14705/rpnet.2018.26.815   
Hew, K. F., Huang, W., Du, J., & Jia, C. (2022). Using chatbots to support student goal setting and social presence in fully online activities: Learner engagement and perceptions. Journal of Computing in Higher Education, 35, 40-68. https://doi.org/10.1007/s12528-022-09338-x   
Jeon, J. (2021). Chatbot-assisted dynamic assessment (CA-DA) for L2 vocabulary learning and diagnosis. Computer Assisted Language Learning. Advance online publication. https://doi.org/10.1080/09588221.2021.1987272   
Jeon, J. (2022). Exploring AI chatbot affordances in the EFL classroom: Young learners' experiences and perspectives exploring AI chatbot affordances in the EFL classroom: Young learners' experiences. Computer Assisted Language Learning. Advance online publication. https://doi.org/10.1080/09588221.2021.2021241   
Jeon, J., & Lee, S. (2023). Large language models in education: A focus on the complementary relationship between human teachers and ChatGPT. Education and Information Technologies. Advance online publication. https://doi.org/10.1007/s10639-023-11834-1   
Jeon, J., Lee, S., & Choe, H. (2023). Beyond ChatGPT: A conceptual framework and systematic review of speech-recognition chatbots for language learning. Computers & Education, 206, 104898. https://doi.org/10.1016/j.compedu.2023.104898   
Ji, H., Han, I., & Ko, Y. (2023). A systematic review of conversational AI in language education: Focusing on the collaboration with human teachers. Journal of Research on Technology in Education, 55(1), 48-63. https://doi.org/10.1080/15391523.2022.2142873.   
Kasneci, E., Sessler, K., Kuichemann, S., Bannert, M., Dementieva, D., Fischer, F., Gasser, U., Groh, G., Gunnemann, S., Hullermeier, E., Krusche, S., Kutyniok, G., Michaeli, T., Nerdel, C., Pfeffer, J., Poquet, O., Sailer, M., Schmidt, A., Seidel, T., & Kasneci, G. (2023). ChatGPT for good? On opportunities and challenges of large language models for education. Learning and Individual Differences, 103, 102274. https://doi.org/10.1016/j.lindif.2023.102274   
Kim, H., Yang, H., Shin, D., & Lee, J. H. (2022). Design principles and architecture of a second language learning chatbot. Language Learning & Technology, 26(1), 1-18. http://hdl.handle.net/10125/73463   
Kline, P. (2015). A handbook of test construction (psychology revivals): Introduction to psychometric design. Routledge.   
Kohnke, L. (2022). A pedagogical chatbot: A supplemental language learning tool. RELC Journal. Advance online publication. https://doi.org/10.1177/00336882211067054   
Kohnke, L. (2023). L2 learners' perceptions of a chatbot as a potential independent language learning tool. International Journal of Mobile Learning and Organisation, 17(1-2), 214-226. https://doi.org/10.1504/IJMLO.2023.128339   
Kohnke, L., Moorhouse, B. L., & Zou, D. (2023). ChatGPT for language teaching and learning. RELC Journal. Advance online publication. https://doi.org/10.1177/00336882231162868   
Leow, M. Q. H., Chiang, J., Chua, T. J. X., Wang, S., & Tan, N. C. (2023). The relationship between smartphone addiction and sleep among medical students: A systematic review and meta-analysis. PLoS ONE, 18(9), e0290724. https:/doi.org/10.1371/journal.pone.0290724   
Liu, G., & Ma, C. (2023). Measuring EFL learners' use of ChatGPT in informal digital learning of English based on the technology acceptance model. Innovation in Language Learning and Teaching. Advance online publication. https://doi.org/10.1080/17501229.2023.2240316   
Ministry of Education, South Korea. (2022). 2022 Revised National Curriculum of English (MOE Notice No. 2022-33: Appendix 14). MOE.   
Moussalli, S., & Cardoso, W. (2020). Intelligent personal assistants: Can they understand and be understood by accented L2 learners? Computer Assisted Language Learning, 33(8), 865-890. https://doi.org/10.1080/09588221.2019.1595664   
OpenAI. (2023, November 6). ChatGPT--Release Notes: Introducing GPT. https://help.openai.com/en/articles/6825453-chatgpt-release-notes   
Shin, D., Kim, H., Lee, J. H., & Yang, H. (2021). Exploring the use of an artificial intelligence chatbot as second language conversation partners. Korean Journal of English Language and Linguistics, 21, 375-391. http://doi.org/10.15738/kjell.21..202104.375   
Stasaski, K., & Ramanarayanan, V. (2020). Automatic feedback generation for dialog-based language tutors using transformer models and active learning. Paper presented at the 34th Conference on Neural Information Processing Systems: NeurIPS 2020, Vancouver, Canada.   
Tavakol, M., & Dennick, R. (2011). Making sense of Cronbach's alpha. International Journal of Medical Education, 2, 53-55. https://doi.org/10.5116/ijme.4dfb.8dfd   
Terrell, S. R. (2012). Mixed-methods research methodologies. The Qualitative Report, 17(1), 254-280. https://doi.org/10.46743/2160-3715/2012.1819   
Ulla, M. B., Perales, W. F., & Busbus, S. O. (2023). To generate or stop generating response': Exploring EFL teachers' perspectives on ChatGPT in English language teaching in Thailand. Learning: Research and Practice. Advance online publication. https://doi.org/10.1080/23735082.2023.2257252   
van Ek, J. A., & Alexander, L. G. (1975). Threshold level English. Pergamon Press.   
van Lier, L. (1996). Interaction in the language curriculum: Awareness, autonomy, and authenticity. Longman.   
Walker, A., & White, G. (2013). Technology enhanced language learning: Connecting theory and practice. Oxford University Press.   
Xu, Y., Wang, D., Collins, P., Lee, H., & Warschauer, M. (2021). Same benefits, different communication patterns: Comparing Children's reading with a conversational agent vs. a human partner. Computers & Education, 161, 104059. https:/doi.org/10.1016/j.compedu.2020.104059   
Yang, H., Kim, H., Lee, J. H., & Shin, D. (2022). Implementation of an AI chatbot as an English conversation partner in EFL speaking classes. ReCALL, 34(3), 327-343. https://doi.org/10.1017/S0958344022000039   
Zhai, X. (2022). ChatGPT User Experience: Implications for education. SSRN Scholarly Paper. 4312418. http://dx.doi.org/10.2139/ssrn.4312418   
Zhang, Q., Naradowsky, J., & Miyao, Y. (2023). Ask an expert: Leveraging language models to improve strategic reasoning in goal-oriented dialogue models. arXiv. 2305.17878. https://doi.org/10.48550/arXiv.2305.17878   
Zhang, S., Shan, C., Lee, J. S. Y., Che, S., & Kim, J. H. (2023). Effect of chatbot-assisted language learning: A meta-analysis. Education and Information Technologies. Advance online publication. https://doi.org/10.1007/s10639-023-11805-6

Appendix. The Participant Survey

# Section 1: Background Information

1. Name   
2. Major   
3. Year of undergraduate study   
4. Describe your experience of using chatbots in English.   
5. How would you rate your English proficiency level? (0-10).

# Section 2: Task with AirlineTicketingBot

2a. After talking to AirlineTicketingBot, please copy and paste your dialogue with AirlineTicketingBot here.

2b. AirlineTicketingBot's English is natural.

<html><body><table><tr><td colspan="4">Strongly disagree &gt; Strongly agree</td></tr><tr><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr></table></body></html>

2c. AirlineTicketingBot understands conversations in context well.

<html><body><table><tr><td colspan="4">Strongly disagree &gt; Strongly agree</td></tr><tr><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr></table></body></html>

2d. I believe AirlineTicketingBot is useful for learning English.

<html><body><table><tr><td colspan="4">Strongly disagree &gt; Strongly agree</td></tr><tr><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr></table></body></html>

2e. Please provide your reason for choosing a particular scale in 2d.

# Section 3: Task with InsomniaBot

3a. After talking to InsomniaBot, please copy and paste your dialogue with InsomniaBot here.

3b. InsomniaBot speaks English naturally.

<html><body><table><tr><td colspan="4">Strongly disagree &gt; Strongly agree</td></tr><tr><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr></table></body></html>

3c. InsomniaBot effectively comprehends conversations according to context.

<html><body><table><tr><td colspan="4">Strongly disagree &gt; Strongly agree</td></tr><tr><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr></table></body></html>

3d. I think InsomniaBot is beneficial for learning English.

<html><body><table><tr><td colspan="4">Strongly disagree &gt; Strongly agree</td></tr><tr><td></td><td>2</td><td>3</td><td>4</td><td>5</td></tr></table></body></html>

3e. Please provide your reason for choosing a particular scale in 3d.

# Section 4: Opinions on the pros and cons of language learning with the LLM-based chatbots

4a. In your opinion, what are the benefits of chatbot-assisted language learning? (you may choose more than one option) Conversation opportunities Acquisition of chatbots' vocabulary and expressions e-prooi Less tension and anxiety when communicating Interest in talking with the new technology Others (specify)

4b. In your opinion, what are the challenges of chatbot-assisted language learning? (you may choose more than one option)

The unnaturalness of conversation Contextually inappropriate responses Not comprehending my utterances Limitation of follow-up questions Others (specify).

4c. Please state what you found beneficial or lacking in using chatbots as an English learning resource (compared with traditional methods of English conversation learning)