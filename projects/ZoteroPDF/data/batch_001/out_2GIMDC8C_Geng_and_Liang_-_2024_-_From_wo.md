# From words to senses: A sense-based approach to quantitative polysemy detection across disciplines

Wenshu Geng 1 , Maocheng Liang \*,1

Beihang University, 37 Xueyuan Road, Haidian District, Beijing, 100191, PR China

# A R T I C L E I N F O

# A B S T R A C T

Handling Editor: Dr Hilary Nesi

Keywords:   
Interdisciplinary polysemy   
Polysemy detection   
Contextualised word representations   
Sense representation   
Quantitative analysis   
Corpus linguistics

Interdisciplinary polysemy refers to the phenomenon in which a word is understood and used differently across disciplines or fields. Nuanced variations in word meanings pose a significant challenge to effective communication and knowledge integration, especially in academic and professional settings. To address these issues, we propose the Interdisciplinary Polysemy Detec tion (IPD) method, which streamlines the identification of polysemous words by making the process more automatic, objective and efficient. IPD not only identifies polysemous words but also quantifies the extent of semantic variation within and across disciplines, providing deeper insights into the scale and nature of meaning shifts in different contexts. The evaluation results demonstrate that IPD can identify interdisciplinary polysemy effectively, showing heightened sensitivity to subtle differences in word senses. This sensitivity makes IPD a useful tool for both researchers and educators, helping to improve communication across fields and contributing to the development of more tailored pedagogical resources. The broader implications of this method may extend to enhancing the understanding of semantic variation in interdisciplinary research and advancing knowledge transfer between specialised domains.

# 1. Introduction

Recent years have seen a significant increase in interdisciplinary communication and research, highlighting growing concerns about the latent barriers arising from linguistic differences between disciplines. Various interpretations of the same word can often lead to misunderstandings (Ballard & Clanchy, 1991; Hyland & Tse, 2007; Mitsugi, 2017). These words are interdisciplinary poly semous words, referring to a word with multiple meanings across different disciplines. For example, the word ‘model’ can refer to a simplified representation of a system in science, a fashion model in the fashion industry or a standard or example in general usage. Understanding such specificity in embodying meanings is beneficial for students. According to Coffin and Hewings (2003), when students develop an explicit awareness of how different disciplines use various text types and language conventions, they can better control their writing. This suggests the benefits of focusing on the identification and interpretation of polysemy, especially in the context of English for specific purposes (ESP).

To explore the identification and interpretation of polysemy in the context of ESP, several studies have used various methodologies. Green and Lambert (2018) contributed to advancing disciplinary literacy by developing a series of discipline-specific word lists for secondary school education, covering eight core subjects. To identify discipline-specific polysemy, they examined various lexical features, such as minimum frequency, occurrence range, dispersion, keyness and collocation analysis. These combined criteria allowed for a more precise identification of discipline-specific polysemous words. Similarly, Deignan and Love (2021) sought to identify subject-specific uses of polysemous words in English secondary school science materials. They applied keyness analysis (Gabrielatos, 2018) to identify words in the Science Corpus that had significantly higher frequencies than those in the Spoken British National Corpus 2014 (Love et al., 2017). They then focused on the ratio of frequency percentage to determine the size of the difference between the relative frequencies, followed by collocation analysis to further distinguish between the everyday and academic meanings of polysemous words. These two steps enabled the authors to pinpoint a large set of potentially subject-specific polysemous words. Nonetheless, while this methodology is robust in identifying frequency-based differences, it may not always capture the finer semantic distinctions that exist in less frequent or more context-specific usages. This is partly because their approach is designed to highlight prominent patterns in well-defined corpora, potentially missing more subtle or less frequent semantic shifts that occur in broader or less structured contexts. In addition, Skoufaki and Petri´c (2021) aimed to enhance the understanding of how polysemous words are used across various academic disciplines by focusing on the Academic Vocabulary List (Gardner & Davies, 2014). They examined polysemous terms by analysing the number of definitions each term had in both the Collins COBUILD Advanced English Dictionary and WordNet (Fellbaum, 1998), integrating multiple authoritative sources to improve the accuracy of polysemy identification. This method of using well-designed external reference materials as a basis for understanding word meanings is certainly well-founded and highly accurate. However, the choice of these specific materials could potentially influence the interpretation of word meanings, perhaps limiting the ability to capture the full range of polysemy in different contexts.

The findings of these studies demonstrate that discipline-specific usage is genuine and significantly affects language users. Their methods inspire us to explore and refine the identification techniques that account for these variations. A key aspect of these variations is polysemy, broadly referring to the phenomenon where a single lexeme has multiple senses and ranging from closely related to distinctly separate meanings. This linguistic feature is considered the norm, as most words express different meanings and behaviours in various contexts while still being represented by the same lexeme. These multiple senses form a continuum of relatedness, indicating the fluid and dynamic nature of language. Understanding this continuum enables us to view polysemy not as a fixed category but rather as a fluid spectrum, where the degrees of relatedness between senses can shift and vary. Thus, our study provides a quantitative method that may help users assess the extent of divergence or convergence among these senses across disciplinary groups. Furthermore, we seek to contribute to the field by enhancing the procedure for identifying polysemy, aiming to make the process more automatic, efficient and user-friendly.

This study introduces a sense-based method, namely, interdisciplinary polysemy detection (IPD), to identify and quantify interdisciplinary polysemy. A word sense here refers to the meaning ascribed to a word in a given context. This sense–context relationship is the foundation of polysemy detection in this article. The IPD method discerns the activated sense of a word within a context and aligns the sense with its corresponding lexical form. This process involves several key steps. Initially, IPD uses a pre-trained model to analyse lexical context information, capturing all senses of the target polysemous word. Subsequently, it evaluates the variation in sense distribution within and across disciplines, allowing IPD to identify and measure the extent of interdisciplinary polysemy. Next, IPD provides a list of disciplinary polysemy based on the size of these differences. To provide a practical understanding of the IPD framework, this study conducted a case study using two distinct corpora—referred to as ‘the Hard Science Corpus’ and ‘the Soft Science Corpus’—as detailed in Section 4.1. Through this case study, we hope to clarify the workflow of IPD and create a reference word list, which is not intended as a final product but rather as a way to illustrate findings. This study responds primarily to the following two research questions.

(1) How effective is the IPD method in identifying the sense variations of interdisciplinary polysemous words? (2) To what extent does the IPD method facilitate the comparison of sense variations across disciplines?

# 2. Theoretical and methodological approaches to polysemy interpretation

# 2.1. Interplay of context and lexical meaning

Cruse (1986) highlighted the pivotal role of context in modulating and selecting meanings, emphasising its importance in un derstanding polysemy. Kilgarriff (1997) distinguished between modulation, a process by which the context refines a general meaning, and selection, a process by which a specific sense is chosen from ambiguous options. For example, the word ‘hand’ might refer to either the right hand or the left hand; certain contexts might clarify this, such as ‘in a salute, the hand should just touch the forehead’, while others may not. Reading contexts not only resolves ambiguity but also respects the indeterminacy inherent in language. In recognising this, numerous studies have focused on how context influences lexical meaning, exploring the complexities of this relationship. In the following sections, we will review various theoretical perspectives that conceptualise this complex interplay.

Building on this foundation, researchers have meticulously examined extensive corpora, seeking to identify and summarise the underlying regularities that shape word usages and meanings. Following Sinclair and others, pattern grammar was further developed by Hunston and Francis in 2000. It draws on Sinclair’s assertion that there is ultimately no distinction between form and meaning (1991), positing that different grammatical patterns often correspond to different meanings of polysemous words. Moreover, extensive corpus analysis has demonstrated that these patterns do more than just co-occur with words—they actively shape and define their meanings. Pattern grammar has underscored the significant role that context plays in shaping meaning; however, the relationship between patterns and meanings is not always a one-to-one correspondence. Therefore, there have been attempts to describe patterns in more detail, such as the Pattern Dictionary of English Verbs (Patrick Hanks), analysing verbs systematically according to their distinct

Unlike pattern grammar, focusing on identifying the relationship between lexical items and the grammatical patterns in which they commonly occur, local grammar analyses how specific grammatical structures within particular contexts shape and constrain the meanings of words. Local grammar, first developed by Maurice Gross in the 1990s, focuses on a detailed analysis of specific gram matical structures and fixed expressions in language (Gross, 1993). Unlike general grammar, seeking to establish overarching rules applicable to the entirety of language use, local grammar is tailored to describe and construct rules specific to a particular discourse meaning or function. Furthermore, it is fundamentally linked to Firth’s concept of restricted language and Harris’s notion of sublanguage, indicating that specific grammatical structures are designed to suit particular discourse contexts or functions (Wei, 2017). Local grammar has also been applied in linguistic descriptions of grammatical structures, individual words and specific phraseologies. For example, Hanks and Moˇze have explored how the noun ‘way’ expresses its phraseology and complexity of meaning through participation in various literal and non-literal patterns (Hanks & Moˇze, 2019). Their study illustrates that local grammar can effectively analyse real language use, thus offering a more nuanced and systematic way to explore the lexis–grammar interface and better capture the behaviour of words across diverse contexts.

While pattern and local grammar emphasise the analysis of grammatical structures in shaping word meanings, frame semantics approaches meaning from a cognitive perspective, interpreting word meanings through the lens of semantic frames that provide a conceptual background for language use. Frame semantics, introduced by American linguist Charles Fillmore in the 1970s, offers a distinctive cognitive approach to understanding and describing word meanings (Fillmore, 1975). Moreover, it proposes that a word’s meanings can be best understood within the context of a broader semantic frame. These frames are cognitive structures that represent complete situational contexts that a word evokes. A key strength of frame semantics lies in its ability to systematically account for rich contextual details that grammatical patterns alone might overlook. Furthermore, it examines the conceptual background that un derpins word usage, offering a deeper understanding of how meanings shift in different contexts, and focuses on the mental structures that guide language use. Believing that different senses of a polysemous word often correspond to different semantic frames, the cognitive perspective enables an extensive analysis of polysemy. Moreover, it reveals the cognitive processes that allow speakers to navigate different senses of a word depending on the situation, thus offering a robust framework for exploring the interaction between context and meaning.

Together, these perspectives highlight that a full understanding of lexical meaning cannot be achieved without meticulous attention to context. Whether this is through the detailed description of grammatical patterns or the cognitive framing of semantics, the analysis of context emerges as a crucial pathway to uncovering the complexities of word meanings, thereby underscoring its central importance in linguistic research.

# 2.2. Contemporary approaches to word meanings’ interpretation

As articulated in the theory of norms and exploitations, the meaning of language is derived not only from the conventional usage of words in specific contexts—referred to as norms—but also from the creative variations or extensions of these norms, known as ex ploitations (Hanks, 2013). This theory suggests that understanding language necessitates a deep understanding of how these words are used in specific contexts and how speakers adapt these usages creatively to convey new meanings. The task of capturing the various contexts in which words may appear as extensively as possible and fully understanding their meanings has become a focus for many researchers. These approaches increasingly rely on large-scale corpora and sophisticated computational techniques to capture the nuances of word meaning. In this section, we will explore these modern methodologies, focusing on how they apply contextual analysis to enhance our understanding of lexical semantics.

A prime example of using automated tools to process large-scale corpus data is the work of Kilgarriff and his team (Evans et al., 2018, pp. 3–25; Kilgarriff et al., 2010). Through the development of the Sketch Engine, they analysed the grammatical and collocational patterns of words, enabling a precise identification of different word senses. They used distributional thesauri to cluster semantically related words based on shared collocates, distinguishing between the various meanings effectively. This methodology highlights how computational tools and an extensive corpus analysis can capture word usage systematically in diverse contexts, of fering a nuanced understanding of lexical semantics and setting a benchmark in the field.

Another approach to interpreting contexts goes beyond direct word analysis, using word embeddings to represent words as vectors in a multidimensional space. Word embeddings, a type of vectorisation technique, represent words in a continuous vector space where semantically similar words are positioned closer together. Contextualised word embeddings further consider the varied contexts of a word, its semantic relationships and its usage patterns. This approach, widely used in computational linguistics (Li & Joanisse, 2021; Schlechtweg et al., 2020; Shoemark et al., 2020), involves vectorising word contexts using pre-trained deep-learning language models. For example, bidirectional encoder representations from transformers (BERT, Devlin et al., 2018) interpret words within the framework of sentence contexts, providing a nuanced analysis of language by apprehending the complexities of word usage in various linguistic environments. Recent advances in using deep learning networks to represent polysemous words are particularly noteworthy. Garí Soler and Apidianaki (2021) identified two layers of semantic information encoded in the embeddings derived from BERT, namely, one that contains inherent knowledge of lexical polysemy and another that activates the specific sense a word expresses in a given context. Haber and Poesio (2021) investigated how BERT-based models handle polysemy and homonymy by analysing the models’ embeddings for these ambiguities and identifying specific patterns that distinguish polysemous words from homonymous ones. Furthermore, Ansell et al. (2021) introduced PolyLM, a language model designed specifically to learn about polysemy. They implemented a language modelling approach that adapts to the polysemous nature of words, providing a targeted analysis of how different senses are represented in embeddings. Goel et al. (2022) proposed an unsupervised framework combining geometric features

with syntactic dependencies to quantify polysemy. Their method involved leveraging the syntactic structure of sentences to refine the polysemy scores, thereby enhancing the model’s ability to detect and differentiate multiple senses.

These studies focus on refining and expanding methods for capturing and analysing polysemy within deep learning models, further confirming the capability of contextualised embeddings to handle the complexities of word sense variation. Therefore, this study used a pre-trained language model to represent words as contextualised word embeddings, to capture the subtle variations in word meanings precisely across different contexts.

# 3. Research design

# 3.1. Research procedures

The construction of IPD comprised the following four steps:

i. Corpora Construction: This initial step involved gathering abstracts from research papers across two disciplinary groups—hard and soft sciences. These texts were then sorted, tokenised, and tagged for parts of speech;   
ii. Contextualised Word Representation: In this step, we represented tokens as word vectors using pre-trained language models, preparing them for further analysis;   
iii. Semantic Variation Measurement: We used ANOSIM (analysis of similarity) to measure the similarity of word meanings within and across the corpora, providing quantitative metrics to rank words by their inter-group dissimilarity;   
iv. Evaluation: We examined the list of words that exhibited discipline-specific senses and their collocational patterns corresponding to dominant senses.

The entire process is visually summarised in Fig. 1, providing an overview of the methodology.

IPD has two primary features to enhance polysemy identification. First, its fully automated operation streamlines the processing of linguistic data, reducing manual intervention and adapting to the evolving nature of polysemous words shaped by social and linguistic changes. Second, IPD quantitatively measures the extent of semantic differences between meanings across registers.

# 3.2. Research methods

# 3.2.1. Research tools

In this section, we introduce the tools used by IPD. In the first step, the Python module scikit-learn (Pedregosa et al., 2011) was extensively used for various tasks such as text sorting, part-of-speech tagging, and word class grouping. In the final step, we used WordSmith Tools (Scott, 2020). This structured approach ensures that each phase of IPD is supported by appropriate and effective technological tools.

In the second step, we used the pre-trained language model BERT to illustrate the framework of IPD. Within this framework, the language model plays a crucial role in representing words as contextualised embeddings. BERT fundamentally transforms machine understanding of human language by simulating the bidirectional nature of human thought. Unlike traditional models that process words sequentially, BERT evaluates words simultaneously with all others in a sentence. This approach enables the model to capture the full contextual meaning of each word, considering its predecessors and successors, thereby providing a robust framework for understanding language subtleties and complexities.

![](img/472713bc66d1c5b6719cddb2578b62fe11bac02d05b908bac1b70c108399b62b.jpg)  
Fig. 1. The process flow of IPD method.

The core of BERT is the transformer architecture, specifically designed to handle extensive contextual information in large texts. The foundational BERT model consists of twelve transformer layers. Each layer enhances language understanding by integrating token embeddings (which represent individual words), segment embeddings (indicating the segment or sentence to which a word belongs), and positional embeddings (which mark word order). This structure is detailed by Kenton and Toutanova (2019, pp. 4171–4186).

A key feature of BERT is its attention mechanism, which dynamically evaluates and emphasises the importance of different words in a sentence. This capability is essential for generating deeply contextual word embeddings that vary significantly based on how words are used in specific contexts, as noted by Vaswani et al. (2017). Additionally, the ability of BERT to produce varied representations for the same word in different contexts addresses the challenge of polysemy effectively, where words have multiple senses depending on usage. Ethayarajh (2019, pp. 55–65) analysed the word embeddings produced by ELMo (Peters et al., 2018), BERT (Devlin et al., 2018), and GPT-2 (Radford et al., 2019), and found that these contextualised representations differ across layers, demonstrating that these models capture the dynamic meanings of words depending on context, as shown in Fig. 2. A single word can have many rep resentations, each uniquely shaped by its context.

Given the sophisticated design of BERT for language modelling and its proven efficacy in various natural language processing tasks, we selected it as the cornerstone for representing word senses in our study.

# 3.2.2. The analysis of similarity as a difference test

ANOSIM, short for analysis of similarity, is a statistical test originally proposed by K. R. CLARKE (1993). This test compares multivariate datasets, typically related to the structure or composition of communities or assemblages. ANOSIM is a non-parametric statistical test commonly applied in the fields of ecology and environmental science. The primary prerequisites for ANOSIM are statistical assumptions associated with non-parametric tests, such as independent observations, nominal data, and random sampling (Clarke & Gorley, 2006, p. 866). The independence assumption implies that the samples being compared should be unrelated and not influenced by each other. Categorical data means data with no inherent order, providing qualitative information about element features. Random sampling was used to preclude bias towards any source.

Another critical consideration when using ANOSIM is the requirement for a similarity or dissimilarity matrix as input. This matrix offers a concise and convenient representation of pairwise dissimilarities within the dataset. With this input, multidimensional scaling can reduce dimensionality by transforming the dissimilarity matrix into a lower-dimensional space. Additionally, the choice of a metric for calculating similarity between samples is another presupposition that depends on the nature of the data and the research question at hand. In previous ecological and biological research, metrics like Bray-Curtis, Jaccard, or Euclidean distance have been commonly employed (Anderson & Walsh, 2013; Cantacessi et al., 2014; Clarke et al., 2006). This paper chose cosine similarity to measure the angle between two vectors in a high-dimensional space. The specific reasons will be detailed in the subsequent text.

The fundamental mode of ANOSIM is to assess the contribution each member makes to the similarity measurement. The mean contribution of each member to the dissimilarity between two groups is defined as the average over all cross-group sample pairs. This identifies which members are good discriminators between the two clusters. Through inter-sample distances, ANOSIM reconstructs the entire relational map. It uses permutation-based testing, which focuses on the relationships between members rather than their ab solute values. In an ANOSIM analysis, the initial report includes the P-value, which indicates the significance levels. However, it can be influenced by the number of permutations - with larger sample sizes, it tends to be low, and vice versa. Therefore, it is advisable to also report the R-value, which provides a more analytical and interpretable measure. The R-value serves as a scaled measure of similarity between groups and is unaffected by changes in sample size. Let ${ \bf r _ { B } }$ be the mean rank of between-group similarities, rW the mean rank of within-group similarities, and $n$ the number of samples; the test statistic R is calculated as follows:

$$
R = \frac { r _ { B } - r _ { W } } { 1 / 4 ( n ( n - 1 ) ) }
$$

The calculated ANOSIM statistic typically falls between $^ { - 1 }$ and 1. A higher R-value indicates greater dissimilarity between the groups, while a lower R-value suggests more similarity. The null hypothesis in ANOSIM posits no statistically significant difference in similarity between the groups. An R-value of zero supports the null hypothesis, indicating no difference among the samples. An R-value of $+ 1$ means all the most similar members are within the same communities, while an R-value of $^ { - 1 }$ indicates that the most similar members are outside the communities. It is widely accepted that the R-value provides insights into how much the chosen factor

![](img/4fa97768e847742e1f0249ad230aee5036b3f07f01be740a66c734b8a7434516.jpg)  
Fig. 2. The highly context-specific representations of ‘mouse’ generated by BERT (Ethayarajh, 2019, pp. 55–65).

influences the variable being studied.

In the second paragraph of this section, we referred to the selection of a metric for calculating similarity. As mentioned in Section 3.2.1, we represented words using contextualised word embeddings. Due to the vector nature of these embeddings, we use cosine similarity to measure the semantic variation between word senses. Cosine similarity measures the cosine of the angle between two vectors in a high-dimensional space (Han et al., 2012). The input matrix for ‘r’ in the formula (including rB and rW) refers to the cosine similarity matrix of word vectors. In the remainder of this section, we will explain the benefits of vectorising senses and analysing them using ANOSIM.

Currently, ANOSIM is widely used in biology due to its advantages in handling populations without core prototypes or clearly defined boundaries. Given the diversity of species, ensuring homoscedasticity among different communities is difficult, making it unsuitable for parametric tests like ANOVA. However, ANOSIM, an analogue of analysis of variance for multispecies data, can be used instead (Chapman & Underwood, 1999). Nonetheless, during the calculation of the similarity or dissimilarity matrix, subjective judgments can sometimes affect the results. For example, the Bray-Curtis dissimilarity metric, widely used in ecology, requires judgments about the abundance or presence of factors. When defining ambiguously defined or inherently fuzzy features, this method can be influenced by prior knowledge and human bias. The same applies to the Jaccard dissimilarity metric, another common metric in biology, which requires decisions regarding shared and unique factors. In such cases, maintaining completely objective judgments can be challenging. To address this, we transformed senses into contextualised embeddings and analysed them with ANOSIM, avoiding manual judgments of similarity and reducing the impact of human subjectivity on similarity calculations. In summary, for IPD, we used a pre-trained language model to create contextualised embeddings for senses, applied cosine similarity to measure dissimilarities, and input the results into ANOSIM to compute the R-value and assess variation between sense groups.

# 4. A case study using IPD for discipline-specific senses

# 4.1. Corpus construction

As mentioned in Section 1, we applied IPD to real-world data to demonstrate its working framework. We chose research papers as input. Research papers are rigorously reviewed academic publications that encapsulate the ways of knowing, selecting, evaluating, reporting, concluding and arguing within their respective academic communities. Moreover, they represent authentic uses of academic language. We selected the abstract section for two main reasons. First, abstracts are highly accessible; as a fundamental component of academic articles, they are always placed prominently at the beginning and are marked with a header, making them easy to access for data crawling. Second, abstracts contain a wealth of integrated information. According to the American National Standards Institute, a well-prepared abstract allows readers to identify the core content of a document quickly and accurately (Institute et al., 1979). However, we acknowledge that while IPD can handle input corpora of any size and type, not just abstracts, our focus on abstracts might not fully reflect the extent of interdisciplinary polysemy across soft and hard disciplines. Therefore, due to the limitations of the selected illustrative data, the results presented in Section 5 may be slightly constrained. The focus on abstracts might overlook certain nuances and specific usages that are present in the full-text articles.

The raw research articles for this study were sourced from Microsoft Academic (Wang et al., 2019), a public academic search engine providing extensive academic publications and enriched information, such as author and affiliation information and API access. Importantly, the primary goal of this research is not to compile an exhaustive list of polysemous words, but rather, to introduce a method that can identify interdisciplinary polysemy automatically. Therefore, the selection of disciplines for research papers is not limited to those commonly involved in interdisciplinary research. Following Kolb’s (1981) classification system, disciplines were categorised into two groups: the hard and soft sciences. Based on this, we selected articles randomly under six subjects rooted in these two categories to construct corpora for the case study. In this study, we used the lottery method, a straightforward random sampling technique, to ensure that each discipline was chosen with equal probability. This method offers every individual in the population an equal chance of being selected, thereby safeguarding the process against external influences (Acharya et al., 2013). We selected this method for its validity, analytical simplicity and presence of a pre-existing enumerated population. We implemented this method by assigning numbers to each paper and using computer-generated random numbers to select articles for inclusion.

Ultimately, we selected 12,000 articles for each corpus, with 1000 articles from each discipline for each year from 2017 to 2020. These selections formed two distinct corpora, namely, ‘the Soft Science Corpus’ and ‘the Hard Science Corpus’. These terms reflect the traditional academic distinction between soft sciences (i.e. psychology, philosophy and sociology) and hard sciences (i.e. computer science, chemistry and physics). The design of the two corpora aimed to illuminate how polysemous words function differently across the two paradigms. By comparing these differences, this case study explores the semantic distinctions and usage variations of words across disciplines. Altogether, the Soft Science Corpus comprises 2,138,268 nouns and the Hard Science Corpus contains 2,169,012 nouns. The close size ensures that the comparison remains balanced and meaningful. Each corpus was carefully compiled to include only articles from journals indexed in the Web of Science, thus ensuring a robust representation of each subfield. Table 1 outlines the details of our corpora, including the number of types and tokens contained in them.

Table 1 Vocabulary details of the two corpora.   

<html><body><table><tr><td>Name</td><td>No. of abstracts</td><td>No. of types</td><td>No. of tokens</td></tr><tr><td>The Soft Science Corpus</td><td>14,000</td><td>191,101</td><td>2,138,268</td></tr><tr><td>The Hard Science Corpus</td><td>14,000</td><td>163,772</td><td>2,169,012</td></tr></table></body></html>

# 4.2. The extraction of example word class

IPD is not limited to identifying polysemous words within a particular class, yet the presence of mixed word classes can complicate polysemy identification. For example, issues may arise when two tokens with the same morphology belong to different word classes, affecting subsequent analysis. Therefore, using IPD, we first classified tokens by their part of speech. For the case study, we concentrated on nouns, motivated primarily by the widespread occurrence of nominalisation in academic language—a process by which words or phrases from other parts of speech are converted into nouns (Charles, 2003; Galve, 1998; Halliday, 2004; Webster, 2004).

The processing of our target nouns involved several steps. Initially, we cleaned raw data by removing headings, footers and ci tations from all the abstracts. Subsequently, we used a BERT-based model for tokenisation and part-of-speech tagging, focusing on lexical nouns tagged as NOUN (for nouns) and PRON (for pronouns). To select nouns that are commonly used in both disciplines, we applied a minimum frequency criterion, selecting nouns that appeared in over 20 abstracts in both corpora. The relatively low threshold is determined by the long-tail effect of vocabulary, where a small number of words appear frequently while the majority appear infrequently. This threshold was set to ensure that the selected nouns were not unique to specific documents or themes. We aimed to include as many words as possible in the case study, thus increasing the likelihood of discovering potential polysemous words. Finally, we obtained 1306 nouns that met these criteria (Table 2).

# 5. Evaluation

# 5.1. Interpreting ANOSIM R-values for semantic differences

In addition to the roles of the R-value introduced in Section 3.2.2, a commonly used rule of thumb helps interpret R-value thresholds:

- An R-value below 0.25 suggests that differences between groups are minimal - An R-value between 0.25 and 0.5 indicates moderate differences with significant overlap - An R-value between 0.5 and 0.75 suggests that the groups are fairly distinct - An R-value above 0.75 signifies very distinct groups, highlighting significant differences.

It is important to emphasise that while the rule of thumb can offer a complete understanding of relationships, there are no absolute, clear-cut thresholds between R-values (Couturier et al., 2013; Du et al., 2022; Vichi et al., 2011). Following these empirical thresholds, Fig. 3 illustrates the distribution of nouns that appear in at least 20 abstracts in both corpora, as detailed in Table 2. Fig. 3 shows that with an R-value of 0.5 as a threshold, most nouns exhibit weak semantic variation across disciplines, while a small number of nouns show significant differences between disciplines.

# 5.2. The generation of a polysemous words list

Based on the R-value, we generated an interdisciplinary polysemous word list sorted by differences in magnitude. Table 3 presents the top 20 polysemous words, including their frequency, R-value and P-value. When performing collocation analysis, the P-value helps determine if the co-occurrence of two words is statistically significant. A low P-value (e.g. less than 0.05) typically suggests that the cooccurrence is not due to chance, thereby confirming its statistical significance. The absolute frequency of the vocabulary in the table is not low in either of the corpora. This indicates that IPD can identify words with semantic differences between the corpora, inde pendently of frequency.

# 5.3. Collocational analysis of polysemy

Having identified words with significant semantic differences across two corpora, we performed collocation analysis to explore word meanings and thereby validate our results. Specifically, we aimed to ascertain preferred collocates within different disciplinary contexts to determine how and why specific senses are activated. Focusing on semantic information, we excluded functional words to reduce distractions. For similar reasons, in this section, we also used the lottery method of sampling to select words from the generated list for collocation analysis, aligning the randomisation approach with the one described in Section 4. This sampling provided four nouns, listed in Table 4, which uses shades of grey to indicate R-value sizes—the darker the shade, the higher the value. The table includes ‘Rank’, indicating the ranking of words in the list; ‘P-value’, indicating the level of significance and ‘FreH’ and ‘FreS’, rep resenting word frequencies in the Hard and Soft Science Corpora, respectively. For each word, we recorded the top five collocates of these selected words (sorting by the log-likelihood value), detailing the number of co-occurrences between the collocates and selected words, along with the log-likelihood value to thereby quantify the co-occurrence strength.

Table 2 Nouns in the two corpora.   

<html><body><table><tr><td>Name</td><td>No. of types (noun)</td><td>No. of tokens (noun)</td></tr><tr><td>The Soft Science Corpus</td><td>72,278</td><td>489,829</td></tr><tr><td>The Hard Science Corpus</td><td>58,090</td><td>540,862</td></tr></table></body></html>

![](img/16c5fb3d38fbd8198e74e365c4ea51a4669d002d146bbc7c4612868bdcddcd53.jpg)  
Fig. 3. Distribution of selected nouns across four R-value intervals.

Table 3 Top 20 polysemous words across the two corpora.   

<html><body><table><tr><td>Rank</td><td>Word</td><td colspan="2">Frequency</td><td>R-value</td><td>P-value</td><td>Rank</td><td>Word</td><td colspan="2">Frequency</td><td>R-value</td><td>P-value</td></tr><tr><td></td><td></td><td>Hard</td><td>Soft</td><td></td><td></td><td></td><td></td><td>Hard</td><td>Soft</td><td></td><td></td></tr><tr><td>1</td><td>values</td><td>994</td><td>633</td><td>0.972443187</td><td>0.001*</td><td>11</td><td>regime</td><td>215</td><td>66</td><td>0.9056063</td><td>0.001*</td></tr><tr><td>2</td><td>expressions</td><td>208</td><td>146</td><td>0.971611609</td><td>0.001*</td><td>12</td><td> determination</td><td>345</td><td>79</td><td>0.903053087</td><td>0.001*</td></tr><tr><td>3</td><td> sphere</td><td>110</td><td>74</td><td>0.932156829</td><td>0.001*</td><td>13</td><td> lens</td><td>120</td><td>144</td><td>0.902486381</td><td>0.001*</td></tr><tr><td>4</td><td>resistance</td><td>100</td><td>185</td><td>0.928608796</td><td>0.001*</td><td>14</td><td>mass</td><td>1553</td><td>139</td><td>0.897303859</td><td>0.001*</td></tr><tr><td>5</td><td>consumption</td><td>370</td><td>206</td><td>0.924219619</td><td>0.001*</td><td>15</td><td> freedom</td><td>149</td><td>281</td><td>0.896108312</td><td>0.001*</td></tr><tr><td>6</td><td> mission</td><td>108</td><td>73</td><td>0.923762084</td><td>0.001*</td><td>16</td><td>atmosphere</td><td>86</td><td>47</td><td>0.891383636</td><td>0.001*</td></tr><tr><td>7</td><td>functions</td><td>704</td><td>205</td><td>0.919440357</td><td>0.001*</td><td>17</td><td>family</td><td>206</td><td>1122</td><td>0.888444345</td><td>0.001*</td></tr><tr><td>8</td><td>gain</td><td>313</td><td>149</td><td>0.916992338</td><td>0.001*</td><td>18</td><td>strength</td><td>353</td><td>143</td><td>0.887018082</td><td>0.001*</td></tr><tr><td>9</td><td>shape</td><td>389</td><td>175</td><td>0.909066058</td><td>0.001*</td><td>19</td><td>interactions</td><td>832</td><td>369</td><td>0.886985218</td><td>0.001*</td></tr><tr><td>10</td><td>transformations</td><td>69</td><td>76</td><td>0.906007628</td><td>0.001*</td><td>20</td><td> ground</td><td>399</td><td>77</td><td>0.883415858</td><td>0.001*</td></tr></table></body></html>

Note. \* means a P-value lower than 0.001.

# 5.3.1. Functions

In the Hard Science Corpus, the collocates basis, correlation, wave and hash are positioned adjacent to the node word forming noun phrases. In these phrases, functions refers to concepts whose values are determined by the interaction with other variables. Therefore, functions, here in hard disciplines, frequently pertains to mathematical or quantitative relationships, as illustrated in example (1). In contrast, in the Soft Science Corpus, functions primarily denotes established terms, such as executive functions and cognitive functions, which involve specific mental processes and cognitive abilities as illustrated in example (2). The semantic difference in functions between the two corpora is clear. In the Hard Science Corpus, functions typically denotes objective, quantifiable relationships, which reflect its mathematical and technical applications. In contrast, in the Soft Science Corpus, functions is more closely linked to mental and conceptual frameworks, particularly in fields like psychology. While both uses of functions share the idea of describing re lationships or purposes, their senses and applications vary across these disciplinary contexts.

Table 4 Four words selected for illustration.   

<html><body><table><tr><td>Word</td><td>Rank</td><td>R-value</td><td>P-value</td><td>FreH</td><td>FreS</td></tr><tr><td>functions</td><td>7</td><td>0.919</td><td>0.001</td><td>704</td><td>205</td></tr><tr><td>stress</td><td>76</td><td>0.742</td><td>0.001</td><td>686</td><td>669</td></tr><tr><td>environment</td><td>310</td><td>0.382</td><td>0.001</td><td>746</td><td>648</td></tr><tr><td>aim</td><td>528</td><td>0.060</td><td>0.052</td><td>416</td><td>756</td></tr></table></body></html>

(1) We perform a detailed study of the analyticity properties and cut structure of these functions up to two loops in the planar case, where we classify and identify the minimal set of basis functions. (2) This association may provide a possible link between impairments in executive functions related to compulsive action.

The frequency of the word functions varies widely across the two groups of disciplines. Furthermore, based on the above discussion, it assumes different senses in the two corpora; one conveys numerical and value-related concepts and the other denotes purpose. These two interpretations stand in stark contrast, in terms of contextual usage and semantic function. This observation supports the results in Table 5, where the P- and R-values of 0.001 and 0.92, respectively, indicate a significant difference.

# 5.3.2. Stress

In the Hard Science Corpus, the words oxidative, induced, endoplasmic, reticulum and salt all closely border stress, forming noun phrases, which all refer to specific types of physical pressure. Among these, stress primarily refers to something that can damage its recipients or make recipients lose their original shape. These senses are highly related to the action taken in some experiments in hard disciplines, as in examples (3) and (4).

(3) Overall, hesperidin offered protective potency on TCE-induced oxidative stress in the flies via anti-oxidative mechanism. (4) Endoplasmic reticulum stress (ERS) and inflammation play crucial roles in DM. Gastrodin (Gas), the main component of Gastrodia elata, possesses anti-oxidative stress, anti-inflammatory, and neuroprotective effects.

In the Soft Science Corpus, stress also refers to some type of pressure; however, the difference is that it mostly refers to mental pressure. Among the five most frequent collocates, perceived, posttraumatic and disorder construct specific terms with stress in which it refers to the causable pressure triggering a particular mental health condition (Example (5)). In these cases, the meaning of stress is quite similar to its use in the Hard Science Corpus as both represent a type of damaging pressure that changes the original state. However, different contexts indicate various forms of pressure and distinct targets of action. Depression and anxiety often appear alongside stress, referring to mental concerns, which are slightly different from physical pressure, as given in example (6).

(5) Despite an array of evidence-based psychological treatments for patients with a posttraumatic stress disorder (PTSD), a majority of patients do not fully benefit from the potential of these therapies.   
(6) To estimate the prevalence of symptoms of depression, anxiety, stress and associated factors in a population of college students.

The core meaning of stress demonstrates no significant difference within the two corpora; in both, stress serves to convey a form of pressure. While the core meaning of stress remains consistent across the disciplinary groups, the specific types of pressure it pertains to vary considerably according to the different individuals and circumstances involved. This accords with Table 6, from which we find that the frequency of stress in the two corpora is relatively similar. With a P-value of 0.001, it shows a significant disparity in the meaning of stress in the two corpora. An R-value of 0.74, a relatively high figure, suggests that stress has a significant impact on the differences between the two disciplines, though not overwhelmingly so.

# 5.3.3. Environment

In both corpora, environment frequently collocates with learning, forming the phrase learning environment, which refers to the conditions in which a person learns, as shown in example (7). A similar sense of environment can be found in phrases such as urban environment, indoor environment, built environment, school environment, work environment, virtual environment, and cloud environment, where environment refers to the conditions or settings in which activities take place, whether physical or digital. Specially, in the Hard

Table 5 The five most frequent collocates of the word functions in the Hard and Soft Science Corpora.   

<html><body><table><tr><td></td><td colspan="3">The Hard Science Corpus</td><td colspan="3">The Soft Science Corpus</td></tr><tr><td>Rank</td><td>Collocate</td><td>Co-occurrence</td><td>Log-likelihood</td><td>Collocate</td><td>Co-occurrence</td><td>Log-likelihood</td></tr><tr><td>1</td><td>basis</td><td>33</td><td>141.961</td><td>executive</td><td>20</td><td>172.328</td></tr><tr><td>2</td><td>correlation</td><td>33</td><td>124.853</td><td> cognitive</td><td>23</td><td>100.393</td></tr><tr><td>3</td><td>wave</td><td>40</td><td>114.34</td><td>rhetorical</td><td>6</td><td>38.445</td></tr><tr><td>4</td><td>physiological</td><td>13</td><td>54.496</td><td>memory</td><td>8</td><td>29.258</td></tr><tr><td>5</td><td>hash</td><td>7</td><td>52.208</td><td>endurance</td><td>3</td><td>24.752</td></tr></table></body></html>

Table 6 The five most frequent collocates of the word stress in the Hard and Soft Science Corpora.   

<html><body><table><tr><td></td><td colspan="3">The Hard Science Corpus</td><td colspan="3">The Soft Science Corpus</td></tr><tr><td>Rank</td><td>Collocate</td><td>Co-occurrence</td><td>Log-likelihood</td><td>Collocate</td><td>Co-occurrence</td><td>Log-likelihood</td></tr><tr><td>1</td><td>oxidative</td><td>243</td><td>2090.861</td><td>perceived</td><td>59</td><td>271.79</td></tr><tr><td>2</td><td>induced</td><td>73</td><td>253.92</td><td> posttraumatic</td><td>28</td><td>248.29</td></tr><tr><td>3</td><td> endoplasmic</td><td>20</td><td>165.613</td><td>depression</td><td>47</td><td>243.493</td></tr><tr><td>4</td><td>reticulum</td><td>20</td><td>161.633</td><td>anxiety</td><td>42</td><td>201.656</td></tr><tr><td>5</td><td>salt</td><td>22</td><td>119.533</td><td> disorder</td><td>41</td><td>188.61</td></tr></table></body></html>

Science Corpus, environment frequently collocates with the word cloud, forming the phrase cloud environment. In this context, envi ronment refers to the digital or virtual infrastructure used for computing and data storage, focusing on technical operations rather than directly impacting human emotions or productivity, as shown in example (8). This technical sense of environment suggests the broader interpretation of environment in hard sciences.

(7) This nontraditional learning environment has found an immense increase in popularity and investment in the last decade.   
(8) Security of such data for storing, processing, retrieving, and updating in the cloud environment is critical.

Based on the aforementioned observations, we found that the divergence in meaning of environment within the two corpora was relatively modest and perhaps slightly analogous. Furthermore, there were instances of overlapping collocational phrases involving environment in both corpora. While there exist subtle distinctions in the specific conditions referred to, individuals with a certain level of language proficiency would have little difficulty understanding environment in both fields. Notably, a language user’s disciplinary background can influence their choice of collocational phrases for environment, potentially leading to associations that may not align with the norms of their field. It is generally congruent with Table 7, wherein the P-value signifies significant differences, albeit with a relatively mild R-value of 0.38, indicating moderate divergence.

# 5.3.4. Aim

The word aim has a high degree of overlap in the most frequent collocates between the two corpora, with four of them being the same. This finding suggests that aim has similar meanings in soft and hard disciplines. Observing the contexts, we found that these collocates narrow down the scope of the term aim and clarify the achievement of aim. Moreover, this indicates that aim plays a role in elucidating research achievements in both disciplines, as shown in examples (19) and (20). Accordingly, we believe that aim has no discipline-specific sense in either disciplinary group.

(9) This study aims to investigate the anti-gastritis activity of the combination of ethanolic extract of cloves leaf and lime leaf extract in alcohol absolute-induced mice. (10) The aim of this work is to develop a new model for segmentation of brain structures in medical brain MR images.

Based on the preceding observations, we assert that the meaning of the word aim remains remarkably congruent within the two corpora, with a substantial overlap in its collocates. This concurs with Table 8, where a P-value of 0.052 suggests a lack of significant divergence in word meaning between the two disciplines.

# 6. Discussion

# 6.1. Key findings and response to research questions

In response to RQ1, the analysis of the four extracted words suggests that the IPD method can identify interdisciplinary polysemy effectively by capturing the subtle sense variations that occur in different academic contexts. This indicates the IPD method’s potential to reveal how the meanings of polysemous words may shift depending on the disciplinary context.

Regarding RQ2, the R-value provided by the IPD method tends to offer a meaningful metric, potentially helping users to quantitatively gauge the extent of differences in word usage between the two corpora. This metric may enhance our ability to compare how the meanings of polysemous words diverge or converge across disciplines, thus offering a clear and objective approach for assessing these variations. Simultaneously, during the case study process, we observed that using IPD to identify target polysemous words is extremely fast and adaptable to various disciplinary inputs. These findings suggest that the IPD method could be an effective tool for studying interdisciplinary language use, with potentially significant implications in academic research and educational applications.

Table 7 The five most frequent collocates of the word environment in the Hard and Soft Science Corpora.   

<html><body><table><tr><td colspan="3">The Hard Science Corpus</td><td colspan="3">The Soft Science Corpus</td></tr><tr><td>Collocate</td><td>Co-occurrence</td><td> Log-likelihood</td><td>Collocate</td><td>Co-occurrence</td><td>Log-likelihood</td></tr><tr><td>cloud</td><td>28</td><td>100.547</td><td>learning</td><td>85</td><td>232.083</td></tr><tr><td>urban</td><td>15</td><td>75.911</td><td>built</td><td>19</td><td>115.91</td></tr><tr><td>indoor</td><td>14</td><td>69.17</td><td>school</td><td> 43</td><td>98.864</td></tr><tr><td>harsh</td><td>7</td><td>52.086</td><td>work</td><td>50</td><td>92.311</td></tr><tr><td> learning</td><td>28</td><td>51.272</td><td>virtual</td><td>21</td><td>88.932</td></tr></table></body></html>

Table 8 The five most frequent collocates of the word aim in the Hard and Soft Science Corpora.   

<html><body><table><tr><td colspan="3">The Hard Science Corpus</td><td colspan="3">The Soft Science Corpus</td></tr><tr><td>Collocate</td><td>Co-occurrence</td><td>Log-likelihood</td><td>Collocate</td><td>Co-occurrence</td><td>Log-likelihood</td></tr><tr><td>study</td><td>142</td><td>560.767</td><td>study</td><td>244</td><td>675.54</td></tr><tr><td>present</td><td>41</td><td>124.625</td><td>paper</td><td>72</td><td>175.495</td></tr><tr><td>work</td><td>39</td><td>124.27</td><td> present</td><td>43</td><td>111.67</td></tr><tr><td>research</td><td>22</td><td>56.021</td><td>article</td><td>57</td><td>110.175</td></tr><tr><td>paper</td><td>31</td><td>50.749</td><td> research</td><td>71</td><td>75.856</td></tr></table></body></html>

# 6.2. Pedagogical implications

Our study introduces IPD, a novel sense-based approach that explores interdisciplinary polysemy as well as captures and quantifies semantic variation across disciplines. This approach increases the sensitivity of polysemy detection and provides a practical tool for addressing communication barriers between disciplines. Our framework facilitates the generation of customised word lists that reflect semantic differences between any two selected texts, offering an immediately useable resource tailored to the user’s needs. Such dynamically generated lists have significant implications for academic English teaching.

The inherent complexity of polysemous words suggests the potential benefit of emphasising the discipline-specific nature of word meanings in educational settings. According to Hyland (2002), this complexity poses a significant challenge for students engaged in joint degrees or interdisciplinary studies; therefore, recognising these discipline-specific nuances might be particularly beneficial. Teaching students to identify and use the specific senses of polysemous words prevalent in their respective disciplines may help them systematically understand the dominant sense and minor senses of a word form within a given text. Furthermore, some existing teaching materials may not focus on contrasting word usage across disciplines, limiting students’ understanding of lexical choice across registers. Deignan and Love (2021) observed that while problematic uses of polysemous terms are frequently noted in educational settings, there is no objective or comprehensive method for distinguishing between both everyday meanings and the discipline-specific meanings of such vocabulary across different fields, which contributes to students’ confusion. IPD is well-positioned to address this gap by identifying any differences in the dominant senses of vocabulary across various materials, thus enabling educators to design teaching resources and develop classroom activities with greater precision.

Moreover, understanding the use of polysemous words across disciplines serves as an excellent reminder of the differences in knowledge construction between fields. For learners new to academic writing, there might be misconceptions that authors, regardless of their disciplinary backgrounds, adopt similar collocational patterns. However, as discussed in Section 6.1, our analysis reveals that this is not true. It demonstrates how different disciplines use polysemous words, such as the different uses of functions and stress in varied ways, influenced by their unique contexts and conventions. This variation highlights the importance of considering disciplinary specificity in collocational patterns, as the expectations tied to specific terms can differ significantly between fields (Hyland, 2002). Furthermore, IPD can enlighten students regarding the significant differences in vocabulary application among writers from different disciplinary backgrounds. This enhances students’ appreciation of the diversity of academic language and helps them master the skills for practicing interdisciplinary communication. Therefore, emphasising the discipline-dependent nature of polysemous words can help students navigate potential semantic confusions when engaging in interdisciplinary research, thereby improving the precision and depth of academic discourse.

# 7. Conclusion

This paper introduces the interdisciplinary polysemy detection (IPD) method, which identifies polysemous words within disciplines and quantitatively measures the semantic differences between their senses. Our evaluation indicates that IPD is objective and efficient, and can quickly generate a word list containing vocabulary with interdisciplinary polysemy by analysing input materials. Through this, IPD can provide support for learners in understanding nuanced semantic variations and for teachers in designing cross-disciplinary language curricula. Although our study advances in identifying polysemous words, further improvements are needed, particularly in determining the number of associated senses.

# Funding

This research is supported by the National Social Science Fund of China (Number: 19BYY082).

# CRediT authorship contribution statement

Wenshu Geng: Writing – review & editing, Writing – original draft, Visualization, Validation, Resources, Methodology, Investi gation, Data curation, Conceptualization. Maocheng Liang: Writing – review & editing, Supervision, Resources, Project administration, Methodology, Investigation, Formal analysis, Conceptualization.

# Declaration of interest

None.

# Acknowledgements

We would like to express our sincere gratitude to Li Yan for her guidance and support throughout the process, from the initial writing stage to subsequent revisions. We are also deeply thankful to Siwen Guo for her encouragement and supportive feedback on the initial idea. We are deeply grateful to the editor not only for inviting high-quality reviewers to provide insightful comments, but also for the continued guidance and helpful suggestions throughout the review process. The constructive feedback from the reviewers has greatly inspired us, and the editors’ dedicated efforts have been invaluable in helping us improve our work.

# References

Acharya, A. S., Prakash, A., Saxena, P., & Nigam, A. (2013). Sampling: Why and how of it. Indian Journal of Medical Specialties, 4(2), 330–333.   
Anderson, M. J., & Walsh, D. C. (2013). PERMANOVA, ANOSIM, and the Mantel test in the face of heterogeneous dispersions: What null hypothesis are you testing? Ecological Monographs, 83(4), 557–574.   
Ansell, A., Bravo-Marquez, F., & Pfahringer, B. (2021). PolyLM: Learning about polysemy through language modeling. In P. Merlo, J. Tiedemann, & R. Tsarfaty (Eds.), Proceedings of the 16th conference of the European chapter of the association for computational linguistics: Main volume (pp. 563–574). Association for Computational Linguistics. https://doi.org/10.18653/v1/2021.eacl-main.45.   
Ballard, B., & Clanchy, J. (1991). Teaching students from overseas: A brief guide for lecturers and supervisors. Longman Cheshire.   
Cantacessi, C., Giacomin, P., Croese, J., Zakrzewski, M., Sotillo, J., McCann, L., Nolan, M. J., Mitreva, M., Krause, L., & Loukas, A. (2014). Impact of experimental hookworm infection on the human gut microbiota. The Journal of Infectious Diseases, 210(9), 1431–1434.   
Chapman, M. G., & Underwood, A. J. (1999). Ecological patterns in multivariate assemblages: Information and interpretation of negative values in ANOSIM tests. Marine Ecology Progress Series, 180, 257–265.   
Charles, M. (2003). ‘This mystery…’: A corpus-based study of the use of nouns to construct stance in theses from two contrasting disciplines. Journal of English for Academic Purposes, 2(4), 313–326.   
Clarke, K. R. (1993). Non-parametric multivariate analyses of changes in community structure. Australian Journal of Ecology, 18(1), 117–143. https://doi.org/ 10.1111/j.1442-9993.1993.tb00438.x   
Clarke, K. R., & Gorley, R. N. (2006). Primer. Plymouth: PRIMER-e.   
Clarke, K. R., Somerfield, P. J., & Chapman, M. G. (2006). On resemblance measures for ecological studies, including taxonomic dissimilarities and a zero-adjusted Bray–Curtis coefficient for denuded assemblages. Journal of Experimental Marine Biology and Ecology, 330(1), 55–80.   
Coffin, C., & Hewings, A. (2003). In C. Coffin, M. J. Curry, S. Goodman, A. Hewings, T. Lillis, & J. Swann (Eds.), Writing for different disciplines (pp. 45–72). Routledge. http://www.routledge.co.uk/shopping_cart/products/product_detail.asp?sku=&isbn=0415261368&pc.   
Couturier, L. I. E., Rohner, C. A., Richardson, A. J., Marshall, A. D., Jaine, F. R. A., Bennett, M. B., Townsend, K. A., Weeks, S. J., & Nichols, P. D. (2013). Stable isotope and signature fatty acid analyses suggest reef manta rays feed on demersal zooplankton. PLoS One, 8(10), Article e77152. https://doi.org/10.1371/journal. pone.0077152   
Cruse, D. A. (1986). Lexical semantics. Cambridge university press.   
Deignan, A., & Love, R. (2021). Using corpus methods to identify subject specific uses of polysemous words in English secondary school science materials. Corpora, 16 (2), 165–189.   
Du, E., Guo, W., Zhao, N., Chen, F., Fan, Q., Zhang, W., Huang, S., Zhou, G., Fu, T., & Wei, J. (2022). Effects of diets with various levels of forage rape (Brassica napus) on growth performance, carcass traits, meat quality and rumen microbiota of Hu lambs. Journal of the Science of Food and Agriculture, 102(3), 1281–1291. https:// doi.org/10.1002/jsfa.11466   
Ethayarajh, K. (2019). How contextual are contextualized word representations? Comparing the geometry of BERT. ELMo, and GPT-2 embeddings.   
Evans, R., Gelbukh, A., Grefenstette, G., Hanks, P., Jakubíˇcek, M., McCarthy, D., Palmer, M., Pedersen, T., Rundell, M., Rychlỳ, P., & others. (2018). Adam kilgarriff’s legacy to computational linguistics and beyond. Computational Linguistics and intelligent text processing: 17th international conference, CICLing 2016, konya, Turkey, april 3–9, 2016, revised selected papers, Part I 17.   
Fellbaum, C. (1998). WordNet: An electronic lexical database. MIT press.   
Fillmore, C. J. (1975). An alternative to checklist theories of meaning (Vol. 1, pp. 123–131).   
Gabrielatos, C. (2018). Keyness analysis: Nature, metrics and techniques. In Corpus approaches to discourse (pp. 225–258). Routledge.   
Galve, I. G. (1998). The textual interplay of grammatical metaphor on the nominalizations occurring in written medical English. Journal of Pragmatics, 30(3), 363–385.   
Gardner, D., & Davies, M. (2014). A new academic vocabulary list. Applied Linguistics, 35(3), 305–327.   
Garí Soler, A., & Apidianaki, M. (2021). Let’s play mono-poly: BERT can reveal words’ polysemy level and partitionability into senses. Transactions of the Association for Computational Linguistics, 9, 825–844.   
Goel, A., Sharma, C., & Kumaraguru, P. (2022). An unsupervised, geometric and syntax-aware quantification of polysemy. In Y. Goldberg, Z. Kozareva, & Y. Zhang (Eds.), Proceedings of the 2022 conference on empirical methods in natural language processing (pp. 10565–10574). Association for Computational Linguistics. https:// doi.org/10.18653/v1/2022.emnlp-main.722.   
Green, C., & Lambert, J. (2018). Advancing disciplinary literacy through English for academic purposes: Discipline-specific wordlists, collocations and word families for eight secondary subjects. Journal of English for Academic Purposes, 35, 105–115.   
Gross, M. (1993). Local grammars and their representation by finite automata. Data, Description, Discourse. Papers on the English Language in Honour of John McH Sinclair, 26–38.   
Haber, J., & Poesio, M. (2021). Patterns of polysemy and homonymy in contextualised language models. Findings of the Association for Computational Linguistics: EMNLP, 2663–2676. https://doi.org/10.18653/v1/2021.findings-emnlp.226, 2021.   
Halliday, M. A. K. (2004). The Language of science (Vol. 5). A&C Black.   
Han, J., Kamber, M., & Pei, J. (2012). Getting to know your data. Data Mining, 2, 39–82.   
Hanks, P. (2013). Lexical analysis: Norms and exploitations. Mit Press.   
Hanks, P., & Moˇze, S. (2019). The way to analyse ‘way’: A case study in word-specific local grammar. International Journal of Lexicography, 32(3), 247–269. https:// doi.org/10.1093/ijl/ecz005   
Hyland, K. (2002). Specificity revisited: How far should we go now? English for Specific Purposes, 21(4), 385–395.   
Hyland, K., & Tse, P. (2007). Is there an “academic vocabulary”. Tesol Quarterly, 41(2), 235–253.   
Institute, A. N. S., Library, C. of N., & Associations Us, I. (1979). American national standard for writing abstracts. New York: The Institute.   
Kenton, J. D. M.-W. C., & Toutanova, L. K. (2019). Bert: Pre-Training of deep bidirectional transformers for language understanding. Proceedings of NAACL-HLT.   
Kilgarriff, A. (1997). I don’t believe in word senses. Computers and the Humanities, 31(2), 91–113.   
Kolb, D. A. (1981). Learning styles and disciplinary differences. The modern American college, 1, 232–235.   
Li, J., & Joanisse, M. F. (2021). Word senses as clusters of meaning modulations: A computational model of polysemy. Cognitive Science, 45(4), Article e12955.   
Love, R., Dembry, C., Hardie, A., Brezina, V., & McEnery, T. (2017). The Spoken BNC2014: Designing and building a spoken corpus of everyday conversations. International Journal of Corpus Linguistics, 22(3), 319–344.   
Mitsugi, M. (2017). Schema-based instruction on learning English polysemous words: Effects of instruction and learners’ perceptions. Journal of Pan-Pacific Association of Applied Linguistics, 21(1), 21–43.   
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., & Dubourg, V. (2011). Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12, 2825–2830.   
Peters, M. E., Neumann, M., Zettlemoyer, L., & Yih, W. (2018). Dissecting contextual word embeddings: Architecture and representation. arXiv Preprint arXiv: 1808.08949.   
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). Language models are unsupervised multitask learners. OpenAI Blog, 1(8), 9.   
Schlechtweg, D., McGillivray, B., Hengchen, S., Dubossarsky, H., & Tahmasebi, N. (2020). SemEval-2020 task 1: Unsupervised lexical semantic change detection. Proceedings of the fourteenth workshop on semantic evaluation (pp. 1–23).   
Scott, M. (2020). WordSmith tools version 8, stroud: Lexical analysis software.   
Shoemark, P., Liza, F. F., Nguyen, D., Hale, S., & McGillivray, B. (2020). Room to glo: A systematic comparison of semantic change detection approaches with word embeddings. Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (pp. 66–76). EMNLP-IJCNLP). https://doi.org/10.18653/v1/D19-1007   
Skoufaki, S., & Petri´c, B. (2021). Exploring polysemy in the academic vocabulary list: A lexicographic approach. Journal of English for Academic Purposes, 54, Article 101038.   
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I. (2017). Attention is all you need. Advances in Neural Information Processing Systems, 30.   
Vichi, M., Allen, J. I., Masina, S., & Hardman-Mountford, N. J. (2011). The emergence of ocean biogeochemical provinces: A quantitative assessment and a diagnostic for model evaluation. Global Biogeochemical Cycles, 25(2). https://doi.org/10.1029/2010GB003867   
Wang, K., Shen, Z., Huang, C., Wu, C.-H., Eide, D., Dong, Y., Qian, J., Kanakia, A., Chen, A., & Rogahn, R. (2019). A review of Microsoft academic services for science of science studies. Frontiers in Big Data, 2. https://www.frontiersin.org/articles/10.3389/fdata.2019.00045.   
Webster, J. J. (2004). The language of science.   
Wei, N. (2017). A corpus-based local grammar: Background, methods and features. Journal of Foreign Languages, 40(1), 10–12.   
Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). Bert: Pre-training of deep bidirectional transformers for language understanding. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. (pp. 4171–4186). doi: 10.18653/V1/N19-1423.

Wenshu Geng, is currently pursuing a Ph.D. degree at the School of Foreign Languages, Beihang University (BUAA), Beijing, China. She received her M.A. degree from City University of Hong Kong, Hong Kong, China, in 2020. Her primary research interest is in Corpus Linguistics.