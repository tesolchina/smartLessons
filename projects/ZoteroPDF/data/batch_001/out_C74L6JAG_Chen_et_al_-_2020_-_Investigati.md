# Investigating college EFL learners’ perceptions toward the use of Google Assistant for foreign language learning

Howard Hao-Jan Chen, Christine Ting-Yu Yang & Kyle Kuo-Wei Lai

To cite this article: Howard Hao-Jan Chen, Christine Ting-Yu Yang & Kyle Kuo-Wei Lai (2020): Investigating college EFL learners’ perceptions toward the use of Google Assistant for foreign language learning, Interactive Learning Environments, DOI: 10.1080/10494820.2020.1833043

To link to this article: https://doi.org/10.1080/10494820.2020.1833043

# Investigating college EFL learners’ perceptions toward the use of Google Assistant for foreign language learning

Howard Hao-Jan Chen $\textcircled{1}$ , Christine Ting-Yu Yang and Kyle Kuo-Wei Lai

Department of English, National Taiwan Normal University, Taipei, Taiwan

# ABSTRACT

Recent studies on the use of Intelligent Personal Assistant (IPA) for second language (L2) learnring have found that IPAs such as Amazon’s Alexa is useful and motivating for L2 learners and that learners’ language proficiency might influence their perceptions toward IPAs. However, most existing studies focused on the potentials of Alexa and paid little attention to Google Assistant (GA). This study was thus conducted to investigate how L2 learners at different proficiency levels perceive the potentials of $G A$ . Twenty-nine EFL college students were recruited to try various voice commands for an hour in order to investigate learners’ perceptions toward the potentials of GA for language learning. Results of the survey and interview show that these learners enjoyed interacting with GA and considered GA an inspiring tool to learn English. They also found that GA can be useful in improving their speaking and listening skills. They perceived GA’s pronunciation to be quite natural and its utterances to be easily comprehensible. Results also reveal that higher level learners achieved better mutual comprehensibility with $G A _ { i }$ , whereas lower level learners encountered more challenges due to their mispronunciations. Based on these findings, future research directions and pedagogical suggestions on IPA-assisted L2 learning are provided.

# ARTICLE HISTORY

Received 13 May 2020   
Accepted 2 October 2020

# KEYWORDS

Intelligent personal assistants; Google Assistant; human-machine interaction; learners’ perceptions; second language speech

# Introduction

With the advance of artificial intelligence (AI) and Natural Language Processing technology, useful and timely information can be accessed quickly via Intelligent Personal Assistants (IPAs), an application that uses inputs (e.g. a user’s voice, vision (images), and contextual information, etc.) to provide assistance by answering questions in natural language, making recommendations, and performing actions (Hauswald et al., 2015). In most cases, IPAs are installed on smart phones, tablet PCs, and smart speakers. Smart speakers, often used in home environment, are a type of voice command device with an integrated IPA that offers interactions with the help of one “hot word” (or several “hot words”). With the aid of automatic speech recognition (ASR) system, they are able to recognize a user’s voice from a distance and respond to a given command.

The most well-known smart speakers include Apple’s Homepod, Google Home series and Amazon Echo speakers. According to Statista $\circledcirc$ website’s report on the global market share of smart speakers between 2016 and 2019, Amazon Echo is currently the leading product (see Figure 1). It’s IPA, Alexa, can perform various types of tasks, such as make web searches, play music, and read Twitter posts/ emails. In addition to the built-in tasks, Amazon’s Alexa Skills store also offers many additional capabilities, allowing it to play games, get random facts about many things, and so on. Ranked second in the market share, Google Home series can provide services similar to those by Amazon Echo and have integrated support for home automation (i.e. letting users control smart home appliances with their voice command). The basic functions of Google Home series can be further enhanced by downloading the various Actions on Google online, and a few researchers have attempted to build their own programs via the use of Actions to create more interactive and enjoyable learning activities (cf. Ali & Hassan, 2018; Tagawa et al., 2019).

![](img/44c9101c7d23a980403d5aa88b2010cc681a3cb16959afe6b761bd0dce778c27.jpg)  
Smart speaker with IPA quarterly shipment share from 2016 to 2019, by vendor.

With the ability to orally interact with users, many educators and researchers have been arguing that IPAs can benefit second language (L2) learners’ language skills/knowledge. Canbek and Mutlu (2016) commented that IPAs can engage L2 learners in activities that develop their knowledge/skills in pronunciation, speaking, and listening. Similarly, Kessler (2018) highlighted that the ASR system in IPAs offers L2 learners with ample opportunities to practice speaking. Serving as a virtual peer to instantly retrieve and provide information, IPAs could support teachers in the language classroom and foster students’ self-learning to improve their pronunciation and vocabulary knowledge (Istrate, 2019). With appropriate teacher guidance of built-in apps/programs, IPAs can create a ubiquitous learning environment for L2 learners to practice listening and pronunciation anytime (Barcomb et al., 2017).

Based on researchers’ insights on IPAs, some research has been carried out to investigate the use of IPAs (e.g. Alexa, Google Assistant, and Apple’s Siri) in assisting L2 teaching and learning, and experimental evidence has demonstrated that IPAs can facilitate the development of learners’ speaking proficiency (Dizon, 2020) and reading comprehension (Sing et al., 2019). In addition to language gains, studies on learners’ perceptions toward the use of IPAs in L2 learning have shown learners’ positive opinions. For example, in Moussalli and Cardoso’s (2016) examination on adult English as a foreign language (EFL) learners’ perceptions toward the use of Alexa, the learners reported an enjoyable experience of speaking with Alexa, and they considered Alexa to be a useful tool for language learning, especially for pronunciation and vocabulary. Similar opinions were also yielded in Dizon (2017), in which his EFL college learners perceived Alexa to be a potentially useful language learning tool after using.

In addition to adult learners, young L2 learners were also found to hold a positive opinion on the potentials of IPAs for language learning. With well-designed AI-assisted tasks, Underwood (2017) observed that his EFL primary learners were highly engaged and motivated to speak English with the IPAs, and they would either reformulate or self-correct their English commands to have the IPAs execute their orders. Existing research has also revealed L2 learners’ positive perception toward the use of IPAs for autonomous learning. In a pilot study, Dizon and Tang (2019) discovered that their EFL college learners considered Alexa a useful tool to facilitate self-learning. Although no frequent use of Alexa was observed during the experiment, their participants still commented that Alexa could provide them with more opportunities to enhance their English speaking and pronunciation proficiency.

While L2 learners mostly perceive IPAs as a useful and engaging language learning tool, their perceptions toward how well they are understood by IPAs are rather inconsistent. In Moussalli & Cardoso’s investigation (2019) on Alexa’s ability to recognize ESL learners’ accented speeches, the learners’ responses to survey and interview questions indicated that both they and Alexa could comprehend each other’s speech smoothly (“Alexa can understand me.”: $M = 3 . 5 5 / 5 ;$ “I can understand Alexa”: $M = 4 . 1 8 / 5$ ). Comparison between the accuracy rate of human raters’ transcriptions of the learners’ speech $( 9 5 \% )$ and that of Alexa’s $( 8 3 \% )$ were all above $8 0 \%$ . Based on their discoveries, the researchers concluded that Alexa adapts well to L2 learners’ accented speech as compared to humans in terms of comprehensibility and intelligibility. There is, however, a noticeable difference (i.e. $12 \%$ ) between human raters’ accuracy rate and Alexa’s, indicating that Alexa still have certain problems in understanding L2 learners’ accented speech. In fact, IPA’s difficulties in fully understanding L2 learners’ utterances had already been reported in Moussalli and Cardoso (2016), in which the EFL learners complained that Alexa sometimes could not understand their requests. This deficiency is further highlighted in Dizon (2017), whose analysis on Alexa’s transcriptions of EFL learners’ voice commands showed an accuracy rate of $5 0 \%$ only.

IPA’s less satisfactory performance on comprehending L2 learners’ utterances might be related to learners’ poorer command of the target language. Y. Wu et al.’s (2020a, 2020b) comparisons of native speakers’ and L2 speakers’ interactions with Google Assistant (GA) showed that, as compared to native speakers (NSs), L2 speakers had heavier mental workload and more difficulties in humanIPA interaction due to their lack of automatic lexical retrieval in the target language production. In Pyae and Scifleet’s studies (2018, 2019), L2 speakers’ experiences of interacting with GA were also less positive than NSs’. Specifically, these L2 speakers reported their frustration of having difficulties “in using English to structure sentences, choose the “right” words (vocabularies), and pronounce instructions in a way that GHSS [Google Home Smart Speaker] recognized (Pyae & Scifleet, 2019, p. 5)”, even though its IPA (i.e. GA) is tested to perform better than other programs in transcribing non-native speech (cf. Daniels & Iwago, 2017; McCrocklin et al., 2019). Based on their findings, both Wu et al. and Pyae & Scifleet argue that L2 speakers’ language proficiency might influence the degree to which IPAs comprehend their utterances and therefore positively/negatively affect their attitude toward using IPAs. More research should thus be conducted to investigate how L2 speakers with different proficiency levels interact with IPAs (Y. Wu et al., 2020a).

This study hence sets out to examine the role language proficiency plays in L2 learners’ perceptions toward the use of IPAs for English learning. The reasons for targeting on learners’ perception were that learners’ positive attitudes and high perceived usefulness of a used technology often positively influence their learning achievement of the subject matter (Brown et al., 2004; Cheng & Chen, 2019; Joo et al., 2012; Rahimi & Yadollahi, 2011; Sung et al., 2017), and that different variables (e.g. proficiency level, learning context, etc.) might cause learners’ different learning experiences of using the same technology for autonomous learning (Godwin-Jones, 2019). Therefore, a better understanding of L2 learners’ perception of IPA-assisted L2 learning allows us to identify both strengths and weaknesses of IPAs for learners at different proficiency levels. Specifically, we targeted on learners’ opinions about the use of GA via Google Home series, which is one of the best-selling products worldwide yet currently less researched on as compared to Amazon’s Alexa. We expect that the current study can answer the following research questions:

(1) What were EFL learners’ perceptions toward $G A$ for language learning?   
(2) Would EFL learners’ proficiency levels influence their perceptions toward GA for language learning?   
(3) Would EFL learners’ language proficiency affect the degree to which their utterances were comprehended by GA?   
(4) What strategies would EFL learners use when they had communication difficulties with GA?

# Methodology

# Participants

Twenty-nine EFL learners (6 males and 23 females) were recruited from a university in northern Taiwan, all of whom were pre-informed of receiving around 16 USD as a reward upon completion of the experiment before signing up. The participants were aged from 18–22 (averaged age: 20.24) with Mandarin Chinese as their first language. Because one of the research aims was to investigate the role of proficiency levels on learners’ perceptions toward the use of IPA, all of the participants were required to provide their scores on the speaking section of TOEIC, TOEFL iBT, IELTs or GEPT, and they were further divided into low (L), intermediate (I), and high-intermediate (HI) groups based on their scores. Table 1 shows the conversion of different test scores and the number of participants for each proficiency level.

# Instruments

# Google Assistant on Google Home Hub

The investigated IPA was $G A$ , and the smart speaker Google Home Hub (see Figure 2) was chosen as the medium for the participants to interact with GA. The reason for adopting Google Home Hub was that this device is equipped with a touch panel, which provides certain types of visual aid (e.g. subtitles, pictures, video clips) depending on the applications. We thus decided to use Google Home Hub as the medium to observe how the participants would interact with it and how this feature would influence the participants’ perceptions toward the use of IPA for English learning.

# Questionnaire and survey

A 5-point Likert-scaled questionnaire (from $1 =$ strongly disagree to $5 =$ strongly agree) with eight items was made to gather information regarding the participants’ general perceptions toward English and their English learning experiences. As demonstrated in Table 2, the degrees of fondness and confidence in learning/using English rise with the increase of proficiency level. In addition, HI participants reported a comparatively higher score on the opportunity to speak English in their daily life, whereas the other two groups considered themselves to have fewer chances to do so.

In addition to a questionnaire, a survey was administered to the participants to gain their perceptions toward the use of GA for English learning and the perceived mutual comprehensibility of learner-IPA interactions. The survey consisted with 22 5-point Likert-scaled items (from $1 =$ strongly disagree to $5 =$ strongly agree), one multiple-choices question about the participants’ favorite applications, and two open-ended questions that investigate the perceived strengths and weaknesses of $G A$ for English learning.

Number of participants and conversation of different speaking scores to the three proficiency levels.   

<html><body><table><tr><td></td><td></td><td colspan="4">Score Range of Speaking Section</td></tr><tr><td>Proficiency (no. of participants)</td><td>CEFR</td><td>TOEIC</td><td>TOEFL iBT</td><td>IELTs</td><td>GEPT</td></tr><tr><td>HI (n=8)</td><td>B2</td><td>level 7</td><td>20-</td><td>5.5-</td><td>High-intermediate</td></tr><tr><td>I (n = 13)</td><td>B1</td><td>level 5-6</td><td>16-19</td><td>4.0-5.4</td><td>Intermediate</td></tr><tr><td>L (n = 8)</td><td>A2</td><td>level 4</td><td>-15</td><td>3.0-3.9</td><td>Basic</td></tr></table></body></html>

![](img/3ca1119e1b6d6a9d83befbdd219b6adc6716eddb9cfa70f1861c81b5c4f99056.jpg)  
Interface of Google Home Hub.

Descriptive results of participants’ English learning experience.   

<html><body><table><tr><td rowspan="2"></td><td colspan="4">Mean (SD)</td></tr><tr><td>L</td><td></td><td>HI</td><td>ALL</td></tr><tr><td>Item I like English.</td><td>3.50 (.76)</td><td>4.00 (.58)</td><td>4.88 (.35)</td><td>4.10 (.77)</td></tr><tr><td>I get good grades in English.</td><td>2.50 (.53)</td><td>3.77 (.60)</td><td>4.13 (.64)</td><td>3.52 (.87)</td></tr><tr><td>English is difficult for me.</td><td>3.50 (.53)</td><td>3.08 (.86)</td><td>1.88 (.64)</td><td>2.86 (.95)</td></tr><tr><td>I can speak English fluently.</td><td>2.50 (.53)</td><td>3.15 (.55)</td><td>3.88 (.83)</td><td>3.17 (.80)</td></tr><tr><td>I am anxious when speaking English.</td><td>3.13 (.64)</td><td>2.92 (.76)</td><td>2.13 (.99)</td><td>2.76 (.87)</td></tr><tr><td>I have good English listening skills.</td><td>3.38 (.52)</td><td>3.54 (.52)</td><td>4.25 (.71)</td><td>3.69 (.66)</td></tr><tr><td>I have the chance to speak English in my daily life.</td><td>2.13 (.64)</td><td>2.69 (1.11)</td><td>3.63 (1.06)</td><td>2.79 (1.11)</td></tr><tr><td>I am motivated to improve my English.</td><td>3.38 (1.06)</td><td>4.00 (.58)</td><td>4.50 (.76)</td><td>3.97 (.87)</td></tr></table></body></html>

To save the participants’ time and have the whole procedure run smoothly, the questionnaire and the survey were combined into one file and given to the participants upon the completion of the hands-on session.

# Interview

To deeply look into the participants’ ideas about the use of GA for English learning that might not be revealed in the survey, a semi-structured oral interview was individually given to each participant right after they completed the survey. The interview consisted of the following three questions: 1) What’s your overall feeling of interacting with GA? 2) What are your favorite applications? And why? and 3) What are the strengths and weaknesses of using $G A$ in English learning? Any suggestions for further improvement?

# Logs of conversations between participants and IPA

When a user logs in his/her Google account, all of his/her operation of Google-related applications is automatically recorded and can be retrieved under the directory My Activity via Chrome. The recorded data also includes the transcriptions of the conversation between the user and GA. To better pinpoint the occasions and causes of communication breakdowns (CBs) in learner-IPA interaction, the transcriptions of the conversation between each participant and GA were downloaded for further analysis. Figure 3 is an excerpted conversation log between one of the low-proficiency

# talk to Pandora Vince

Pandora Vince

![](img/6c346e1c15fa814b2b037db8aa53a9dc04e71ca6de0af1407333facfbc9c43a2.jpg)  
Excerpted interaction logs between one of the intermediate-level learners with GA.

![](img/13ea6f804536111cb63585e3ba26fbdc67ecb081020afb683880028087f4f40d.jpg)  
Procedures of the experiment.

learners and GA. Words/sentences in blue were utterances produced by the learner, and texts in black were GA’s responses to the learner’s queries/questions.

# Procedures

Before the hands-on session, the participants were firstly informed of the video-taping and recording of the whole experiment (including the interview), and all of the participants agreed with the taping and signed a consent form. Then one of the researchers briefly introduced how to interact with $G A$ with some basic commands (e.g. “Hey, Google, play some music.”; “Hey, Google, stop.”) and explained the whole procedure to the participants.

The experiment consisted of two sessions: a 60-min hands-on session to interact with $G A$ and a 30-min survey session. The hands-on session included six 10-min tasks that allowed participants to experience various activities provided by GA. The first task required the participants to ask GA various questions for information. In the second and third tasks, the participants commanded $G A$ to play music/news and tell stories/jokes. In the fourth and fifth task, the participants played four interactive games and freely conversed with five chatbots available on Google Home Hub. The last task asked the participants to use two English learning apps developed by a Taiwanese team. Throughout the hands-on session, the participants were provided with hand cards (see Appendix) that contained instructions of what they should do for each task and/or example commands for their reference. After the hands-on session, the questionnaire-survey was given to the participants, and the participants were allotted around $2 0 \mathrm { \ m i n }$ to complete it. Following the survey was the interview, which lasted around $1 0 \mathrm { \ m i n }$ . The whole experiment took about $1 . 5 ~ \mathsf { h }$ long (as illustrated in Figure 4).

# Results

# Learners perceptions toward the use of GA

The first research question investigated the participants’ perceptions toward the use of GA for English learning. Before reporting the survey results on the participants’ perceptions, a Cronbach’s α test was conducted to the survey and yielded the result of 0.924, showing that the items have high internal consistency.

As shown in Table 3, the participants generally had a positive perception toward the use of GA after the hands-on session. They believed that GA could boost their motivation in learning English pronunciation, vocabulary, listening, and speaking. They also considered that their pronunciation, vocabulary size, reading ability, listening ability, and speaking ability would benefit from the use of GA. They found it less stressful to use GA for practicing English speaking and listening as compared to other in-class activities and speaking in front of their teachers and/or classmates. In addition, the participants considered GA’s English was easily comprehensible and sounded quite natural. In general, they found their interactions with $G A$ enjoyable and interesting, and considered to use GA to learn English pronunciation and other foreign languages. Although the participants’ perceptions toward the use of GA for English learning were mostly positive, they did have more concerns on GA’s ability to understand their utterances $( M = 3 . 2 8 / 5$ , SD $= . 7 5 )$ , which rated relatively lower than their perceptions toward their understanding of GA’s English $\begin{array} { r } { { ( M = 4 . 2 1 / 5 } } \end{array}$ $\mathsf { S D } = . 5 6 )$ ).

# Comparisons of learners’ perceptions across different levels

In addition to the participants’ perceptions in general, the current study also aims to investigate whether the participants’ proficiency levels affect their perceptions toward the use of GA for English learning. Each proficiency group’s responses to the survey items were obtained and further analyzed with one-way ANOVA tests individually, results of which were presented in Table 4. For the majority of the items, there were no significant differences among the mean scores of the following aspects, namely learning motivation, learning anxiety, usefulness for language learning, willingness to use, and overall experience.

Results of participants’ general perceptions toward the use of .   

<html><body><table><tr><td>Item</td><td>Mean</td><td>SD</td></tr><tr><td>Learning motivation</td><td></td><td></td></tr><tr><td>GA can boost my motivation to learn English.</td><td>3.72</td><td>.88</td></tr><tr><td>GA can boost my motivation to learn English pronunciation..</td><td>3.97</td><td>.91</td></tr><tr><td>GA can boost my motivation to learn English words..</td><td>3.72</td><td>1.00</td></tr><tr><td>GA can boost my motivation to improve my English listening ability.</td><td>4.24</td><td>.87</td></tr><tr><td>GA can boost my motivation to improve my English speaking fluency..</td><td>4.00</td><td>.96</td></tr><tr><td>Learning anxiety</td><td>4.17</td><td></td></tr><tr><td>Compared to other in-class activities (e.g. role-playing, recitation, and group cooperation), using GA to practice English listening is less stressful for me.</td><td></td><td>.93</td></tr><tr><td>Compared to other in-class activities (e.g. role-playing, recitation, and group cooperation), using GA to practice English speaking is less stressful for me.</td><td>4.07</td><td>1.07</td></tr><tr><td>Compared to speaking English in front of a teacher, using GA to practice English speaking is less stressful for me.</td><td>3.97</td><td>1.12</td></tr><tr><td>Compared to speaking English in front of my classmates, using GA to practice English speaking is les stressful for me.</td><td>3.90</td><td>1.14</td></tr><tr><td>Usefulness for language learning</td><td></td><td></td></tr><tr><td>GA can help me improve my pronunciation.</td><td>3.79</td><td>.98</td></tr><tr><td>GA can help me increase my vocabulary size.</td><td>3.72</td><td>.84</td></tr><tr><td>With the text on the screen, GA can help me improve my English reading skills.</td><td>3.93</td><td>.92</td></tr><tr><td>GA can improve my English listening comprehension..</td><td>4.28</td><td>.59</td></tr><tr><td>GA can improve my English speaking fluency.</td><td>3.79</td><td>.90</td></tr><tr><td>GA is a good language learning tool.</td><td>3.93</td><td>.88</td></tr><tr><td>Willingness to use.</td><td></td><td></td></tr><tr><td>I will learn English pronunciation by using GA.</td><td>3.76</td><td>.99</td></tr><tr><td>I want to use GA to learn other languages.</td><td>3.83</td><td>.97</td></tr><tr><td>Mutual Comprehensibility of Learner-IPA Utterances</td><td></td><td></td></tr><tr><td>GA can understand my English.</td><td>3.28</td><td>.75</td></tr><tr><td>I can understand the English of GA.</td><td></td><td></td></tr><tr><td>Do you think the pronunciation of GA is natural?.</td><td>4.21</td><td>.56 .69</td></tr><tr><td>Overall experience</td><td>4.48</td><td></td></tr><tr><td>Overall, I like the feeling of using GA during the hands-on session.</td><td>4.07</td><td>1.07</td></tr><tr><td></td><td></td><td></td></tr><tr><td>Overall, I find it interesting to interact with GA.</td><td>3.97</td><td>1.12</td></tr></table></body></html>

One-way ANOVA results of $\downarrow , \downarrow ,$ and HI groups’ perceptions toward the use of .   

<html><body><table><tr><td rowspan="2">Item</td><td colspan="3">Mean (SD)</td><td rowspan="2">t/F</td><td rowspan="2">Sig.</td><td rowspan="2">Post hoc</td></tr><tr><td>L</td><td>1</td><td>HI</td></tr><tr><td colspan="7">Learning Motivation.</td></tr><tr><td>GA can boost my motivation to learn English.</td><td>3.50 (.76)</td><td>3.92 (.95)</td><td>3.63 (.92)</td><td>.622</td><td>.545</td><td></td></tr><tr><td>GA can boost my motivation to learn English pronunciation.</td><td>4.00 (1.07)</td><td>4.23 (.73)</td><td>3.50 (.93)</td><td>1.701</td><td>.202</td><td></td></tr><tr><td>GA can boost my motivation to learn English words.</td><td>3.63 (1.06)</td><td>3.92 (.95)</td><td>3.50 (1.07)</td><td>.483</td><td>.623</td><td></td></tr><tr><td>GA can boost my motivation to improve my English listening</td><td>4.13 (.99)</td><td>4.23 (.60)</td><td>4.38 (1.19)</td><td>.156</td><td>.856</td><td></td></tr><tr><td>ability. GA can boost my motivation to improve my English speaking</td><td>4.25 (1.04)</td><td>4.08 (.86)</td><td>3.63 (1.06)</td><td>.911</td><td>.415</td><td></td></tr><tr><td colspan="7">fluency. Learning Anxiety</td></tr><tr><td>Compared to other in-class activities (e.g. role-playing, recitation, and group cooperation), using GA to practice</td><td>4.63 (.52)</td><td>4.15 (.90)</td><td>3.75 (1.16)</td><td>1.895</td><td>.171</td><td></td></tr><tr><td>English listening is less stressful for me. Compared to other in-class activities (e.g. role-playing, recitation, and group cooperation), using GA to practice</td><td>4.00 (1.07)</td><td>4.23 (.93)</td><td>3.88 (1.36)</td><td>.283</td><td>.756</td><td></td></tr><tr><td>English speaking is less stressful for me. Compared to speaking English in front of a teacher, using GA</td><td>4.25 (1.16)</td><td>4.08 (.95)</td><td>3.50 (1.31)</td><td>1.019</td><td>.375</td><td></td></tr><tr><td>to practice English speaking is less stressful for me. Compared to speaking English in front of my classmates, using GA to practice English speaking is less stressful for me.</td><td>4.13 (1.13)</td><td>4.23 (.93)</td><td>3.13 (1.25)</td><td>2.868</td><td>.075</td><td></td></tr><tr><td>Usefulness for language learning GA can help me improve my pronunciation.</td><td>4.00 (.93)</td><td>4.00 (.82)</td><td>3.25 (1.16)</td><td>1.803</td><td>.185</td><td></td></tr><tr><td>GA can help me increase my vocabulary size.</td><td>3.75 (.71)</td><td>3.85 (.90)</td><td>3.50 (.93)</td><td>.407</td><td>.670</td><td></td></tr><tr><td>With the text on the screen, GA can help me improve my</td><td>3.75 (1.04)</td><td>4.08 (.86)</td><td>3.88 (.99)</td><td>.315</td><td>.733</td><td></td></tr><tr><td>English reading skills. GA can improve my English listening comprehension.</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>GA can improve my English speaking fluency.</td><td>4.13 (.64) 4.13 (.83)</td><td>4.38 (.65) 3.85 (.69)</td><td>4.25 (.46) 3.38 (1.19)</td><td>.469 1.473</td><td>.631 .248</td><td></td></tr><tr><td>GA is a good language learning tool..</td><td>4.00 (.93)</td><td>4.08 (.49)</td><td>3.63 (1.30)</td><td>.665</td><td>.523</td><td></td></tr><tr><td>Willingness to use.</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>I will learn English pronunciation by using GA.</td><td>3.88 (.83)</td><td>3.92 (.86)</td><td>3.38 (1.30)</td><td>.829</td><td>.448</td><td></td></tr><tr><td>I want to use GA to learn other languages.</td><td>3.75 (.71)</td><td>4.00 (.71)</td><td>3.63 (1.51)</td><td>.391</td><td>.391</td><td></td></tr><tr><td>Mutual comprehensibility of learner-IPA utterances</td><td>3.00 (.76)</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>GA can understand my English.. I can understand the English of GA.</td><td>3.88 (.35)</td><td>3.23 (.73) 4.08 (.49)</td><td>3.63 (.74) 4.75 (.46)</td><td>1.476 8.491</td><td>.247 .001*</td><td>HI &gt;I,</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td>HI&gt;L</td></tr><tr><td>Do you think the pronunciation of GA is natural?</td><td>4.00 (.76)</td><td>4.77 (.44)</td><td>4.50 (.76)</td><td>3.700</td><td>.039*</td><td>HI &gt;L,1</td></tr><tr><td>Overall experience</td><td></td><td></td><td></td><td></td><td></td><td>&gt;L</td></tr><tr><td>Overall, I like the feeling of using GA during the hands-on</td><td>4.00 (1.07)</td><td>4.23 (.93)</td><td>3.88 (1.36)</td><td>.919</td><td>.411</td><td></td></tr><tr><td>session.</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Overall, I find it interesting to interact with GA.</td><td>4.25 (1.16)</td><td>4.08 (.95)</td><td>3.50 (1.31)</td><td>.440</td><td>.649</td><td></td></tr></table></body></html>

$^ { \ast } p < . 0 5$

Nevertheless, for the aspect of mutual comprehensibility of learner-IPA utterances, significant differences were found for two out of the three items, namely “I can understand the English of GA.” and “Do you think the pronunciation of $G A$ is natural?” Post hoc analyses on the two items revealed the following between-group differences. First, while the three groups all reported themselves to have no difficulty understanding GA, the HI group was particularly confident in their ability to understand GA’s utterances $( M = 4 . 7 5 / 5$ , $\mathsf { S D } = . 4 6 )$ as compared to the other two groups (I: $M =$ $4 . 0 8 / 5 ,$ $\mathsf { S D } = . 4 9$ ; L: $M = 3 . 8 8 / 5$ , $\mathsf { S D } = . 3 5$ . As for the perceived naturalness of GA’s pronunciation, both the HI group’s score $( M = 4 . 5 0 / 5$ , $\mathsf { S D } = . 7 6 )$ ) and the I group’s $( M = 4 . 7 7 / 5$ , ${ \mathsf { S D } } = . 4 4$ ) were significantly higher than the L group’s $( M = 4 . 0 0 / 5$ , $\mathsf { S D } = . 7 6 )$ ; there was, however, no significant difference between the HI group and the I group for this item. Thus, to both higher level groups, GA’s pronunciation sounded statistically more natural as compared to the low level group.

The participants’ responses to the two open-ended questions approximately echoed with those to the survey, which showed that $G A$ would be especially useful to enhance their listening ability (n $= 1 3 , 4 4 . 8 3 \% )$ , pronunciation $( n = 1 1 , 3 7 . 9 3 \% )$ , speaking skills $( n = 9 , 3 1 . 0 3 \% )$ , and vocabulary knowledge $( n = 6 , 2 0 . 7 0 \% )$ . The participants felt more motivated to speak with $G A$ $( n = 6 , 2 0 . 7 0 \% )$ . This kind of English learning was fun and easy $[ n = 7 ]$ , $2 4 . 1 4 \%$ ) and would motivate them to learn English $( n = 6 ,$ $2 0 . 7 0 \%$ ).

As for the interview, analyses of the participants’ responses to the perceived strengths of $G A$ for English learning show that some participants in the I group and the HI group considered $G A$ to be a convenient language learning tool. A few of the participants in the L group and the HI group commented that $G A$ could offer more chances to practice English speaking. In addition, some participants in the I group further reported that, during the interaction with $G A _ { i }$ , they were more aware of their own errors/mistakes in pronunciation and had more exposures to authentic English.

While the perceived strengths of GA sometimes differed among the groups, there was a clear consensus on the weaknesses. For example, the three groups all responded that GA often gave mechanical responses and thus could not replace human-human interactions. Furthermore, all of the three groups complained that GA was very sensitive to pronunciation errors/mistakes that this sometimes hindered their interactions. In addition, the two higher level groups complained that lacking in explicit/corrective feedback on problematic sounds/words/sentences was a bit confusing. They did not know which part(s) of their utterances caused GA difficulty in comprehending their English and thus had no idea how to correct the errors/mistakes. Lastly, both the L group and the I group suggested that more visual aids (e.g. subtitles and pictures) could be offered by $G A$ , and the I group further proposed the inclusion of learning applications/materials for various English proficiency tests. Table 5 summarizes the participants’ responses to the interview questions.

# GA’s understanding of learners’ utterances

As shown in previous sections, the participants reported that they could easily understand GA’s English, whereas they considered that their English were less understood by GA.

To better understand the participants’ difficulties interacting with GA, we further examined the types of CB occurring during learner-IPA interactions. Video recordings of three participants (2 females and 1males) in each group were randomly selected and carefully analyzed by one of the researchers. As shown in Table 6, most of the CBs were caused by the participants’ mispronunciations (194 times), and only few resulted from stammering (8 times). This suggests that GA was sensitive to the participants’ pronunciations and that any mistake or ambiguity of a word’s sound might hinder GA’s understanding of the participants’ utterances.

While mispronunciation was identified as the major cause of CBs, its occurrences in the three learner groups were rather different. Both the L group and the I group committed more than 70 times of pronunciation errors in their utterances, whereas the HI group only made 44 times. In addition, stammering as a cause of CB was observed in both the L group and the I group, while this was not an issue to the HI group. In sum, both the L group and the I group encountered obviously more CBs than the HI group, and incorrect pronunciations were the major contributing factor. These findings could explain why the HI group’s score on “GA can understand my English” was the highest among the three. Because these high level learners produced few mispronunciations in their interactions with GA, they thus considered themselves better understood by GA as compared to the other two groups.

Summary of L, I, and HI groups’ responses to the interview questions.   

<html><body><table><tr><td>Category</td><td>L n (%)</td><td>n (%)</td><td>HI n (%)</td></tr><tr><td colspan="4">Strength</td></tr><tr><td> More chances to practice English speaking</td><td>2 (25%)</td><td></td><td>1 (12.5%)</td></tr><tr><td>Helpful to notice pronunciation errors/mistakes</td><td></td><td>3 (23.08%)</td><td></td></tr><tr><td>More convenient to learn English</td><td></td><td>3 (23.08%)</td><td>1 (12.5%)</td></tr><tr><td>More exposures to authentic English</td><td></td><td>1 (7.70%)</td><td></td></tr><tr><td colspan="4">Weakness</td></tr><tr><td>Lacking in some characteristics of human-human interactions</td><td>2 (25%)</td><td>4 (30.77%)</td><td>5 (62.5%)</td></tr><tr><td>Too sensitive to pronunciation errors/mistakes</td><td>3 (37.5%)</td><td>5 (38.46%)</td><td>2 (25%)</td></tr><tr><td>No provision with explicit (corrective) feedback on problematic pronunciation/sentence</td><td></td><td>4 (30.77%)</td><td>2 (25%)</td></tr><tr><td colspan="4">structure Suggestion</td></tr><tr><td>More provisions of visual aids</td><td>3 (37.5%)</td><td>1 (7.70%)</td><td></td></tr><tr><td>Inclusion of learning applications/materials for English proficiency tests</td><td></td><td>2 (15.38%)</td><td></td></tr></table></body></html>

Types of CB observed in learner-IPA interactions.   

<html><body><table><tr><td></td><td></td><td colspan="3">Occurrences (%)</td></tr><tr><td>Type of CB</td><td>Examples</td><td>L</td><td></td><td>HI</td></tr><tr><td> Pronunciation errors</td><td>start [sta:rt] into [sta:t]; lesson [lesen] into [lisen]</td><td>74 (98.7)</td><td>76 (91.6)</td><td>44 (100)</td></tr><tr><td>Hesitations</td><td>I am going to have ... (pause)</td><td>1 (1.3)</td><td>7 (8.4)</td><td>0()</td></tr></table></body></html>

# Learners’ strategies in dealing with communication breakdowns

The last research question focused on the strategies that the participants employed to repair the CBs. The researchers identified three types of strategy, namely repeat (i.e. say the same word/phrase/sentence again), pronounce differently (i.e. alter some of the vowels/consonants of a problematic word), or rephrase (i.e. change into another synonymous word or paraphrase the whole sentence). Table 7 presents the occurrences of these strategy types among the three groups respectively. When CBs occurred, the HI group tended to rephrase the problematic words/sentences rather than to repeatedly produce the same utterances; the other two groups, however, were more likely to repeat the same utterances to repair the CBs. These discrepancies indicated that the HI group was more capable of modifying their own utterances to keep the interaction going, while the L group and the I group would keep producing the same utterances several times before trying other strategies.

# Discussion

In the current study, the participants generally had a positive perception toward the use of IPAs, and many of their positive opinions corroborated with findings of previous research. For example, participants in our study and in Moussalli and Cardoso (2016) both felt comfortable speaking with IPAs and considered IPAs a helpful tool to improve their pronunciation and vocabulary. In addition to the two types of language knowledge, our participants also believed that GA could improve their reading, listening, and speaking skills, partially echoing with Dizon’s (2020) and Sing et al.’s (2019) empirical findings that IPAs could benefit L2 learners’ speaking proficiency and reading comprehension. To our participants, interacting with IPAs was an interesting and enjoyable experience, which is consistent with Dizon and Tang’s (2019), Moussalli & Cardoso’s, Pyae and Scifleet’s (2019), and Underwood’s (2017) findings. Results obtained in the current study and previous ones thus demonstrate that IPAs might serve as useful tools for L2 learners to improve their language abilities/knowledge (especially pronunciation, speaking, and vocabulary), and that these devices could create a comfortable and pleasant language learning environment.

Regarding the mutual comprehensibility of learners and GA, most of our participants considered GA’s English and pronunciation to be natural and easy to understand. Similar findings were also yielded in Moussalli and Cardoso (2016, 2019), which showed that L2 learners could understand

Types of strategy to repair CBs in learner-IPA interactions.   

<html><body><table><tr><td></td><td colspan="3">Occurrences (%)</td></tr><tr><td>Type of Strategy</td><td>L</td><td></td><td>HI</td></tr><tr><td>Repeat</td><td>43 (61.4)</td><td>45 (60.8)</td><td>9 (20.9)</td></tr><tr><td>Pronounce differently</td><td>6 (8.6)</td><td>5 (6.76)</td><td>1 (2.3)</td></tr><tr><td>Rephrase (word/sentence)</td><td>21 (30)</td><td>24 (32.43)</td><td>33 (76.8)</td></tr></table></body></html>

Alexa easily. This thus indicates that understanding the English of IPAs causes little problems to L2 learners. There are, however, inconsistent results of IPAs’ ability to comprehend L2 learners’ utterances in our study and others. Our participants perceived that GA sometimes could not fully understand their English, which is in agreement with Dizon’s (2017) finding that Alexa could understand only about $5 0 \%$ of his participant’s commands. Results yielded here and in Dizon’s are different from Moussalli and Cardoso’s (2019), whose L2 learners considered themselves to be easily understood by Amazon’s Alexa.

A plausible explanation for the seemingly contradictory findings yielded in our study and in Moussalli and Cardoso’s (2019) might lie in the proficiency levels of participants. In this study, we recruited EFL learners with low, intermediate, and high-intermediate proficiency, whose perceptions toward GA’s understanding of their utterances were $M = 3 . 0 0$ , $M = 3 . 2 3$ , and $M = 3 . 6 3$ respectively. The high-intermediate level learners’ mean score approximates to the ESL learners’ $( M = 3 . 5 5 / 5 ,$ , $\mathsf { S D } = 0 . 9 3 )$ ) in Mousalli and Cardoso, whose language proficiency is described from low-intermediate to advanced. This approximation might thus suggest that learners with higher language proficiency (e.g. the high-intermediate EFL learners in ours and the ESL learners in theirs) are more likely to consider themselves better understood by IPAs, whereas lower level learners (e.g. the low and intermediate EFL learners in our study) tend to perceive themselves misunderstood by IPAs more often.

Less proficient EFL learners’ difficulties in being understood by IPAs might have resulted from their high occurrence of pronunciation errors. In our study, the participants reported that $G A$ was too sensitive to their pronunciation errors, and this claim was further substantiated by the analysis of their video recordings, which shows mispronunciations as the main cause of CBs. Pronunciation errors as the major cause were also reported by Moussalli and Cardoso (2019), who discovered that pronunciation issues accounted for $5 3 . 1 1 \%$ of their participants’ CBs. In Pyae and Scifleet (2019), the NNSs’ also specified their difficulties in correctly pronouncing words for $G A$ to recognize. Findings of our study thus echo with previous research that IPAs like Alexa and $G A$ still have some difficulties understanding learners’ utterances (Dizon, 2017; Moussalli $\&$ Cardoso, 2016; Pyae & Scifleet, 2019), due largely to mispronunciations. In addition, the two lower-level learners in our study committed almost two times more pronunciation errors than the high-intermediate learners, further explaining why they encountered more CBs and hence perceived themselves to being less understood by $G A$ . Based on findings of our study and previous research, we proposed that the prerequisite for IPAs to adapt well to L2 learners’ utterances is that L2 learners might have to reach a higher level of proficiency and pronunciation accuracy. It should be noted that most current IPAs’ ASR engines are not built for NNSs (Levis, 2007) and therefore sensitive to learners’ deviant speech, as depicted by Van Compernolle (2001):

Much of the progress in the last 15 years in acoustic modeling [for ASR] is based on more detailed modeling, creating sharper and sharper distributions for narrower and narrower classes. This is diametrically opposite of the tolerance and robustness required for non-natives. (p. 76)

If the ASR engines in IPAs have difficulties understanding NNSs’ speech as described above, then this could somewhat negatively influence L2 learners’ perception toward the use of IPAs for language learning, as revealed in the findings of the current study and in Pyae and Scifleet (2019).

In addition to frequencies of pronunciation errors, EFL learners at different proficiency levels were found to favor different strategies to repair CBs. More than $6 0 \%$ of the time, the two lower level learners just repeated the same utterance(s) when a CB appeared, and rephrasing only accounted for $30 \%$ of the employed strategies. The high level learners, on the other hand, oftentimes (i.e. more than $7 5 \%$ ) rephrased a problematic word/sentence, rather than repeated it (i.e. around $2 1 \%$ ), to resolve a CB. The different strategy patterns among the three proficiency groups might be explained by the findings of past L2 acquisition research. Studies have revealed that more proficient L2 learners are more likely to employ linguistic-based, intralingual strategies to repair CBs while less proficient learners tend to use interlingual strategies or repetitions (Chen, 1990; Derwing & Rossiter, 2002; Hua et al., 2012; Metcalfe & Noom-Ura, 2013). While our high level learners had greater linguistic competence to either lexically or syntactically self-repair their utterances to fix CBs, our less proficient learners’ lack of adequate linguistic competence caused them to self-repeat their problematic utterances more often.

Comparing our results to those of Moussalli and Cardoso (2019), the strategy patterns exhibiting in their ESL learners (Repetition: $4 5 . 3 0 \%$ , Rephrased: $3 1 . 7 6 \%$ , Abandoned: $2 2 . 9 4 \%$ ) are more similar to those in our two lower-level groups. A possible explanation for this might be the task differences in our study and theirs, which could potentially elicit different types of communication strategies (Kaivanpanah et al., 2012). In Mousalli and Cardoso, their learners’ interaction with Alexa was mainly asking a pre-established set of questions to the IPA, whereas our learners were assigned with six different tasks that required them not only to ask questions or give commands but also to interact with other third-party applications accessible by Google Home Hub. Our learners might be more likely to produce more spontaneous speeches as compared to those in Mousalli and Cardoso and thus had more chances to rephrase their utterances.

# Concluding remarks and suggestions for future research

This study sets out to investigate EFL learners’ perceptions toward the use of IPAs for language learning and to examine whether language proficiency affects how they perceive and being understood by IPAs. Results reveal that learners at different proficiency levels considered the IPA an easy tool to develop many language skills/knowledge. To these learners, especially high-intermediate ones, understanding the IPA’s English was not a problem. The learners’ positive perceptions toward the use of IPAs hence indicate these tools’ potentials in language learning. However, the learners complained about the IPA’s deficiency in fully comprehending their English, which led to many CBs in the learner-IPA interactions. This issue, mostly caused by mispronunciations, occurred more often in low and intermediate learners’ interactions with the IPA, and these less proficient learners oftentimes employed repetition to repair a CB, which contrasted with higher-level learners’ frequent use of rephrasing.

Our findings highlight that, at the current stage, IPAs still have difficulties in completely understanding L2 learners’ utterances, particularly utterances produced by lower level learners. For the better use of IPA-assisted language learning, we offer some suggestions to language teachers, CALL researchers, and IPA developers respectively. First, language teachers are suggested to explain to less proficient students about the demanding/sensitive ASR engines in IPAs. If learners can understand the sensitivity of ASR engines beforehand, they might feel less frustrated/confused by the occurrences of CBs, and they might be more willing to modify their problematic L2 output during their interactions with IPAs.

The second suggestion is given to CALL researchers who are interested in developing their own applications. While existing IPAs can provide many useful and authentic input to L2 learners, they are less capable of pushing learners to produce more complex output than simple comments (e.g. “Hey Google, play BBC news”). If more applications with two-way activities are developed, these applications can push learners to produce more complex target languages. To our knowledge, there are some researchers developing their own applications via Actions on Google and Alexa Skills, such as My Cool English Coach (https://assistant.google.com/services/a/uid/00000047e31c13a4?hl= en-GB). We thus encourage CALL researchers to build applications that require more meaningful and complex output from learners, so as to enhance the interactivity and the pedagogical usefulness of IPAs for language learning.

As for IPA developers, we suggest that attempts to use both native and non-native speakers’ speeches as models for training ASR engines could be made. As highlighted by Levis (2007), accommodating non-native speech is challenging for current IPAs due to the fact that their speech recognition is based on native speech models (cf. Coniam, 1999; Daniels & Iwago, 2017; Derwing et al., 2000; Ehsani & Knodt, 1998). Inclusion of non-native speech for ASR training, therefore, might enhance IPAs’ adaptability to both native and non-native speeches and hence improve L2 learners’ interaction with IPAs.

Findings of our study indicate that language proficiency could affect how L2 learners perceive the potential of IPAs for L2 learning and how their utterances are comprehended by IPAs. The effects of language proficiency on learners’ language gains via the use of IPAs, however, could not be clearly revealed in perception-based studies. To further understand the impact of IPAs on L2 learners at different proficiency levels, undertaking of experimental studies is suggested to measure real language gains of L2 learners.

# Notes on contributors

Howard Hao-Jan Chen (Ph. D, University of Pennsylvania) is Professor of English Department at National Taiwan Normal University, Taipei, Taiwan. Professor Chen has extensive experiences developing various CALL websites and he also published several papers in CALL Journal, ReCALL Journal and several related language learning journals. His research interests include computer-assisted language learning, corpus research, and second language acquisition. He is now developing and maintaining a large English Learning website, Cool English, serving 260,000 elementary and secondary school students in Taiwan.

Christine Ting-Yu Yang is currently a research assistant in the English Department at National Taiwan Normal University, Taipei, Taiwan. Her research interests include computer-assisted language learning and corpus linguistics.

Kyle Kuo-Wei Lai is a doctoral student at National Taiwan Normal University, Taipei, Taiwan, Republic of China. His research interests include computer-assisted language learning and digital game-based language learning.

# Disclosure statement

No potential conflict of interest was reported by the author(s).

# Funding

This work was financially supported by the “Chinese Language and Technology Center” of National Taiwan Normal University (NTNU) from The Featured Areas Research Center Program within the framework of the Higher Education Sprout Project by the Ministry of Education (MOE) in Taiwan.

# ORCID

Howard Hao-Jan Chen $\textcircled { 1 0 }$ http://orcid.org/0000-0002-8943-5689

# References

Ali, M., & Hassan, A. M. (2018). Developing applications for voice enabled IoT devices to improve classroom activities. The 21st International Conference of Computer and Information Technology (ICCIT), 1–4. https://doi.org/10.1109/ ICCITECHN.2018.8631906   
Barcomb, M., Grimshaw, J., & Cardoso, W. (2017). I can’t program! Customizable mobile language-learning resources for researchers and practitioners. Languages, 2(3), 8–15. https://doi.org/10.3390/languages2030008   
Brown, S. A., Fuller, R. M., & Vician, C. (2004). Who’s afraid of the virtual world? Anxiety and computer-mediated communication. Journal of the Association for Information Systems, 5(2), 79–107. https://doi.org/10.17705/1jais.00046   
Canbek, N. G., & Mutlu, M. E. (2016). On the track of artificial intelligence: Learning with intelligent personal assistants. International Journal of Human Sciences, 13(1), 592–601. https://doi.org/10.14687/ijhs.v13i1.3549   
Chen, S. Q. (1990). A study of communication strategies in interlanguage production by Chinese EFL learners. Language Learning, 40(2), 155–187. https://doi.org/10.1111/j.1467-1770.1990.tb01332.x   
Cheng, C. H., & Chen, C. H. (2019). Investigating the impacts of using a mobile interactive English learning system on the learning achievements and learning perceptions of student with different backgrounds. Computer Assisted Language Learning, 1–26. https://doi.org/10.1080/09588221.2019.1671460   
Coniam, D. (1999). Voice recognition software accuracy with second language speakers of English. System, 27(1), 49–64. https://doi.org/10.1016/S0346-251X(98)00049-9

Daniels, P., & Iwago, K. (2017). The suitability of cloud-based speech recognition engines for language learning. JALT CALL Journal, 13(3), 211–221. https://doi.org/10.29140/jaltcall.v13n3.220

Derwing, T., Munro, M., & Carbonaro, M. (2000). Does popular speech recognition software work with ESL speech? TESOL Quarterly, 34(3), 592–603. https://doi.org/10.2307/3587748   
Derwing, T. M., & Rossiter, M. J. (2002). ESL learners’ perceptions of their pronunciation needs and strategies. System, 30 (2), 155–166. https://doi.org/10.1016/S0346-251X(02)00012-X   
Dizon, G. (2017). Using intelligent personal assistants for second language learning: A case study of Alexa. TESOL Journal, 8(4), 811–830. https://doi.org/10.1002/tesj.353   
Dizon, G. (2020). Evaluating intelligent personal assistants for L2 listening and speaking development. Language Learning & Technology, 24(1), 16–26. https://doi.org/10125/44705   
Dizon, G., & Tang, D. (2019). A pilot study of Alexa for autonomous second language learning. In F. Meunier, J. Van de Vyver, L. Bradley, & S. Thouësny (Eds.), CALL and complexity–short papers from EUROCALL 2019 (pp. 107–112). Research-publishing.net.   
Ehsani, F., & Knodt, E. (1998). Speech technology in computer-aided language learning: Strengths and limitations of a new CALL paradigm. Language Learning & Technology, 2(1), 45–60. http://llt.msu.edu/vol2num1/article3/   
Godwin-Jones, R. (2019). Riding the digital wilds: Learner autonomy and informal language learning. Language Learning & Technology, 23(1), 8–25. https://doi.org/10125/44667   
Hauswald, J., Laurenzano, M. A., Zhang, Y., Li, C., Rovinski, A., Khurana, A., Dreslinski, R. G., Mudge, R., Petrucci, V., Tang, L., & Mars, J. (2015). Sirius: An open end-to-end voice and vision personal assistant and its implications for future warehouse scale computers. Proceedings of the Twentieth International Conference on Architectural Support for Programming Languages and Operating Systems, 223–238. https://doi.org/10.1145/2694344.2694347   
Hua, T. K., Nor, N. F. M., & Jaradat, M. N. (2012). Communication strategies among EFL students-An examination of frequency of use and types of strategies used. GEMA Online® Journal of Language Studies, 12(3), 831–848.   
Istrate, A. M. (2019). The impact of the virtual assistant (VA) on language classes. In Proceedings of the 15th International Scientific Conference eLearning and Software for Education (pp. 296–301). Bucharest, Romania: Carol I National Defence University.   
Joo, Y. J., Lim, K. Y., & Kim, S. M. (2012). A model for predicting learning flow and achievement in corporate e-learning. Educational Technology & Society, 15(1), 313–325.   
Kaivanpanah, S., Yamouty, P., & Karami, H. (2012). Examining the effects of proficiency, gender, and task type on the use of communication strategies. Porta Linguarum: Revista Internacional de Didáctica de las Lenguas Extranjeras, 17, 79–94.   
Kessler, G. (2018). Technology and the future of language teaching. Foreign Language Annals, 51(1), 205–218. https://doi. org/10.1111/flan.12318   
Levis, J. (2007). Computer technology in teaching and researching pronunciation. Annual Review of Applied Linguistics, 27, 184–202. https://doi.org/10.1017/S0267190508070098   
McCrocklin, S., Humaidan, A., & Edalatishams, E. (2019). ASR dictation program accuracy: Have current programs improved? In J. Levis, C. Nagle, & E. Todey (Eds.), Proceedings of the 10th Pronunciation in Second Language Learning and Teaching Conference, ISSN 2380-9566, Ames, IA, September 2018 (pp. 191-200). Ames, IA: Iowa State University.   
Metcalfe, J., & Noom-Ura, S. (2013). Communication strategy use of high and low proficiency learners of English at a Thai university. Learn Journal: Language Education and Acquisition Research Network, 6(1), 68–89.   
Moussalli, S., & Cardoso, W. (2016). Are commercial ‘personal robots’ ready for language learning? Focus on second language speech. In S. Papadima-Sophocleous, L. Bradley & S. Thouësny (Eds.), CALL communities and culture– short papers from EUROCALL (pp. 325–329). Research-pusliching.net. https://doi.org/10.14705/rpnet.2016. eurocall2016.583   
Moussalli, S., & Cardoso, W. (2019). Intelligent personal assistants: Can they understand and be understood by accented L2 learners? Computer Assisted Language Learning, 1–26. https://doi.org/10.1080/09588221.2019.1595664   
Pyae, A., & Scifleet, P. (2018). Investigating differences between native English and non-native English speakers in interacting with a voice user interface: A case of Google Home. Proceedings of the 30th Australian Conference on ComputerHuman Interaction, 548–553. https://doi.org/10.1145/3292147.3292236   
Pyae, A., & Scifleet, P. (2019). Investigating the role of user’s English language proficiency in using a voice user interface: A case of Google Home smart speaker. Proceedings of Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems, 1–6. https://doi.org/10.1145/3290607.3313038   
Rahimi, M., & Yadollahi, S. (2011). Foreign language learning attitude as a predictor of attitudes towards computerassisted language learning. Procedia Computer Science, 3, 167–174. https://doi.org/10.1016/j.procs.2010.12.029   
Sing, P. B., Embi, M. A., & Hashim, H. (2019). Ask the Assistant: Using Google Assistant in classroom reading comprehension activities. International Journal of New Technology and Research (IJNTR), 5(7), 39–43. https://doi.org/10.31871/ IJNTR.5.7.6   
Sung, H. Y., Hwang, G. J., Lin, C. J., & Hong, T. W. (2017). Experiencing The Analects of Confucius: An experiential gamebased learning approach to promoting students’ motivation and conception of learning. Computers & Education, 110, 143–153. https://doi.org/10.1016/j.compedu.2017.03.014   
Tagawa, T., Jin, M., & Inoue, H. (2019). A smart speaker application to assist Japanese onomatopoeia learning: A prototype. In K. Graziano (Ed.), Proceedings of society for information technology & teacher education international conference (pp. 1124–1127). Association for the Advancement of Computing in Education (AACE). https://www. learntechlib.org/primary/p/207785/   
Underwood, J. (2017). Exploring AI language assistants with primary EFL students. In K. Borthwick, L. Bradley & S. Thouësny (Eds.), CALL in a climate of change: Adapting to turbulent global conditions–short papers from EUROCALL (pp. 317–321). Research-publishing.net. https://doi.org/10.14705/rpnet.2017.eurocall2017.733   
Van Compernolle, D. (2001). Recognizing speech of goats, wolves, sheep and … non-natives. Speech Communication, 35 (1-2), 71–79. https://doi.org/10.1016/S0167-6393(00)00096-0   
Wu, Y., Edwards, J., Cooney, O., Bleakley, A., Doyle, P., Clark, L., Rough, D., Cowan, & Cowan, L. (2020a). Mental Workload and Language Production in Non-Native Speaker IPA Interaction. In 2nd Conference on Conversational User Interfaces (CUI ‘20), Bilbao, Spain, July 22-24, 2020. New York, USA: ACM. https://doi.org/10.1145/3405755.3406118   
Wu, Y., Rough, D., Bleakley, A., Edwards, J., Cooney, O., Doyle, P., Clark, L., Cowan, & Cowan, L. (2020b). See what I’m saying? Comparing Intelligent Personal Assistant use for Native and Non-Native Language Speakers. Accepted to Mobile HCI 2020. https://doi.org/10.1145/3379503.3403563