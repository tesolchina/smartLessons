# We agree completely with the reviewer, but . ”: Stance in author rebuttal letters for journal manuscript reviews

Yuting Lin

Department of English, Shenzhen University, Shenzhen, China

# a r t i c l e i n f o

# a b s t r a c t

Article history: Available online 16 November 2023

Keywords:   
Stance   
Author rebuttal letter   
Peer review   
Research article   
Metadiscourse

Authors’ rebuttal letters (ARLs) in response to journal reviewers critically affect whether a paper is accepted or rejected. However, the genre is traditionally “occluded” from the public view, and its linguistic or rhetorical features are seldom examined in the literature. Using Hyland’s (2005) model, this study analyzes stance markers, i.e., expressions of the speaker’s attitudes towards or commitment concerning a proposition, in 50 ARLs from five high-impact Nature Portfolio journals, which started publishing ARLs as supplements to manuscripts in 2020. The analysis shows that authors’ stance deployment differs markedly between different sections of the ARL, i.e., Opening Statement, Point-by-Point Response, Additional Changes, and Closing Remarks. Attitude markers, boosters, and self-mentions are more frequent in ARLs than in research articles, serving to advocate the paper, highlight improvements, and show gratitude towards reviewers. Only $6 \%$ ARLs fully accommodate all reviewer suggestions. When rejecting a criticism, authors rarely express total disagreement with reviewers, choosing instead to hedge the No Revision claims, use expressions of agreement and gratitude as buffers, and boost positive aspects of the paper. Findings of this study may be of interest to those who seek a better understanding of the language of ARLs, including ESP teachers and novice researchers.

$\circledcirc$ 2023 Elsevier Ltd. All rights reserved.

# 1. Introduction

In a time when researchers around the world face pressure to publish in high-impact English-speaking journals, manuscript peer review has received increasing attention from English for Specific Purposes researchers and practitioners (Coxhead et al., 2023; Hyland and Jiang, 2020; Hynninen, 2022; Paltridge, 2017; Samraj, 2021). Effective revision of a manuscript in response to referee critiques is key to successful academic publishing. When submitting a revised manuscript, authors are typically requested to upload an “author rebuttal letter” (ARL), a document that explains how the reviewer comments have been addressed. A compelling ARL helps clarify the revisions made, persuade the reviewer/editor of the merit of the paper, and increase the efficiency and speed of peer-review. However, replying to reviewer comments is often challenging for novice researchers, especially when they receive harsh criticisms (Geng and Yu, 2022; Hyland and Jiang, 2020; Kwan, 2013). Research writing manuals offer general guidance on how to write ARLs, such as responding politely, objectively, and point-by-point to each reviewer comment (e.g., Cargill & O’Connor, 2011; Peat et al., 2013). Yet detailed linguistic analysis of actual samples of ARLs has been limited, likely because the genre is traditionally “occluded” from the public view (Swales, 1996).

The recent Open Peer Review (OPR) movement in high-impact science journals offers an opportunity to explore the language of ARLs. Aimed to increase transparency in academic publishing, OPR schemes allow authors to publish alongside their manuscript the full peer review records, including editorial decision letters, reviewer reports, and their own responses. Open peer review practices have grown steadily since 2001, when 36 of the 37 initial adopters are journals produced by BioMed Central, an Open Access publisher. As of 2019, the policy was adopted in 536 journals, of which $1 3 . 2 \%$ are ranked as the top $2 5 \ \%$ (i.e., Q1) in their fields, and $91 \%$ are in the STEM disciplines (Wolfram et al., 2020). In 2020, Nature began to implement transparent peer review, with $4 6 \%$ Nature articles in 2021 being published with reviewer comments and author replies. The growth of OPR adoption has prompted extensive research to understand its acceptance by researchers (RossHellauer et al., 2017), influence on review quality (Bravo et al., 2019; van Rooyen et al., 2010), and policies across journals/ disciplines (Wolfram et al., 2020). Studies of the linguistic or rhetorical features of OPR ARLs, however, have remained limited, except for Hynninen’s (2022) recent analysis of the peer review exchanges for three research articles published in an Open Access journal in geosciences.

Knowledge of the linguistic features of ARLs is important for researchers to communicate effectively with reviewers. Additionally, discourse studies of ARLs may provide insights for instructors who teach English for Research Publication Purposes courses to develop materials and design exercises (Li and Flowerdew, 2020). This paper thus analyzes the use of stance markers, which are expressions of the author’s attitudes or epistemic certainty in relation to a proposition, in 50 ARLs collected from five high-impact Nature Portfolio journals. Drawing on Hyland’s (2005) model of stance markers in academic writing, this study answers the following questions:

1) What kinds of stance markers can be found in ARLs, and how frequently are they used?   
2) How do authors’ stance choices differ between different sections of the ARL, and why?

It is hoped that this study also contributes to the existing literature on stance in academic writing, as scholarly attention in this field has been paid mainly to the more readily available genres, such as research articles.

# 2. Literature review

This section considers previous studies about the author rebuttal letter genre and stance in written academic discourse. It shows that novice writers can find it challenging to write an ARL, and that an explicit knowledge of stance features of the genre may help authors communicate more effectively with reviewers.

# 2.1. The author rebuttal letter genre

The author rebuttal letter genre belongs to the range of text genres produced during journal peer review, which have generated much scholarly attention over the last two decades (Belcher, 2007; Coniam, 2011; Coxhead et al., 2023; Flowerdew and Dudley-Evans, 2002; Hewings, 2004). Studies that analyzed ARLs typically dealt with texts collected from a single journal, and they focused mainly on the structural organization of the genre. Gosden (2001), based on 40 ARLs from a journal in chemical physics, noted that the letter contains opening remarks, point-by-point replies, and closing remarks. Changes made by authors can be categorized into correction, addition, clarification, downgrading, and English language editing (ibid.). Similarly, Feak’s (2009) study of 16 ARLs from a medical journal shows that the genre consists of greeting, opening, response, and closing. Feak (2009) also examined several lexico-grammatical features of the 16 letters, including active/passive voice, tense, and verbs describing the revision activity. Others have analyzed editorial decision letters and reviewer reports with a view to helping novice scholars write effective responses (Flowerdew and Dudley-Evans, 2002; Fortanet, 2008; Gosden, 2003; Hyland, 2016; Larina and Ponton, 2020; Paltridge, 2015, 2017). This body of research highlights the need to fulfil the indirect request made by reviewers, for example, a revision request framed as a question or a statement (e.g., Paltridge, 2015). General guidance on how to prepare ARLs can be found in academic writing manuals. A search on Google Books, using the keywords “peer review”, “reviewer’s comment”, “author”, and “respond”, shows that over 10 academic writing manuals have been published in the last five years (2018–2022) that offer some advice on the structure or content of ARLs. The recommendations typically include pasting all reviewer remarks into the letter, responding to each comment point-by-point, providing an argument when disagreeing with a comment, and be respectful, confident and clear (e.g., Boyle and Ramsay, 2019; Oermann and Hays, 2018). Additionally, one manual suggests beginning the ARL with an expression of thanks (Douglas and Grant, 2018), and one recommends using the present or past perfect tense when stating changes (Kotz and Cals, 2021). Even with the help with the academic writing manuals, novice writers may still be unclear as to how certain recommendations can be implemented at a discursive or linguistic level. For example, when developing an argument for not taking a reviewer suggestion, they may contest bluntly with the referee (e.g., “I disagree”, “your comment is wrong”), resulting in the rejection of their paper (Lei and Hu, 2019). Alternatively, they may accept whatever the reviewer requests for, even when finding the suggested change unnecessary or distracting (Liu, 2014). Another issue is that some novice scholars overemphasize in the letter to editors their academic achievements, hope for success, and hope for a prompt reply, while experienced writers tend to exclude these elements (Shaw and Okamura, 1998; Swales, 1996). These issues have been attributed to early career researchers’ lack of knowledge of the norms and conventions governing author-reviewer communication, which “are often tacit and thus escape easy identification and mastery” (Lei and Hu, 2019, p.68).

It should be noted that authors and reviewers may adjust their language use during OPR, knowing that their exchanges are to be published. OPR does not change the reviewer’s recommendation regarding the acceptance or rejection of a paper (van Rooyen et al., 2010), time spent on review (Bravo et al., 2019), or use of hedging devices (Wolfram et al., 2021). However, reviewer comments for OPR journals are typically longer and contain slightly more “research terms” (e.g., experiment, hypothesis, statistics) than those for closed review journals (Bornmann et al., 2011; Wolfram et al., 2021). While few studies have compared the language of OPR and traditional ARLs, the possible influence of open peer review on authors’ rhetorical style should be considered when interpreting the results of this study.

# 2.2. Stance in academic writing

The term stance refers to the expression of the speaker’s attitudes towards or commitment concerning a proposition (Lyons, 1977). Stance has been studied from different perspectives, including Metadiscourse (Hyland, 2005), Appraisal (Martin and White, 2005), Evaluation (Hunston and Thompson, 2000), and Grammatical/Lexical Stance (Biber and Finegan, 1989). Stance devices contribute to enhancing the persuasiveness of a text, building a suitable relationship with readers, and construing a socially acceptable writer persona (Hyland, 2005). It is thus a key aspect of one’s academic literacy to be able to use stance resources appropriately, following conventions adopted in their communities.

Previous studies have shown that authors’ stance deployment in academic writing varies by genre, by discipline, by time, and by culture. For example, hedging constitutes more than half of the stance choices in research papers, as a strategy to present scientific findings with precision and prudence (Hyland, 2005). In research article abstracts, which serve to attract readers to the full manuscript, the certainty of propositions are more often amplified than toned down (Gillaerts and Van de Velde, 2010). Attitudinal expressions are the most prominent stance feature in academic book reviews, an evaluative genre (Zou and Hyland, 2022). In oral research presentations, which involves face-to-face interaction, self-mentioning items such as “we” and “I” outnumber other stance markers (Hyland and Zou, 2021). Disciplinary norms also influence authors’ stance preference, as research articles in the social sciences and humanities contain $7 5 \%$ more stance items than papers in the hard sciences (Hyland, 2005). The disciplinary difference is diminishing over time, with an increase of stance markers in research articles in the hard sciences in the last fifty years, (Hyland and Jiang, 2018). Further, some stance strategies are culture specific. For instance, English-medium research papers feature more hedges than Chinese-medium ones (Hu and Cao, 2011). EFL students and novice scholars express their stance differently, and oftentimes less effectively, than experienced writers (Crosthwaite et al., 2017; Hyland, 2005). For example, through a mentorship program designed to help graduate students to become reviewers, Coxhead et al. (2023) find that student reviewers hedge their criticisms too often, resulting in vagueness in their feedback.

Regarding author-reviewer communication, Paltridge’s (2017) study of 97 reviewer reports for an Applied Linguistics journal is the first to systematically analyze stance in this occluded genre. He found that hedges are notably more frequent in the “Accept” and “Minor Revisions” reviews than the “Major Revisions” or “Reject” reviews, reflecting a higher degree of directness in the latter. Samraj’s (2016, 2021) study of 94 reviewer reports from the same journal also suggests that “Minor Revisions” reviews contain a greater number of “weaker recommendations” expressions, such as may, might, would, and could. “Major Revisions” reviews, on the other hand, often contain “stronger recommendations”, in the form of need to, must, and ought to (ibid.).

In sum, the literature on stance in academic writing mostly analyzed the more readily available genres, such as research articles, theses, and book reviews. Informed by previous studies of stance in reviewer reports and research articles (e.g., Hyland and Jiang, 2018; Paltridge, 2017; Samraj, 2016, 2021), this paper sees the need to examine stance and its rhetorical role in successful examples of ARLs — those accompanying articles that are published in Nature Portfolio journals. As important differences have been identified in the stance deployment in different sections of research articles (e.g., the abstract and the body of a paper) and different types of reviewer reports (e.g., “Major Revisions” and “Minor Revisions” reviews), this study examines the variation of authors’ stance choices between different sections of ARLs, as the following section explains.

# 3. Methods

This study analyses stance markers in 50 ARLs from five high-impact Nature Portfolio journals. By 2022, fourteen Nature Portfolio journals have adopted OPR policies. The five highest-ranked journals in terms of JCR impact factors were selected, namely Nature $( N )$ , Nature Biomedical Engineering (NBE), Nature Cell Biology (NCB), Nature Immunology (NI), and Nature Microbiology (NM) (see supplementary files 1 and 2). The five journals allow authors to publish the reviewer reports and their rebuttals as supplementary files to the manuscript since February 2020. Reviewers are made aware that the peer review files may be published, and they may choose to remain anonymous or not. Editorial decision letters are not always published. In 2022, over $4 0 \%$ of the research articles in the five journals were published under OPR (see supplementary file 1). The journal Nature published a larger number of research articles (547 articles) than the other four journals (45–75 articles). A random sample of 10 ARLs (in PDF format) were collected from each of the five journals so that the sample texts are not skewed towards a particular journal. The sample ARLs are:

1) published in 2022   
2) for full-length research articles (i.e., excluding review articles, correspondences, etc.)   
3) produced in the first round of peer review

The ARLs were converted to WORD documents and imported into MAXQDA Analytics Pro 2022 (VERBI Software, 2021), which allows for lexical search, auto/manual coding of text, and word frequency analysis. Hyperlinks, email addresses, and hashtags were not included in the word count. The total corpus size is 131,355 words, and the average length of the ARLs is 2,627 words (see Table 1).

Table 1 Overview of the Sample ARLs.   

<html><body><table><tr><td>Number of ARLs</td><td>Total corpus size (words)</td><td>Mean text length (words)</td><td>Standard deviation</td></tr><tr><td> 50</td><td>131,335</td><td>2,627</td><td>1165.03</td></tr></table></body></html>

All ARLs contain the full text of the reviewer/editor comments they address, in that each referee comment is listed in turn, under which a reply to the specific comment is given. Below is an example from a sample ARL ( ${ \mathsf C } =$ Referee comments; $\boldsymbol { \mathrm { R } } =$ Author responses; $N = ,$ Journal title abbreviations; Names of authors are removed throughout this paper).

C: This first mention of [.] might prove confusing for those outside the field. R: We agree; the missing details have been added. (N) The reviewer comments (C) were excluded from the word count of the ARLs and were not coded in the stance analysis.

# 3.1. Annotating sections of the ARLs

Sections of the ARLs were annotated using the coding scheme in Table 2. Following previous studies (Feak, 2009; Gosden, 2001), this study distinguished between three major sections of ARLs, i.e., Opening Statement, Point-by-Point Response, and Closing Remarks. Two other sections, Additional Changes and References, have been added to the coding scheme by reading the 50 ARLs. The Point-by-Point Response was further categorized into Response to Positive Comments and Response to Negative/Mixed Comments. Additionally, Response to Negative/Mixed Comments was classified into three types of responses, i.e. Revision, No Revision, and Partial Revision. Note that referee comments (C) are presented in Table 2 as examples of “positive comment” and “negative/mixed comment”. Their stance features were not analyzed.

Table 2 Coding Scheme for Sections in the ARL.   

<html><body><table><tr><td>Section</td><td>Description of section</td><td>Example from the corpus</td></tr><tr><td>1 Opening Statement (Opn Stmt)</td><td>Opening remarks preceding the point-by-point response, often to express gratitude, show an overview of the revisions, and explain the organization of the ARL.</td><td>We greatly appreciate the Reviewers&#x27; comments to improve our manuscript. To address these comments, we have [...]. Below we provide a point-by-point response to the reviewers&#x27; comments and indicate how we have modified the manuscript. (N)</td></tr><tr><td>2 Point-by-Point Response (Pt-by-Pt Res) 2.1 Response to Positive Comments (Res Pos Cmt)</td><td>Point-by-point replies to individual comments Response to comment that is entirely positive</td><td>C: This is a timely and highly interesting study that has [...]. R: We thank the reviewer for these highly</td></tr><tr><td rowspan="2">2.2 Response to Negative/Mixed Comments (Res Neg/Mixd Cmt) 2.2.1 Revision (Rev)</td><td>Response to comment that is (partially) negative</td><td rowspan="2">supportive comments. (N) C: This first mention of [...] might prove</td></tr><tr><td>Revise the paper in accordance with the reviewer&#x27;s request confusing for those outside the field.</td></tr><tr><td>2.2.2 No Revision (No Rev)</td><td>No revision is made</td><td>R: We agree; the missing details have been added. (n) C: The [...] analysis needs to be simplified.</td></tr><tr><td>2.2.3 Partial Revision (Part Rev)</td><td>The revision is not in full accordance with the reviewer&#x27;s request</td><td>R: The authors feel this is well explained already. (NM) C: Reference information of [12], [32], and [38] are insufficient or incorrect.</td></tr></table></body></html>

Table 2 (continued )   

<html><body><table><tr><td>Section</td><td>Description of section</td><td>Example from the corpus.</td></tr><tr><td></td><td></td><td>bibliographic information in references [32] and [38]. (N)</td></tr><tr><td>3 Additional Changes (Add Chg) 4 Closing Remarks (Cl Rmk)</td><td>Changes that are not requested by the. reviewer/editor</td><td>While working on the resubmission we noticed a few small mistakes that we now corrected. (N) We hope these new data and clarifications will</td></tr><tr><td></td><td>Repeat thanks, re-confirm that revisions have been made, and sign off the ARL.</td><td>render our manuscript acceptable for publication. Sincerely, Dr. M (NCB)</td></tr><tr><td>5 References (Ref)</td><td colspan="2">List of references that are cited in the ARL</td></tr></table></body></html>

Using the coding scheme in Table 2, the author and an additional coder (a research assistant trained in discourse analysis) each coded 10 ARLs independently, reaching an agreement of $9 2 . 7 \ \%$ The differences were resolved through discussion, in addition to consultations with an expert who has published papers in and reviewed manuscripts for high-impact OPR journals. The author then coded the other 40 ARLs independently. A random sample of 20 ARLs were re-coded by the author one month after the initial coding. The resulting intra-coder agreement is $9 8 . 1 \ \%$ .

# 3.2. Annotating stance markers in the ARLs

The model developed by Hyland (2005) was used to annotate stance markers in the ARLs. Hyland’s approach has been chosen because it has been applied to a wide range of academic genres, including reviewer reports (Paltridge, 2017) and research articles (Hyland and Jiang, 2018), two genres that are closely related to ARLs. Hyland (2005) defines authorial stance as being realized through four types of linguistic devices. The stance devices may take the form of verbs (e.g., believe, show), modals (e.g., must, might), adjectives (e.g., happy, disappointed), adverbs (e.g., likely, possibly), and nouns (e.g., the fact that) (Hyland, 2005).

1) Hedges (Items that mitigate commitment to the truth or accuracy of a proposition, e.g., possible, might)   
2) Boosters (Items that emphasize the certainty of a proposition, e.g., clearly, beyond doubt)   
3) Attitude markers (Items that express the author’s feelings, attitudes, or judgment concerning a proposition, e.g., sur  
prisingly, agree)   
4) Self-mentions (First person pronouns, e.g., we, our, I)

To begin with, Hyland’s (2005) list of stance markers was employed to search and automatically code the 50 ARLs, using the “Text Search and Autocode” function of MAXQDA. The author then read 10 randomly selected ARLs and manually annotated any items that are not on Hyland’s (2005) list. An extended list of stance markers was generated based on the 10 ARLs, which was used to automatically annotate the other 40 ARLs. All the 50 ARLs were checked again by hand to ensure the accuracy of the coding. Two weeks post-coding, the author repeated the coding process for 10 randomly selected ARLs, reaching an agreement of $9 0 . 1 \ \%$ . Annotated items that are not on Hyland’s (2005) list fall into four categories:

1) Synonyms of items on Hyland’s (2005) list, e.g., astounding, a synonym of the attitude marker surprising   
2) Inflected forms of items on Hyland’s (2005) list, e.g., indicating, an inflected form of the hedging device indicate   
3) Stance nouns followed by that-compliment clauses, e.g., the fact/belief/possibility that (see Jiang and Hyland, 2018)   
4) Attitude markers that are not on Hyland’s (2005) list, which however serve to convey the author’s affective attitudes towards the reviewer (thank, grateful, apologize, appreciate), the reviewer comment (correct, incorrect, fair, unfair, helpful, insightful, constructive, valuable, excellent), the manuscript (strong, fascinating, novel, robust, successful, strengthened, improved), or the revision activity (difficult, challenging, complex)

The results of the stance analysis were normalized to per 1,000 words, as the size of each section of the ARL differs. Stance features in sections under the same level of headings (as shown in Table 2) are compared. The Kruskal–Wallis $H$ test (twotailed, $\pmb { \mathscr { x } } = 0 . 0 5$ ), a non-parametric equivalent of the one-way ANOVA that does not assume a normal distribution, was used to determine if there were significant differences in the frequency of stance markers per 1,000 words among the different sections of the ARL. It was carried out on two sets of sections/subsections: Sections 1-4 of the ARL, and subsections 2.2.1-2.2.3 of the ARL. The Kruskal–Wallis $H$ test was followed by the post-hoc Dunn’s test, a non-parametric multiple comparison test that does not assume a normal distribution, to identify differences between pairs. The post-hoc Dunn’s test used the Bonferroni correction, a method to counter the multiple-comparison problem. With the Bonferroni correction, the alpha level for the post-hoc Dunn’s test was adjusted by dividing the overall alpha level $\textstyle { \mathfrak { a } } = 0 . 0 5$ ) by the number of pair-wise comparisons being performed. Additionally, the Mann Whitney $U$ test (two-tailed, $\pmb { \mathscr { a } } = \mathbf { 0 . 0 5 }$ ), a nonparametric equivalent to an Independent Samples T-test, was performed on sections 2.1 and 2.2 of the ARL.

The next section begins by reporting the results of the statistical analysis (also see supplementary file 4). It then presents a qualitative analysis of the rhetorical functions of the four types of stance markers, focusing especially on the most frequent stance markers in each section.

# 4. Results

All ARLs contain Point-by-Point Response, as shown in Table 3. Additionally, $6 2 \ \%$ ARLs have Opening Statement, $2 4 \ \%$ provide Reference, $1 0 \%$ offer Closing Remarks, and $8 \%$ show Additional Changes. Although the majority $( 7 6 . 7 \% )$ of reviewer suggestions are fully incorporated, $7 6 \%$ ARLs contain at least one No Revision response, and $8 2 \%$ contain at least one Partial Revision response. Taken together, only $6 \%$ ARLs fully incorporate all reviewer suggestions, suggesting that divergence from reviewer opinion is common. In addition to responding to criticisms, $34 \%$ ARLs also formulate specific replies to comments that are entirely positive. We can also see from Table 3 that Opening Statement and Closing Remarks are typically brief, with an average word count of 190 and 31 words, respectively. Unsurprisingly, Response to Negative/Mixed Comments is notably longer (106 words on average) than Response to Positive Comments (16 words on average). Revision, at 94 words on average, ranges from a one-word reply (e.g., “corrected”, “deleted”, “changed”) to a detailed description of the changes. No Revision (106 words on average) is slightly lengthier than Revision. At 190 words, Partial Revision is the longest type of responses. The greater textual space for Partial Revision is possibly because it serves two rhetorical goals, i.e., 1) describing the changes, and 2) showing why the reviewer comment is not fully addressed.

Table 3 Sections in the ARLs (Total N of $\mathbf { A R L S } = 5 0$ ).   

<html><body><table><tr><td>Section</td><td colspan="2">Total N (%) of ARLs containing the sectiona</td><td>Total N of the section in the corpusb</td><td>Total N of words for the section</td><td>Avg. N of words for the sectionc</td><td> Standard Deviation</td></tr><tr><td>1 Opn Stmt</td><td>31</td><td>(62 %)</td><td>31</td><td>5,896</td><td>190</td><td>219.15</td></tr><tr><td>2 Pt-by-Pt Res</td><td>50</td><td>(100 %)</td><td> 50</td><td>122,287</td><td>2,446</td><td>1052.81</td></tr><tr><td>2.1 Res Pos Cmt</td><td>17.</td><td>(34 %)</td><td>41</td><td>663</td><td>16.</td><td>11.49</td></tr><tr><td>2.2 Res Neg/Mixd Cmt</td><td>50</td><td>(100 %)</td><td>1144</td><td>121,624</td><td>106</td><td>114.35</td></tr><tr><td>2.2.1 Rev</td><td>50</td><td>(100 %)</td><td>877</td><td>82,037</td><td>94</td><td>107.39</td></tr><tr><td>2.2.2 No Rev</td><td>38</td><td>(76 %)</td><td>132</td><td>13,951</td><td>106</td><td>84.70</td></tr><tr><td>2.2.3 Part Rev</td><td>41</td><td>(82 %)</td><td>135</td><td>25,636</td><td>190</td><td>144.35</td></tr><tr><td>3 Add Chg</td><td>4</td><td>(8%)</td><td>4</td><td>420</td><td>105</td><td>37.04</td></tr><tr><td>4 Cl Rmk</td><td>5</td><td>(10 %)</td><td>5.</td><td>156</td><td>31</td><td>11.45</td></tr><tr><td>5 Ref</td><td>12</td><td>(24 %)</td><td>12</td><td>2,576</td><td>215</td><td>117.08</td></tr></table></body></html>

a,b “Total N $( \% )$ of ARLs containing the section” refers to the number of ARLs that contain a section. “Total N of the section in the corpus” refers to the total number of times that a section appears in the corpus, and a section may show up more than once in the same ARL. c “Avg. N of words for the section” is calculated by dividing “Total N of words for the section” by “Total N of the section in the corpus”.

Overall, 6,819 stance markers are found in the ARLs, including 3,754 self-mentions, 1,346 attitude markers, 975 hedges, and 744 boosters. Table 4 shows a comparison of stance markers in ARLs and in other genres related to journal peer review, i.e., reviewer reports and research articles, drawing on previous studies by Paltridge (2017) and Hyland and Jiang (2018). Selfmentions appear to be more frequent in ARLs and reviewer reports than in research articles, signaling a more visible authorial presence in the former two genres. Attitude markers are the most common in reviewer reports, showing that reviewers articulate their attitudinal stance more explicitly than authors. Authors are more likely to hedge their views than reviewers, evidenced by a higher incidence of hedges in research articles and ARLs than reviewer reports. Boosters are the most prevalent in ARLs, suggesting that authors invest a high degree of assurance in their claims when responding to reviewers.

Table 4 Stance Markers in ARLs and Other Genres Related to Journal Peer Review.a   

<html><body><table><tr><td rowspan="2">Genre</td><td> Self-mentions</td><td>Attitudes</td><td>Hedges</td><td rowspan="2">Boosters</td><td rowspan="2">Total</td></tr><tr><td>F per 1,000 wordsb (% of total items)</td><td></td><td></td></tr><tr><td>Author rebuttal letters</td><td>28.6 (55.1 %)</td><td>10.2 (19.7 %)</td><td>7.4 (14.3 %)</td><td>5.7 (10.9 %)</td><td>51.9 (100 %)</td></tr><tr><td>Reviewer reports (Paltridge, 2017:124-129)</td><td>21.5 (40.6 %)</td><td>23.0 (43.5 %)</td><td>6.0 (11.2 %)</td><td>2.5 (4.7 %)</td><td>52.8 (100 %)</td></tr><tr><td>Research articles (Hyland and Jiang, 2018:111)</td><td>3.9 (14.5 %)</td><td>4.0 (14.9 %)</td><td>15.1 (56.1 %)</td><td>3.9 (14.5 %)</td><td>26.9 (100 %)</td></tr></table></body></html>

a To make the results comparable, the numbers in the rows “Reviewer reports” and “Research articles” are recalculated based on data from Hyland and Jiang (2018) and Paltridge (2017). b “F per 1,000 words” refers to the frequency of stance marker per 1,000 words in a corpus.

Table 5 shows the mean frequency (M) and standard deviation (SD) of stance markers per 1,000 words in different sections of the ARLs. The Kruskal–Wallis $H$ test showed a significant difference in the frequency of total stance markers per 1,000 words between the four main sections of the ARL, i.e., Opening Statement, Point-by-Point Response, Additional Changes, and Closing Remarks $M = 4 1 . 7 8$ , $p < . 0 0 1$ ). The Post-Hoc Dunn’s test, using a Bonferroni corrected alpha of 0.0083, further indicated that Opening Statement contains more stance markers than Point-by-Point Response $( Z = 6 . 0 6$ , $p < . 0 0 1 .$ ) or Additional Changes $Z = 3 . 2 3$ , $p = . 0 0 1 $ ). The four sections also differ in the frequency of self-mentions ${ \bf \mathit { H } } = 3 7 . 9 2 { \mathrm { ~ } }$ , $p < . 0 0 1$ ), attitudes $\cdot H = 3 8 . 8 4$ , $p < . 0 0 1$ ), hedges $( H = 4 4 . 3 7 , p < . 0 0 1 )$ ), and boosters $\cdot H = 8 . 5 5$ , $p = . 0 3 6 )$ . The Post-Hoc Dunn’s test was significant for the following pairs of sections: 1) Opening Statement contains more self-mentions than Point-by-Point Response $( Z ~ = ~ 5 . 9 9$ , $p ~ < ~ . 0 0 1$ ); 2) Opening Statement has more attitude markers than Point-by-Point Response $( Z = 5 . 5 8$ , $p < . 0 0 1 \ r .$ ) or Additional Changes $Z = 3 . 5 9$ , $p < . 0 0 1$ ); Closing Remarks also has more attitude markers than Additional Changes $( Z = 4 8 . 3$ , $p \ : = \ : . 0 0 6 )$ ; 3) Point-by-Point Response contains more hedges than Opening Statement $( Z = 6 . 1 0$ , $p < . 0 0 1$ ) or Closing Remarks $Z = 3 . 7 5$ , $p < . 0 0 1$ ). There is no statistical difference in the frequency of boosters between any pair of sections.

Table 5 Frequency of Stance Markers per 1,000 words in the ARLs.   

<html><body><table><tr><td>Section</td><td colspan="2">Self-mentions</td><td colspan="2">Attitudes</td><td colspan="2">Hedges</td><td colspan="2">Boosters</td><td colspan="2">Total</td></tr><tr><td></td><td></td><td> SD</td><td>M</td><td> SD</td><td>m</td><td> SD</td><td>m</td><td> SD</td><td>m</td><td> SD</td></tr><tr><td>1 Opn Stmt</td><td>66.43</td><td>29.41</td><td>45.29</td><td>30.66</td><td>1.52</td><td>3.03</td><td>5.53</td><td>7.84</td><td>118.78</td><td>53.40</td></tr><tr><td>2 Pt-by-Pt Res</td><td>28.20</td><td>8.56</td><td>10.06</td><td>4.30</td><td>7.78</td><td>3.46</td><td>5.98</td><td>3.12</td><td>52.02</td><td>13.42.</td></tr><tr><td>2.1 Res Pos Cmt</td><td>75.69</td><td>46.00</td><td>121.50</td><td>116.26</td><td>1.01</td><td>4.06</td><td>6.87</td><td>16.38</td><td>205.07</td><td>103.02</td></tr><tr><td>2.2 Res Neg/Mixd Cmt</td><td>27.86</td><td>8.41</td><td>9.62</td><td>4.25</td><td>7.82</td><td>3.48</td><td>5.99</td><td>3.12</td><td>51.29</td><td>13.31</td></tr><tr><td>2.2.1 Rev</td><td>28.15</td><td>10.70</td><td>9.05</td><td>4.97</td><td>5.80</td><td>3.45</td><td>5.03</td><td>3.04</td><td>48.04</td><td>15.85</td></tr><tr><td>2.2.2 No Rev</td><td>28.4</td><td>20.18</td><td>11.11</td><td>9.98</td><td>11.64</td><td>10.06</td><td>7.93</td><td>6.15</td><td>59.13</td><td>26.81</td></tr><tr><td>2.2.3 Part Rev</td><td>30.60</td><td>12.60</td><td>11.39</td><td>6.46</td><td>11.14</td><td>6.98</td><td>7.40</td><td>5.19</td><td>60.53</td><td>20.40</td></tr><tr><td>3 Add Chg</td><td>31.41</td><td>18.37</td><td>4.07</td><td>7.04</td><td>4.87</td><td>5.01</td><td>3.45</td><td>3.56</td><td>43.80</td><td>20.09</td></tr><tr><td>4 Cl Rmk</td><td>72.46</td><td>56.67</td><td>61.51</td><td>44.43</td><td> 0.00</td><td> 0.00</td><td>8.70</td><td>17.39</td><td>142.67</td><td>114.63</td></tr><tr><td>5 Ref</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td></tr></table></body></html>

The rest of Section 4 shows in greater detail the use of the four types of stance markers in each section of the ARL, with examples from the corpus. In the examples, the stance markers that are being discussed are shown in bold and italics.

# 4.1. Stance markers in Opening Statement

The Opening Statement, found in 31 ARLs, is marked by a high incidence of stance markers. Self-mentions, found in 30 ARLs, are typically used when authors express feelings of gratitude, delight, and hope for success ([1]). As shown earlier, Opening Statement contains more self-mentions than Point-by-Point Response, indicating that authors signal explicitly their self-presence at the beginning of the ARL. Almost all the self-mentions in the ARLs are in the plural form (i.e., we, our, ours, us), as all the sample research articles have multiple authors.

# [1] We are delighted by the very constructive comment. (N)

Attitude markers were found in the Opening Statement of 31 ARLs. As the multiple comparison test shows, attitude markers are markedly more frequent in Opening Statement than Point-by-Point response or Additional Changes, suggesting that authors express stronger emotions at the beginning of the ARL. The ten most common attitude markers in Opening Statement are shown in Table 6.

Table 6 Top 10 Most Frequent Attitude Markers in Opening Statement.   

<html><body><table><tr><td>Attitude marker</td><td>F per 1,000 words</td><td>Attitude marker</td><td>F per 1,000 words</td></tr><tr><td>thank</td><td>7.29</td><td>improved</td><td>1.02</td></tr><tr><td>appreciate</td><td>1.70</td><td> insightful</td><td>1.02</td></tr><tr><td>constructive</td><td>1.70</td><td>thoughtful</td><td>0.85</td></tr><tr><td>important</td><td>1.53</td><td>helpful</td><td>0.68</td></tr><tr><td>hope (v.)</td><td>1.02</td><td>carefully</td><td>0.51</td></tr></table></body></html>

Table 6 shows that attitude markers expressing gratitude to the reviewers (thank, appreciate) and positive evaluations of the reviewer report (constructive, insightful, thoughtful, helpful) are highly frequent in Opening Statement. An example of the expressions of gratitude is shown in [2]. Table 6 also indicates that the attitudinal expression improved is common in Opening

Statement. Adjectives that serve to advocate the revised paper, such as improved, strengthened, and successful, were found in 16 ARLs [3]. Hope (v.) is another frequent attitude marker. In six ARLs, authors express hope for the acceptance of the paper in Opening Statement ([4]).

[2] We would like to thank the referees for their thorough and positive reviews of this paper and their numerous helpful comments. (N)

[3] We believe that our revised manuscript represents a markedly improved version with greater clarity, better balance, and improved English and readability. (N)

[4] We sincerely hope that it can now be regarded acceptable for publication in Nature Biomedical Engineering. (NBE)

Hedges are less common in Opening Statement (found in seven ARLs) and are mostly used in the description of new findings that have emerged from the revised data ([5]).

[5] This further suggests that adiponectin receptors are required to preserve HSC function by reducing inflammation from immune cells. (NCB)

Boosters, found in 13 ARLs, mainly serve to emphasize improvement ([6]).

[6] We believe our manuscript is extremely successful in its first two goals, with the revised version showing new success in the third. (NBE)

After making an opening statement, authors respond to specific comments of the reviewer, in the Point-by-Point Response section.

# 4.2. Stance markers in Point-by-Point Response

The Point-by-Point Response may contain two sub-sections: Response to Positive Comments and Response to Negative/ Mixed Comments. The Mann–Whitney $U$ test showed that authors use more stance markers when responding to positive comments $\textstyle { \mathcal { Z } } = 5 . 4 8$ , $p < . 0 0 1$ ), including more self-mentions $( Z = 3 . 5 7 , p < . 0 0 1 )$ and attitudes $Z = 6 . 1 2$ , $p < . 0 0 1$ ). Response to negative/mixed comments is less personal or emotional, but they contain a greater number of epistemic stance markers, including more hedges $Z = 5 . 4 4$ , $p < . 0 0 1 $ ) and boosters $( Z = 3 . 9 7 , p < . 0 0 1 )$ .

Response to Positive Comments, found in 17 ARLs, is typically short (16 words on average), in which authors show gratitude for the reviewer’s support, using self-mentions and attitudinal constructions in combination, such as we thank and we appreciate [7]. Unsurprisingly, the most frequent attitude markers in this type of responses are thank, thanks, appreciate, valuable, and constructive, which emphasize appreciation to reviewers.

# [7] We thank the referee for these encouraging comments. (NBE)

Response to Negative & Mixed Comments were found in all the 50 ARLs and may contain three types of responses: Revision, No Revision, and Partial Revision. The Kruskal–Wallis $H$ test indicated that the three types of responses differ in the frequency of total stance markers $\cdot H = 1 2 . 4 9$ , $p = . 0 0 2 $ ) and hedges $H = 1 5 . 8 2$ , $p < . 0 0 1$ ). As shown by the Post-Hoc Dunn’s test using a Bonferroni corrected alpha of 0.017, Revision is marked by fewer stance markers than No Revision $( Z = 2 . 9 7 ,$ , $p = . 0 0 3 \mathrm { ; }$ or Partial Revision $Z = 3 . 0 3$ , $p = . 0 0 2$ ). More specifically, there are fewer hedges in Revision than No Revision $Z = 3 . 1 4$ , $p = . 0 0 2 )$ or Partial Revision $Z = 3 . 5 8$ , $p < . 0 0 1 $ ). In other words, authors hedge their argument more often when rejecting a referee comment. The rest of this subsection discusses each of the three types of responses in turn.

In the Revision responses, authors accept the criticism and make the requested change. They use self-mentions to highlight their role in improving the manuscript and making contributions to the field [8].

[8] We have developed a new and simpler enzymatic lysis method for [.]. We have designed, built, tested, and validated the function of [.]. We further improved the study by [.]. (NBE)

The most frequent attitude markers in Revision, No Revision, and Partial Revision are given in Table 7. We can see from Table 7 that thank and agree are the top two most frequent attitude markers in Revision ([9]). The attitudinal expressions appreciate, thanks, excellent (e.g., an excellent point), and correct (e.g., the reviewer is correct) are also frequent. Attitude markers serving to thank or show agreement with the reviewer can be found in 47 ARLs. In one ARL, the authors even preface each of the Revision responses with the same statement “we thank the reviewer for the comments”. Sorry and apologize are also frequent attitude markers in Revision, as Table 7 shows. The expressions of apologies, together with attitude markers showing negative evaluation of the paper (e.g., confusing, misleading, awkward, unclear), can be found in 27 ARLs. They are mainly used in the description of non-scientific errors, such as typos, phrasing issues, and formatting mistakes ([10]). Possible explanations are that authors perceive careless mistakes as something they should have avoided. The other two frequent attitude markers in Table 7, important and interesting, may be used to describe the reviewer’s comment (e.g., this important suggestion; a very interesting point) or the study itself (e.g., these important experiments; interesting implications for mating in nature).

Table 7 Top 10 Most Frequent Attitude Markers in Revision, No Revision, and Partial Revision.   

<html><body><table><tr><td colspan="2"> Revision</td><td colspan="2">No Revision</td><td colspan="2"> Partial Revision</td></tr><tr><td>Attitude markers</td><td>F per 1,000 words</td><td>Attitude markers</td><td>F per 1,000 words</td><td>Attitude markers</td><td>F per 1,000 words</td></tr><tr><td>thank</td><td>2.07</td><td> important</td><td>1.36</td><td> agree</td><td>1.76</td></tr><tr><td>agree</td><td>1.08</td><td>agree</td><td>1.29</td><td>thank</td><td>1.05</td></tr><tr><td> important</td><td>0.60</td><td>interesting</td><td>0.86</td><td>important</td><td>0.70</td></tr><tr><td> apologize</td><td>0.43</td><td>thank</td><td>0.72</td><td> importantly</td><td>0.39</td></tr><tr><td>appreciate</td><td>0.33</td><td>importantly</td><td>0.65</td><td> difficult</td><td>0.35</td></tr><tr><td>thanks (n.)</td><td>0.27</td><td>unfortunately</td><td>0.57</td><td>challenging</td><td>0.35</td></tr><tr><td> interesting</td><td>0.21</td><td>difficult</td><td>0.36</td><td>interesting</td><td>0.31</td></tr><tr><td>sorry</td><td>0.17</td><td>expected</td><td>0.29</td><td>unfortunately</td><td>0.27</td></tr><tr><td>excellent</td><td>0.13</td><td>appreciate</td><td>0.22</td><td>appreciate</td><td>0.27</td></tr><tr><td>(the reviewer is) correct</td><td>0.12</td><td>well (explained/supported, etc.)</td><td>0.22</td><td>expected</td><td>0.23</td></tr></table></body></html>

[9] We thank the reviewer for this valuable comment that we fully agree upon. (NBE)

[10] We thank the reviewer for identifying this error, which was a typo. We apologize and it has been now corrected. (NCB)

Table 8 shows the most frequent hedges in Revision, No Revision, and Partial Revision. Hedges help framing scientific claims precisely and cautiously in Revision, where authors present the revised findings ([11]). In three ARLs, hedges also serve to tone down negative evaluations of the manuscript (e.g., possible misleading, perhaps confusing), as in [12].

Table 8 Top 10 Most Frequent Hedges in Revision, No Revision, and Partial Revision.   

<html><body><table><tr><td colspan="2">Revision</td><td colspan="2">No Revision</td><td colspan="2"> Partial Revision</td></tr><tr><td>Hedges</td><td>F per 1,000 words</td><td>Hedges</td><td>F per 1,000 words</td><td>Hedges</td><td>F per 1,000 words</td></tr><tr><td>could</td><td>0.60</td><td>would</td><td>2.22</td><td>would</td><td>2.46</td></tr><tr><td>would</td><td>0.56</td><td>could</td><td>1.15</td><td> could</td><td>1.33</td></tr><tr><td> likely</td><td>0.52</td><td>may.</td><td>1.00</td><td>may</td><td>0.86</td></tr><tr><td>may</td><td>0.46</td><td> likely</td><td>0.86</td><td> possible</td><td>0.78</td></tr><tr><td>suggest</td><td>0.37</td><td>feel</td><td>0.72</td><td>might</td><td>0.78</td></tr><tr><td>might </td><td>0.32</td><td> possible</td><td>0.57</td><td>likely</td><td>0.43</td></tr><tr><td> possible</td><td>0.28</td><td>should</td><td>0.43</td><td>often</td><td>0.35</td></tr><tr><td>indicate</td><td>0.22</td><td> unlikely</td><td>0.43</td><td>feel</td><td>0.27</td></tr><tr><td>suggests</td><td>0.21</td><td>indicates</td><td>0.36</td><td>suggest</td><td>0.20</td></tr><tr><td>should</td><td>0.16</td><td>suggest</td><td>0.29</td><td> mainly</td><td>0.20</td></tr></table></body></html>

[11] These data indicate that, with a transduction efficiency of $\sim 1 0 { - } 1 5 \%$ , approximately $9 0 \%$ of the modified cells contains a single integration. (NI)

[12] We apologize for the possible misleading presentation of this graph. $( N )$

The most frequent boosters in Revision, No Revision, and Partial Revision are shown in Table 9. The frequent boosters in the three types of responses are all certainty boosters, which are typically verbs (find, show, demonstrate, believe, think) and adverbs (clearly, indeed) that amplify the truth of a proposition (Hyland and Zou, 2021). The verbs can be used to represent the proposition as “what is thought” (e.g., find, believe, think) or “what is known” (e.g., show) (Hunston, 2013). For example, the most frequent booster in Revision, found, serves to convey the authors’ epistemic conviction in the certainty of their findings [13]. Boosters also help reinforce statements that describe the improved quality of the paper ([14]). In [15], the booster indeed enhances the authors’ conviction in the helpfulness of the reviewer comments.

Table 9 Top 10 Most Frequent Boosters in Revision, No Revision, and Partial Revision.   

<html><body><table><tr><td colspan="2">Revision</td><td colspan="2">No Revision</td><td colspan="2"> Partial Revision</td></tr><tr><td>Boosters</td><td>F per 1,000 words</td><td>Boosters</td><td>F per 1,000 words</td><td>Boosters</td><td>F per 1,000 words</td></tr><tr><td>found</td><td>0.78</td><td> indeed</td><td>1.00</td><td>show</td><td>0.94</td></tr><tr><td>show</td><td>0.62</td><td>believe</td><td>0.79</td><td>indeed</td><td>0.90</td></tr><tr><td>indeed</td><td>0.57</td><td>found</td><td>0.65</td><td>believe</td><td>0.82</td></tr><tr><td>showed</td><td>0.37</td><td>show</td><td>0.65</td><td>think</td><td>0.43</td></tr><tr><td>believe</td><td>0.22</td><td>shown</td><td>0.50</td><td>shown</td><td>0.39</td></tr><tr><td>shown</td><td>0.21</td><td>think</td><td>0.43</td><td>clearly</td><td>0.31</td></tr><tr><td>clearly</td><td>0.18</td><td>shows</td><td>0.43</td><td>demonstrated</td><td>0.31</td></tr><tr><td>demonstrated</td><td>0.18</td><td>find</td><td>0.43</td><td> showed</td><td>0.31</td></tr><tr><td>think</td><td>0.17</td><td>demonstrate</td><td>0.36</td><td>find</td><td>0.27</td></tr><tr><td>demonstrate</td><td>0.17</td><td> clearly</td><td>0.29</td><td>demonstrate</td><td>0.27</td></tr></table></body></html>

[13] We have now analyzed the [.] and found that it’s reduced in activated B cells and plasma cells. (NI)

[14] We trust that the overall clarity and readability is now markedly enhanced. (N)

[15] This is indeed a very interesting point raised by the reviewer. (NCB)

In No Revision responses, which are found in 38 ARLs, authors reject the reviewer suggestion. Self-mentions are used in No Revision to emphasize the authors’ intention to solve problems. In [16], for example, the self-mention we emphasizes the authors’ plan to address the referee comment in follow-up studies.

[16] We are gradually working towards a system which we hope will provide a means to answer these questions. (N)

In No Revision, authors rarely voice their rejection explicitly. As shown in Table 7 above, attitude constructions showing disagreement with reviewers, such as incorrect, disagree, and unfair, are uncommon in No Revision or Partial Revision responses. This type of attitude markers was found in only three ARLs ([17]).

# [17] We disagree and see no issue with the band sizing. (NI)

A more common way to decline to address a reviewer comment, is to first accept the criticism, and then present the argument for not acting on it ([18]). Table 7 shows that agree is one of the most frequent attitude markers in No Revision and Partial Revision, despite the authors’ actual rejection of the reviewer suggestion. In the case of No Revision, expressions of agreement/gratitude were found in 22 ARLs. Table 7 also indicates that positive evaluations of the significance, novelty, and robustness of the study, such as well-explained/supported, important, and interesting, are common in No Revision. Found in 18 ARLs, this type of attitude markers represents another rhetorical strategy to reject revision, i.e., by advocating the merit of the original paper ([19]). Difficult and unfortunately, both being frequent attitude markers in No Revision, also serve to build an argument for not incorporating the reviewer suggestion. This type of attitude markers, found in 10 ARLs, show that the suggested change is unfeasible ([20]).

[18] We agree that performing these experiments would be interesting. However, their complexity is also extremely high and unlikely to work. (NCB)

[19] No – this result, whilst not significant, shows that [.], which is an important finding. (NM)

[20] Unfortunately, it is difficult to test [.] because it would take 2 years to age the [.] mice required for the experiment. (NCB)

Hedges, which are significantly more frequent in No/Partial Revision than Revision, construe another important strategy for mitigating disagreement. A higher incidence of hedges makes the No/Partial Revision responses less assertive in tone. From Table 8 above, we can see that the plausibility markers would, could, and may are the most frequent hedging devices in No/Partial Revision. The plausibility modal would, for example, is almost four times more common in No Revision than in Revision. In [21], would softens the author’s claim that the suggested change is distractive. The epistemic verb feel, a hedging device, is frequent in No/Partial Revision but not in Revision, as Table 8 shows. In No Revision, the phrase we feel is almost exclusively used to tone down the authors’ rejection of the reviewer suggestion, as in [22]. Hedges are also used in No Revision to show the authors’ recognition of alternative scientific views. As shown in [23], instead of fully denying the referee suggestion, authors describe it as would perhaps be helpful.

[21] We do not propose to add these data to the manuscript as it would distract from the main message of the study. (NCB)

[22] We feel this is beyond the scope of our current study. (NI)

[23] Addition of [.] would perhaps add another level of confirmation to this, but the effect of this mutation on neutralisation is well established in the field. (NM)

Interestingly, No/Partial Revision also contains significantly more boosters than Revision, showing that authors are not always conciliatory when their views are being challenged. In Table 9, we see that all the frequent boosters in No/Partial Revision are certainty markers, which foreground authors’ conviction in their claims. In [24], for example, authors use the fact that and beyond doubt to reinforce their confidence in their findings. The increased use of boosters in No/Partial Revision shows that authors attempt to build an assured and decisive image of themselves when rejecting criticisms.

[24] The fact that CTLA-4 is modified by ubiquitin in a manner dependent on cytoplasmic lysine residues, seems beyond doubt. (NI)

Partial Revision, meaning that the reviewer’s request is not fully fulfilled, was found in 41 ARLs. The frequency of stance markers in Partial Revision and No Revision shows no difference, as suggested by the Kruskal–Wallis H test. From Tables 7–9, we can also observe that the most common stance markers are generally similar in Partial Revision and No Revision. Extract [25] is an example of how authors may frame the Partial Revision responses.

[25] With regards to the question on fluorescence quantifications, we have now expanded our Methodology section to [.]. With regards to intravital imaging, we believe this [.] would go beyond the already beaming scope of this study. (NI)

In [25], the self-mention we emphasizes the authors’ role in trying to address the reviewer’s concerns. The use of the attitudinal expression beaming, which appears to be a play on words, helps advocate the paper. The certainty booster believe shows the authors’ conviction in the strength of the paper, while the plausibility modal would prevents the statement from sounding too assertive.

# 4.3. Stance markers in Additional Changes

In four ARLs, authors outline additional revisions that are not requested by the reviewer. Self-mentions are used when authors take the credit for detecting the error and performing the additional revision ([26]). In [27], the booster believe amplifies the claim that the additional change is worthy of being made. Hedges in this section serve to describe new scientific claims derived from the additional changes, e.g., “rescue appeared as efficient as with WT ASOR”.

[26] We noticed a few small mistakes that we now corrected.

[27] We have added a new experiment that had not been requested by the reviewers, but which is a valuable addition, as we believe. (NCB)

# 4.4. Stance markers in Closing Statement

In five ARLs, authors make a brief closing note, in which they repeat thanks, re-emphasize improvements, and express hope for acceptance. Thank and hope are the top two most frequent attitude markers in Closing Statement. They are often used in combination with the self-mention we ([28]-[29]). Boosters emphasize the authors’ confidence in the revised manuscript ([30]). Closing Statement contains no hedges.

[28] We again thank all Referees for their suggestions, which further helped to improve the manuscript. On behalf of all co-authors, Dr. X. (N)   
[29] We hope these new data and clarifications will render our manuscript acceptable for publication. Sincerely, Dr. Y. (NCB)   
[30] We think that by addressing these issues, we ameliorated our study. (NI)

# 5. Discussion and conclusion

This study identifies the pattern of stance deployment in 50 Nature Portfolio open peer review ARLs and compare it to that in research articles (Hyland and Jiang, 2018) and reviewer reports (Paltridge, 2017). It analyzes the variation in authors’ stance choices in different sections of the ARL, drawing on the most frequent stance markers in each section and examples from the section.

Findings of this study appear to support the view that the process of peer review is an integrative negotiation between authors and reviewers (Bedeian, 2004; Liu, 2014). Previous studies suggest that early career researchers may perceive authorreviewer communication as “a distributive negotiation in one of two ways”, meaning that they may either submissively accept every reviewer request, or fiercely contest all criticisms (Lei and Hu, 2019; Liu, 2014, p. 183). This study shows full or partial disagreement with reviewers is common, as only $6 \%$ Nature Portfolio ARLs fully incorporate every referee request. Mitigation strategies constitute an important feature of the authors’ rhetoric when they reject a reviewer comment. Authors seldom openly label the reviewer’s criticism as “unfair” or “incorrect”. They often use hedges to soften the No Revision claims (“we feel this is beyond the scope of our current study”), and expressions of thanks and gratitude to buffer the rejection (“The reviewer raises an interesting question, however [.]”; “we appreciate this comment, but [.]”).

This study has identified stance features which seem to contradict the results of earlier studies or recommendations offered in academic writing manuals. According to Swales’ (1996) analysis of cover letters accompanying journal submissions to an Applied Linguistics journal, and Shaw and Okamura’s (1998) study of the same genre in civil engineering journals, expert writers rarely advocate the paper, express hope for acceptance, or build relations with editors/reviewers in an “effusive” manner. The “conventional coolness” identified in Swales’ (1996) and Shaw and Okamura’s (1998) studies has been attributed to an egalitarian academic discourse system, meaning that “thanking or expressing hope may be against the principle of free and rational choice” (Shaw and Okamura, 1998, p.276). This type of “coolness” is less typical of the sample ARLs, in which attitude markers expressing gratitude to reviewers (e.g., thank, appreciate), positive evaluations of the reviewer report (e.g., constructive, insightful), positive appraisal of the manuscript (e.g., improved, well-explained), and hope for success (e.g., hope) are among the most common stance items. In addition, while recently published academic writing manuals suggest that authors “do not need to respond to complimentary and positive comments” (Tan, 2022, p. 215), $34 \%$ ARLs have done so. Further, prefacing every response with the phrase “thank you” or “we agree”, an act of “overcompensation” (Lei and Hu, 2019), can be found in two ARLs. A possible explanation of the self-marketing and relation-building elements in ARLs is the “publish or perish” pressure that dominates many academic institutions, which is believed to have led to a growing presence of promotional language in today’s academic publications (Hyland and Jiang, 2018; Shaw et al., 2014; Wen and Lei, 2022). Authors who seek to publish in the highly competitive Nature Portfolio journals may forcefully advocate the manuscript in ARLs, so that the merits of their work do not go unnoticed by the editor or reviewer, who often needs to maintain a rapid turnaround time for the review.

This study offers the following suggestions for ESP teachers in helping students to write effective ARLs. 1) Teachers can sensitize students to expert writers’ stance preferences in ARLs. They may ask students to identify stance markers in different sections of ARLs, and discuss whether removing the identified features might undermine the cooperation with reviewers and the persuasiveness of the letter. 2) Teachers might raise students’ awareness that the peer review process is an integrative rather than distributive negotiation. Exercises can be designed to analyze the frequency of No/Partial Revision responses in ARLs, as well as the reasons and phrasing expert writers use to support the no revision claims. Teachers can invite students to discuss how stance markers are employed by expert writers for hedging or buffering the disagreement with reviewers, and whether similar rhetorical strategies can be used in the students’ own ARLs. 3) For students in the hard sciences, it may also be helpful to read the ARLs with the accompanying reviewer reports and research articles, to better understand the process through which a research article is revised into its publishable form.

Another implication of this study, regarding methodology, appears to be that it is useful to include manual analysis when analyzing attitude markers in a new genre. In this study, automatic annotation of hedges/boosters/self-mentions using Hyland’s (2005) list of stance markers was highly efficient, as it has covered $9 6 . 3 \ \%$ hedges, $9 3 . 8 \ \%$ boosters, and $100 \%$ selfmentions that were annotated (see supplementary file 3). For attitude markers, however, some items are related specifically to ARLs (e.g., gratitude towards the reviewer, apologies for mistakes, and hope for acceptance) and can only be identified through a close reading of the documents.

A limitation of this study is that it does not distinguish between ARLs written by authors who are first language and highly proficient second language writers and those who are not, as it focuses on expert researchers’ use of language, regardless of their cultural background. Another reason for not investigating cross-cultural differences is because many Nature Portfolio research articles involve international collaboration. Secondly, it should be remembered that authors may adjust their language in the ARL, knowing that the exchanges may be published. They may opt out of OPR when the peer review process is difficult, hence the low incidence of open confrontation with reviewers in the sample ARLs. Third, for Nature Portfolio journals, the majority of authors who agree to follow OPR are scientists in life sciences, earth sciences, and paleontology (Nature, 2022). With the growth of OPR adoption in high-impact academic journals, future research could investigate stance deployment in ARLs from a wider range of disciplines. Lastly, the discussion of the rhetorical functions of stance markers in ARLs is qualitative but not quantitative. Studies focusing on quantitative analysis may be carried out in the future.

# Data availability

I have shared my data in the supplementary files of the paper.

# Acknowledgements

I am grateful to the two anonymous reviewers and the editor for their constructive feedback on earlier versions of this paper. This work was supported by the National Office for Philosophy and Social Sciences of China [grant numbers 21CYY010].

# Appendix A. Supplementary data

Supplementary data to this article can be found online at https://doi.org/10.1016/j.esp.2023.10.004.

# References

Bedeian, A. G. (2004). Peer review and the social construction of knowledge in the management discipline. The Academy of Management Learning and Education, 3(2), 198-216.   
Belcher, D. (2007). Seeking acceptance in an English-only research world. Journal of Second Language Writing, 16(1), 1-22.   
Biber, D., & Finegan, E. (1989). Styles of stance in English: lexical and grammatical marking of evidentiality and affect. Text - Interdisciplinary Journal for the Study of Discourse, 9(1), 93-124.   
Bornmann, L., Wolf, M., & Daniel, H.-D. (2011). Closed versus open reviewing of journal manuscripts: how far do comments differ in language use? Scientometrics, 91(3), 843-856.   
Boyle, J., & Ramsay, S. (2019). Writing a Science PhD. Bloomsbury Publishing.   
Bravo, G., Grimaldo, F., Lopez-Inesta, E., Mehmani, B., & Squazzoni, F. (2019). The effect of publishing peer review reports on referee behavior in five scholarly journals. Nature Communications, 10. Article 322.   
Cargill, M., & O’Connor, P. (2011). Writing Scientific Research Articles: Strategy and Steps. John Wiley & Sons.   
Coniam, D. (2011). Systematising System: one reviewer’s analysis of the review process. System, 39(4), 539-553.   
Coxhead, A., Batchelor, J., Mushi, O., Qiu, X., & Hyon, S. (2023). Becoming a reviewer: insights from the student and editorial boards of ESPJ. English for Specific Purposes, 72, 20-25.   
Crosthwaite, P., Cheung, L., & Jiang, F. (2017). Writing with attitude: stance expression in learner and professional dentistry research reports. English for Specific Purposes, 46, 107-123.   
Douglas, Y., & Grant, M. (2018). The Biomedical Writer: what You Need to Succeed in Academic Medicine. Cambridge University Press.   
Feak, C. (2009). Negotiating publication: author responses to peer review of medical research articles in thoracic surgery. Revista Canaria de Estudios Ingleses, 59, 17-34.   
Flowerdew, J., & Dudley-Evans, T. (2002). Genre analysis of editorial letters to international journal contributors. Applied Linguistics, 23(4), 463-489.   
Fortanet, I. (2008). Evaluative language in peer review referee reports. Journal of English for Academic Purposes, 7(1), 27-37.   
Geng, F., & Yu, S. (2022). Exploring Doctoral Students’ Emotions in Feedback on Academic Writing: A Critical Incident Perspective. Studies in Continuing Education. Advance online publication.   
Gillaerts, P., & Van de Velde, F. (2010). Interactional metadiscourse in research article abstracts. Journal of English for Academic Purposes, 9(2), 128-139.   
Gosden, H. (2001). “Thank you for your critical comments and helpful suggestions”: compliance and conflict in authors’ replies to referees’ comments in peer reviews of scientific research papers. Iberica, (3), 3-17.   
Gosden, H. (2003). “Why not give us the full story?”: functions of referees’ comments in peer reviews of scientific research papers. Journal of English for Academic Purposes, 2(2), 87-101.   
Hewings, M. (2004). An ‘important contribution’ or ‘tiresome reading’? A study of evaluation in peer reviews of journal article submissions. Journal of Applied Linguistics and Professional Practice, 1(3), 247-274.   
Hu, G., & Cao, F. (2011). Hedging and boosting in abstracts of applied linguistics articles: a comparative study of English- and Chinese-medium journals. Journal of Pragmatics, 43(11), 2795-2809.   
Hunston, S., & Thompson, G. (2000). Evaluation in Text: Authorial Stance and the Construction of Discourse. Oxford University Press.   
Hunston, S. (2013). Systemic functional linguistics, corpus linguistics, and the ideology of science. Text & Talk, 33(4–5), 617-640.   
Hyland, K. (2005). Metadiscourse: Exploring Interaction in Writing. Continuum.   
Hyland, K. (2016). Academic Publishing: Issues and Challenges in the Construction of Knowledge - Oxford Applied Linguistics. Oxford University Press.   
Hyland, K., & Jiang, F. (2018). “In this paper we suggest”: changing patterns of disciplinary metadiscourse. English for Specific Purposes, 51, 18-30.   
Hyland, K., & Jiang, F. (2020). “This work is antithetical to the spirit of research”: an anatomy of harsh peer reviews. Journal of English for Academic Purposes, 46. Article 100867.   
Hyland, K., & Zou, H. (2021). “I believe the findings are fascinating”: stance in three-minute theses. Journal of English for Academic Purposes, 50. Article 100973.   
Hynninen, N. (2022). Opening up the peer review process: evaluation and alignment in research paper trajectories. Journal of English for Research Publication Purposes, 3(1), 29-50.   
Jiang, F., & Hyland, K. (2018). Nouns and academic interactions: a neglected feature of metadiscourse. Applied Linguistics, 39(4), 508-531.   
Kotz, D., & Cals, J. (2021). Scientific Writing And Publishing In Medicine And Health Sciences: A Quick Guide In English and German. De Gruyter.   
Kwan, B. S. C. (2013). Facilitating novice researchers in project publishing during the doctoral years and beyond: a Hong Kong-based study. Studies in Higher Education, 38(2), 207-225.   
Larina, T., & Ponton, D. M. (2020). Tact or frankness in English and Russian blind peer reviews. Intercultural Pragmatics, 17(4), 471-496.   
Lei, J., & Hu, G. (2019). Doctoral candidates’ dual role as student and expert scholarly writer: an activity theory perspective. English for Specific Purposes, 54, 62-74.   
Li, Y., & Flowerdew, J. (2020). Teaching English for Research Publication Purposes (ERPP): a review of language teachers’ pedagogical initiatives. English for Specific Purposes, 59, 29-41.   
Liu, L. (2014). Addressing reviewer comments as an integrative negotiation. Management and Organization Review, 10(2), 183-190.   
Lyons, J. (1977). Semantics (vol. 2)Cambridge University Press.   
Martin, J. R., & White, P. R. R. (2005). The Language of Evaluation: Appraisal in English. Palgrave Macmillan.   
Nature. (2022). Nature is trialing transparent peer reviewdthe early results are encouraging. Nature, 603(7899), 8.   
Oermann, M., & Hays, J. (2018). Writing for Publication in Nursing (4th ed.). Springer Publishing.   
Paltridge, B. (2015). Referees’ comments on submissions to peer-reviewed journals: when is a suggestion not a suggestion? Studies in Higher Education, 40(1), 106-122.   
Paltridge, B. (2017). The Discourse of Peer Review: Reviewing Submissions to Academic Journals. Springer.   
Peat, J., Elliott, E., Baur, L., & Keena, V. (2013). Scientific Writing: Easy when You Know How. John Wiley & Sons.   
Ross-Hellauer, T., Deppe, A., & Schmidt, B. (2017). Survey on open peer review: attitudes and experience amongst editors, authors and reviewers. PLoS One, 12(12). Article e0189311.   
Samraj, B. (2016). Discourse structure and variation in manuscript reviews: implications for genre categorization. English for Specific Purposes, 42, 76-88.   
Samraj, B. (2021). Variation in interpersonal relations in manuscript reviews with different recommendations. English for Specific Purposes, 62, 70-83.   
Shaw, P., Kuteeva, M., & Okamura, A. (2014). Submission letters for academic publication: disciplinary differences and promotional language. Journal of English for Academic Purposes, 14, 106-117.   
Shaw, P., & Okamura, A. (1998). The letter of submission: avoiding the promotional genre. IEEE Transactions on Professional Communications, 41(4), 274-276.   
Swales, J. M. (1996). Occluded genres in the academy: the case of the submission letter. In E. Ventola, & A. Mauranen (Eds.), Academic Writing: Intercultural and Textual Issues. John Benjamins, 45–58.   
Tan, Z. (2022). Academic Writing for Engineering Publications: A Guide for Non-native English Speakers. Springer Nature.   
van Rooyen, S., Delamothe, T., & Evans, S. J. W. (2010). Effect on peer review of telling reviewers that their signed reviews might be posted on the web: randomised controlled trial. BMJ British Medical Journal, 341. Article c5729.   
VERBI Software. (2021). MAXQDA 2022 [Computer Software]. Berlin, Germany: VERBI Software. https://www.maxqda.com   
Wen, J., & Lei, L. (2022). Linguistic positivity bias in academic writing: a large-scale diachronic study in life sciences across 50 years. Applied Linguistics, 43(2), 340-364.   
Wolfram, D., Wang, P., & Abuzahra, F. (2021). An exploration of referees’ comments published in open peer review journals: the characteristics of review language and the association between review scrutiny and citations. Research Evaluation, 30(3), 314-322.   
Wolfram, D., Wang, P., Hembree, A., & Park, H. (2020). Open peer review: promoting transparency in open science. Scientometrics, 125(2), 1033-1051.   
Zou, H., & Hyland, K. (2022). How the medium shapes the message: stance in two forms of book reviews. Journal of Pragmatics, 193, 269-280.