# Vocabulary knowledge differences between placed and promoted EAP students

Martyn K. Clark\*, Saori Ishida

Department of Second Language Studies, University of Hawai’i at Manoa, 1890 East-West Road, Moore #570, Honolulu, HI 96822, USA

# Abstract

This study investigated differences in vocabulary knowledge as a potential explanation for perceived differences between placed and promoted students in a university EAP reading course. Students in an advanced reading course $( N { = } 5 9 $ ) were tested on their vocabulary knowledge using the Vocabulary Levels Test Form B [Nation, I. S. P. (2001). Learning vocabulary in another language. Cambridge: Cambridge University Press] at the beginning of the academic semester. Additionally, the promoted students’ $( n = 2 9$ ) vocabulary scores were compared to their own scores from the beginning of the intermediate course one semester earlier. Analysis of the data shows that students placed directly into the advanced reading course upon entry to the university have statistically significantly greater vocabulary knowledge than students promoted into the course after one semester of study in the EAP program. This difference was observed for both general as well as academic vocabulary knowledge. Moreover, promoted students’ vocabulary scores showed no significant increase over their initial scores as intermediate students for either general or academic vocabulary knowledge despite the fact that they had taken one or more university content courses. Potential reasons for these results as well as curricular implications are discussed.

$©$ 2005 Elsevier Ltd. All rights reserved.

Keywords: Vocabulary knowledge; Placement; Curriculum; Academic Reading; English for Academic purposes

This paper represents an empirical investigation into a phenomenon that has been anecdotally recognized by teachers in our reading classes for several years. Namely, students in the advanced reading course seem to be split into two distinct groups—those who were placed directly into the advanced course on the basis of a placement test and those who have been promoted from the intermediate level. Although the promoted students have completed a semester of reading instruction in the English for Academic Purposes (EAP) program in addition to taking one or more regular university classes, their ability to read English efficiently still seems to lag behind that of the placed students.

This situation is certainly not unique to our program. For example, Brown (1980) identified placed and promoted students as two distinctly different student populations within some advanced ESL classrooms when compared on course grades, departmental final exam grades, and a 50-item cloze test, with the placed students outperforming the promoted students on all three measures. Such a gap, Brown concluded, might be a common occurrence in ESL programs that make decisions on students’ placements based on norm-referenced placement tests. As this is the case in our program, and probably in countless other EAP programs given the administrative realities of having to place students quickly and efficiently, we decided to focus specifically on the role vocabulary knowledge might play in explaining this perceived gap in our reading classes with the hope that the results of our investigation would be of interest to other program administrators and instructors. Before presenting the details of our investigation, it is useful to first briefly review some of the literature regarding the role of vocabulary knowledge in second language (L2) reading.

# 1. Vocabulary knowledge and reading

The relationship between vocabulary knowledge and reading comprehension has been an extensive focus of investigation among reading researchers and the amount of attention paid to this area of research has clearly indicated that it is a crucial issue for learners. Researchers have demonstrated that vocabulary knowledge in L2 contributes significantly to reading comprehension in L2 (e.g., Carrell, 1988; Koda, 1989; Laufer, 1992), and of particular interest has been the question of how large a vocabulary is necessary to achieve adequate comprehension of L2 materials.

Over the past several decades, researchers have attempted to answer this question empirically. For example, based on findings from her empirical study examining the relationship between reading comprehension of academic-oriented texts and a lexical coverage measure, Laufer (1989) found that learners would be likely to read a text written in L2 with good comprehension if they knew $9 5 \%$ of the words appearing in the text. In another experiment, Hsueh-chao and Nation (2000) examined the effects of unknown vocabulary on reading comprehension using four versions of a text that varied with regard to lexical coverage rate—100, 95, 90 and $80 \%$ . Based on an analysis of learners’ comprehension scores, Hsueh-chao and Nation noted that all the learners in the $80 \%$ lexical coverage condition demonstrated uniformly low comprehension scores. They further indicated that some learners were able to adequately comprehend a fiction text at $9 5 \%$ lexical coverage. However, in order for L2 learners to read for pleasure with ease, it was suggested that learners need to know $98 \%$ of the words in the materials, a claim also made by Hirsh and Nation (1992). These numbers suggest that a fairly extensive vocabulary is needed to read efficiently in an L2. This is potentially important for EAP students. Since university students are typically expected to read materials assigned to them, it is the students who must adjust to the level of the text rather than the other way around.

Of course, students do bring more than just their vocabulary knowledge to their reading. For learners literate in their L1, one concept that has been widely accepted is the notion that there is a language threshold beyond which learners can draw on their L1 reading strategies to deal with L2 texts. Based on a review of previous research, Laufer (1997) concludes that this comprehension threshold “is, to a large extent, lexical” (p. 21), and suggests that the threshold vocabulary level that learners need to transfer their L1 reading strategies to their L2 reading is about 3000 word families, which is equivalent to 4800 individual lexical items (for the conversion formula from word families to lexical items, see P. Nation, 1983a). Until learners reach this level of about 5000 words, Laufer claims, they cannot successfully transfer their L1 reading strategies to their L2 reading contexts because their insufficient knowledge of vocabulary prevents them from comprehending enough of the material to make sense of the text in an efficient manner.

Laufer supports this claim by reference to her study (1992) in which 64 EFL learners were compared in terms of their L2 vocabulary knowledge level, reading comprehension in L2, and their general academic ability including the reading ability in their L1. The findings of this study seem to provide us with practical insight into the level of vocabulary knowledge needed in L2 reading. First of all, irrespective of their general academic ability, learners with a vocabulary size of fewer than 5000 lexical items could not read well in L2. Second, as for learners whose vocabulary size was between 5000 and 6500 lexical items, some learners were able to read well, and others were not. This appeared to indicate that, within this 5000–6500 lexical item range, some learners were able to make use of their general academic ability which included their reading ability in L1. Third, learners with a vocabulary size of more than 8000 lexical items were able to read well, regardless of their general academic ability. Given these findings, it seems reasonable to suppose that learners cannot read sufficiently in L2 if their vocabulary size is below the 5000 lexical item level due to an inability to make use of their reading strategies in L1 as well as their existing background knowledge.

However, it is not enough to know any random 5000 words, and it is here that word frequency comes into play. Although the division between high frequency words and low frequency words is arbitrary, the 2000-word level is often considered as a suitable point to make this arbitrary distinction (Laufer & Nation, 1999; Nation & Newton, 1997). In their experiments focusing on teaching of the 2000-level words, Coady, Magoto, Hubbard, Graney, and Mokhatari (1993) found that increased proficiency in high frequency vocabulary led to an increase in learners’ reading proficiency. Nation and Newton (1997) suggest that EAP learners should learn high frequency words first, and then focus on academic vocabulary. Academic vocabulary refers to lexical items that often appear in academic texts, and it differs from both high frequency vocabulary and technical vocabulary in that it is common across various academic fields. (Technical vocabulary is vocabulary only associated with a given academic field—see Chung & Nation, 2003, for a detailed description.) Moreover, academic vocabulary is “like a specialized extension of the high frequency words” (Chung & Nation, 2003). Since EAP learners are those with academic goals, it is natural that they need to be able to read academic texts well in their fields of study in order to achieve their goals. Without sufficient knowledge of academic vocabulary, they cannot deal with reading materials efficiently for various types of academic tasks given to them, putting them at a disadvantage compared to their nativespeaking counterparts. In addition to learning high frequency words and academic words, it is also important for learners to develop coping strategies to deal with low frequency words, which can hinder the comprehension of texts (Laufer & Nation, 1999). Together, these findings suggest that learners need to have a good knowledge of high frequency words coupled with enough additional vocabulary to adequately cover a high percentage of the words they encounter in order to read with any efficiency.

Evidence of the learners’ recognition of the importance of vocabulary in reading has been found in our own EAP program. In an in-house needs analysis of the reading curriculum, Ono (2002) found that students identified understanding technical vocabulary as the most problematic reading skill while understanding general vocabulary ranked significantly higher than most other reading skills (including those traditionally labeled as comprehension skills such as identifying main ideas, recognizing the author’s purposes, distinguishing fact from opinion, etc.). In addition, when students were asked specifically for suggestions on how to improve the curriculum of the intermediate level class, one of the most frequent responses was to increase the use of activities that help them learn and memorize vocabulary. This suggests that students themselves are aware of deficiencies in their vocabulary knowledge as a hindrance to comprehension.

Given this background, we are now ready to turn to the question of to what extent differences in vocabulary knowledge might be salient in explaining the perceived differences between placed and promoted students in reading courses in our program.

# 2. Context of the study

The English Language Institute (ELI) at the University of Hawai’i at Manoa is dedicated to providing EAP instruction for matriculated students for whom English is not a native language. The ELI offers courses at the intermediate and advanced level1 in reading, listening/speaking, and writing, all designed to facilitate students’ handling of English-medium instruction at the university level. Students able to demonstrate evidence of sufficient language proficiency, such as standardized test scores or extended study in English-medium contexts, are exempted from taking ELI classes and are free to register for a full load of credit-bearing content courses. Students who have not yet demonstrated evidence of sufficient language proficiency are required to take the English Language Institute Placement Test (ELIPT) upon arrival at the university to determine in which areas, if any, additional language instruction might be beneficial. The ELIPT consists of reading, listening, and writing subsections and students are either placed into ELI classes or exempted from additional instruction based on the results of that test and additional review of their records. Because not all students need language support in all areas, some students will be placed into as few as one ELI course while others will need a total of six (both the intermediate and advanced courses in each of the three skill areas). As students take no more than one ELI course per skill area in a given semester, regular university courses are taken concurrently with ELI courses. Therefore, students in the ELI are taking at least one and as many as five regular university courses while completing their ELI requirements.

![](img/e4eb32d7e3d880a18ce1bbcf53638859fa2774a05bb02434aedd9320721b947b.jpg)  
Fig. 1. Overview of ELI placement process.

Fig. 1 shows an overview of the ELI placement process. Students not scoring very well on the reading portion of the placement test would be required to take ELI 72 (intermediate reading) in their first semester and ELI 82 (advanced reading) in their second semester. Students performing better on the placement test would only be required to complete one semester in ELI 82. Although students are occasionally required to repeat ELI 72 if they have not made sufficient progress during the semester, the political reality of the situation (ELI courses are non-credit and seen as remedial instruction by many in the university community) is such that most ELI 72 students will be promoted to ELI 82 after one semester as long as they meet the attendance and performance requirements of the course; but they are not required to pass an exit test. The concern of the present study is to examine the difference between those students promoted into ELI 82 after one semester of study at the university (Promoted) and those students placed directly into ELI 82 as a result of the placement test (Placed). We were interested in two related questions:

1. Are there differences in vocabulary knowledge between placed and promoted students in the ELI 82?

2. Do students initially placed in ELI 72 increase their vocabulary knowledge after completing one semester of study at the university?

In order to answer these questions without disrupting the instructional schedule of ELI classes, it was necessary to carry out the data collection as part of the diagnostic activities scheduled during the first week of classes.

# 3. Method

# 3.1. Data

The data for this study consisted of vocabulary test scores for students $( N { = } 5 9 )$ ) enrolled in ELI 82 classes in Spring 2003 as well as vocabulary scores for a subset of those students $( n = 2 9 ,$ ) from the same vocabulary test given in Fall 2002 in ELI 72. Since the vocabulary test was given as a scheduled diagnostic activity during regularly scheduled class time, individual biographical information for the participants was not collected. The general population of the ELI in Spring 2003 included students from some 20 countries, predominantly in Asia and the Pacific, with the majority from Japan $(46 \% )$ , Korea $( 1 7 \% )$ , People’s Republic of China $( 1 0 \% )$ , and Taiwan $( 8 \% )$ . The vast majority of students in the ELI have had at least 6 years of formal English instruction, though their experience in English-speaking environments ranges from minimal exposure to several years. By definition, students in the ELI have not met exemption criteria and have a TOEFL score of between 500 and 600 (173 and 250 CBT). Informed consent was obtained from the students for the use of these scores for research purposes.

# 3.2. Materials

The Vocabulary Levels Test. To measure vocabulary knowledge, the Vocabulary Levels Test Form B (I.S.P. Nation, 2001) was used. Originally developed by Paul Nation (I.S.P. Nation, 1990, 2001; P. Nation, 1983b), this test has proven a useful measure of vocabulary size and has produced several forms and revisions (e.g., Belgar & Hunt, 1999; Kudo, 1999; Schmitt, 2001; Schmitt, Schmitt, & Clapham, 2001). The Vocabulary Levels Test comprises 156 words divided into five levels (Table 1) and is designed to test the learner’s knowledge of high frequency words, low frequency words, and specialized (academic) vocabulary (P. Nation, 1983b).

Table 1 Format of Vocabulary Levels Test   

<html><body><table><tr><td>Test section</td><td>Words sampled</td><td>Words tested</td></tr><tr><td>2000 level</td><td>2000 most frequent words</td><td>30</td></tr><tr><td>3000 level</td><td>3000 most frequent words.</td><td>30</td></tr><tr><td> 5000 level</td><td>5000 most frequent words</td><td>30</td></tr><tr><td>Academic</td><td>Academic words</td><td>36</td></tr><tr><td>10,000 level</td><td>10,000 most frequent words</td><td>30</td></tr></table></body></html>

1. analogous   
2. objective happening after   
3. potential most important   
4. predominant not influenced by personal opinions   
5. reluctant   
6. subsequent

Words are presented as matching items in groups of three along with three distractors to prevent guessing, as in the example from the academic vocabulary section above (Fig. 2).

When used for diagnostic feedback, the general procedure for scoring the Vocabulary Levels Test is to give the student one point for each correctly matched word and record the score of each section separately as an indication of the students’ knowledge of that particular frequency level (P. Nation, 1983b) and this was how the ELI instructors used the test. For the purposes of this current research, however, we were more interested in comparing students’ total scores on a test of general vocabulary that covered a range of frequency levels. For this reason, we chose to aggregate the various frequency section scores under the label of General Words and the academic section into an Academic Words score.

Administration. In both Fall 2002 and Spring 2003, students in intact ELI reading classes were given the Vocabulary Levels Test as part of a previously scheduled diagnostic activity conducted by their regular teachers. Teachers were instructed to allow approximately $3 0 \mathrm { { m i n } }$ for the test, a time limit which they considered reasonable. P. Nation (1983b) reports a native speaker finishing the test in $5 \mathrm { { m i n } }$ and Schmitt et al. (2001) report an average of $3 1 \mathrm { { m i n } }$ from a range of $1 5 { \mathrm { - } } 6 0 ~ { \mathrm { m i n } }$ for students who were timed (p. 72). Students were told not to spend too much time on any single word and that it was permissible to skips words that they did not know. The tests were collected by the teachers at the end of the allotted time and scored later by the authors. The results were then passed on to the teachers for diagnostic purposes. No problems were reported during the administration of any of the tests for either of the semesters.

Reliability of the Vocabulary Levels Test. Although previous research led us to believe that the Vocabulary Levels Test would produce acceptable measures for our purposes, we confirmed this empirically for our data. Coefficient alpha was calculated as a measure of score reliability for each semester’s administration. These values are shown in Table 2 along with confidence interval estimates obtained following the procedure outlined in

Table 2 Reliability estimates and confidence intervals of Vocabulary Levels Test   

<html><body><table><tr><td>Semester</td><td>n</td><td>Reliability estimate</td><td>99% Confidence interval (lower)</td><td>99% Confidence interval (upper)</td></tr><tr><td>Spring 2003</td><td>59</td><td>0.92</td><td>0.88</td><td>0.95</td></tr><tr><td>Fall 2002</td><td>29</td><td>0.92</td><td>0.85</td><td>0.96</td></tr></table></body></html>

Fan and Thompson (2003). From these results, it is safe to assert that the scores obtained exhibit sufficient reliability to justify their use.

# 3.3. Procedure

To test the hypothesis of whether vocabulary differences exist between placed and promoted students, test results for ELI 82 were sorted into two groups—results from students placed directly into the course (Placed) and those from students who were taking the course after spending one semester in ELI 72 (Promoted). Although it would have been possible to do a multivariate test using each of the sections of the test as a dependent variable, we felt that this was not appropriate as each section represents a somewhat arbitrary point along the same frequency continuum. It is difficult to conceive that there would be a qualitative difference between the 2999th most frequent word, for example, and the 3000th. The exception to this is the Academic section which is based on a different sample of materials, namely academic texts, and is not exclusively frequency driven (Coxhead, 2000). For these reasons, we limited our comparison to two univariate tests. The two groups were compared on their General Words scores as well as on their scores on the Academic Words portion of the test, as the vocabulary knowledge tested by this section could be seen as potentially the most relevant in the university context. To investigate the question of whether the promoted students’ vocabulary had improved since entering the university, the score of placed students in ELI 82 were compared to the scores they had received on the test when they were ELI 72 students. Because of the multiple comparisons involved in the data analysis, an alpha level of $\alpha { = } 0 . 0 1$ was adopted for the entire study.

# 4. Results

# 4.1. Placed vs. promoted students

The descriptive statistics for the Vocabulary Levels Test are shown in Table 3 for placed and promoted students enrolled in ELI 82. Though the current investigation focuses on the aggregate General Words score and the score on the Academic Words section of the test, Table 3 presents the scores separately for the other sections of the test as well since many readers are familiar with viewing the test scores in this fashion.

To investigate differences between the overall vocabulary knowledge for placed and promoted students, a $t \cdot$ -test was conducted on the General Words score for each group.

Table 3 Descriptive statistics for Vocabulary Levels Test (section by status)   

<html><body><table><tr><td></td><td colspan="2">Mean</td><td colspan="2">SD</td><td colspan="2">Min</td><td colspan="2">Max</td></tr><tr><td>Section</td><td>PL</td><td>PR</td><td>PL</td><td>PR</td><td>PL</td><td>PR</td><td>PL</td><td>PR</td></tr><tr><td>2000</td><td>28.97</td><td>27.86</td><td>1.16</td><td>1.71</td><td>26</td><td>24</td><td>30</td><td>30</td></tr><tr><td>3000</td><td>26.83</td><td>24.34</td><td>2.41</td><td>2.44</td><td>22</td><td>20</td><td>30</td><td>29</td></tr><tr><td>5000</td><td>22.17</td><td>18.00</td><td>4.36</td><td>4.92</td><td>10</td><td>6</td><td>29</td><td>25</td></tr><tr><td>10,000</td><td>7.90</td><td>4.86</td><td>4.88</td><td>4.01</td><td>0</td><td>0</td><td>22</td><td>15</td></tr><tr><td>General</td><td>85.87</td><td>75.07</td><td>9.77</td><td>9.44</td><td>66</td><td>55</td><td>111</td><td>98</td></tr><tr><td>Academic</td><td>30.40</td><td>26.17</td><td>3.01</td><td>6.62</td><td>25</td><td>0</td><td>36</td><td>33</td></tr></table></body></html>

PL, placed $( n = 3 0 )$ ); PR, promoted $( n = 2 9 ,$ ).

Table 4 t-test of difference between placed and promoted students’ General Words score   

<html><body><table><tr><td rowspan="2">T</td><td rowspan="2">df</td><td rowspan="2">Sig. (two-tailed)</td><td rowspan="2">Mean difference</td><td colspan="2">99% Confidence interval of difference</td><td rowspan="2">d</td></tr><tr><td>Lower</td><td>Upper</td></tr><tr><td>4.316</td><td>57</td><td>0.000</td><td>10.7977</td><td>4.13</td><td>17.47</td><td>1.14</td></tr></table></body></html>

The results indicate that there is a significant difference between the scores of placed and promoted students on the General Words section of the test (Table 4). Cohen’s $d$ was calculated as a measure of effect size and can be interpreted as standard deviation units using the pooled standard deviation (Cohen, 1988). Looked at in this fashion, the placed students’ scores were slightly more than one standard deviation higher than those of the promoted students. The strength of this effect can also be seen by examining the lower and upper confidence intervals estimates for the mean difference. For this particular group of ELI 82 students, the mean of the placed students was approximately 11 points higher than that of the promoted students.

A second $t { \cdot }$ -test was conducted on the scores of the placed and promoted students for the Academic Words section only, as this difference is potentially more important for the ELI than the students’ general word knowledge (Table 5). The reliability for the Academic Words section scores only was estimated at $\alpha { = } 0 . 8 6$ . Again, the results indicate a significant difference and a rather large effect between the two groups. Not only do placed and promoted students differ in terms of their overall vocabulary knowledge, they also differ in their knowledge of academic vocabulary. This is especially noteworthy as students promoted into ELI 82 have spent at least one semester in the university and have taken one or more credit-bearing university courses.

Table 5 t-test of difference between placed and promoted students’ Academic Words section scores   

<html><body><table><tr><td></td><td>df</td><td>Sig.</td><td>Mean</td><td colspan="2">99% Confidence interval of difference</td><td>d</td></tr><tr><td></td><td></td><td>(two-tailed)</td><td>difference</td><td>Lower</td><td>Upper</td><td></td></tr><tr><td>3.138</td><td>57</td><td>.003</td><td>4.23</td><td>0.58</td><td>7.88</td><td>0.84</td></tr></table></body></html>

Table 6 Descriptive statistics for students re-taking Vocabulary Levels Test   

<html><body><table><tr><td></td><td colspan="2">Mean</td><td colspan="2">SD</td><td colspan="2">Min</td><td colspan="2">Max</td></tr><tr><td>Section</td><td>T 1</td><td>T 2</td><td>T 1</td><td>T 2</td><td>T 1</td><td>T 2</td><td>T 1</td><td>T 2</td></tr><tr><td>2000</td><td>26.86</td><td>27.86</td><td>2.46</td><td>1.71</td><td>19</td><td>24</td><td>30</td><td>30</td></tr><tr><td>3000</td><td>24.14</td><td>24.34</td><td>3.41</td><td>2.44</td><td>18</td><td>20</td><td>29</td><td>29</td></tr><tr><td>5000</td><td>17.48</td><td>18.00</td><td>4.66</td><td>4.92</td><td>8</td><td>6</td><td>24</td><td>25</td></tr><tr><td>10,000</td><td>5.31</td><td>4.86</td><td>5.84</td><td>4.01</td><td>0</td><td>0</td><td>19</td><td>15</td></tr><tr><td>General</td><td>73.79</td><td>75.07</td><td>11.84</td><td>9.44</td><td>52</td><td>55</td><td>97</td><td>98</td></tr><tr><td>Academic</td><td>24.48</td><td>26.17</td><td>5.67</td><td>6.62</td><td>7</td><td>0</td><td>32</td><td>33</td></tr></table></body></html>

T 1, score as ELI 72 student; T 2, score as ELI 82 student; $N { = } 2 9$

Table 7 Repeated measures $t$ -test on General Words scores (re-test)   

<html><body><table><tr><td></td><td>df</td><td>Sig.</td><td>Mean</td><td>SD</td><td colspan="2">99% Confidence interval of difference</td><td>d</td></tr><tr><td></td><td></td><td>(two-tailed)</td><td>difference</td><td></td><td>Lower</td><td>Upper</td><td></td></tr><tr><td>0.639</td><td>28</td><td>0.528</td><td> 1.276</td><td>10.75</td><td>6.79</td><td>4.24</td><td>0.119</td></tr></table></body></html>

# 4.2. Retests after one semester of study

The question of whether students’ vocabulary knowledge improves after one semester of study in the university was investigated by comparing students’ vocabulary scores from Fall 2002 as ELI 72 students with the same students’ scores in Spring 2003 as ELI 82 students. Though a total of 39 students were promoted into ELI 82 in Spring 2003, only 29 records were matched with Fall 2002 scores due to faulty record-keeping and student absence for the first test. Table 6 shows the descriptive statistics for these scores. A repeated-measures $t { \cdot }$ -test was conducted on the General Words scores and results indicate that there was no significant difference between the scores after one semester of study at the university (Table 7). Another repeated-measures $t$ -test was also conducted on the Academic Words scores. Again, the results showed no significant difference between the two sets of scores (Table 8), though the effect size was slightly larger than for the General Words.

Table 8 Repeated measures $t$ -test on Academic Words scores (re-test)   

<html><body><table><tr><td></td><td>df</td><td>Sig.</td><td>Mean</td><td>SD</td><td colspan="2">99% Confidence interval of difference</td><td>d</td></tr><tr><td></td><td></td><td>(two-tailed)</td><td> difference</td><td></td><td>Lower</td><td>Upper</td><td></td></tr><tr><td>1.14</td><td>28</td><td>0.263</td><td> 1.69</td><td>7.97</td><td>5.78</td><td>2.40</td><td>0.212</td></tr></table></body></html>

# 5. Discussion

The results clearly indicate that a substantial difference exists between placed and promoted students in ELI 82 on both general and academic vocabulary knowledge as measured by the Vocabulary Levels Test. This result is consistent with the instructors’ perceptions that there are essentially two different populations in the advanced reading class. It would be easy to downplay the importance of this finding as merely a confirmation of the obvious. Given that students enter the ELI with a range of abilities and are initially assigned to classes on the basis of those abilities, it is unsurprising that a gap initially existed between intermediate and advanced students and all we have done is provide evidence that one semester of study is not sufficient to make up this pre-existing gap. In fact, this was the conclusion reached by Brown (1980) a quarter of a century ago in his comparison of placed and promoted students. That there should be a gap is perhaps obvious; what we have empirically determined is the size of that gap as it relates to vocabulary knowledge.

With respect to the question of whether ELI 72 students increase their vocabulary knowledge after one semester of study, the results indicate that this is not the case. We were a little disappointed by the apparent lack of progress made by ELI 72 students after spending one semester in the university. Keep in mind that students are taking creditbearing content courses at the same time they are receiving instruction in the ELI. This would seem to indicate that merely being exposed to academic texts in their content classes is not sufficient for the development of vocabulary knowledge. It is possible that the ELI 72 students’ relative lack of vocabulary (especially for those students with the lowest scores) prevented them from reaching the necessary threshold of understanding needed to deal with the academic texts they encountered and thus they were unable, or less able, to use contextual cues to pick up vocabulary through reading alone. It is also conceivable that when students became frustrated with assigned readings, they were able to rely on other sources of information, such as classmates who share the same L1, and as a result did not interact with academic texts as much as would be expected. It might also be possible that, given the types of tasks the students had to do in their classes, it was not necessary to learn the new words they encountered, but merely to understand them temporarily.

Obviously, we are not claiming that the students failed to learn any vocabulary during their semester of study at the university. The students no doubt learned discipline-specific vocabulary in most if not all of their classes. Nevertheless, these results do seem to indicate that vocabulary acquisition will not necessarily take care of itself, and explicit attention needs to be paid to vocabulary knowledge as a part of instruction.

Lest readers have formed the wrong impression, it should be pointed out that we do not believe that there is an instructional crisis in the ELI. Although the results of this study support the idea that the perceived differences in reading ability that prompted this research could be, to a large extent, due to differences in vocabulary knowledge, it does not provide us with a full picture of how students actually deal with words when interacting with academic material. As is the case with many other EAP programs, a large portion of our limited class time (some $4 0 \mathrm { h }$ over the course of 16 weeks) is geared towards helping students cope with the academic tasks they are dealing with in their content classes.

And, in fact, the average GPA for students who have completed ELI requirements is no different from the university average (ELI Assistant Director, personal communication, June 18, 2004).

The fact remains, however, that there appears to be a gap between placed and promoted students in vocabulary knowledge and the fact that students at the intermediate level do not seem to increase their vocabulary knowledge significantly over the course of one semester indicates that merely increasing the number of instructional hours at the intermediate level would probably not be an efficient solution. The question, then, becomes one of to what extent can an EAP reading course improve the students’ vocabulary knowledge, which has been shown in the literature to be critical for reading with ease, while at the same time helping students manage the immediate needs of their content classes. Because the university expects students to complete their studies in a reasonable amount of time, it is not feasible to keep them in the ELI for more than two semesters. This means that any changes will have to be instructional rather than institutional.

Based on the results of our study, we have proposed changes in the reading curriculum to encourage instructors to take a more aggressive approach to vocabulary instruction. Frequent vocabulary and basic academic vocabulary should be highlighted in ELI 72 while students in ELI 82 should deal extensively with vocabulary which is specific to their fields of study. A similar pedagogical approach to vocabulary instruction can be found in the Complementary Pyramid Syllabus Design (CPSD) proposed by Spector-Cohen, Kirschner, and Wexler (2001) in which different reading proficiency levels warrant emphasis on different types of vocabulary knowledge and proficiency-appropriate pedagogical choices.

What is needed next is a case-study approach examining academically successful students with different vocabulary levels to see how this type of knowledge difference affects them in their daily studies both inside and outside of our EAP program. If it turns out that the lack of vocabulary knowledge is a major impediment to academic success, our proposed long range solution would be to treat the two ELI reading courses as totally separate entities. Advanced students would take a one-semester course of reading instruction to fulfill ELI requirements and intermediate students would take a twosemester course. In this way, it would be easier to incorporate an extended, systematic approach to vocabulary instruction within the framework of our current instructional modules to better serve those students entering the program with a lower level of vocabulary knowledge.

Another direction for future research would be to investigate possible learning differences between intermediate and advanced students. It may be the case that aptitude and other factors are playing a role for many students—that is, the majority of students who place into ELI 72 are not just $\cdot 7 2 \mathrm { s } ^ { \prime }$ in terms of current academic proficiency, but perhaps also in terms of their aptitude toward developing in any L2, or aptitude for learning vocabulary. One possible future study would be to measure the vocabulary gain of advanced students over the course of a semester to see if those students with greater initial vocabulary knowledge are able to build their vocabulary knowledge in ways that the intermediate students in our study did not.

Although this study was essentially a piece of action research occasioned by our desire to investigate a phenomenon in our reading classes, it does raise a more general issue.

The legacy of the communicative language movement has placed a premium on contextualized language practice and the exigencies of helping students transition to full academic course loads necessitate an approach centered on training for common academic tasks. And, judging purely from content course GPA, such an approach is surely beneficial. Nevertheless, a very real gap in student vocabulary knowledge exists which is seemingly not remedied by merely dealing with contextualized academic tasks either in the EAP classroom or the university classroom. The question therefore remains of how important vocabulary knowledge is to overall academic success (not just reading comprehension) and how lexical knowledge can be efficiently increased while at the same time helping students focus on specific target tasks and encouraging instructors to present contextualized language. Given that mere exposure to vocabulary in contexts of academic study does not seem to result in improvement in vocabulary knowledge, explicit focus on vocabulary development strategies may be essential if, indeed, vocabulary development is considered an important or essential part of the EAP curriculum. Perhaps further investigations will be able to shed light on this question.

# References

Belgar, D., & Hunt, A. (1999). Revising and validating the 2000 Word Level and University Word Level Vocabulary Tests. Language Testing, 16(2), 131–162.   
Brown, J.D. (1980). Newly placed students versus continuing students: Comparing proficiency. In J.C. Fisher, M.A. Clarke, & J. Schacter (Eds.), On TESOL ’80 building bridges: Research and practice in teaching English as a second language (pp. 111–119). Washington, DC: TESOL.   
Carrell, P. (1988). Some causes of text-boundedness and schema interference in ESL reading. In P. Carrell, J. Devine, & D. Eskey (Eds.), Interactive approaches to second language reading (pp. 101–113). Cambridge, MA: Cambridge University Press.   
Chung, T., & Nation, P. (2003). Technical vocabulary in specialized texts. Reading in a Foreign Language, 15(2) (Retrieved April 1, 2004, from http://nflrc.hawaii.edu/rfl/October2003/chung/chung.html).   
Coady, J., Magoto, J., Hubbard, P., Graney, J., & Mokhtari, K. (1993). High frequency vocabulary and reading proficiency in ESL readers. In T. Huckin, M. Haynes, & J. Coady (Eds.), Second language reading and vocabulary acquisition (pp. 217–228). Norwood, NJ: Ablex.   
Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed). Hillsdale, NJ: Lawrence Erlbaum Associates.   
Coxhead, A. (2000). A new academic word list. TESOL Quarterly, 34(2), 213–238.   
Fan, X., & Thompson, B. (2003). Confidence intervals about score reliability coefficients. In B. Thompson (Ed.), Score reliability: Contemporary thinking on reliability issues (pp. 69–87). Thousand Oaks, CA: Sage.   
Hirsh, D., & Nation, P. (1992). What vocabulary size is needed to read unsimplified texts for pleasure? Reading in a Foreign Language, 8(2), 689–696.   
Hsueh-chao, M., & Nation, P. (2000). Vocabulary density and reading comprehension. Reading in a Foreign Language, 13(1), 403–430.   
Koda, K. (1989). The effects of transferred vocabulary knowledge on the development of L2 reading proficiency. Foreign Language Annals, 22(6), 529–540.   
Kudo, Y. (1999). Vocabulary learning strategies and vocabulary size of Japanese high school students. Unpublished MA Thesis, University of Hawai’i at Manoa, Hawai’i.   
Laufer, B. (1989). What percentage of text-lexis is essential for comprehension?. In C. Lauren, & M. Nordman (Eds.), Special language: From humans to thinking machines (pp. 316–323). Clevedon: Multilingual Matters.   
Laufer, B. (1992). Reading in a foreign language: How does L2 lexical knowledge interact with the reader’s general academic ability? Journal of Research in Reading, 15(2), 95–103.   
Laufer, B. (1997). The lexical plight in second language reading: Words you don’t know, words you think you know, and words you can’t guess. In J. Coady, & T. Huckin (Eds.), Second language vocabulary acquisition (pp. 20–34). Cambridge: Cambridge University Press.   
Laufer, B., & Nation, P. (1999). A vocabulary-size test of controlled productive ability. Language Testing, 16(1), 33–51.   
Nation, I. S. P. (1990). Teaching and learning vocabulary. Boston: Heinle & Heinle.   
Nation, I. S. P. (2001). Learning vocabulary in another language. Cambridge: Cambridge University Press.   
Nation, P. (1983a). Learning and teaching vocabulary. Wellington, NZ: Victoria University.   
Nation, P. (1983b). Testing and teaching vocabulary. Guidelines, 5(1), 12–25.   
Nation, P., & Newton, J. (1997). Teaching vocabulary. In J. Coady, & T. Huckin (Eds.), Second language vocabulary acquisition (pp. 238–254). Cambridge: Cambridge University Press.   
Ono, L. (2002). A needs analysis of the English Language Institute reading program at the University of Hawaii at Manoa. Unpublished manuscript, Honolulu, HI.   
Schmitt, N. (2001). Vocabulary in language teaching. Cambridge: Cambridge University Press.   
Schmitt, N., Schmitt, D., & Clapham, C. (2001). Developing and exploring the behavior of two new versions of the Vocabulary Levels Test. Language Testing, 18(1), 59–88.   
Spector-Cohen, E., Kirschner, M., & Wexler, C. (2001). Designing EAP reading course at the university level. English for Specific Purposes, 20, 367–386.