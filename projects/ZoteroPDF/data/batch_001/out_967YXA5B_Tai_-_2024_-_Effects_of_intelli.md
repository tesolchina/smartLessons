# Effects of intelligent personal assistants on EFL learners’ oral proficiency outside the classroom

Tzu-Yu Tai

To cite this article: Tzu-Yu Tai (2024) Effects of intelligent personal assistants on EFL learners’ oral proficiency outside the classroom, Computer Assisted Language Learning, 37:5-6, 1281-1310, DOI: 10.1080/09588221.2022.2075013

To link to this article: https://doi.org/10.1080/09588221.2022.2075013

# Effects of intelligent personal assistants on EFL learners’ oral proficiency outside the classroom

Tzu-Yu Tai

Center for English Education, National Tsing Hua University, Hsinchu, Taiwan RO C

# ABSTRACT

Intelligent personal assistants (IPAs) are a valuable tool in language learning because they provide opportunities for authentic interaction. However, their effectiveness, compared with that of human interlocutors, in facilitating second and foreign language interaction has not been explored. Therefore, this study investigated the effect of IPAs (i.e. Google Assistant on smartphones) on English as a foreign language (EFL) learners’ oral proficiency outside the classroom and the differences between IPA-human interaction and human-only interaction. A total of 89 college freshmen participated in an out-of-class program consisting of 10-minute sessions twice a week for one semester. The participants were randomly divided into three groups: (1) those who interacted with Google Assistant on smartphones; (2) those who interacted with L1 English speakers; and (3) those who interacted with L2 English speakers. Both quantitative (English oral proficiency tests) and qualitative data (focus group interviews) were collected and analyzed. The results revealed that the out-of-class use of Google Assistant significantly improved the EFL learners’ oral proficiency, with a positive effect similar to that of interaction with L1 English speakers. A detailed analysis of the interviews revealed that the mobility and ubiquity of Google Assistant exposed learners to a large amount of high-quality oral input, provided opportunities to practice speaking with immediate, multimodal feedback, engaged learners through various modes of interaction, eliminated learners’ fear of making mistakes, reduced learners’ anxiety in speaking English, and encouraged self-directed learning outside the classroom, which are all conducive to improving EFL learners’ oral proficiency.

# KEYWORDS

Intelligent personal assistant (IPA); Google Assistant; English as a foreign language (EFL); oral proficiency; mobile devices

# 1.  Introduction

Interaction plays a crucial role in the language acquisition process (Long, 1996, 2017). However, interacting in a target language is the most difficult and anxiety-provoking language skill for second and foreign language (L2) learners due to rare input and output practice in authentic contexts, limited class time (Hanzawa, 2021; Richards, 2015), and personal factors such as anxiety, worries about making errors, and low confidence (Bashori, Hout, Strik, & Cucchiarini, 2020; Ebadi & Ebadijalal, 2020). Therefore, improving the oral proficiency of learners of English as a foreign language (EFL) is a constant challenge for instructors (Fernández-Garcia & Fonseca-Mora, 2019; Zarrinabadi, Lou, & Darvishnezhad, 2021).

With the emergence of artificial intelligence and automatic speech recognition (ASR), some researchers (e.g. Dizon, 2020; Moussalli & Cardoso, 2020; Tai & Chen, 2020) have suggested that intelligent personal assistants (IPAs; e.g. Apple’s Siri, Amazon’s Alexa, or Google Assistant) offer potential advantages in L2 interactions. IPAs are voice-controlled services connected to smart speakers (e.g. Apple’s HomePad, Amazon Echo, and Google Home) or smartphones. With their built-in ASR system and natural language processing capabilities, IPAs can understand speech, respond to spoken input, process users’ requests, and communicate with users in a human-like manner. IPAs can serve as a conversational partner for language learners (Sandeep, 2019), provide opportunities for learners to gain exposure to input and practice with output in a stress-free environment (Bashori et  al., 2020; Dizon, 2020), allow for more focused and personalized instruction and individualized feedback (Moussalli & Cardoso, 2020), and encourage autonomous learning (Istrate, 2019). With these benefits, IPAs may help learners overcome many limitations and obstacles encountered in conventional L2 classroom.

Despite showing such promising potential, as Dizon (2020) noted, the use of IPAs in language education, particularly the use of IPAs smartphones, has not been extensively researched (Silva et  al., 2020). The few studies on this topic have been exploratory, limited in scope and sample sizes, and have provided subjective perspectives on the potential of IPAs rather than results demonstrating linguistic improvement among users. In addition, research on IPA-assisted language learning has focused on the in-class instructional context; knowledge of the specific outcomes of out-of-class IPA use remains limited. Moreover, how effectively the use of IPAs for L2 interactions promotes L2 user learning outcomes compared with interactions involving either L1 and L2 speakers (or both) is a crucial but unexplored research area (Van den Berghe, Verhagen, & Oudgenoeg-Paz, 2019). For these reasons, rigorous experimental research with carefully designed evaluative instruments is required to assess the efficacy of IPA-assisted language learning (Bibauw, François, & Desmet, 2019).

This study therefore investigated the impact of IPAs (i.e. Google Assistant on smartphones) on EFL learners’ oral proficiency outside the classroom. The differences between IPA-human interactions and human-only interactions in particular were explored. The investigation of the out-of-class application of IPAs on smartphones and the analysis of their pedagogical usefulness may yield information useful for developing concrete methods to implement EFL communication activities involving IPAs and help practitioners make informed decisions regarding the utilization of IPAs outside the classroom.

# 2.  Literature review

# 2.1.  IPAs for L2 education

The rapid development of technology has generated attractive and convenient venues and platforms for language learning. IPAs, the voice controlled services on smartphones or smart speakers, offer potential advantages to L2 learning (Bashori et  al., 2020; Dizon, 2020; Moussalli & Cardoso, 2020). According to Goksel-Canbek and Mutlu (2016), IPAs use a combination of three technologies: (1) a conversational interface, which relies on ASR tools to interpret meaning; (2) personal context awareness, which enables IPAs to understand users’ language patterns; and (3) service delegation, which allows IPAs to integrate with other programs. IPAs can access information from a variety of online sources to respond to users’ commands or questions.

According to Carhill-Poza and Chen (2020), IPA-assisted language learning has foundations in the interactionist approach (Long, 1996, 2017), which emphasizes the crucial role of interaction in L2 learning. Real-time interactivity is a highly valued feature of IPAs (Moussalli & Cardoso, 2020; Sandeep, 2019). Interactive IPA platforms enable social interaction by providing learners with opportunities for real and meaningful communication. According to interactionist theory, learners receive input and feedback, gain opportunities for output, and negotiate meaning through dialogue, which is essential for L2 development.

Immediate feedback is another key feature of IPAs. IPAs allow for self-paced learning, providing a more focused, personalized form of instruction and individualized feedback (Istrate, 2019). With the infinite availability and patience of IPAs, learners can engage in repetitive practice activities (Bibauw et al., 2019). According to Gu, Davis, Tao, and Zechner (2021), immediate automated feedback helps L2 learners understand the gaps in their linguistic knowledge and self-correct, which is an effective method for improving their oral proficiency, especially in terms of pronunciation and fluency.

The mobility, accessibility, and practicability of IPAs on mobile devices enable sustainable learning and allow learners to access learning content at any time, which creates more opportunities for authentic language use compared with the classroom environment (Istrate, 2019; Kukulska-Hulme, 2019). IPAs can also increase learners’ exposure to input and practice with output in authentic contexts, which are highly crucial for mastering a target language.

Moreover, IPAs create a low-anxiety environment for language practice (Tai & Chen, 2020). Interacting with IPAs rather than human interlocutors can reduce anxiety and increase learners’ willingness to communicate in the target language. These unique characteristics of IPAs correspond to the tenets of interactionist theory, which highlight the critical need for input, interaction, feedback, and output for L2 development (Long, 2017).

IPAs represent a solution to several obstacles learners encounter in face-to-face EFL setting by providing opportunities for interactions, individualized learning, immediate feedback, and a comfortable environment in which to practice languages. However, as Dizon (2020) and Bibauw et  al. (2019) indicated, the use of IPAs in language education has not been thoroughly investigated, and more experimental research is required.

# 2.2.  The target IPA: Google assistant on smartphones

This study investigated Google Assistant on smartphones, an IPA developed by Google that provides communication in ways that leverage how people naturally interact (Moussalli & Cardoso, 2020). Google Assistant plays different interactive roles: narrator (e.g. speaking about itself or asking quiz questions), interlocutor (e.g. trying to establish a three-party IPA-learner-learner interaction with equal participation), interviewer (e.g. asking questions), facilitator (e.g. stimulating learners to talk with each other), and entertainer (e.g. interacting, singing and playing videos (Bibauw et  al., 2019; Engwall, Lopes, & Åhlund, 2021). Therefore, learners can engage in dynamic interactions with Google Assistant as if they were communicating with L1 English speakers, which is essential for effective L2 learning (Long, 2017).

Google Assistant displays content such as audio, text, pictures, and visual aids on screen. According to the multimedia principle described by Mayer (2017), learning from words (i.e. either spoken or written) and pictures (i.e. either static or dynamic) is more effective than learning from words alone because processing information through different modalities expands the resources of working memory and increases learning effectiveness.

In addition, the mobility and ubiquity of Google Assistant (Kukulska-Hulme, 2019) give users using personal devices unlimited access to learning resources and speaking practice (Istrate, 2019). According to Moussalli and Cardoso (2020), this provides learners with a wide variety of convenient learning methods suited to their needs and lifestyles as well as opportunities to engage in more authentic interactions than available in the classroom. However, research on IPA-assisted language learning has focused on IPAs with smart speakers. The use of IPAs on smartphones has received relatively little attention from researchers and thus requires further investigation (Silva et  al., 2020).

# 2.3.  Research on IPA-assisted language learning

A growing number of studies have investigated the effectiveness and appeal of IPA-assisted language learning. For example, Underwood (2017) explored 11 primary school-age EFL learners’ perceptions of IPAs (e.g. Amazon’s Alexa and Apple’s Siri) and the ability of the IPAs to provide accurate answers. They discovered that learners exhibited a positive attitude toward IPA-based interaction and actively participated, and spoke more English when using IPAs during group work. Sandeep (2019) discovered that Amazon’s Alexa was effective because it was perceived as a non-threatening conversational partner. Learner-centric interactions reduce learners’ inhibition and enhance their confidence in communicating.

Moussalli and Cardoso (2016) examined the use of Amazon Echo and its companion IPA, Alexa, by four EFL learners. The participants interacted with Alexa using a set of predetermined questions and the results revealed that Echo offered the EFL learners a stress-free opportunity to gain exposure to input and practice output. The learners felt comfortable speaking with Echo and thought it was a useful tool to learn English pronunciation and vocabulary. Moussalli and Cardoso (2020) investigated Echo’s ability to process L2 learners’ speech at different levels of accentedness. The results indicated that the L2 learners had no problems understanding Echo. Echo is comparable to humans in terms of comprehensibility and intelligibility.

The results of these studies indicate that IPAs can expose L2 learners to input and promote interaction in a fun, stress-free environment at any time. Despite the positive results, IPA‐based learning does not always outperform traditional teacher‐led training. For example, Dizon (2020) investigated the effects of Alexa on the development of EFL learners’ listening and speaking skills. A total of 13 adult EFL learners were recruited and participated in a 10-week program of weekly interactions with Alexa, each for 12 minutes. The results revealed that the speaking proficiency of learners who use IPAs improved significantly compared with that of the learners who did not use IPAs. However, no significant difference was observed in the two group’s listening skills.

In another study, Tai and Chen (2020) assessed adolescent EFL leaners’ willingness to communicate (WTC) during a 2-week program of interaction with Google Assistant. Although they observed an increase in the majority of the learners’ engagement and WTC, Google Assistant increased the cognitive load on lower achievers and hindered their learning and WTC in English.

As Dizon (2020) indicated, research on IPA-assisted language learning is in a rudimentary stage. The few studies on the subject have been exploratory, limited in scope and sample size, and have provided subjective perspectives on the potential of IPAs, thus yielding conflicting results. According to Bibauw et  al. (2019), this inconclusiveness may stem from methodological decisions, such as small sample sizes and short program durations, which may have prevented the studies from yielding substantive findings. Rigorous experimental research with carefully designed evaluative instruments is thus required.

Studies on IPAs have focused on regular EFL instructional contexts. Knowledge regarding the application of IPAs outside the classroom remains limited. In addition, most studies have investigated IPAs connected to smart speakers (e.g. Dizon, 2020; Moussalli & Cardoso, 2016, 2020; Sandeep, 2019; Underwood, 2017 [Alexa on Amazon’s Echo]; Tai & Chen, 2020 [Google Assistant on Google Home Hub]). IPAs on smartphones have received relatively little attention from researchers (Silva et  al., 2020). According to Kukulska-Hulme (2019), various forms of mobile and smart assistants should be incorporated into informal language learning practices. Mobile technology offers portability, interactivity, context sensitivity, individuality, and potential advantages for out-of-class learning. Thus, more evidence on the out-of-class application of IPAs on smartphones is required to comprehensively understand IPA-assisted language learning. According to Van den Berghe et  al. (2019), the effectiveness of IPAs in L2 interactions compared with that of L1 and L2 speakers’ interactions is a crucial but unexplored topic.

This study therefore examined the effect of the out-of-class application of Google Assistant on smartphones on EFL learners’ oral proficiency and compared this effect with that of interaction with L1 English speakers and L2 English speakers. This study also explored EFL learners’ perceptions of the out-of-class use of Google Assistant for English speaking practice. The following research questions were addressed:

1. How much does the use of Google Assistant significantly improve the adolescent EFL learners’ oral proficiency?

2. Does the oral proficiency significantly differ among the adolescent EFL learners who interact with Google Assistant, L1 English speakers, and L2 English speakers outside the classroom?   
3. How do the adolescent EFL learners perceive the effect of using Google Assistant outside class on their oral proficiency in English?

# 3.  Method

# 3.1.  Design

This study investigated the impact of using an IPA (i.e. Google Assistant on smartphones) outside the classroom on EFL learners’ oral proficiency. The participants were 89 college freshmen (63 men and 26 women, 18–20 years) recruited from three English Listening and Speaking classes, taught by the same English teacher, at a public university in Taiwan. They were randomly divided into three groups: (1) those who interacted with Google Assistant on smartphones (GA group); (2) those who interacted with L1 English speakers (L1 group; e.g. foreign students in the participants’ university); and (3) those who interacted with L2 English speakers (L2 group; e.g. peers and friends, who were L1 Chinese speakers and learned English as a foreign language). The GA group participated in an out-of-class program consisting of interactions with Google Assistant on smartphones for 10 minutes twice a week over the course of a semester. The L1 and L2 groups completed similar oral interaction activities on the same topics used for the GA group.

# 3.2.  Participants

All participants were L1 Chinese speakers majoring in non-language disciplines, such as computer science, electrical engineering, chemical engineering, and material science engineering, who enrolled in the English listening and speaking course to strengthen their oral communication skills. The course convened once a week in 90-minute classes over the course of a semester. The same instructor, the researcher, taught all three groups using the same English textbook and learning activities. Before the participants selected the course, their proficiency was measured in accordance with the language center’s standards specifically, their English reading and writing performance on the General Scholastic Ability Test, a standardized proficiency exam to determine high school students’ readiness for college. According to the definition of competence provided by the Common European Framework of Reference for language (CEFR), the participants were at level B1.

The L1 English speakers were foreign students who joined the international exchange programs provided by the participants’ university. English was used as a lingua franca for academic and daily communication. The L2 English speakers were L1 Chinese speakers, who learned English as a foreign language. Although no screening tests were arranged for the L2 English speakers before the intervention, there were specific entrance requirements on their English competence before entering the curriculum. They had to pass the General Scholastic Ability Test and reach intermediate English proficiency levels in reading and writing.

# 3.3.  Google assistant-mediated interaction activity

The study aimed to provide self-directed interactive activities beyond the classroom, playing a supplementary role to help EFL learners gain more language exposure and speaking practice. The participants were provided a list of interaction topics (see Appendix A) following the suggestions of the CEFR for B1 level and expanded those present in the course book 21th Century Communication, Listening, Speaking, and Critical Thinking (Lee, 2021). An excerpt from learners’ interaction with Google Assistant was shown in Table 1 to illustrate the type of exchanges.

# 3.4.  Instruments

The instruments in the study were the oral proficiency tests, and interviews.

Table 1. E xtract from Google Assistant-mediated interaction.   

<html><body><table><tr><td>Speaker</td><td colspan="2">Transcript</td></tr><tr><td>Learner: Google: Learner:</td><td>Are you smart? I try to be the smartest version of me every day.. Do you have a friend?.</td><td></td></tr><tr><td>Google: Learner:</td><td>My very best friend is... you. I think a best friend should be someone you can always learn from. What do you look for in a best friend? Kind.</td><td>GA acting as an interlocutor</td></tr><tr><td>Google: Learner:</td><td>I am the kind of friend you want to have. Do you know COvID-19?</td><td></td></tr><tr><td>Google:</td><td>According to Wikipedia, COviD-19 is an infectious disease caused by the SARS-CoV-2 virus. Most people who fall sick with COvID-19 will</td><td>GA acting as</td></tr><tr><td rowspan="2"></td><td>experience mild to moderate symptoms and recover without special treatment. However, some will become seriously ill and require. medical attention. (Showing the information on screen).</td><td>a narrator</td></tr><tr><td></td><td></td></tr><tr><td>Learner: Google:</td><td>Can you sing a song?. Sure! Let&#x27;s celebrate that we have the vaccine to help us bring a change to this old routine...(Singing the song).</td><td>GA acting as an entertainer</td></tr></table></body></html>

# 3.4.1.  Oral proficiency test

The participants’ oral proficiency in English was assessed before the experiment through a pretest and after with a posttest (Appendix B). The oral proficiency test was audio recorded and administered individually. The tests were developed by the researcher and based on the guidelines for the high-intermediate level of the General English Proficiency Test (GEPT), which is equivalent to an English level of B2 on the CEFR. The GEPT, developed by the Language Training and Testing Center, is used for English learners at all levels in Taiwan.

The speaking test consisted of three parts: (1) answering prerecorded questions, (2) describing pictures, and (3) having discussions (Table 2). The items on the pretest and posttest were the same but in a different order. The rating scale for high-intermediate speaking on the GEPT was used to evaluate the participants’ oral proficiency (Appendix C). The rubric evaluated oral proficiency in terms of fluency, appropriateness of content, accuracy of pronunciation, vocabulary, and grammatical range and accuracy. The results of the speaking pretest and posttest were coded blindly by two L1 English teachers. First, the two English teachers graded 10 recorded oral presentations separately, and the inter rater reliability was 0.81. They then graded the rest of the presentations separately, and the averaged ratings were used for the data analysis.

# 3.4.2.  Focus group interview

To explore the participants’ perceptions of the process and its impact on their oral proficiency, three focus group interview sessions were conducted with the three groups of participants. Open-ended questions related to their experiences interacting with Google Assistant, the L1 English speakers, and the non-L1 English speakers were posed (Appendix D).

# 3.5.  Data analysis

This study utilized a mixed-methods design to address the research questions. To address the first two research questions, the results of the three groups’ oral proficiency tests were analyzed through a two-way mixed-design analysis of variance (ANOVA) (groups: GA, L1, and L2;

Table 2. T est format and structure.   

<html><body><table><tr><td>Skill</td><td>Part</td><td>Task Types</td><td>Number of items</td><td>Time (mins.)</td></tr><tr><td>Speaking</td><td>1</td><td>Answering Questions</td><td>8</td><td>15</td></tr><tr><td></td><td>?</td><td>Picture Description</td><td>1</td><td></td></tr><tr><td></td><td>3</td><td>Discussion</td><td>1</td><td></td></tr></table></body></html>

tests: pretest and posttest). For the third question, a three-phase thematic analysis was performed to interpret the data from the audio recordings of the focus group interviews.

# 3.6.  Procedure

This study lasted for one semester, a total of 17 weeks. Figure 1 presents the experimental procedure. The participants received a brief orientation on the goals of the study, and an English oral proficiency test was administered in the first week. In the second week, the participants received an orientation on the interactive activity outside the classroom. In addition, the researcher demonstrated how to interact with Google Assistant on smartphones to the GA group. Starting from the third week, the three groups were required to interact with either Google Assistant, the L1 English speakers, or the L2 English speakers in their free time in 10-minute sessions twice a week. The participants in the GA group had to take a screenshot of their interaction with Google Assistant on smartphones, including the transcription of their speech output and Google Assistant’s responses on screen, and uploaded to Google class drive folder each week. The L1 and L2 groups had to note down the time and ask for their interlocutors’ signature after interaction. After the program, the participants completed the English oral proficiency posttest. Finally, three focus group interview sessions were conducted separately: one with the GA group, another with the L1 group, and the last with the L2 group. In the interviews, the participants were able to share their impressions of the process and their attitude toward interacting with Google Assistant, the L1 English speakers, and the L2 English speakers. The interviews were conducted in Chinese.

![](img/b80d963421fbd377ff23f8f960c1bc5bbc65d04e52ec9fe518614942ff9d35c7.jpg)  
Figure 1. E xperimental procedure.

# 4.  Results

# 4.1.  Results of oral proficiency tests

To evaluate the effect of Google Assistant on the EFL learners’ oral proficiency, a two-way mixed-design ANOVA was performed. Mauchly’s test for assumption of Sphericity was statistically insignificant (Mauchly’s $\mathrm { W } = 1 . 0 0$ , $X ^ { 2 } = . 0 0$ , $p > . 0 5 )$ , indicating equal levels of variance in the data for the different conditions. Thus, no degrees of freedom adjustments were needed. Table 3 presents the descriptive statistics of the scores of the three groups on the oral proficiency pretest and post-test and Table 4 presents the results of the two-way mixed-design ANOVA.

There was a non-significant main effect for groups, $F \left( 2 , 1 5 \right) = 2 . 0 8 { \mathrm { ; } }$ $p \ = \ . 1 3$ , $\boldsymbol \eta ^ { 2 } = . 0 5$ . The critical F-value for (2, 15) at the 5 percent of significance was 3.68. As shown in Table 5, the $\mathrm { F }$ value is smaller than the critical F-value, so the main effect for groups was not significant. The results indicated that the treatment effects were similar for the groups. Evidence supporting this assumption came from the low Eta squared values $\left( \boldsymbol { \mathsf { \Pi } } \right) ^ { 2 } = . 0 5$ , $\boldsymbol \eta ^ { 2 } < . 0 6 )$ , representing a small effect size.

By contrast, there was a significant main effect of tests, $F$ $F \left( 1 , \ 1 5 \right) =$ 116.21, $p = . 0 0$ , $\eta ^ { 2 } = . 5 8$ . The $\mathrm { F }$ value is larger than the critical F-value, $\mathrm { F } _ { \bullet _ { 0 5 } } ( 1 , 1 5 ) = 4 . 5 4$ , so the main effect for tests was significant. The results indicated that there was no similar change in the participants’ test scores across the speaking pretest and post-test. In other words, their oral proficiency improved to varying degrees as a result of the differential effects of the treatments on their learning. The large Eta squared values $( \boldsymbol \eta ^ { 2 } = . 5 8$ , $\boldsymbol { \eta } ^ { 2 } > . 1 4 )$ lent support to the hypothesis that the time effect was significant.

Table 3. D escriptive statistics of the oral proficiency tests.   

<html><body><table><tr><td></td><td></td><td colspan="2">Pretest</td><td colspan="2">Post-test</td></tr><tr><td>Group</td><td>N</td><td>Mean</td><td>SD</td><td>Mean</td><td>SD</td></tr><tr><td>GA</td><td>35</td><td>77.03</td><td>4.34</td><td>85.03</td><td>5.24</td></tr><tr><td>41</td><td>24</td><td>76.92</td><td>5.13</td><td>84.00</td><td>4.16</td></tr><tr><td>L2</td><td>30</td><td>78.73</td><td>2.49</td><td>79.40</td><td>5.22</td></tr></table></body></html>

Table 4. T wo-way mixed-design ANO VA results.   

<html><body><table><tr><td>Source</td><td>Ss</td><td>df</td><td>MS</td><td>F</td><td>p</td><td>n?</td></tr><tr><td>Between</td><td>1813.58</td><td>5</td><td></td><td></td><td></td><td></td></tr><tr><td>Group</td><td>128.30</td><td>2</td><td>64.15</td><td>2.08</td><td>.13</td><td>.05</td></tr><tr><td>Test</td><td>1197.54</td><td>1</td><td>1197.54</td><td>116.21***</td><td>.00</td><td>.58</td></tr><tr><td>Group x Test</td><td>487.74</td><td>2</td><td>243.87</td><td>23.67***</td><td>.00</td><td>.36</td></tr><tr><td>Within</td><td>3544.84</td><td>30</td><td>41.22</td><td></td><td></td><td></td></tr><tr><td>Subjects</td><td>886.25</td><td>15</td><td>10.31</td><td></td><td></td><td></td></tr><tr><td>Error</td><td>2658.59</td><td>15</td><td>30.91</td><td></td><td></td><td></td></tr><tr><td>Total</td><td>5358.42</td><td>35</td><td>1546.78</td><td></td><td></td><td></td></tr></table></body></html>

Note. \* p < .05, \*\*p < .01, $p < . 0 0 1$ (significant level of F value).

Table 5. T he critical F value at $5 \%$ significant level.   

<html><body><table><tr><td></td><td>F</td><td>df1</td><td>df2</td><td>Sig.</td></tr><tr><td>Group</td><td>2.08</td><td>2</td><td>15</td><td>3.68</td></tr><tr><td>Test</td><td>116.21</td><td>1</td><td>15</td><td>4.54</td></tr><tr><td>Group x Test</td><td>23.67</td><td>2</td><td>15</td><td>3.68</td></tr></table></body></html>

As for the interaction effect of time and groups’ performance, the analysis revealed that the interaction effect was significant, $F \left( 2 , 1 5 \right) =$ 23.67, $p = . 0 0$ , $\boldsymbol \eta ^ { 2 } = \mathrm { \mathcal { 3 6 } }$ . The $\mathrm { F }$ value is larger than the critical F-value, $\mathrm { F } _ { \cdot 0 5 } ( 2 , \ 1 5 ) \ = \ 3 . 6 8$ , so the interaction effect was significant, indicating that the three treatment modalities improved the participants’ oral proficiency to varying degrees. The Eta squared values $( \eta ^ { 2 } = . 3 6 , \eta ^ { 2 } > . 1 4 )$ present evidence substantiating the claim. In order to further explore these group differences in the growth of oral proficiency over time and the interaction between group and time, the Scheffe’s post hoc test was performed to examine the main effect of time and the interaction effect.

A one-way ANOVA was performed to compare the three groups’ performance on the oral proficiency pretest and post-test. As shown in Table 6, the result $\left( p > . 0 5 \right)$ of Levene’s test for the equality of variances indicates that the assumption of the homogeneity of variances in the groups is satisfied.

No significant difference in pretest performance was observed among the three groups $\left( \mathrm { F } \ \left( 2 , \ 3 0 \right) \right. = \left. . 7 4 \right.$ , $p = . 1 6$ , $\eta ^ { 2 } = . 0 4 )$ , with an $\boldsymbol { \mathrm { \Pi } } \boldsymbol { \mathrm { \Pi } } \boldsymbol { \mathrm { \Pi } } ^ { 2 }$ of .04 indicating a small effect, as shown in Table 7. The results revealed that the three groups had a similar level of English oral proficiency before the experiment. By contrast, a significant difference in speaking posttest performance was observed among the three groups $( \mathrm { F } ~ ( 2 , ~ 3 0 ) ~ = ~ 6 . 7 3$ , $p = . 0 0$ , $\boldsymbol \eta ^ { 2 } = . 2 1 $ ), with an $\boldsymbol { \mathrm { \Pi } } \boldsymbol { \mathrm { \Pi } } \boldsymbol { \mathrm { \Pi } } ^ { 2 }$ of .21 indicating a large effect. The GA group had the highest score $\mathbf { \zeta } ^ { \prime } \mathbf { M } = 8 5 . 0 3$ , $\mathrm { S D } = 5 . 2 4 )$ , followed by the L1 group $\mathbf { \check { M } } = 8 4 . 0 0$ , $\mathrm { S D } = 4 . 1 6 $ ) and the L2 group $\mathbf { \chi } ^ { \prime } \mathbf { M } = 7 9 . 4 0$ , $\mathrm { S D } = 5 . 2 2 )$ .

Table 6. R esults on the Levene’s test of equality of variances.   

<html><body><table><tr><td></td><td>Levene Statistic</td><td>df1</td><td>df2</td><td>Sig.</td></tr><tr><td>Pretest</td><td>2.65</td><td>2</td><td>86</td><td>.10</td></tr><tr><td>Post-test</td><td>2.24</td><td>2</td><td>86</td><td>.11</td></tr></table></body></html>

Table 7. ANO VA of pure main effect of group and test.   

<html><body><table><tr><td>Source of Variance</td><td>SS</td><td>df</td><td>MS</td><td>F</td><td>p</td><td>n?</td></tr><tr><td>Group</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Pretest</td><td>61.10</td><td>2</td><td>30.55</td><td>.74</td><td>.16</td><td>.04</td></tr><tr><td>Post-test</td><td>554.93</td><td>2.</td><td>277.47</td><td>6.73***</td><td>.00</td><td>.21</td></tr><tr><td>Error</td><td>3544.84</td><td>30</td><td>41.22</td><td></td><td></td><td></td></tr><tr><td>Test</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>GA</td><td>1120.00</td><td>1</td><td>1120.00</td><td>36.23***</td><td>.00</td><td>.89</td></tr><tr><td>L1</td><td>602.08</td><td>1</td><td>602.08</td><td>19.48***</td><td>.00</td><td>.68</td></tr><tr><td>L2</td><td>6.67</td><td>1</td><td>6.67</td><td>.22</td><td>.52</td><td>.01</td></tr><tr><td>Error</td><td>2658.59</td><td>15</td><td>30.91</td><td></td><td></td><td></td></tr></table></body></html>

Note. ${ } ^ { * } p < . 0 5 .$ ${ \vec { p } } < . 0 1$ , $p < . 0 0 1$ , ${ \sf F } _ { . 0 5 } \left( 2 , 3 0 \right) = 3 . 3 2$ $\mathsf { F } _ { . 0 5 } ( 1 , 1 5 ) = 4 . 5 4$ .

The Scheffé post hoc tests indicated that the mean score of the GA group was significantly higher than that of the L2 group $\left( \boldsymbol { p } ^ { } = . 0 0 \right)$ . A similar significant difference was observed between the L1 and L2 groups $\left( p \ = \ . 0 0 \right)$ . However, no significant differences between the GA group and L1 group $( p = . 4 4 )$ were observed, indicating that Google Assistant and L1 English speakers had similar positive effects on the EFL learners’ oral proficiency. The Eta squared values $\left( \boldsymbol { \mathrm { \eta } } ^ { 2 } \ = \ . 2 1 \right.$ , $\boldsymbol { \eta } ^ { 2 } > . 1 4 )$ together with the results of the Scheffé post hoc test, which were shown to be significant $\left( p < . 0 5 \right)$ , provide further support for the meaningfulness of the between-subjects effects as well as the plausibility of the hypothesis that the group effect has been caused by the different effects of the treatment studied. A further finding was that the participants’ interaction with Google Assistant and L1 interlocutors proved even more efficient in improving oral proficiency.

Finally, a repeated-measures ANOVA was performed to examine the differences within the groups between the oral proficiency pretest and posttest. The results revealed significant differences between the two tests for the GA group $( \mathrm { ~ F ~ } ( 1 , 1 5 ) = 3 6 . 2 3 , \ : p = . 0 0 , \ : \eta ^ { 2 } = . 8 9 )$ and the L1 group $( { \mathrm { F } } \ ( 1 , \ 1 5 ) \ = \ 1 9 . 4 8$ , $p ~ = ~ . 0 0$ , $\boldsymbol \eta ^ { 2 } \ = \ . 6 8 )$ , but not for the L2 group $( \mathrm { F } ~ ( 1 , ~ 1 5 ) ~ = ~ . 2 2$ , $p = . 5 2$ , $\boldsymbol \eta ^ { 2 } = . 0 1 $ ). The tests of within-subject effects as well as the results of the Scheffé post hoc test gave support to the assumption that the time effect was significant $( F \left( 1 , 1 5 \right) = 1 1 6 . 2 1$ , $p = . 0 0$ , $\eta ^ { 2 } = . 5 8 )$ , suggesting that the three groups had been differentially impacted over time. The results indicated that the GA and L1 groups’ oral proficiency significantly improved over time. Large Eta squared values (GA group: $\boldsymbol { \mathrm { 1 } } ^ { 2 } \ : = \ : . 8 9$ ; L1 group: $\eta ^ { 2 } = . 6 8 )$ lent support to the time effect was significant. The findings demonstrated that Google Assistant and L1 interlocutors significantly improved the EFL learners’ overall oral proficiency over time.

# 4.2.  Results of participants’ oral performance in five subdimensions

To determine in which of the subdimensions of oral proficiency the three groups differed, several two-way mixed-design ANOVAs were performed for the pretest and posttest. No significant differences in the five subdimensions were observed among the three groups for the pretest (fluency: F $( 2 , \ 8 6 ) \ = \ 1 . 2 9$ , $p \ = \ . 2 8$ , $\boldsymbol \eta ^ { 2 } = . 0 3$ ; content: $\mathrm { ~ F ~ } \left( 2 , \ 8 6 \right) = \ . 2 2$ $p \ = \ . 8 0$ , $\boldsymbol { \mathrm { \Pi } } \boldsymbol { \mathrm { \Pi } } ^ { 2 } \ : = \ : . 0 1$ ; pronunciation: F $( 2 , \ 8 6 ) \ = \ 2 . 2 8$ , $p \ = \ . 1 1$ , $\boldsymbol \eta ^ { 2 } = . 0 5$ ; vocabulary: F $( 2 , \ 8 6 ) \ = \ 2 . 7 2$ , $p = . 0 7$ , $\boldsymbol \eta ^ { 2 } = . 0 6$ ; grammar: F $( 2 , \ 8 6 ) \ =$ .11; $ { p } = \ . 9 0$ , $\boldsymbol \eta ^ { 2 } = . 0 0$ ; Table 8). Significant differences were observed among the three groups’ posttests in terms of fluency: F $( 2 , 8 6 ) = 1 9 . 8 8 $ , $p = . 0 0$ , $\boldsymbol \eta ^ { 2 } = . 3 2$ ; content: F $( 2 , 8 6 ) = 4 . 8 3$ , $p = . 0 1$ , $\mathsf { \Pi } \eta ^ { 2 } = \mathsf { \Pi } . 1 0$ ; vocabulary: F $( 2 , 8 6 ) = 7 . 1 6 .$ $p = . 0 0$ , $\boldsymbol \eta ^ { 2 } = . 1 4$ , and grammar: F $( 2 , 8 6 ) = 3 . 9 6 ,$ $p = . 0 4$ , $\boldsymbol \eta ^ { 2 } \ = \ . 0 8$ . However, no significant difference in pronunciation scores was observed, $\mathrm { ~ F ~ } ( 2 , 8 6 ) = 1 . 4 9$ , $p = . 2 3$ , $\boldsymbol \eta ^ { 2 } = . 0 3$ .

Table 8. D escriptive statistics and two-way mixed-design ANO VA results for participants’ performance in five subdimensions.   

<html><body><table><tr><td colspan="2"></td><td colspan="2">GA (N=35)</td><td colspan="2">L1 (N=24)</td><td colspan="2">L2 (N=30)</td><td colspan="3"></td></tr><tr><td></td><td>Test</td><td>M</td><td>SD</td><td>M</td><td>SD</td><td>M</td><td>SD</td><td>F</td><td>p</td><td>n?</td></tr><tr><td rowspan="2">Fluency</td><td>1</td><td>14.49</td><td>1.04</td><td>14.79</td><td>1.35</td><td>14.07</td><td>2.36</td><td>1.29</td><td>.28</td><td>.03</td></tr><tr><td>2</td><td>17.43</td><td>1.40</td><td>17.33</td><td>1.27</td><td>15.47</td><td>1.38</td><td>19.88***</td><td>.00</td><td>.32</td></tr><tr><td rowspan="2">Content</td><td>1</td><td>15.26</td><td>1.42</td><td>15.42</td><td>1.28</td><td>15.10</td><td>2.30</td><td>.22</td><td>.80</td><td>.01</td></tr><tr><td>2</td><td>16.66</td><td>1.90</td><td>15.88</td><td>1.42</td><td>15.10</td><td>2.48</td><td>4.83**</td><td>.01</td><td>.10</td></tr><tr><td rowspan="2">Pronunciation</td><td>1</td><td>15.40</td><td>1.42</td><td>15.42</td><td>1.06</td><td>16.03</td><td>1.32</td><td>2.28</td><td>.11</td><td>.05</td></tr><tr><td>2</td><td>16.26</td><td>2.31</td><td>16.63</td><td>1.10</td><td>15.77</td><td>1.70</td><td>1.49</td><td>.23</td><td>.03</td></tr><tr><td rowspan="2">Vocabulary</td><td>1</td><td>15.83</td><td>1.48</td><td>15.67</td><td>1.34</td><td>16.67</td><td>2.25</td><td>2.72</td><td>.07</td><td>.06</td></tr><tr><td>2</td><td>18.23</td><td>1.80</td><td>17.88</td><td>1.48</td><td>16.30</td><td>2.82</td><td>7.16***</td><td>.00</td><td>.14</td></tr><tr><td rowspan="2">Grammar</td><td>1</td><td>15.74</td><td>1.27</td><td>15.57</td><td>1.26</td><td>15.60</td><td>1.65</td><td>.11</td><td>.90</td><td>.00</td></tr><tr><td>2</td><td>16.49</td><td>1.70</td><td>15.75</td><td>1.59</td><td>17.27</td><td>2.78</td><td>3.96*</td><td>.04</td><td>.08</td></tr></table></body></html>

Note. ${ } ^ { * } p < . 0 5 .$ , $\stackrel { * * } { p } < . 0 1$ , $p < . 0 0 1$ (significant level of F rations); $F _ { . 0 5 ( 2 , 8 6 ) } = 3 . 1 0 3$ .

Table 9. R epeated-measures ANO VA of participants’ performance in five subdimensions.   

<html><body><table><tr><td></td><td>Group</td><td>Ss</td><td>df</td><td>MS</td><td>F</td><td>p</td><td>n2</td></tr><tr><td rowspan="3">Fluency</td><td>GA</td><td>151.56</td><td>1</td><td>151.56</td><td>206.59***</td><td>.00</td><td>.86</td></tr><tr><td>L1</td><td>77.52</td><td>1</td><td>77.52</td><td>59.47***</td><td>.00</td><td>.72</td></tr><tr><td>L2</td><td>29.40</td><td>1</td><td>29.40</td><td>10.30***</td><td>.00</td><td>.26</td></tr><tr><td rowspan="3">Content</td><td>GA</td><td>34.30</td><td>1</td><td>34.30</td><td>28.31***</td><td>.00</td><td>.45</td></tr><tr><td>L1</td><td>2.52</td><td>1</td><td>2.52</td><td>2.15</td><td>.16</td><td>.09</td></tr><tr><td>L2</td><td>.00</td><td>1</td><td>.00</td><td>.00</td><td>1.00</td><td>.00</td></tr><tr><td rowspan="3"> Pronunciation</td><td>GA</td><td>12.86</td><td>1</td><td>12.86</td><td>6.15*</td><td>.02</td><td>.15</td></tr><tr><td>L1</td><td>17.52</td><td>1</td><td>17.52</td><td>26.90***</td><td>.00</td><td>.54</td></tr><tr><td>L2</td><td>1.07</td><td>1</td><td>1.07</td><td>.70</td><td>.41</td><td>.02</td></tr><tr><td rowspan="3">Vocabulary</td><td>GA</td><td>100.80</td><td>1</td><td>100.80</td><td>92.13***</td><td>.00</td><td>.73</td></tr><tr><td>L1</td><td>58.21</td><td>1</td><td>58.21</td><td>38.48***</td><td>.00</td><td>.63</td></tr><tr><td>L2</td><td>2.02</td><td>1</td><td>2.02</td><td>.32</td><td>.27</td><td>.04</td></tr><tr><td rowspan="3">Grammar</td><td>GA</td><td>9.66</td><td>1</td><td>9.66</td><td>15.38***</td><td>.00</td><td>.31</td></tr><tr><td>41</td><td>.00</td><td>1</td><td>.00</td><td>.00</td><td>1.00</td><td>.00</td></tr><tr><td>L2</td><td>41.67</td><td>1</td><td>41.67</td><td>13.38***</td><td>.00</td><td>.32</td></tr></table></body></html>

Note. ${ \bf { \bar { \rho } } } p < . 0 5 ,$ $\ " > \emptyset < . 0 1$ , ${ \vec { p } } < . 0 0 1$ , (significant level of F rations); $F _ { . 0 5 ( 1 , 3 4 ) } = 4 . 1 3 0$ $F _ { . 0 5 ( 1 , 2 9 ) } = 4 . 1 8 3$ $F _ { . 0 5 ( 1 , 2 3 ) } = 4 . 2 7 9$ .

The Scheffé post hoc tests indicated that the GA and L1 groups scored similarly in the five dimensions: fluency $( p = . 7 9 )$ , content $( p =$ .15), pronunciation $( p \ : = \ : . 4 5 )$ , vocabulary $\left( p \right. = \left. . 5 3 \right)$ , and grammar $( p =$ .19). By contrast, the GA group’s fluency $\left( \boldsymbol { p } = . 0 0 \right)$ , content $\left( p \right. = \left. . 0 0 \right)$ , and vocabulary $\left( \boldsymbol { p } = . 0 0 \right)$ scores were significantly higher than those of the L2 group, whereas the scores for the other two dimensions, pronunciation $( p = . 2 9 )$ and grammar $( p = . 1 4 )$ , were similar in the posttest. The L1 group outperformed the L2 group in terms of fluency $\left( \boldsymbol { p } = . 0 0 \right)$ , vocabulary $\left( \boldsymbol { p } = . 0 0 \right)$ , and pronunciation $\left( p = . 0 9 \right)$ .

A repeated-measures ANOVA was performed to examine the differences within groups between pretest and posttest scores in the five dimensions. Table 9 lists the results of the repeated-measures ANOVAs for the participants’ performance in the five subdimensions over time.

Significant differences between the GA group’s pretest and posttest performance were observed in all five dimensions, namely fluency $( \mathrm { F ~ } \left( 1 , \ 3 4 \right) = \ 4 9 . 8 6$ , $p ~ = ~ . 0 0$ , $\eta ^ { 2 } = . 8 6 )$ , content $( \mathrm { F } ~ ( 1 , ~ 3 4 ) ~ = ~ 6 . 0 5 ,$ $\hbar =$ .00, $\boldsymbol { \eta } ^ { 2 } \ : = \ : . 4 5 \ )$ , pronunciation $( \mathrm { F } ( 1 , \ 3 4 ) = 3 . 5 8$ , $ { p } = \ . 0 2$ , $\boldsymbol { \eta } ^ { 2 } \ : = \ : . 1 5 )$ , vocabulary $( \mathrm { F } \ ( 1 , \ 3 4 ) \ = \ 1 . 7 3$ , $p \ : = \ : . 0 0$ , $\eta ^ { 2 } = . 7 3 )$ , and grammar (F (1, $3 4 ) \ = \ 2 . 0 2$ , $p = . 0 0$ , $\boldsymbol \eta ^ { 2 } = . 3 1 ,$ ), indicating that interaction with Google Assistant improved the GA group’s oral proficiency over time.

The L1 group’s fluency $( \mathrm { ~ F ~ } ( 1 , 2 3 ) = 2 5 . 5 , \ : p = . 0 0 , \ : \eta ^ { 2 } = . 7 2 )$ , pronunciation $\left( \mathrm { F } \ \left( 1 , \ 2 3 \right) \right. = \left. 4 . 8 8 \right.$ , $p = . 0 0$ , $\eta ^ { 2 } = . 5 4 )$ ), and vocabulary (F (1, 23) $= 1 . 7 3$ , $p = . 0 0$ , $\boldsymbol \eta ^ { 2 } = . 7 3 )$ scores were significantly higher in the post-test, whereas the scores for the other two dimensions, content $\left( \mathrm { F } \ \left( 1 , \ 2 3 \right) \right. =$ .44, $p \ = \ . 1 6$ , $\boldsymbol \eta ^ { 2 } \ : = \ : . 0 9 \ )$ and grammar $\left( \mathrm { ~ F ~ } \left( 1 , \ 2 3 \right) \right. = \ : 2 . 0 2$ , $p \ : = \ : . 0 0$ , $\boldsymbol \eta ^ { 2 } =$ .31), slightly improved.

The L2 group exhibited significant improvement in fluency (F (1, 29) $= 9 . 6 7$ , $p = . 0 0$ , $\eta ^ { 2 } = . 2 6 )$ and grammar $\left( \mathrm { ~ F ~ } \left( 1 , \ 2 9 \right) \right. = \ : 8 . 7 0 $ , $p = . 0 0$ , $\boldsymbol { \mathrm { \Pi } } \boldsymbol { \mathrm { \Pi } } \boldsymbol { \mathrm { \Pi } } ^ { 2 }$ $\mathbf { \lambda } = \mathbf { \lambda } . 3 2 )$ but not in content $\left( \mathrm { ~ F ~ } ( 1 , 2 9 ) = . 0 0 \right)$ , $p { = } 1 . 0 0$ , $\boldsymbol \eta ^ { 2 } = . 0 0 \rangle$ ), pronunciation $( \mathrm { F } \ ( 1 , \ 2 9 ) \ = \ . 3 0$ , $p = . 4 1$ , $\boldsymbol \eta ^ { 2 } = . 0 2 \mathrm { ) }$ , and vocabulary (F (1, 29) $\ c = \ . 3 2$ , $p \ : = \ : . 2 7$ , $\eta ^ { 2 } = . 0 4 )$ .

Section 5 presents the results of the qualitative analysis of the three groups’ perceptions of their interactions with Google Assistant, the L1 English speakers, and the L2 English speakers, respectively.

# 5.  Discussion

No significant difference in pretest performance was observed among the GA, L1, and L2 groups. However, the GA and L1 groups’ posttest oral proficiency was significantly higher than that of the L2 group. In addition, the oral proficiency of the GA and L1 groups significantly improved. These results indicate the effectiveness of Google Assistant in improving EFL learners’ oral proficiency and that it exhibits a positive effect similar to that of interaction with L1 English speakers. The results substantiate the findings of Dizon (2020), who demonstrated the positive effect of IPAs on the development of EFL learners’ speaking skills. The results also support Sydorenko, Daurio, and Thorne (2018), who argued that although L1 English speakers are ideal conversational partners, automated agents can also be used to practice and improve L2 proficiency in the absence of L1 English speakers. Section 5.1 presents an analysis of the three groups’ oral performance in terms of the five subdimensions.

# 5.1.  Fluency

The participants’ fluency significantly improved after the intervention. The GA group’s fluency scores were the highest, followed by those of the L1 group and those of the L2 group. The results confirmed the effects of additional out-of-class speaking practice and corroborate the findings of Hanzawa (2021), who indicated that long-term EFL learning effects English fluency. As the number of practice trials increased, the EFL learners’ fluency in speaking gradually increased.

The GA group scored the highest among the three groups. A possible reason is that interacting with Google Assistant decreased their anxiety, as one participant described:

I am not good at English speaking. In in-person classrooms, all eyes are on me. My teacher and classmates notice my errors, which makes me nervous, embarrassed, and fearful. With Google Assistant, that was not the case. It created a friendly and less stressful atmosphere, which made me feel relaxed. I talked with it freely and confidently.

我的口說不好，當所有的眼睛都看著我，老師和同學都注意到我哪裡錯，我會緊張、尷尬、害怕。和Google就不一樣。比較友善的氛圍，較沒壓力，我能輕鬆自在地講也比較有自信。

The participant’s description is consistent with the results of other studies (e.g. Moussalli & Cardoso, 2020; Sandeep, 2019; Tai & Chen, 2020), which have demonstrated that IPAs can reduce L2 learners’ speaking and participation anxiety by creating a stress-free, interactive environment. According to Hanzawa (2021), anxiety is a key affective factor influencing the fluency of L2 speech.

As for the L1 group, the interview data revealed that their interaction with the L1 English speakers created an authentic environment for meaningful communication and provided essential foundational knowledge. The participants gained exposure to high-quality spoken English and received immediate feedback, which encouraged them to practice and engage in self-directed learning, thereby improving their overall oral proficiency. The results were in line with interactionist research that has shown that L1 interlocutors can be better input providers than L2 partners during interaction (Sato & McDonough, 2020). However, communicating with L1 English speakers was threatening for some participants who felt embarrassed or awkward because of their perceived limitations in using English (Richards, 2015). In particular, the lower-proficient learners were under pressure because they believed that their own English was ‘broken’ while their L1 English partners were ‘perfect’ speakers.

The L2 group participants’ fluency in oral communication also improved significantly after the intervention. In the interviews, the participants explained that they felt much more comfortable communicating with their learner partner. Gass and Mackey (2020) attributed this different mindset to their perception of shared incompetence, which provide them with a comfort zone in which they collaboratively worked on linguistic issues. Therefore, the participants’ comfort level, the collaborative nature of peer interaction, and more repeated practice were conducive to learners’ fluency development.

# 5.2.  Content and vocabulary

The quantitative data indicated that the GA group’s content and vocabulary scores significantly improved in the posttest and that they scored considerably higher than did the other two groups. The qualitative analyses revealed three factors contributing to this improvement: (1) ubiquitous L1 and L2 learning support, (2) multimodal feedback presentation (e.g. audio, text, pictures, and visual aids), and (3) new information drawing the learners’ interest and encouraging autonomous learning.

Most of the participants appreciated that Google Assistant provided ubiquitous learning support in both English and Chinese (L1), as one participant described:

I appreciated the anytime, anywhere availability of Google Assistant on my smartphone. For example, I could have a 5-minute conversation while waiting for the bus. It also made me interested in searching for additional definitions of words I encountered during the interaction. Asking Google for help is convenient. For example, when I ask “Hey, Google! What is pandemic?”, it showed the meaning of the word and related online information on the screen. If you want to know its Chinese (L1) meaning, you just say, “Hey, Google! Translate ‘pandemic’ into Chinese.”

我很喜歡Google 助理，它無所不在隨手可得，例如:我可以利用等公車時和它對話。我喜歡搜尋互動中遇到的單字和相關意思，有Google幫忙很方便，我只要說: 「Hey, Google! What is pandemic?」螢幕上就出現定義，也提供相關資訊，想知道中文，只要說: 「Hey, Google! Translate pandemic into Chinese.」。

Another advantage was that Google Assistant’s multimodal feedback solved the learners’ problems in interpreting information and supported the GA group’s interactions, especially those with lower oral proficiency. This is what occurs in real conversation, as people pay attention to nonverbal language such as tone of voice, nonverbal cues, and context. The results were consistent with Montero Perez (2022) study that the combination of verbal and visual elements enhances L2/FL learners’ vocabulary learning. A further significant type of assistance identified in the interview data involved the provision of target language interactions with Google Assistant and immediate feedback, which aided learners to effectively acquire new words (Tai & Chen, 2020). The following quotes demonstrate just that: ‘I just see a picture and I start imagining what the useful vocabulary could be used’, and ‘It’s easier to speak because I look at the picture and it gives me a clear idea of what I have to talk about’. As substantiated by another GA participant, ‘With pictures, I have a basis to start and your imagination flourishes’. These statements echoes what Lavalle and Briesmaster (2017) propose that pictures can establish a context for speaking and provide learners with information to use. Pictures also represent a guide for students in spoken descriptions and contribute to their imaginations. Thus, multimedia input and interaction with Google Assistant promote learners’ vocabulary learning and stimulates their discussion (Mayer, 2017; Zhang & Zou, 2021).

The multimodality of the information on the app allowed for the participants to discover new information which motivated them to seek additional content related to certain topics, as one participant described:

When I saw something interesting or cool or something that I didn’t know, I started by using the descriptions provided by Google, and then I searched for more information on the Internet. I learned not only English but also general knowledge.

(GA08)

當我看到有趣, 很酷, 或我不知道的東西時, 我會繼續往下搜尋, 學英文也學知識。

His description demonstrates that Google Assistant offered information-rich learning opportunities and materials, which encouraged active learning and promoted in-depth exploration of topics of interest. These inquiries into the unknown naturally increased the participants’ vocabulary and improved their oral performance.

As for the L1 group, the participants’ vocabulary scores improved significantly, and their content scores slightly improved. As the interview data showed, lack of accuracy and intelligibility of utterances were the two primary problems the participants experience in their interaction with L1 English speakers. The obstacles in communication seemed to start with a vocabulary item, one which had not been learnt or one which could not be easily recalled. To compensate the EFL learners’ lexical deficiencies, the L1 English speakers assisted them in finding the right word. Furthermore, to help EFL speakers overcome the problems in self-expression, the L1 English speakers would give complementary repair when they could predict and guess the remaining part of their partners’ unfinished utterance. These interactional moves develop the L1 group’s vocabulary knowledge of English.

The L2 group’s performance in content and vocabulary was consistent between the two tests. This results may have been caused by the language requirements and the interlocutors’ English proficiency. In interviews, when the researcher asked the participants about the ways they used to deal with communication breakdowns, they reported that switching to

L1, literal translation, and let-it-pass strategy were the most common strategies employed in peer interaction. The participants tended to use Chinese (L1) to continue conversations when they were stuck or use body language to convey what they wanted to say, as one participant explained:

English is foreign to us. It’s weird to speak English with my good friend, an EFL learners. When we got stuck, we used body language or Chinese (L1). In Chinese, we had lots to say. However, in English, our conversation was limited to a set of general topics, routine events, or trivial matters.

和我的好朋友講英文感覺很怪，英文對我們來講都是外語。遇到不會講的，就比手畫腳或中文。講中文我們有超多話題可聊，但講英文，我們就只聊一些和日常有關話題或瑣碎無聊問題。

It seems that the participants’ knowledge of L1 makes the meaning transfer easier without spending time searching for an L2 equivalent. In fact, the use of L1 knowledge seems an easy access strategy, and thus, of time-saving when used in L2 communication. Therefore, sometimes the participants translated a lexical item, a phrasal verb, an idiom or structure, word by word, and from L1 to L2 in communication. Other common strategies employed by EFL learners to handle their lack of linguistic resources to solve the problem of expressing a message: give up the message or change their original utterances (avoidance and reduction strategies). That is, the EFL learners left more lexical searches unresolved. Clearly, the difference between the L1 and L2 English interlocutors’ feedbacks had an impact on the participants’ vocabulary learning. As Payne and Whitney (2019) indicated, nonverbal communication is specific to human-human interaction and is often natural and instinctive rather than conscious. In human-only interaction, L2 learners can resort to a wide range of paralinguistic compensation strategies to convey their meaning. Once the learners understood their interlocutor’s communicative intention, they often proceeded to the next part of the activity.

In addition, some of the L2 English speakers were at a lower English proficiency level. They might not be able to resolve the linguistic problems or use a wide variety of language (Su, 2021). Therefore, they had little new language to contribute to the interacting process. Because of their decreased exposure to English input and fewer opportunities to practice output, the L2 group’s content and vocabulary scores only slightly improved.

# 5.3.  Pronunciation

The quantitative analyses revealed that through a semester’s worth of practice, the GA and L1 groups’ pronunciation scores improved significantly. By contrast, the L2 group’s pronunciation scores slightly decreased. The results support Xie, Chen, and Ryder (2021), who noted that a large amount of immediate feedback from L1 English or near-L1 English speakers is required to improve L2 learners’ pronunciation.

The GA group’s improvement in pronunciation is consistent with the findings of Dizon (2020) and Moussalli and Cardoso (2016, 2020), who demonstrated IPAs’ ability to improve learners’ pronunciation. In addition to exposing leaners to a large amount of high-quality oral input, Google Assistant provides learners with opportunities to practice input and output, and its multimodal presentation of feedback improved the GA group’s pronunciation. For example, when the participants’ utterances were not understood, Google Assistant provided implicit feedback (e.g. through a comment, question, silence, or incorrect response notification). In addition, during interactions, Google Assistant provided the participants with two types of feedback: aural and written. The written feedback was provided on-screen transcription of the interaction, which helped participants identify their errors. As Moussalli and Cardoso (2020) described, IPAs cannot become impatient or irritated, which helps learners to practice more: ‘Google Assistant was willing to participate in endless practice’. According to Gu et  al. (2021), immediate automated feedback is an effective method for improving learners’ pronunciation because it prompts them to identify their errors and self-correct.

A possible explanation for the L1 group’s improvement in pronunciation is that interaction with L1 English speakers exposed the participants to high-quality oral input and encouraged self-correction and self-directed learning (Ebadi & Ebadijalal, 2020). However, some participants reported that they were under pressure when interacting with L1 English speakers because they believed that their own English was ‘broken’ while their L1 English speaking-partners were ‘perfect speakers’ (Sato & McDonough, 2020).

By contrast, the L2 group’s pronunciation remained unchanged because of a lack of feedback and input. The participants reported that even when they were able to notice their peers’ pronunciation errors, they hesitated to provide corrective feedback because of their proficiency (e.g. distrust of each other’s linguistic abilities) and social relationship (e.g. face saving). They recognized that they shared a limited ability to converse in English with their peers, as one participant described: ‘English is foreign to both of us. We are not good at judging each other’s pronunciation’.

# 5.4.  Grammar

The L2 group’s posttest grammar scores were the highest, followed by those of the GA group and those of the L1 group. Although the GA group’s grammar scores improved, they tended to use simple grammatical structures, which revealed the nature of their interaction with Google Assistant. According to Moussalli and Cardoso (2020), ASR technology can only recognize sentences of a certain length; otherwise, the recognition rate decreases. Therefore, the interaction with Google Assistant must not have been complex.

The L1 group’s low grammar scores may be the result of L1 English speakers’ emphasis on content and meaning rather than on the accuracy of grammar. In line with Sato’s (2017) study, the extent to which L1 English speakers deliberately point out EFL learners’ grammatical errors seems to be low. The participants explained this phenomenon in terms of their perception that the L1 English speakers seemed to be more tolerant of the grammatical errors because their feedback was not intended to push the EFL learners to correct the errors. Their responses involved slower speech, more repetition, more questions, and greater willingness to allow a topic shift. The finding was in accordance with Jamshidnejad (2020) study that many L1 speakers’ reformulation moves were embedded in sentences which required other types of responses such as a topic continuation rather than modified output. Instead of excessively correcting learners’ language errors, L1 English speakers created a positive interactive atmosphere which allowed EFL learners to become more willingness to communicate in English (Lee, Lee, & Hsieh, 2019).

As for the L2 group’s significant improvement in grammar, the participants reported that they focused more on the grammatical accuracy and the accuracy of their speech while interacting with their peers. This result is consistent with that of Lee et  al. (2019), who indicated that EFL learners strive for grammatical accuracy in speech because of accuracy-oriented teaching and test-oriented curricula. At the same time, the participants told the researcher that they were able to listen to both their partner’s utterances and their own utterances when they were interacting with their learner partner; thus they noticed grammatical features more in peer interaction and worked collaboratively by giving each other corrective feedback. They employed more repairing and recasts (e.g. self-repetition, other-repetition, confirmation check). According to Sato (2017), peer corrective feedback benefits both providers and receivers. On the one hand, provision of corrective feedback entails detection of errors in the comprehension system, which may have a positive impact on interlanguage restructuring, but on the other, corrective feedback from other learners has the same function as teacher corrective feedback in that it enhances monitoring during production at the preverbal stage. This process of noticing in both comprehension and production, repeated practice of accurate forms, and thus, reducing the error rate contributes to proceduralization by storing correct linguistic representations in long-term memory (Ullman, 2016). However, such accuracy-oriented interaction might lead to learners’ communication anxiety for fear of making mistakes and losing face in front of peers, and, in turn, their willingness to communicate (Lee et  al., 2019).

The results indicated that the out-of-class use of Google Assistant can improve EFL learners’ oral proficiency in terms of fluency, content, pronunciation, vocabulary, and grammar. The qualitative findings shed further light on the quantitative results, offering reasons for such improvement, including exposing EFL learners to oral input that is abundant and of good quality, offering them ample opportunities to practice speaking with immediate feedback in a friendly environment, promoting motivation and confidence in L2 communication, and monitoring their self-directed language learning process beyond the classroom. In addition, more time spent interacting with Google Assistant might also contribute to the GA group’s better oral proficiency.

In particular, the interview data revealed that the effects of the intervention seemed to be greater for learners with lower oral proficiency beforehand. The results were similar to Tai and Chen (2020) study in that it is the lower proficiency EFL learners who benefited more from the application of Google Assistant. When communicating with Google Assistant, the participants, especially those with lower oral proficiency, became more confident with speaking English because Google Assistant provided multimodal feedback on screen, which made itself understood and helped them answer correctly. They showed fewer inhibitions and displayed less social anxiety. They tended to be more willing to exchange personal information with it and more honest in presenting their viewpoints. Based on the findings, it seems that an IPA-mediated learning environment may constitute a more relaxed atmosphere than a classroom. The social support and psychological benefits positively affect EFL learners’ willingness to communicate (Tai & Chen, 2020) and thus promoted oral proficiency.

On the other hand, several reasons may explain why the EFL learners with higher-proficient speaking skills made less improvement. First, the dialogue content might not be challenging enough for them because they could already speak good and fluent English. Given the current technology on ASR, the sentences for recognition are often within a limited length, otherwise the recognition rate will be sacrificed. Thus, the design of Google Assistant’ dialogues could not be very complex and thus not challenging for these learners. Therefore, there was little room for improvement.

This study has identified several obstacles related to technological problems that prevented the GA group from successfully using Google Assistant, such as recognition errors, irrelevant responses, and distraction.

For example, several participants who really struggled with their English pronunciation, perceived that communicating in English with Google Assistant was difficult because it had problems in accurately recognizing accented speech. IPAs’ deficiencies in fully comprehending language learners’’ utterances had already been reported by prior research (e.g. Dizon, 2020; Moussalli & Cardoso, 2020; Tai & Chen, 2020). According to Wu et  al. (2020), the speech recognition engines of IPAs, which are based on L1 English speaker speech models, often work better with L1 speakers than L2 speakers and hence are less tolerant of L2 speakers’ accented speech. The results of this study as well as of other studies indicate that achieving high mutual comprehensibility between IPAs and EFL learners remain challenging.

Finding L1 English speakers willing to participate was challenging for the L1 group because of the relatively smaller number of L1 English speakers in this university. What is worse, few of them were willing to interact with the participants weekly over a semester. Thus, the majority of the L1 group’s participants usually had to vary their interlocutors. Another challenge was scheduling meetings. Some participants explained that they had difficulty in finding time together because of their busy daily schedule. Therefore, their English interaction time (e.g. frequency and duration) decreased in the last few weeks. Similarly, the time limitations and difficulties enrolling interlocutors offered the L2 group fewer opportunities to interact and receive feedback.

# 6.  Conclusion

This study investigated the impact of the out-of-class use of IPAs (i.e. Google Assistant on smartphones) on EFL learners’ oral proficiency and the differences between IPA-human interaction and human-only interaction. The results demonstrated that Google Assistant significantly improved the EFL learners’ overall oral proficiency, with a more positive effect than that of interaction with a L1 English speaker.

The detailed analysis of the interviews demonstrated that the mobility and ubiquity of Google Assistant on smartphones increased learners’ exposure to high-quality English, provided opportunities for conversation with immediate, multimodal feedback, engaged learners in meaningful interactions in a stress-free environment, eliminated anxiety, and empowered EFL learners’ to improve their oral proficiency outside the classroom. Google Assistant switched between different modes of interaction (i.e. acting as an interlocutor, an interviewer, a narrator, a facilitator, and an entertainer), which allowed for the learners to engage in dynamic interactions as they would with L1 English speakers, which is essential for effective L2 learning (Long, 2017).

Although the L1 group encountered time constraints and the difficulty of enlisting L1 English interlocutors, their interaction with the L1 English speakers created an authentic environment for meaningful communication and provided essential foundational knowledge and an opportunity to receive immediate feedback and gain exposure to high-quality spoken English, which encouraged the learners to practice and engage in self-directed learning, thereby improving their oral proficiency, especially in terms of pronunciation.

From a pedagogical perspective, this study provided evidence in support of the use of IPAs in EFL learning. As Moussalli and Cardoso (2020) indicated, the use of IPAs can enable teachers to appropriately allocate resources, especially if the technology is used as an extension of the language classroom in combination with classroom-based interactive practices. Because EFL learners have few opportunities to use English meaningfully outside the classroom, Google Assistant is a helpful tool for facilitating authentic and flexible learning and can offer new mechanisms for meaningful interaction.

This study nevertheless had several limitations, which can be rectified in future research. The first limitation concerns a relatively small sample size, especially in the L1 group. The participants majored mainly in computer science, electrical engineering, and material science engineering, who might be highly gifted users of technology. In addition, there might be a volunteer effect because all of them volunteered for the study. Thus, it is recommended that future studies be undertaken with larger, more diverse samples to generate more substantial evidence and generalize the results to diverse EFL learners. The second limitation is the lack of control for the precise time-on-task and report on their interaction. The varying interactive time and report among the three groups might affect their oral proficiency. Such variables could be controlled as covariates in future research. The third limitation is that because this study explored the effect of Google Assistant on smartphones on oral proficiency, the results may not be generalizable to other IPAs. Additional studies should investigate a wider range of IPAs to develop a more comprehensive understanding of the effectiveness of IPAs in EFL learning. Such research can provide a more comprehensive understanding of the potential of IPAs to facilitate EFL learners’ learning and help practitioners make informed decisions regarding the integration of IPAs into curricula. Finally, for strong internal validity, it seems to be best to include a control group that doesn’t receive any treatment. Without this group, it’s harder to be certain that the outcome was caused by the experimental treatment and not by other variables such as the listening and speaking class per week. In order to substantiate the interpretations, future research can compare the effect of certain design features and components of IPA technology (e.g. gamification) on different populations (e.g. age, proficiency, and academic majors) and on other language skills in and outside the classroom. Additionally, peer leadership training should be incorporate into the design of the course. Future research could thus extend the present study to gain greater insight into EFL learners’ acquisition of oral proficiency through interacting with L2 interlocutors who have received leadership training.

# Disclosure statement

No potential conflict of interest was reported by the authors.

# Notes on contributor

Tzu Yu Tai is an Assistant Professor in the Center for English Education, National Tsing Hua University. She also teaches English in Taipei Municipal Hong Dao Junior High School. Her research interests include CALL and TESOL.

# ORCID

Tzu-Yu Tai $\textcircled{1}$ http://orcid.org/0000-0003-0506-9579

# References

Bashori, M., Hout, R., Strik, H., & Cucchiarini, C. (2020). Web-based language learning and speaking anxiety. Computer Assisted Language Learning. https://doi.org/10.1 080/09588221.2020.1770293   
Bibauw, S., François, T., & Desmet, P. (2019). Discussion with a computer to practice a foreign language: Research synthesis and conceptual framework of dialogue-based CALL. Computer Assisted Language Learning, 32(8), 827–877. https://doi.org/10.108 0/09588221.2018.1535508   
Carhill-Poza, A., & Chen, J. (2020). Adolescent English learners’ language development in technology-enhanced classrooms. Language Learning & Technology, 24(3), 52–69. 10125/44738   
Dizon, G. (2020). Evaluating intelligent personal assistants for L2 listening and speaking development. Language Learning & Technology, 24(1), 16–26. 10125/44705   
Ebadi, S., & Ebadijalal, M. (2020). The effect of Google Expeditions virtual reality on EFL learners’ willingness to communicate and oral proficiency. Computer Assisted Language Learning. https://doi.org/10.1080/09588221.2020.1854311   
Engwall, O., Lopes, J., & Åhlund, A. (2021). Robot interaction styles for conversation practice in second language learning. International Journal of Social Robotics, 13, 251–276. https://doi.org/10.1007/s12369-020-00635-y   
Fernández-Garcia, A., & Fonseca-Mora, M. C. (2019). EFL learners’ speaking proficiency and its connection to emotional understanding, willingness to communicate and mu s i c a l e x p e r i e n c e . Language Te a ching R e s e a r c h . h t t p s : / / d o i . org/10.1177/1362168819891868   
Gass, S. M., & Mackey, A. (2020). Input, interaction, and output in L2 acquisition. In Theories in second language acquisition (pp. 192–222). New York: Routledge.   
Goksel-Canbek, N., & Mutlu, M. E. (2016). On the track of artificial intelligence: Learning with intelligent personal assistants. International Journal of Human Sciences, 13(1), 592–601. https://doi.org/10.14687/ijhs.v13i1.3549   
Gu, L., Davis, L., Tao, J., & Zechner, K. (2021). Using spoken language technology for generating feedback to prepare for the TOEFL iBT® test: A user perception study. Assessment in Education: Principles, Policy & Practice, 28(1), 58–76. https://doi.org/ 10.1080/0969594X.2020.1735995   
Hanzawa, K. (2021). Development of second language speech fluency in foreign language classrooms: A longitudinal study. Language Teaching Research. https://doi. org/10.1177/13621688211008693   
Istrate, A. M. (2019). The impact of the virtual assistant on language classes. eLearning & Software for Education, 1(1), 296–301. https://doi.org/10.12753/2066-026X-19-040   
Jamshidnejad, A. (2020). The nature and functions of communication strategies in L2 oral communication. In Speaking english as a second language (pp. 229–251). London: Palgrave Macmillan.   
Kukulska-Hulme, A. (2019). Mobile language learning innovation inspired by migrants. Journal of Learning for Development, 6(2), 116–129. Retrieved from https://files.eric. ed.gov/fulltext/EJ1222911.pdf   
Lavalle, P. I., & Briesmaster, M. (2017). The study of the use of picture descriptions in enhancing communication skills among the 8-grade students. Learners of English as a Foreign Language, 9(1), 1–16. Retrieved from http://digitalcommons.nl.edu/ie/vo19/iss1/4   
Lee, C. (2021). 21st century communication 4: Listening, speaking, and critical thinking. National Geographic Learning.   
Lee, J. S., Lee, K., & Hsieh, J. C. (2019). Affective variables and willingness to communicate of EFL learners in in-class, out-of-class, and digital contexts. System, 82, 63–73. https://doi.org/10.1016/j.system.2019.03.002   
Long, M. H. (1996). The role of the linguistic environment in second language acquisition. In W. C. Ritchie & T. K. Bhatia (Eds.), Handbook of research on language acquisition (pp. 413–468). Cambridge: Academic Press.   
Long, M. H. (2017). Instructed second language acquisition (ISLA): Geopolitics, methodological issues, and some major research questions. Instructed Second Language Acquisition, 1, 7–44. https://doi.org/10.1558/isla.33314   
Mayer, R. E. (2017). Using multimedia for e-learning. Journal of Computer Assisted Learning, 33, 403–423. https://doi.org/10.1111/jcal.12197   
Montero Perez, M. (2022). Second or foreign language learning through watching audio-visual input and the role of on-screen text. Language Teaching, 55(2), 163–192. https://doi.org/10.1017/S0261444821000501   
Moussalli, S., & Cardoso, W. (2016). Are commercial ‘personal robots’ ready for language learning? Focus on second language speech. In S. Papadima-Sophocleous, L. Bradley & S. Thouësny (Eds.), CALL communities and culture–short papers from EUROCALL (pp. 325–329). P a r i s : Research-pusliching.net. https://doi.org/10.14705/ rpnet.2016.eurocall2016.583   
Moussalli, S., & Cardoso, W. (2020). Intelligent personal assistants: Can they understand and be understood by accented L2 learners? Computer Assisted Language Learning, 33(8), 865–890. https://doi.org/10.1080/09588221.2019.1595664   
Payne, J. S., & Whitney, P. J. (2019). Developing L2 oral proficiency through synchronous CMC: Output, working memory, and interlanguage development. Calico Journal, 20(1), 7–32. https://doi.org/10.1558/cj.v20i1.7-32   
Richards, J. C. (2015). The changing face of language learning: Learning beyond the classroom. RELC Journal, 46(1), 5–22. https://doi.org/10.1177/0033688214561621   
Sandeep, S. S. (2019). Learning English language through Amazon Alexa for Indian students. Journal of the Gujarat Research Society, 21(10), 619–622. Retrieved from http://gujaratresearchsociety.in/index.php/JGRS/article/view/711   
Sato, M. (2017). Interaction mindsets, interactional behaviors, and L2 development: An affective‐social‐cognitive model. Language Learning, 67(2), 249–283. https://doi. org/10.1111/lang.12214   
Sato, M., & McDonough, K. (2020). Predicting L2 learners’ noticing of L2 errors: proficiency, language analytical ability, and interaction mindset. System, 93, 102301. https://doi.org/10.1016/j.system.2020.102301   
Silva, A. B., Gomes, M. M., da Costa, C. A., da Rosa Righi, R., Barbosa, J. L. V., Pessin, G., de Doncker, G., & Federizzi, G. (2020). Intelligent personal assistants: A systematic literature review. Expert Systems with Applications, 147, 1. https://doi. org/10.1016/j.eswa.2020.113193   
Su, Y. (2021). Accepting invitations and offers in second language Chinese: Effect of proficiency on pragmatic competence in interaction. Journal of Pragmatics, 180, 11–149. https://doi.org/10.1016/j.pragma.2021.04.033   
Sydorenko, T., Daurio, P., & Thorne, S. L. (2018). Refining pragmatically-appropriate oral communication via computer-simulated conversations. Computer Assisted Language Learning, 31(1–2), 157–180. https://doi.org/10.1080/09588221.2017.139432 6   
Tai, T. Y., & Chen, H. J. (2020). The impact of Google Assistant on adolescent EFL learners’ willingness to communicate. Interactive Learning Environments. https://doi. org/10.1080/10494820.2020.1841801   
Ullman, M. T. (2016). The declarative/procedural model: a neurobiological model of language learning, knowledge, and use. In Neurobiology of language (pp. 953–968). Cambridge: Academic Press.   
Underwood, J. (2017). Exploring AI language assistants with primary EFL students. In K. Borthwick, L. Bradley & S. Thouësny (Eds.), CALL in a climate of change: Adapting to turbulent global conditions – short papers from EUROCALL 2017 (pp. 317–321). P a r i s : Research-publishing.net. https://doi.org/10.14705/rpnet.2017.eurocall2017.733   
Van den Berghe, R., Verhagen, J., & Oudgenoeg-Paz, O. (2019). Social robots for language learning: A review. Review of Educational Research, 89(2), 259–295. https:// doi.org/10.3102/0034654318821286   
Wu, Y., Rough, D., Bleakley, A., Edwards, J., Cooney, O., Doyle, P. R., Clark, L., & Cowan, B. R. (2020). See what I’m saying? Comparing intelligent personal assistant use for native and non-native language speakers [Paper presentation]. MobileHCI’20: 22nd International Conference on Human-Computer Interaction with Mobile Devices and Ser vices, October, Oldenburg Germany (p. 19) https://doi. org/10.1145/3379503.3403563   
Xie, Y., Chen, Y., & Ryder, L. H. (2021). Effects of using mobile-based virtual reality on Chinese L2 students’ oral proficiency. Computer Assisted Language Learning, 34(3), 225–245. https://doi.org/10.1080/09588221.2019.1604551   
Zarrinabadi, N., Lou, N. M., & Darvishnezhad, Z. (2021). To praise or not to praise? Examining the effects of ability vs. effort praise on speaking anxiety and willingness to communicate in EFL classrooms. Innovation in Language Learning and Teaching. https://doi.org/10.1080/17501229.2021.1938079   
Zhang, R., & Zou, D. (2021). A state-of-the-art review of the modes and effectiveness of multimedia input for second and foreign language learning. Computer Assisted Language Learning. https://doi.org/10.1080/09588221.2021.1896555

# Appendix A. Topics for google assistant-mediated interaction activity

<html><body><table><tr><td>Week</td><td>Topics for Google Assistant-mediated interaction activity</td></tr><tr><td>1</td><td>A Tv/Online program you enjoy</td></tr><tr><td>2</td><td>Hobby: music, playing computer games, sports</td></tr><tr><td>3</td><td>Partnership: friends, classmates, roommates</td></tr><tr><td>4</td><td>Family: family members, distribution of tasks</td></tr><tr><td>5</td><td>Studying: schools, subjects, professions</td></tr><tr><td>6</td><td>Place of living: country, city, town, house, building</td></tr><tr><td>7</td><td>Communication: internet (e-mail, Skype, chat), post, telephone (mobile, text message)</td></tr><tr><td>8</td><td>Traveling: countries, tourist attractions, transport</td></tr><tr><td>9</td><td>Health: Upgrading your life, eating, drinking</td></tr><tr><td>10</td><td>Culture: entertainment, theaters, museums,</td></tr><tr><td>11</td><td>Shopping: markets, department stores, clothing</td></tr><tr><td>12</td><td>Holidays and celebrations</td></tr><tr><td>13</td><td>Services: restaurant, hotel</td></tr><tr><td>14</td><td>Media: television, newspapers, magazines</td></tr></table></body></html>

# Appendix B. Oral proficiency test

# Part I Answering Questions

For questions 1 to 4, you will have 15 seconds to answer each question.   
For questions 5 to 8, you will have 30 seconds to answer each question.   
1. What are some things you are good at doing? How did you learn them?   
2. Do you often use humor when you communicate in English? Why, or why not?   
3. A good principle for life is to be kind to others. What is one principle you try to follow in your life?   
4. If you had the money and resources to start a project you liked, what would you do? Why?   
5. Talk about a time when you were scared. Did you learn anything from that fear? Why, or why not?   
6. Name one person who has been very influential in your life. In what ways did this person have an effect on you?   
7. Do you think media stories are more or less trustworthy than they used to be? Support your view.   
8. Most people see anxiety as negative. Are there any positives to this feeling? Explain your answer.

# Part II Picture Description

Look at the picture, think about the questions below for 30 seconds, and then record your answers for 2 minutes.

Hints:

1. What are the people in the picture doing?   
2. Why do you think they are doing this?   
3. Have you ever used such facilities in public places? Tell me about your experience.   
If you haven’t, would you like to?   
4. How are such facilities in public places helpful to people? Please explain.   
5. If you still have time, please describe the picture in as much detail as you can.

![](img/80b3763bfced3b3d127f141f33753f4c21c37db424b4169e53e10a5778c4c2e5.jpg)

Think about your answer(s) to the question(s) below for 2 minutes, and then record your answer(s) for 2 minutes. You may use your test paper to make notes and organize your ideas.

Appendix C. GEPT High-Intermediate level speaking test rating scale   

<html><body><table><tr><td>Band score</td><td>Raw score</td><td>Description</td></tr><tr><td rowspan="6">5</td><td rowspan="6">100</td><td>. Speaks fluently</td></tr><tr><td>Responses appropriately answer questions</td></tr><tr><td>Expresses himself clearly and in an organized manner</td></tr><tr><td>. Pronunciation, intonation correct and natural</td></tr><tr><td>Grammar correct and vocabulary used with facility While there are occasional errors, he can still communicate effectively.</td></tr><tr><td></td></tr><tr><td rowspan="4">4</td><td>80</td><td> Responses appropriately answer questions</td></tr><tr><td></td><td> Express himself, and can easily answer questions in general topics</td></tr><tr><td></td><td> Pronunciation, intonation generally accurate and natural</td></tr><tr><td></td><td>Knows enough vocabulary, grammatical structures to While there are still some errors in usage, these do not hinder communication</td></tr><tr><td rowspan="4">3</td><td rowspan="4">60</td><td>Able to answer questions to familiar topics</td></tr><tr><td>Although he doesn&#x27;t speak fluently, has a grasp of basic grammatical</td></tr><tr><td>structures and vocabulary. Some errors in pronunciation, intonation.</td></tr><tr><td></td></tr><tr><td rowspan="4">2</td><td rowspan="4">40</td><td>Errors sometimes influence communication</td></tr><tr><td>Does a fair job of answering questions on familiar topics Replies mostly in incomplete sentences.</td></tr><tr><td>Expression difficult; communication often hindered</td></tr><tr><td>Limited vocabulary and grammatical structures Numerous errors in</td></tr><tr><td rowspan="4">1</td><td rowspan="4">20</td><td>pronunciation, intonation. Only able to answer very simple questions</td></tr><tr><td></td></tr><tr><td>Ability to express himself extremely limited Communication difficult</td></tr><tr><td></td></tr><tr><td rowspan="2"></td><td></td><td>Vocabulary, grammatical structures insufficient</td></tr><tr><td></td><td>Many errors in pronunciation, intonation.</td></tr><tr><td>0</td><td>0</td><td>Unanswered</td></tr></table></body></html>

Note. Retrieved from https://www.lttc.ntu.edu.tw/e_lttc/E_GEPT /hi_intermediate.htm.

# Appendix D. Interview questions

1. Do you like to practice speaking with Google Assistant/L1 English speakers/non-L1 English speakers? Why?   
2. Do you think Google Assistant/L1 English speakers/non-L1 English speakers helpful for practicing and enhancing oral proficiency? Why (not)?   
3. Did you encounter any difficulties during your interaction with Google Assistant/ L1 English speakers/non-L1 English speakers?   
4. Are you going to interact with Google Assistant/L1 English speakers/non-L1 English speakers in future? Where and for what purposes?