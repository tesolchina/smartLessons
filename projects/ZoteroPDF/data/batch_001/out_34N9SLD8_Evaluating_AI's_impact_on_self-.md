# Evaluating AI’s impact on self-regulated language learning: A systematic review

Wenli-Li Chang , Jerry Chih-Yuan Sun

Institute of Education, National Yang Ming Chiao Tung University, No. 1001, Daxue Rd., East Dist., Hsinchu City 300093, Taiwan

# A R T I C L E I N F O

# A B S T R A C T

Keywords:   
Self-regulated language learning   
AI mediation   
Learning partner   
Systematic review

AI technology is reshaping language classrooms, prompting students to adopt flexible roles exhibiting linguistic competence and self-regulated learning (SRL) skills. Considerable studies explore the necessary integrated learning perspectives, emphasizing AI’s adaptive role as a mind tool. In AI-mediated language learning, the technology’s metacognitive importance enables stu dents to learn with AI as a partner, encouraging independent critical thinking. Within Zimmer man’s SRL model, AI as a mind tool is integrated for improving language students’ strategic employment in a cyclical process. A systematic review, following PRISMA protocols, examines the intersection of AI and self-regulated language learning (SRLL) over 2000–2022. Findings high light AI’s evolving role, predominantly through algorithms and systems, aiming for micro and macro integration. Interactive AI has not fully engaged in two-way directions, despite a familiar process approach in reviewed studies. In the favored ESL/EFL research context, task-specific AI is utilized to encourage cyclical improvement with learner autonomy enhancement mainly among higher education students at intermediate level or above. Pedagogical values are possible when major SRL phases are fully practiced, even without highly autonomous AI. Future research is directed toward adaptive personalized technology by exploring the dynamic interplay between AI technologies and SRLL as educational practices under Education 4.0 principles.

# 1. Introduction

In this modern, highly digitized society, language educational practices have been reshaped with extensive technology integration opportunities, morphing from learning from computers as content into learning with computers as partners. Despite the fact that language learners’ personal involvement level widely varies with their personality traits and positional categories in educational settings, this emergent phenomenon has been clearly identified in EDUCAUSE (2021, 2024) Horizon Report Teaching and Learning Edition, with great emphasis on adaptive, flexible, and personalized learning technologies in effective digital classrooms that assume primarily the form of artificial intelligence (AI), namely, the “leverag[ing] of computers and machines to mimic the problem-solving and decision-making capabilities of the human mind” (IBM Cloud Education, 2020). The conceptualization of such a digital “mind tool” or cognitive aid for not only language learners but learners in general follows Jonassen et al. (1999, 2000) as the underlying principle and flourishes with AI technology, through which the changing role of learners evolves in parallel, from passive receivers to active knowledge constructors, creative communicators, and computational thinkers, as explained by ISTE Standards (Crompton, 2017).

In an equally widened scope of language learning with digital technology as a mind tool, growing attention has focused on the facilitation of essential skills and competencies that move beyond fundamental language proficiency (i.e., “language learning skill areas, language subsystems”) to the inclusion of self-regulated learning (SRL) skills (i.e., “appropriate learning strategies for learning effectiveness”) (Zhou & Wei, 2018). In the current digital era, the SRL capacity becomes increasingly essential as language learners depend on digital platforms for education and SRL enables them to effectively manage their educational activities in the context (e.g., Zutiasari et al., 2024). By the common definition adopted in previous studies, SRL entails a cyclical process of metacognition, cognitive control, motivation, and strategic use of learning behaviors, which takes place within and beyond language classroom walls, therefore leading to learners’ self-initiation and continuous monitoring of technology use for learning (Lai & Gu, 2011). With the dynamic and ubiquitously supportive nature of adaptive technology, language learners who utilize such a “metacognitive tool” (Saadati et al., 2021) are able to experience a relatively high degree of learning autonomy (Lee, 2016), the beneficial aspects of which, examined with a mixed focus on both learning process and language performance, have been greatly emphasized over the past few decades (e.g., Liu et al., 2024; Shyr & Chen, 2018).

Indeed, AI technology for SRL in language classrooms manifests as the customized technical adaptation to learner minds in an essential role that provides personalized learning scaffolds, as highlighted in the 2021 Horizon Report. However, far too little has been done in joining and revisiting previous research efforts on the topic. This paper reviews AI integration in self-regulated language learning from 2000 to 2022, with focus on the technology’s impact on educational practice and skill development. Employing a standardized protocol, this review investigates AI’s effectiveness as a learning tool, analyzes its applications, study approaches, and educational influences, and considers cognitive aspects affecting AI in self-regulated language learning. The review questions aim to delve into not only the practical implementations and positioning of AI but also its extensive impact on contemporary educational frameworks and approaches. This comprehensive approach seeks to address the unresolved questions by exploring the following research inquires.

1. What AI technologies are used in self-regulated language learning classrooms?   
2. How is AI integrated and positioned relative to classroom participants in the context of self-regulated language learning?   
3. What methodologies are employed in empirical studies on AI in self-regulated language learning?   
4. How do study findings on AI in the context of self-regulated language learning align with broader shifts in education?   
5. Which cognitive and metacognitive factors are considered in evaluating AI’s effectiveness in self-regulated language learning   
outcomes?

# 2. Literature review

# 2.1. AI technology in language education

In the context of language learning, the trend for AI integration has received growing attention in academic research, as it has been widely accepted in a general educational setting and has thus gradually evolved into a necessary means for classroom participants (students and teachers) at the forefront. This ongoing trend of AI adoption is supported by recent studies (Daulay & Ginting, 2024; Karatas¸ et al., 2024), noting a significant increase within language education institutions. Table 1 summarizes AI use in language classrooms, organizing applications into key areas such as learning analytics and teaching support, while detailing their technology focus, specific tools, pedagogical focus, and performance indicators. Additionally, it differentiates AI applications employed at individual and institutional levels, aligning AI learning tools with individual usage and learning analytics with institutional settings, as specified by EDUCAUSE (2022). This adaptive and ubiquitous learning technology, though still in the early stages of its development, has evidently transformed into an inclusive digital tool that yields multifaceted benefits, encompassing both the micro level and the macro level. Liang et al.’s (2021) systematic review lent support to the facilitating role of AI in language education, highlighting the positive learning outcomes that learners achieved and researchers identified in their studies. These outcomes include not only the enhancement of cognitive skills, particularly strategies involved in reading and writing, but also affective and behavioral development, including technology acceptance, linguistic interaction, and L2 enjoyment (Wang et al., 2024). Zhao and Nazir (2022) further high lighted a significant review trend: the sustaining effectiveness of AI in enhancing language comprehension skills building and facil itating output training. Meanwhile, they suggest that the integration of individualized AI systems for language learning tools is still favored over an institutional level of commitment to curriculum examination and is continuously practiced for personal growth and development in mixed aspects (affect, behavior, cognition, and metacognition). Considering that the methodologies mainly consist of systematic reviews and case study analyses, which could introduce publication bias and limited generalizability due to selective in clusion of studies and context-specific results, these methods still present a broad perspective of AI’s pedagogical impact.

Table 1 Recent review articles on AI in language education.   

<html><body><table><tr><td>Individual-level AI application</td><td>Technology focus</td><td>Specific tool</td><td> Pedagogical focus</td><td> Performance indicator</td><td>Reference</td></tr><tr><td>Learning analytics</td><td>Machine translation (MT)</td><td>MT tool</td><td>Theoretical framework, main user</td><td>User attitude</td><td>Deng and Yu (2022)</td></tr><tr><td></td><td>Neural machine translation (NMT)</td><td>NMT tool</td><td>L2 pedagogy, skills training, FL learning</td><td>Proficiency level</td><td>Klimova et al. (2022)</td></tr><tr><td>Teaching support</td><td>Intelligent education system</td><td>Teaching assistant robot</td><td>Virtual learning, smart classroom</td><td>Development in mixed aspects</td><td>Zhao and Nazir (2022)</td></tr><tr><td>Data interpretation</td><td>Data mining and natural language processing (NLP)</td><td>NLP system, intelligent tutoring system</td><td>Skills and knowledge acquisition, classroom interaction</td><td>Affective development</td><td>Liang et al. (2021)</td></tr><tr><td>Automated interaction</td><td>Conversational agent</td><td>Chatbot, digital assistant</td><td>Context of use, virtual human agent design</td><td>User interaction, perception</td><td>Diederich et al. (2022)</td></tr><tr><td>Content evaluation</td><td>Machine learning, automated assessment</td><td>Automated essay scoring system</td><td>Assessment technique, content-based evaluation</td><td>Evaluation accuracy</td><td>Ramesh and Sanampudi (2021)</td></tr><tr><td>Inclusive learning environment</td><td>Smart learning environment</td><td>Analytical tool, mobile and social</td><td>Learner-oriented content, technology-supported</td><td>Socio-techno interaction and adaptability (engagement, interactivity, willingness)</td><td>Alfoudari et al. (2021)</td></tr></table></body></html>

According to Table 1, the multifaceted benefits are delivered to a widened range of participants in language classrooms, affecting both students and teachers. It is also revealed that AI-based, personalized scaffolds and supports are tailored to improve educational experiences for learners and teaching methodologies for educators, in parallel with their simultaneous learning to self-regulate and develop metacognitive abilities using an evaluative approach (e.g., Chen, 2024; Deng & Yu, 2022; Zhao & Nazir, 2022). The rapid AI evolution has also enabled the integrated educational practices to flexibly assign changing roles to the technology in language education (Novawan et al., 2024) where two primary forms are present in the context: AI algorithms and AI systems (Papadopoulos et al., 2020). Neural Machine Translation (NMT) tools (Klimova et al., 2022), conversational agents (Diederich et al., 2022), educational chatbots (Kuhail et al., 2022), and automated scoring systems (Ramesh & Sanampudi, 2021; Strobl et al., 2019) - these rich manifestations of AI technology in a language classroom have enhanced a personalized learning process, as highlighted in the recent research (Kaswan et al., 2024), and encouraged knowledge construction, creative communication, and an advanced, metacognitive level of computational thinking in the process.

The recent review articles on AI in language education reveal a wide array of technological integrations, ranging from machine translation tools discussed by Deng and Yu (2022) and Klimova et al. (2022), which highlight an expansion from evaluating user attitudes to measuring proficiency levels, to teaching support through intelligent systems by Zhao and Nazir (2022) and data inter pretation via NLP by Liang et al. (2021), which indicate a spectrum from direct instructional aids to analytical, behind-the-scenes operations. Studies such as Diederich et al. (2022) on conversational agents differs from Ramesh and Sanampudi (2021)’s focus on content evaluation through automated essay scoring, emphasizing user interaction over accuracy. Additionally, Alfoudari et al. (2021) explores smart learning environments for inclusive education, stressing the importance of engagement and adaptability. These articles collectively reveal a diverse application spectrum, from machine translation to smart learning environments, focusing on practical results and proficiency. Key themes include the evolution from user attitudes to measurable skills, diverse instructional strategies, and technology ranging from teaching assistant robots to automated scoring systems. This comparative synthesis of AI in language edu cation studies signifies a broadened trend where AI not only supports pedagogical approaches and technology-supported learning but also promotes assessment techniques and learner engagement. Later reviews expand these discussions and include in-depth evaluations of AI effectiveness in fostering interactional competence (e.g., Zhai & Wibowo, 2023), alongside comprehensive analysis of AI in classroom discourse (e.g., Wang et al., 2024), reflecting an ongoing intention to enrich language learning environments.

# 2.2. AI as language learners’ mind tool

A mental perspective in research appears necessary and urgent in facilitating the practice of AI integration as a cognitive aid, or “mind tool”—a digital application that promotes critical thinking about the subject matter, according to Jonassen et al.’s (1998), and is likely to expand across both individual and institutional levels to support language learners’ SRL development. The operational definition of a mind tool is enriched by incorporating the insights of Azevedo et al. (2006), which emphasize sophisticated scaffolding from either humans or technology greatly improves students’ conceptual understanding and self-regulatory behaviors. The highlighted potential of technology-based environments as metacognitive tools underlines the dual function of mind tools in aiding knowledge acquisition and cultivating learners’ skills in reflection, comprehension, and management of their educational activities. Following the thread of discussion, recent studies connect the innovative use of generative AI with advanced mental activities, thereby bringing improved learning effectiveness and metacognitive mastery (Chen, 2024; ElSayary, 2024).

Within the theoretical framework of Zimmerman’s (2000, 2002, 2009) model that attempts to explain the interactions bringing socio-cognitive influence on SRL, the concept of these teachable cyclical phases is utilized for identifying, assisting, and further evaluating language learners’ forethought, performance, and self-reflection at given learning tasks in a recursive process. The AI-mediated pedagogical practice of SRL, or SRLL (self-regulated language learning), as detailed by Yang et al. (2023), aligns closely with the widely accepted educational values of personalization inherent in this highly personalized technology, including profiling and prediction, assessment and evaluation, adaptive systems and personalization, and intelligent tutoring systems, as synthesized by Liang et al. (2021) and highlighted by Kaswan et al. (2024) with continued research efforts.

Previous review studies on the topic have shown the continued joint efforts to optimize AI technology for both individualized language learning tools and institution-wide analytical tools, but not necessarily in an effective role of mind tool that fulfills the needs at all three SRL phases: task analysis and self-motivation in forethought (phase 1), monitoring and controlling in performance (phase 2), as well as self-judgment and self-reaction in self-reflection (phase 3), as classified in the proposed model of Zimmerman’s (2000, 2002, 2009). The need for relevant training is emphasized by Klimova et al. (2022), who discovered this in their systematic review on

AI-based NMT tools for scaffolding and supporting the foreign language learning process. By their definition of essential SRL skills, monitoring strategies are significantly lacking and should be developed for improving students’ performance at utilizing the tools and at breaking through communication barriers (technology-wise and language-wise). Upon the highlighted personal category of pro ficiency level, the research suggested that strategy insufficiency grows as their language level decreases, though their overall review focus remained at merely one cyclical phase (performance) in Zimmerman’s (2000, 2002, 2009) SRL development model, lacking a whole-scale consideration of the other two phases of forethought and self-reflection, therefore leading to an underdeveloped process in the SRLL context (Yang et al., 2023).

The present review article differentiating itself from existing reviews with its specialized target of self-regulated learning, following established protocols and guidelines, providing a historical perspective on AI in language education, and delving into AI’s meta cognitive roles as a mind tool. This review article shows no sheer focus on assessing performance indicators but extends with considerations of the strategic and reflective aspects of language learning facilitated by AI, intended to offer comprehensive pedagogical insights aligned with Zimmerman’s SRL model. Overall, this article indicates a progression towards a deeper understanding of AI’s educational impact, especially regarding a comprehensive analysis of how AI technologies assist learners across the full self-regulation spectrum and in fostering autonomous and reflective language learning practices.

# 3. Methods

# 3.1. Data source and article selection process

With the research purposes and review objectives specified, the present study developed and registered a review protocol following the guidelines for Preferred Reporting Items for Systematic Review and Meta Analysis (PRISMA) (Moher et al., 2009). Fig. 1 illustrates the search process and provides information regarding the search strategy, data sources, and the adopted inclusion/exclusion criteria. On the topic of AI in SRL training in the context of language education, the Web of Science (WoS), an online journal search and indexing database, was utilized in September 2022 for scholarly publications dated within the time span of 2000–2022. This time span was selected to cover the rapid developments in AI technology and its educational use, aligning with the growth of SRL in language learning. A total of 52,271 results were initially identified for their relation to the search topic that was paraphrased in various related terms and displayed in the publication titles, abstracts, and author keywords, as shown in Fig. 2. Based on Liang et al.’s (2021) search keywords for articles on a broad category of AI in language education, this study developed its own set of keyword entries, with additional reference to Zimmerman’s (2000, 2002, 2009) SRL model, for a parallel search target in the selection process that further refined the search results to 2256 articles. The search strategy was designed to ensure a comprehensive yet targeted approach, utilizing WoS as a primary source for relevant scholarly works.

# 3.2. Eligibility criteria

Predetermined criteria were established for refining the selected articles and for completing the PRISMA-based systematic review protocol so as to carefully screen and analyze research on the given topic. As summarized in Table 2, the inclusion and exclusion criteria account for the removal of the 2191 selected articles that did not meet the previously determined document type (non-aca demic journal articles excluded) $( \mathbf { n } = 8 4 3$ ), research area (non-educational research excluded) $( \mathtt { n } = 1 3 4 5 )$ , WoS index (non-peerreviewed SSCI articles excluded) $( \mathtt { n } = 3 )$ ), and language for publication (only full-length, English articles included). The intentional exclusion of grey literature (e.g., conference papers, reports) aimed to prioritize the reliability of peer-reviewed academic sources for analysis. By the end of the search process, 65 articles were selected but further refined by excluding 43 studies set in the context of primary education, special education, and professional, field-specific training for science literacy, medical skills, and advanced computer programming. 22 articles were ultimately included for the present systematic review with a specific focus on SRL in secondary education language classrooms or above. This focus was chosen to highlight areas where SRL strategies are commonly researched and applied. Inter-reviewer consistency was achieved by engaging two experienced language teaching experts in the search process, one of whom was also an author. Both experts participated in a training session on the coding scheme and selection standards. After confirming the selected articles’ eligibility for the final analysis, a preliminary examination of a sample of articles was conducted to align the reviewers’ comprehension and application of the standards, thus ensuring consistency in their evaluations.

![](img/94a217dcd1ca681f0d6728786baa914602c67bac9a14134d06be57b23b5dda64.jpg)  
Fig. 1. Systematic review protocol.

![](img/16ec7a9ed00c55ae248b1923ec41cbad79b9fbbc8d4445cb8c992a183483ad34.jpg)  
Fig. 2. WoS search strategy and keywords used in the systematic review.

Table 2 Inclusion and exclusion criteria for the systematic review.   

<html><body><table><tr><td>Selection criteria</td><td>Inclusion criteria</td><td>Exclusion criteria</td></tr><tr><td>Document type</td><td>Peer-reviewed academic journals Empirical studies</td><td>Books, reports, proceeding papers, review articles Publication prior to 2000</td></tr><tr><td>Research area</td><td>Educational research Focus on language teaching and</td><td>Non-education foci Non-tertiary education, special education, professional training program in science, medical skills, and</td></tr><tr><td>WoS index</td><td>learning SSCI-indexed articles</td><td>computer programming Not specific to the field of social sciences</td></tr><tr><td> Language</td><td>English</td><td>Non-English</td></tr></table></body></html>

![](img/15ae8d32f4cf5c3036d18bfe208421941106c10f0b2676d6737f4c600a13493e.jpg)  
Fig. 3. Networked high frequency terms from publications on AI-mediated SRLL (upper left) vs. AI in language education (lower right): Titles, abstracts, and author keywords.

# 3.3. Data analysis

Following the previously mentioned data collection procedure, the selected articles on the topic of AI in SRLL were analyzed and coded using a reviewer-based content analysis approach, in combination with VOSviewer, a publication clustering tool for data visualization in terms of network, overlay, and density at an aggregate level, as well as a widened scale covering both AI in SRL and SRLL for further comparison (Fig. 3). The initial step in the content analysis involved instructing the reviewers on the coding scheme to guarantee consistent application across all articles. This training included detailed reviews of each coding category, practical coding exercises, and meetings to achieve consensus on any variances. As illustrated in Table 3, a coding scheme was developed and administered in analyzing the final selection of articles for considering the three major aspects: AI in use, research paradigm, and pedagogical implication in skills training. Underlying the code categories for analysis was Zimmerman’s (2000, 2002, 2009) SRL model, relating the mental aspect adopted mainly to AI-mediated SRLL outcomes manifested in language proficiency and meta cognitive self-regulation. This enabled the analysis framework to align SRL components (forethought, performance, self-reflection)

Table 3 Categories of coding scheme (adapted from Liang et al., 2021).   

<html><body><table><tr><td>AI technology defined</td><td>Empirical research explained</td><td>SRLL outcomes examined</td></tr><tr><td>[A] Involvement scale</td><td>[E] Year of publication</td><td>[M] Language proficiency</td></tr><tr><td>[A1] Micro (individual)</td><td>[E1] 2000-2005</td><td>[M1] Pronunciation</td></tr><tr><td>[A2] Meso (institutional)</td><td>[E2] 2006-2010</td><td>[M2] Grammar</td></tr><tr><td>[A3] Macro (governmental)</td><td>[E3] 2011-2015</td><td>[M3] Vocabulary</td></tr><tr><td>[A4] Mixed</td><td>[E4] 2016-2020</td><td>[M4] Listening</td></tr><tr><td>[B] Integration purpose</td><td>[E5] 2021-present</td><td>[M5] Speaking</td></tr><tr><td>[B1] For learning tools</td><td>[F] Target language</td><td>[M6] Reading</td></tr><tr><td>[B2] For learning analytics</td><td>[F1] English as L1</td><td>[M7] Writing</td></tr><tr><td>[B3] Combined</td><td>[F2] English as L2</td><td>[N] Self-regulatory phase</td></tr><tr><td>[C] Application type</td><td>[G] Learning purpose</td><td>[N1] Forethought</td></tr><tr><td>[C1] Analytical</td><td>[G1] General</td><td>[N1-a] Task analysis</td></tr><tr><td>[C2] Functional</td><td>[G2] Specific</td><td>[N1-a1] Goal setting</td></tr><tr><td>[C3] Interactive</td><td>[H] Learner profile</td><td>[N1-a2] Strategic planning</td></tr><tr><td>[C4] Textual</td><td>[H1] Language proficiency</td><td>[N1-b] Self-motivational beliefs</td></tr><tr><td>[C5] Visual</td><td>[H1-a] Primary</td><td>[N1-b1] Self-efficacy</td></tr><tr><td>[D] Interaction manner [D1] AI-to-student</td><td>[H1-b] Intermediate</td><td>[N1-b2] Outcome expectations</td></tr><tr><td>[D2] Student-to-AI</td><td>[H1-c] Advanced</td><td>[N1-b3] Task interest/value</td></tr><tr><td>[D3] AI-to-teacher</td><td>[H2] Education level</td><td>[N1-b4] Goal orientation</td></tr><tr><td>[D4] Teacher-to-AI</td><td>[H2-a] Secondary education</td><td>[N2] Performance</td></tr><tr><td>[D5] Mixed</td><td>[H2-b] Undergraduate school</td><td>[N2-a] Self-control</td></tr><tr><td></td><td>[H2-c] Graduate school</td><td>[N2-a1] Task strategy</td></tr><tr><td></td><td>[I] Research question</td><td>[N2-a2] Self-instruction</td></tr><tr><td></td><td>[11] Descriptive</td><td>[N2-a3] Imagery</td></tr><tr><td></td><td>[12] Relational</td><td>[N2-a4] Time management</td></tr><tr><td></td><td>[13] Causal</td><td>[N2-a5] Environmental structuring</td></tr><tr><td></td><td>[I4] Mixed</td><td>[N2-a6] Help seeking</td></tr><tr><td></td><td>[J] Duration of investigation</td><td>[N2-a7] Interest incentive</td></tr><tr><td></td><td>[J1] Short (8 wk)</td><td>[N2-a8] Self-consequence</td></tr><tr><td></td><td>[J2] Medium (9-16 wk)</td><td>[N2-b] Self-observation</td></tr><tr><td></td><td>[J3] Long (16 wk)</td><td>[N2-b1] Metacognitive-monitoring</td></tr><tr><td></td><td>[K] Sample size</td><td>[N2-b2] Self-recording</td></tr><tr><td></td><td>[K1] Small (10)</td><td>[N3] Self-reflection</td></tr><tr><td></td><td>[K2] Medium (11-30)</td><td>[N3-a] Self-judgment</td></tr><tr><td></td><td>[K3] Large (31)</td><td>[N3-a1] Self-evaluation</td></tr><tr><td></td><td>[L] Key findings</td><td>[N3-a2] Causal attribution</td></tr><tr><td></td><td>[L1] Positive</td><td>[N3-b] Self-reaction</td></tr><tr><td></td><td>[L2] Negative</td><td>[N3-b1] Self-satisfaction/affect</td></tr><tr><td></td><td>[L3] Mixed</td><td>[N3-b2] Adaptive/defensive</td></tr></table></body></html>

with the coding structure. Each reviewer, previously identified as two experienced language teaching experts (one author included) individually conducted coding and then collaboratively resolved discrepancies (such as categorization differences) through discussion in joint analysis meetings. This iterative process aimed to improve the validity and reliability of the coding results. Throughout the entire collection and analysis processes, the level of clarity and transparency was maintained, in determining the inclusion and exclusion criteria, in screening and extracting studies for analysis, as well as in ensuring consensus among reviewers, so as to reduce potential biases in a systematic review.

# 4. Results and discussion

# 4.1. General findings

This study aims to explore evolving definition of terms and concepts, research patterns, and pedagogical effects in relation to AImediated SRLL outcomes that are manifested in multiple aspects. Fig. 3 provides VOSviewer-generated, clustered and networked key terms from the 22 studies under review, contrasted with a network visualization generated at an early stage of the paper selection process when AI integration and language education were examined using a broader dataset of 2256 papers. The figure suggests an overall trend in exploring the AI potential as a learning tool, taking multiple forms (e.g., chatbot, gamification, deep learning, algo rithm) that appear highly consistent with the major types of adaptive AI technologies integrated for educational purposes (i.e., chatbot, expert system, intelligent tutor/agent, machine learning, personalized learning system and environment, visualization and virtual learning environment), as summarized in previous review studies (e.g., Zhang & Aslan, 2021). It is further suggested that such adaptive technology is integrated mainly for enhancing but not limited to language proficiency (e.g., essay, grammar, conversation, reading comprehension). Additional aspects in research are incorporated into this thread of discussion and include an affective and motiva tional perspective (e.g., anxiety, cognitive load), as well as a behavioral perspective (e.g., score, grade, discipline). Among the varied research perspectives, SRLL focus has further specified the favored form of integrating AI in language classrooms (i.e., feedback-based machine learning algorithms in the form of intelligent tutoring systems) for different learning outcomes, including self-efficacy, one of the fundamental mediators of metacognition and the triggering antecedents of a self-regulatory learning process.

A closer look at the figure that includes multiple sets of closely related nodes and concepts within the network suggests a pre liminary, exploratory attempt in this thread of discussion over AI for SRL development in language classrooms. The use of AI tech nology, as shown in the figure, is mainly manifested in the form of intelligent tutoring systems (AI systems), as well as the machine learning algorithm (AI algorithm). The purpose of using intelligent AI systems in language education is commonly associated with content knowledge building and construction, illustrated by the connections between ‘knowledge’ and ‘intelligent tutoring systems’ in Fig. 3. In contrast, machine learning algorithms, closely interconnected with ‘language,’ ‘feedback,’ and ‘self-efficacy’ nodes, are mainly employed to focus on developing specific skills crucial for language proficiency and self-confidence. With reference to Zim merman’s (1989) account for Bandura’s (1986) triadic reciprocality where feedback activates environmental self-regulation, as demonstrated in Fig. 3 by links between ‘feedback,’ ‘self-efficacy,’ and ‘language,’ the indispensable role of SRL is not only being emphasized for its existing essentiality in computer-mediated learning contexts (e.g., Azevedo, 2009) but is also likely to be enhanced through a feedback loop that most ideally directly targets individual students and becomes highly enactive, according to Schunk and Zimmerman (1994). In parallel consistency with Pintrich (2000) and Moos and Azevedo (2009) who view SRL with an extended focus on the positive learning loop that relies heavily on self-regulatory strategies and is enacted toward autonomous, goal-directed behavior, AI integration is strengthened and necessitated in its role of facilitating language learning with technology as a collaborative partner, as shown by the close link between ‘intelligent tutoring systems,’ ‘machine learning,’ and ‘language’ in Fig. 3. This integration encourages SRLL to be practiced at highly self-reactive and self-reflective phases and to transform AI into a self-regulating,

![](img/9489ded0f3a8a780409179b91d3c40ba03ec77a7de40755616e839ee8e333ab5.jpg)  
Fig. 4. Empirical studies on AI for SRLL and AI for language education, 2000–2022.

mind tool.

4.2. AI technology redefined: utilizations and positioning in SRLL contexts

Question 1. What AI technologies are used in self-regulated language learning classrooms?

Fig. 4 highlights empirical studies on AI in SRLL and general AI for language education over two decades using a focused subset of the 2256 studies and emphasizing trends in empirical research. Following the surging trend in exploring AI for language education from 2016 onward, the further attempts have continued and accelerated in the ensuing years when student-centered teaching and learning with intuitive networked partners and collaborators thrives as one core component of Education 4.0 (Harkins, 2008). Apparently, the extended purpose remains to examine AI as a mind tool for language learners’ SRL development, though at a comparatively slow pace. Positioned as a facilitator for growing metacognition and self-regulation in a learning process, AI technology is integrated into language classrooms with emphasis, placed by the selected articles under review, upon the provision of individual-level, student-directed scaffold and support: interactive $7 2 . 7 3 \%$ , analytical $2 2 . 7 3 \%$ , and textual $4 . 5 5 \%$ (as defined by Sarker, 2022 and illustrated in Fig. 5), among which domain-specific, narrow AI systems/programs (as defined by Searle, 1980), especially expert systems (as shown in Fig. 6), outweigh AI algorithms as focus in the application to language learning contexts. One primary cause is tied with the comparatively low involvement of researchers/language instructors of cross-disciplinary backgrounds that range across information and communication technology, as well as other professional domains, and is therefore unlikely to accelerate the technological, pedagogical, and content-specific practice of AI integrated into language classrooms.

Question 2. How is AI integrated and positioned relative to classroom participants in the context of self-regulated language learning?

For the establishment of an adaptive and personalized AI-enhanced environment, the ongoing implementation of this technology is evident in the research settings of the selected articles. Adopting classifications from Table 3 to provide context, Table 4 reveals that an instructional support system is reinforced and extended from teacher to student (mainly for leaning performance enhancement at $9 5 . 4 5 \%$ , or for system evaluation at $4 . 5 5 \%$ ). Categorized under interactive and mainly from AI to student, such AI incorporation is cast in a facilitative role of learning “through” technology, yet not to the extent of learning “with” technology as a two-way, interactive learning partner. Despite the wide variety of AI applications including scaffolding system for argument evaluation (Kim et al., 2022), chatbot for portfolio analysis (Hwang et al., 2022), and writing feedback system (Liu et al., 2021), a gap is still clearly observed from the present application of AI as Hinsen et al.’s (2022) definition of versatile helpers to its optimal, organizational-level participation as peers for innovation-producing Education 4.0 that prior studies (e.g., Harkins, 2008) emphasize the blurred teacher-student boundary line for learner autonomy. At this trend toward AI for language learning tools that begin to merge multiple functions of profiling and prediction, assessment and evaluation, adaptive systems and personalization, and intelligent tutoring systems, as highlighted by Liang et al. (2021), the lack of the desired student-to-AI interaction, as opposed to teacher-to-AI interaction or to the most commonly observed AI-to-human interaction, still emerges within the preference for interactive AI systems. This role of AI as an adaptive and flexible learning partner remains underexplored, namely, not fully interactive to the ideal level of fully activating and maintaining self-regulation.

An additional factor in the challenged adaptiveness and interactiveness in systems is related to AI integration for SRLL training that, in theory, should be embraced by educational institutions optimized with digital and intelligent technology (Schools of the Future, 2020) and, in practice, should comprise three phases (forethought, performance, self-reflection), as highlighted in Zimmerman’s (2000, 2002, 2009) SRL model. However, most of the selected empirical studies appear to support one single phase at a language class:

![](img/c1dd3b5bd898f3a12b496e710433a0283df383ef05ffdedf637b129bb9e5c1a8.jpg)  
Fig. 5. Types of AI integration in empirical studies on AI for SRLL, 2000–2022.

![](img/7fe0554df95344758396793389ee9b5e9fc29d86f1b1a05ce88823830d26e8b7.jpg)  
Fig. 6. Primary forms of interactive AI applications.

pre-thinking (e.g., Hew et al., 2022; Liu et al., 2014), learning performance (e.g., Nelson Jr, 2011), or personal reflection (e.g., Chen et al., 2013; Liu et al., 2021), lacking an ideal underlying holistic approach that encourages continued efforts in an optimal cyclical progression (e.g., Chu et al., 2022). In other words, from the socio-cognitive perspective, given that the interacting learning factors (person, behavior, environment) are fundamental to the adopted SRL model, their seemingly weakened triadic causation may cause difficulty in ensuring the necessary dynamic interplay, thereby bringing down the anticipated self-influence. The selected AI systems and algorithms for SRLL tools have also been confined to limited, narrow AI alternatives (NLP, chatbot, expert system, intelligent tutoring system, automated feedback, resource recommender), and therefore demand further exploration in this thread of discussion.

4.3. Empirical research explained: study design and key outcomes on AI in SRLL

Question 3. What methodologies are employed in empirical studies on AI in self-regulated language learning?

The selected papers under systematic review have shown an obvious trend in navigating the AI-enhanced ESL/EFL context $( 9 0 . 9 1 \% )$ where the target English language is not students’ primary language option in their everyday life. Ranging from generalpurpose to domain-specific, these experimental language programs, facilitated by AI technology (mainly narrow and task-specific), are intended for developing language skills and strengthening language awareness in terms of different language aspects, mean while sharing a research attempt at the methodological frameworks used to address existing language teaching or learning difficulties $( 6 8 . 1 8 \% )$ , or to examine system design $( 3 1 . 8 2 \% )$ ) in relation to overall curriculum. Among the varied language foci, as shown in Fig. 7, writing skills instruction is most offered $( 4 0 . 9 1 \% )$ , followed by vocabulary building $( 2 7 . 2 7 \% )$ that is commonly implemented in parallel with skills training (both receptive and productive). Skills-based language curriculum, as opposed to knowledge-based one, appears to gain continued attention in the ESL/EFL context and very likely thrive in its strong consistency with the global trend toward multi-faceted competency development (e.g., Moser, 2015).

A further look makes it clear that, in the recent decade, skills integration has become an increased methodological emphasis in instructional/experimental design and implementation (growing by $3 6 . 3 6 \%$ , as opposed to the previous decade), meanwhile extending the attempts to include thinking skills and strategies as additional, high-order targets (e.g., Butterfuss et al., 2022; Chen et al., 2013; Hew et al., 2022; Liu et al., 2021; Roscoe et al., 2019), as summarized in Table 5. It is further indicated that AI significantly supports the development of SRL across various language skills, with applications ranging from writing and vocabulary to speaking. These AI tools enhance planning, monitoring, and evaluation phases of SRL, enabling students to actively engage and improve autonomously in language learning. The language learning context highlighted in the studies of the same recent ten years has also grown in its provision of purposeful, domain-specific language practices, compared to general purposes (e.g., Aslan et al., 2014; Chen et al., 2013; Chu et al., 2022; Crossley & McNamara, 2013; Liu et al., 2014; Wiechmann & Kerz, 2014). The target ESL/EFL students in the selected studies of the same time period share common features in learner profiles, especially in terms of their language proficiency and education background: higher-education students $( 6 1 . 5 4 \% )$ , nearly half of whom are advanced, proficient language learners (e.g., Aslan et al., 2014; Chen et al., 2013; Kim et al., 2022). The sample size of these studies with human participants has also reached an average of 33 students toward a statistically meaningful, large-scale design in each experiment combined with control group per formance for comparison and further examined in a pretest-posttest design. The average length of research study extends, from the previous decade, to a semester of 2–3 months-time (medium duration time), or is divided into multiple sections/sessions of one-class time (e.g., Butterfuss et al., 2022; Kim et al., 2022).

Question 4. How do study findings on AI in the context of self-regulated language learning align with broader shifts in education?

Almost all of the empirical studies under review contribute to the research topic with positive findings and lend strong support to the advantageous facilitating role of AI in a language classroom. Among these studies, causal research design prevails at a significant percentage of $5 9 . 0 9 \%$ , reflecting a broader educational trend toward establishing more scientifically rigorous methodologies for exploring AI’s educational impacts. Relational design follows at $2 2 . 7 3 \%$ , and descriptive research, which establishes no direct causal relationships among factors and variables, constitutes $1 8 . 1 8 \%$ . These evolving research efforts positively respond to the accelerating trend toward education in AI, by AI, and for AI at an extended, macro level (UNESCO, 2022; Zhang & Aslan, 2021), though education studies of (narrow) AI still obtain the greatest research attention for optimal (language) learning conditions. The overall evolving waves of AI, from the earliest stage of Internet AI to the latest autonomous AI (as defined by Lee, 2018), are accommodated in such a continued research attempt for the highlighted purpose of confirming connection and further clarifying, in proper design, causality among the key elements of triadic reciprocality (language learner, self-regulated behavior, AI-enhanced environment), as explained in the underlying model (i.e., Bandura, 1986; Zimmerman, 1989) but refined for an SRLL context with AI integration. These selected studies have also demonstrated great educational values with practical pedagogy explained, though the actual practice of AI integration for SRLL, being detailed in the selected articles, does not necessarily lead to fully supportive scaffolded instruction. For the most ideal cyclical improvement of student learning, a key stage of removing scaffold (AI technology) is necessary, and therefore an optimized language learning process is still expected, in which researchers fully explore the mental aspects and students become their own agents and self-regulators.

Table 4   

<html><body><table><tr><td colspan="6">Al techmoiogy Itegrauon m language classroonis.</td></tr><tr><td>Reference</td><td>Purpose of AI integration</td><td colspan="2">Form of AI application: System (+algorithm)</td><td>Type of AI application</td><td>Manner of interaction</td></tr><tr><td>Kim et al. (2022)</td><td>Evaluate written arguments Present alternative writing examples</td><td colspan="2">AI-supported scaffolding (AIss) system (+NLP)</td><td>Interactive</td><td>Facilitative AI to student</td></tr><tr><td>Butterfuss et al.</td><td>Integrate automated writing evaluation into an intelligent tutoring system</td><td colspan="2">Writing Pal (W-Pal) system</td><td></td><td></td></tr><tr><td>(2022) Hwang et al.</td><td>Facilitate individual intents based on students&#x27;</td><td colspan="2">Smart UEnglish chatbot app as an expert system</td><td></td><td></td></tr><tr><td>(2022) Chu et al.</td><td>portfolios data Incorporate teacher intelligence into digital</td><td colspan="2">Self-regulated English Vocabulary game (SR-EVG)</td><td></td><td></td></tr><tr><td>(2022) Hew et al.</td><td>games using SRL approach Support student goal setting and social presence</td><td colspan="2">expert system</td><td></td><td></td></tr><tr><td>(2022)</td><td>in online activities</td><td colspan="2">SMART chatbot, learning buddy chatbot</td><td></td><td></td></tr><tr><td>Ni and Cheung (2022)</td><td>Predict continuance intention to use and actual use of ITSs using extended Technology</td><td colspan="2">Bosom and Smart Learning (BLS) intelligent tutoring system</td><td></td><td></td></tr><tr><td>Aslan et al.</td><td colspan="2">Acceptance Model (TAM)</td><td colspan="2"></td><td></td></tr><tr><td>(2014)</td><td colspan="2">Model academic achievement in foreign language teaching</td><td colspan="2">Machine learning based student modeling middleware with Bayesian networks</td><td></td></tr><tr><td>Nam et al.,</td><td colspan="2">Represent and model temporal patterns of</td><td colspan="2">Adaptive intelligent tutoring system (ITS)</td><td></td></tr><tr><td>2018</td><td colspan="2">student engagement in language learning</td><td colspan="2"></td><td></td></tr><tr><td>Liu et al. (2021)</td><td colspan="2">Incorporate a reflective thinking promoting mechanism</td><td colspan="2">AI-supported automated writing feedback</td><td></td></tr><tr><td>Chen et al.</td><td colspan="2">Provide supporting mechanisms in an intelligent</td><td colspan="2">Faded personalized prompts and feedback</td><td></td></tr><tr><td>(2013) Roscoe et al.</td><td colspan="2">tutoring system Provide appropriate and adaptive practice</td><td colspan="2">Writing Pal tutoring system</td><td></td></tr><tr><td>(2019)</td><td colspan="2">opportunities in multiple forms Provide a dynamic environment for English</td><td colspan="2">Adaptive hypermedia-based English learning system</td><td></td></tr><tr><td>Lo et al. (2004)</td><td colspan="2">learning</td><td colspan="2">for preposition (HELP)</td><td></td></tr><tr><td>Hsieh et al.</td><td colspan="2">Enhance extensive reading habit and memory</td><td colspan="2">Personalized article recommendation system (+</td><td></td></tr><tr><td>(2012)</td><td colspan="2">cycles of words</td><td colspan="2">fuzzy inference, memory cycle update, analytic</td><td></td></tr><tr><td></td><td colspan="2"></td><td colspan="2">hierarchy process/AHP)</td><td></td></tr><tr><td>&lt;!-Col Count:5-&gt;Chen et al., 2008</td><td colspan="2">Provide an effective and flexible learning environment using adaptive recommender</td><td colspan="2">Personalized intelligent mobile learning system (PIMS) (+ Fuzzy Item Response Theory/FIRT)</td><td>(Interactive)</td></tr><tr><td>Wiechmann and Kerz (2014)</td><td colspan="2">Model L2 written production using multiple cues</td><td colspan="2">Ensemble machine learning models for adaptive</td><td>Analytical</td></tr><tr><td>Kapelner et al. (2018)</td><td colspan="2">Predict informativeness of a context for target words.</td><td colspan="2">boosting, random forest technique Adaptive and intelligent educational systems</td><td></td></tr><tr><td>Nelson Jr, 2011</td><td colspan="2">using a statistical learning approach Explore attentional mechanisms in second language</td><td colspan="2">Adaptive Resonance Theory (ART) neural network</td><td></td></tr><tr><td></td><td colspan="2">lexical learning and memory</td><td colspan="2"></td><td></td></tr><tr><td>Liu et al. (2014)</td><td colspan="2">Support writing with automatically generated generic trigger questions</td><td colspan="2">Learning-to-rank based AQG system (+NLP)</td><td></td></tr><tr><td>Ha and Nehm (2016)</td><td colspan="2">Explore misspelled words and computer-based scoring accuracy</td><td colspan="2">Automated computerized scoring systems (ACsSs) (+ machine learning)</td><td></td></tr><tr><td>Crossley and McNamara</td><td colspan="2">Model human judgements of speaking proficiency in</td><td colspan="2">Automatic Scoring Technique (AST) system for text</td><td></td></tr><tr><td>(2013) He et al. (2009)</td><td colspan="2">L2 speech samples Improve summary grading performance using</td><td colspan="2">analysis and scoring Intelligent assessment and tutoring system (+LSA-n-</td><td></td></tr><tr><td></td><td colspan="2">computer-assisted assessment</td><td colspan="2">gram ensemble)</td><td></td></tr><tr><td> Jiang et al. (2022)</td><td colspan="2">Facilitate oral complexity, accuracy, and fluency using flipped classroom approach</td><td colspan="2">Mobile-based dictation automatic speech recognition (ASR) application</td><td>Textual</td></tr></table></body></html>

![](img/3925103464a1b6c7c78aa2c3b46ecad6fb992b297c61108f3d2f723998b14059.jpg)  
Fig. 7. Skills focus in empirical studies on AI for SRLL, 2000–2022.

4.4. AI’s effectiveness in SRLL examined: self-regulatory phases and educational practices

Question 5. Which cognitive and metacognitive factors are considered in evaluating AI’s effectiveness in self-regulated language learning outcomes?

As empirical findings and discussion vary according to the underlying theoretical frameworks, language learning outcomes in the AI-mediated context are diversely interpreted across the selected empirical studies. The adoption of psychological perspectives is not uncommon, as further explained in Fig. 8 that reveals a prevalent process-oriented approach aligning with socio-cognitive theory. The learning outcomes, particularly from recent studies (2011–2020), illustrate diverse mental processes fostered by AI, encompassing enactivism (e.g., Hwang et al., 2022), community-building within learning environments (e.g., Chen et al., 2013), and scaffolded learning (e.g., Butterfuss et al., 2022; Kim et al., 2022). Other critical areas include learning engagement (e.g., Nam et al., 2017), metacognitive development (e.g., Liu et al., 2014), self-motivation (e.g., Aslan et al., 2014), self-regulation (e.g., Chu et al., 2022; Hew et al., 2022) in flipped classroom (e.g., Jiang et al., 2022), and self-determination (e.g., Roscoe et al., 2019) in double-loop learning (e. g., Liu et al., 2021). Additional theoretical insights are drawn from system designs based on item response theory (e.g., Chen et al., 2006), adaptive resonance theory (e.g., Nelson Jr, 2011), and analytical frameworks utilizing statistical learning methods (e.g., Kapelner et al., 2018), alongside assessments of user adaptation through the technology acceptance model (Ni & Cheung, 2022). Instructional designs incorporate communicative strategies (e.g., Lo et al., 2004) and experience-based learning approaches (e.g., Wiechmann & Kerz, 2014), and are implemented within domain-specific educational frameworks that guide curriculum planning (e.g., Ha & Nehm, 2016).

Following Zimmerman’s (2000,2002, 2009) SRL theoretical approach to AI-enhanced language learning, the three primary cyclical phases (forethought, performance, self-reflection) are examined in the empirical studies with focus on the inclusion of AI as an effective mind tool for SRLL. This role of AI for language learning tools encourages higher-order metacognition in learning strategy use (goal setting, monitoring, self-reflection) and is manifested as clearly announced instructional focus in up to $2 2 . 7 3 \%$ of the selected empirical studies, all of which are publications in the recent decade (2011–2020). Empirical evidence from the reviewed studies clearly exhibits AI’s significant support to SRLL by improving learners’ capability to set goals, monitor progress, and adjust strategies autonomously, which affirms AI’s role as a ‘mind tool’ that engages and empowers students’ effective management of their own learning processes. This growing awareness of necessary SRL training in language classrooms clearly benefits from AI as trending solutions in education (i.e., AIED), though multiple challenges and self-directed learning opportunities emerge at the same time (Pinkwart, 2016) and therefore explain the inevitably changing relationship of (language) education within AI, further facilitated by AI, and even in a progressive cycle for improving AI. Fig. 9 summarizes all research attempts discovered in the studies for the facilitation of learner-centered language teaching and learning but reveals no proportionally widened focus on self-regulation strategies (not mutually exclusive): goal setting, $1 8 . 1 8 \%$ ; self-efficacy, $1 8 . 1 8 \%$ (among all of the coded strategies that support the phase of forethought); metacognitive monitoring, $4 0 . 9 1 \%$ (the phase of performance); self-reflection, $3 1 . 8 2 \%$ (the phase itself), as opposed to a full-scale inclusion of all self-regulatory phases $( 9 . 0 9 \% )$ and to a partially mixed perspective $( 1 8 . 1 8 \% )$ ).

For effective pedagogical practices, AI integration in learner-centered language classrooms requires practical implementation in stages for multiple and ongoing cycles of improvement, just as the adaptive AI technology itself, through higher-order thinking, problem-solving, decision-making, is constantly evolving into a fully context-aware, self-optimized (and most ideally, strong and autonomous AI) system or program (Chen et al., 2020). At each empirical stage of AI integration and implementation for self-regulated language learning, the overall efficiency is mostly examined for addressing existing teaching and learning difficulties, as previously mentioned, with consideration of linguistic performance and strategic employment that is demonstrated or observed as a determinant in a learning cycle. This cyclical progression should also be encouraged when narrow, task-specific AI only is utilized but appropriated according to its functionality. Conversational agent, for example, helps students to preview and generate forethoughts on course topics for pre-class preparation (Diwanji et al., 2018); knowledge graph, to visualize and organize individual and group-based output for monitoring during-the-class performance (Chen & Tsao, 2021); and learning dashboard, as built in a class or learning management system, to reflect on personal progress at different phases in learning for improvement in cycle (Chen & Chen, 2009).

<html><body><table><tr><td colspan="8">Table 5 Empirical study design and major outcome.</td></tr><tr><td colspan="8">Studies intended to address existing language teaching or learning difficulties</td></tr><tr><td rowspan="2">Ref.</td><td rowspan="2">Instruction focus</td><td rowspan="2">Learning purpose</td><td>Learner profile</td><td rowspan="2">Size</td><td colspan="2"> Research design</td><td>Finding</td></tr><tr><td>Background</td><td>Duration</td><td>Data</td><td></td></tr><tr><td>Butter-fuss et al., 2022</td><td>Persuasive essay, writing strategy</td><td>General</td><td>Higher/lower literacy skills; high school students</td><td>56</td><td>Course of 4 training</td><td>Pretest- posttest</td><td>Causal</td></tr><tr><td>Hwang et al. (2022)</td><td>Oral conversa-tion, lexical resources</td><td>General</td><td>6th-grade elementary school students</td><td>23, 20</td><td>sessions 10 weeks</td><td>Control group design</td><td></td></tr><tr><td>Jiang et al. (2022)</td><td>Oral fluency, accuracy</td><td>General</td><td>Undergraduate freshman students</td><td>160</td><td>14 weeks</td><td>Control group design</td><td></td></tr><tr><td>Liu et al. (2021)</td><td>Reflective thinking, online writing</td><td>General</td><td>Undergraduate-level EFL learners</td><td>53, 50</td><td>4 weeks</td><td>Control group design</td><td></td></tr><tr><td>Roscoe et al. (2019)</td><td>Essay writing, writing strategy</td><td>General</td><td>Native speakers; high school students</td><td>163</td><td>3 phases in 2-h</td><td>Pretest-</td><td></td></tr><tr><td>Hsieh et al.</td><td>Extensive reading, vocabulary</td><td>General</td><td>University sophomore</td><td>30, 30</td><td>session 4 months</td><td>posttest Control group design</td><td></td></tr><tr><td>(2012) Kim et al. (2022)</td><td>Argumen-tative writing</td><td>Academic, discipline-</td><td>students Proficient tertiary students</td><td>6, 8 (by course</td><td>2 sections of online course</td><td>Mixed method</td><td></td></tr><tr><td>Chu et al.</td><td>Vocabulary</td><td>specific</td><td>Novice learners; college</td><td>section) 22, 22</td><td></td><td>Pretest-</td><td></td></tr><tr><td>(2022) Aslan et al.</td><td>building Grammar-based</td><td>Business Academic</td><td>students Turkish students</td><td>23, 23</td><td>4 weeks 8 weeks</td><td>posttest Pretest-</td><td></td></tr><tr><td>(2014) Chen et al.</td><td>achieve-ment test Reflective writing</td><td></td><td>University level preparation College-level English</td><td></td><td></td><td>posttest</td><td></td></tr><tr><td>(2013) Chen et al.,</td><td>News reading,</td><td>Academic</td><td>majors</td><td>70</td><td>3.5 months</td><td>Repeated measures</td><td></td></tr><tr><td>2008 Hew et al.</td><td>vocabulary Goal setting,</td><td>Topic-specific</td><td>3rd-grade university students Post- and under- graduate</td><td>15 29, 38 (by</td><td>5 weeks</td><td>Pretest- posttest</td><td></td></tr><tr><td>(2022) Ni and Cheung</td><td>listening</td><td>General</td><td>university students</td><td>study 1, study 2)</td><td>Preclass time, 2 weeks of class</td><td></td><td>Relational</td></tr><tr><td>(2022) Nam et al.,</td><td>Composi-tion writing</td><td>General</td><td> Secondary senior students</td><td>528</td><td>One-semester term</td><td>CFA, SEM</td><td></td></tr><tr><td>2018 Lo et al. (2004)</td><td>Vocabulary training</td><td>General</td><td>Native speakers; middle schoolers (4th-6th grade) 5-8 years of English</td><td>33</td><td>2 parts of tasks</td><td>Modeling methods</td><td></td></tr><tr><td></td><td>Preposition learning</td><td>General</td><td>instruction; university students</td><td>39; 26, 23</td><td>40 min</td><td>Control group design</td><td></td></tr><tr><td colspan="8">Studies intended to examine system design in relation to overall curriculum</td></tr><tr><td>Ref.</td><td>Instruction</td><td>Learning</td><td> Learner profile</td><td></td><td> Research design</td><td></td><td>Finding</td></tr><tr><td></td><td>focus</td><td>purpose</td><td>Background</td><td>Size</td><td>Duration</td><td>Data</td><td></td></tr><tr><td>Ha and Nehm (2016)</td><td>Spelling errors</td><td>General</td><td>Non-/native speakers</td><td>459, 1529 (entries)</td><td>2 studies</td><td>Case study</td><td>Causal</td></tr><tr><td>He et al. (2009)</td><td>Summary writing </td><td>Exam-</td><td>Secondary school; Mid-Year Examination</td><td> 50 (summa-</td><td>-</td><td>Text analysis</td><td></td></tr><tr><td>Nelson Jr, 2011</td><td>Lexical learning</td><td>specific General</td><td>English-Spanish bilinguals; early</td><td>ries) 735 (words)</td><td>-</td><td>Corpus</td><td>Relational</td></tr><tr><td>Kapelner et al.</td><td>Vocabulary</td><td>General</td><td>and adult L2 learners Middle school to college level;</td><td> 1000 (words)</td><td></td><td>approach Corpus-based</td><td>Descriptive</td></tr><tr><td>(2018) Wiech-mann et al.,</td><td>learning Expert writing</td><td>Academic</td><td>Internet users German advanced learners; 2nd-</td><td>50 (term</td><td>-</td><td>scale rating Control-group</td><td></td></tr><tr><td>2014 Liu et al. (2014)</td><td>Critical review</td><td>Academic</td><td>and 3rd-year language majors University-level advanced</td><td>papers) Citations</td><td>-</td><td>design Ranking</td><td></td></tr><tr><td></td><td>writing</td><td></td><td>writers</td><td></td><td></td><td></td><td></td></tr><tr><td>Crossley &amp; McNamara,</td><td>Spoken responses</td><td>TOEFL- Specific</td><td>TOEFL-iBT participants from around the world</td><td>244 (samples)</td><td>6 speaking tasks</td><td>Text analysis</td><td></td></tr></table></body></html>

![](img/c840f5223d176e7f33c8164e387f1baecbf3042a9abd1bb614da3daadf0f30f5.jpg)  
Fig. 8. Focus in explaining AI-enhanced language learning.

![](img/626f6e09ee975a11af81ff9ed6154d2c9e2f3ffbcb938aff1a5827474b2113fa.jpg)  
Notes: \*of each forethought strategy covered (goal-setting, self-efficacy); \*\*of metacognitive monitoring   
Fig. 9. Self-regulatory phases covered in the empirical studies on AI for language learning, 2000–2022.

# 5. Conclusion

The present review explores the use of various AI technologies in SRLL classrooms, including machine translation and intelligent tutoring systems, highlighting their integration and positioning as facilitative tools within the classroom environment. This exploration is further driven by inquiries into the methodologies employed in empirical studies on AI in SRLL, including data mining and user interaction analysis. The findings connect AI’s role in language learning with broader educational trends, emphasizing a significant shift towards more adaptive and personalized learning experiences. This review further highlights cognitive and metacognitive factors as crucial in evaluating AI’s effectiveness, meanwhile emphasizing how these technologies support the cyclical processes of self-regulated learning.

# 5.1. Implications for practice

As the digital tool that “[t]o little surprise […] returns in 2021 as a key technology” (EDUCAUSE, 2021), AI has progressed in its adaptive and personalized nature that comprises a smart learning environment, especially in the context of higher education. Given that AI applications in educational settings have been commonly associated with language instruction (Demir, 2021), meaningful language learning is highly expected to be achieved with the joint research efforts intended for the optimization of language learning context where digital technology becomes adaptively interactive, as in the position of an understanding and supportive learning partner. Effective integration strategies include the use of AI for real-time language feedback, personalized learning paths based on student performance data, and interactive simulations for language skills training, as demonstrated in empirical cases by the Smart UEnglish chatbot (Hwang et al., 2022), the Writing Pal system (Butterfuss et al., 2022), and the self-regulatory vocabulary game (Chu et al., 2022).

Relevant studies have lent further support to the integration of self-regulating AI through which language learners are facilitated by learning “with” computers and technology as a mind tool. Through the present systematic review that targets the recent two decades, the selected empirical studies on the topic not only confirm the trend but clarify the operational definition of such a facilitative role of adaptive technology that accelerates an ongoing cyclical progression for engaging language learners as active knowledge constructors, creative communicators, and most importantly, computational thinkers. In other words, with the growing intention and acceptance of utilizing AI both for learning tools and learning analytics, modern digital learners are hereby encouraged to advance WITH person alized AI scaffolds by gaining awareness of their own learning challenges and feasible ways to break through.

# 5.2. Implications for theory

This improved personalization and facilitation in AI integration is seen as a potential area for further development, given that language learners are provided with practical chances to interact with the technology-enhanced, smart environment, meanwhile with themselves, most ideally through the three recursive phases of forethought, performance, and self-reflection. Even though AI has not yet been properly placed in all different phases for full-scale functioning, this present study has helped to identify stage work in the thread of discussion over AI application for SRLL purposes. The current research focus appears to remain on AI for timely, real-time feedback in language education, primarily at an individual, student-directed level that facilitates teachers’ subjective assessment, as well as teacher-to-student classroom preparations and interactions (Pintrich, 2000; Zimmerman & Moylan, 2009). Extended research efforts should be directed to the parallel problem of utilization inefficiency, given that the general improvement in resource conditions does not necessarily guarantee the essential digital skills and usages or the expected SRL/SRLL skills. The student-centered AI learning chances should therefore be refined with the inclusion of a primary component of user readiness and relevance by identifying and integrating for cultivating competence (skills) and application (usage) highly demanded (Bandura, 1991; Schunk, 2012). This approach should also expand to encompass a wider range of interaction patterns, including student-content, student-content, student-self, student-teacher, and student-student dynamics (Paris & Paris, 2001).

# 5.3. Limitations and future research

Such a redefined role of technology-as-intellectual-learning-partner is highly stressed in the 2021 Horizon Report and remains so in the subsequent 2022 Horizon Report. EDUCAUSE (2022) further notes, “[a]rtificial intelligence (AI) technologies are now a common feature for institutional assessments and instructional tools,” which acknowledges the transition from micro level to meso or near-macro level of digital tools utilization for learning with computers and technology. In the mean-time when the application scale is extended from addressing existing challenges to evaluating the broad-based curriculum design and institutional measure (such as hardware, training, theory, and quality concerns) (Okewu et al., 2021), the complex mind of individual language learners should never be overlooked, thereby still necessitating a human-centered approach to AI in future research directions, as recommended by UNESCO (2022). The promise of “AI for all” must be that “everyone can take advantage of the technological revolution under way and access its fruits, notably in terms of innovation and knowledge” and should be explored for its possibility of bringing an inclusive AI-enhanced language learning context where students learn to self- (or even co-regulate) properly with personalized technology in response to the smart learning trend toward Education 4.0, and in their equally flexible role of an effective, self-initiated digital learner.

This study’s exploration into AI’s role in SRLL within higher education’s smart learning environments highlights its potential as a dynamic partner in language instruction. Through a systematic review spanning recent decades, the evolving function of AI is identified and associated with a facilitator of active, creative, and computational engagement in language learning. However, the study acknowledges its methodological focus on WoS database, not including other databases such as Springer, Taylor & Francis, and Sage, which could have provided additional insights. In other words, the review’s scope, limited to a single database, suggests a focused methodology rather than a broad examination of all available academic resources. Such a focused approach was selected to ensure the depth while keeping the review process practical and manageable.

Future research must focus on broadening sources, enhancing search methodologies, and adopting cross-disciplinary approach to understanding and application of AI in self-regulation and language learning. Selected articles for review should be expanded through the use of multiple indexing services and citation databases to mitigate publication bias. Search strategy for article selection should also be refined for broadened inclusion of keyword options, as well as search areas within each article selected. Additionally, future empirical investigations will evaluate AI tools in educational settings, covering a wide range of topics, such as AI’s contribution to learner autonomy, its role in engaging students in self-regulated learning processes, and its adaptability to accommodate individual learning needs. Further studies may also examine AI’s influence on pedagogical strategies, teaching approaches, and overall quality of instruction. Regarding search topics for discussion, given that AI technology itself carries discipline-specific connotations, its primary role of language learning “tool” in an EFL/ESL context should be explicitly contrasted jargon-embedded descriptions (e.g., conversational agent, machine translation software, intelligent tutoring system) to specify its uses and impacts. This applies equally to the trend toward SRL/L, which may be differently perceived or emphasized by stages of practice (e.g., focus on setting goals, on per forming tasks, on making self-reflections) and therefore requires exploration of review research from varied and potentially interdisciplinary perspectives. The evolving nature of AI technology is sure to continuously support research efforts in the context of language learning, especially for the benefit of self-regulated learners’ cyclical improvement.

# CRediT authorship contribution statement

Wenli-Li Chang: Writing – review & editing, Writing – original draft, Methodology, Formal analysis, Conceptualization. Jerry Chih-Yuan Sun: Writing – review & editing, Validation, Supervision, Project administration, Funding acquisition, Conceptualization.

# Acknowledgements

This research was supported by the National Science and Technology Council (formerly the Ministry of Science and Technology) in Taiwan through Grant numbers NSTC 112-2410-H-A49-019-MY3, MOST 111-2410-H-A49-018-MY4, and NSTC 113-2423-H-A49-001. We would like to thank NYCU’s ILTM (Interactive Learning Technology and Motivation, see: http://ILTM.lab.nycu.edu.tw) Lab members and the students for participating the study, as well as the reviewers for providing valuable comments.

# References

Alfoudari, A. M., Durugbo, C. M., & Aldhmour, F. M. (2021). Understanding socio-technological challenges of smart classrooms using a systematic review. Computers & Education, 173, Article 104282. https://doi.org/10.1016/j.compedu.2021.104282   
Aslan, B. G., Oztürk, ¨ O., ¨ & Inceoglu, M. M. (2014). Effect of Bayesian student modeling on academic achievement in foreign language teaching (university level English preparatory school example). Educational Sciences: Theory and Practice, 14(3), 1160–1168.   
Azevedo, R. (2009). Theoretical, conceptual, methodological, and instructional issues in research on metacognition and self-regulated learning: A discussion. Metacognition and Learning, 4, 87–95.   
Azevedo, R., Cromley, J. G., Winters, F. I., Moos, D. C., & Greene, J. A. (2006). Using computers as metacognitive tools to foster students’ self-regulated learning. Technology, Instruction, Cognition and Learning, 3(1/2), 97.   
Bandura, A. (1986). Social foundations of thought and action. Englewood Cliffs, NJ. 1986(23–28), 2.   
Bandura, A. (1991). Social cognitive theory of self-regulation. Organizational Behavior and Human Decision Processes, 50(2), 248–287.   
Butterfuss, R., Roscoe, R. D., Allen, L. K., McCarthy, K. S., & McNamara, D. S. (2022). Strategy uptake in writing pal: Adaptive feedback and instruction. Journal of Educational Computing Research, 60(3), 696–721.   
Chen, M. R. A. (2024). Metacognitive mastery: Transformative learning in EFL through a generative AI chatbot fueled by metalinguistic guidance. Educational Technology & Society, 27(3).   
Chen, C. M., & Chen, M. C. (2009). Mobile formative assessment tool based on data mining techniques for supporting web-based learning. Computers & Education, 52 (1), 256–273.   
Chen, C. H., Chung, M. Y., & Wu, W. C. V. (2013). The effects of faded prompts and feedback on college students’ reflective writing skills. The Asia-Pacific Education Researcher, 22(4), 571–583.   
Chen, C. M., Hsu, S. H., Li, Y. L., & Peng, C. J. (2006). Personalized intelligent m-learning system for supporting effective English learning. In , 6. 2006 IEEE international conference on systems, man and cybernetics (pp. 4898–4903). IEEE.   
Chen, C. M., & Tsao, H. W. (2021). An instant perspective comparison system to facilitate learners’ discussion effectiveness in an online discussion process. Computers & Education, 164, Article 104037.   
Chen, X., Xie, H., & Hwang, G. J. (2020). A multi-perspective study on artificial intelligence in education: Grants, conferences, journals, software tools, institutions, and researchers. Computers and Education: Artificial Intelligence, 1, Article 100005.   
Chu, S. T., Hwang, G. J., Chien, S. Y., & Chang, S. C. (2022). Incorporating teacher intelligence into digital games: An expert system-guided self-regulated learning approach to promoting EFL students’ performance in digital gaming contexts. British Journal of Educational Technology, 54(2), 534–553.   
Crompton, H. (2017). ISTE standards for educators: A guide for teachers and other professionals. International Society for Technology in Education.   
Crossley, S., & McNamara, D. (2013). Applications of text analysis tools for spoken response grading. Language, Learning and Technology, 17(2), 171–192.   
Daulay, S. F., & Ginting, P. (2024). Transforming English language teaching through AI: Evaluation of the strategies and potential of artificial intelligence applications in EFL. Ideas: Journal on English Language Teaching and Learning, Linguistics and Literature, 12(1), 376–395.   
Demir, K. A. (2021). Smart education framework. Smart Learning Environments, 8(1). https://doi.org/10.1186/s40561-021-00170-x   
Deng, X., & Yu, Z. (2022). A systematic review of machine-translation-assisted language learning for sustainable education. Sustainability, 14(13), 7598. https://doi. org/10.3390/su14137598   
Diederich, S., Brendel, A. B., Morana, S., & Kolbe, L. (2022). On the design of and interaction with conversational agents: An organizing and assessing review of human-computer interaction research. Journal of the Association for Information Systems, 23(1), 96–138.   
Diwanji, P., Hinkelmann, K., & Witschel, H. F. (2018). Enhance classroom preparation for flipped classroom using AI and analytics. In Iceis (pp. 477–483), 1.   
EDUCAUSE. (2021). 2021 EDUCAUSE Horizon report, teaching and learning edition. EDUCAU.   
EDUCAUSE. (2022). 2022 EDUCAUSE Horizon report, teaching and learning edition. EDUCAU.   
EDUCAUSE. (2024). 2022 EDUCAUSE Horizon report, teaching and learning edition. EDUCAU.   
ElSayary, A. (2024). Integrating generative AI in active learning environments: Enhancing metacognition and technological skills. Journal of Systemics, Cybernetics and Informatics, 22(3), 34–37.   
Ha, M., & Nehm, R. H. (2016). The impact of misspelled words on automated computer scoring: A case study of scientific explanations. Journal of Science Education and Technology, 25(3), 358–374.   
Harkins, A. M. (2008). Leapfrog principles and practices: Core components of education 3.0 and 4.0. Futures Research Quarterly, 24(1), 19–31.   
He, Y., Hui, S. C., & Quan, T. T. (2009). Automatic summary assessment for intelligent tutoring systems. Computers & Education, 53(3), 890–899.   
Hew, K. F., Huang, W., Du, J., & Jia, C. (2022). Using chatbots to support student goal setting and social presence in fully online activities: Learner engagement and perceptions. Journal of Computing in Higher Education, 1–29.   
Hinsen, S., Hofmann, P., Johnk, ¨ J., & Urbach, N. (2022). How can organizations design purposeful human-AI interactions: A practical perspective from existing use cases and interviews. In Proceedings of the 55th Hawaii international conference on system sciences.   
Hsieh, T. C., Wang, T. I., Su, C. Y., & Lee, M. C. (2012). A fuzzy logic-based personalized learning system for supporting adaptive English learning. Journal of Educational Technology & Society, 15(1), 273–288.   
Hwang, W. Y., Guo, B. C., Hoang, A., Chang, C. C., & Wu, N. T. (2022). Facilitating authentic contextual EFL speaking and conversation with smart mechanisms and investigating its influence on learning achievements. Computer Assisted Language Learning, 1–27.   
IBM Cloud Education. (2020). What is artificial intelligence (AI)?.   
Jiang, M. Y. C., Jong, M. S. Y., Lau, W. W. F., Chai, C. S., & Wu, N. (2022). Exploring the effects of automatic speech recognition technology on oral accuracy and fluency in a flipped classroom. Journal of Computer Assisted Learning.   
Jonassen, D. H. (2000). Computers as mindtools for schools: Engaging critical thinking. Upper Saddle River, NJ: Prentice Hall.   
Kapelner, A., Soterwood, J., Nessaiver, S., & Adlof, S. (2018). Predicting contextual informativeness for vocabulary learning. IEEE Transactions on Learning Technologies, 11(1), 13–26.   
Karatas¸, F., Abedi, F. Y., Ozek Gunyel, F., Karadeniz, D., & Kuzgun, Y. (2024). Incorporating AI in foreign language education: An investigation into ChatGPT’s effect n foreign language learners. Education and Information Technologies, 1–24.   
Kaswan, K. S., Dhatterwal, J. S., & Ojha, R. P. (2024). AI in personalized learning. In Advances in technological innovations in higher education (pp. 103–117). CRC Press.   
Kim, M. K., Kim, N. J., & Heidari, A. (2022). Learner experience in artificial intelligence-scaffolded argumentation. Assessment & Evaluation in Higher Education, 1–16.   
Klimova, B., Pikhart, M., Benites, A. D., Lehr, C., & Sanchez-Stockhammer, C. (2022). Neural machine translation in foreign language teaching and learning: A systematic review. Education and Information Technologies, 1–20.   
Kuhail, M. A., Alturki, N., Alramlawi, S., & Alhejori, K. (2022). Interacting with educational chatbots: A systematic review. Education and Information Technologies, 1–46.   
Lai, C., & Gu, M. (2011). Self-regulated out-of-class language learning with technology. Computer Assisted Language Learning, 24(4), 317–335.   
Lee, L. (2016). Autonomous learning through task-based instruction in fully online language courses. Language, Learning and Technology.   
Lee, K. F. (2018). The four waves of AI. Fortune, 178(5), 92–94.   
Liang, J. C., Hwang, G. J., Chen, M. R. A., & Darmawansah, D. (2021). Roles and research foci of artificial intelligence in language education: An integrated bibliographic analysis and systematic review approach. Interactive Learning Environments, 1–27. https://doi.org/10.1080/10494820.2021.1958348   
Liu, M., Calvo, R. A., & Rus, V. (2014). Automatic generation and ranking of questions for critical review. Journal of Educational Technology & Society, 17(2), 333–346.   
Liu, C., Hou, J., Tu, Y. F., Wang, Y., & Hwang, G. J. (2021). Incorporating a reflective thinking promoting mechanism into artificial intelligence-supported English writing environments. Interactive Learning Environments, 1–19.   
Liu, G. L., Zhang, Y., & Zhang, R. (2024). Examining the relationships among motivation, informal digital learning of English, and foreign language enjoyment: An explanatory mixed-method study. ReCALL, 36(1), 72–88.   
Lo, J. J., Wang, H. M., & Yeh, S. W. (2004). Effects of confidence scores and remedial instruction on prepositions learning in adaptive hypermedia. Computers & Education, 42(1), 45–63.   
Moher, D., Liberati, A., Tetzlaff, J., Altman, D. G., & Group, P. (2009). Preferred reporting items for systematic reviews and meta-analyses: The PRISMA statement. PLoS Medicine, 6(7), Article e1000097. https://doi.org/10.1371/journal.pmed.1000097   
Moser, J. (2015). From a knowledge-based language curriculum to a competency-based one: The CEFR in action in Asia. Asian EFL Journal, 88, 1–29.   
Nam, S., Frishkoff, G., & Collins-Thompson, K. (2017). Predicting students’ disengaged behaviors in an online meaning-generation task. IEEE Transactions on Learning Technologies, 11(3), 362–375.   
Nelson Jr, R. (2011). Vigilance, expectancy, and noise: Attention in second language lexical learning and memory. Second Language Research, 27(2), 153–171.   
Ni, A., & Cheung, A. (2022). Understanding secondary students’ continuance intention to adopt AI-powered intelligent tutoring system for English learning. Education and Information Technologies, 1–26   
Novawan, A., Walker, S. A., & Ikeda, O. (2024). The new face of technology-enhanced language learning (TELL) with artificial intelligence (AI): Teacher perspectives, practices, and challenges. Journal of English in Academic and Professional Communication, 10(1), 1–18.   
Okewu, E., Adewole, P., Misra, S., Maskeliunas, R., & Damasevicius, R. (2021). Artificial neural networks for educational data mining in higher education: A systematic literature review. Applied Artificial Intelligence, 35(13), 983–1021.   
Papadopoulos, I., Lazzarino, R., Miah, S., Weaver, T., Thomas, B., & Koulouglioti, C. (2020). A systematic review of the literature regarding socially assistive robots in pre-tertiary education. Computers & Education, 155, Article 103924. https://doi.org/10.1016/j.compedu.2020.103924   
Paris, S. G., & Paris, A. H. (2001). Classroom applications of research on self-regulated learning. Educational Psychologist, 36(2), 89–101. https://doi.org/10.1207/ S15326985EP3602_4   
Pinkwart, N. (2016). Another 25 years of AIED? Challenges and opportunities for intelligent educational technologies of the future. International Journal of Artificial Intelligence in Education, 26, 771–783.   
Pintrich, P. R. (2000). The role of goal orientation in self-regulated learning. In Handbook of self-regulation (pp. 451–502). Academic Press.   
Ramesh, D., & Sanampudi, S. K. (2021). An automated essay scoring system: A systematic literature review. Artificial Intelligence Review, 1–33.   
Roscoe, R. D., Allen, L. K., & McNamara, D. S. (2019). Contrasting writing practice formats in a writing strategy tutoring system. Journal of Educational Computing Research, 57(3), 723–754.   
Saadati, Z., Zeki, C. P., & Vatankhah Barenji, R. (2021). On the development of blockchain-based learning management system as a metacognitive tool to support selfregulation learning in online higher education. Interactive Learning Environments, 1–24.   
Sarker, I. H. (2022). AI-based modeling: Techniques, applications and research issues towards automation, intelligent and smart systems. SN Computer Science, 3(2). https://doi.org/10.1007/s42979-022-01043-x   
Schools of the Future. (2020). Defining new models of education for the fourth industrial revolution. Report. World Economic Forum. https://www.weforum.org/reports/ chools-ofthe-future-defining-new-models-of-education-for-the-fourth-industrial-revolution, 2020.   
Schunk, D. H. (2012). Learning theories: An educational perspective. Pearson Education, Inc.   
Schunk, D. H., & Zimmerman, B. J. (1994). Self-regulation in education: Retrospect and prospect. In D. H. Schunk, & B. J. Zimmerman (Eds.), Self-regulation of learning and performance. Hillsdale, NJ: Erlbaum.   
Searle, J. R. (1980). Minds, brains, and programs. Behavioral and Brain Sciences, 3(3), 417–424. https://doi.org/10.1017/s0140525x00005756   
Shyr, W. J., & Chen, C. H. (2018). Designing a technology-enhanced flipped learning system to facilitate students’ self-regulation and performance. Journal of Computer Assisted Learning, 34(1), 53–62.   
Strobl, C., Ailhaud, E., Benetos, K., Devitt, A., Kruse, O., Proske, A., & Rapp, C. (2019). Digital support for academic writing: A review of technologies and pedagogies. Computers & Education, 131, 33–48.   
UNESCO. (2022). Artificial intelligence in education. Explore UNESCO.   
Wang, X., Pang, H., Wallace, M. P., Wang, Q., & Chen, W. (2024). Learners’ perceived AI presences in AI-supported language learning: A study of AI as a humanized agent from community of inquiry. Computer Assisted Language Learning, 37(4), 814–840.   
Wiechmann, D., & Kerz, E. (2014). Cue reliance in L2 written production. Language Learning, 64(2), 343–364.   
Yang, Y., Wen, Y., & Song, Y. (2023). A systematic review of technology-enhanced self-regulated language learning. Educational Technology & Society, 26(1), 31–44.   
Zhai, C., & Wibowo, S. (2023). A systematic review on artificial intelligence dialogue systems for enhancing English as foreign language students’ interactional competence in the university. Computers and Education: Artificial Intelligence, 4, Article 100134.   
Zhang, K., & Aslan, A. B. (2021). AI technologies for education: Recent research & future directions. Computers & Education: Artificial Intelligence, 2, Article 100025. https://doi.org/10.1016/j.caeai.2021.100025   
Zhao, Q., & Nazir, S. (2022). English multimode production and usage by artificial intelligence and online reading for sustaining effectiveness. Mobile Information Systems, 2022. https://doi.org/10.1155/2022/6780502   
Zhou, Y., & Wei, M. (2018). Strategies in technology-enhanced language learning. Studies in Second Language Learning and Teaching, 8(2), 471–495.   
Zimmerman, B. J. (1989). A social cognitive view of self-regulated academic learning. Journal of Educational Psychology, 81(3), 329.   
Zimmerman, B. J. (2000). Attaining self-regulation: A social cognitive perspective. SanDiego, CA: Academic Press.   
Zimmerman, B. J. (2002). Becoming a self-regulated learner: An overview. Theory into Practice, 41(2), 64–70.   
Zimmerman, B. J., & Moylan, A. R. (2009). Self-regulation: Where metacognition and motivation intersect. In Handbook of metacognition in education (pp. 299–315). Routledge.   
Zutiasari, I., Heri, H., Rahayu, W. P., & Rusmana, D. (2024). Self-regulated learning is the internalization of mobile seamless learning-based learning strategies in improving communication skills. East Asian Journal of Multidisciplinary Research, 3(6), 2305–2314.