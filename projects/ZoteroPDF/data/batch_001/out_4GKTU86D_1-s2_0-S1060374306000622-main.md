# The process-oriented ESL writing assessment: Promises and challenges

Young-Ju Lee

University of Illinois at Urbana-Champaign, USA

# Abstract

This study examines a process-oriented ESL writing assessment called the Computerized Enhanced ESL Placement Test (CEEPT). The CEEPT at the University of Illinois at Urbana-Champaign or its noncomputerized alternative (EEPT) have since 2000 offered a daylong process-oriented writing assessment in which test takers are given extended time to plan, produce, and revise an essay. This study examines how 100 English as a Second Language (ESL) students take up the opportunity in this assessment procedure to reflect, interact with others, and revise their essays. Specifically, this study investigates what level of revision test takers focused on as well as the extent to which the quality of written products differed between first and second drafts. Results of this study showed that students produced their final drafts in a more coherent manner with complex sentences, as indicated by increased analytic as well as holistic scores, T-units, and a global level of revision. Extracts from essays whose scores increased, stayed the same, and decreased are presented to give a richer sense of how changes in the measures reflected writers’ revisions. This study thus offers insights into a serious attempt to translate a richer and more complex, process-oriented understanding of writing into a large institutional writing assessment.

$©$ 2006 Elsevier Inc. All rights reserved.

Keywords: ESL writing assessments; Process-oriented writing; Revision process; Computerized writing assessments

# Introduction

As Susser (1994) argued, the term process can be defined in three ways: (1) the act of writing itself, (2) the emphasis of writing instruction on process writing pedagogies, and (3) theories of writing. When writing impromptu timed essays, students go through a process in its first usage; writing, composing, or transcribing. The term process in this study is used in its second sense, where process signifies a process of discovery in which ideas are generated and not just transcribed as writers think through and organize their ideas before writing and revising their drafts. This second sense of process is also related to an expanded theoretical understanding of the construct of writing that is more social and less bound by the ability of an individual, as many traditional theories of writing suggest. There has been a mismatch between processoriented English as a Second Language (ESL) writing instruction and product-oriented assessment. Although the methodology for teaching ESL writing has shifted toward processcentered approaches over the last two decades, the assessment of ESL writing skills on standardized and institutional ESL placement tests has continued to focus on written products (Hinkel, 2002).

The construct of academic writing in assessment has begun to change in a way that allows students to demonstrate their ability as they engage fully in processes through brainstorming, drafting, and revising in response to peer reviews (Camp, 1993). This expanded and new construct of academic writing can include features, though multiple drafts and opportunities for revision, which are incompatible with the impromptu essay test aimed at measuring a cognitive trait of the individual. Timed single-draft essay tests where students are given 30–50 minutes to write on an assigned topic without any opportunity to reflect, interact with others, and revise do not provide an authentic writing environment. Wiggins (1994), for example, criticized timed single-draft essay tests because they do not provide opportunities to get feedback during the test, noting that the dominant approach to writing assessment is in sharp contrast with the real world, where we almost always get feedback from classmates, instructors, colleagues, or editors. Timed single-draft essay tests, I would argue, offer a one-dimensional indication of students’ academic writing ability, while multiple-draft essay tests may provide a multi-dimensional view that offers greater construct validity.

One response to this shifting conceptualization of writing has been the use of portfolio assessments. Portfolio assessment has provided readers with a more complex view of the writer because it includes a variety of writing created by a writer over a period of time (Freedman, 1993). However, portfolio assessment typically depends on a system-wide adoption as in a public school system (e.g., Callahan, 1997) or a major college composition program (e.g., Belanoff & Dickson, 1991), making it easiest to employ for exit examinations or accountability assessments. Results of portfolios can also be difficult to interpret because of the potentially great variations in resources, such as time and quality of feedback, that assist students’ written performance. Thus, writing assessment specialists have also sought more controlled, concentrated forms of process assessment. For example, Goldberg, Roswell, and Michaels (1995) examined the effect of peer response and revision on texts, using the Maryland School Performance Assessment Program (MSPAP) writing assessment. As a process-oriented performance assessment administered statewide to all students in Grades 3, 5, and 8, the MSPAP writing assessment includes opportunities to draft, review, and revise essays within a multi-day testing format. Contrary to authors’ expectations, the results of their study showed that there were generally limited revisions to rough drafts and minimal score improvements from rough to final drafts. As their study indicates, such tests face real challenges in creating conditions that motivate and support student engagement in the writing process. From a practical perspective, in situations where students come from diverse educational systems and where there is limited time for assessment, as in college-level ESL assessment of writing for placement into or exemption from courses, portfolio assessment may simply be precluded as an option.

Although portfolio-based assessment is very popular in the L1 assessment contexts as well as in L2 writing classrooms, there are very few such writing assessments available in the ESL context. The question then is: What are possible models of process-oriented writing assessment in the ESL context? How can we practically retain the benefits associated with portfolio assessments and not return to the constraints imposed on timed single-draft essay tests? Finally, when process-oriented assessment features, such as sufficient time for writing and the opportunity to receive peer feedback and revise rough drafts, are integrated into the ESL testing context, how do ESL student writers make use of those opportunities?

# The computerized enhanced ESL placement test

The English Placement Test (EPT) at the University of Illinois at Urbana-Champaign is administered to all incoming international students whose TOEFL scores are below the campus or (if higher) departmental admission cutoff scores. The campus requires them to take the EPT if their TOEFL scores are below 610 (paper-and pencil) or 253 (computer-based). The primary purpose of the EPT is to place students into or exempt them from appropriate ESL courses.

There are three types of EPT: regular EPT, Paper-based Enhanced EPT (PEEPT), and Computerized Enhanced EPT (CEEPT) (see Fig. 1). All three are integrated English for Academic Purposes (EAP) assessments (Pyo, 2001). During the regular EPT, students watch a videotaped lecture, read an article on a topic related to that of the lecture, and write an essay that integrates information from the two sources. The essay writing has a 50 minute time limit. Hence, the regular EPT is a timed single-draft essay test.

Since 2000, UIUC has offered one possible model for process-oriented writing assessment. The Enhanced ESL Placement Test (EEPT) and its computerized alternative CEEPT are daylong process-oriented writing assessments in which test takers are given sufficient time to plan, produce, and revise an essay. The CEEPT differs from the PEEPT in that the former is administered on computers instead of paper. Students can select which version of the test they wish: the regular EPT, PEEPT, or CEEPT.

The CEEPT provides a potential alternative between timed single-draft essay tests and portfolio assessments. Theoretically, the CEEPT defines academic writing ability as the knowledge to comprehend information from lectures and articles and to produce an academic English essay via multiple drafts, with the help of extended time spent in facilitative activities such as a class discussion and a feedback session. The construct being assessed is not simply a text written as a reflection of academic writing competence of the individual; instead, it is assisted or mediated writing performance, which includes social aspects of writing such as negotiation, learning, and interaction (Prior, 1998). Although the integration of process-oriented assessment features is challenging, it is desirable to identifying practical assessment features that reflect current theoretical understandings of writing.

![](img/d0ab8368960c8de018ffd09d7c0ceeadf8c592fa1f03d8d6c0808e1f2288df05.jpg)  
Fig. 1. Three kinds of EPT.

In the UIUC setting, process-oriented writing assessments can be said to result in better placement than timed-single draft essay tests. Cho (2001) investigated which writing test allows for better placement between the Paper-based Enhanced EPT (PEEPT) and the regular EPT. The same 57 graduate students took both the regular EPT and the PEEPT. Among the 57, 43 students received higher placement results on the PEEPT than they did on the regular EPT; 34 students received one score higher and 9 students received two scores higher on the PEEPT than on the regular EPT. Since it was decided that the essay that earned the higher score would be used for the placement decision, 43 students’ placement results changed accordingly. That is, as the result of the PEEPT, 34 students took one less ESL course and 9 students were exempt from ESL courses. Placement results did not change for the remaining 14 students. It is worthwhile to note that no single student received lower placement results on the PEEPT than on the regular EPT. It can be concluded that many of the writers at least afforded themselves the opportunities for revision and feedback in ways that resulted in higher scores and higher placements.

# Statement of purpose

The potential of process-oriented writing assessment is often implied but seldom examined empirically in ESL assessment contexts in terms of multiple types of evidence such as the level of revision, scores, and detailed text analysis. We know, for example, very little about the ways and degree to which students’ performance changes from rough to final drafts as they engage in the full range of writing processes within a testing context. The purpose of this study is to investigate the effect of the revision session facilitated by computer writing tools on the quality of second drafts. The following research questions were addressed in this study:

1. Did ESL students’ essays change significantly as a result of peer feedback and revision in CEEPT testing context?   
2. To what extent and in what ways did the quality of written products differ between first and second drafts composed during the CEEPT?

These two questions focus our attention on how ESL student writers took up these opportunities for feedback, reflection, and revision in this novel assessment context.

# Methodology

# Participants

A hundred graduate students in Business $( n = 4 3$ ), Humanities $( n = 2 0$ ), Science $( n = 9 )$ , and Technology $( n = 2 8 )$ ) participated in this study. The participants represented various first language backgrounds, with the majority of them being speakers of Chinese $( n = 3 2$ ), Korean $( n = 3 1$ ), and Spanish $( n = 1 0$ ).

# Procedures

The CEEPT procedures are presented in Fig. 2. Three notable features of the CEEPT are (a) extended time for writing, (b) refined facilitative activities, and (c) access to a word processor for essay writing. During the morning session, examinees watch the video, read the article, and write first drafts with the help of a group discussion. During the afternoon session, examinees write their second and final drafts based on the peers’ comments.

To improve the facilitative activities of the CEEPT, two critical changes were made from the previous test procedures. First, general questions for group brainstorming and guided questions for group discussion were revised since the old questions did not contain information from the accompanying article. Second, two peer review familiarization tasks were devised. Students

# PART ONE

# 9:00 EXPLANATION ABOUT THE CEEPT PROCEDURES (5 MIN)

Teacher explains how the test proceeds and tells students to read directions. 9:05 TOPIC INTRODUCTION (5 MIN)

Teacher defines the topic

9:10GROUP BRAINSTORMING (10 MIN)

In groups of three or four, students brainstorm answers to general questions proposed by the teacher about the topic. Teacher distributes the discussion questions sheets

9:20 WHOLE CLASS DISCUSSION (10 MIN)

Students share the answers with the class.

9:30 BREAK (5 MIN)

# 9:35 VIDEO WATCHING (10 MIN)

Teacher distributes scratch papers; students watch video on topic

9:45 ARTICLE READING (20 MIN)

Teacher distributes the assigned article relevant to the topic of the video. 10:05 GROUP DISCUSSION (20 MIN)

In new groups, students discuss the video and the article using guided questions.

10:25 BREAK (5 MIN)

10:30 EXPLANATION ON THE SCORING CRITERIA (10 MIN)

Students are given the holistic scoring criteria. Teacher briefly explains the scoring criteria. Students read scoring criteria and ask questions, if necessary.

10:40 TIME FOR ORGANIZING ESSAY (10 MIN)/ ROUGH DRAFT WRTING (40 MIN)

Students will organize their essays and then start to write their first drafts

11:30 LUNCH BREAK

Teacher collects students' essays and any handouts

# PART TWO

# 1:30 PEER REVIEW FAMILIARIZATION TASKS (20 MIN)

Teacher defines peer review with students, explains the purpose and benefit of the peer feedback session, returns the first draft essays and two blank peer review sheets to students, and distributes a text written by someone unknown to students. As a whole class activity, teacher asks students to respond to a paragraph based on the peer review sheet. Teacher explains the peer review sheet and shows a completed peer review sheet.

# 1:50PEER REVIEW (60 MIN)

Teacher forms groups of three. Students take turns reading each essay and writing comments on the peer review sheet. Read essay #1 and write comments (15 min). Read essay #2 and write comments (15 min). Group discussion on person A's essay (10 min) Group discussion on person B's essay $\mathrm { 1 0 ~ m i n }$ ). Group discussion on person $C$ 's essay $ { \mathrm { ~ \textrm ~ { ~ ~ } ~ } } _ { 1 0 \ : \mathrm { m i n } }$ ). For each group discussion, two students who have written comments about an essay give oral feedback about how the essay could be improved. After finishing oral feedback, student collects two peer review sheets from the other students.

# 2:50 BREAK (10 MIN)

# 3:00 ESSAY REVISION (50 MIN)

Students write their second and final essays based on the peers' comments.

# 3:50ENDOF THE WHOLE TEST

The teacher will collect all the materials and two drafts

Fig. 2. (Continued ).

needed to be familiarized with peer response tasks, considering cultural and linguistic variables. Some students might not respond to peer writing critically and may not provide peers with useful feedback due to a lack of knowledge about peer response techniques (Zhu, 1995). To familiarize students with peer review, this version of the CEEPT included a ‘‘class’’ activity where the ‘‘teacher’’ asks the students to respond to a sample paragraph based on the peer review sheet. For security reasons, the sample paragraph cannot appear in an appendix. This activity also introduced the students to sample peer review sheets. The teacher explained to the students how to fill in these forms.

‘‘Computerized’’ in the CEEPT means that test takers had access to a word processor for essay writing. Videos were shown on a big screen and articles were provided in hardcopy. Participants completed the CEEPT using a Microsoft Word program. They did not have access to spell checkers or grammar checkers; only the copy and paste function were allowed.

Rating scales

Two scales were used to assess and analyze students’ draft and final essays. The first scale used in this study was the holistic placement scale used for UIUC placement decisions based on the CEEPT (see Appendix A). This scale addresses the following dimensions of academic writing: flow of ideas, effective elaboration, linguistic expression, synthesis of ideas, and paraphrasing. Each essay is given a single global rating, which is directly associated with the operational placement result. The four levels of scores assigned to graduate students are: too low, ESL 500, ESL 501, and exempt, which is equivalent to scores from 1 to 4. The CEEPT score of 1 (i.e., too low) indicates students do not have the ability to take content courses and thus are not admitted. The CEEPT score of 2 (i.e., ESL 500) indicates that students are required to take two ESL courses in sequence: ESL 500 and in a subsequent semester, ESL 501. The CEEPT score of 3 (i.e., ESL 501) means that students are required to take only the second class. The CEEPT score of 4 (i.e., exempt) indicates that students are exempt from ESL courses.

In addition to the usual holistic assessment, an analytic assessment was also employed for this study in order to provide more specific information about what features of the essays might account for changes in the holistic scores. In an earlier analysis of the CEEPT, Lee (2002) developed an analytic rating scale that consists of five categories: organization, content, grammar and lexical choice, the use of sources, and plagiarism. Under each category, there are four levels of statements. For the present study, this scale was used with two changes. First, the category of plagiarism was renamed as avoidance of plagiarism. The original name sounds counter-intuitive because a high score on this category means that students did not copy source materials without citations. Second, another category, mechanics, was added to show features related to computer-specific mechanical changes such as indentation, capitalization, paragraph development, punctuation, and stylistic format. An analytic rating scale consisting of six categories was used for this study. Please note that analytic scores were not used for the operational placement result.

# Text analysis of CEEPT essays

# Quantitative measures of texts

The number of words, T-units, and the T-unit length were compared between first and second drafts. A T-unit in this study is operationally defined as a minimal unit constituting a complete sentence (i.e., one independent clause and any dependent clauses connected to it). The T-unit length is the average number of words per T-unit and is obtained by dividing the number of words by the number of T-units. Error-free T-units were not employed in this study since judgments of what counts as errors can be controversial. Although discrepancies in identifying T-units are negligible, determining error free T-units is problematic (Polio, 1997).

# Inter-rater reliabilities for text analysis

The analysis of students’ first and second drafts (i.e., a total of 200 drafts) involved independent judgment about T-units and level of revision. A second rater independently analyzed $20 \%$ of the drafts (i.e., a total of 40 drafts consisting of the first and second drafts from 20 students). The pair-wise correlations were calculated to get inter-rater reliabilities between the researcher and the second rater as seen in Table 1. Inter-rater reliability figures for all aspects of the text analysis were highly acceptable, each one well above 0.9.

Table 1 Inter-rater reliabilities for text analysis   

<html><body><table><tr><td rowspan="2">Text analysis</td><td colspan="2">Inter-rater reliabilities</td></tr><tr><td>First draft</td><td>Second draft</td></tr><tr><td>T-units</td><td>0.983</td><td>0.938</td></tr><tr><td>Level of revisiona</td><td></td><td></td></tr><tr><td> Mechanics</td><td></td><td>0.944</td></tr><tr><td>Words</td><td></td><td>0.913</td></tr><tr><td>Phrases</td><td></td><td>0.974</td></tr><tr><td>Sentences</td><td></td><td>0.992</td></tr><tr><td>Paragraphs</td><td></td><td>0.966</td></tr></table></body></html>

a Inter-rater reliabilities for level of revision are the same for the first and second drafts.

# Level of revision: Revision categories

This study investigated the revision processes involved in the CEEPT by tracking changes made between two drafts. Microsoft Word’s Track Changes function allowed a researcher to track changes made to already existing documents (i.e., the first draft). The Track Changes identifies textual changes; strikethrough indicates text deletions, and underlining indicates text additions. The classification of revisions in this study aimed to identify the range of revision and the extent to which parts of the text were altered by the writer. This study adopted Kim’s (2002) descriptions for textual changes at the levels of mechanics and words. Mechanics include changes in spelling, punctuation, font, and capitalization. The word category includes changes in additions, deletions, movements, and replacement of a word. The word category also includes grammatical changes in articles, plurals, prepositions, pronouns, word order, tense/aspect, and verb agreement. The phrase level includes changes in additions, deletions, movements, and replacement of a phrase. The sentence level revision refers to additions, deletions, movements, and replacements of a sentence. The paragraph level refers to additions, deletions, movements, and replacements of a paragraph. Fuller explanations of this coding with examples from the data are provided in Appendix B.

Although I turned on the Track Changes function during the lunch break of the CEEPT, six students’ computers did not respond properly. Therefore, essays composed on them were not available for analyses of level of revision. The number in parentheses in Appendix B indicates participants’ unique identification number for this study.

# Hypotheses

If the CEEPT is effective at encouraging student engagement in a fuller version of the academic writing process, then the following hypotheses should be confirmed:

(1) Holistic scores on the final essays should be higher than those on the draft essays, and the distributions of those scores should shift. (If this process-enhanced assessment is successful, then the effect of the extended assisted writing process should not be linear—different writers should display differential capacities to take advantage of these opportunities, differences that reflect differences in a more complex construct of academic writing as mediated activity.)   
(2) Analytic scores on the final essays should be higher than those on the draft essays and the distributions of those scores should shift.

Table 2 Crosstabulation of holistic scores of first drafts with those of second drafts   

<html><body><table><tr><td rowspan="2">First draft</td><td colspan="3">Second draft holistic scores</td></tr><tr><td>2</td><td>3</td><td>4</td></tr><tr><td>1</td><td>1</td><td>0</td><td>0</td></tr><tr><td>1.5</td><td>1</td><td>1</td><td>0</td></tr><tr><td>2</td><td> 14</td><td>15</td><td>2</td></tr><tr><td>2.5</td><td>14</td><td>23</td><td>1</td></tr><tr><td>3</td><td>5*</td><td>19</td><td>2</td></tr><tr><td>3.5</td><td>0</td><td>0</td><td>2</td></tr></table></body></html>

Note: Bolds indicate increased scores between two drafts. Underlining shows the same scores, while asterisks denote decreased scores.

(3) The frequency of words, T-units, and T-unit lengths should all increase. The first two measures simply reveal that revisions were performed. Increased t-unit length would be consistent with elaboration within clauses, a likely sign of qualitative revision of ideas and language.

(4) Analysis of revision should indicate that revision between drafts occurred: evidence of higher-order revision should also occur, as evidence of global and qualitative revision.

These hypotheses are all stated to describe what we would expect if students are taking advantage of the opportunities for feedback, reflection, and revision that the exam offers. By addressing these hypotheses qualitatively as well as quantitatively, this analysis explores the basic question of how these ESL graduate students respond to this unfamiliar form of assessment.

# Results

# Hypothesis 1: Holistic scores

The scores for the holistic scale ranged from 1 to 4. Table 2 presents the cross-tabulation of first draft scores with second draft scores. Table 2 shows a discrepancy of a score range between the two drafts: six levels (i.e., 1, 1.5, 2, 2.5, 3, 3.5, and 4) for the first draft, and four levels (i.e., 1, 2, 3, 4) for the second draft. Because first drafts were scored holistically only for research purposes, raters did not negotiate essay scores, so a researcher computed the average of two scores.1 For example, a score of 1.5 shows that one rater gave a score of 1 and the other rater gave a score of 2. Scores of 1.5, 2.5, and 3.5 indicate that the two raters did not agree, and that there was a discrepancy of one.

In order to examine whether there were statistically significant differences in textual quality between the two drafts, dependent $t$ -tests were conducted. For the analysis of holistic scores, essays with scores of 1.5, 2.5, and 3.5 on first drafts were excluded (leaving 58 of 100 participants). Table 3 presents the summary of the dependent $t$ -test results. On average, scores were 0.293 higher on second drafts than on first ones for 58 essays, which was statistically significant. Students’ drafts were, thus, clearly rated higher on average, suggesting that many writers took advantage of the opportunities to reflect on and productively revise their essays.

Table 3 Holistic scores for the two drafts   

<html><body><table><tr><td rowspan="2">Scores</td><td colspan="2">First drafta</td><td colspan="2">Second drafta</td><td colspan="4">Dependent t-test</td></tr><tr><td>m</td><td>S.D.</td><td>m</td><td>S.D.</td><td>Mean difference</td><td>t</td><td>d.f.</td><td>p</td></tr><tr><td>Holistic</td><td>2.43</td><td>0.53</td><td>2.72</td><td>0.58</td><td>0.29</td><td>3.30</td><td>57</td><td>0.002**</td></tr></table></body></html>

a $N = 5 8$ . $p < 0 . 0 1$ .

It is very informative to examine a holistic difference of 0.293 in terms of placement decision. The change in placement on the holistic scores is indicated by underlining, bolds, and asterisks in Table 2. The analysis was done for the unambiguous 58 cases. Twenty students received increased holistic scores that would have generated change of placement decisions. One student’s score increased from 1 to 2, 15 students from 2 to 3, 2 students from 2 to 4 and 2 students’ scores increased from 3 to 4.2 That is, 20 students ended up taking less ESL courses as the result of improved holistic scores from first to second drafts. Thirty-three students received the same holistic scores, as indicated by underlining. No change, of course, does not mean that the quality of the essays did not improve or decrease, just that any changes did not move the essay across a categorical boundary. Interestingly, five students received lower holistic scores on second drafts than on first ones. All five students’ scores decreased from 3 to 2.

Overall placement would have been different between first drafts produced in the morning session versus second drafts produced in the afternoon session. In other words, the gain scores made a difference in placement. It should, however, be noted that examination of first drafts suggested that many students wrote in-progress first drafts (e.g., leaving some elements incomplete)—reflecting the fact that first drafts were not themselves assessed. It is important to note that the holistic scores that generated the placement were non-linear; all the scores on the first drafts did not increase by a certain amount on second drafts. If the opportunity to revise taps into a different construct of writing ability, the effect should be differential, not linear. In other words, student writers made differential use of the opportunities for feedback, reflection, and revision.

Hypothesis 2: Analytic scores

The fact that second drafts were better than first ones based on a holistic rating scale does not give sufficient information regarding improved essay quality. To better address what features contributed to essay quality, we needed to examine analytic scores between two drafts, although the analytical scale did not have an impact on the operational placement results. Since analytic scores were not used for the operational placement result, analytic scores between two raters were not negotiated and were averaged. Therefore, 100 essays were all used to examine analytic scores between drafts. Table 4 presents descriptive statistics and dependent $t$ -test results about six analytic scores. On average, students got higher analytic scores on the second drafts than the first ones, and there were significant differences in the six analytic scores between the two drafts. Significant results from the analytic scores on organization, content, grammar, use of sources, avoidance of plagiarism, and mechanics suggest that second drafts were linguistically better than first drafts. In short, it appears that writers revised globally and locally.

Table 4 Six analytic scores for the two drafts   

<html><body><table><tr><td rowspan="2">Analytic scores</td><td colspan="2">First drafta</td><td colspan="2">Second drafta</td><td colspan="4">Dependent t-test</td></tr><tr><td>M</td><td>S.D.</td><td>M</td><td>S.D.</td><td>Mean difference</td><td>t</td><td>d.f.</td><td>p</td></tr><tr><td>Organization</td><td>2.51</td><td>0.619</td><td>3.12</td><td>0.536</td><td>0.61</td><td>7.86</td><td>99</td><td>0.000**</td></tr><tr><td>Content</td><td>2.33</td><td>0.566</td><td>3.00</td><td>0.555</td><td>0.67</td><td>8.84</td><td>99</td><td>0.000**</td></tr><tr><td>Grammar and lexical choice</td><td>2.69</td><td>0.470</td><td>3.17</td><td>0.528</td><td>0.48</td><td>7.71</td><td>99</td><td>0.000**</td></tr><tr><td>Use of sources</td><td>2.48</td><td>0.607</td><td>3.30</td><td>0.456</td><td>0.82</td><td>12.25</td><td>99</td><td>0.000**</td></tr><tr><td>Avoidance of plagiarism</td><td>3.71</td><td>0.422</td><td>3.86</td><td>0.247</td><td>0.15</td><td>2.69</td><td>99</td><td>0.008**</td></tr><tr><td>Mechanics</td><td>2.92</td><td>0.585</td><td>3.48</td><td>0.408</td><td>0.56</td><td>8.20</td><td>99</td><td>0.000**</td></tr></table></body></html>

a $N = 1 0 0$ . k $p < 0 . 0 1$ .

# Hypothesis 3: Quantitative measures of texts

The significant results for the six analytic scores motivated further text analysis. Text analysis can reveal what influences improved essay scores. Table 5 presents the frequency of words, T-units, and T-unit length for the first and second drafts. On average, test takers produced 147.74 more words, and 7.17 more T-units in their second drafts than in their first drafts. The results of the dependent t-test indicated that differences of 147.74 words, 7.17 Tunits, and 1.14 T-unit length between two drafts were significant. This showed that students produced significantly more words, T-units, and complex sentences on second drafts than first drafts.

It is interesting to note that the text length increased for all 100 students’ essays. To adequately address the relationship between text length and change of holistic scores, the discussion will be limited to 58 essays, not 100 ones. For the twenty students whose holistic scores increased, their essays increased by 236 words on average. For the 33 students whose essay scores remained the same, their essays increased by 130 words on average. For the five students whose essay scores decreased, their essays increased by 98 words on average.

Table 5 Frequency of words, T-units, and T-unit length for the two drafts   

<html><body><table><tr><td rowspan="3">Quantity of texts</td><td colspan="4">Frequency</td><td colspan="4">Dependent t-test</td></tr><tr><td colspan="2">First drafta</td><td colspan="2">Second drafta</td><td rowspan="2">Mean difference</td><td rowspan="2">t</td><td rowspan="2">d.f.</td><td rowspan="2">p</td></tr><tr><td>m</td><td>S.D.</td><td>m</td><td>S.D.</td></tr><tr><td>Words</td><td>301.52</td><td>105.87</td><td>449.26</td><td>127.92</td><td>147.74</td><td>15.442</td><td>99</td><td>0.000**</td></tr><tr><td>T-units</td><td>18.38</td><td>6.42</td><td>25.55</td><td>7.08</td><td>7.17</td><td>13.166</td><td>99</td><td>0.000**</td></tr><tr><td>T-unit length</td><td>16.72</td><td>3.15</td><td>17.87</td><td>3.20</td><td>1.14</td><td>4.983</td><td>99</td><td>0.000**</td></tr></table></body></html>

a $N = 1 0 0$ . $p < 0 . 0 1$ .

Table 6 Multiple independent $t$ -tests for level of revision: holistic scores   

<html><body><table><tr><td rowspan="2">Level of revision</td><td colspan="2">Advanced groupa</td><td colspan="2">Intermediate groupb</td><td colspan="4">Independent t-test</td></tr><tr><td>m</td><td>S.D.</td><td>m</td><td>S.D.</td><td>Mean difference</td><td>t</td><td>d.f.</td><td>p</td></tr><tr><td>Mechanics</td><td>3.95</td><td>3.80</td><td>4.03</td><td>3.97</td><td>0.08</td><td>0.09</td><td>92</td><td>0.92</td></tr><tr><td>Word</td><td>14.70</td><td>11.90</td><td>15.24</td><td>10.62</td><td>0.47</td><td>0.19</td><td>92</td><td>0.85</td></tr><tr><td>Phrase</td><td>8.75</td><td>7.52</td><td>7.48</td><td>6.72</td><td>1.27</td><td>0.81</td><td>92</td><td>0.42</td></tr><tr><td>Sentence</td><td>7.57</td><td>5.52</td><td>5.73</td><td>4.17</td><td>1.85</td><td>1.68</td><td>92</td><td>0.09</td></tr><tr><td>Paragraph</td><td>1.00</td><td>1.11</td><td>0.82</td><td>1.26</td><td>0.18</td><td>0.72</td><td>92</td><td>0.47</td></tr></table></body></html>

a $n = 6 1$ . b n = 33.

# Hypothesis 4: Level of revision

Please recall that six students’ essays were not available for analyses of level of revision due to technical difficulties. To see if English proficiency affected the level of revision, 94 students were divided into groups based on their holistic scores on the second drafts. It was expected that advanced students would pay more attention to the global level of revision (i.e., sentence and paragraph levels) than the local level of revision (i.e., word and phrase levels). Research (e.g. Bridwell, Brooke, & Sirc, 1989) suggests that students may pay more attention to larger units of discourse for revision when they compose on computers. Overall, 33 students got a score of 2, 55 students received a score of 3, and 6 students got the highest score of 4 on second drafts. Due to the small number of students in the third group, they were combined with students with a score of 3 to form an advanced group. Thus, the 33 students with a score of 2 were classified as intermediate students, while the 61 students with a score of 3 or 4 were classified as advanced students. Drawing on the categorical analysis of levels of revision (see Appendix B), Table 6 shows that advanced students made more changes at the phrase, sentence, and paragraph levels than did intermediate students, whereas intermediate students made more changes at the word and mechanics levels than advanced students. Students in both groups made the most changes at the word level. However, multiple independent $t$ -tests showed that none of these mean differences in level of revisions were significant. This indicates that the intermediate and advanced students (as defined here by holistic scores) made similar revisions in terms of both category and frequency.

To examine if level of revision was related to change of analytic scores, the six analytic scores were classified into three categories: increase, same, or decrease. Due to insufficient numbers for two categories of same and decrease, these two groups were combined for statistical analyses. Each analytic score was used to classify the 94 students into two groups: (1) a high group, with increased analytic scores, and (2) a low group, with same or decreased scores. Multiple independent $t$ -tests were done to examine five levels of revision between the two groups for each analytic scale. Only two categories (organization and content) showed significant differences. Table 7 presents multiple independent $t$ -tests analysis for organization scores. As in Table 7, the $p$ -values for word and paragraph are less than 0.01 and for mechanics are below the 0.05 level. The word and paragraph levels of revision were significantly associated with changes of organization scores. Students who made changes at the paragraph level received higher scores on organization than those who did not. Table 8 presents multiple independent $t$ -tests analysis for content scores. Again, there were highly significant results for word and paragraph levels of revision as well as significance for mechanics. In all cases, the high group made more changes at these levels. These findings are interesting and not entirely expected. Broadly, the literature suggests that global changes would be most likely to produce changes in categories like organization and content. Thus, the significant finding for paragraphs is expected. However, it is less clear why the next two levels (sentence and phrase) would not be significant while the lowest levels (word and mechanics) appear to be significant. It may be that such local changes had global effects on readers. Of course, it is also important to recall that analytic scores are themselves based on holistic judgment, so these findings may point to ways that raters used the categories to account for perceived quality differences.

Table 7 Multiple independent $t$ -test for level of revision: organization scores   

<html><body><table><tr><td rowspan="2">Level of revision</td><td colspan="2">High groupa</td><td colspan="2">Low groupb</td><td colspan="4">Independent t-test</td></tr><tr><td>m</td><td>S.D.</td><td>m</td><td>S.D.</td><td>Mean difference</td><td>t</td><td>d.f.</td><td>p</td></tr><tr><td>Mechanics</td><td>5.17</td><td>3.65</td><td>3.42</td><td>3.83</td><td>1.74</td><td>2.09</td><td>92</td><td>0.039*</td></tr><tr><td>Word</td><td>19.80</td><td>10.77</td><td>12.66</td><td>11.07</td><td>7.14</td><td>2.94</td><td>92</td><td>0.004**</td></tr><tr><td>Phrase</td><td>7.33</td><td>7.09</td><td>10.40</td><td>7.24</td><td>3.07</td><td>1.95</td><td>92</td><td>0.055</td></tr><tr><td>Sentence</td><td>6.97</td><td>5.74</td><td>6.83</td><td>3.63</td><td>0.14</td><td>0.19</td><td>92</td><td>0.906</td></tr><tr><td>Paragraph</td><td>1.27</td><td>1.25</td><td>0.23</td><td>0.43</td><td>1.03</td><td>4.39</td><td>92</td><td>0.000**</td></tr></table></body></html>

a $n = 6 4$ . b $n = 3 0$ . p < 0.05. $p < 0 . 0 1$ .

# Examples of students’ revisions

To get a better qualitative feel for how these relationships were manifested in students’ essays, we can examine examples extracted from three sets of essays. Fig. 3 offers a glimpse into how

Table 8 Multiple independent $t$ -test for level of revision: content scores   

<html><body><table><tr><td rowspan="2">Level of revision</td><td colspan="2">High groupa</td><td colspan="2">Low groupb</td><td colspan="4">Independent test</td></tr><tr><td>m</td><td>S.D.</td><td>m</td><td>S.D.</td><td>Mean difference</td><td>t</td><td>d.f.</td><td>p</td></tr><tr><td>Mechanics</td><td>5.35</td><td>4.07</td><td>3.46</td><td>3.65</td><td>1.89</td><td>2.18</td><td>92</td><td>0.032*</td></tr><tr><td>Word</td><td>21.53</td><td>12.53</td><td>12.53</td><td>10.67</td><td>8.70</td><td>3.50</td><td>92</td><td>0.001**</td></tr><tr><td>Phrase</td><td>7.54</td><td>6.88</td><td>10.31</td><td>7.92</td><td>2.76</td><td>1.67</td><td>92</td><td>0.098</td></tr><tr><td>Sentence</td><td>6.72</td><td>4.94</td><td>7.46</td><td>5.70</td><td>0.74</td><td>0.62</td><td>92</td><td>0.535</td></tr><tr><td>Paragraph</td><td>1.15</td><td>1.26</td><td>0.38</td><td>0.57</td><td>0.76</td><td>2.96</td><td>92</td><td>0.004**</td></tr></table></body></html>

$n = 6 8$ . b $n = 2 6$ . p < 0.05. p < 0.01.

# First draft

First we know that our brain is divide in two parts or two hemispheres. Those sides of our brain is associated with some works or talents, for example the right side of the brain is associated with the music, art, emotions and memorable things, and the left side is more rational and is associated with the math, reading and wrinting, numbers. On the video tape also they said that we use both side of the brain and each side control that side of our body.

# Second draft

First we know that our brain is divided in two parts or two hemispheres. Those sides of our brain was associated with some talents, for example the right side of the brain is associated with the music, art, emotions and memorable things, and the left side is more rational and is associated with the math, reading and writing, numbers. On the video tape also they said that we use both side of the brain and each side controls each side of our body. And this two hemispheres are joined with a "Corpus Callosum" that permit to combine both sides of our brain. There are many deseases of brains one of then is the "Aphasia' this desease consist when one of the hemisphere do not work correctly. This and another deseases can be detect by a "Brain Scan' this is a method can help to us to find this and another problems related with the brain.

increased text length contributed to improved essay quality. This essay increased by 185 words, and its holistic score increased from 2 to 3. This paragraph shows minor revision to the existing text at the word level, but is most marked by addition of three sentences providing new information. In contrast, Fig. 4 shows an example in which a minimal increase in the text length was associated with no change of scores. This essay increased by one word from 340 to 341, and its score of 2 remained the same from the first to the second draft. It is the essay with the least increased text length among the 33 essays whose scores remained the same. However, it is worth noting that this paragraph displays extensive revision at the word and phrase level. In fact, every sentence in the paragraph displays some revision. Fig. 5 illustrates an example where holistic scores decreased from 3 to 2 and this essay only increased by 46 words. It is the essay with the least increased text length among five essays whose scores decreased. This paragraph displays minor revision at the word and phrase level and it still contains noticeable grammatical and spelling errors.

# First draft

Science make us understand, with several research, that many of the process that we make diary is related with our actions and the manner to manage situations. Our brian consist of two hemispheres. The left hemisphere that control all of the process and action of th entire right side of the body. The other division of the brain was the right hemisphere that control the entire left side of the body. Also of the scientific research show that the left brain control our logical an rational side. That mean that this part of the brain work directly with information like nombers, letters, and words. The left side work direct with the emotinal and intuition part that work with images, concepts, and ideas.

# Second draft

Science make us understand many of the process that we make everyday. It is related with our brain's features and functions, like was explained in the videotape. Our brain basically consist of two hemispheres, left hemisphere, and right hemisphere. The left hemisphere control all of the process and actions that occur at the entire right side of ourt body. The other division of the brain, the right hemisphere, controls the entire left side of the body. Also the scientific research, shows that the left brain controls our logical and rational side. That means that this part of the brain works directly with mathematical and linguistic process. The left side works direct with the emotinal and intuitive part that work with abstract process. This information gives us an idea how conduct a effective advertising process.

Fig. 4. One paragraph from the essay that shows the same score from the first to second draft (ID 0604). Text additions are highlighted in bold in the second draft paragraph.

# Test takers’ perceptions of the CEEPT

From a practical perspective, as we consider how students took up the opportunities for feedback, reflection, and revision in this assessment, it is also useful to examine how the students perceived the assessment and reacted to having to spend an entire day taking a writing placement test. A CEEPT survey was administered to participants on the same day they took the test in August 2005. The CEEPT survey elicited test takers’ perceptions of (a) format and content of the test, (b) computer mode, and (c) revision process through closed- and open-ended items. The open-ended item on the CEEPT survey asked students to discuss their overall reactions to the test.

# First draft

Informatin about the brain straucture and asymmetry can also be used to decide on the strategy at the stages of the marketing. For instance, if the most important think is the taking attention of the customer, than artistic and creative advertisement is used instead of pure information. To sell a sport car, it is important to persuade the customer to come the car store. In selling luxury products, you have to persuade the customer in car store. You can not persuade the customer at home. So, important thing is persuading them buying a sport car and coming to your store.

# Second draft

Secondly, information about the brain structure and asymmetry can be used to decide on the strategy at the stages of the marketing. For instance, if the most important think is the taking attention of the customer, than artistic and creative advertisement is used instead of pure information. To sell a sport car, it is important to persuade the customer to come the car store. In selling luxury products, you have to persuade the customers in car store instead of their home. So, important thing is persuading them buying a sport car and coming to your store.

Responses to the open-ended item on the CEEPT survey were analyzed. By transcribing the answers and reading through them, I was able to discover several categories or groupings. Test takers’ responses were classified into six themes: (1) time, (2) peer feedback, (3) group discussion, (4) authentic writing, (5) general comments, and (6) suggestions for the future CEEPT. Critical comments are presented in Table 9, but they are not corrected for grammatical errors. The most important part of the response is italicized.

Responses showed positive evidence in support of the CEEPT, as presented in Table 9. Students strongly perceived the benefit of the CEEPT in terms of the opportunity to elicit their true writing abilities. Students had mixed feelings toward the time and peer feedback. It is interesting to note that the negative comments about time included short as well as long test length. There were no negative comments regarding group discussion, authentic writing, or general aspects. The effect of each activity of the CEEPT on test performance and on types of revision needs further research. However, this information suggests that many of the students did not find this type of assessment unduly burdensome or irrelevant to eliciting valid measurement of their academic writing abilities.

<html><body><table><tr><td colspan="3">Table 9 Excerpts from students&#x27; reactions to the CEEPT</td></tr><tr><td>Type of Positive comments comments</td><td></td><td>Negative comments</td></tr><tr><td>Time</td><td>&quot;I guess the time factor really plays a key role and the longer duration gave me time to generate more ideas and gave me a chance to work on it.&quot; &quot;Enough time and brainstorming make the ideas more varied.&quot;</td><td>Short time needed &quot;Shorter time is better.&quot; &quot;We should reduce the length of the test.&quot; Long time needed &quot;I think the writing time (50 + 50 minute) is a bit short for people like me that writes slowly.&quot; &quot;The method was fine. But I think it needs much time to finish&quot; &quot;Although the test takes a lot of time,</td></tr><tr><td>Peer feedback</td><td>was not enough.&quot; &quot;The other major factor which really ameliorates your writing skills is peer discussion.&quot; &quot;It was informative, especially with peers. I could judge whether I perceived the title of the topic in the right manner while discussing with peer groups.&quot; &quot;It was a good opportunity to learn about other. international students&#x27; English proficiency.&quot; &quot;It is a good method to improve English writing, especially through peer editing.&quot;</td><td>&quot;However, depending on the discussion partners, the quantity and quality of the information can differ. If you want to apply this form to the TOEFL test, the unfairness between participants will be a serious problem in my opinion.&quot;&#x27; &quot;Group members have almost similar ability in writing. So, sometimes it makes me confused&quot;</td></tr><tr><td>Group discussion</td><td>&quot;It is more interesting and I can get new ideas from the group members.&quot; &quot;We could talk to each other, get more ideas than just from myself.&quot; &quot;Discussion as a group makes me write an essay more comfortably and excitingly&quot; &quot;Brainstorming is an effective way to write an</td><td>None</td></tr><tr><td>Authentic writing</td><td>academic essay.&quot; &quot;You have ideas and feedback on the subject and your writing is nice and more realistic because mostly you write in the real world like in this test.&quot; &quot;It teaches me how to write, discuss, and revise in the real world&quot; &quot;Definitely, more realistic and efficient than TOEFL or GRE.&quot; &quot;In the real situation, we can get lots of information about the subject of the essay while writing it. So I think that this test is appropriate for testing the writing ability in a real situation.&quot; &quot;Congratulations! This method really can measure the real ability to write an essay.&quot; &quot;Because this test is like a real situation - writing</td><td>None</td></tr></table></body></html>

Table 9 (Continued )   

<html><body><table><tr><td>Type of comments</td><td>Positive comments</td><td>Negative comments</td></tr><tr><td>General</td><td>&quot;It gives me more time to revise my first draft, come up with new ideas, and clarify my thoughts which I believe reflects my true ability in writing.&#x27; &quot;It helped me have broad ideas about the topic.&quot; &quot;It is interesting and no pressure&quot;. &quot;I can feel more relaxed&quot; &quot;I had lots of fun, had self-confidence.&quot;.</td><td>None</td></tr><tr><td>Suggestions for the future CEEPT</td><td>of stress got a lot lower with this kind of test.&quot;. &quot;It is a new experience for me to write an essay.&quot;. &quot;You should have more CEEPT.&quot;. &quot;Keep going with this test. I didn&#x27;t feel stressed and I actually enjoyed it.&quot; &quot;It is good to provide some protecting screen to protect our eyes. The rays from the screen directly run into our eyes and skins.&quot; &quot;It is very long and if you can give coffee the next time, it will be better.&quot; &quot;This method is applicable for nonsensitive exams, not the GRE/TOEFL. The GRE/TOEFL is more formal and important and is strongly dependent on partner.&quot;.</td><td></td></tr></table></body></html>

# Conclusions

By examining to what extent and in what ways the quality of essays differed between first and second drafts composed during the CEEPT, this study investigated how this group of ESL graduate students at a major U.S. university took up opportunities for feedback, reflection, and revision during an ESL writing assessment. The results of this study confirmed the four basic hypotheses. There were significant score differences between two drafts composed during the CEEPT, as indicated by analytic as well as holistic scores. Quantitative analysis of the texts showed that students produced significantly more words, T-units, and complex sentences on second drafts than on first drafts. Evidence from the analysis of levels of revision showed that the students focused on global revision as well as local. In particular, there was a significant relationship between paragraph level revision and change of organization scores. By adding, deleting, and replacing paragraphs, second drafts became more organized than first ones; the second drafts were presented in a more coherent manner and with better structures. However, the relationship of levels of revision to holistic scores were not significant and the finding that changes in mechanics and words (and not higher-level changes in phrases or sentences) were also significantly related to changes in analytic scores for organization and content suggest a need for further investigation. In short, this research shows that many students took advantage of the structured process offered in this assessment; they went beyond increasing the text length and produced final drafts that qualitatively included key features of academic writing and that pointed to key writing processes: increased holistic and analytic scores, complex sentences, and global revision for content and organization. These measures then were able to provide useful information about the ways that students’ final drafts improved significantly and about the ways they engage in revision.

There are several limitations to the present study. The results might have been different if a different writing topic had been used. It is important to recognize that although the first drafts were analyzed in this research, from the perspectives of the students these texts were intermediate drafts that would not be assessed for their placement. The present research did not investigate how specific components of the test structure (i.e. time, opportunity for revision, peer response) contributed to the ways students engaged in revision. This study did not investigate how students’ past experiences with writing or their beliefs about writing shaped their engagement in the process during this assessment. A closer study of actions and talk in the sessions would provide important data to better understand how these students took up (and did not take up) these opportunities for feedback, reflection, and revision. These limitations suggest avenues for future research.

In summary, the CEEPT, the institutional ESL process-oriented writing assessment at UIUC, attempts to capture important real world academic writing practices as it provided students not only with a chance to revise their essays, but also with opportunities for feedback, discussion, learning, and reflection. Evidence suggests that students did engage in these opportunities in general. Thus, the benefit of process-oriented writing assessment as it is presently constructed in the CEEPT seems justified. This study offers insights into, and one possible model of, process-oriented writing assessment. The CEEPT, as one promising form of process-oriented writing assessment, can provide a potential alternative between timed single-draft essay tests and portfolio assessments. The findings in this study advance our understanding of ESL writing assessments and should also contribute to broader examination of how ESL graduate students engage in revision of their writing in diverse contexts.

# Acknowledgments

This article is a part of my dissertation research at the University of Illinois at UrbanaChampaign. I wish to express my deep gratitude to my dissertation director, Professor Fred Davidson and my dissertation committee member, Professor Paul Prior. They spent their valuable time helping me with various aspects of this project. I am really grateful to Professor Prior for his careful reading and insightful comments on earlier versions of this paper. I would like to thank the English Language Institute of the University of Michigan and Educational Testing Service for funding this research project. Finally, I would like to thank editors and two anonymous reviewers for their helpful suggestions.

# References

Belanoff, P., & Dickson, M. (Eds.). (1991). Portfolios: Process and product. Portsmouth, NJ: Boynton/Cook.   
Bridwell, L., Brooke, R., & Sirc, G. (1989). Revising and computing: Case studies of student writers. In S. W. Freedman (Ed.), The acquisition of written language: Response and revision (pp. 172–193). Norwood, New Jersey: Ablex Publishing Corporation.   
Callahan, S. (1997). Tests worth taking?: Using portfolios for accountability in Kentucky. Research in the Teaching of English, 31, 295–336.   
Camp, R. (1993). The place of portfolios in our changing views of writing assessment. In R. E. Bennett, & W. C. Ward (Eds.), Construction versus choice in cognitive measurement: Issues in constructed response, performance testing, and portfolio assessment (pp. 183–212). Hillsdale, NJ: Lawrence Erlbaum.   
Cho, Y. (2001). Examining a process-oriented writing assessment in a large-scale ESL testing context. Unpublished doctoral dissertation. University of Illinois at Urbana-Champaign.   
Freedman, S. W. (1993). Linking large-scale testing and classroom portfolio assessments of student writing. Educational Assessment, 1, 27–52.   
Goldberg, G. L., Roswell, B. S., & Michaels, H. (1995). Can assessment mirror instruction? A look at peer response and revision in a large-scale writing test. Educational Assessment, 3, 287–314.   
Hinkel, E. (2002). Second language writers’ text: Linguistic and rhetorical features. Mahwah, NJ: Lawrence Erlbaum Associates.   
Kim, M. (2002). Process and product: An investigation of the writing on non-native speakers of English on a computerbased academic English writing test. Unpublished doctoral dissertation. University of California at Los Angeles.   
Lee, H.-K. (2002). A comparative study of ESL writers’ performance in a paper-based and a computer-delivered writing test. Unpublished master’s thesis equivalent paper. University of Illinois at Urbana-Champaign.   
Polio, C. (1997). Measures of linguistic accuracy in second language writing research. Language Learning, 47, 101–143.   
Prior, P. (1998). Writing/disciplinarity: A sociohistoric account of literate activity in the academy. Mahwah, NJ: Lawrence Erlbaum.   
Pyo, K. (2001). Construct validation of an integrated-approach EAP placement test using multi-group structural equation modeling. Unpublished doctoral dissertation. University of Illinois at Urbana-Champaign.   
Susser, B. (1994). Process approaches in ESL/EFL writing instruction. Journal of Second Language Writing, 3, 31–47.   
Wiggins, G. (1994). The constant danger of sacrificing validity to reliability: Making writing assessment serve writers. Assessing Writing, 1, 129–139.   
Zhu, W. (1995). Effects of training for peer response on students’ comments and interaction. Written Communication, 12, 492–528.

# Appendix A

UIUC CEEPT rating scale   
Holistic rating scale   
Division of English as International Language (DEIL)

# Too low

- Insufficient length.   
- Extremely bad grammar.   
- Does not write on assigned topic; does not use any information from the sources.   
- Majority of essay directly copied.   
- Summary of source content marked by inaccuracies.

# ESL 500

- May contain an introduction, body, and conclusion (generally simplistic).   
- Does not flow smoothly; hard to follow ideas.   
- Lacks development and/or substantial content.   
- May be off topic.   
- Little or no use of sources to develop ideas.   
- Lacks synthesis (of ideas in the two sources or of source and the student’s own ideas).   
- Summary of source content contains minor inaccuracies and possibly major inaccuracies.   
- Lacks sophistication in linguistic expression; little sentence variety and sentence complexity not mastered.   
- Lexical-grammatical inaccuracies are frequent and impede comprehension; awkwardness.   
- Attempts at paraphrase are generally unskillful and inaccurate.

# ESL 501

- Usually contains an introduction, body, and conclusion (reasonable attempt).   
- Some development or elaboration of ideas.   
- Some use of sources to develop ideas.   
- Writes on topic.   
- Some synthesis (of ideas in the two sources or of sources and the student’s own ideas).   
- Summary of source content may contain minor inaccuracies.   
- Neither simplistic and awkward nor smooth and sophisticated.   
- Some sentence variety and complexity.   
- Some grammatical-lexical errors; essay still comprehensible.   
- Moderately successful paraphrase (in terms of smoothness and accuracy).

# Exempt

- Usually contains an introduction, body, and conclusion.   
- Substantive content and effective elaboration (whether based on sources or own ideas).   
- Writes on topic.   
- Good synthesis (of ideas in the two sources or of source and the student’s own ideas).   
- Summary of source content usually accurate.   
- Effective skillful paraphrase (ideas accurate and smooth expression).   
- Smooth flowing (may be sophisticated with lexical and sentence variety and complexity).   
- Strong linguistic expression (in terms of grammar, vocabulary, and style).

Analytic rating scale Adapted from Lee (2002)

# Organization

1. No plan, insufficient length to ascertain organization.   
2. No clear plan or does not follow plan; lack of paragraph and essay cohesion.   
3. Noticeable plan. Reasonable attempt at introduction, body, conclusion; some paragraph and   
essay cohesion.   
4. Clear plan; excellent introduction, body, conclusion; cohesion at paragraph and essay level.

# Content

1. No support or elaboration of ideas; insufficient length to evaluate. Irrelevant to assigned topic; completely lacking main idea.   
2. Main idea attempted to develop, but not successful or basic restatement. Attempted elaboration; minimal or ineffective support for ideas, or insufficient length.   
3. Most points elaborated. Ideas developed and supported somewhat.   
4. Main idea developed well. All major points elaborated. Ideas developed, and well supported.

# Grammar and lexical choice

1. Extremely bad grammar; totally incomprehensible. No sentence variety or complexity.

2. Frequent grammatical/lexical errors; awkwardness. Little sentence variety and sentence complexity not mastered.   
3. Some grammatical/lexical errors; but still comprehensible. Some sentence variety and complexity.   
4. Grammatical/lexical errors do not impede understanding. Few errors, mostly easily corrected; sentence variety; sophisticated vocabulary usage and sentence complexity mastered.

# Use of sources

1. Fails to use any information from sources; or summary of source content marked by inaccuracies.   
2. Some source use, but may be insufficient to evaluate source understanding or contains major concepts and minor details.   
3. Overall accurately summarized, but may contain a few minor inaccuracies.   
4. Effective use of sources to support ideas. No major inaccuracies in summary of source content.

# Avoidance of plagiarism

1. Majority copied without citation.   
2. Overt plagiarism committed (direct copying 1/3 of essay).   
3. Covert plagiarism committed (imperfect attempts to paraphrase, infrequent direct copying up   
to two sentences).   
4. None/minimal plagiarism committed (citation of source desirable, but not necessary).

# Mechanics

1. Excessive typos impede understanding; indentation, paragraphing, and overall format are poor; mostly incorrect use of capitalization and punctuation.   
2. Frequent typos; indentation, paragraphing, and overall format are good; often incorrect use of capitalization and punctuation.   
3. Some typos; indentation, paragraphing, and overall format are very good; usually correct use of capitalization and punctuation.   
4. Few typos; indentation, paragraphing, and overall format are excellent; correct use of capitalization and punctuation.

# Appendix B.

Analytical coding for levels of revision with examples from the data

<html><body><table><tr><td colspan="2">Examples of mechanical changes</td></tr><tr><td>Type of change</td><td>Examples</td></tr><tr><td>Spelling</td><td>The president of an asdvertising company (ID 0605)</td></tr><tr><td rowspan="3">Punctuation</td><td>On the country, a beautiful lady (ID 1301)</td></tr><tr><td>Right-brained people (ID 1310)</td></tr><tr><td>None</td></tr><tr><td>Font Capitalization</td><td>Both parts of the brain are connected with something called Ceorpus Ceallusum... (ID 2005)</td></tr></table></body></html>

Examples of word level revision

Appendix B (Continued)   

<html><body><table><tr><td>Type of change</td><td>Examples</td></tr><tr><td>Addition</td><td>People usually believe that scientific findings are not useful in daily life, but is not necessarily</td></tr><tr><td>Deletion</td><td>true (ID 1329) There are two different pools of people thinking in two different directions in the field of</td></tr><tr><td>Movement</td><td>brain specialization area (ID 2001) But, the inspiring advertising with different brain underlying strategies can stimulate me</td></tr><tr><td>Replacement</td><td>and persuade me to pay for the produces if I really need (ID 2010) Acoording to the article (Brain Specialization and Advertising), the right brain copes deals</td></tr></table></body></html>

Examples of phrase level revision

<html><body><table><tr><td>Type of change</td><td>Examples</td></tr><tr><td>Addition</td><td>In sum, according to researches advertisement and using of the brain are so related with each other (ID 1330)</td></tr><tr><td>Deletion</td><td>For this reason, it is essential to understand the different strategies to insipire positive</td></tr><tr><td>Movement</td><td>advertising (ID 2034) None</td></tr><tr><td>Replacement</td><td>You will choose to sell a car with a beautiful girl showing the car.. model girl (ID 2031)</td></tr></table></body></html>

Examples of sentence level revision

<html><body><table><tr><td>Type of change</td><td>Examples</td></tr><tr><td>Addition</td><td>There are several examples of efficiency of emotional advertising. First, companies can make people remember them or their products by using celebrities (ID 0609)</td></tr><tr><td>Deletion</td><td>The core movement is brain strueture and advertising. If I am advertiser, I have to choose- the best way for consumer&#x27;s purehase. (ID 2021)</td></tr><tr><td>Movement</td><td>So the firm of advertisor can make more benefit. In conclusion, an advertisor should consider the potential customers features while choosing the advertising strategies. Defining the features of eustomers, the functions of hemispheres takes important place. -- So the firm of advertisor can make more benefit. In this content, an advertiser should keep in mind that defining the potential customer group has an important role.</td></tr><tr><td></td><td>Defining the features of customers, the functions of hemispheres takes important place. In conclusion, an advertiser should define the potential customers group firstly and then consider the potential customers features while</td></tr><tr><td>Replacement</td><td>choosing the marketing strategies (ID 1319) However, it will bring us a big success in maketing plan if we can intergrate rightly this knowledge into the advertising. with the aid of this diseovery, more and more advertising</td></tr></table></body></html>

Examples of paragraph level revision

<html><body><table><tr><td>Type of change</td><td>Examples</td></tr><tr><td>Addition</td><td>In word, the advertising is related with brain structure. To create good advertisement,</td></tr><tr><td rowspan="4"></td><td>the advertisers should consider human beings&#x27; brain structure for forcasting consumers&#x27;</td></tr><tr><td>behaviour and apply to their advertising. Because of different type of brain, the successful</td></tr><tr><td>advertising should include both left-brained advertising and right- brained advertising</td></tr><tr><td>strategies in their advertising (ID 2030)</td></tr></table></body></html>

<html><body><table><tr><td>Deletion Movement Replacement</td><td>At this time you might be thinking or asking about the importanee of this. ..- Well, knowing- this is quite important, beeause depending of what sides of our brain we use mostly we made- decisions about our life. For example, imagine that you want to buy a new house, and someone. shows you different types of house, for example small one (apartment) but very near from your- work and modern, and another one more bigger but far from your work and with a garden.- What king of information do you need in order to deeide? Well, all depends of your needs, but- also of what king of person you are a right brain oriented, or a left brain oriented. (ID 1328) None As for the left side of brain, it controls of our left part body, and is related to emotion,- intuition. It works with images, consepts and so on. So it could be said that left side of brain- is our emotional sense. Left brain orinted people have advantag over right brain oriented ones.</td></tr></table></body></html>

Young-Ju Lee received her M.A. in Applied Linguistics and TESL from the University of California at Los Angeles. She earned her Ph.D. in Educational Psychology at the University of Illinois at Urbana-Champaign, specializing in language assessment. She is interested in qualitative and quantitative validation studies, ESL writing assessments, impact studies, computerized testing, and interface between second language acquisition and language testing. She is currently working as a research scientist at Korea Institute of Curriculum and Evaluation in Seoul, Korea.