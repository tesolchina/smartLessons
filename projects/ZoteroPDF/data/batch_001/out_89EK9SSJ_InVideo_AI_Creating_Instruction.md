# InVideo AI: Creating Instructional Audiovisual Input for English Learning

# Han Lin

School of Foreign Studies, South China Normal University, People’s Republic of China

# Xiaobin Liu

School of Foreign Studies, South China Normal University, People’s Republic of China

# Abstract

Videos serve as potent multimodal stimuli in the field of EFL instruction, supported by robust theoretical foundations about multimedia learning. However, creating pedagogically appropriate videos presents challenges, particularly in selecting suitable resources for specific instructional objectives. InVideo AI stands out as a powerful platform for streamlined and personalized video creation. Within EFL learning, it offers the conversion of text into engaging video content to enhance comprehension, the creation of supplementary materials for enriching language input, and the facilitation of diverse learning activities through customized settings. This tech review aims to present an in-depth exploration of InVideo AI and its applications in English language learning, highlighting both the advantages and constraints of this innovative platform.

# Keywords

InVideo AI, video, audiovisual input, multimodal input, multimedia learning

# Introduction

The integration of videos in English as a Foreign Language (EFL) learning, supported by the cognitive theory of multimedia learning (Mayer, 2020) and dual coding theory (Paivio, 1990), enhances learning efficacy by engaging diverse sensory channels and facilitating deeper cognitive processing. Videos serve as instructional audiovisual materials and multimodal input, combining visual stimuli, such as animations, with auditory texts to mitigate cognitive load (Castro-Alonso and Sweller, 2021), thereby enhancing listening comprehension, reading proficiency, grammar acquisition, and vocabulary assimilation (Zhang and Zou, 2022). However, creating pedagogically appropriate videos poses challenges, particularly in selecting suitable resources for specific instructional objectives (Kessler, 2018). InVideo AI, as an innovative artificial intelligence (AI) video creation platform, effectively addresses these challenges by generating tailored, pedagogically aligned videos, thereby benefiting EFL instruction.

# Overview

InVideo AI is a cutting-edge AI-driven video creation tool with exceptional text-to-video conversion capabilities (https://ai.invideo.io). Featuring a user-friendly interface, it simplifies the video production. The platform provides prompt-writing guidance tailored to a chosen workflow (see Figure 1). Through the specification of requirements such as background music style and other settings, prompts are automatically generated.

Experienced users have the option to circumvent this initial step and input prompts directly for video creation. By analyzing the prompt, the platform provides various options for audience, visual style, and targeted platform (see Figure 2). Leveraging its vast media library, InVideo AI carefully selects video clips, seamlessly integrating them with natural voiceovers and appropriate background music to match the prompt. Undoubtedly, this tool serves as an indispensable tool for generating instructional content tailored to language learning objectives.

# Facilitating Comprehension Through Multimodal Input

Combining images, sounds, and even subtitles concurrently, videos offer contextualized English learning that aids learners in language comprehension (Teng, 2019). InVideo AI enables users to convert listening scripts and reading texts into videos, facilitating comprehension by supplementing vivid animations with textual information. As shown in Figure 3, InVideo AI vividly illustrates the geographical features of Peru in an EFL textbook paragraph, making it more understandable to learners compared to plain text.

![](img/320290d71f284a3681329b32eeba9e7e60100875b4592b0fdd7347f839e12bfd.jpg)  
Figure 1. Prompt writing guidance on different workflows.

![](img/f9dcbf3195c3644a53d83509517b42c9d4e1f1506e86ac99971d44ed4d788a67.jpg)  
Figure 2. Text prompt and personalized options for video creation.

![](img/5c225f8ca5767e3d2e56f0073778142902465fecceb183e0a9b77df23256686b.jpg)  
Figure 3. Text-to-video conversion by InVideo AI.

Users can personalize the generated videos by providing prompts to add subtitles, adjust scenes, or modify the voice. Figure 4 showcases InVideo AI’s ability to incorporate an interactive introductory chapter with thought-provoking questions, enhancing interactivity and purposeful viewing.

![](img/c7fed995f11bf2206393b7a28500ab017f3d1e037b15ac28d19afa45da630eec.jpg)  
Figure 4. Adding comprehension questions to the generated videos.

# Enriching Language Input with Creative Resources

Thematic-related input is beneficial for language acquisition (McDonald and Reynolds, 2023). InVideo AI enables video creation tailored to specific topics, offering rich language input within the same thematic context. For instance, after learning a text on Peru, additional videos (see Figure 2) can expand students’ comprehension of Peruvian culture, aiding in acquiring thematic-related expressions related to Peru’s history, geography, cuisine, etc.

Furthermore, the structure-specific salience of videos facilitates grammar learning (Cintrón-Valentín et al., 2019). InVideo AI can also generate videos focusing on specific grammatical forms. For example, aligned with a unit’s thematic context and grammatical emphasis in an EFL textbook, a video introducing natural disasters using restrictive attributive clauses is produced (see Figure 5), assisting students in perceiving grammatical structures within a defined context.

# Supporting Diverse Activities by Different Settings

InVideo AI allows customizable video settings for a variety of English audiovisual and speaking activities. Different subtitle options cater to various learning tasks: videos without subtitles support dictation and retelling, while videos with subtitles aid pronunciation activities such as imitative reading and dubbing. Word-by-word subtitles, highlighting the current spoken word in yellow (see Figure 6), are ideal for shadowing practice. Sequential viewing of the video without subtitles followed by viewing with subtitles facilitates extensive and intensive listening exercises, enhancing students’ skills to grasp main ideas and capture details. Teachers can also adjust voice and accent settings to create customized videos for diverse learning activities.

![](img/3e98e8f6832f3ad2bd5e91999ef0e73fc953974727afc63116324641eafc2a83.jpg)  
Figure 5. Videos focusing on specific grammatical forms.

![](img/755bc29605ad287b59c855a2dbe6903033907cadf893ff74989c0691e29b2f9b.jpg)  
Figure 6. Word-by-word subtitles with the current spoken word highlighted.

# Conclusion

InVideo AI is a powerful video generation tool that enhances comprehension, enriches language input, and facilitates various activities through tailored settings, making it applicable across reading, grammar, listening, and speaking courses. However, it has limitations. Features such as specified text enhancement in subtitles and annotation processing, identified as beneficial for vocabulary acquisition (Zou and Teng, 2023), are lacking in InVideo AI. Language teachers can utilize other video editors, such as Microsoft

![](img/fe7c92365d4a82161cf1c19fad9d4e15c88643d612fdc1c5194c1b019a7121ed.jpg)  
Figure 7. Keyword annotation by Microsoft Clipchamp.

Clipchamp, for subsequent annotations (See Figure 7). Additionally, current free users of InVideo AI are limited to 10-min AI creations and 4 watermarked video exports weekly. A paid upgrade to the Premium version can unlock these restrictions, if necessary. Finally, the progress in generative AI video creators, such as Sora by OpenAI, may challenge InVideo AI, which relies on existing libraries. Nevertheless, the creative use of InVideo AI still offers valuable insights for the pedagogical application of future video platforms.

# Declaration of Conflicting Interests

The authors declared no potential conflicts of interest with respect to the research, authorship and/or publication of this article.

# Funding

The authors received no financial support for the research, authorship, and/or publication of this article.

# ORCID iDs

Han Lin $\textcircled{1}$ https://orcid.org/0009-0005-0114-6348   
Xiaobin Liu $\textcircled{1}$ https://orcid.org/0000-0001-5395-4420

# References

Castro-Alonso JC and Sweller J (2021) The modality principle in multimedia learning. In: Mayer RE and Fiorella L (eds) The Cambridge handbook of multimedia learning. Cambridge: Cambridge University Press, 261–267. DOI: 10.1017/9781108894333.026

Cintrón-Valentín M, García-Amaya L and Ellis NC (2019) Captioning and grammar learning in the L2 Spanish classroom. The Language Learning Journal 47(4): 439–459.   
Kessler G (2018) Technology and the future of language teaching. Foreign Language Annals 51(1): 205–218.   
Mayer RE (2020) Multimedia learning. 3rd edn. Cambridge: Cambridge University Press. DOI: 10. 1017/9781316941355   
McDonald JA and Reynolds BL (2023) Learning semantic and thematic vocabulary clusters through embedded instruction: Effects on very young English learners’ vocabulary acquisition and retention. Applied Linguistics Review 14(5): 1129–1156.   
Paivio A (1990) Mental representation: A dual-coding approach. Oxford: Oxford University Press. DOI: 10.1093/acprof:oso/9780195066661.001.0001   
Teng MF (2019) Maximizing the potential of captions for primary school ESL students’ comprehension of English-language videos. Computer Assisted Language Learning 32(7): 665–691.   
Zhang R and Zou D (2022) A state-of-the-art review of the modes and effectiveness of multimedia input for second and foreign language learning. Computer Assisted Language Learning 35(9): 2790–2816.   
Zou D and Teng MF (2023) Effects of tasks and multimedia annotations on vocabulary learning. System 115: 103050.