# Comparing trained EFL peer reviewers' feedback: From claim to reality

Alireza Memari Hanjani'

epartment of English Language, Islamshahr Branch, Islamic Azad University, Islamshahr, Iran

# ARTICLEINFO

# ABSTRACT

Keywords:   
L2 writing   
Peer review training Peer evaluation   
Peer feedback nature Peer feedback focus Peer feedback quality

Comparing trained L2 writing student reviewers' feedback behaviors as well as examining the extent to which their claims are aligned with their actual evaluation practices have received limited scholarly attention. Employing think-aloud protocols, one cause and one effect essays evaluated by five upper-intermediate L2 learners, and follow-up semi-structured interviews, this case study research aimed to explore trained L2 peer reviewers' feedback behaviors and the matches and mismatches between their claims and evaluation practices. While the first and the second data source compared the participants' actual feedback practices in terms of nature, type, and validity, the last source probed their claims on peer evaluation. The findings contribute to peer feedback research by emphasizing on the need for individual, customized, and constant peer review training sessions rather than general, all-purpose, and decontextualized instructions which can consequently improve peer feedback quality in L2 writing contexts.

# 1. Introduction

The topic of peer feedback and its incorporation into L2 writing classes have become a common practice in different parts of the world. Considering the increasing popularity of the proces approach to writing instruction, traning learners to take a more proactive role in evaluating their peers papers seems inevitable (Huisman, Sab, van den Broek, & van Driel, 2019). To date, researchers have investigat this ssue from different ats. The majoity of th stds address pr feack raig eficieny Mr Hnan 2021; Carles & Boud, 2018; Min, 2016) learners atitudes towards instructed peer edack (Memari Hanjani, 2013, 2018; Lee, 2015; Tian & Li, 2019), and their engagement with this technique and its impact on their revision (Memari Hanjani, 2019; Fan & Xu, 2020, Yu, Zhang, Zheng, Yuan, & Zhang, 2018).

Recently, a research conducted by Memari Hanjani (2021) compared the cognitive processes of trained and untrained EFL peer reviewers feedback practices asessing a cause and an effct esays. By employing think-aloud protocols and comments provided by the participants, the investigator compared/contrasted the nature, focus, and validity of their comments and concluded that training could produce more relevant, and specific feedback; improved awarenessand concentration of trained reviewers, and increased the validity of their comments. This follow-up research investgated the similarities/differences between EFL trained per reviewers feedback behaviors with regard to evaluating the same cause and effet essays after receving similar trainings in terms quantity and quality. It also endeavored to examine matches/mismatches between each participant's feedback claims and practice by using think-aloud data, retrospective semi-structured interviews, and the essays they evaluated.

Indeed, not much is known about the similarities and differences of trained L2 peer reviewers feedback behaviors as wellas their evaluation claims and the extent to which these factors translate into their actual fdack practices. 2 students feedback approaches and claims can play essential roles in their evaluation practices as they are thinking beings whose actions are directed by their thoughts. Yet, just how much do these differences exist (if any) and the extent to which per reviewers claims converge with their actual evaluation practices have not been the focus of detailed research. Given the popularit of per feedack in L2 writing classes, uncovering the trained L2 reviewers' feedack behaviors and their claims that inspire their evaluation practices can help L2 practitioners provide more eficient peer fedback tranings. Hence, this provides the rationale of the present study. Indee, focusing spe. cifically on think-aloud and interview data, this article reports a case study that compared five trained L2 peer reviewers' feedback behaviors in terms of nature, focus, and accuracy on the one hand, and their claims and actual performance evaluating one cause and one effect essays developed by an anonymous student and th extent to which their claims were manifested in their actual practices on the other. Thus, it contributes to the current research base on peer feedback.

# 2. Literature review

As a popular topic in L2 writing research, peer evaluation has been extensively investigated through empirical inquiries. By searching the itrature such studie can be classfied in three broad categories: studies mainly focusing on peer review training ef. ficiency, studies elciting students perceptions of experiencing this technique, and studies exploring its impact on leners short and/ or long term writing quality.

The first group of research has focused on feedback training eficiency. For instance, using think-aloud protocols, Memari Hanjani (2021) compared the evaluation practice of two groups of trained and untrained senior EFL university students providing feedback on cause and effct essays in terms of type, focus, and quality. The findings indcatd that instructin fostere trained reviewers feedback quality compared to their untrained counterparts. Besides, Chang (2015) conducted a longitudinal exploratory investigation during which she modeled ideal evaluation in a writing clss and sought is effct n audience awarenes and affctvity of the participants evaluation behaviors in a computer-mediated context. The results revealed that prolonged instruction increased not only the re. viewers revision-oriented and global isues feedack rates, but also their non-evaluative stances. Drawing on a social cognitie model of sequential skill cquisition, Min (2016) investigated the effects of two modeling (mastery and coping) and two feedback types (praise and correction plus explication) and their combinations on four groups of EFL novice students' evaluations of higher-order issues. Her findings suggested that in general training had a positive effect on the quality of the participants' comments even though the efect was more significant in one of the groups compared to the others. Fan and Xu's (2020) study of 21 trained EFL university er reviewers indicatd the participants abilit to provide form-focused content-focused, and evaluative fedback to ther peers. Likewise, investigations conducted by Min (2005, 2008) indicated that a two-month pee review training enabled EFL students to produce more revision-oriented, detailed and relevant written feedback on global features f the compositions they asessed. Such findings were also corroborated by a study performed by Rahimi (2013) on Iranian EFL university students where the trained group mainly addressed higher-level problems of the paragraphs they asessed compared to their untrained classmates at the end of the experiment. Further, afer organizing a three-week peer review training workshop for non-English major universty students in Hong Kong, Lam (2010) acknowledged that the participants learnt basic revising skill needed for conducting sucessul per review ativities. Finall, using blog based per review activitie i L2 writing, Liou and Peng (2009) explored the impact of training on EFL university students' comments. Their findings indicatd that instructiontrigered more relevant, revision-oriented, per feedback and increased the qualit of the participants' revised drafts. Inall,it istresed that gol-oriented peer review instruction can ehance its efficiency as it properly introduces, explains, and models the method and helps students focus on specific, principled aspects of the writing task (Leijen, 2014).

Other investigations havereflected the positie efects of feedback training and practice on student reviewers learning strategies in general and writing proficiency in particular to0 Ca0, Yu, & Huang, 2019; Carless & Boud, 2018; Yu, 2019; Winstone, Hepper, & Nash, 2019). Generall, it is stated that the reviewers can benefit from the activity as it exposes them to a wide range of alternative approaches, ideas and perspectives, and writing styles not to mention the opportunity that it provides to re-examine the assignment criteria, identify and fix their own mistakes, and improve their academic writig performance (Cao et al., 2019; Cho & Cho, 2011; McConlogue, 2015; Min, 2005; Patchan and Schunn, 2015; Huisman et al., 2019). It is also revealed that the activity developed self-awareness literacy of the fedback providers and improved the global, and local aspects of their papers and consequently their writing skill (Cho & MacArthur, 2011; Huisman, Sab, van Driel, & van den Broek, 2018; Lundstrom & Baker;, 2009). Likewise it is confirmed that the activity improved students academic literacy including audience and genre awareness critical thinking, evaluative judgment, writing competence, and developed their learning sills (Berggren, 2015; Lam, 2010; Man, Xu, & Tole, 2018; Yu, 2019) Further, the symmetrical, and interpersonal communications between peer reviewers and writers can create an authentic writing environment which raises reader-writer harmony (Chang, 2015). Finall, it isargued that the activity enhances learners' motivation, sense of ownership, slf-confidence, and communication and negotiation skill (Memari Hanjani & Li, 2014; Brown, 2004; Min, 2005; Topping, 2003).

A number of studies have also documented L2 students' favorable attitudes towards peer review post training (Memari Hanjani, 2013, 2018; Fan & Xu, 2020; Le, 2015; Min, 2008; Tian & Li, 2019). Fan and Xu (2020) for example, underlined that almost all of their EFL learners expressed \*relatively strong willingness and interest in peer feedback practice and viewed it as a valuable opportunity to identify and reflect on their writing problems (p.5). Eliciting Chinese EFL univerity students attitudes towards written and oral peer feedback, Tian and Li (2019) concluded that the participants appreciated the activities and regarded them useful ince they offered opportunities o cultivate their writing competence. They were also strongly motivated to engage in theactivities and negotiate meaning through interactions. Further, Memari Hanjani (2018) incorporated collctive peer scafflding in an EFL paragraph writing class and sought the learners' reflections. He found that the participants favored the experience as it improved their writing quality, self-reision skill, and audience awareness in a pleasant atmosphere. His earlier research (2013) on EFL university esay writing students had produced similar results as well Le (2015), also reported that junior L2 students perceived the activity beneficial, constructive, and a novel experience which fostered their audience awareness and triggered their intrinsic interest in L2 writing. Finally, Min's (2008) study highlighted EFL student writrs positivereflections to peer review and attributed them to their trained peers' more empathetic perspectives and friendlier tones in their evaluations.

In terms of feedback engagement, it is acknowledged by scholars that evaluation is a two-way process and involves feedback provider and receiver. Fedback receivers need to appreciate critical comments and understand, judge, and make decision regarding the validity of the feedback they receive (Carles & Boud, 2018; Yu & Liu, 2021; Zha0, 2010). As Storch and Wigglesworth (2010) argued, if students do not trust the feedack they receive, they are unlikely to uptake it. However, Fan and u (2020) highlighted that interaction could facilitate negotiation of meaning and hence noticing and understanding form and content-focused feedback. Yet, they noted that engagement depended on the types of feedback; while the participants incorporated almost allof the local feedack they received $( 9 5 \% )$ , they only responded to about one-third of global comments $( 3 8 \% )$ . Memari Hanjani's (2019) study of EFL paragraph writing learners indicated that collctive per scafolding activity enhanced the quality of their consecutive self-revised descriptive and narrative paragraphs even though its long-term effect was inconclusive. Examining three Master of education EFL students engagement with the feedback they reeived from their counterparts on their thees, Yu and his colleagues (2018) also noted that even though there existed individual differences among the participants' engagement with the comments they received, their affective engagement could promote or negatively influence their behavioral and cognitive engagement. Further, Rahimi's (2013) study of Iranian EFL university students revealed that due to instruction, the qualit of comments provided by L2 reviewers improved remarkably which in turn prompted higher feedback uptake ratio and superior papers both in short and long terms. Min (2006) also reported a high rate of incorporating feedback generated after peer review training by thefedback receivers since the comments were frequently revisin-oriented and explicitly explained in a cllaorative atmosphere. Consequently, the activity enhanced the qualit of the revised compositions developed by L2 learners.

To date, only one case study conducted by Yu and Hu (2017) has acknowledged the impact of individual variations and sociocultural context on two Chinese L2 learners fedback practices even when the trainings they received were the same. The researchers concluded that peer reviewers' different feedback practices could be atributed to combination of factors such as their philosophy about feedback and writig, their motives and goals, and theirattitudes towards face-saving and group harmony' (p.33) If writing practitioners wish to develop effctive interventions for supporting L2 lerners in per feedback, then it is crucial to hae a systematic examination and detailed understanding of their feedback behaviors, seek their claims regarding this activity, and explore the potential matches/mismatches between what they claim with what they actually do. The results are illuminative for researchers and practitioners as they can address any challenges with more informed and eficient trainings. Indeed, developing such awareness is important a it is the beginning of a proces of recognizing individual variations as well asconcentrating on the possible discrepancies between what trained per reviewers do and what we think they do and in turn best equipping them to maximize the validity of feedback they provide. To serve that end, the present study compared trained EFL peer reviewers' feedback performance with respect to nature, focus, and accuracy as wellas the extent to which their claims and feedack practices were compatible. It was hence guided by the following research questions:

1. What are the similarities/differences of trained L2 reviewers' behaviors in terms of nature, focus, and accuracy of feedback?   
2. What are the claims of the trained peer reviewers concerning feedback?   
3. To what extent do the trained peer reviewers' claims match/mismatch with their feedback performance?

# 3. Methodology

The research outlined in this article is an exploratory case study which employed data collected from think-alouds and semi structured interviews to provide an in-depth insight into the evaluation behaviors as well as matches/mismatches between the claims and feedback performance of fie trained L2 peer reviewers evaluating a sample cause and a sample effect essy written by an anonymous student. The data presented inthis case study were generated by a larger research comparing the cognitive processes of trained vs untrained EFL peer reviewers in a priate universty i Iran; however, the focus, reearch questions, and the approach to the data collection and analysis were different.

A multiple case approach was adopted where the case was astudent evaluating two essays. Several students were selected in order to get a broader view on how they approached the evaluation task and convergences and divergences between their claims and performance (Creswell, 2007).

# 3.1. Context and participants

The study involved five senior undergraduate EFL translation students at a private university in Iran who had attended academic essay writing course, but did not have any prior exposure to peer review training, nor had they participated in any forms of eer review activity before the study. To select the participants, convenience purposive sampling method was used. That is from the results obtained by a pool of 20 volunteers who developed a sample paper on What ffects do exercse have on our body? three females and two males were elected by using Multiple-trait scoring rubric. The participants' age ranged from 23 to 25 years, with the average age being

24. Persian was their native language and they had studied English for more than eight years both at university and school/private institutes. Their English proficiency level was also upper-intermediate based on the results of Test of English as a Foreign Language (TOEFL) available in the English department. Following is a brief description of each reviewer:

Jack was 25 years old. Altogether, he had been studying English language in high school and at the university for nine years. He was an energetic student and worked as a part time translator in a company. He wished to become a tour leader after graduation.

George was also 25 years old. He was a self-confident learner and as he expressed, one of the reasons he participated in th research was t learn principles of research. He wished to pursue his postgraduate studies in an English speaking country and become: university lecturer.

Amelia was 24 years old. She had attended English language courses for ten years and was a teacher in a private English institute for the past two years. She also enjoyed teaching and was determined to continue her job after graduation.

Betty was also 24 years old and had been studying English for about 10 years. She was Amelia's friend and taught at the sam institute. She was an ambitious student and wished to become one of the best English lecturers in the world.

Nicole was 23 years old. She had been learning English for 8 years. She was also teaching English in kindergarten and planned to continue teaching after graduation.

# 3.2. Data collection

# 3.2.1. Step 1 (essay reviewing)

The participants attended two-hour review sessions to freshen their knowledge of English academic essay writing conventions especially cause and effect essay even though they had passed this course before. The first session comprise generic instructions on English academic essay structure, components, and thir functions by providing a model essay. During the second sesson, the focus f instructions was on cause and effct essays. In this session, the organization, components, focus, function, and techniques for developing this genre were highlighted and by providing a couple of model essays, the participants could examine such qualite in practice.

# 3.2.2. Step 2 (training)

Each reviewer participated in three $3 0 \ \mathrm { m i n }$ one-on-one researcher-reviewer training workshop. During the first session, the researcher used a peer review she and a sample cause essay and by thinking out loud he demonstrated how to make comments to the paper and addressed its local and global errors/problems following the guidelines provided by the peer review sheet. In the second session, a sample effect essay was evaluated following the same procedures. In the last ession, each reviewer was provided with one cause and one effect papers and was invited to evaluate them whil thinking aloud following the same procedures they had already experienced to ensure that allof them had comprehended pee review and think-aloud techniques. The model essays were developed by an anonymous student and were chosen careful as they included both local and global errors. The researcher assted the reviewers if they experienced any ambiguities or problems during reviewing aloud process.

# 3.2.3. Step 3 (peer reviewing)

Afer obtaining the reviewers' consent to record their think-alouds, each was given two papers; one focusing on cause and one focusing on efect The topics of the essays were The Causes of Crime in Society" and The Effects of an Unhealthy Diet" which were believed to be relevant to participants' experience and were composed by their fllow students. Then, they were recommended to asses the papers based on the instructions they had received and following the guidelines provided in the peer review sheets under similar conditions: at the same time, and in the same venue. The papers contained both macro and micro levelerrors. While thinking out loud, each reviewer's voice was recorded by a diffrent digia voice rcorder. The researcher also circled in the class making sure that the students were on task and encouraged them to verbalize their mental proceses if they weresilent. At the end of the session, the researcher collected the reviewed papers for analysis.

# 3.2.4. Step 4 (interviewing)

Semi-structured individual interviews were carried out with each of the participants. The interviews lasted between $2 0 { - } 3 0 \mathrm { m i n }$ and they followed the protocol determined by the research questions. The interview prompts focused on issues such as the participants overal felins about peer rview actiity, thir edackfous, ther challges, th sufficiey of tranng, t. Pri ws used so the interviewees could express their opinions without experiencing any unnecessary pressure that might be caused by using L2.The interviews were audio recorded with the permission of the interviewees. Finall, by agreeing not to publicize their names and identities, the participants were reassured of their anonymity and confidentiality. Thus, in reporting the findings, pseudonyms are used to sustain confidentiality and cover the participants' identities.

# 3.3. Data analysis

The collected data were analyzed as follows:

A. Audio-recordings. The student reviewers' recorded think-alouds were analyzed first. The participants spent two hours and sixteen minutes evaluating th cause" and two hours and eighteen minutes the "effect" essays respectively (for hours and thirty-four minutes in total. To analyze the recorded think-alouds, an inductive aproach was utilized following Straussand Corbin (1998). As the interviews were in Persian, first the participants' voices were transcribed and translated into English. Second, a taxonomy of the reviewers' mental processes were generated following the same procedures reported by Memari Hanjani (2021). In the open coding phase the translations were read and re-read repeatedly and the data were fragmented, analyzed, and evaluated, so that patterns and major themes could appear. An important decision at this stage was think-aloud data segmentation. Each comment provided by the reviewers addressing an issue was referred to as a think-aloud segment. Next, in the axial coding phase the data were integrated and new connections were created between a theme and its sub-themes. Finall, a further analysis was conducted tocount the frequency of each theme. In order to validate the emerged themes, $2 0 \%$ of the data were shared with an experienced colleague and disagreements in coding were sorted through discussion. Consequently, the preliminary set of themes was further revised.

B. Interviews.

Similar procdures were followed to analyze the interviews letting the interview data suggest categories by themselves. First interviews were transcribed, translated into English, and saved as a Word document. Next, each interviewe's responses were read recursively and the data were broken down and examined, so that the themes relevant to the focus f the study could be identified. sorted, and classfied. To increase the validity of the findings and to avoid any misunderstandings, the transcripts and the emerged themes were presented to all participants and thir fedack were elicited. They al confirmed the themes with no changes that further improved the validity of the interview data analyses and interpretations.

C. Essays.

It involved isening to the participants think-alouds and comparing them with the essays they had evaluated. More precisely, this step encompassed aessing the reviwers mentl proesse in terms of fdback type revision or non-revisionorienttio, ealuation focus; content and organization or language and mechanics, and feedback validity; accuracy or inaccuracy. For instance, to compare the percentage of revision and non-revisin oriented comments provided by the reviewers, the reearcher first tllied th total number of their comments and the revision and non-revision oriented ones. Then, he computed the ratio by dividing the revision or nonrevision oriented comments by the total number of reviewers' comments independently. Further, to find the evaluation focus of the feedback provided by the reviewers, the frequency of local and global comments were counted frs. Then, the figures were divided by the total number of revision oriented comments separately. Ultimately, to discover the validity of the feedback provided by the participants, the reearcher initillytallied the total number of accurate and inaccurate comments separately and divided them by the total number of revision oriented comments subsequently.

# 4. Findings

Before presenting the findings, it should be noted that the sample cause and effectesays were also assessed by three professional and experienced raters. They evaluated both the cause and the effect esays individuall and together and all confirmed that while the maximum number of required revisions for the sample cause essay were 69 of which 54 $( 8 0 \% )$ were local errors, the total number of amendments which the effect essay needed were 83 of which 68 $( 8 2 \% )$ were local mistakes.

# 4.1. Research question 1

# 4.1.1. Feedback nature

As Table 1 below outlines, the individual variations in terms of the time spent evaluating the cause easy' and the number of comments provided by each individual were considerable, ranging from 13.30 to $3 7 . 5 0 \ \mathrm { m i n }$ and 45 to 110 comments respectively. While Jack spent the least time ( $\mathrm { 1 3 . 3 0 ~ m i n } \mathrm { ) }$ evaluating the paper and providing the least amount of comments (45), George's performance was opposite as he spent $3 7 . 5 0 \mathrm { m i n }$ evaluating the paper and generated the largest (110) amount of feedback even though the ratio of both reviewers' revision-oriented comments was almost the same $5 3 . 3 \%$ vs $5 3 . 6 \%$ . Further, the ratio of revision-oriented comments provided by the reviewers was very close ( $5 3 \%$ to $6 2 . 5 \%$ ) confirming that more than half of all of the participants' comments had revision nature. By defintion, revision-oriented feedback is reerred to comments intended to judge as wel as to require the writers to fix, amend, change, or improve their texts such as correction, criticism, confirmation, and explaining convention/rule.

On the other hand, the gap was les significant concerning the effect easy as the time spent by the participants assesing this ype of essay ranged from 24.30 to $3 4 . 5 0 \mathrm { m i n }$ and they provided 57 to 104 comments (Table 2). In this case, Nicole was the one who spent the least amount of time (24.35) and offering the least number of comments (57), whereas the evaluation behaviors of the other participants were mixed with Jack spending the highest amount of time $( 3 4 . 5 0 \mathrm { m } )$ and George giving the highest number of comments (104) to the same paper. Besides, the ratios of revision-oriented comments provided by the reviewers were variable. George's and

Table 1 Length and nature of feedback given by peer reviewers evaluating cause essay.   

<html><body><table><tr><td>Name</td><td>Time</td><td>Total Number of Comments</td><td colspan="2">Revision Oriented</td><td colspan="2">Non-revision Oriented</td></tr><tr><td></td><td></td><td></td><td> Frequency</td><td> Percentage</td><td> Frequency</td><td>Percentage</td></tr><tr><td> Jack</td><td>13.30</td><td>45</td><td>24</td><td>53.3%</td><td>21</td><td>46.7%</td></tr><tr><td>George</td><td>37.50</td><td>110</td><td>59</td><td>53.6%</td><td>51</td><td>46.4%</td></tr><tr><td>Amelia</td><td>23.10</td><td>77</td><td>47</td><td>61%</td><td>30</td><td>39%</td></tr><tr><td>Betty</td><td>24.30</td><td>70</td><td>43</td><td>61.5%</td><td>27</td><td>38.5%</td></tr><tr><td>Nicole</td><td>37.20</td><td>88</td><td>55</td><td>62.5%</td><td>33</td><td>37.5%</td></tr><tr><td> Mean</td><td>27.24</td><td>62</td><td>45.6</td><td>58.4%</td><td>32.4</td><td>41.6%</td></tr></table></body></html>

Table 2 Length and nature of feedback given by peer reviewers evaluating effect essay.   

<html><body><table><tr><td>Name</td><td>Time</td><td>Total Number of Comments</td><td colspan="2">Revision Oriented</td><td colspan="2">Non-revision Oriented</td></tr><tr><td></td><td></td><td></td><td>Frequency</td><td> Percentage</td><td>Frequency</td><td>Percentage</td></tr><tr><td> Jack</td><td>34.50</td><td>85</td><td>43</td><td>50.6%</td><td>42</td><td>49.4%</td></tr><tr><td>George</td><td>25.35</td><td>104</td><td>76</td><td>73%</td><td>28</td><td>27%</td></tr><tr><td>Amelia</td><td>27.50</td><td>102</td><td>54</td><td>53%</td><td>48</td><td>47%</td></tr><tr><td>Betty</td><td>24.45</td><td>80</td><td>56</td><td>70%</td><td>24</td><td>30%</td></tr><tr><td> Nicole</td><td>24.35</td><td>57</td><td>31</td><td>54.4%</td><td>26</td><td>45.6%</td></tr><tr><td>Mean</td><td>27.47</td><td>85.6</td><td>52</td><td>60.2%</td><td>33.6</td><td>39.8%</td></tr></table></body></html>

Betty's comments were predominantly revision-oriented ( $7 3 \%$ and $7 0 \%$ respectively) although slightly over half of the other three participants' feedback required revision.

# 4.1.2. Feedback focus

Considering the feedback focus of the participants, as Table 3 reveals, there were some degrees of individual variations. Whil four participants mainly focused on local mistakes of the causesay they evaluated, Jack' feedack mainly focused on global issues. 0f24 revision oriented comments provided by him, 16 $( 6 6 . 7 \% )$ addressed higher-order issues in this type of paper he assessed. This indicates the per reviewers' predominant concerns for surface-level mistakes and their strong preference to improve the language and me. chanics aspects of the essay they reviewed.

The same pattern of feedback focus was also noticed in the participants' performance when responding to the efect essay. More than two-third of the comments addressed form rather than meaning (Table 4). Interestingly, Jack's feedback focus shifted towards generating more local resonse in this caeen though slightl les than half of his comments stil contained discourse-level features $( 4 4 . 2 \% )$ compared to that of other members of the group (mean $2 6 . 5 \%$

# 4.1.3. Feedback accuracy

Concerning feedback accuracy, Table 5 underlines that the majority of comments provided by the participants evaluating the cause essay were accurate ranging from $7 5 \%$ to $8 3 . 7 \%$ which appears to be very promising.

Almost the same patten could be traced in the participants' evaluation practice addressing the efec esay where the percentage of accurate comments of four reviewers ranged from $7 2 \%$ to $8 4 \%$ percent (Table 6). The only exception was Nicole's performance as the accuracy ratio of her comments dropped to $6 1 . 3 \%$ . Her accurate feedback ratio was also the lowest evaluating the cause essay $( 7 7 . 3 \% )$ Further, in both cases, Betty's accurate comments ratio was the highest. $8 3 . 7 \%$ of her feedback on the cause essay and $8 4 \%$ of her feedback on effect paper were valid. (Tables 5 and 6).

# 4.2. Research questions 2 & 3

This section presents data regarding the claims of the participants concerning feedback (RQ2) and the extent to which their claims match/mismatch with their feedback practices (RQ3), as revealed through semi-structured individual interview.

# 4.2.1. Feedback nature

Allof the participants agreed that the trainings were eficient. Their responses indicated that they favored the training and found peer review shes very helpful, guiding them through the roces of esay evaluations epeciall i terms of content and organization. For instance, Betty expressed that \*the trainings and peer review shees helped us evaluate the papers against some criteria and principles and avoid ireleant comments. They were very efficient and we could use them as a compass showing the right direction and keeping us focused to generate valid comments".

This was somehow surprising since despite their allegations, slightly over half of the reviewers' comments were revision-oriented and relevant (mean $5 8 \%$ and $6 0 \%$ in cause and effect essays respectively). However when evaluating the effect essay, more than twothird of feedback offered by George and Betty seemed relevant and required revision (Tables 1 and 2).

In summary, there appears to be inconsistency between learners' claims and performance in terms of nature of feedback. The trainings and peer feedback sheets were not that much fficient as the participants thought as they somehow failed to prompt precise and specific feedback which required revision.

Table 3 Focus of feedback given by peer reviewers evaluating cause essay.   

<html><body><table><tr><td>Name</td><td>Revision Oriented Comments</td><td colspan="2">Local</td><td colspan="2">Global</td></tr><tr><td></td><td></td><td>Frequency</td><td> Percentage</td><td>Frequency</td><td>Percentage</td></tr><tr><td>Jack</td><td>24</td><td>8</td><td>33.3%</td><td>16</td><td>66.7%</td></tr><tr><td>George</td><td>59</td><td>47</td><td>79.6%</td><td>12</td><td>20.4%</td></tr><tr><td>Amelia</td><td>47</td><td>33</td><td>70%</td><td>14</td><td>30%</td></tr><tr><td>Betty</td><td>43</td><td>28</td><td>65%</td><td>15</td><td>35%</td></tr><tr><td>Nicole</td><td>55</td><td>43</td><td>78%</td><td>12</td><td>22%</td></tr><tr><td>Mean</td><td>45.6</td><td>31.8</td><td>65.1%</td><td>13.8</td><td>34.9%</td></tr></table></body></html>

Table 4 Focus of feedback given by peer reviewers evaluating effect essay.   

<html><body><table><tr><td>Name</td><td>Revision Oriented Comments</td><td colspan="2">Local</td><td colspan="2">Global</td></tr><tr><td></td><td></td><td>Frequency</td><td>Percentage</td><td>Frequency</td><td> Percentage</td></tr><tr><td> Jack</td><td>43</td><td>24</td><td>55.8%</td><td>19</td><td>44.2%</td></tr><tr><td>George</td><td>76</td><td>58</td><td>76.3%</td><td>18</td><td>23.7%</td></tr><tr><td>Amelia</td><td>54</td><td>39</td><td>72.2%</td><td>15</td><td>27.8%</td></tr><tr><td>Betty</td><td>56</td><td>40</td><td>71.4%</td><td>16</td><td>28.6%</td></tr><tr><td> Nicole</td><td>31</td><td>23</td><td>74.2%</td><td>8</td><td>25.8%</td></tr><tr><td>Mean</td><td>52</td><td>36.8</td><td>70%</td><td>15.2</td><td>30%</td></tr></table></body></html>

Table 5 Accuracy of feedback given by peer reviewers evaluating cause essay.   

<html><body><table><tr><td>Name</td><td> Revision Oriented</td><td colspan="2">Accurate</td><td colspan="2">Inaccurate</td></tr><tr><td></td><td>Comments</td><td>Frequency</td><td> Percentage</td><td>Frequency</td><td> Percentage</td></tr><tr><td> Jack</td><td>24</td><td>18</td><td>75%</td><td>6</td><td>25%</td></tr><tr><td>George</td><td>59</td><td>46</td><td>78%</td><td>13</td><td>22%</td></tr><tr><td>Amelia</td><td>47</td><td>37</td><td>78.7%</td><td>10</td><td>21.3%</td></tr><tr><td>Betty</td><td>43</td><td>36</td><td>83.7%</td><td>7</td><td>16.3%</td></tr><tr><td>Nicole</td><td>55</td><td>42</td><td>77.3%</td><td>13</td><td>23.7%</td></tr><tr><td>Mean</td><td>45.6</td><td>35.8</td><td>78.5%</td><td>9.8</td><td>21.5%</td></tr></table></body></html>

Table 6 Accuracy of feedback given by peer reviewers evaluating effect essay.   

<html><body><table><tr><td>Name</td><td> Revision Oriented</td><td colspan="2">Accurate</td><td colspan="2">Inaccurate</td></tr><tr><td></td><td>Comments</td><td>Frequency</td><td>Percentage</td><td>Frequency</td><td>Percentage</td></tr><tr><td> Jack</td><td>43</td><td>31</td><td>72%</td><td>12</td><td>28%</td></tr><tr><td>George</td><td>76</td><td>58</td><td>76.3%</td><td>18</td><td>23.7%</td></tr><tr><td>Amelia</td><td>54</td><td>43</td><td>79.6%</td><td>11</td><td>20.4%</td></tr><tr><td>Betty</td><td>56</td><td>47</td><td>84%</td><td>9</td><td>16%</td></tr><tr><td>Nicole</td><td>31</td><td>19</td><td>61.3%</td><td>12</td><td>38.7%</td></tr><tr><td>Mean</td><td>52</td><td>39.5</td><td>74.6%</td><td>12.5</td><td>25.4%</td></tr></table></body></html>

# 4.2.2. Feedback focus

The Participants opinions regarding their eedback focus were mixed. During interviews Jack and Betty expresses that they valued the ideas and organizations of the papers they reviewed the most and they prioritized higher-order isues over lower-order concerns. As Jack remarked:

I evaluated the papers twice. First, I checked them for content and organization and then for language and mechanics erors. The adantage f focusing on content first, is that you can chec if adequate support is provided, idenify the irelevant sentences, check whether the required components such as thesis statement and topic sentences are present and expressed clearly. It is esier o focus on form and structure after addressing the content and organization of an essay.

For Nicole, on the other hand, correcting form and stucture of an esay was more essential since \*in order to comprehend a paper, it should be err-free. George and Amelia stated that both local and global issues were qually important and when evaluating an essay, they addresed surface and deep lel isues if necessary. As Amelia noted, I think not only grammar, word choice, and punctuation errors should be fixed, but also comments on ideas, logic, and organization issues are required."

However, the data in Tables 3 and 4 do not support George's, Amelia's and Bett's claims. Indeed, there appeared to be dis. crepancies between what they thought and what they actually performed. As the figures suggest, the majority of feedback they generated (more than two-third) addressed form and inguistc errors in both papers they reviewed. Yet, Jack'sealuation performance was mixed. Considering his feedback on the cause essay, his claims and performance seemed consstent as only one-third of his comments focused on local mistakes $( 3 3 . 3 \% )$ . However, examining his evaluation behavior of the effect essay revealed some degree of inconsistencies between his claim and practice since well over half of his feedback centered on such errors $\left( 5 5 . 8 \% \right)$ . Only Nicole's feedback focus matched with her claims since $7 8 \%$ of the comments she generated assessing cause genre and $7 4 . 2 \%$ of the feedback offered reviewing efect genre addressed local errors. In all the great majority of the reviewers' claims mismatched with their performance as they emphasized surface-level accuracy rather than deep-level fluency in their evaluation practice.

# 4.2.3. Feedback accuracy

The participants were also asked about the potential effcts of genre and topic of the essays on the validity of the feedback they generated. Their claims varied over this sue. George and Bett rejected the impact of such variables on the quality of their evaluations; whereas, Jack, Amelia, and Nicole expressed opposit opinions. The first group admitted that the same principles and conventions should be considered in allessays and the evaluationcriteri are the same no matter the genre and topicof the essays, yet the latter believed that familiarty wit the genre and topic of papers improved the quality of their feedback and could positively influence the accuracy and validity of ther comments. Gerge, for instance, maintined tht the evaluation criteria ar the same for ll types of essays and topics. We should just fllow the instructions and conventions. The evaluators should not judge the accuracy or inaccuracy of the ides expressed by the writrs. On the ther hand, melia noed tht amiirity wth the re and topic f essays is especially helpful when evaluating the content of essays. When we are familiar with the topic, we can bettr understand if the esy is well organized and supported and is free from irrelevant information and can provide more specific and valid feedback".

Examining Tables 5 and 6 demonstrated that a great majority of the comments provided by the reviewers were accurate regardless of the genre and topic of the essays the participants evaluated $( 7 8 . 5 \%$ of the cause and $7 4 . 6 \%$ of effect essays feedback respectively). However, there existed some individual variations. For instance, George's observed performance matched with his claims as he believed the gnre and the topic of essays could not influence the quality of his feedback. Indeed, the valiity ratio of his comments did not change evaluating the cause and the effect genres ( $7 8 \%$ vs. $7 6 . 3 \%$ respectively). However, Nicole's ratio of valid feedback dropped from $7 7 . 3 \%$ in the cause genre to $6 1 . 3 \%$ in the effect essay which in this case her claims were also compatible with her practice too, but in an opposite direction to that of George's. Overall the ther participants claims tended todiverge with their actual performance as the ratio of the accurate feedback they offred was the same regardles of the genre and the topic of the essays they evaluated.

# 5. Discussion

This study extends the existing research on peer review training by examining the processes through which peer evaluators addressed a sample cause and a eec essays. It sought to addessthe similarities/differences of trained per reviewers feedback behaviors as wel as the matches and mismatches between their claims and fedback performance by employing think-aloud protocols, retrospective interviews and anonymous esays. In this regard, the study provided new insights into the potential relationship between peer reviewers claims and practce filling ap in th iterature which has not previously ben addressed. The results are informative for researchers and practitioners since it was revealed that about $6 0 \%$ of the reviewers' comments were revision oriented in both cause and efec essays which is i line wit the findings of other reearch (Fan & Xu, 2020; Lu & Law, 2012) which have tessed the frequent use of evaluative fedback by the trained per reviewers. However, despite the fact that the quality and quantity of the trainings were similar for all of the participants, there were some exceptions. While $7 3 \%$ of George's and $7 0 \%$ of Betty's comments had evaluative nature reviewing the efect esay, the figures were somehow similar o other participants performance considering the cause essay. Interestingly, these two students commented that the genre of the essays had no influence on the quality of their evaluations and following some guidelines and instructions could help them provide the same feedack no matter what geres th essays were. Hence. we noticed a mismatch between the claims and the performance of these two individuals in this regard. This dfference can probably be attribute  ltion sequee. Sinc the participants first elatethe case y andthn trnd to the fftssy, these two learners might have become more experienced and have been able to provide more revision-oriented feedback in their following performance.

Additionally, inconsistent with the findings of some of the previous investigations (Chang, 2015; Fan & Xu, 2020; Min, 2005, 2006; Rahimi, 2013), the evaluation focus of the participants was mainly on form rather than content when reviewing both essays (about $6 5 \%$ of comments on the 'cause' essay and $7 0 \%$ on the 'effect' essay on average). This may indicate that the reviewers were preoccupied by correctig the surface level errors of the esays they evaluated at first glance. However, as it was noted earlier i ection 4, while about $8 0 \%$ of errors in the sample papers were local, the maximum ratio for detecting and commenting on global problems in both papers was only around $2 0 \%$ . Hence, it seems quite normal to observe that the great majority of the feedback provided by the reviewers addressed sentence lel rather discourse level features. They probably neded to fi th erors they noticed frs i order to comprehend the content of the papers. Besides, comparing the participants clams and evaluation performance showed discrepancies between at least three respondents' views and feedack performance (George, Amelia, and Betty). These students underestimated the amount of feedback they offered regarding localissues, and overestimated the amount of global feedack they provided on content. While they emphasized that commenting on content and organization was their main concern, their performance did not confirm that. Indeed, only Nicole's performance matched with her allgation as she preferred an error-free text over a meaningful paper.

In terms of feedback validity, it was observed that a great majority of corrections suggested by the participants were accurate in both genres. Indeed, about three-fourth $( 7 5 \% )$ of the comments were valid on average indicating the efficiency of incorporating peer evaluation in EFL writing courses and the abilit of higher level leaners to offer quality feedback even after two one-on-one feedback training sessons. Comparing the learners interview responses with their performance also showed that even though two participants (Jack, Amelia) admitted the potntial efect of genre and topic of the esay on the acuracy f their omments, their feedback practice did not support that. I fact, the proportion of ther acurate comments was quite similar in both genres. On the ther hand, George and Betty claimed that the type and topic of the essays did not influence their peformance if they stuck to academic essa writing rules and principles and followed the evaluation instructions. In practice, their performance converged with their claims as the ratio of their accuratefedack was the same in both genres. icole was also the other participant whose claims were supported by her performance. She suggested that genre and topic familiart could make a diffrence considering the validity of comments. Her actual practice confirmed her claim as the proportion of her accurate comments dropped from $7 7 . 3 \%$ to $6 1 . 3 \%$ comparing her comments on the 'cause' and effect' essays which can probably indicate her higher level of competence evaluating the former over the latter.

The findings from this case study indicate that the participants' claims were usuall inconsistent with their actual essay evaluation practices in terms of revision-orientation, feedback focus, and feedback validy despte some instance of consistency. Beides, some differences were noticed in the reviewers' performance, even though the trainings they received were identical. Several potential reasons can explain these divergent behaviors. First, it should be noted that students vary dramatically in thir personalities, backgrounds, writing proficiency, aspirations and motivations and their reactions to similar activities may be dissimilar despite the trainings they have received have been the same. Second, some learners may need more time and practice to internalize the task requirements compared to their counterparts. Further, educational and contextual factors appear to have an impact on such dis crepancies. That is, the reviewers previous experiences may also have contributed to their evaluation practice orientations. More precisely, their past experiences of L2 writing classes and previous feedback exposure might have influenced the ways in which they approached evaluating the samplessays. Teachers normally addressthe language and mechanics errors of their students in L2 writing classes and this could inadvertentl draw the reviewers' attention to the importance of accuracy over fluency of the papers they evaluated. Thus, their performance unconsciously deviated from their claims and the trainings they had received. Finally, the par. ticipants were not probably aware of their clams consciously or found it ifficult t articulat them. Thus, this unsystematicreflection of claims could also be the source of observed gaps between their actual performance and their allegations in the interviews.

Essay evaluation is a multifaceted and dynamic task and to be eficient it requires orchestration and expertize of several factors including academic writing, genre awareness linguistic competence, subject familiarity, and higher order capabilites such as critical thinking and reasoning strategies. Therefore, peer evaluation can pose many challenges to learners. They need to be skilled in performing this activity. They need to have the motivation and the abilities to take this instructional strategy, and they need to be confident in their capabilitie. Beside, they may be challenged by not being familiar with or not having enough expertie on the gene and the topic of the essays they evaluate, so they may not be able to asess their peers' essays esecially the content properly. In order for students to implement per evaluation successully, they need to be able to overcome these challenges. As noted by several researchers, pr feedackis unlikely to meet its goals without training and support (Memari Hanjani, 2021, 2019; Liou & Peng, 2009; Min, 2016; Rahimi, 2013). However as the findings of the present study imply, peer review training should be transformed in order to yield more eficient outcomes. One major practical implication emerging from the study is that essay evaluation requires prolonged, customized, and specific training. L2 learners need constant support to hone their skill on how to implement peer evaluation in the writing classes. Moreover, they need appropriate resources such as assessing criteria peer review shets, exemplars, rfrence books, and relevant Apps in order to eliminate peer evaluation barriers that hinder their performance step by step.

Further, L2 writing teachers should acknowledge student reviewers different evaluation behaviors and their level of competencies and flexibly adjustheir training practices to suit their needs by devising suitable coaching activities and equip them with the required skill to make judgments and sound assessments. Indeed, they should review and revis their training policies and adopt appropriate strategies based on the leaners' needs and abilities. One-size-fits-alltrainings should be replaced by contextualized, tailor-made instructions based on each students needs and capabilities. Trainings should be purposeful, dynamic, fluid, and gradual according tothe strengths and weaknesses of student reviewers during their evaluation process. As they are progressive, they can be geared to dis cussing the chllenges each reviewer faces on regular basis and provide oportunitie tosupport their evaluation processes. A key teacher role is to communicate the rational for peer evaluation activity; explain how it operates, and address challenges that each student evaluator might encounter during the process Through ongoing instructor-student dialog and post-peer review activities, teachers should attempt to reduce leaners doubts, e expectations, and delop plan for facilitating the evaluation process that they eed to follow in order to e sucessul reviewers. They should alo fster learnrs self-confidence y engaging them with autonomous learning such as performing self-evaluation activities, and highlight their potentials to provide valid and accurate feedback and trust their evaluative judgment.

# 6. Conclusion

The present study examined five trained upper-intermediate EFL learners' evaluation behaviors and the convergences and di vergences between their claims and actual evaluation performance. In this sense, it contributes to a growing body of research in undersanding per feedack training and evaluation. The findings have advanced our understanding of trained L students' different evaluation aproaches as well s their claims and their atual peformance by offering more evidence on the complexit ofthis activity and the requirement for prolonged, personalized, and specific evaluation instructions. A key finding of this study is that, despite being exposed o simar tranings, the particiants performance diffred in tems ofevaluation rientation, and feedback fous and validt. Considering such difference andmismatches betweethe participants clams and their fdack performance, thereults can provide valuable implications for peer feedback training. Firstly, traning should not be one-size fis all. As the learners' abilities and backgrounds are ifferent, practitioner should gear their instructions based on their learners individual needs and potentials and provide specific, one-on-one training conferences in addition to general instruction. Secondly, training should be consistent and adjusted to students valuation performanceas they may forget evaluation critria over time  require more intruction and emphasis on certan aspects ofassessment. Min-training sessions could be arranged during the course to address the individual students evaluation inabilities and advance their feedback efficiency to respond to different types of errors. This point has been generally overlooked in feedack training. Finally, intructor-student dialog and post-per review activities should aim to reduce leners doubts and increase their self-esteem and facilitate the evaluation process in the long run.

Despite the new insights gained from this study, a number of limitations need to be acknowledged. Firstly, this was an exploratory case study, and hence the results and findings may lack generalizability, particularly given the importance of context and L2 learners differences when comparing their evaluation performance and claims. Further studies in other contexts with more participants which focus on dfferent characteristics f L2 learners such as their background, gender, age, native language, and language proficiency level are required to confirm these findings and expand their generalizability to other contexts. In addition, only two sample essays - one cause and one effect - were used for the study at a ingle point. One area of future research could involve a longitudinal study that monitors how purposeful, constant, and adjusted trainings afect the feedack providing performance of L2 peer reviewers and its transformations (if any) and compare it with their claims over time. Researchers need more evidence f how progressve training lead to short-term and long-term student reviewers' evaluation performance. Nonetheless, i is hoped that this study raises awareness regarding the necessity of purposeful, constant, and customized peer evaluation instructions until L leaners become experienced and efficient reviewers and understand the purpose, nature, and focus of feedback.

# CRediT authorship contribution statement

Alireza Memari Hanjani: Writing - review & editing, Writing - original draft, Resources, Proect administration, Methodology, Investigation, Data curation, Conceptualization

# Data availability

The authors do not have permission to share data.

# References

Bergre, . (2015). ng frm ging feak: A stdy f odary-el stdts. L Jonal, 691), 58-70. htp//./10.1093/t/cu036   
Brown, H.D. (2004). Language assessment: principle and classroom practices. New York: Longman.   
Ca,      01i q     wn  r e study. Studies in Educational Evaluation, 63, 102-112. https://doi.org/10.1016/j.stueduc.2019.08.001   
Cares   d 018) T t  ak c  fk   ,438) 1315-1325. https://doi.org/10.1080/02602938.2018.1463354   
Chang, ..015. in e d  t 2 n 21. /. 10.1016/j.asw.2015.04.001   
Cho, K., & MacArthur, C. (2011) Learning by reviewing. Jounal of Educational Psychology, 103(1), 73-84. https:/do.og/10.1037/a0021950   
Cho, Y. H & h, (201). Pr riewrs l from giin omnts nttionl cie, 39, 629643. htps:/.g/10.1007/11251010-91461   
an    . 2020 pg tt  th   2 wi f    50 il 0075. /.g 10.1016/j.jslw.2020.100775   
Huisan,  a rl    r .018  n     k   ak perceptions and essy pformance. Asssment & Evaluatin in Higher Edcation, 43, 955-968.https:/oi.og/10.1080/02602938.2018.1424318   
Huisan,  ab , v ro. vriel . 019) Th  f ftiv r ac n hgr ion s a wti eta Analysis. Assessment and Evaluation in Higher Education, 44(6), 863-880. htps://doi.org/10.1080/02602938.2018.1545896   
Lam, R. (2010). A per review training workshop: Coaching students to give and evaluate per feedback. TESL Canada Jounal, 272),114-127.   
Le, ..     j  t nt 5, 1-10. https://doi.org/10.1016/j.system.2015.08.003   
Leje  t (Eds.), Methods in writing process research (pp. 167-183). Peter Lang Verlag.   
Lou HC. P, . 2009.n eft on mputer-md pr rei. t 37 14525. t/.g/0.1016st009.01.00 011-9177-2 (1), 30-43. https://doi.org/10.1016/j.jslw.2008.06.002   
an, D. ,   J, .018. ddg os p fak cti mon e s:  tdy  ahie rsty Assessment & Evaluation in Higher Education, 43(4), 527-536. https://doi.org/10.1080/02602938.2017.1376310   
conlog . 015ig m: t the  f cig d i r ac   gr ion, 09, 1495-150. https://doi.org/10.1080/03075079.2013.868878   
a i English, 7(2), 273-292. https://doi.org/10.22108/are.2019.112997.1363   
ai      -57 https://doi.org/10.6018/ijes.331771   
ear 1) th g 49 Article 100530. https://doi.org/10.1016/j.asw.2021.100530   
ear ,    014 Ex2 weativeis nci ath wtt 4 101-114. /oi. 10.1016/j.system.2014.03.004   
emar ,13.  ti n,   wi s lr, sit Exeter.   
Min, H. T. (2005). Training students to become successul peer reviewers. Syst, 3, 293-308. htps://doi.org/10.1016/.ystem.2004.11.003   
i 0      11 doi.org/10.1016/j.jslw.2006.01.003   
in,H. 200 r st a wr  in  e for c  27(3, 5-05. /g/0.1016/. esp.2008.02.0022   
i 0f   k    31,3-57 https://doi.org/10.1016/j.jslw.2016.01.004   
athn5  t      .ti Science, 43(5), 591-614. https://doi.org/10.1007/s11251-015-9353-x Research, 17, 67-89. https://doi.org/10.1177/1362168812459151   
Stoch,  . 010  g, ke,   tive    .    nge Acquisition, 32(2), 303-334. https://doi.org/10.1017/S0272263109990532 https://doi.org/10.1080/09658416.2018.1535602   
oppig 3.    t, t  n search of qualities and standards (pp. 55-87). Netherlands: Springer.   
Witne  r h 019)       f f. Educational Psychology, (https://orcid.org/0000-0002-2284-2001).   
Yu, . 2019 n rm  r k  th ers sd in he     wng 40, 42-52. https://doi.org/10.1016/j.asw.2019.03.004   
Yu, .       5./. org/10.1016/j.asw.2017.03.004   
Yu, .  . 021n s f ier   wng Anid rng 4./.106/. asw.2021.100525   
Yu, .     018   h  nr t  nd Evaluation in Higher Education, 44(1), 50-65. https:/doi.org/10.1080/02602938.2018.1467879   
hao,.10 i   ad r aci hs sro Assessing Writing, 15(1), 3-17. https://doi.org/10.1016/j.asw.2010.01.002