# Understanding the SSARC model of task sequencing: Assessing L2 writing development

Mahmoud Abdi Tabari a,\* , Yizhou Wang b , Michol Miller c

a University of Nevada, Reno, Department of English, 1664 N. Virginia St, Reno, NV 89557, USA b Melbourne University, School of Languages and Linguistics, Australia c University of Hawai‘i at Manoa, ¯ Department of Second Language Studies, USA

# A R T I C L E I N F O

# A B S T R A C T

Keywords:   
Task complexity   
Task sequencing   
L2 writing development   
TBLT

This study aimed to explore the impact of task sequencing on the development of second language (L2) writing and investigate how L2 learners performed on three decision-making writing tasks completed in different orders over nine weeks. 120 advanced-high EFL students were randomly assigned to one of three groups and given different task sequences: 1) a simple-medium-complex (SMC) sequence, 2) a complex-medium-simple sequence (CMS), or 3) a random sequence (RDM). Essays were analyzed using measures of syntactic complexity, accuracy, lexical complexity, and fluency (CALF). Results showed that the CALF of L2 writing demonstrated longitudinal development over time in all three task sequencing groups. CALF development was not immediately apparent in the first six weeks, with most measures displaying a significant increase by the end of the ninth week. Furthermore, different task sequences resulted in varying patterns and magni tudes of CALF growth, but no specific sequence was found to be superior overall.

# 1. Introduction

The widespread adoption of task-based language teaching (TBLT) in recent decades has sparked significant interest in language learning research and pedagogy. This approach integrates diverse theoretical perspectives and practical teaching methods, emphasizing the development of effective task sequencing techniques to enhance second language (L2) acquisition. Despite the proposal of several sophisticated models over the years (Prabhu, 1987; Candlin, 1987; Skehan, 1996; Nunan, 2004; Robinson, 2001, 2005, 2007, 2010, 2015), consensus on empirically-proven criteria and procedures for effective task sequencing remains elusive (Baralt, Gilabert, & Robinson, 2014). Ellis et al. (2019) noted that “the grading and sequencing of tasks remain a major challenge in TBLT” (p. 14).

Recent task-based studies have aimed to establish pedagogically sound and researchable criteria for task sequencing, focusing on optimizing pedagogic tasks for L2 learners. These studies have particularly tested Robinson’s (2010) SSARC (Stabilize, Simplify, Automatize, Restructure, Complexify) model, closely associated with the Cognition Hypothesis (CH) and the Triadic Componential Framework (TCF). The SSARC model asserts two fundamental claims: (1) sequencing decisions should be based solely on cognitive factors, and (2) tasks should follow a sequence from simple to complex. Numerous investigations have explored the effects of task sequencing guided by the SSARC model on L2 oral production (Baralt, 2014; Kim, 2020; Kim & Payant, 2014; Malicka, 2014, 2018; Santos, 2022; Thompson, 2014). However, fewer studies have focused on applying the SSARC model to pedagogic task sequencing in L2 written production (Abdi Tabari & Cho, 2022; Abdi Tabari et al., 2024; Abdi Tabari & Miller, 2021; Lambert & Robinson, 2014;

Levkina & Gilabert, 2014). These studies have produced mixed findings regarding the effects of different task sequences on the complexity, accuracy, lexis, and fluency (CALF) of L2 written production. Moreover, to our knowledge, only two studies have investigated the role of task sequencing in short-term L2 writing development (Abdi Tabari & Miller, 2021; Lambert & Robinson, 2014), yielding inconclusive results.

Understanding how task sequencing influences L2 writing development is crucial as it sheds light on the mechanisms through which external manipulation impacts L2 learning processes. Task sequencing influences cognitive load, attention, and practice dis tribution, all critical factors in language acquisition. By manipulating task order, educators can create conditions that either facilitate or hinder the development of L2 writing skills. This study seeks to elucidate these mechanisms by examining the effects of different task sequences on L2 writing performance over time.

Drawing on the SSARC model of pedagogic task sequencing and synthesizing findings from prior L2 written-performance studies, this research investigates the role of task sequencing in L2 writing development by evaluating performance tasks ordered from simple to complex, complex to simple, and randomly. The evidence from this study contributes to testing the SSARC model’s predictions regarding the superiority of simple–complex sequencing over other task sequences and uncovering the longitudinal role of task sequencing in L2 writing development among L2 learners. By exploring these dimensions, the study aims to deepen understanding of how manipulating task sequences impacts L2 writing development processes, thereby informing more effective pedagogical practices.

# 2. Review of literature

# 2.1. Early studies on task sequencing

Early conceptions of task sequencing argued for sequencing according to task difficulty or complexity, conceptualized in various ways. Prabhu (1987) proposed sequencing tasks based on a “common sense judgment of increasing complexity” (p. 40), according to a hierarchy of task types ranging from simple to more difficult based on the output learners must produce to achieve task completion. Task sequencing, therefore, should be arranged according to the level of ‘reasonable challenge’ (Prabhu, 1987). Candlin (1987) outlined a more comprehensive set of task sequencing criteria by increasing task complexity according to cognitive load, communi cative stress, code complexity, and interpretive density; Skehan (1996) followed Candlin’s (1987) proposal but reconceptualized the criteria according to information processing theory to help learners achieve a balance between fluency and accuracy in task outcome, and provide opportunities to systematize language that can be incorporated into learners’ ongoing language repertoires (Skehan, 1996). Alternatively, Nunan’s (2004) approach to task sequencing focuses on the nature of linguistic input in task content, and task sequencing proceeds so that the demands on the learner gradually increase based on input features such as grammatical complexity; learner factors and procedural factors inherent in the task also contribute to determining task complexity.

Initial efforts at developing a sound approach to task sequencing suffered from a lack of clarity and empirical evidence for establishing operational sequencing criteria (Long & Crookes, 1992) and the conflation of distinct categories in task design, namely those related to task factors which can be manipulated and those which result from external influences outside of the task designer’s control (Malicka, 2018). In recent years, Robinson’s (2001), 2005, 2007) Cognitive Hypothesis (CH) and Triadic Componential Framework (TCF), followed by the subsequent SSARC model (Robinson, 2010, 2015, 2021) have evolved in response to the need to develop “theoretically motivated, empirically substantiable, and pedagogically feasible” criteria for task sequencing (Robinson, 2001, p. 27). Robinson’s (2001, 2003) CH, situated in functional and cognitive linguistic theory, states that by increasing the cognitive demands of tasks and the overall task complexity, learners will be pushed to achieve greater fluency and accuracy in their L2 production as they meet greater communicative demands; performing tasks in a simple to complex sequence will support automaticity and cumulative learning as the communicative and conceptual challenges posed by the task increase, thus driving L2 development (Robinson, 2010, 2015).

In conjunction with the CH, Robinson’s (2007) Triadic Componential Framework (TCF) classifies task characteristics into three categories: task conditions, task difficulty, and task complexity. Task conditions refer to the interactional factors influencing the type and quantity of interactions required in a task, while task difficulty is related to the individual abilities and affective factors learners bring to the task. Finally, cognitive task complexity represents the extent to which a task makes processing demands on attentional resources. Task complexity can be increased through the manipulation of both resource-directing variables, e.g., single vs multiple tasks, and resource-dispersing variables, e.g., causal reasoning (Robinson, 2001, 2005). Resource-directing variables direct learner attention to the language needed for task completion (for example, number of task elements and reasoning demands), and resource-dispersing variables place procedural and performative cognitive demands on learners but do not direct learner attention to linguistic features (such as planning time and task structure) (Robinson, 2001, 2005). The TCF provides a taxonomic inventory that can facilitate the operationalization of task design and task sequencing decisions, and a comprehensive list of common variables adapted from Robinson and Gilabert (2007) can be found in Appendix A.

Building on the CH and TCF, Robinson’s (2010), 2015) SSARC (Stabilize-Simplify-Automate-Restructure-Complexify) model further elaborates his principled approach to task sequencing, such that task design aims to distribute learning over a series of tasks that vary in terms of both conceptual and communicative demands. The SSARC model posits two design principles for task sequencing: first, task sequencing should be carried out according to variations in cognitive task complexity, achieved by manipulating both resource-directing and resource-dispersing variables (Robinson, 2010, 2015). Second, task complexity should be increased along resource-dispersing variables before resource-directing variables. Resource-dispersing variables are first increased in complexity to stimulate task performance utilizing the learner’s current L2 interlanguage, thus improving fluency and automaticity while achieving the task demands (Robinson, 2007). Next, resource-directing variables are increased so that learners’ cognitive resources are directed to aspects of the L2 system needed to achieve more sophisticated language; as a result, learner production is hypothesized to become more accurate and complex, as learners’ noticing and uptake of the relevant language in the task input are enhanced, and their interlanguage is restructured (Robinson, 2007, 2015). The three steps of task sequencing according to the SSARC model are described in Fig. 1.

In Step 1, Stabilize and Simplify, learners complete simple tasks to stabilize and engage their current interlanguage. In Step 2, Automatize, task complexity is then increased along with resource-dispersing variables to encourage quicker access to learners’ interlanguage and promote automatization. Finally, in Step 3, Restructure and Complexify, task complexity is raised along both resource-dispersing and resource-directing variables so that learners’ interlanguage systems are destabilized and restructured, thus further complexifying their interlanguage (Robinson, 2010). The SSARC model proposes a clear procedure for task sequencing that is hypothesized to promote interlanguage development through shifts in task complexity which may in turn lead to gradual shifts in learners’ interlanguage as they complete the task sequence; the model recognizes the dynamic nature of language learning, following Complex Dynamics Systems Theory (Larsen-Freeman, 2011).

# 2.2. The SSARC model of pedagogic task sequencing and L2 production

Robinson’s SSARC model offers a theoretically-driven approach to task sequencing that can be operationalized in syllabus design, but relatively few empirical research studies have been conducted to prove its effectiveness in promoting language development. Previous studies investigating the effectiveness of Robinson’s SSARC model of task sequencing differ in terms of task modality (L2 oral or written production), the array of task sequences tested (simple-complex, complex-simple, etc.), and the types of task complexity factors manipulated (resource-directing and/or resource-dispersing), but have produced mixed results in terms of empirical evidence supporting the model’s effectiveness for language development. Those studies comparing the effects of simple-to-complex sequencing to the effects of other sequencing approaches have examined the following aspects of L2 development: specific linguistic dimensions (Levkina & Gilabert, 2014), the frequency of language-related episodes (LREs; Baralt, 2014), and overall performance (Malicka, 2014, 2018).

Several studies have examined the effects of different task sequencing configurations on L2 oral development (Baralt, 2014; Kim, 2020; Malicka, 2014, 2018; Robinson, 2001; Santos, 2022; Thompson, 2014). Robinson (2001) tested the effects of simple-complex and complex-simple sequencing on oral map tasks and found that the simple-complex sequence led to greater accuracy, while the complex-simple sequence resulted in greater fluency. Malicka (2014, 2018) tested the effects of different sequences (simple-to-complex, randomized, or individual tasks) on L2 oral production by raising complexity along the resource-directing variables of $\pm$ reasoning demands and $\pm$ few elements in descriptive problem-solving monologic tasks. Although Malicka (2014) did not establish significant differences between the simple-complex sequencing group and the random-order task group, Malicka (2018) reported that simple-to-complex task sequencing led to improved speech rate, accuracy, and structural complexity when compared to individual task performance.

Kim (2020) compared the effects of different task treatments carried out in simple-complex sequencing on the oral production of novice L2 English learners. One group completed tasks manipulated along both resource-directing variables ( $\pm$ few elements and $\pm$ reasoning demands) and resource-dispersing variables ( $\pm$ planning time) according to Robinson’s (2010) SSARC model. Two other groups completed the same tasks, with additional support in the form of guided planning with vocabulary and content designed according to the researcher’s inductive observations. Results showed that the tasks sequenced according to Robinson’s SSARC model (without guided planning) outperformed the other groups on measures of syntactic complexity, providing support for the strength of the SSARC model over teacher intuition when sequencing tasks. Most recently, Santos (2022) investigated the effects of simple-complex and complex-simple sequencing following the SSARC model on the oral performance of Chinese learners of Portu guese, by manipulating the resource-directing variable of $\pm$ reasoning demands on a monologic narrative task. Findings showed that the simple-complex sequence only supported gains in participants’ accuracy, without significant effects on complexity or fluency.

![](img/817ab2d043e90951daeb651c09f6f8f72dc561653a64c5d345c429d7a18fe6d9.jpg)  
Fig. 1. Steps in the SSARC Model of Task Sequencing (from Robinson, 2010, p. 248). Notes. $\mathbf { i } =$ current interlanguage state; ${ \mathsf { e } } =$ mental effort; $\mathrm { \bf { \ell } } _ { \bf { S } ^ { ' } }$ $=$ simple task demands; $\mathbf { \tilde { c } ^ { \prime } = }$ complex task demands; rdisp $=$ resource-dispersing dimensions of tasks; rdir $=$ resource-directing dimensions of tasks; and $\mathbf { n } =$ the potential number of practice opportunities on tasks, which are determined in situ by teachers observing pedagogic task performance.

Baralt (2014) investigated the effects of task sequencing on both oral and written L2 Spanish development in story-retelling tasks. The study examined the effects of four simple-complex sequences (SSC, SCS, CSC, CCS) on L2 oral and written development by manipulating task complexity along $\pm$ reasoning demands. Results showed that sequences with more complex tasks (CCS and CSC) generated increased learning opportunities, as measured by the number of language-related episodes (LREs) and thus greater L2 development, as measured by the production of the subjunctive tense on both oral and written post-tests. While the study does not support the simple-complex order of task sequencing, the results indicate that providing more complex tasks may be more effective for supporting L2 development through interactive task-based learning.

A limited number of studies have investigated the effects of Robinson’s (2010) SSARC model on sequencing tasks eliciting L2 written production. Levkina and Gilabert (2014) tested the effect of different sequences (simple-complex, complex-simple, and ran domized) manipulating task complexity along two resource-directing variables ( $\pm$ spatial reasoning; $\pm$ perspective-taking) on English learners’ retention of spatial expressions over time. The results showed that complex-to-simple sequencing led to greater short-term retention of spatial expressions, while delayed post-tests showed that simple-complex sequencing resulted in greater long-term retention. Lambert and Robinson (2014) examined the effects of simple-complex and randomized task sequencing on L2 written production of narrative summary tasks, manipulated along both resource-directing ( $\pm$ few elements; $\pm$ reasoning demands) and resource-dispersing variables ( $\pm$ planning; $\pm$ prior knowledge; $\pm$ number of steps; $\pm$ multi-tasking). Although no significant differ ences were found between the SSARC group and the control group, the findings indicated the simple-to-complex task sequence led to greater overall long-term gains in task performance. Allaw and McDonough (2019) tested the effect of simple-complex versus complex-simple sequences on the L2 written production of French learners by sequencing tasks by manipulating both resource-directing ( $\pm$ spatial reasoning) and resource-dispersing variables $( \pm$ task structure). The results indicated that both se quences yielded improvements in lexical diversity, grammatical accuracy, and fluency; however, the simple-complex sequence led to greater overall performance and long-term L2 improvement.

Recently, Abdi Tabari and Miller (2021) investigated the effects of simple-complex versus complex-simple sequences on the L2 written production of decision-making tasks manipulated along resource-dispersing $( \pm$ planning time) and resource-directing $\ l . \pm$ few elements) variables. Findings demonstrated that the participants in the simple-complex sequencing group produced L2 writing with higher levels of syntactic and lexical complexity, grammatical accuracy, and written fluency than the individual task groups. Finally, Abdi Tabari and Cho (2022) examined the effects of a simple-complex sequence versus individual task performance of tasks at different complexity levels on L2 written production with decision-making tasks manipulated along both resource-dispersing ( $\pm$ planning time) and resource-directing $( \pm$ few elements) complexity variables. Results showed that the simple-complex sequencing group out performed the complex-simple group overall in terms of syntactic complexity and grammatical accuracy over a short period.

Inspired by previous research exploring the effects of task sequencing on L2 writing (Abdi Tabari & Cho, 2022; Abdi Tabari & Miller, 2021; Allaw & McDonough, 2019; Lambert & Robinson, 2014) and in conjunction with scholars’ calls for more longitudinal studies investigating how L2 writers perform tasks under different task sequencing conditions over time (Ellis et al., 2019; Robinson, 2021), the current study utilizes the SSARC model of pedagogic task sequencing to test the predictions about the precedence of simple–complex sequencing over alternative sequences in L2 writing and to examine how L2 writers who follow different task se quences develop different aspects (CALF) of their writing over a semester (i.e., longitudinal growth). Hence, this study is guided by the following research question (RQ):

RQ: How do different task sequencing orders across various levels of cognitive complexity affect the CALF of L2 writing development?

# 3. Methods

# 3.1. Participants

Our sample, chosen by convenience sampling, consisted of 120 Iranian graduate students (62 females, 58 males) enrolled in four sections of an advanced academic writing course designed for students of English as a foreign language (EFL) at a large university in Tehran, Iran. These students met weekly for $^ { 2 \mathrm { ~ h ~ } }$ and $3 0 \mathrm { { m i n } }$ over 12 weeks throughout one semester. The students in all four sections were taught by the same instructor who adhered to the university writing curriculum and used the same syllabus and teaching ma terials. They were aged between 22–25 years old $\mathbf { M } = 2 3 . 5$ ; $S _ { Ḋ } \mathrm { Ḋ } = 2 . 7 Ḍ Ḍ .$ ) and had learned English composition for more than five years (M $= 6 . 5$ ; $\mathrm { { S D } } = . 7 3 $ ). No students had obtained overseas learning experience or lived in an English-speaking country. At the onset of the study, students were asked to take the International English Language Testing System (IELTS) Academic Writing Task 2 to ensure that they were homogenous regarding their L2 writing proficiency levels. Their overall scores ranged between 7.0 and 7.5, equivalent to advanced high according to the ACTFL benchmarks or the C1 level based on the CEFR scale. To ensure homogeneity in students’ first language (L1) writing and to eliminate any discernible impact on their L2 writing, we requested students to complete a written argumentative task in their L1. Subsequently, we engaged two Persian colleagues to assess their baseline essays using a holistic scoring rubric. This rubric encompassed dimensions such as content, organization, structure, vocabulary use, and mechanics, specifically designed for the evaluation of argumentative essays. To assess the reliability of the rubric, we computed Cohen’s (1988) kappa coefficient for all the dimensions of the rubric and the coefficients were consistently over.80. In addition, the Kappa result showed strong inter-rater reliability $\left( \kappa = . 9 2 \right)$ ). Upon signing the consent forms, students were randomly divided into three groups of equal size $( N = 4 0 )$ ) and asked to perform three decision-making tasks, each with three versions (simple, medium, complex) over nine weeks while following different orders (Simple-Medium-Complex [SMC], Complex-Medium-Simple [CMS], or Random Order Sequence [RDM]).

# 3.2. Writing tasks

The three written decision-making tasks in this study were designed following the task sequencing principles of Robinson’s (2010) SSARC model; however, these tasks were designed to vary in cognitive complexity by manipulating only resource-directing factors, which were 1) number of elements, and 2) reasoning demands. In the first task, students were asked to take on the role of a university admissions counselor who must read a selection of college applications and decide which students should be selected for admission to the university based on a set of given criteria, such as number of spots available, GPA and SAT requirements, number of recom mendation letters received, the quality of statements of purpose and admissions essays, and coursework requirements from high school. Both the number of evaluation criteria and the number of applicants differed in each version of the task. In the second task, students took on the role of a member of a well-known technology company’s hiring team and made hiring decisions from a selection of job candidates for a software engineer position; students were asked to select candidates based on criteria such as educational background, years and type of experience, and certifications. Finally, the third task asked students to choose the best candidates for university scholarships based on criteria such as GPA, academic experience, TOEFL scores, and letters of recommendation; the three different versions of the task increased in task complexity by increasing the number of evaluation criteria and the number of applicants for evaluation (as shown in Table 1).

In Version 1, participants completed the simplest version of each written decision-making task and were asked to decide which two out of four university candidates should be admitted (Task 1), which two out of four software engineers should be hired (Task 2), or which two out of four candidates should receive a scholarship (Task 3). In Version 1, both resource-directing variables of reasoning demands and number of task elements were fewer than other versions of the tasks, to allow participants to simplify the input, stabilize their current interlanguage, and utilize their existing linguistic resources to complete the task. In Version 2, the cognitive complexity of the medium version of each of the three tasks was increased along both resource-directing variables of reasoning demands and number of task elements. Participants were required to select two out of five university candidates (Task 1), software engineers (Task 2), or scholarship applicants (Task 3), and evaluate more criteria than were provided in Version 1. Following the SSARC model, task complexity was slightly increased in this version to increase the cognitive complexity of the task and facilitate learners’ automatization of their existing interlanguage. For Version 3, participants completed the most cognitively complex version of each task, and selected two out of six university candidates (Task 1), software engineers (Task 2), or scholarship applicants (Task 3), representing increases in the number of task elements; participants were also given an increased number of evaluation criteria to make their decisions, resulting in an increase in task complexity along the variable of reasoning demands. According to the SSARC model, the increased cognitive complexity in the third version of these tasks was intended to help promote the restructuring of learners’ interlanguage system, utilize new linguistic forms, and complexify their written production as they were pushed to meet the task demands.

# 3.3. Validating task complexity manipulations

The perception questionnaire was used to validate the manipulation of the cognitive complexity level in the nine written decisionmaking task versions, ensuring that the cognitively complex task version indeed required more cognitive effort (R´ev´esz, 2014). While this questionnaire serves as a valid and well-established means of verifying hypothesized Task Complexity differences, we recognize its inherent subjectivity and acknowledge that the addition of objective measures could have contributed to a more nuanced understanding of task complexity differences.

To validate the manipulation, all student participants in the current study rated nine task versions concerning overall perceived difficulty, mental effort, perceived stress level, perceived interest level, planning time pressure, and writing time pressure. Similarly, 15 TBLT expert participants, with extensive experience in teaching L2 writing courses, used the same questionnaire and provided ratings for overall perceived difficulty and the level of mental effort, given the significance of these items to experts. These ratings were collected using a nine-point Likert scale questionnaire adapted from Lee’s (2019) original questionnaire (see Appendix B). Item 1 is characterized by Very Easy, Very Little Effort, Very Relaxed, Not Interesting, Very Little Pressure, and Very Poorly. Conversely, Item 9 represents Very Difficult, Very Much Effort, Very Frustrated, Very Interesting, Very Much Pressure, and Very Well. The mean ratings for all written decision-making task versions are summarized in Fig. 2. All self-ratings showed a consistent pattern confirming the validation of the assumptions about cognitive complexity in task design. The quantitative patterns were also checked using linear mixed-effects modelling (LMM), and the differences were all statistically significant $( \mathtt { p } < . 0 0 0 1 )$ between the three versions for each task (see Fig. 2). The self-rating scores revealed that the writing tasks designed and employed in this study represented the manipulated differences in cognitive tasks regarding both variables (i.e., $\pm$ reasoning demands and $\pm$ number of task elements).

Table 1 . The Sequence of Different Writing Task Versions Following the SSARC Model.   

<html><body><table><tr><td>Task complexity variables</td><td colspan="3">Task Sequencing</td></tr><tr><td>Resource-directing variables</td><td>Version1: Simple</td><td>Version 2: Medium</td><td>Version 3: Complex</td></tr><tr><td>Reasoning Demands</td><td>+ Justifications for a few choices (limited</td><td>+ + Justifications for some choices (some mental operations)</td><td>+ ++ Justifications for several choices (more</td></tr><tr><td>Number of Task Elements</td><td>mental operations) + Two Elements</td><td>+ + Four Elements</td><td>mental operations) + ++ Six Elements</td></tr></table></body></html>

# 3.4. Procedure

In this nine-week study, 120 students were randomly assigned to three groups (SMC, CMS, and RDM), engaging in a series of decision-making tasks over the semester. Each task had three versions presented in different orders successively. The deliberate choice of one-week intervals between tasks was made to align with the weekly schedule of all sections, each meeting for $^ { 2 \mathrm { ~ h ~ } }$ and $3 0 \mathrm { m i n }$ per session. This scheduling strategy reflects our commitment to maintaining consistency in the study design. The administered tasks were integral to the TBLT-informed course syllabus and the Writing curriculum followed by the students in a classroom setting. These tasks integrated with ongoing writing activities throughout the semester and were composed as part of in-class activities, contributing to student participation. Importantly, there was no external pressure for students to excel in these tasks beyond the natural expectations associated with task fulfillment. The study’s primary goal was to observe writing development over time within a low-pressure environment, where students were motivated by their intrinsic commitment to the course and the opportunity to earn extra bonus credits for active participation.

![](img/27b4c17312ab59007ba3c74314fbcfac9052fd6babb97b0855e5817b132d70a4.jpg)  
Fig. 2. Ratings of the Cognitive Complexity Level for Simple, Medium, and Complex Writing Task Versions. Error bars represent stan dard deviations.

We also conducted a pilot study in which 40 students at the same writing proficiency level were asked to perform three versions of a similar written task to determine the length of time for each task version. Based on the pilot study results, the fastest students completed the simple, medium, and complex task versions in 30, 36, and $4 0 \mathrm { { m i n } }$ , respectively, while the slowest ones performed the task versions in 35, 40, and $4 5 \mathrm { { m i n } }$ , respectively. Given that time-on-task was not considered a measure of validation for cognitive task complexity manipulations in the study, the times that the slowest students spent on each task version were determined as the time limit. In this way, we could control for time-limit constraints to portray a more valid and precise picture of each student’s performance as a result of increasing cognitive complexity.

In line with the SSARC model of task sequencing, the students in the first group performed each version of the written decisionmaking task in the simple-medium-complex order using a word processor every week. In total, they carried out nine versions of the three decision-making tasks over nine weeks successively. Within the same timeframe, those in the second group performed all nine versions of the three decision-making tasks using a word processor, but in reverse order (i.e., complex-medium-simple). Lastly, their counterparts in the third group completed nine task versions in random order using a word processor. In this sense, the sequence of three versions for each writing task was changed at random every week to preclude students from repeating the same sequence of task performance over the nine weeks of the study (see Table 2 displaying the sequence of three groups). It is also worth noting that, within the first group, the essays exhibited an average length of 391 words $( \mathbf { S D } = 7 2 $ ). The range spanned from the shortest essay at 301 words $( \mathrm { S D } = 5 4 )$ ) to the longest, encompassing 467 words $( S \mathrm { D } = 6 8 )$ ). For the second group, the essays had an average length of 388 words (SD $= 4 5$ ). The shortest essay comprised 307 words $\mathbf { S D } = 3 2 $ ), while the longest extended to 449 words $\mathrm { \Delta } \mathrm { S D } = 5 6 $ ). Likewise, within the third group, the essays had an average length of 382 words $\mathrm { \Delta } \mathsf { S D } = 4 8 \mathrm { \Delta }$ ). The shortest essay contained 311 words $\mathbf { ( S D = 4 1 }$ ), and the longest reached a length of 475 words $( S \mathrm { D } = 5 2 )$ ).

# 3.5. CALF metrics

For assessing the textual quality of the L2 writing samples, we followed the CALF framework (Housen et al., 2012, 2018; Norris & Ortega, 2009) which conceptualizes L2 writing proficiency as consisting of four subsystems, including syntactic complexity, accuracy, lexical complexity, and writing fluency. To represent syntactic complexity [C], we selected three metrics from the L2 Syntactic Complexity Analyzer (L2SCA) (Lu, 2010), including mean length of T-unit (MLT), dependant clauses per T-unit (DC/T), and complex nominals per T-unit (CN/T), where a T-unit represents a minimally terminable unit (usually a sentence) (see Hunt, 1966). Each metric offers a unique perspective on different aspects of syntactic complexity, allowing us to capture the richness and sophistication of participants’ syntactic structures. To gauge writing accuracy [A], we employed two distinct indices: the proportion of error-free clauses (EFCs) and the proportion of correct verb forms (CVFs). In assessing EFCs, all syntactic, morphological, and lexical errors were tabulated. Following the methodology advocated by Wigglesworth and Storch (2009), errors in capitalization, spelling, and punc tuation were intentionally excluded from the count due to their perceived severity. Non-grammatical errors were similarly dis regarded, in line with their suggestion, as they did not impede overall meaning. Additionally, essays underwent evaluation for CVFs, encompassing the precision in the use of verbs, including considerations such as subject-verb agreement, modal verbs, tense, and aspect. The first author graded all essays based on these two indices. To ensure the reliability of accuracy measures, an independent expert coded and scored half of the essays. The resulting Pearson correlation coefficients indicated a high level of inter-coder agreement for both EFCs $\left( r = . 9 4 \right)$ and CVFs $\left( r = . 9 6 \right)$ , affirming the robustness and consistency of the accuracy assessments. Regarding lexical complexity (L), we employed two widely used metrics to capture distinct aspects of this construct. First, we adopted the Measure of Textual Lexical Diversity (MTLD) to gauge lexical diversity. This metric, unlike traditional type-token ratio metrics, is found to be reliable for text lengths of 100–400 words, aligning well with the essay data collected in our study (Abdi Tabari, Lu, & Wang, 2023). Second, we chose the log frequency of content words (WF), representing the average log frequency over content words in the CELEX database, to measure lexical sophistication. This metric is suitable for capturing both minor and substantial improvements in a text and serves as a more reliable indicator of lexical sophistication when compared to raw frequency. Lastly, we calculated the writing speed, or words per minute (W/M), as a measure of fluency in L2 writing [F], given its ecological validity and applicability for assessing writing fluency in curriculum-based assessments (Abdi Tabari, 2023). All metrics described above are widely used in L2 writing research (see Johnson, 2017 for a review). The collected writing samples were checked for formatting errors and obvious spelling mistakes before processing, and the calculation of syntactic and lexical complexity metrics was assisted by an automated text analyzer, TAASSC (Kyle, 2016) and Coh-Metrix 3.0 (Graesser & McNamara, 2004).

Table 2 . A Description of the Group Sequencing Procedure.   

<html><body><table><tr><td rowspan="2">Groups</td><td colspan="9">9 Weeks of Data Collection</td></tr><tr><td>Week 1</td><td>Week 2</td><td>Week 3</td><td>Week 4</td><td>Week 5</td><td>Week 6</td><td>Week 7</td><td>Week 8</td><td>Week 9</td></tr><tr><td> SMC</td><td>Simple</td><td>Medium</td><td>Complex</td><td>Simple</td><td>Medium</td><td>Complex</td><td>Simple</td><td>Medium</td><td>Complex</td></tr><tr><td>CMS</td><td>Complex</td><td>Medium</td><td>Simple</td><td>Complex</td><td>Medium</td><td>Simple</td><td>Complex</td><td>Medium</td><td>Simple</td></tr><tr><td>RDM</td><td>Medium</td><td>Simple</td><td>Complex</td><td>Simple</td><td>Complex</td><td>Medium</td><td>Complex</td><td>Simple</td><td>Medium</td></tr></table></body></html>

Note. SMC $=$ Simple-Medium-Complex Group, CMS $=$ Complex-Medium-Simple Group, and RDM $\ c =$ Random Sequence Group

# 3.6. Data analysis

In the first step, we checked the correlation between CALF metrics and time points (Week 1–9) to determine the overall devel opment pattern. We then grouped the nine weeks or time points (Week 1–9) into three stages (Stage 1: Week 1–3; Stage 2: Week 4–6; Stage 3: Week 7–9) for measuring longitudinal development. For each stage, there were three consecutive weeks in which L2 writers completed a cycle of three task versions in a different sequence, i.e., SMC, CMS, or RDM. Note that the current design does not allow us to separate the effect of specific task complexity level and the effect of task sequencing, because the two parameters are correlated in the current design (e.g., the complex task is always the first task in the CMS group). For the same reason, we do not wish to explore how specific task complexity levels affect learner performance, but rather, we focus on how three cycles of tasks with different ordering may affect longitudinal development over nine weeks (three stages). Specifically, we compared the initial gains (Stage 2 vs Stage 1) and overall gains (Stage 3 vs Stage 1) of all CALF measures for each sequencing group. For inferential statistics, we used Linear Mixedeffects Modelling (LMM). As suggested by Plonsky and Oswald (2014), the effect sizes were interpreted based on benchmarks for L2 research. To interpret the effect size of correlations, coefficients at.25,.40, and.60 indicate small, medium, and large sizes. For CALF gains between stages, we also computed Cohen’s d metric as an indicator of effect size in each case. For Cohen’s $d$ metric in $\mathfrak { z }$ -tests (similar to traditional t-tests, but with an infinitival degree of freedom): small size $= . 4 0$ , medium $\mathrm { s i z e } = . 7 0$ , large $\mathbf { s i z e } = 1 . 0 0$ . While we primarily focus on the linguistic development within each sequence group, the models also allow a direct examination of between-group differences via F-tests (similar to traditional ANOVA models, but with adjustments of degrees of freedom), although the results must be interpreted with caution since groups might have different performance levels at the starting point. We want to point out that the F-tests and $\mathbf { z }$ -tests have different null hypotheses and focus on different aspects of the quantitative patterns, and therefore the p-values obtained from these tests might not always be consistent, e.g., the difference between significant and non-significant gains might be non-significant (Gelman & Stern, 2006). Nevertheless, a significant F-test will provide extra evidence of between-group differences but null effects from F-tests do not necessarily imply equivalence in linguistic gains across different treatments.

![](img/adc341a05e69eeef9aacfde9bc0ca1ce4c5c90317efa05764af611301a1289ad.jpg)  
Fig. 3. Correlation Matrix of CALF Metrics. Note. Significance of Pearson’s r coefficient: \* , $p < . 0 5 ,$ , \* \*, $p < . 0 1$ , $\textit { \textbf { x } } \ast \textit { \textbf { x } }$ , $p < . 0 0 1$

# 4. Results

Before analyzing the CALF development patterns, we carried out a series of Pearson’s correlation tests to check the association between the eight CALF metrics to diagnose potential multicollinearity issues (see Fig. 3). In general, we did not find any correlation coefficients above.70 (Mostafa & Crossley, 2020), suggesting that the selected metrics do not measure overlapping properties.

The CALF metrics in the L2 writing samples over nine weeks are summarised in Fig. 4 below. A growing trend can be observed in almost all linguistic complexity metrics in all three groups, while differences existed regarding the degree of change across CALF metrics and between sequencing groups, e.g., L2 writing fluency (W/M) showed a clear development trend in the CMS group and the random sequencing (RDM) group, but not in the SMC group. To confirm the general tendency of development, we carried out correlation analyses between CALF measures and time points (weeks) in three groups to analyze the overall pattern, assuming a linear development trend, as seen in Table 3. As can be observed, out of 24 pairwise correlations, 20 showed a significant positive correlation $( p ^ { \prime } s < . 0 5 )$ . First, non-significant correlations were observed for CN/T in the SMC group $( r = . 0 8 5$ , $p = . 1 0 6 )$ , where a trend of development can be seen descriptively), and W/M in the SMC group $( r = - . 0 4 6$ , $p = . 3 8 5 )$ , potentially because the group had a high writing speed from early on. In the CMS group, word frequency (WF) did not show a significant correlation with time point $( r = . 0 5 5$ , $p = . 2 9 9 \}$ , while the descriptive trend was consistent with the other two significant groups. Lastly, MTLD did not show a significant correlation with time in the RDM group $( r = . 0 5 5$ , $p = . 2 9 9 $ ).

![](img/cf62f5d2144f989a39ccf759b99d340483040cc038ecc9f435fec62cd711e180.jpg)  
Fig. 4. Longitudinal Development of CALF in L2 Writing over Nine Weeks: Mean Values at Each Time Point (A) and the Linear Trends of Development (B). Note. Three groups were different in terms of task sequencing (Simple-Medium-Complex [SMC], Complex-Medium-Simple [CMS], and Random Order [RDM]).

The correlation analyses were helpful to infer the overall development pattern. However, it should be acknowledged that the development of CALF might not be necessarily linear in nature, as there were still fluctuations over time potentially due to the level of complexity in each week. Therefore, we also analyzed the gains based on development stages, i.e., between the initial stage (Week 1–3), the second stage (Week 4–6), and the final stage (Week 7–9). An initial gain in CALF was defined as the numeric difference between Stage 1 and Stage 2, and an overall gain was defined as the numeric difference between Stage 1 and Stage 3. In the following, our analyses aimed to reveal whether the development patterns were immediately visible after three weeks, or alternatively, whether such patterns were only observable after a longer period. CALF gains in the three groups are summarised in Fig. 5. In each panel, we added a dotted line at zero, which refers to no difference between the earlier and later performances. If significant developments exist, then we expect the boxplots to be higher than the zero baselines. For inferential statistics, we used linear mixed-effects modelling (LMM) and $\mathcal { Z }$ -tests (see Table 4).

As for initial gains in CALF, as seen in the upper part of Table 4, the comparisons were largely non-significant. In the SMC group, we did not observe any significant initial gain $( p > . 0 5$ for eight CALF metrics), while the CMS group showed a significant initial gain in MLT $( M = 0 . 8 1$ , $p = . 0 0 5 4$ , $d = 0 . 5 2 9 $ ). In the RDM group, significant initial gains were observed in CN/T $\mathbf { \boldsymbol { M } } = 0 . 0 8$ , $\pmb { p } = . 0 4 3 7$ , $d =$ 0.333) and CVFs $( M = 0 . 0 4$ , $p = . 0 0 2 7$ , $d = 0 . 5 5 9$ ). We also directly tested the between-group differences, but no CALF metric showed a significant effect of the sequence group $( p > . 0 5$ for eight comparisons, $F \mathrm { . }$ -tests). Overall, the results suggested that the performance of writing tasks under the randomly assigned task sequencing conditions could not necessarily lead to significant changes in most of the CALF measures over a short period.

When we considered overall gains in CALF (see the lower part of Table 4), we observed more statistically significant developments. Out of the eight metrics tested, five showed significant improvements for the SMC group (MLT, DC/T, EFCs, CVFs, and MTLD), four were significant for the CMS group (MLT, CN/T, EFCs, and CVFs), while the RDM group showed improvements in almost all CALF metrics except for MTLD.

For example, in the SMC group, significant improvements were seen in two syntactic complexity measures, MLT $( M = 0 . 7 8$ , $p = . 0 0 7 6$ , $d = 0 . 3 9 7 $ ) and DC/T $( M = 0 . 1 0$ , $p < . 0 0 0 1$ , $d = 0 . 7 5 5$ , indicating that learners tended to write longer T-units, and they tended to use more subordination, or dependant clauses, in their composition. The SMC group also showed overall improvements in accuracy measures, with a tendency to produce more EFCs $( M = 0 . 0 3$ , $p = . 0 0 6 6$ , $d = 0 . 7 6 4 \mathrm { \AA }$ ), as well as more CVFs $( M = 0 . 0 4$ , $p = . 0 0 0 3$ , $d = 0 . 3 2 2 \mathrm { \Omega }$ ). Additionally, there was also a significant overall gain of lexical diversity (MTLD, $M = 3 . 4 0$ , $\pmb { p } = . 0 1 4 4$ , $d =$ 0.254) in the SMC group. However, there were no significant changes in either WF or W/M. Next, with the opposite task sequencing, the CMS group also had significant overall gains in MLT $M = 0 . 8 4$ , $p = . 0 0 4 1$ , $d = 0 . 5 0 2 )$ ) and CN/T $( M = 0 . 1 0 , p = . 0 1 0 5 ,$ , $d = 0 . 5 4 9 $ ). Similar to the SMC group, the CMS group also had significant accuracy gains in EFCs $\mathbf { \nabla } M = 0 . 0 6$ , $p < . 0 0 0 1$ , $d = 0 . 7 6 4 )$ and CVFs $\left( M = \right)$ $0 . 0 2 , p = . 0 4 9 7$ , $d = 0 . 3 2 2 \mathrm { \Omega }$ ). However, the tests did not reveal significant improvement in MTLD, Word Frequency, and W/M. Finally, in the RDM group, significant changes were observed in almost all CALF metrics, with the exception that the overall gain in MTLD did not reach the significance level. The effect size metrics (Cohen’s $d$ are summarised in Table 5, where a comparison between the three groups is also given. Again, between-group comparisons were double-checked by a series of $F \mathrm { . }$ -tests, where significant effects were observed for DC/T $( p = . 0 2 7 6 )$ and W/M $( p = . 0 1 9 0 )$ ), providing additional evidence for sequence-related differences in these two linguistic dimensions.

To summarize, the linguistic metrics showed limited changes in the initial gains, but most of them showed substantial improve ments in the overall gain, indicating that the learning effects were not instantaneous but emerged over a relatively longer period of time (e.g., nine weeks). When such improvements were indeed observed, our results showed mixed findings regarding the potential benefit of task-sequencing based on complexity level: compared with the random sequence, CMS and SMC sequences often led to improvements of larger magnitudes (e.g., MLT, DC/T, CN/T, EFCs, and MTLD), but not always. On the contrary, only the RDM group showed significant improvements in lexical sophistication and writing fluency (WF and W/M), and they also showed improvements in

Table 3 Correlation between CALF Measures and Time Points (Weeks) in Three Groups.   

<html><body><table><tr><td>CALF metric ~ Week time</td><td colspan="2"> SMC Group</td><td colspan="2">CMS Group</td><td colspan="2">RDM Group</td></tr><tr><td></td><td>r</td><td>p</td><td></td><td>p</td><td>r</td><td>p</td></tr><tr><td>MLT</td><td>.18***</td><td>.0007</td><td>.20***</td><td>.0002</td><td>.11*</td><td>.0321</td></tr><tr><td>DC/T</td><td>.26***</td><td>.0001</td><td>.14**</td><td>.0081</td><td>.31***</td><td>&lt;.0001</td></tr><tr><td>CN/T</td><td>.085</td><td>.106</td><td>.17**</td><td>.0014</td><td>.18***</td><td>.0006</td></tr><tr><td>EFCs</td><td>.19***</td><td>.0003</td><td>.25***</td><td>&lt;.0001</td><td>.15**</td><td>.0058</td></tr><tr><td>CVFs</td><td>.22***</td><td>.0001</td><td>.14**</td><td>.0099</td><td>.22***</td><td>&lt;.0001</td></tr><tr><td>MTLD</td><td>.17**</td><td>.0013</td><td>.13*</td><td>.0148</td><td>.049</td><td>.357</td></tr><tr><td>WF</td><td>.11*</td><td>.0375</td><td>.055</td><td>.299</td><td>.17**</td><td>.0015</td></tr><tr><td>w/m</td><td>.046</td><td>.385</td><td>.17***</td><td>.0009</td><td>.17**</td><td>.0012</td></tr></table></body></html>

Note. \* , $p < . 0 5$ , \* \*, $p < . 0 1$ , \* \*\* , $p < . 0 0 1$

![](img/db52619a3d5243f9c636f4eb1d16a51e6722beed58c571e1a6cc618d72bc0d44.jpg)  
Fig. 5. Initial Gains and Overall Gains in L2 Writing CALF over Nine Weeks in Three Task Sequencing Groups (Simple-Medium-Complex [SMC], ComplexMedium-Simple [CMS], and Random Order [RDM]). Note. Red lines indicate the zero-baseline.

CVFs at a higher level as compared to the CMS and SMC groups. Therefore, no group showed a clear advantage over the others in all linguistic dimensions.

# 5. Discussion

The main objective of this study was to investigate how task sequencing according to the SSARC model impacts various facets of L2 writing development over a semester. The findings highlighted nuanced patterns across different task sequencing conditions. In the short term, the SMC group did not exhibit significant initial gains in CALF, while the CMS group showed significant improvements only in MLT. In contrast, the RDM group demonstrated significant initial gains in CN/T and CVFs. These outcomes suggest that randomly assigned task sequencing did not consistently lead to short-term CALF improvements. Moreover, the results did not align with the SSARC model’s predictions favoring the SMC sequence, which contradicts previous studies indicating improvements in lexical di versity, grammatical accuracy, fluency, and syntactic and lexical complexity with the SMC sequence over brief periods (Abdi Tabari & Cho, 2022; Abdi Tabari & Miller, 2021; Allaw & McDonough, 2019). However, the current study’s findings of non-significant short-term effects resonate with earlier research that found no significant differences between the SMC and control groups (Lambert & Robinson, 2014; Levkina & Gilabert, 2014).

These results suggest that the function of SMC task sequencing for L2 writing may not effectively support short-term development, and increasing task complexity may not immediately prompt adjustments and expansions in L2 writers’ interlanguage systems. A key aspect to consider is task spacing (Rogers, 2022), as L2 learners generally benefit more from immediate or short-term interval repetition (Bui et al., 2019). In contrast to studies demonstrating benefits with shorter intervals like immediate repetition, our study employed one-week gaps between tasks. This decision may have posed challenges for L2 learners in recalling and reproducing their formulation processes and extracting linguistic resources. The one-week interval might not have provided sufficient opportunities for continuous practice and reinforcement, potentially hindering optimal conditions for short-term improvement in participants’ written CALF production.

Table 4 . Initial and Overall Gains of CALF Metrics in Three Groups. P Values Are Obtained by Contrastive Analysis based on Estimated Marginal Means from Linear Mixed-Effects Modelling $\mathbf { \sigma } _ { \mathbf { Z } }$ -tests, reference value $= 0 \mathrm { \dot { \Omega } }$ ).   

<html><body><table><tr><td rowspan="2">CALF</td><td colspan="2">SMC Group</td><td colspan="2">CMS Group</td><td colspan="2">RDM Group</td></tr><tr><td>M (SD)</td><td>p</td><td>M (SD)</td><td>p</td><td>M (SD)</td><td>p</td></tr><tr><td colspan="7"> Initial gains (Week 1 -3 vs Week 4 -6)</td></tr><tr><td>MLT</td><td>0.39 (2.05)</td><td>.1743</td><td>0.81 (1.53)</td><td>.0054**</td><td>0.34 (1.69)</td><td>.2317</td></tr><tr><td>DC/T</td><td>0.02 (0.15)</td><td>.2198</td><td>0.02 (0.07)</td><td>.2924</td><td>0.04 (0.11)</td><td>.0411</td></tr><tr><td>CN/T</td><td>0.03 (0.35)</td><td>.4592</td><td>0.03 (0.21)</td><td>.4370</td><td>0.08 (0.24)</td><td>.0437*</td></tr><tr><td>EFCs</td><td>0.02 (0.11)</td><td>.1628</td><td>0.02 (0.07)</td><td>.1878</td><td>0.01 (0.07)</td><td>.2768</td></tr><tr><td>CVFs</td><td>0.02 (0.09)</td><td>.1248</td><td>0.02 (0.09)</td><td>.1660</td><td>0.04 (0.07)</td><td>.0027**</td></tr><tr><td>MTLD</td><td>1.45 (8.21)</td><td>.2927</td><td>0.74 (7.72)</td><td>.6088</td><td>0.98 (9.17)</td><td>.4780</td></tr><tr><td>WF</td><td>0.01 (0.18)</td><td>.5476</td><td>0.04 (0.14)</td><td>.0600</td><td>0.03 (0.12)</td><td>.1764</td></tr><tr><td>w/m</td><td>0.01 (0.99)</td><td>.9669</td><td>0.01 (0.94)</td><td>.9306</td><td>0.22 (0.67)</td><td>.1020</td></tr><tr><td colspan="7">Overall gains (Week 1 -3 vs Week 7 -9)</td></tr><tr><td>MLT</td><td>0.78 (1.95)</td><td>.0076***</td><td>0.84 (1.66)</td><td>.0041**</td><td>0.68 (1.95)</td><td>.0197*</td></tr><tr><td>DC/T</td><td>0.10 (0.13)</td><td>&lt; .0001***</td><td>0.03 (0.10)</td><td>.0740</td><td>0.10 (0.13)</td><td> .0001***</td></tr><tr><td>CN/T</td><td>0.05 (0.24)</td><td>.2091</td><td>0.10 (0.18)</td><td>.0105*</td><td>0.10 (0.21)</td><td>.0110*</td></tr><tr><td>EFCs</td><td>0.03 (0.07)</td><td>.0066***</td><td>0.06 (0.07)</td><td>&lt; .0001***</td><td>0.03 (0.08)</td><td>.0074**</td></tr><tr><td>CVFs</td><td>0.04 (0.08)</td><td>.0003***</td><td>0.02 (0.07)</td><td>.0497*</td><td>0.05 (0.07)</td><td>&lt; .0001***</td></tr><tr><td>MTLD</td><td>3.40 (9.06)</td><td>.0144*</td><td>1.97 (7.74)</td><td>.1547</td><td>1.49 (10.07)</td><td>.2803</td></tr><tr><td>WF</td><td>0.04 (0.14)</td><td>.1384</td><td>0.01 (0.14)</td><td>.6506</td><td>0.07 (0.16)</td><td>.0060**</td></tr><tr><td>w/m</td><td>0.03 (0.83)</td><td>.8027</td><td>0.21 (0.90)</td><td>.1274</td><td>0.49 (0.73)</td><td>.0003***</td></tr></table></body></html>

Note. \* , $p < . 0 5$ , \* \*, $p < . 0 1$ , \* \*\* , $p < . 0 0 1$ .

Table 5 . Effect Sizes (Cohen’s d) of CALF Development in Three Groups and Non-Significant Results Are Not Shown with Hyphens.   

<html><body><table><tr><td rowspan="2">CALF</td><td colspan="2">SMC Group</td><td colspan="2">CMS Group</td><td colspan="2">RDM Group</td><td rowspan="2">Summary (Overall gain)</td></tr><tr><td>Initial</td><td>Overall</td><td>Initial</td><td>Overall</td><td>Initial</td><td>Overall</td></tr><tr><td>MLT</td><td>-</td><td>0.397</td><td>0.529</td><td>0.502</td><td></td><td>0.347</td><td>CMS &gt; SMC &gt; RDM</td></tr><tr><td>DC/T</td><td></td><td>0.755</td><td></td><td>-</td><td></td><td>0.723</td><td>SMC &gt; RDMF</td></tr><tr><td>CN/T</td><td></td><td>-</td><td></td><td>0.549</td><td></td><td>0.480</td><td>CMS &gt; RDM</td></tr><tr><td>EFCs</td><td>-</td><td>0.481</td><td></td><td>0.764</td><td></td><td>0.444</td><td>CMS &gt; SMC &gt; RDM</td></tr><tr><td>CVFs</td><td></td><td>0.585</td><td></td><td>0.322</td><td>0.559</td><td>0.789</td><td>RDM &gt; SMC &gt; CMS</td></tr><tr><td>MTLD</td><td></td><td>0.375</td><td></td><td></td><td></td><td>-</td><td>SMC</td></tr><tr><td>WF</td><td></td><td></td><td></td><td></td><td>:</td><td>0.411</td><td>RDMF</td></tr><tr><td>w/m</td><td>-</td><td>-</td><td></td><td></td><td>:</td><td>0.677</td><td>RDM</td></tr></table></body></html>

Note: For interpretation, d at.4,.7, and 1.0 indicates a small, medium, or large effect size. F The between-group differences are also supported by $F \mathrm { . }$ - tests.

These findings underscore the importance of task complexity and spacing in L2 writing research. In particular, it is crucial to understand how different sequencing models provide cognitive affordances and shape learners’ writing processes. The SMC sequence aims to incrementally increase task complexity, encouraging learners to engage in deeper cognitive processing and more complex language production. However, the anticipated benefits of this structured complexity increase might be offset if learners cannot sustain their cognitive engagement due to task spacing or other contextual factors.

Turning to long-term gains, the SMC group exhibited significant improvements in two syntactic complexity sub-constructs (MLT and DC/T) and both accuracy sub-constructs (EFCs and CVFs) with large and medium effect sizes, along with an increase in lexical diversity measured by MTLD with a large effect size (Allaw & McDonough, 2023). However, differences between the groups were not significant for lexical sophistication measured by WF (Allaw & McDonough, 2023). The SMC group also demonstrated slower writing speed in the final three weeks (Allaw & McDonough, 2023). These long-term results partially supported the SSARC model’s pre dictions, suggesting that increasing cognitive complexity enhances attention to form-function mappings, fostering more elaborate L2 knowledge connected with interlanguage representation (Robinson, 2010). Furthermore, these results align with Lambert and Robinson (2014), who found greater long-term gains with the SMC task sequence. At the same time, we admit that the current research design does not allow us to separate the role of task sequencing and the role of specific task complexity level at each time point, since the two parameters are correlated (e.g., the complex task is always the first task in the CMS group). Researchers who wish to isolate the effect of task complexity level from sequencing may need a design with a wide range of sequences (e.g., SMC, SCM, MSC, MCS, CSM, and CMS), and this remains a valuable research question for future studies.

The significant long-term improvements in the SMC group may be attributed to structured task sequencing promoting scaffolded practice opportunities. This approach effectively directs learners’ attention to specific linguistic structures, facilitating their devel opment over time (Allaw & McDonough, 2019). The cognitive demands of the increasing complexity might prompt learners to develop more sophisticated writing strategies, such as planning and revising their texts more meticulously to manage the complexity of the tasks.

The CMS group showed significant overall gains in MLT and CN/T with large effect sizes, as well as significant gains in EFCs and CVFs with large and small effect sizes. However, improvements in MTLD, WF, and W/M were not significant. These findings suggest that the notable improvements in some complexity and accuracy sub-constructs within the CMS group may be linked to repetition effects. Despite having the same overall exposure to input and output as the other groups, the unique task order in the CMS group potentially contributed to their enhanced performance compared to the RDM group. Furthermore, task repetition facilitated greater complexity and accuracy in the final three weeks (Abdi Tabari, 2022). It could also be argued that the CMS group leveraged their familiarity with task structures to reduce cognitive burden over time, enabling them to allocate attentional resources to various writing processes, resulting in more sophisticated texts (R´ev´esz et al., 2017).

However, their writing speed remained consistent. According to the SSARC model, the CMS group initially relied on familiar structures to strengthen their interlanguage state or "simple, stable attractor state of current interlanguage" (Robinson, 2010), grad ually expanding their syntactic repertoire through complexification. Reducing task complexity from complex to simple may not effectively highlight lemmas for L2 writers, thereby limiting their lexical repertoire and utilization of sophisticated lexical items in less cognitively demanding task versions (Zhan et al., 2021).

The RDM group exhibited significant gains in CALF of L2 writing development, except for lexical variety (MTLD), with small effect sizes observed for different syntactic complexity sub-constructs and a small effect size for EFCs, and large effect sizes for CVFs, WF, and W/M. This indicates that the RDM group showed better writing development than the SMC and CMS groups in terms of lexical so phistication, writing fluency, and one accuracy sub-construct (Abdi Tabari, 2022). However, their progress varied across different L2 writing constructs compared to the other groups. This improvement could be attributed to repetition effects, where sufficient exposure to input and output over time resulted in long-term gains across various L2 writing constructs, especially in lexical sophistication and fluency in the final three weeks (Nitta & Baba, 2014). Additionally, practice opportunities allowed for deeper cognitive processing, facilitated memory elaboration, and supported schema development for successful performance in writing tasks, irrespective of their sequence (Nitta & Baba, 2014). Overall, the RDM group’s gains highlight the significance of repetition and exposure in fostering L2 writing development, emphasizing the role of frequent practice in achieving proficiency.

Overall, this study investigated the effects of the SSARC model of task sequencing on various aspects of L2 writing development in both short and long terms. The findings indicated that randomly assigned task sequencing did not consistently lead to short-term CALF gains and did not support the SSARC model’s predictions favouring the SMC sequence. However, over the long term, the SMC group showed significant improvements in syntactic complexity, accuracy, and lexical diversity, while the CMS group demonstrated gains in specific complexity sub-constructs and accuracy measures. The RDM group also exhibited significant gains in overall CALF, except for lexical variety. These results underscore the roles of task complexity and repetition effects in L2 writing development and contribute to understanding the challenges faced by L2 writers. These insights suggest that the interplay between task complexity, sequencing, and spacing critically shapes L2 learners’ cognitive processes and writing strategies. Future research should delve deeper into the cognitive mechanisms and strategic behaviours fostered by different task sequences to enhance L2 writing instruction and curriculum design.

# 6. Conclusion: implications, limitations, and directions for future research

Based on the promising results of this study, we derive profound theoretical and pedagogical implications, particularly concerning the teaching and assessment of L2 writing. The study provides nuanced validation for key aspects of the SSARC model, specifically highlighting the effectiveness of a structured progression from simpler to more complex tasks. The observed enhancements in syntactic complexity, accuracy, and lexical diversity in L2 writing strongly affirm the model’s premise that a well-sequenced and progressively challenging task design can significantly enhance language development over time. However, it is essential to acknowledge the study’s nuanced findings, which suggest that contextual variables may influence the model’s effectiveness. Further inquiry into these nuances is crucial for refining the model’s application, enabling educators to tailor its implementation to diverse contexts and learner profiles. Therefore, the study advances our understanding of when and how the SSARC model can be optimally deployed, providing valuable insights into the theoretical framework of language learning and pedagogy.

This study carries profound implications for L2 writing pedagogy. Educators aiming to enhance their practices can strategically adopt task sequencing rather than relying on isolated writing assignments, aligning with our exploration of task sequencing’s impact on L2 writing development (Lambert & Robinson, 2014). By implementing a scaffolded approach throughout the semester, educators facilitate a cyclic learning process where students retrieve and apply prior knowledge, evaluate and refine their written work, and consolidate their writing skills. This approach not only enhances students’ ability to navigate the inherent structures of writing tasks but also fosters comprehensive and progressive development of their writing proficiency. Our findings also reveal nuanced variations among different task sequences, highlighting diverse patterns and extents of development. While no single sequence emerged as universally superior, thoughtful consideration of task order contributes significantly to the longitudinal enhancement of CALF in L2 writing. Thus, integrating a scaffolded approach to writing tasks throughout the semester and remaining sensitive to the potential impacts of task sequencing can lead to a more effective and nuanced development of L2 writing skills, especially among advanced-high EFL students.

From an L2 writing assessment perspective, it is crucial to consider how tasks should be administered in order to both evaluate and support L2 writing performance and development. Assessments should mirror the structured progression from simpler to more complex tasks observed in the study. By incorporating this approach, assessors can accurately track learners’ developmental trajectories in syntactic complexity, accuracy, lexical diversity, and fluency over time. Implementing longitudinal assessments allows for monitoring sustained improvements in CALF metrics, providing insights into the cumulative effects of task sequencing on L2 writing development. Furthermore, assessments should be designed to gauge learners’ cognitive engagement and strategic use of language structures in response to increasingly complex tasks, fostering critical thinking skills and deeper linguistic performance. Tailoring assessment strategies to accommodate diverse learner backgrounds and linguistic competencies is crucial for equitable assessment practices. Understanding individual learners’ needs enables educators to effectively adjust task requirements and instructional approaches.

In sum, leveraging insights from task sequencing research to refine assessment practices in L2 writing instruction is essential. By adopting scaffolded approaches and considering the effects of task sequencing, educators can optimize assessment strategies to pro mote comprehensive writing development. These implications underscore the significance of aligning assessment practices with pedagogical approaches that systematically cultivate L2 writing skills. By integrating task sequencing insights into assessment frameworks, educators can effectively support learners’ language learning and promote their overall linguistic and cognitive growth.

However, there are limitations to this study that should be acknowledged. First, task complexity was manipulated based on two resource-directing variables while resource-dispersing variables were not explored. Future research should manipulate task complexity by considering both variables simultaneously to uncover their impacts on L2 writing development over time. The cognitive task complexity assumptions were validated using learner self-ratings and expert ratings of difficulty. Nevertheless, a more sophis ticated triangulation of objective methods (e.g., keystroke-logging or eye-tracking), introspective methods, and neuroimaging methods may aid future research in assessing the role of cognitive load in L2 writing development. Further, product-based fluency metrics may not fully capture the cognitive mechanisms and processes involved in writing. Future research should adopt process-based fluency metrics to investigate how different task sequences influence L2 writers’ speed, fluency, pausing, and eye-gaze behaviours, as well as the cognitive processes that trigger pausing. Finally, the current study focused on investigating L2 writing outcomes over time rather than exploring the cognitive processes associated with L2 writing under different task sequencing conditions. While our findings offer valuable insights into the patterns of L2 writing development, the study does not examine the specific cognitive mechanisms that may underlie these outcomes. To address this limitation, future research should adopt a mixed-methods approach. By integrating quantitative measures of writing performance with qualitative analyses of cognitive processes, researchers can achieve a more compre hensive understanding of how task sequencing influences learners’ cognitive processes during L2 writing tasks. This integrated approach would enable a nuanced exploration of the cognitive mechanisms involved, thereby enhancing the overall impact and practical relevance of research in the field of L2 writing development. Despite these limitations, the promising findings of this study contribute to the advancement of current knowledge regarding the role of task sequencing in L2 writing development.

# CRediT authorship contribution statement

Mahmoud Abdi Tabari: Writing – review & editing, Writing – original draft, Resources, Project administration, Methodology, Investigation, Conceptualization. Yizhou Wang: Writing – review & editing, Writing – original draft, Visualization, Validation, Software, Data curation. Michol Miller: Writing – review & editing, Writing – original draft.

# Declaration of Competing Interest

We declare that we have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

# Data availability

Data will be made available on request.

Appendix A. Task variables in Robinson’s triadic componential framework (Adapted from Robinson & Gilabert, 2007, p. 164)   

<html><body><table><tr><td>Task Complexity (Cognitive Factors)</td><td>Task Conditions (Interactive Factors)</td><td>Task Difficulty (Learner Factors)</td></tr><tr><td>a) Resource-directing variables making cognitive/</td><td> a) Participation variables making</td><td> a) Ability variables and task-relevant resource</td></tr><tr><td>conceptual demands</td><td>interactional demands</td><td>differentials</td></tr><tr><td>+ /- here and now + /- few elements</td><td>+ /- open solution</td><td>h/l working memory</td></tr><tr><td>-/+ spatial reasoning</td><td>+ /- one-way flow</td><td>h/l reasoning h/l task-switching</td></tr><tr><td>-/+ causal reasoning</td><td>+ /- convergent solution</td><td></td></tr><tr><td></td><td>+ /- few participants</td><td>h/l aptitude</td></tr><tr><td>-/+ intentional reasoning</td><td>+ /- few contributions needed</td><td>h/l field independence</td></tr></table></body></html>

(continued )   

<html><body><table><tr><td>Task Complexity (Cognitive Factors)</td><td>Task Conditions (Interactive Factors)</td><td>Task Difficulty (Learner Factors)</td></tr><tr><td>/+ perspective-taking</td><td>+ /- negotiation not needed</td><td>h/l mind/intention-reading</td></tr><tr><td>b) Resource-dispersing variables making performative/</td><td>b) Participant variables making</td><td>b) Affective variables and task-relevant state-</td></tr><tr><td> procedural demands</td><td>interactant demands</td><td>trait differentials</td></tr><tr><td>+ /- planning time</td><td>+ /- same proficiency</td><td>h/l openness to experience</td></tr><tr><td>+ /- single task</td><td>+ /- same gender</td><td> h/l control of emotion</td></tr><tr><td>+ /- task structure</td><td>+ /- familiar</td><td>h/l task motivation</td></tr><tr><td>+ /- few steps</td><td>+ /- shared content knowledge</td><td>h/l processing anxiety</td></tr><tr><td>+ /- independency of steps</td><td>+ /- equal status and role</td><td>h/l willingness to communicate</td></tr><tr><td>+ /- prior knowledge</td><td>+ /- shared cultural knowledge</td><td>h/l self-efficacy</td></tr></table></body></html>

# Appendix B. Learner self-rating questionnaire

Please answer the following questions after completing each task version.   
1. What was the level of the overall difficulty of the task? (Please circle).

<html><body><table><tr><td>1</td><td></td><td></td><td></td><td></td><td></td><td>7</td><td>8</td><td>9</td></tr><tr><td></td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td></td><td></td><td></td></tr></table></body></html>

2. How much mental effort was required to perform the task? (Please circle).

<html><body><table><tr><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table></body></html>

<html><body><table><tr><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td></tr></table></body></html>

ery Little Effort Very Much Effort 3. What was the level of stress you felt while performing the task? (Please circle).

4. How interesting was the task?

<html><body><table><tr><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>9</td></tr></table></body></html>

Very Relaxed Very Frustrated

5. How much time pressure did you feel during the planning stage?

<html><body><table><tr><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td></tr></table></body></html>

Not interesting Very Interesting

<html><body><table><tr><td>1</td><td>2</td><td>3</td><td>4</td><td></td><td></td><td></td><td>8</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td>5</td><td>6</td><td>7</td><td></td><td>9</td></tr></table></body></html>

Very little pressure Very much pressure

<html><body><table><tr><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td></tr></table></body></html>

Very little pressure Very much pressure 6. How much time pressure did you feel during the writing stage?

How well do you believe you carried out the task?

# Appendix C. Supporting information

Supplementary data associated with this article can be found in the online version at doi:10.1016/j.asw.2024.100893.

# References

Abdi Tabari, M., & Miller, M. (2021). Unraveling the effects of task sequencing on the syntactic complexity, accuracy, lexical complexity, and fluency of L2 written production. Canadian Journal of Applied Linguistics, 24(2), 1–29. https://doi.org/10.37213/cjal.2021.31306   
Abdi Tabari, M. (2022). Investigating the interactions between L2 writing processes and products under different task planning time conditions. Journal of Second Language Writing, 55, 100871. https://doi.org/10.1016/j.jslw.2022.100871   
Abdi Tabari, M., & Cho, M. (2022). Task sequencing and L2 writing development: Exploring the SSARC model of pedagogic task sequencing. Language Teaching Research, 136216882210909. https://doi.org/10.1177/13621688221090922   
Abdi Tabari, M. (2023). Unpacking the effects of different lengths of pre-task planning time: L2 writing outcomes and learners’ perceptions. The Language Learning Journal, 1–14. https://doi.org/10.1080/09571736.2023.2213237   
Abdi Tabari, M., Lu, X., & Wang, Y. (2023). The effects of task complexity on lexical complexity in L2 writing: An exploratory study. System, 114, 103021. https://doi. org/10.1016/j.system.2023.103021   
Abdi Tabari, M., Khajavy, G. H., & Goetze, J. (2024). Mapping the interactions between task sequencing, anxiety, and enjoyment in L2 writing development. Journal of Second Language Writing, 65, 101116. https://doi.org/10.1016/j.jslw.2024.101116   
Allaw, E., & McDonough, K. (2019). The effect of task sequencing on second language written lexical complexity, accuracy, and fluency. System, 85, Article 102014. https://doi.org/10.1016/j.system.2019.06.008   
Baralt, M. (2014). Task complexity and task sequencing in traditional versus online language classes. In M. Baralt, R. Gilabert, & P. Robinson (Eds.), Task sequencing and instructed second language learning (pp. 95–122). Bloomsbury.   
Baralt, M., Gilabert, R., & Robinson, P. (2014). An introduction to theory and research in task sequencing and instructed second language learning. In M. Baralt, R. Gilabert, & P. Robinson (Eds.), Task sequencing and instructed second language learning (pp. 1–37). Bloomsbury.   
Bui, G., Ahmadian, M. J., & Hunter, A.-M. (2019). Spacing effects on repeated L2 task performance. System, 81, 1–13. https://doi.org/10.1016/j.system.2018.12.006   
Candlin, C. (1987). Towards task-based language learning. In C. Candlin, & D. Murphy (Eds.), Language learning tasks (pp. 5–22). Prentice-Hall.   
Cohen, J. (1988). Statistical power analysis for the behavioral sciences. Lawrence Erlbaum Associates,. https://doi.org/10.1016/C2013-0-10517-X   
Ellis, R., Skehan, P., Li, S., Shintani, N., & Lambert, C. (2019). Task-based language teaching: Theory and practice. Cambridge University Press,   
Gelman, A., & Stern, H. (2006). The difference between “significant” and “not significant” is not itself statistically significant. The American Statistician, 60(4), 328–331. https://doi.org/10.1198/000313006×152649   
Housen, A., De Clercq, B., Kuiken, F., & Vedder, I. (2018). Multiple approaches to complexity in second language research. Second Language Research, 35(1), 3–21. https://doi.org/10.1177/0267658318809765   
Hunt, K. (1966). Recent measures in syntactic development. Elementary English, 43, 732–739.   
Johnson, M. D. (2017). Cognitive task complexity and L2 written syntactic complexity, accuracy, lexical complexity, and fluency: A research synthesis and metaanalysis. Journal of Second Language Writing, 37, 13–38. https://doi.org/10.1016/j.jslw.2017.06.001   
Kim, N. (2020). The effects of different task sequences on novice L2 learners’ oral performance in the classroom. Language Teaching Research. https://doi.org/10.1177/ 1362168820937548   
Kim, Y., & Payant, C. (2014). A pedagogical proposal for task sequencing: An exploration of task repetition and task complexity on learning opportunities. In M. Baralt, R. Gilabert, & P. Robinson (Eds.), Task sequencing and instructed second language learning (pp. 151–177). Bloomsbury.   
Lambert, C., & Robinson, P. (2014). Learning to perform narrative tasks: A semester-long classroom study of L2 task sequencing effects. In M. Baralt, R. Gilabert, & P. Robinson (Eds.), Task sequencing and instructed second language learning (pp. 207–230). Bloomsbury.   
Larsen-Freeman, D. (2011). Complex, dynamic systems: A new transdisciplinary theme for applied linguistics? Language Teaching, 45, 202–214. https://doi.org/ 10.1017/s0261444811000061   
Levkina, M., & Gilabert, R. (2014). Task sequencing in the L2 development of spatial expressions. In M. Baralt, R. Gilabert, & P. Robinson (Eds.), Task sequencing and instructed second language learning (pp. 37–70). Bloomsbury.   
Long, M. H., & Crookes, G. (1992). Three approaches to task-based syllabus design. TESOL Quarterly, 26, 27–56. https://doi.org/10.2307/3587368   
Malicka, A. (2014). The role of task sequencing in L2 oral production. In M. Baralt, R. Gilabert, & P. Robinson (Eds.), Task sequencing and instructed second language learning (pp. 71–95). Bloomsbury.   
Malicka, A. (2018). The role of task sequencing in fluency, accuracy, and complexity: Investigating the SSARC model of pedagogic task sequencing. Language Teaching Research, 24, 1. https://doi.org/10.1177%2F1362168818813668.   
Mostafa, T., & Crossley, S. A. (2020). Verb argument construction complexity indices and L2 writing quality: Effects of writing tasks and prompts. Journal of Second Language Writing, 49, Article 100730. https://doi.org/10.1016/j.jslw.2020.100730   
Nitta, R., & Baba, K. (2014). Task repetition and L2 writing development. In H. Byrnes, & R. M. Manchon ´ (Eds.), Task-based language learning insights from and for L2 writing (pp. 107–136). John Benjamins.   
Nunan, D. (2004). Task-based language teaching. Cambridge University Press.   
Plonsky, L., & Oswald, F. L. (2014). How big is “big”? Interpreting effect sizes in L2 research. Language Learning, 64(4), 878–912. https://doi.org/10.1111/lang.12079   
Prabhu, N. S. (1987). Second language pedagogy. Oxford University Press.   
R´ev´esz, A., Kourtali, N.-E., & Mazgutova, D. (2017). Effects of task complexity on L2 writing behaviors and linguistic complexity. Language Learning, 67(1), 208–241. https://doi.org/10.1111/lang.12205   
Robinson, P. (2001). Task complexity, task difficulty, and task production: Exploring interactions in a componential framework. Applied Linguistics, 22, 27–57. https:// doi.org/10.1093/applin/22.1.27   
Robinson, P. (2005). Cognitive complexity and task sequencing: Studies in a componential framework for second language task design. IRAL: International Review of Applied Linguistics in Language Teaching, 43, 1–32.   
Robinson, P. (2007). Criteria for classifying and sequencing pedagogic tasks. In M. del Pilar Garcia Mayo (Ed.), Investigating tasks in formal language learning (pp. 7–26). Multilingual Matters.   
Robinson, P. (2010). Situating and distributing cognition across task demands: The SSARC model of pedagogic task sequencing. In In. M. Pütz, & L. Sicola (Eds.), Cognitive processing in second language acquisition: Inside the learner’s mind (pp. 243–268). John Benjamins. https://doi.org/10.1075/celcr.13.   
Robinson, P. (2015). Cognition hypothesis, second language task demands, and the SSARC model of pedagogic task sequencing. In M. Bygate (Ed.), Domains and Directions in the Development of TBLT (pp. 87–121). John Benjamins.   
Robinson, P. (2021). The cognition hypothesis, the triadic componential framework, and the SSARC model: An instructional design theory of pedagogic task sequencing. In M. Ahmadian, & M. Long (Eds.), The Cambridge handbook of task-based language teaching (pp. 205–225). Cambridge University Press.   
Robinson, P., & Gilabert, R. (2007). Task complexity, the cognition hypothesis, and second language learning and performance. International Review of Applied Linguistics, 45(3), 161–284. https://doi.org/10.1515/iral.2007.007   
Rogers, J. (2022). Spacing effects in task repetition research. Language Learning, 73(2), 445–474. https://doi.org/10.1111/lang.12526   
Santos, S. (2022). Increasing the reasoning demands of a task and task sequencing on the oral production of Chinese learners of Portuguese as a foreign language. In SciELO Preprints. https://doi.org/10.1590/1678–460×202256813.   
Skehan, P. (1996). A framework for the implementation of task-based instruction. Applied Linguistics, 17, 38–63.   
Thompson, C. (2014). The effects of guided planning, task complexity, and task sequencing on L2 oral production. In M. Baralt, R. Gilabert, & P. Robinson (Eds.), Task sequencing and instructed second language learning (pp. 123–148). Bloomsbury.   
Wigglesworth, G., & Storch, N. (2009). Pair versus individual writing: Effects on fluency, complexity and accuracy. Language Testing, 26(3), 445–466. https://doi.org/ 10.1177/0265532209104670   
Zhan, J., Sun, Q., & Zhang, L. J. (2021). Effects of manipulating writing task complexity on learners’ performance in completing vocabulary and syntactic tasks. Language Teaching Research. https://doi.org/10.1177/13621688211024360

Mahmoud Abdi Tabari is a teaching assistant professor of TESOL and Writing Studies at the University of Nevada, Reno, where he teaches classes on writing pedagogy and multilingual writing. His research interests include second language acquisition, second language writing, and task-based language teaching.

Yizhou Wang is a linguistics teaching associate at the School of Languages and Linguistics, at the University of Melbourne. His research interests include general and applied linguistics, psycholinguistics, and speech sciences.