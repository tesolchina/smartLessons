# How do we respond to generative AI in education? Open educational practices give us a framework for an ongoing process

Anna MillsA Maha BaliB Lance EatonC

English Instructor, College of Marin, Kentfield, California, USA   
Professor of Practice, Center for Learning and Teaching, The American University in Cairo,   
Cairo, Egypt   
Director of Digital Pedagogy, College Unbound, Providence, Rhode Island, USA

DOI: https://doi.org/10.37074/jalt.2023.6.1.34

# Abstract

With the release of ChatGPT in November 2022, the field of higher education rapidly became aware that generative AI can complete or assist in many of the kinds of tasks traditionally used for assessment. This has come as a shock, on the heels of the shock of the pandemic. How should assessment practices change? Should we teach about generative AI or use it pedagogically? If so, how? Here, we propose that a set of open educational practices, inspired by both the Open Educational Resources (OER) movement and digital collaboration practices popularized in the pandemic, can help educators cope and perhaps thrive in an era of rapidly evolving AI. These practices include turning toward online communities that cross institutional and disciplinary boundaries. Social media, listservs, groups, and public annotation can be spaces for educators to share early, rough ideas and practices and reflect on these as we explore emergent responses to AI. These communities can facilitate crowdsourced curation of articles and learning materials. Licensing such resources for reuse and adaptation allows us to build on what others have done and update resources. Collaborating with students allows emergent, studentcentered, and student-guided approaches as we learn together about AI and contribute to societal discussions about its future. We suggest approaching all these modes of response to AI as provisional and subject to reflection and revision with respect to core values and educational philosophies. In this way, we can be quicker and more agile even as the technology continues to change.

We give examples of these practices from the Spring of 2023 and call for recognition of their value and for material support for them going forward. These open practices can help us collaborate across institutions, countries, and established power dynamics to enable a richer, more justly distributed emerging response to AI.

Keywords: ChatGPT; entangled pedagogy; generative AI; GPT-3; GPT-4; large language models; LLMs; OEP; OER; higher education; open educational practices; Open Educational Resources; open pedagogy; PICRAT.

# Educational shocks

For many students and faculty, Fall 2022 was the semester that promised relief from COVID-related concerns; gone were masks from many campuses, hybrid flexible classroom set-ups, and a sense of precarity of safety (note: we acknowledge there were still risks and for many; it was and continues to be unsafe, but most institutions by Fall of 2022 had moved on from concern about COVID). The sense of normality after several years of constant shifting and calibration ended with the arrival of ChatGPT, a form of generative AI with disruptive potential like COVID but without the overwhelming attention and support that came with the pandemic. Even though generative AI had existed for quite some time, it suddenly became a topic of focus in education circles through articles like “The college essay is dead” in The Atlantic by Stephen Marche (2022). Since then, millions, if not billions, of words have been both written and generated (by AI), exploring what this all means for education.

Shocks in education, like the COVID-19 pandemic or the advent of ChatGPT and other AI text generators, create a need to respond quickly, even though we often have insufficient local knowledge to take action. Open and public scholarship becomes a space for us to find and support one another as we build expertise through a turbulent time. This openness as a worldview, process, or attitude (Koseoglu & Bali, 2016) can include sharing amongst instructors within and across institutions and an openness to collaborate with students and other stakeholders.

Our first response to educational shocks should be to check in with our values. adrienne maree brown (who prefers to write her name in lowercase) reminds us that “intentional adaptation” can be invaluable to navigating change. We can ground our intentions by refocusing on our goals and values. Change can be a “shock” (like an earthquake in nature or the COVID-19 pandemic in academia/education) or a “slide” (a slower change that we have more time to adapt to). Our role is to

harness the shocks and direct the slides – all towards achieving the systemic, cultural and psychic shifts we need to navigate the changes with the greatest equity, resilience and ecological restoration possible (brown, 2017).

It has been a challenge for many institutions and individuals to respond, in part because generative AI has been a moving target, with changes happening constantly throughout the early part of 2023. The challenge also lies in the variety of faculty reactions: generative AI seems to challenge, concern, or excite faculty in very different ways. This has made it difficult for institutions to come up with clear guidance and support. We saw a great wave of concern about academic integrity implications. We also saw faculty with backgrounds in data rights and digital privacy issues, like Lauren Goodlad and Samuel Baker (2023) and Autumn Caines (2023), who discouraged students from using language models but advocated teaching about the systems so students would understand the risks and ethical concerns. Other faculty have been excited to explore pedagogical applications of language models. Wharton Business School professor Ethan Mollick has shared his experiments introducing multiple uses of generative AI in his courses on his blog, “One Useful Thing.” Marc Watkins (2023) has shared his applications of generative AI in the writing classroom in his substack Rhetorica.

Gradually, interest in pedagogical applications has become more widespread. As Rasul et al. (2023, p. 3) put it, “the scholarly community is actively investigating the most efficient and responsible methods to integrate ChatGPT into tertiary education.” Even among faculty generally positively disposed toward the technology, though, studies of faculty perceptions note significant concerns and uncertainty about how to rethink assessment (Limna et al., 2023; Firat, 2023). Meanwhile, many more faculty have barely begun to learn what these tools are or to reflect on what they mean for education and how to adjust next.

Our sense is that generative AI feels deeply threatening to many faculty because it seems to co-opt the forms of assessment that are integral to their teaching. Many faculty work under deep pedagogical and philosophical understandings about how they teach, what they teach, and what a classroom is, culminating in demonstrations of learning that are often written, visual, or presentational outputs, ideally, entirely created by the student (or with other students in group projects). Many faculty have thought, tested, and further connected the intellectual underpinnings of their teaching so that all things from syllabi to outputs fit as a strongly reinforced web. For many, generative AI takes a pair of scissors and cuts apart that web. And that can feel like having to start from scratch as a professional. Given that the pandemic itself also had that effect, we’re left with educators feeling overwhelmed, lost, maybe struggling, or maybe ignoring AI altogether–not because they don’t want to navigate it but because it all feels too much or cyclical enough that something else in another two years will upend everything again. How to begin to respond to this shock when we are in this state of overwhelm? Many folks are looking for leadership.

# Open educational practices (OEP) as shock absorber

The “shock” and “overwhelm” framing has dire connotations. Yet this challenge or even crisis in education offers an opportunity to demonstrate some of our best strengths, such as creativity and collaboration. For instance, the pandemic demonstrated educators’ robust ability to work together across collaborative tools such as Google Docs, Zoom, and social media. It amplified levels of digital collaborative literacy. At this moment, we need to merge that with open educational practices to more effectively and collectively move forward in the age of generative AI such as ChatGPT.

Open educational practices (OEP) grew out of the Open Educational Resources (OER) movement. Open education practices can broadly be understood to offer agile, collaborative approaches across institutions, systems, age categories (high school versus college), and nations. With open practices, educators can move forward through uncertainty with hope and mutual support. In a moment of overwhelm, we can turn toward each other and toward students and share imperfect, incomplete insights and experiments. With ongoing collaboration, these partial contributions can build toward better emergent responses to AI as we pool our resources, whether or not we have local support systems and like-minded individuals in our vicinity.

While best known for free textbooks and Creative Commons licenses, the OER movement offers much more. In particular, David Wiley (2014) developed a now canonical description of the rights of users of open educational resources, also known as the $" 5 ~ \mathsf { R } \mathsf { S } ^ { \prime \prime }$ of OER (Retain, Reuse, Revise, Remix, Redistribute):

Retain – the right to make, own, and control copies of the content   
Reuse – the right to use the content in a wide range of ways (e.g., in a class, in a study group, on a website, in a video)   
Revise – the right to adapt, adjust, modify, or alter the content itself (e.g., translate the content into another language)   
Remix – the right to combine the original or revised content with other open content to create something new (e.g., incorporate the content into a mashup)   
Redistribute – the right to share copies of the original content, your revisions, or your remixes with others (e.g., give a copy of the content to a friend) (Wiley, 2014)

Each of these “rights” is a description of a way of working with learning materials. Yet other scholars have gone further to call for an explicit focus on these practices rather than on the resources themselves and the rights granted by their licenses. As Catherine Cronin (2017, p. 2) has explained, “Open educational practices (OEP) is a broad descriptor of practices that include the creation, use, and reuse of open educational resources (OER) as well as open pedagogies and open sharing of teaching practices.” When we think of OER, we might tend to think of a textbook produced by an author, but the creation of new resources is only one aspect of an ecosystem that is more about process than product. Cheryl Ann Hodgkinson-Williams and Henry Trotter (2018) point out that open educational practices can include curation and distribution of resources, facilitated by crowdsourcing and open peer review.

Below, we describe some specific open educational practices that have helped us in responding to AI: engaging with broad communities, sharing rough work, crowd-sourcing curation, building on others’ experiments, collaborating with students (also known as open pedagogy), and planning for continuous revision and reflection. There are inevitably more practices than we can list, but we believe these provide a rich start to helping educators find their way through generative AI and other future shocks.

# Positionality

It may be worth noting that while the three of us authoring this paper together knew each other beforehand, we became closer in the process of navigating the impact of generative AI in education, and have been inspired by and sometimes contributed to each other’s open practices as we describe them in this article.

Anna has taught writing at City College of San Francisco and College of Marin for 17 years. These are non-selective, open-access public two-year colleges in the San Francisco Bay Area. I have written an Open Educational Resources textbook, How arguments work: A guide to writing and analyzing texts in college (Mills, 2020), that has been used at over 55 colleges; I have revised it in collaboration with colleagues and continue to try to improve it and add ancillary materials. In the last two years, I have become active in social media discussions of OER, writing pedagogy, and AI and created a resource area on AI for the Writing Across the Curriculum Clearinghouse (Mills, n.d., 2022).

Maha is a professor of practice (faculty developer) at the Center for Learning and Teaching at the American University in Cairo in Egypt. This is a private liberal arts institution in an emerging economy. I often test out my unfinished ideas on social media and on my blog and learn from dialogue with others in my Personal Learning Network before I bring these ideas back into my institution. For example, Anna and I gave a global Equity Unbound workshop about AI before I gave any of my local workshops on AI.

Lance has been teaching at different New England institutions for 17 years, while also working at the intersection of technology and education for institutions from community college to Ivy League for the past 12 years. Currently, I am the Director of Digital Pedagogy at College Unbound, a college of primarily adult students who are predominantly Women of Color. For much of my life, technology held promise and opportunity; but the more that I examined my whiteness, masculinity, middle-class status, and bisexuality, the more I recognized the challenges, critiques, and trappings that technology can create. These considerations have shaped my engagement with generative AI and inspired me to make sure that students, in particular, are part of the conversation.

# Turning toward community

Higher education has traditionally invested time and energy in departments, educational institutions, and disciplinary associations. However, open educational practices focus on forms of community that cross institutional boundaries, disciplinary silos, and national borders. When there is a “shock” we first look to existing patterns and platforms for interaction. Pre-pandemic some people had already built Personal Learning Networks (PLNs) as conceived by Connectivist discourse (Whitby, 2013). The pandemic, however, represented a time when educators rapidly gained new digital collaborative skills. Within the first six months of ChatGPT’s release, many of us further honed these skills and expanded our Personal Learning Networks (PLNs). Our loose ties with global peers become a “cushion” during the “shock.” Even if we don’t have the answers, we know there are others to converse with and learn with. Beyond institutional communities, our job status is less directly implicated, and we may feel freer to disclose our uncertainties in informal, often digital communities. Below we explore examples of the most flexible, broadly accessible, and agile formats for such discourse: social media, groups, and listservs, and, to a lesser degree, public annotation.

# Social media

As most academics are probably aware, Twitter, LinkedIn, Facebook, and Mastodon have all hosted and continue to host a high volume of discussions on language models and other forms of generative AI in higher education. These platforms often facilitate surprising collaborations. In one example, Juan David Gutierrez of the Universidad del Rosario in Colombia and Anna Mills’ Twitter interactions led to Gutierrez translating a piece by Lauren Goodlad and Anna Mills (2023), “Adapting college writing for the age of large language models such as ChatGPT: Some next steps for educators” into Spanish. Anna gave feedback on and helped with the English translation of Gutierrez’s (2023) policy on generative AI; she later featured that document in her presentations as a model for educating students about risk through policy.

TikTok and Instagram are less commonly used by educators but seem to offer more opportunities to interact with students. For example, Maha learned from Tiktok and Instagram student accounts the tips and tricks students used to fool AI detectors, which helped her while testing the efficacy of AI detectors and advising faculty. She found it an interesting way to “listen to students” who were not directly her own. Anna has observed this as well as she read the debates among students in the comments on student TikTok videos about supposedly plagiarism-free AI essay assistance.

Social media is also useful for learning and assistance with AI. Twitter has been the predominant platform for this, but the others also host a high volume of tips and newbie questions. Maha found some local accounts on Tiktok and Instagram, which explained to people in Egypt how to gain access to ChatGPT even though it was not enabled for Egypt. Lance found Instagram Reels (recycled TikToks) and Instagram posts sharing ChatGPT prompts and news.

# Listservs and groups

Both public and private listservs and groups have seen a great deal of discussion and resource sharing around generative AI in higher education. Inevitably, many discussions have taken place on department listservs and discipline listservs, but new cross-disciplinary groups have also arisen specifically focused on AI. These semi-private, moderated listservs have grown quickly and stayed active; they have helped to connect discussions across disciplines and institutions. One example is “Higher Ed discussions of AI writing Facebook group” (https://www.facebook.com/ groups/632930835501841/), started by Laura Dumin of the University of Central Oklahoma. It comprises 2,945 members as of May 17, 2023 and saw 157 posts in the preceding month. Dumin describes it thus:

This is a group for educators in Higher Ed to discuss ideas around using (or not using) AI writing programs in writing courses… We welcome discussions about AI use in the classroom, how to structure assignments to make the best use of writing and critical thinking skills, classroom and institutional policies surrounding AI use, and other topics in the same spirit as these. We hope people will feel comfortable asking questions and sharing articles/ assignments/policies related to how AI is impacting our teaching.

The $^ { \prime \prime } { \sf A l }$ in Education Google Group” (https://groups.google. com/g/ai-in-education?pl $= 1$ ) hosted by instructional designer Daniel Stanford grew out of the Professional and Organizational Development (POD) Network in Higher Education listserv and had 706 members as of May 30, 2023. It coordinates regular Zoom discussion sessions attended by more than 100 members. Examples of other groups include the regular attenders at Bryan Alexander's Future Trends Forum, which has hosted half a dozen live virtual gatherings on generative AI since December. Open Education Global’s discussion forum has hosted explorations of AI, often led by Alan Levine (https://connect.oeglobal.org/tag/ai). In addition, focused spaces like the subreddit on ChatGPT (https://www.reddit.com/r/ChatGPT/) have allowed dialogue about AI and learning between education professionals, students, and the general public.

# Public annotation

We see much sharing of documents: articles on AI in higher ed, sample policy statements, lesson plans, news coverage, and records of ChatGPT sessions. Social media and groups offer the chance to comment on each document, but public annotation of the documents offers another way to extend the discussion. For example, a popular New York Times article, “Alarmed by A.I. chatbots, universities start revamping how they teach” (Huang, 2023) saw 3,566 comments in January 2023.

When we want to annotate line by line as we might in Word or Google Docs, we can use the platform Hypothes.is, which allows users to add comments tied to specific highlighted text in any web page. Other users can then see a comment pane with all public responses to the text in the margin. Direct links to comments can also be reshared on social media and listservs. In collaboration with the Education Director of Hypothes.is, Jeremy Dean, Anna has promoted the idea of coordinating educators’ discussions through margin notes. She added an invitation at the top of her list of sources on AI in higher education: “Let’s share ideas on these readings! Comment in the margins of any online article with public Hypothesis annotations. Tag your comments and view others’ comments with the tags ChatGPTedu and AItextedu.“ Thus far, we see 125 comments tagged ChatGPTedu (https://hypothes.is/search?q $=$ tag%3AChatGPTedu), though there are likely many more not tagged. On Twitter, Anna invited public comment (https://twitter.com/EnglishOER/ status/1623113529103634432?s=20) on OpenAI’s “Educator considerations for ChatGPT” (n.d.) which led to a discussion in the margins among 8 users.

# Share early, share rough, be curious

The cross-institution, often cross-disciplinary social media and online group spaces described in the previous section allow us to make mistakes and progress and learn from each other before bringing ideas back to our institutions. As we explore concerns about academic integrity and excitement about pedagogical possibilities, we share questions, processes, and incomplete thoughts on social media, blogs, webinars, and lists. In these spaces, we can share and learn from imperfect, early responses, labeling them as such. This creates a greater sense of playfulness and experimentation to get through paralysis, lower the bar, and be willing to share materials that respond to recent updates in the technology.

The practice of sharing rough ideas isn’t just beneficial because it allows us to respond to AI as the tech updates rapidly. It is part of a deeper invitation to open practices that emphasize collaboration and trust. Maha has explored the concept of “self as $\mathsf { O E R } ^ { \prime \prime }$ or “open self” (Koseoglu & Bali, 2016), which embraces openness as a worldview and attitude. She suggests that we should value making one’s thought process open to others and being open to changing one’s perspective through dialogue. This openness is fruitful and encourages similar openness in others.

It is important, of course, to be mindful about the risks of putting out incomplete thoughts. We make ourselves vulnerable by doing this, and while many times the response is supportive, at times we do see harsh criticisms, an ungenerous tone, and trolling in response to these offerings. Setting community norms around supportive response, whether on social media, on listservs, or other platforms, is crucial to making the sharing of rough ideas sustainable. In the absence of such norms or any way to enforce them, community members sometimes come in to support one another.

# Anna shares a rough resource list

I, Anna, first began to explore large language models and their implications for writing assessment in June 2022. Faculty leaders like Lauren Goodlad, Marc Watkins, Mike Sharples, Sarah Elaine Eaton, Thomas Lancaster, John Warner, Maha Bali, and Leon Furze were already writing and presenting on the topic. However, at the time, I wasn’t finding many curated lists of articles. I knew that many of my colleagues were just approaching the topic, and direct access to the resources I had learned from might save them a bit of time.

I was used to doing curation work in the world of Open Educational Resources since I maintained a list of open textbooks and other Open Educational Resources for college writing and literature in my role as the English Discipline Lead for the Academic Senate for California Community Colleges OER Initiative. I was familiar with the challenges of finding and assessing open educational resources, and had led webinars introducing English instructors to the landscape of OER. AI had some commonalities with OER in that it could seem technical, intimidating, and overwhelming. When I didn’t find many online spaces that offered guidance on generative AI and teaching writing, I decided to take an attitude I had learned in the Open Education community: why not put something out there even if it was imperfect? If I offered a resource list under an open license, I and others could always revise or remix it later.

The Writing Across the Curriculum (WAC) Clearinghouse, housed at Colorado State University, seemed like a good fit because I knew they were committed to Open Access journals and books, had worked with OER platforms like LibreTexts, and had hosted collaborative projects like the First-Year Composition Archive of course materials. I reached out to Mike Palmquist, the director of the WAC Clearinghouse, and he and Lee Nickoson generously supported the plan.

The following disclaimer went right at the top of the list: “This is an open and evolving list put together by a writing teacher who is not an expert in the field, with suggestions from a few other more knowledgeable folks.” I have kept the disclaimer, and the rough nature of the list doesn’t seem to have reduced its usefulness. As of May 25, 2023, according to Lee Nickoson’s report on the Writing Across the Curriculum Clearinghouse website analytics, more than 10,000 distinct individuals have visited the AI and Teaching Writing resource area (32,845 total visitors and 15,076 unique IP addresses). The number who have visited the Google Doc list of sources is likely significantly higher, though we have not yet configured a tracking system. Many of the references to the list that we come across go directly to that Google Doc rather than to the WAC Clearinghousehosted page.

We have seen many grateful comments come in on the Google Doc, on Twitter and Mastodon and by email. In one example, Carol Bailey tweeted in February, “[T]here's so much being written now, it's hard to stay on top of it all! Thanks for all the care you put curating this resource - it's always my #1 recommendation” (2023).

# Lance Eaton shares College Unbound’s generative AI policy plan

Lance’s story

My discussions with my friend and colleague Autumn Caines soon after the release of ChatGPT helped me envision a process for College Unbound to respond. At College Unbound, we recognized that it was going to be a shifting landscape. We crafted a temporary policy that had some flexibility in it – by and large, deferring to faculty whose individual context might require a different policy. However, we made sure there was at least something the faculty could look at for guidance.

While I know there were lots of hot takes on generative AI and education by the end of January, I still thought it necessary to share my own exploration on my blog and capture in a public space some of the working and thinking that was going on at College Unbound (Eaton, 2023b). My sense was that resources were not the only way to help; colleagues might want to hear how others were trying to make sense of the shifting terrain.

# Anna’s response

I, Anna, had been grateful to many colleges for sharing AI policies I included in my resource list. It stood out to me, though, when Lance not only shared his policy on January 9, 2023, but made clear that it was a temporary one. The idea of a provisional policy resonated with me as valuable recognition of the ongoing process we wouemotld need. Lance shared his institution’s staged plan for offering faculty development, writing a new policy with students, and reassessing. He even shared the letters sent to students and faculty about the temporary policy. The letters admitted, “This policy is not comprehensive – it really can’t be at this time.”

When Lance shared his plan on Twitter, Risang Baskara commented, “Dear Lance, I would like to ask your permission to use this document as one of the readings in our next department FGD discussing ChatGPT…We may want to replicate some steps as they are very clear.” Carol Bailey commented, “It’s REALLY impressive. I so hope I can get my university to do something similar. Many thanks for sharing!”

# Maha Bali shares ideas for teaching with and about AI

I, Anna, have felt energized and inspired by the way Maha shares so many ideas so quickly in a spirit of generosity. She trusts that other educators share her passion and will join her in inquiry. I have come to understand that this practice is one of the intentionally cultivated strengths that helps her connect with so many people as an international faculty development leader. She shares and makes mistakes on Twitter and on her blog, gets feedback, and then comes back to her institution ready to give more leadership based on what she’s learned.

Since January, she has been publicly exploring ways educators can respond to generative AI. For example, on January 5, 2023, she shared a post titled “What if we create a culture of ‘transparent assessment’ (AI & AI)” (Bali, 2023a), Here, she wrote, “I woke up this morning with this thought, related to Academic Integrity (AI) and Artificial Intelligence (the other AI). What if we took a ‘disclosure of learning process’ approach rather than [a] prevent and punish approach? Ask students to show how tech (and people!) helped them along the way. This would enhance their metacognition and give us insights on how they learn these with or without AI.” She embedded the Twitter post where she had raised this idea and received 18 replies. On January 15, she shared a series of questions on Twitter and on her blog: $^ { \prime \prime } { \sf S } 0$ what are the characteristics of an assignment that AI cannot fully succeed in writing? Is that the right question? Or is the question we should be asking: How do I design an assessment that makes my students want to truly learn? That motivates inquiry and expression?” (Bali, 2023e). What stood out to me here was that she shared her uncertainty about how to focus her own thinking. I was feeling similar uncertainty, and felt welcomed by her tweet, empowered to be honest. Surely others felt similarly relieved to hear both the concerns and approaches and the informal tone coming from a known leader. The tweet was viewed by over 50,000 people, and a rich discussion with over 50 replies followed.

Maha has continued to share her process of inquiry around AI throughout the spring. She described the “crush” she had when she first began to experiment with ChatGPT and the evolution of this crush into something more grounded (“How not to be overly impressed with ChatGPT”: Bali. 2023c). She explored how to ethically cite ChatGPT (Bali, 2023b) and updated her post with ideas gleaned from Twitter responses. She also suggested that we invite students to read speculative fiction stories about the future of AI in education (Bozkurt et al., 2023) from a special issue of the Asian Journal for Distance Education. Then, she suggested, we could ask students to comment on one or more of the possible futures or write their own brief speculative fiction piece. Maha’s own short story in the journal imagined how an AI-generated “teacher” bot might offer a student choices about the teaching style the student preferred while responding to the student’s emotional needs and nudging the student to seek out peers and teachers for other kinds of care and teaching.

# Curate resources with crowdsourcing

Though we need a lot of public discussion on generative AI in education, as the reflections proliferate, they can also contribute to a sense of overwhelm and paralysis. At the Future of Writing Symposium at the University of Southern California, Jeremy Douglass described what he experiences as a “firehose” of takes on AI and writing in higher education. We may share resources and initiate discussions on social media and listservs, but these platforms do not serve to organize the information or compare like resources over time. Asking the “hivemind” for just-in-time pointers can work, but it has its limits. Social media and listserv interactions are too haphazard and shifting to serve as anchors.

Most of us, then, have to rely on curation. Here, we propose incorporating crowdsourcing into curation as an open educational practice that helps make curation more efficient, sustainable, and collaborative.

Crowdsourced curation can take place on platforms designed for the purpose. The Zotero ChatGPT group has 166 members and 315 items (https://www.zotero.org/ groups/4888338/chatgpt). OER Commons (https://www. oercommons.org/) and Merlot (https://www.merlot.org/ merlot/) allow users to tag, rate, review, and bookmark open educational resources (OER). Users can create and share their own lists of these resources. However, Anna and Lance’s crowdsourced curation projects have not required curation platforms but have instead simply used Google Docs and Google Forms.

# Lance Eaton’s syllabus and policy collection

Often, people need language or examples to think with or against to build it into their work. I realized crowdsourcing syllabus policies around generative AI could help me and others. It was something I could do in a moment of uncertainty. I went to my different social media platforms (Facebook, Twitter, Mastodon, LinkedIn, Reddit) and shared a call for folks to submit their policies. The crowdsourced syllabi policies document has continued to grow over the Spring 2023 semester with over 30 contributions (https:// docs.google.com/document/d/1RMVwzjc1o0Mi8Blw_- JUTcXv02b2WRH86vw7mi16W3U/edit). Tatiana Torres Zapata also translated the syllabi policies into Spanish for larger linguistic impact (https://www.canva.com/ design/DAFfvwSGoO0/g7CZUnl4IFfeglf2YzfIOA/edit?utm_ content $=$ DAFfvwSGoO0).

Knowing that people would have different comfort levels with Google Docs (where I put the policies), I made the decision to make the Google Doc view-only and had folks submit their policies via a Google Form. This extra step did create friction, and that inevitably meant fewer policies. Yet, it was important to keep the layout clear and consistent for others. It also saved me time of regularly perusing the document to see or update changes.

Maha’s comment: The diversity of policies shared on Lance’s curation became an inspiration for my colleagues locally. As a faculty developer, I could showcase all these different approaches in different courses around the world for others to adopt or adapt.

# Anna’s resource list updates, assisted by crowdsourcing

As I, Anna, developed the Writing Across the Curriculum resource list with Lee Nickoson’s editorial suggestions, I also reached out on Twitter to share my work-in-progress and solicit recommended sources. At the top of the list, I added a general invitation: “Please use the Google Docs commenting feature to suggest additional sources!” I committed to recognizing all those who contributed by name in a footnote.

While we initially planned to publish the list directly on the Writing Across the Curriculum Clearinghouse site in parallel with other resource areas hosted there, it gradually became clear that the provisional, easily updatable nature of the Google Doc list was more suited to the continuing uncertainty and rapid change around the topic. The familiarity of the Google Docs platform commenting and suggesting mechanisms encouraged more participation than other platforms likely would have (a phenomenon consistent with the insights of entangled pedagogy, as we discuss further on). As a commercial, general-purpose platform already heavily used for commenting, it presents a minimal cognitive load barrier to most users.

Crowdsourcing proved an invaluable way to keep the list updated and expand it beyond my own capacities. The resource list document shows 103 substantive suggestions as of May 2, 2023. (There were actually a total of 689 comments or suggestions, but many of those were blank or typos as people didn’t realize that they had suggesting privileges.) In addition, I received a dozen or so emails with suggestions for additions to the list.

# Crowdsourcing assignment prompts to run through ChatGPT

Crowdsourcing can also be used in conjunction with other community events like online workshops. Anna and Maha ran a free hands-on workshop via the organization Equity Unbound on Zoom. In the process of preparing for it, we created an editable Google document where anyone could contribute their assignment prompts for us to run through ChatGPT (in case people did not have access to ChatGPT) and other AI platforms. This document eventually became a reference for understanding how AI responded to a variety of assignment prompts. It was especially useful at a time when the ChatGPT server was sometimes down, and someone trying to run a demo would not have been able to run it live.

# $" 1 0 0 +$ creative ways to use AI in education”

Creativity for Learning in Higher Education or #creativeHE is “an open collaborative community for creative and innovative practitioners and students,” headed by Dr. Chrissi Nerantzi of the University of Leeds (Nerantzi et al.

(Eds)., 2023). In spring 2023, along with Antonio Arboleda, Mariana Karatsior of the University of Macedonia, and Sandra Abegglen of the University of Calgary, she launched a project called $^ { \prime \prime } 1 0 0 +$ Creative Ways to Use AI in Education” (https://creativehecommunity.wordpress.com/2023/02/02/ creating-a-collection-of-creative-ideas-to-use-ai-ineducation/). The invitation laid out the philosophy that “Experimentation is at the heart of education… Ideas shared may be in embryonic stage, half-baked but worth exploring further through active and creative inquiry.” The organizers set a deadline of March 31 and offered a template for a single Google slide that any professional in higher education could fill out.

Maha supported the project, inviting the organizers to an Equity Unbound workshop on AI that she and Anna were hosting. She developed three slides of her own describing creative approaches to teaching about AI. She used an AI drawing app, Quickdraw, to introduce students to basic concepts around AI, including bias, in an interactive way. When Time Magazine exposed OpenAI’s reliance on the exploitation of Kenyan workers to make ChatGPT safer (Perrigo, 2023), Maha created a wolf-in-sheep’s-clothing meme to stimulate discussion with students. She also shared a playful activity where she asked students to discuss which metaphors best applied to AI and offered several of her own, from fast food to store-bought cake.

Anna: Inspired by meeting the #creativeHE organizers at the workshop I did with Maha, I created a learning management system module on Critical AI Literacy and Critical Assessment, building on assignments I had tried with students in Fall 2022 (https://ccconlineed.instructure.com/courses/7707/ modules#module_60328). I chose a handful of videos and articles to introduce students to language model capabilities and risks. A sequence of assignments featuring collaborative annotation allowed students to build understanding and use it to reflect on the shortcomings of ChatGPT output on an assignment that met learning goals for our class. My learning management system, Canvas, offered a sharing space called Canvas Commons. When I searched on “ChatGPT” and AI on Canvas Commons, though, I found very little. That gave me confidence that I would be contributing even if mine wasn’t polished (I would have liked to add full lesson plans, images, examples, and much more). I shared the assignment on Twitter, and the learning management system module was downloaded or imported 85 times from Canvas Commons.

# Build on what others have done

Openly-licensed policies, slides, handouts, and assignments make it possible for individual teachers, departments, and institutions to customize their own versions. We can directly revise what others have done if it is open-licensed. Finding Creative-Commons-licensed materials means we have something to build on quickly whether or not our institution offers this kind of guidance. Another advantage is that anyone, not just the original authors, can update materials as the technology evolves.

Here are a few examples of ways building on open-licensed materials has proved useful in Spring 2023. We hope that future studies can look more rigorously at how frequently open-licensed policies and instructional materials on AI are adapted or reused.

Lance has gotten numerous requests to use or adapt the College Unbound policy (made easier by the fact that the policy has a Creative Commons license).   
Anna has been sharing open-licensed presentation slides on Twitter and has heard back that they have been repurposed at other colleges (Mills, $2 0 2 3 \mathsf C ;$ Dreeme, 2023). One note from John Roberton $@$ KavuBob (2023) read $" \ @parrow$ EnglishOER a quick note of thanks! we had a chatgpt workshop planned and I shared your openly licensed slides with copresenters. It’s possible that you got more than a few citations as adapted versions of your slides showed up in our combined slidedeck!”   
Abram Anders, a professor of English at Iowa State University, incorporated slides from one of Anna’s open-licensed presentations in his own open-licensed presentation, “How to Use ChatGPT to Boost Your Research and Teaching.” Anna then incorporated ideas from and referenced his slides in a later presentation. Anna’s colleague Dayamudra Dennehy (2023), Distance Education Coordinator at City College of San Francisco, drew on Anna’s resource list and slides to make her own presentations and tailored list for City College of San Francisco. Then Anna and Dayamudra had informal conversations about AI and then recorded and shared a conversation, “Writing as a process: reflecting on ChatGPT as educators” (Dennehy & Mills, 2023).

# Collaborate with students

As we noted earlier, open educational practices include collaboration with students in the creation of learning materials, often referred to as “open pedagogy.” Robin DeRosa and Rajiv Jhangiani (2017, para. 14) describe open pedagogy as “an access-oriented commitment to learnerdriven education and a process of designing architectures and using tools for learning that enable students to shape the public knowledge commons of which they are a part”. Collaborating with students on AI-related materials enables emergent, student-centered, and student-guided approaches. This is especially appropriate to the current juncture since instructors and students are learning together as the technology and social norms around it evolve rapidly.

# Lance Eaton’s collaboration with students at College Unbound

Lance: Over the years, I have been seeking clarity about students, agency, and ways to create learning spaces as less hierarchical. This is something my institution, College

Unbound, centers in much of our work. The more that I recognize that I am in community with students and that we can learn together, the more possibilities to connect, collaborate, and learn with students reveal themselves. Open pedagogy has shaped my work for about eight years now, so in any course, I look for opportunities for students’ works to live beyond the course. With my Provost’s permission and enthusiasm, I launched a one-credit course called AI & Education in Spring 2023, where the students and I learned about generative AI and proposed a set of usage policies for students and faculty.

My goal is not just to collaborate but to center students and their thoughts. So much of the conversation I have seen since the rise of ChatGPT and other generative AI has been exclusively faculty and administration. A lot of rich individual conversations occur in classrooms, and that is equally important, but the public discourse around generative AI in higher education is almost entirely devoid of student voice (Sullivan et al., 2023). I knew the College Unbound students could help to address that. Centering student voices was also important to me because I and my institution are actively working to develop antiracist and justice-oriented practices. We have a student body that is over two-thirds BIPOC women, and we strive to recognize, support, and respond meaningfully to our students.

In the AI & Education course, students read about and played with generative AI to better understand its benefits, limitations, and ethical underpinnings. Weekly, students asked and recorded eight to ten questions and answers from ChatGPT in addition to learning more about generative AI and educational considerations. This provided the background for us to develop our usage policy. In the latter half of the class, each student proposed their own guidelines, and then we determined together which pieces of each other’s guidelines we wanted to incorporate into the collective document. Initially, students were only allowed to suggest pieces of others’ guidelines and to endorse others’ suggestions. We reviewed the resulting collective policy to iron out inconsistencies, add more details, and clean up the language across the policy. At this point, students could return to their own policies to add anything that was missing or not sufficiently addressed.

This process created space for all to explore, discuss, and reflect on their own before jumping into creating policy. Students have different levels of experience with the technology, creating institutional policy, and navigating their own feelings about using generative AI. Moving from the personal to the collective allowed for folks to feel grounded and also to support and endorse one another’s work. They were able to learn and lean on others’ insights and polish a final output that reflected collective efforts (Eaton (Ed.), 2023).

The policy document became a platform for further highlighting of student voices in various forums. Early on, I knew that I would be both presenting and writing about this. Given my work in higher education and instructional design, it’s not the first time that I have been engaging with a topic (OER, hybrid flexible learning, digital service learning) before it had really taken off across higher education. I knew

I would inevitably find myself writing and talking about it. However, given that I had been collaborating with students, I wanted to make sure they, too, were included in some of the writing and conversations.

By February 2023, several students were interested in continuing the conversation outside the classroom, and so I brought them to be on a one-hour panel at the NERCOMP annual conference in Providence, Rhode Island, in late March. Their insights and thoughtful contributions to the discussion led this room of $^ { 2 5 + }$ leaders in higher education to realize the importance of having students as part of the process (at the end, the first words out of participants’ mouths were, “Now, I know what I need to do when I get back to campus; get students in the conversation.”). The students also did a NERCOMP webinar panel for a room of 70 leaders in higher education. In future months, they will be interviewed on podcasts and also keynotes at three academic gatherings (including EDUCAUSE 2023). They are engaged in writing with me to further share our thoughts and findings.

# Other examples of collaboration with students

We’ve seen a range of examples of student involvement which we won’t describe in detail.

Maha’s institution, the American University at Cairo, surveyed students in the process of developing AI guidelines. One thing they learned through the survey was that for certain uses of AI students did not feel the need to disclose to faculty because these uses did not impact the actual text produced and submitted. Maha has also had deeper collaborations with particular students interested in writing and reflecting on AI, like Yasser Atef, who is an active Twitter user and was doing work study as an accessibility intern at her department. Yasser helped test the accessibility of various AI platforms for students with visual impairment.

A Boston University class led by Wesley Wildman developed a policy later adopted by the data science department (Bray, 2023).

Lauren Goodlad, director of the Critical AI Institute at Rutgers University, uses the Critical AI blog to publish select “Student Insights” developed in her classes. One example is “The search for creativity: Does Artificial Intelligence like Gpt-3 have what it takes to tell its own stories?” (Tai, 2023).

A student panel at the University of Leeds on AI in education, coordinated by Stephen Taylor (2023).

A student panel at the UC San Diego Academic Integrity Office “Threats & Opportunities” Virtual Symposium (https://www.youtube.com/ watch?v $=$ y0P1KyM0ubE).

A student panel at Colgate College (https:// thecolgatemaroonnews.com/43246/news/ student-panel-discusses-implications-ofartificial-intelligence-at-colgate/)

# Plan to keep revising

We need to be ready to make quick updates as the technology and our understanding of its implications evolve. We can plan for policies and pedagogical frameworks around AI to be provisional and to keep changing. This allows us to focus on process, collaboration and reflection in the moment rather than getting it right for all time.

# Emergent policy in response to paradigm shifts at College Unbound

Lance: In College Unbound’s approach, we recognized that it was going to be a shifting landscape. We crafted a temporary policy that had some flexibility, by and large, deferring to faculty whose individual context might require a different policy depending upon their courses and their students. However, we made sure there was at least something faculty could look to. Going forward, we see the student-developed policy as an opportunity for ongoing development, not as a static endpoint. Yes, these students will develop and test out recommended usage policies for us going forward. And yes, AI itself and our attitudes toward AI will continue to change. Therefore, we see this as a step in ongoing policy guidance. We also realized the potential of this process of emergent response to help us approach other new technologies yet to come, as well as other sudden or dramatic shifts (e.g. the pandemic). Besides allowing for agility in the institutional response, such a practice of ongoing revision in collaboration with students centers the students and gives their work meaning through real-life application.

# An evolving resource list

Anna: The Writing Across the Curriculum Clearinghouse resource list is a dynamic document shaped not just by Google Doc comments but by suggestions and feedback on Twitter and through email. I continue to modify the category structure of the resource list as I add to it; for example, I added a section on using AI for help preparing teaching materials and one on assignments involving AI, as well as a section for materials in Spanish. To keep the list manageable, I moved pre-ChatGPT materials to an “additional” list (Mills, n.d.).

Crowdsourcing comments have brought not just new sources, but pushback that has helped me revise and improve the list. For example, Mike Sharples, an early explorer of the terrain who published Story machines: How computers have become creative writers (Sharples & Perez, 2022), posted on Twitter to correct my placement of his book in the section labeled “Books on AI in General.” I invited him to curate the section on creative writing and was delighted when he accepted.

Lauren Goodlad’s concern about AI hype in some New York Times articles led me to add an additional disclaimer: “Please note that inclusion in this list does not indicate endorsement. Some of these resources include various forms of AI hype or claims that have not been verified. They are provided to give a general sense of the landscape of discourse around the topic.” I also separated out some of the most egregious instances of misleading articles into their own section toward the end, titled “Prominent Pieces That May Include Hype Or Inaccuracy.”

I initially resisted a request for a section on using ChatGPT with students, though others echoed the request and offered sources in the comments. I wasn’t sure I wanted to encourage teachers to rush to incorporate the new product into their teaching. Later, as I saw how many teachers were beginning to write about pedagogical applications, I did create such a section.

# Refocus on values as we assess our process and pedagogy

We have described a continuous process of experimentation, collaboration, building on each other’s work, and revising our responses to AI. But on what basis will we revise? As we noted at the beginning, a process of “Intentional Adaptation” described by adrienne maree brown (2017), is a chance to reflect on core values and goals. What criteria can we use to evaluate both our practices as we explore the questions raised by AI and also the pedagogical value of any approaches we come up with? We find two frameworks for thinking about technology integration in education helpful here: PICRAT and entangled pedagogy.

# PICRAT

The PICRAT model is a “technology integration model” that emphasizes student agency, engagement, and creativity as well as teacher reflection. PICRAT supports teachers in seeing the impact of integrating a particular technology on two dimensions: how it transforms their own practices, and how it impacts student learning. The “PIC” refers to students’ relationship to technology, with the PIC standing for Passive, Interactive, and Creative. The “RAT” refers to how the technology is impacting the teachers’ pedagogy, and RAT stands for Replacement, Amplification, and Transformation (Kimmons et al., 2020, 2022). This framework can be useful to discuss both the integration of AI into education and the use of open educational practices (OEP) in the ways we respond to the appearance of AI in our lives. Since this paper is focused on OEP, we’ll give examples of that.

In terms of open education, from the student/learner side: a passive use of open education in the AI movement is to assign students an open textbook about AI to read; a more interactive approach is to have students interact on social media with other students around the world to discuss their attitudes towards AI, or to collaboratively annotate articles about AI; a more creative approach would be to have students co-create the guidelines/policies for AI use in their institution or class, or to have students test AI for bias and publish the results. Inasmuch as open educational practices include collaboration with students, often termed open pedagogy, these practices would generally be creative on the PIC scale as they lead students to participate in creating learning materials.

The PICRAT model does not stop at separating out the PIC from the RAT, but encourages teachers to reflect on the combination of PIC and RAT. For example, if a teacher “replaces” a commercial textbook with an open textbook on AI, for students, it is a passive experience. If a teacher encourages students to develop their own AI guidelines, they’ve most likely transformed their own practices while having students do this creative work, because learners are likely to come up with guidelines very different from what they would have come up with on their own; if a teacher creates their own guidelines from a crowdsourced Google doc of other guidelines, the crowdsourcing process itself would have been a kind of amplification (because the teacher sees more guidelines than they would have seen without open education) or even transformative to the teacher (if the teacher synthesizes something new from seeing so many guidelines), but the student experience will be passive (they receive guidelines that were “found” using open education, but they have no input into them).

# Entangled pedagogy

While the PICRAT model is extremely helpful for teacher reflection, and it does recognize the teacher and learner dimensions at multiple levels, it still tends to implicitly suggest that there is a relatively neat relationship between technology and pedagogy. Either the technology influences the pedagogy or the pedagogy leads the technology. Inspired in part, perhaps, by Marshall McLuhan’s famous call to focus on the medium, not the message, Tim Fawns’ (2022) concept of “entangled pedagogy” acknowledges the interdependence of technology and pedagogy. Fawns (2022, p. 711) describes a “mutual shaping of technology, teaching methods, purposes, values and context.”

Fawns (2022) proposes an aspirational view of entangled pedagogy where educators, learners, and any other stakeholders can respond to complexity and uncertainty constructively by building on values and ethics in collective, responsive, contextualized ways. In the case of open educational practices and AI, our interactions as educators, educational developers, students, and administrators with particular social media platforms and the tools we use to crowdsource, dialogue, and co-create all influence our discussions and decisions and how they enact our values. For example, when we crowdsource via open Google Docs or Slides, we open ourselves up to messiness or trolling, but the openness may facilitate more sharing. When we use platforms like Twitter to interact, each sharer’s individual network of contacts, the possibilities of private messaging, the length of a Tweet, all influence the kind of conversations that occur. Sharing on a platform like Instagram or Tiktok may result in responses from more young people (like undergraduate students), whereas sharing on LinkedIn or Twitter may garner more professional attention. The ease with which our students can access AI, their digital literacies, and our own, all influence the emotional relationship we have with the technology. The availability of support in our open networks or lack thereof, our intersectional identities, and the ways these identities play out locally and globally, all will influence how much we share or choose not to share. The takeaway here is that we should continue to carefully watch the interactions between the media we use and the conclusions we draw in our open educational practices around AI.

# How do we support and promote these open educational practices around AI?

We need to invest in open educational practices to prepare for shocks and ongoing changes in higher education. Though many of the practices we have described can be carried out without dedicated funding, they certainly involve labor. Some are thankfully easy and quick and can still have a significant impact. A person reading the WAC Clearinghouse resource list can suggest an additional article in a minute or two. Making a Google Doc lesson plan public and tweeting out a link to it takes a few more minutes. Of course, those individual actions won’t happen in isolation; they come out of the faculty member’s engagement with broader communities (disciplinary, professional, and academic). They more or less presuppose that the faculty member is spending significant time keeping up with developments in AI and education. If open educational practices around AI are just one more “should” added on to the others, how many faculty will feel they have the additional capacity? Here we offer a few suggestions.

# Value the open educational practices we already engage in

Many powerful open educational practices are things we already do, on platforms we already use. We can reduce the sense of overwhelm by focusing first on these practices rather than on adding new burdens. A first step that involves no labor or cost is to simply recognize the importance of sharing on listservs and social media to higher education’s response to shocks like AI. The pandemic has helped us all learn to collaborate digitally, and we should celebrate the ways people are already present online and ready to engage. For example, Maha’s department curated what faculty at her institution locally were doing about AI in a newsletter and shared the open-access newsletter (normally only shared locally) on social media and listservs. This was a small step that made a big difference to others.

Valuing open practices can take place on an individual level as we shift our thinking about how much we are contributing, but it will have even more impact if we see a cultural shift in academia toward valuing these practices as elements of scholarship and teaching. Not only prestige, but recognition in terms of hiring, tenure, and promotion decisions could reflect the value of these practices to our work as educators responding to the exigencies of our time.

# Frame open educational practices as mutual assistance

Another way to decrease the sense of overwhelm around open educational practices is to think of them as ways we help ourselves and others at once. We turn to these practices for support, and when we offer support to others, we get much-needed feedback and validation. Sharing our ideas, experiments, and expertise broadly beyond our institutions can energize us to keep reflecting and evolving our practice. Reciprocity in openness need not require equality of offers in real time – we give when we are able, we seek support when we need it (brown, 2017), and we trust that within our networks, it eventually balances out to an extent.

# Compensate the labor involved

Of course, the work of open educational practices needs to be celebrated and supported in material ways as well. In part, shifting hiring and promotion criteria could help faculty to prioritize these practices over other time-consuming forms of scholarship. But we also see a need for dedicated funding to encourage OEP. Historically some funding efforts for open educational resources have been centered around saving students money on textbooks. That won’t work so well in relation to AI because we’re generally not substituting for textbooks students would otherwise purchase. However, we might still build on alternate funding structures developed in the open educational resources movement. These have included funding to support professional development, resource curation funding, funding to pay peer reviewers, and funding for open educational resources “liaisons” on individual campuses.

We should note that compensation for the labor of open educational practices related to AI should be seen in the context of concerns about compensation for labor and pressure on faculty in higher education overall. Many practices that address academic integrity concerns around AI focus on student engagement and demand more time. Rudolph et al. (2023, p. 15) recommend in order to prevent AI misuse, higher education institutions “avoid the creation of an environment where faculty is too overworked to engage and motivate their students.”

# Conclusion: Toward social justice through an open response to AI

One of the main features of all the practices we have described is that they are cross-institution, cross-disciplinary, and open to participation and leadership from all levels of academic hierarchies, including students and non-tenuretrack faculty. They cross countries and cultures as well. As such, they have the potential to work against inequities in power and resources.

These open practices help extend the resources of richer institutions to under-resourced institutions. Many schools have no centers for teaching and learning and very little support for professional development. In others, there is just one person responsible for supporting faculty in these ways. All education developers lean on open resources for community, enrichment, and emotional support. While we strongly encourage this kind of sharing, we caution that this may reproduce privilege in what ends up getting shared and amplified: the viewpoints of Western/economically privileged institutions over other parts of the world that are less economically strong; certain cultures such as U.S.- based education systems over others, etc. For example, we might easily fall into the trap of supposing that educators from under-resourced institutions or developing economies should follow the lead of faculty who have more institutional support. At the same time, open practices do allow faculty from under-resourced and less highly regarded institutions to amplify their voices and take on leadership in response to AI.

Open educational practices do not support social justice by default. Aspirations toward participatory, anti-hierarchical inquiry may not turn out utopian in practice. We also caution that many of the technologies used in open sharing themselves may make users vulnerable, violate individuals’ privacy, and carry and reproduce neocolonialist assumptions. The act of sharing itself can pose risks or cause harm to those living under authoritarian regimes. And “parity of participation” (Fraser, 2008) may not occur if the designers of spaces come with their own epistemologies that leave little room for someone from a different culture or background to modify them. We are all embedded in hierarchical relations whether we are aware of it or not, and we will have to struggle not to perpetuate those hierarchies. As Sara Ahmed (2014) has observed, “It takes conscious willed and willful effort not to reproduce an inheritance.”

Still, we aspire towards open educational practices that share values in common with critical pedagogy, pedagogies of liberation, and anti-racist pedagogy. We call for an ongoing examination of the positionality of participants and the power dynamics involved in order to foreground equity as we respond to AI in higher education.

We, Maha, Lance, and Anna, look forward to rich exchanges and mutual support as we continue to explore AI in education through these practices. We hope that others will find that the open educational practices framework gives them hope as they contemplate the uncertainty around AI in the short and long term. Perhaps there are practices we have mentioned that you would like to try? Or perhaps you are willing to share a comment or a response to our article. We hope you will, whether through social media, email, public annotation via Hypothes.is, or another means.

# References

Ahmed, S. White Men. (2014, November 4). feministkilljoys. https://feministkilljoys.com/2014/11/04/white-men/

AI in Education. Google Groups. https://groups.google. com/g/ai-in-education

Alexander, B. (n.d.). Future trends forum. [YouTube]. https://www.youtube.com/ playlist?list $\bf \Pi =$ PLlcx8yl6hlPC3QjlbIHzxGqCP3qRa0zcg

Anders, A (2023). How to use ChatGPT to boost your research and teaching. https://docs.google.com/presentation/ d/e/2PACX-1vTaK8QwTtFFGZYoOenLVJScc0_1nrM U E W 7 m u X b s 4 F m 5 l C 7 G o V b 9 R u 3 G - Z c j Z u X Z g Z a 9 E 6 C 1 b V 3 W Y g L / pub?start $=$ false&loop $=$ false&delayms=3000&slide $=$ id. g1506fece23e_1_119

Academic Senate for California Community Colleges Open Educational Resources Initiative. (n.d.). About us. ASCCC OERI. https://asccc-oeri.org/about-us

Bailey, C. [@beilinglaoshi]. (2023, February 14). Good idea - there’s so much being written now, it’s hard to stay on top of it all! Thanks for all the care you put into curating this resource - it’s always my #1 recommendation [Tweet]. Twitter. https://twitter.com/beilinglaoshi/ status/1625557701903192085? $\scriptstyle = 2 0$

Bali, M. (2023a, January 5). What if we create a culture of “transparent assessment” (AI & AI). Reflecting allowed: Maha Bali’s blog about education. https://blog.mahabali.me/ educational-technology-2/what-if-we-create-a-culture-oftransparent-assessment-ai-ai/

Bali, M. (2023b, January 26). On citing our hybrid brain/ writing #chatGPT #openAI. Reflecting allowed: Maha Bali’s blog about education. https://blog.mahabali.me/ educational-technology-2/on-citing-our-hybrid-brainwriting-chatgpt-openai/

Bali, M. (2023c, January 27). How \*not\* to be overly impressed with #ChatGPT. Reflecting allowed: Maha Bali’s blog about education. https://blog.mahabali.me/educationaltechnology-2/how-not-to-be-overly-impressed-withchatgpt/

Bali, M. (2023d, March 13). Have I got an AI assignment for you! Speculative AI futures – inspiration & creation. Reflecting allowed: Maha Bali’s blog about education. https://blog. mahabali.me/educational-technology-2/have-i-got-anai-assignment-for-you-speculative-ai-futures-inspirationcreation/

Bali, M. [@Bali_Maha]. (2023e, January 15). So what are the characteristics of an assignment that AI cannot fully succeed in writing? Is that the right question? Or is the question we should be asking: How do I design an assessment that makes my students want to truly learn? That motivates inquiry and expression? [Tweet]. Twitter. https://twitter.com/Bali_Maha/ status/1614711365146386432

Bali, M., Cronin, C., & Jhangiani, R. S. (2020). Framing open educational practices from a social justice perspective. Journal of Interactive Media in Education, 2020(1), 1-12. DOI: https://doi.org/10.5334/jime.565

Bali, M. & Koseoglu, S. (2016, August 26). Self as OER. The Chronicle of Higher Education. http://www.chronicle.com/ blogs/profhacker/self-as-oer-selfoer/62679

Bali, M. & Mills, A. (2023, January 25). How well can AI respond to my assignment prompts? https://docs.google.

com/document/d/1ZbrdqB2xqoOVOdo2OAbk9Osz4_ xyG7Xhp2RpeJyWG0g/edit?usp $=$ sharing

Bali, M. & Moustafa, H. (Eds.). (2023). How AUC faculty are addressing AI in their teaching spring 2023. CLT New Chalk Talk. https://learnhub.aucegypt.edu/cltnewsletter/ $? { \mathsf { p } } = 1 0 8 3$

Baskara, R. [@risangbaskara] (2023, February 2). Dear Lance, I would like to ask your permission to use this document as one of the readings in our next department FGD discussing ChatGPT. [Tweet]. Twitter. https://twitter.com/risangbaskara/ status/1621361155989188610?s=20

Bozkurt, A., Xiao, J., Lambert, S., Pazurek, A., Crompton, H., Koseoglu, S., Farrow, R.,… & Jandrić, P. (2023). Speculative futures on ChatGPT and Generative Artificial Intelligence (AI): A collective reflection from the educational landscape. Asian Journal of Distance Education, 18(1). http://www. asianjde.com/ojs/index.php/AsianJDE/article/view/709

Bray, H. (2023, April 4). BU creates standards for chatbots in the classroom. The Boston Globe. https://www.bostonglobe. com/2023/04/04/business/bu-creates-standards-chatbotscomputer-science-classes/?p1 $=$ Article_Inline_Text_Link

brown, a. (2017). Emergent strategy: Shaping change, changing worlds. AK Press.

Caines, A. (2023). Prior to (or instead of) using ChatGPT with your students. Is a Liminal Space. https://autumm.edtech. fm/2023/01/18/prior-to-or-instead-of-using-chatgpt-withyour-students/

ChatGPT (n.d.). Reddit. https://www.reddit.com/r/ChatGPT/

ChatGPTedu. (n.d.). Hypothes.is. https://hypothes.is/ search?q $=$ tag%3AChatGPTedu

Cronin, C. (2017). Openness and praxis: Exploring the use of open educational practices in higher education. The International Review of Research in Open and Distributed Learning, 18(5), 1-21. DOI: https://doi.org/10.19173/irrodl. v18i5.3096

Cronin, C. & MacLaren, I. (2018). Conceptualising OEP: A review of theoretical and empirical literature in open educational practices. Open Praxis, 10(2), 127-143. DOI: https://doi.org/10.5944/openpraxis.10.2.825

D’Agostino, S. (2022, November 3). #AcademicTwitter will endure—for now. Inside Higher Ed. https://www. insidehighered.com/news/2022/11/04/professors-andacademics-will-stay-twitter%E2%80%94-now

Dean, J. (2023, February 16). Five ways to use social annotation with and against ChatGPT. Hypothes.is. https:// web.hypothes.is/blog/five-ways-to-use-social-annotationwith-and-against-chatgpt/

Dennehy, D. (n.d.). AI/ChatGPT resources. https://sites. google.com/mail.ccsf.edu/chat-gpt-dayamudra/home

Dennehy, D. & Mills, A. (2023, February 10). ChatGPT in higher ed: A discussion between educators [Youtube]. https:// www.youtube.com/watch?v $=$ 3ag1KWeH040

DeRosa, R. & Jhangiani, R. (2017). Open pedagogy. In A guide to making open textbook with students. Rebus Community. https://press.rebus.community/ makingopentextbookswithstudents/chapter/openpedagogy/

Douglass, J. (2023, May 1). Writing to and from, for and against, with and without language models. Future of Writing Symposium.

Dreeme, C. [@cecildreeme]. (2023, April 18). Thank you for sharing! Was the talk recorded? I missed it, but this is a really helpful summary of the issue, especially for writing instructors. I’m going to share this with my department as we figure out our approach! [Tweet]. Twitter. https://twitter. com/cecildreeme/status/1648442635831611392?s=20

Eaton, L. (n.d. a). Classroom policies for AI generative tools. https://docs.google.com/document/ d/1RMVwzjc1o0Mi8Blw_JUTcXv02b2WRH86vw7mi16W3U/ edit#

Eaton, L. (n.d. b). Políticas del Aula para Herramientas Generativas de IA. (T. Torres-Zapata, Trans.) https://www. canva.com/design/DAFfvwSGoO0/g7CZUnl4IFfeglf2YzfIOA/ edit?utm_content $=$ DAFfvwSGoO0

Eaton, L. (2023a, January 9). College unbound - AI generative tools policy development plan. https:// docs.google.com/document/d/1w1NKdOM2UW359_ XPdtyVhMq6pBEt2B5rPNIfs3HeZN0/

Eaton, L. (2023b, January 31). ChatGPT: AI generative tools and education. By any other nerd. https://www.byanyothernerd. com/2023/01/chatgpt-ai-generative-tools-and.html

Eaton, L. [@leaton01]. (2023c, February 2). Here’s our nonpunitive approach to working with students to figure out what makes sense for the use of such tools in teaching & learning at college unbound. [Tweet]. Twitter. https://twitter.com/ leaton01/status/1621186190656389120?s=20

Eaton, L. (2023d, March 23). My recent (& not particularly original) thoughts on AI. By Any Other Nerd. https://www. byanyothernerd.com/2023/03/my-recent-not-particularlyoriginal.html

Eaton, L. (Ed.). (2023). Proposal of usage guidelines for AI generative tools at CU. https://docs.google.com/document/ d/12Kx-Xp5lu1zQr16XFddvWOZg99UQCqpOqyn0Zg4Q1 0g/edit#heading=h.31io3d5xnjva

Fawns, T. (2022). An entangled pedagogy: Looking beyond the pedagogy-technology dichotomy. Postdigital Science and Education, 4, 711–728. https://doi.org/10.1007/s42438- 022-00302-7

Firat, M. (2023). What ChatGPT means for universities: Perceptions of scholars and students. Journal of Applied Learning and Teaching, 6(1), 57-63. https://doi.org/10.37074/

First-Year Composition Archive. (n.d.). Writing across the curriculum clearinghouse. https://fyca.colostate.edu/

Fraser, N. (2008, August 3). Nancy Fraser on the “Parity Of Participation.” 3 Quarks Daily. https://3quarksdaily. com/3quarksdaily/2008/08/nancy-fraser-on.html

Goodlad, L. & Baker, S. (2023). Now the humanities can disrupt “AI.” Public Books. https://www.publicbooks.org/ now-the-humanities-can-disrupt-ai/

Goodlad, L. & Mills, A. (2023). Adapting college writing for the age of large language models such as ChatGPT: Some next steps for educators. Critical AI. https://criticalai. org/2023/01/17/critical-ai-adapting-college-writing-forthe-age-of-large-language-models-such-as-chatgpt-somenext-steps-for-educators/

Gutierrez, J. (2023, February 22). Guidelines for the use of artificial intelligence in university courses. https://forogpp. files.wordpress.com/2023/02/guidelines-for-the-use-ofartificial-intelligence-in-university-courses-v4.3.1.pdf

Higher Ed Discussions of AI writing. (n.d.). Home [Facebook page]. Facebook. https://www.facebook.com/ groups/632930835501841/

Hodgkinson-Williams, C. A., & Trotter, H. (2018). A social justice framework for understanding open educational resources and practices in the global south. Journal of Learning for Development, 5(3), 204–224. https://jl4d.org/ index.php/ejl4d/article/view/312

Huang, K. (2023, January 16). Alarmed by A.I. chatbots, Universities start revamping how they teach. The New York Times. https://www.nytimes.com/2023/01/16/technology/ chatgpt-artificial-intelligence-universities.html

Hypothes.is. (n.d.). Edge 1. web.hypothes.is/blog/five-ways to-use-social-annotation-with-and-against-chatgpt/1.

Hypothesis annotations. (n.d.). Educator considerations for ChatGPT. OpenAI. https://hyp. i s / g o ? u r l $=$ h t t p s % 3 A % 2 F % 2 F p l a t f o r m . o p e n a i . com%2Fdocs%2Fchatgpteducation&group $=$ __world__

Kimmons, R., Graham, C., & West, R. (2020). The PICRAT model for technology integration in teacher preparation. Contemporary Issues in Technology and Teacher Education, 20(1), 176-198.

Kimmons, R., Draper, D., & Backman, J. (2022). PICRAT: The PICRAT technology integration model. EdTechnica: The Open Encyclopedia of Educational Technology. https:// edtechbooks.org/encyclopedia/picrat

Limna, P., Kraiwanit, T., Jangjarat, K., Klayklung, P., & Chocksathaporn, P. (2023). The use of ChatGPT in the digital era: Perspectives on chatbot implementation. Journal of Applied Learning and Teaching, 6(1), 64-74. https://doi. org/10.37074/jalt.2023.6.1.32

Mack, S. (2023, May 5). Student panel discusses implications of Artificial Intelligence at colgate. The Colgate Maroon-News. https://thecolgatemaroonnews.com/43246/news/studentpanel-discusses-implications-of-artificial-intelligence-atcolgate/

Marche, S (2022, December 6). The college essay is dead. The Atlantic, https://www.theatlantic.com/technology/ archive/2022/12/chatgpt-ai-writing-college-studentessays/672371/

Mills, A. (2020). How arguments work: A guide to writing and analyzing texts in college. Open Education Resource (OER) LibreTexts Project.

Mills, A. (Curator). (n.d.). AI text generators and teaching writing: Starting points for inquiry. writing across the curriculum clearinghouse. https://wac.colostate.edu/ repository/collections/ai-text-generators-and-teachingwriting-starting-points-for-inquiry/

Mills, A. (2023a). AI text generators: Sources to stimulate discussion among teachers. https://docs. google.com/document/d/1V1drRG1XlWTBrEwgGqdcCySUB12JrcoamB5i16-Ezw/edit#heading=h.qljyuxlccr6

Mills, A. (2023b, March 16). Critical AI literacy and critical assessment. Canvas Commons. https://lor.instructure.com/ resources/455e6f86b9e2403ea59b7083dd7d8f56?shared

Mills, A. [@EnglishOER]. (2023c, January 29). Thanks to all those who came to “what to do about #ChatGPT: Next steps for educators” for so many useful points and questions [Tweet]. Twitter. https://twitter.com/EnglishOER/ status/1619798302165463041? $\cdot \varsigma { = } 2 0$

Mills, A. [@EnglishOER]. (2023d, February 7). Do you have opinions or input on OpenAI’s message to educators about #ChatGPT? Willing to share in public discussion as well as submitting ideas to OpenAI? See their letter and my comments and add your own using the $@$ hypothes_is tool [Tweet]. Twitter. https://twitter.com/EnglishOER/ status/1623113529103634432?s ${ \romannumeral 20 }$

Mollick, E. (2023). One useful thing. https://www. oneusefulthing.org/

Narla, A. (Moderator). (2023). Student panel - What they think about Artificial Intelligence & their learning [YouTube]. UC San Diego Academic Integrity Office “Threats & Opportunities” Virtual Symposium. https://www.youtube. com/watch?v $=$ y0P1KyM0ubE

Nerantzi, C., Abegglen, S., Karatsiori, M., & MartinezArboleda, A. (Eds.). (2023, March). $^ { 1 0 0 + }$ Creative ideas to use AI in education. #creativeHE. https://creativehecommunity. wordpress.com/2023/02/02/creating-a-collection-of-101- creative-ideas-to-use-ai-in-education/

OpenAI. (n.d.). Educator considerations for ChatGPT. https:// platform.openai.com/docs/chatgpt-education

Open Education Global. (n.d.). OEGlobal connect. https://

connect.oeglobal.org/tag/ai

Perrigo, B. (2023, January 18). OpenAI used Kenyan workers on less than $\$ 2$ per hour to make ChatGPT less toxic. Time Magazine. https://time.com/6247678/openai-chatgptkenya-workers/

Rasul, T., Nair, S., Kalendra, D., Robin, M., de Oliveira Santini, F., Ladeira, W. J., ... & Heathcote, L. (2023). The role of ChatGPT in higher education: Benefits, challenges, and future research directions. Journal of Applied Learning and Teaching, 6(1), 41-56. https://doi.org/10.37074/jalt.2023.6.1.29

Robertson, J. [KavuBob]. (2023, March 8). @EnglishOER a quick note of thanks! we had a chatgpt workshop planned and I shared your openly licensed slides with copresenters. It’s possible that you got more than a few citations as adapted versions of your slides showed up in our combined slidedeck! [Tweet]. Twitter. https://twitter.com/KavuBob/ status/1633601128423378944?s=20

Rudolph, J., Tan, S., & Tan, S. (2023). ChatGPT: Bullshit spewer or the end of traditional assessments in higher education?. Journal of Applied Learning and Teaching, 6(1), 342-363. https://doi.org/10.37074/jalt.2023.6.1.9

Sharples, M., & Perez, R. P. (2022). Story machines: How computers have become creative writers. Routledge.

Sullivan, M., Kelly, A., & McLaughlan, P. (2023). ChatGPT in higher education: Considerations for academic integrity and student learning. Journal of Applied Learning and Teaching, 6(1), 31-40. https://doi.org/10.37074/jalt.2023.6.1.17

Tai, C. (2022, August 4). Student insights: The search for creativity: Does artificial intelligence like GPT-3 have what it takes to tell its own stories? Critical AI. https://criticalai. org/2022/08/04/student-insights-the-search-for-creativitydoes-artificial-intelligence-like-gpt-3-have-what-it-takesto-tell-its-own-stories/

Taylor, S. (Moderator). (2023, March 8). AI in Higher Ed student panel discussion - Open Education Week 2023. #creativeHE. https://events.teams.microsoft.com/event/e4e474a1-5a16- 476a-bf96-88cc98ab89ee@bdeaeda8-c81d-45ce-863e5232a535b7cb

Watkins, M. (2023, March 20). Embracing generative AI in education rhetorica. https://marcwatkins.substack.com/p/ embracing-generative-ai-in-education

Watters, A. (2015, April 8). Ed-tech’s inequalities. http:// hackeducation.com/2015/04/08/inequalities/

Whitby, T. (2013). How do I get a PLN? Edutopia. https:// www.edutopia.org/blog/how-do-i-get-a-pln-tom-whitby

Wiley, D (2014). The access compromise and the 5th R. improving learning. https://opencontent.org/blog/ archives/3221

Zotero. (n.d.). ChatGPT Zotero. https://www.zotero.org/ groups/4888338/chatgpt