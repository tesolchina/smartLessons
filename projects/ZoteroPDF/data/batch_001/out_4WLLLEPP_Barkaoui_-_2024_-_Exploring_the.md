# Exploring the effects of task difficulty and learner variables on performance on picture description writing tasks

Khaled Barkaoui

aculty of Education, York University, 4700 Keele Street, Toronto, Ontario M3J 1P3, Canada

# ARTICLEINFO

# ABSTRACT

Keywords:   
Picture description writing tasks   
Task difficulty   
Duolingo english test   
Fluency   
Accuracy   
Complexity   
First language

Picture description (PD) tasks are widely used in second language (L2) teaching, research, and assessment to elicit and/or evaluate L2 learners' writing performance. However, there is little research on the effects of the characteristics of such tasks on L2 writing performance. This study aimed to examine the effects of task dificulty and learner variables on the linguistic characteristics of responses to the 2020 version of the Duolingo English Test (DET) PD writing tasks. The written responses of 1439 test takers from four first language (L1) backgrounds and at different levels of L2 proficiency to 335 DET PD tasks at two levels of difficulty were analyzed and compared in terms of measures of fluency, accuracy, and complexity using various computer programs. The findings indicated that task difficulty did not affect writing performance significantly; high-proficiency learners tended to perform better than did their low-proficiency counterparts; responses receiving higher scores tended to be longer and more accurate; and learner L1 was significantly associated with writing grades and linguistic features. The findings and their implications for the DET PD task and the DET validity argument are discussed.

# 1. Introduction

This study aimed to examine the inguistic characteristics of test takers' written responses to picture description (PD) tasks on the Duolingo English Test (DET) and the efects of task difficulty and test taker variables on these characteristc.Writing descritions is an important language sil. As Coker (2012) has noted, a wide range of text types and genres include description. For example, clear, detailed descriptive writing is central not only to literature (e.g., poems, iction), but also to scientific and procedural writing such as when describing methods and observations in scientific reports and steps in instruction manuals. For this reason, some English language proficiency tests, such as the Duolingo English Test (DET), use PD tasks to asess second language (L2) learners writing and/or speaking proficiency.

Producing efective written descriptions can be challenging (Coker, 2012; Schleppegrell 1998). As Coker (2012) explained, writing successful descriptions requires general writing skill as well as "genre-specific qualities such as understanding the communicative goals of description, the way that information isorganized in the text, and the necessary level of detail' (p. 162; cf. Schleppegrell 1998). For example, when describing a picture, one needs to identify the object or people in the picture and to describe their char. acterisics or attributes (e.g, size, color) and their relationships, with or without engaging in interpretation (Coker, 2012; Schlep. pegrell 998. This requires a high level of "audience awareness or perspective taking as the writer nes to anticipate the reader's needs in terms of both the type and amount of information to be provided and to use words efectively to \*paint a picture that the reader can see" (Coker, 2012, p. 164). Schleppegrell (1998) found that describing pictures (of plants and animals entails the use of various grammatical structures to acomplish three meta-functions: (a) conveying information about the object or situation in the picture; (b) evoking a particular perspective from which the description procees and thus establishing a particular reationship with the reader (e.g., This/Our/The animal); and (c) constructing a cohesive and organized text that sustains a focus on the object or situation being described (p. 190). As such, describing pictures can be challenging for L2 learners. Schleppegrell, for example, identified several grammatical dificulties that picture decriptions pose for L2 learners such as using the appropriat articles and verb tenses.

PD tasks are widely used in L2 instruction to prompt L2 learners to produce output and opinions and in L2 research and assessment to elicit and/or evaluate output from L2 learners (Boers, 2018; Qiu, 2019). Boers (2018) argued that PD tass are widely used in L2 research and asessment because they can keep the amount of textual input minimal; push learners to rely on their own lingustic resources (rather than using language from the prompt); and \*elicit samples of language that share the same content' thus allowing direct comparisons of the linguistic characteristics of these samples (p. 37). Qiu (2019), however, cautioned that while the use of pictures can support L2 learners in reading and listening tasks, their effcts on speaking performance can vary depending on the characteristics of the pictures. For example, Qiu (2019) explained, pictures with a clear storyline may requir les attention to content and thus result in more atention to accuracy, while pictures with loose narrative structure may make a task more dificult since learners have to spend more time on understanding and linking the pictures.

Several studies have used PD tass to elicit output from L2 learners (e.g., Choong, 2011; Ellis & Yuan, 2004; Kormos & Trebits, 2012; Qiu, 2019; Saito & Hanzawa, 2018). These studies often compare learner performance, typicall operationalized as fluency, accuracy and complexity (collectively known as CAF), on PD tass with different characteristics or onPD and other types f tasks Ells and Yuan (2004), for example, used PD tasks to examine the effects of three types of planning conditions on L2 learners' written narratives, while Choong (2011) examined the efect of task complexity in a series of picture narration tasks on the performance of adanced L2 learners Saio and Hanzawa (2018) used a PD task t licit speech samples from L2 learners at the beginning, middle, and end of an academic year, to trace the learners oral proficiency development over time, while Qiu (2019) compared the speaking performance of L2 learners on picture-based storytelling tasks and short speech tasks.

In L2 asessment, there is ittle discussion of PD tass (e.g., Iwashita & McNamara, 2001; Weir & Wu, 2006). Iwashita and McNamara (2001), for example, argued that PD tasks can support test takers because they are oten about the here and now, which is less cognitively demanding than other tass which tend to focus on the \*there and then." Additionally, while PD tasks are sometimes used to elicit samples of L2 learners' writing performance, only a couple of studies have examined how these tasks affect L2 learners writing performance. Xu and Wu (2012) used think aloud protocols to examine the test taking strategies employed by 12 Chinese high-schoo English language learners when completing two picture-prompt writing tasks, a situational writing task which involved planning a trip based on four pictures and an interpretational task which involved interpreting a picture of alittleboy looking into a mirror and seeing a strong adult. Xu and Wu found that students and raters interprete and approached the tasks differently. Add. tionally, because of the high stakes involved in the test, the original intention of the interpretational task was distorted. Instead of freely expressing their own interpretations, students strived to guess the test-developers intent and figure out the best' theme. LI (2018) examined the extent to which the picture-prompt writing tass of three alternate test forms are parallel by comparing the content and requirements of the three tass and the scores of 95 EFL learners on the thee tasks. Li found that the three tasks were not significantly different in terms of difficulty although ask requirements and content e., picture themes, lexical complexity of picture titles) varied across tasks.

In contrast to the limited number of studies on the effcts of PD tass on L2 writing performance, there are several studies on their effect on firs guage (L1) peformance Thee studie ave examined the linguistic characteristics of 1 wrien picture descriptions (e.g., Coker, 2012; Schleppegel, 1998); thedifferences between oral and written picture decriptions (e.g., De Temple et l., 1991); and the effects of PD task on childre 1 writing (e.g., Coker, 2006; De Templee al., 991 chleppegrell, 998; Wu et al., 1994). For example, De Temple et al. (1991) and Wu et al. (1994)coded oral and written descriptions of pictures produced by children in terms of statement of the thme of the picture, the detail nessary todescrib it the preence of decritive phrases or clauses, and the use of locatives. They found that the mode of production (oral versus written) and the demands of the tass (for a present or an absent audience) affected the quality of the descriptions.

Studies on PD tasks in L1 writing have analyzed written picture descriptions in terms of various linguisticfeatures such as text length; the type, amount, quality and accuracy of information and details included; the incidence of parts of speech (e.g., nouns, adjectives, verbs, adverbs) used to identify and describe objects and people in terms of their characterisics, attribute, actions, and relationships; lexical features (g., type token ratio); syntactic fatures (g., clause length and types, tense); lingustic acuracy e.g. grammatical erors) informational organization (eg., cohesion, text structure) and stance (eg., use of modals) (e.g., Coker, 2006; e Temple et al., 1991; King & Dickinson, 2018 Schleppegrell, 1998; Wu et al., 1994). Similarly, the current study aims to analyze responses to the DET PD tasks in terms of various linguistic features.

# 1.1. The DET PD writing tasks

The DET is an online, computer-adaptive, and computer-scored test of English language proficiency for communication and use in English-medium setings Cardwel et al., 2023). At the time this study was conducted, the DET consisted of two sections. The frst section was adaptive and included fie item types toasses comprehension: c-test, audio yes/no vocabulary, visual yes/no vocabulary, dictation, and licited tatin. After ompleting the frst sectin, test taker respond to four writing ass and four spekin tasks that vary in diffculty. When this study was conducted, the difficulty levelof the DE writing and speaking tasks that a test taker receives was determined based on estimates of the test taker's abilit from the firt, adaptive portion of the test (LaFlair & Settes, 2020, p. 8) The speaking tasks included one picture description task and three independent peaking tasks, while the writing tasks included three picture description tasks and one independent task with a written prompt.2

In the writing picture description tasks, test takers are shown a picture and instructed to write one or more sentences to describe the picture" (see Fig. 1 for examples. The pictures in the PD tasks are selected by people with graduate-level degrees in applied linguistics" (LaFlair & Sette, 2020, p. 12) and, in the 2020 version of the DET, the images were assigned into three nominal leves of difficulty: ow, intermediate, and high, called dificulty levels A, B and C, respectively, that were intended to correspond to the CEFR bands A, B, and C. Picture difficulty was determined based on factors such as the number of agents (e.g., people, animals) depicted in the picture, the complexit of their relationships and actions (g., tationary or engaged in a seres of actions), and the complexit of the language needed to describe them. Test takers have 30 s to plan and 3 to ${ \mathsf { 5 } } \operatorname* { m i n }$ to write in response to the independent task and 60 s to complete each PD task; the total amount of time spent on writing would vary depending on when a test-taker decided to finish their response by proceeding to the next item or ran out of time (Duolingo, 2023).

It should be noted here that the DET i updated annuall ased on both internal and external research (see Burstein et al., 2021 and Cardwell et a., 2023 for information on the latest version of the DET). For example, since this study was conducted, two new item types, interactive reading and listening, were added to the test. Additionally, speaking and writing task prompts, including pictures in PD tasks, are currently (2023) randomly administered to test takers, rather than based on task difficulty.

Responses to all the DET items and tasks are scored automatically viastatistical procedures developed specifically for each item type. Responses to the PD writing tasks are scored by proprietary automated scoring algorithms developed through acombination of statistical machine learning and natural language processing. The writing scoring system evaluates each response on grammatical accuracy and complexity, lexical sophistication and diversty, task relevance, and length. The writing scoring algorithm employed at the time of this study was trained on 3626 writing performances. Agreement between the automated scores and human ratings of the same performances was above.70 (LaFlair & Settles, 2020).

The DET reports four subscores that aim to provide information on test takers proficiency in different components of language: Literacy, Conversation, Comprehension, and Production (LaFlair, 2020; Cardwellet al., 2023). These subscores are estimated independently and are based on weighted combinations of cores on specific item types. For example, the Comprehension score is based on scores on the five items in the adaptive section of the DET and measure test taker's understanding of spoken and writen language" on a scale from 10 to 160 (Duolingo, 2021, p.17). Writing grades, which range between 0 and 10, are estimated at the portfolio level; that is, the total writing grade reresents a test taker's peformance on the four writing tasks (for more details about current DE scoring see Cardwell et l., 23 and LaFlair & Settes, 2020; for more details on the DET, se Burstein et a., 2021; Cardwell et a., 2023; LaFlair & Settles, 2020; and Wagner & Kunnan, 2015).

# 2. The present study

This study is part of a larger project that adopted a text analysis aproach to examine several key assumptions underlying the DET explanation and generalization inferences in relation to both the tasks and criteria used in the DET to elicit test taker writing performance and evaluate thir written responses, respectively, as shown in Fig. 2 (based on Chapell, 2008 and Knoch & Chapelle, 2018) Concerning the PD writing tasks, the assumptions underlying the DET explanation inference that this study aimed to evaluate are that (a) PD tasks with different difficult levels affect the linguistc characteristics of test takers responses differently (quantitatively and/or qualitatively), and (b) the linguistic characteristics of responses to the PD tasks vary in relation to construct-relevant factors such as test taker English language proficiency (ELP), but (c) not in relation to constructirrelevant factors such as test taker demographic variables (.g., gender, first language [L1) (cf. Yan & Staples, 2019). Assumptions in relation to the criteria for evaluating test takers' responses include: (d) variabilit in the linguistic characteristics of test takers responses to PD tass wil be reflected in differences in their writing grades and (e test takers writing grades are primarily determined by linguistic fatures directl related to criteria on the DET rating scale (cf. Wolf et al., 2018).

Assumptions underlying the DET generalization inference for the writing tasks relate to the use of different pictures at each dif ficulty level that are assumed to be equivalent and, thus, are randomly assigned to test takers depending on their proficiency level as estimated by their Comprehension scores (see above). Consequently, akey assumption is that, because PD tass at the same level of difficulty are comparable, () the cores and lingistic characteristc of test takers responses o not vary sigficanly acros P tasks nested within the same level of difficulty (f. Yan & Staple, 2019). Another key assumption underlying the generalization inference is that (g) the criteria for evaluating performance on the PD tasks do not vary depending on task difficulty level. No previous studies have examined these assumptions.

To evaluate these assumptions, the written response of a large sample f test takers to DET PD tass at different levels of difficulty were obtained from Duolingo and analyzed in terms of various inguisti features (see below). To test assumptions a-c in Fig. 2, the scores and linguistic characteristics of test takers responses were compared acros task difficulty levels tet taker ELP leels, and two test taker demographic variables that were collected and provided by Duolingo, test taker gnder and 1, to adressthe firs research question.

![](img/81d827f790282f6e16121f3acb699f5827ddbee5f1a0df1ebf3ff54d28969792.jpg)  
Fig. 1. Examples of the DET PD Writing Tasks.   
Fig. 2. DET Assumptions Examined in the Study. (adapted from Chapelle, 2008; Knoch & Chapelle, 2018).

<html><body><table><tr><td>Inference</td><td colspan="2">Elicitation Task.</td><td colspan="2">Evaluation Criteria</td></tr><tr><td rowspan="3">Interpretation</td><td>a.</td><td>PD tasks with varying difficulty levels. affect the linguistic features of test takers&#x27; responses differently.</td><td>d. characteristics of responses to PD tasks will manifest in differences in</td><td rowspan="3">Variability in linguistic their writing grades. Writing grades are primarily</td></tr><tr><td>b.</td><td>Linguistic characteristics of responses to. PD tasks vary in relation to construct- relevant factors (e.g., test taker ELP).</td><td>e. determined by linguistic features directly related to criteria on the DET</td></tr><tr><td>c.</td><td>Linguistic characteristics do not vary in relation to construct-irrelevant factors (e.g.,) gender, L1).</td><td>rating scale.</td></tr><tr><td>Generalization</td><td>f.</td><td>Linguistic characteristics and scores of test takers&#x27; responses do not exhibit significant variations across PD tasks nested within the same difficulty level.</td><td>g.</td><td>Criteria for evaluating performance on the PD tasks do not vary depending on task difficulty level.</td></tr></table></body></html>

RQ1. : To what extent do the writing grades and the linguistic characteristics of test-takers' responses to the DET PD writing tasks vary across a) task difficult levels, (b) test takers' ELP levels; and (c) test takers from diferent backgrounds (in terms of L1 and gender)?

To test assumptions $d ,$ e, and $g$ in Fig. 2, the following main and sub-questions were posed:

RQ2. : What are the relationships between the linguistic characteristics of tet-takers responses to the DET PD writing tass and their writing grades?

a. To what extent do the linguistic characteristics of test-takers' responses to the PD writing tass vary across writing grade levels? (i. e., assumption d).   
b. Which writin features correlate with DET writing grades and best distinguish between responses at diffrent writing grade levels? (i.e., assumption e).   
c. Do the answers to questions 2a and $2 b$ depend on task difficulty level? (i.e., assumption g).

Finally, to test assumption $f$ in Fig. 2, the writing grades and linguistic characteristics of test takers' responses were compared across tasks within task difficulty level to address research question 3.

RQ3. : To what extent do the writing grades and the linguistic characteristics of test-takers' responses to the DET PD writing tasks vary across tasks nested within task difficulty level?

# 3. Method

# 3.1. Sample

Duolingo provided data for 1767 test takers who took the DET between January 2020 and February 2021. The data included information about tes taker demographics (age, 1, country, and gender); DET writing, total scores and subscore; and copies of the written responses to the PD tasks for each test taker. Duolingo provided one written response for each test taker, although each test taker completed three PD tasks as part of the est ee above). The datasts included 335  tass at two diffiulty levels: intermediate (level B) and high (leel C) tasks at diffiulty level  (low) were not included. The length of the reonses to theP tass in the dataset ranged between 1 and 55 words. A decision was made to include only responses that are at least 10 words long. Furthermore, to avoid outliers, responses that were more than 40-word long (less than $0 . 2 \%$ were excluded. The final dataset comprised 1439 test takers who responded to the 335 prompts (see Table 1). On average, around four test takers responded to each prompt, with the number of responses per prompt ranging from 1 to 13.

The test takers' age ranged between 18 and 40 years $( M = 2 3 . 6 6$ years, $S D { = } 5 . 1 2 $ , but the majority $( 8 0 \% )$ were between 18 and 27 years old. Half $( 5 0 \% )$ were females. The test takers came from 60 different countries, with the majority being from China $( 5 0 \% )$ , India $( 9 \% )$ , and Mexico $( 5 \% )$ . They reported speaking four first languages: Mandarin $( 5 3 \% )$ , Spanish $( 2 2 \% )$ , English $( 1 6 \% )$ , and Arabic $( 9 \% )$ Half $( 5 0 \% )$ responded to 189 tasks at diffculty level B and the other half responded to 146 tasks at difficulty level C. As noted above, assumption c in Fig. 2 concerns the impact of construct-irrlevant factors on test taker performance on the PD tass. To test this assumption two of the four test taker background variables collcted and provided by Duolingo were used: gender and 1. Country was not used because it overlaps with L1 and some countries have a very small sample, while age was highly skewed with the majority $( 8 0 \% )$ of the test takers being between 18 and 27 years old. Finally, the DET comprehension subscore (LaFlair, 2020) was used as a measure of test taker ELP (to test assumption $^ { b }$ in Fig. 2). The test takers' comprehension scores ranged between 50 and 150 $M =$ 117.96, $S D { = } 2 0 . 1 3 )$ , while their writing grades ranged between 0.63 and 9.95 out of 10 $( M = 5 . 4 8$ $S D { = } 1 . 9 9 $

# 3.2. Linguistic characteristics of written responses

As noted above, responses to the DET writing tasks are evaluated on grammatical accuracy and complexity, lexical sophistication and diversity, length, and tk leance. onuenly, in this study linguistic feres relatdto thritria werexamined, excet for task relevance, to test assumptions $d ,$ e, and $g$ in Fig. 2. The specific measures used in this study are listed in Table 2 and described in the following paragraphs.

Length was operationalized as the number of words per response. Given that all tet takers had the same amount of time to respond to each PD task, length can be considered an indicator f fluency (Cumming e al., 2005; Wolf-Quintero et al. 1998). Length can also serve as a proxy for text development (Crossley & McNamara, 2016). Linguisic acuracy was operationalized as the ratio of grammatical, lexical and mechanical errors per 10 words. The computer program, Singsound GEC system for error detection, developed by Xu et al. (2019), was used to identif linguistic errors in the essays. The system identifies 25 types of erors under five categories (see Bryant et al., 2017). Only thre categories were included in this study: Grammatical (e.g., noun inflection, morphology, verb form, verb inflction, subject-verb agreement, verb tense, word order), lexical (i.e, incorrect word choice, and mechanics (e.g, orthography, spelling).4

Syntactic complexity refers to how varied and sophisticated or complex the syntactic structures in a text are (Lu, 2010; Wolfe-Quintero et a., 198). Based on recommendations in the literatre (e.g., Lu, 2010; Norris & Ortea, 2009; Wolfe-Quintero et al., 1998), four main measures of syntactic complexity were examined in ths study using the Tol for the Automatic Analysis of Syntactic Sophistication and Complexity (Kyle, 2016): global complexity (mean length of sentences [MLS] and mean number of clauses per sentence [C/S]); complexity by subordination (mean number of dependent clauses per clause [DC/C]); clausal complexity (mean length of clause [MLC]); and the incidence of parts of speech per 10 words. As noted above, previous studies on PD tasks have emphasized the importance of examining the incidence of parts of speech (e.g., Croker, 2006; De Temple et al., 1991; King & Dick. inson, 2018; Schleppegrell, 1998; Wu et al., 1994). Parts of speech examined in this study include nouns and pronouns that identify and refer to objects and people in a picture; adjectives that describe the properties and atributes of the objects and people being described; verbs to describe relationships and actions; adverbs to describe actions; artices (definite and indefinite); and prepositions that describe location, time, relationships, etc.

Finally, lexical complexity, which refers to the richness of a writer's lexicon (Lu, 2012; Wolfe-Quintero et al., 1998), was measured using two indices: lexical density (i., ratio of content words to the total number of words per response) and average word length (AWL) as a measure of lexica sophistication. Both measures were computed using the Automatic Analysis of Lexical Sophistication (Kyle & Crossley, 2015, 2016; Kyle, Crossey & McNamara, 2015). Generall, texts with a high proportion of content words contain more information than texts with a high proportion of function words (Michel, 2017), while higher AWL values indicate more sophisticated

Table 1 Number of Tasks and Written Responses by Task Difficulty Level.   

<html><body><table><tr><td>Task Difficulty Level</td><td>Number of Tasks</td><td>Number of Test takers and Responses</td></tr><tr><td>Level B</td><td>189</td><td>724</td></tr><tr><td>Level C</td><td>146</td><td>715</td></tr><tr><td>Total</td><td>335</td><td>1439</td></tr></table></body></html>

Table 2 Measures of Linguistic Characteristics.   

<html><body><table><tr><td>DET Rating Criteria</td><td>Measures</td></tr><tr><td>Length (fluency)</td><td>Number of words per essay</td></tr><tr><td>Linguistic accuracye</td><td>Number of grammatical, lexical and mechanics errors per 10 words</td></tr><tr><td rowspan="5">Syntactic complexity</td><td> Mean length of sentence (MLS)</td></tr><tr><td>Clauses per sentence (C/S)</td></tr><tr><td>Dependent clauses per clause (DC/C)</td></tr><tr><td> Mean length of clause (MLC)</td></tr><tr><td>Incidence of parts of speech per 10 words</td></tr><tr><td rowspan="2">Lexical sophistication and diversity</td><td>Lexical density: Ratio of lexical words</td></tr><tr><td>Lexical sophistication: Average Word Length</td></tr></table></body></html>

# vocabulary use (Wolfe-Quintero et al., 1998).

Given that the responses included in the study were short (10 to 40 words), the indices isted above were selected to minimize the effects of text length. Like previous studies on PD tasks (see above), this study used mainly indices that require counting specific features wthout reference to other unit eg., T-units such as counting the number of words, number f erors, occurrence of parts of speech, number of content words (for lexical density), and number of leters per word (for AWL). Additionall, while previous studies usually divide the frequency f occurrencef inguistc features y 100 to obtain standardzed frequencies or ratios, 10 words was used as the denominator for most indices in this study. However, measures of syntactic complexity (MLS, MLC, C/S and DC/C) involved using other units (i.., sentence and clause) which might have been affected by the length of the responses. As areult, readers should interpret results for these indices with caution.

# 3.3. Statistical analyses

To addres RQ1 concerning the main effects of task difficult level and test taker ELP, gender, and 1, as well as their interactions on writing grades and linguistic features, while controlling for the efects of differences in test taker ELP (i., comprehension score), univariate and multivariate analysis of covariance ([M]AncovA) were used, with task difficulty level L1, and gender as predictors, comprehension score as a covariate, and writing grade or linguistic features as the outcomes. If MAnovA indicated a significant effect, AcovA was conducted on each dependent variable separately. If AncvA detected a significan ffect for 1, follow-up pairwise comparisons (with Bonferroni corrections) were conducted among the four L1 groups.

To address RQ2a, writing grades were divided into three levels (se below) and then multivariate analysis of variance (MANOVA) was conducted, with writing grade level as the predictor and inguistic fatures as the outcomes, to compare linguistic features across writing grade levels. If MAnOVA indicated a significant effect, a univariate analysis of variance (AnOvA) was conducted on each feature separately. If ANOVA detected a significant effect for writig grade level,follow-up pair-wise comparisons (with Bonferroni corrections) were conducted among the three writing grade levels. Additionally, as a follow up, and to address RQ2b and RQ2c, discriminant function analysis (DFA), with writing grade level as the outcome and writing features as the predictors, was conducted to identify which writing features best distinguish between the three writing grade levels.

Finally, to address RQ3, a subset of responses was created that included those tasks with the largest number of responses within each difficulty level (B and C; se below). The sub-dataset was then analyzed using MANoVA to find out f there was significant variability in writing grades and linguistic features across tasks (nested) within each task difficulty level.

To save space, only main and interaction efects that are significant are reported below. Because the study included several dependent variables, the threshold for the significance value was reduced from the commonly used $p < . 0 5$ to $p < . 0 1$ . For significant effects, effect size was estimated using partial eta-squared $( \dot { \eta } ^ { 2 } )$ $\dot { \eta } ^ { 2 } \ge$ .01 indicates a small effect size; $\dot { \eta } ^ { 2 } \geq . 0 6$ indicates a medium effect; and $\dot { \eta } ^ { 2 } \ge . 1 4$ indicates a large effect (Cohen, 1969, cited in Richardson, 2011).

# 4. Findings

The findings are reported in relation to the thre reearch questions of the study. Before presenting the findings, i is worth noting that ANOvAs detected significant effects for L1 on comprehension scores: $( F ( 3 , 1 4 3 1 ) = 2 6 . 5 6 $ $p < . 0 0 1$ $\dot { \eta } ^ { 2 } = . 0 5 )$ . Post hoc analyses indicated that all pairwise comparisons were significant. Overall the English speakers had the highest comprehension scores $M =$ 127.01, $S D { = } 2 0 . 5 3 \mathrm { \Omega }$ , followed by the Spanish $\mathbf { \Phi } ( M = 1 1 9 . 9 8$ $S D { = } 1 8 . 9 3$ ), Mandarin $\scriptstyle { M = 1 1 5 . 7 9 }$ $S D { = } 1 8 . 6 4 \mathrm { \Omega }$ , and Arabic $\scriptstyle ( M = 1 1 0 . 5 2$ $S D { = } 2 4 . 4 9 $ speakers. This finding suggests that the four L1 groups differed significantly in terms of their overal ELP as measured by their comprehension scores.

# 4.1. RQ1: variability in writing grades and linguistic features

ANcOVA detected a significant and strong association between comprehension scores and writing grades $( F ( 1 , 1 4 2 2 ) = 1 3 9 8 . 6 7 $ $p < . 0 0 0 1$ $\dot { \eta } ^ { 2 } =$ .50) and significant weak main effects on writing grades for L1 $( F ( 3 , 1 4 2 2 ) = 1 8 . 3 6 p < . 0 0 0 1$ $\dot { \eta } ^ { 2 } = . 0 4 )$ , but not for task difficulty level, gender, or any interactions. There was a strong and positive association between comprehension and writing grades $( r = . 7 0 , p < . 0 1 )$ indicating that, as expected, test takers with higher ELP (i.e., higher comprehension scores) tended to obtain higher writing grades. For L1, post-hoc pairwise comparisons of marginal means (MM) indicated that the Mandarin group had significantly higher writing grades $( M M = 5 . 7 2$ than did the Arabic $( M M = 5 . 1 1 )$ ) and Spanish $( M M = 5 . 0 9 )$ groups (see Table 3 for descriptive statistics and Table A in the Appendix for the t-test results for allsignificant pairwise comparisons acros 1 groups). The ifferences between the other L1 groups were not statistically significant at $p < . 0 1$

Length: AncovA detected a significant medium association between comprehension scores and response length $( \mathrm { F } ( 1 , 1 4 2 2 ) =$ 309.42, $\mathbf { p } < . 0 0 0 1$ $\dot { \mathsf { \Pi } } ^ { 2 } =$ .18), and significant small main effects on length for L1 $( \mathrm { F } ( 3 , 1 4 2 2 ) = 7 . 4 9$ $\mathbf { p } < . 0 0 0 1$ $\dot { \mathsf { \Pi } } ^ { 2 } =$ .02), and gender (F - $1 , 1 4 2 2 ) = 8 . 3 9$ $\mathtt { p } = . 0 0 4$ $\dot { \mathsf { \Pi } } ^ { 2 } =$ .01), but not task difficulty level or any of the interactions. There was a strong and positive association between comprehension scores and length $( \mathbf { r } = . 4 4$ $\mathbb { P } < . 0 1 \AA$ indicating that test-takers who obtained higher comprehension scores tended to write longer responses. For L1, post-hoc pairwise comparisons indicated that the Spanish group wrote significantly longer responses $( \mathbf { M M } = 2 0 . 8 3$ words) than did each of the other three L1 groups whose responses ranged between 18.70 and 19.13 words, on average (se able 3). The differences between the other three 1 groups were not stistclly significant. Finally, female test-takers wrote significantly longer responses $( \mathbf { M } \mathbf { M } = 1 9 . 9 8$ words, $\mathbf { S E } { = } 0 . 2 8 $ than did their male counterparts $( \mathrm { M M } = 1 8 . 8 6 $ words, $\mathbf { S E } { = } 0 . 2 7 $

Linguistic Accuracy: MAncovA detected a significant and strong association between comprehension scores and the combination of error ratios $( F ( 3 , 1 4 2 0 ) = 1 4 8 . 7 7$ $p < . 0 0 1$ $\dot { \eta } ^ { 2 } =$ .24), and significant main effects on error ratios for L1 $( F ( 9 , 4 2 6 6 ) { = } 4 . 5 9$ $p < . 0 0 1$ $\dot { \eta } ^ { 2 } = . 0 1 )$ , but not for task difficulty, gender, or any of the interactions. Follow up AncovAs indicated that comprehension score had significant and medium to strong associations with the ratios of grammatical errors $( F ( 1 , 1 4 2 2 ) = 2 4 9 . 2 7 ,$ $p < . 0 0 1$ 3 $\dot { \eta } ^ { 2 } = . 1 5 )$ , lexical errors $( F ( 1 , 1 4 2 2 ) = 7 3 . 1 0$ $p < . 0 0 1$ $\dot { \eta } ^ { 2 } = . 0 5 )$ , and mechanical errors $( F ( 1 , 1 4 2 2 ) = 1 2 3 . 4 4$ $p < . 0 0 1$ 3 $\dot { \eta } ^ { 2 } = . 0 8 )$ . The correlations between comprehension scores and error ratios were all significant $( p < . 0 1 )$ and negative $( r = - . 3 9 $ for grammatical errors, $- . 2 3$ for lexical errors, and-.28 for mechanicalerrors), indicatig that tes-takers wit higher ELP tended to make fewer errors. Finall, follow up ANcoVAs indicated that L1 had significant effects only on the ratios of mechanical errors $( F ( 3 , 1 4 2 2 ) = 9 . 1 7$ $p < . 0 0 1$ $\dot { \eta } ^ { 2 } = . 0 2 )$ Pairwise comparisons indicated that the Mandarin group had a significantly lower ratio of mechanics errors $( M M = . 2 2 3 )$ than did each of the other three L1 groups (see Table 3).

Syntactic Complexity: There was a significant but weak association between comprehension scores and the combination of syn tactic complexity indices $( \mathrm { F } ( 4 , 1 4 1 9 ) = 9 . 1 5 $ $\mathbf { p } < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } = . 0 3 )$ . Additionally, there was a significant weak main effect for L1 (F(12, $4 2 6 3 ) { = } 6 . 0 9$ $\mathbf { p } < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } = . 0 2 )$ but not for task difficulty, gender, or any of the interactions. Follow up AncovAs indicated that comprehension score had significant associations only with MLC $( \mathrm { F } ( 1 , 1 4 2 2 ) = 2 7 . 5 7 $ $\mathbf { p } < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } = . 0 2 )$ . MLC had the highest, but non-significant, correlation with comprehension scores $( \mathrm { r } = . 1 4 )$ , followed by C/S $( \mathbf { r } = - . 0 6 )$

Table 3 Marginal Means (MM) and Standard Error (SE) for Writing grades and Linguistic Features by L1 Group.   

<html><body><table><tr><td>L1 Group</td><td colspan="2">Arabic</td><td colspan="2">English</td><td colspan="2">Mandarin</td><td colspan="2"> Spanish</td></tr><tr><td></td><td>mm</td><td>SE</td><td>mm</td><td>SE</td><td>Mm</td><td>SE</td><td>mm</td><td>SE</td></tr><tr><td>Writing grades</td><td>5.11</td><td>0.12</td><td>5.48</td><td>0.09</td><td>5.72</td><td>0.05</td><td>5.09</td><td>0.08</td></tr><tr><td>Length</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Number of words</td><td>18.70</td><td>0.53</td><td>19.13</td><td>0.41</td><td>19.02</td><td>0.22</td><td>20.83</td><td>0.34</td></tr><tr><td>Accuracy Grammatical errors</td><td>0.04</td><td>0.18</td><td>0.03</td><td>0.13</td><td>0.02</td><td>0.14</td><td>0.03</td><td>0.14</td></tr><tr><td>Lexical errors</td><td>0.18</td><td>0.03</td><td>0.13</td><td>0.02</td><td>0.14</td><td>0.01</td><td>0.18</td><td>0.01</td></tr><tr><td>Mechanics errors</td><td>0.37</td><td>0.04</td><td>0.34</td><td>0.03</td><td>0.22</td><td>0.02</td><td>0.34</td><td>0.02</td></tr><tr><td>Syntactic complexity</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>c/S</td><td>1.3</td><td>0.07</td><td>1.4</td><td>0.06</td><td>1.57</td><td>0.03</td><td>1.7</td><td>0.05</td></tr><tr><td>DC/C</td><td>0.19</td><td>0.02</td><td>0.2</td><td>0.02</td><td>0.18</td><td>0.01</td><td>0.21</td><td>0.01</td></tr><tr><td>MLC</td><td>9.08</td><td>0.33</td><td>9.39</td><td>0.26</td><td>8.93</td><td>0.14</td><td>8.31</td><td>0.22</td></tr><tr><td>MLS</td><td>12.8</td><td>0.48</td><td>12.77</td><td>0.37</td><td>13.03</td><td>0.2</td><td>13.25</td><td>0.31</td></tr><tr><td>Nouns &amp; Pronouns</td><td>3.57</td><td>0.06</td><td>3.6</td><td>0.05</td><td>3.35</td><td>0.03</td><td>3.43</td><td>0.04</td></tr><tr><td>Adjectives</td><td>0.61</td><td>0.05</td><td>0.52</td><td>0.04</td><td>0.59</td><td>0.02</td><td>0.56</td><td>0.03</td></tr><tr><td>Adverbs</td><td>0.32</td><td>0.04</td><td>0.27</td><td>0.03</td><td>0.28</td><td>0.02</td><td>0.34</td><td>0.03</td></tr><tr><td>Verbs</td><td>1.57</td><td>0.05</td><td>1.62</td><td>0.04</td><td>1.67</td><td>0.02</td><td>1.77</td><td>0.03</td></tr><tr><td>Articles</td><td>0.90</td><td>0.05</td><td>0.88</td><td>0.04</td><td>0.92</td><td>0.02</td><td>0.96</td><td>0.03</td></tr><tr><td>Prepositions</td><td>0.99</td><td>0.05</td><td>1</td><td>0.04</td><td>1.00</td><td>0.02</td><td>0.93</td><td>0.03</td></tr><tr><td>Lexical complexity</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Lexical Density</td><td>0.50</td><td>0.01</td><td>0.51</td><td>0.01</td><td>0.5</td><td>0.01</td><td>0.49</td><td>0.01</td></tr><tr><td>AWL</td><td>4.10</td><td>0.04</td><td>4.23</td><td>0.03</td><td>4.05</td><td>0.02</td><td>4.09</td><td>0.03</td></tr></table></body></html>

Covariate (comprehension score) $=$ 117.96.

Follow up ANcOvAs indicated that L1 had significant effects only on C/S $( F ( 3 , 1 4 2 2 ) = 1 0 . 4 3$ $p < . 0 0 1$ $\dot { \eta } ^ { 2 } = . 0 2 )$ and MLC $( F ( 3 ,$ $1 4 2 2 ) = 3 . 8 6$ $p = . 0 0 9$ $\dot { \eta } ^ { 2 } =$ .01). As Table 3 shows, the Spanish group had a significantly higher C/S index $( M M = 1 . 7 0 )$ than did the English $( M M = 1 . 4 0 )$ and the Arabic $( M M = 1 . 3 0 )$ groups. The Mandarin group had a significantly higher C/S index $( M M = 1 . 5 7 )$ than did the Arabic group. Additionally, the Spanish group had a significantly lower MLC index $( M M = 8 . 3 1 $ ) than did the English group $( M M = 9 . 3 9 $ . The differences between the other L1 groups were not significant.

Parts of Speech: There was a significant association between comprehension scores and the combination of parts of speech inci dence $( \mathrm { F } ( 6 , 1 4 1 7 ) = 1 2 . 3 2 $ $ { \mathbf { p } } < . 0 0 1$ 3 $\dot { \mathsf { n } } ^ { 2 } = . 0 5 )$ . Additionally, there was a significant main effect for L1 $( \mathrm { F } ( 1 8 , 4 2 5 7 ) = 3 . 1 7 , \mathrm { p } < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } = . 0 1 )$ , but not for task dificulty, gender, or any of the interactions. Follow up AncovAs indicated that comprehension score had significant but weak associations with the incidence of nouns and pronouns $( \mathrm { F } ( 1 , 1 1 , 4 2 2 ) = 2 0 . 6 9$ $\mathbf { p } < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } = . 0 1 )$ , adverbs (F(1, $1 1 , 4 2 2 ) = 9 . 6 8 $ $\mathbf { p } = . 0 0 2$ $\dot { \mathsf { n } } ^ { 2 } = . 0 1 \dot { \mathsf { \Omega } }$ , articles $( \mathrm { F } ( 1 , \ 1 1 , 4 2 2 ) = 1 4 , 2 2$ $ { \mathbf { p } } < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } = . 0 1 \rrangle$ , and prepositions $( \mathrm { F } ( 1 , \ 1 1 , 4 2 2 ) = 2 3 . 1 7$ $\mathbf { p } < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } = . 0 2 )$ . Generally, test-takers with higher ELP tended to use more articles $( \mathbf { r } = . 1 0 $ $\mathbf { p } < . 0 1 $ ) and prepositions $( \mathbf { r } = . 1 3$ $\mathbb { P } < . 0 1 )$ and fewer nouns and pronouns $( \mathbf { r } = - . 1 1$ $\mathbf { p } < . 0 1 $

Follow up ANcoVAs indicated that L1 had significant smalleffects on the incidence of nouns and pronouns $( F ( 1 , 1 1 , 4 2 2 ) = 9 . 1 9$ $\mathbf { p } < . 0 0 1$ 3 $\dot { \eta } ^ { 2 } = . 0 2 )$ and verbs $( F ( 1 , 1 1 , 4 2 2 ) = 5 . 3 0$ $\mathbf { p } = . 0 0 1$ $\dot { \eta } ^ { 2 } = . 0 1 )$ (see Table 3). The Mandarin group used significantly fewer nouns and pronouns $( M M = 3 . 3 5 )$ than did the English $( M M = 3 . 6 0 )$ and Arabic $( M M = 3 . 5 7 )$ groups. The Spanish group used significantly more verbs $( M M = 1 . 7 7 )$ than did the Arabic group $( M M = 1 . 5 7 )$ . Differences between the other L1 groups were not significant.

Lexical Complexity: MANcoVA detected a significant association betwen comprehension scores and the combination of lexical complexity indices $( \mathrm { F } ( 2 , 1 4 2 1 ) = 1 5 . 9 8 $ $\mathbf { p } < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } = . 0 2 \mathsf { ) }$ , and significant small main effects for L1 $( \mathrm { F } ( 6 , 2 8 4 4 ) = 4 . 6 7$ $\mathbf { p } < . 0 0 1$ A $\dot { \mathsf { n } } ^ { 2 } = . 0 1 )$ , but not for task diffculty, gender, or any of the interactions. Follow up ANcovAs indicated that comprehension score had significant association only with AWL $( \mathrm { F } ( 2 , 1 4 2 2 ) = 2 7 . 3 2$ 3 $ { \mathbf { p } } < . 0 0 1$ 3 $\dot { \mathsf { n } } ^ { 2 } = . 0 2 )$ . AWL was significantly and positively correlated with comprehension scores $( \mathbf { r } = . 1 6 $ $\mathbf { p } < . 0 1 $

Follow up ANcOvAs indicated that L1 had significant effects on both lexical density $( F ( 3 , 1 4 2 2 ) = 4 . 3 3$ $p = . 0 0 5$ $\dot { \eta } ^ { 2 } = . 0 1 )$ and AWL $( F ( 3 , 1 4 2 2 ) = 7 . 4 4$ $p < . 0 0 1$ $\dot { \eta } ^ { 2 } = . 0 2 )$ (see Table 3). The Spanish group, who wrote significantly longer responses (see above), had significantly lower lexical density $( M M = 0 . 4 9$ than did the English group $( M M = 0 . 5 1 )$ , who had a significantly higher AWL index $( M M = 4 . 2 3 )$ than did the Spanish $( M M = 4 . 0 9 )$ and Chinese $M M = 4 . 0 5$ ) groups. The other L1 groups did not differ from each other significantly.

# 4.2. RQ2: relationships between linguistic features and writing grades

The responses were divided into three writing grade levels based on their writing grades (i.e., a third of the 10-point rating scale, level $1 = s c \mathrm { o r e s } 0$ to 3.49; level $\mathbf { 2 } = \tt s c o r e s \ 3 . 5$ to 6.49; and level $3 = s c o r e s 6 . 5$ to 10). Linguistic features were then compared across the three writing grade levels. Before comparing linguisic features aross grade levels, MAnovA, with grade level and task diffiulty level as predictors and linguistic features as outcomes, was conducted to examine whether there i a significant interaction between grade level and task diffculty leve, which would indicate that differences in linguistic fatures acros grade levels depend on task difficulty level (thus violating assumption $g$ in Fig. 2). The interaction was not significant $( F ( 4 0 , 2 8 0 8 ) = 1 . 3 7 , p = . 0 6 )$ , indicating that any significant differences in linguistc features across grade levels apply to bothdifficult levels equally. As a result, MAnA was conducted again with only grade level as a predictor. MAnovA detected a significant and strong efect for grade level on linguistic features: $( F ( 4 0 , 2 8 1 4 ) = 2 4 . 5 9$ $p < . 0 0 1$ $\dot { \eta } ^ { 2 } =$ .26). Follow up ANOvAs indicated that the following features exhibited significant variability acros grade lels (e Table 4 for decritive statistics and Table  in the Appendx for the-test results for al signficant pairwise comparisons across grade levels):

. Length: $( \mathrm { F } ( 2 , 1 4 2 5 ) = 3 2 9 . 2 3$ $p < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } = . 3 2 )$ . All pairwise comparisons were significant at $p < . 0 1$ . Level 3 responses were significantly longer than level 2 responses, which were in turn significantly longer than level 1 responses.   
: Linguistic accuracy: All three accuracy indices varied significantly across grade levels: Grammatical: $( \mathrm { F } ( 2 , 1 4 2 5 ) = 7 7 . 9 3 , p < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } = \mathsf { . 1 0 } )$ ; lexical: $( \operatorname { F } ( 2 , 1 4 2 5 ) = 3 2 . 6 2 $ $p < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } = \mathsf { \Omega } \cdot 0 4 )$ ; mechanical: $( \mathrm { F } ( 2 , 1 4 2 5 ) { = } 6 5 . 4 1 $ $p < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } = . 0 8 )$ . Level 3 responses had a significantly lower rate of grammatical, lexical and mechanics errors than did level 2 responses, which in turn had a significantly lower rate of errors than did level 1 responses.   
: Syntactic complexity: Two of the four indices varied significantly across writing grade levels: MLS: $( \mathrm { F } ( 2 , 1 4 2 5 ) { = } 1 4 . 6 7 $ $\mathbf { p } < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } = . 0 2 )$ and MLC: $( \mathrm { F } ( 2 , 1 4 2 5 ) = 1 6 . 1 4 , p < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } = . 0 2 \mathsf { ) }$ . Level 1 responses had a significantly lower MLS index than did level 2 and 3 responses; the difference between levels 2 and 3 was not significant. Level 3 responses had a significantly higher MLC index than did level 1 and 2 responses; the difference between levels 1 and 2 was not significant.   
: Parts of speech: The incidence of five parts of speech varied significantly across grade levels: $\circ$ Nouns and pronouns: $( \mathrm { F } ( 2 , 1 4 2 5 ) { = } 9 . 0 0 $ $\mathbf { p } < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } = . 0 1 )$ . Level 1 responses had significantly higher incidence of nouns and pronouns than did level 2 and 3 responses. The difference between levels 2 and 3 was not significant. $\circ$ Adjectives: $( \mathrm { F } ( 2 , 1 4 2 5 ) = 4 . 6 2 , \mathrm { p } = . 0 1$ $\dot { \mathsf { n } } ^ { 2 } = . 0 1 \mathsf { 1 }$ . Level 3 responses had significantly higher incidence of adjectives than did level 2 responses. Differences between level 1, on one hand, and levels 2 and 3, on the other, were not significant. $\circ$ Adverbs: $( \mathrm { F } ( 2 , 1 4 2 5 ) { = } 5 . 9 9 $ $\mathbf { p } = . 0 0 3$ $\dot { \mathsf { n } } ^ { 2 } = . 0 1 \rrangle$ . Level 3 responses had significantly higher incidence of adverbs than did level 2 responses. Differences between levels 1 and 2 and between levels 1 and 3 were not significant.

Table 4 Descriptive Statistics for Linguistic Features by Writing grade Level.   

<html><body><table><tr><td>Writing grade Level</td><td colspan="2">1 (n = 342)</td><td colspan="2">2 (n = 529)</td><td colspan="2">3 (n = 568)</td><td colspan="2">Total</td></tr><tr><td></td><td></td><td>SD</td><td></td><td>SD</td><td>M</td><td>SD</td><td></td><td>SD</td></tr><tr><td colspan="9">Length</td></tr><tr><td>Number of Words</td><td>14.06</td><td>3.45</td><td>18.20</td><td>5.48</td><td>23.69</td><td>6.59</td><td>19.38</td><td>6.75</td></tr><tr><td colspan="9">Accuracy</td></tr><tr><td>Grammatical Errors</td><td>0.62</td><td>0.70</td><td>0.34</td><td>0.50</td><td>0.21</td><td>0.30</td><td>0.36</td><td>0.52</td></tr><tr><td>Lexical Errors</td><td>0.25</td><td>0.41</td><td>0.15</td><td>0.28</td><td>0.09</td><td>0.19</td><td>0.15</td><td>0.29</td></tr><tr><td> Mechanics Errors</td><td>0.51</td><td>0.64</td><td>0.26</td><td>0.40</td><td>0.16</td><td>0.29</td><td>0.28</td><td>0.46</td></tr><tr><td colspan="9">Syntactic Complexity</td></tr><tr><td>MLS</td><td>11.80</td><td>4.32</td><td>12.94</td><td>5.44</td><td>13.81</td><td>5.86</td><td>13.01</td><td>5.42</td></tr><tr><td>c/S</td><td>1.50</td><td>0.85</td><td>1.58</td><td>0.86</td><td>1.55</td><td>0.77</td><td>1.55</td><td>0.82</td></tr><tr><td>DC/C</td><td>0.19</td><td>0.27</td><td>0.18</td><td>0.24</td><td>0.19</td><td>0.22</td><td>0.19</td><td>0.24</td></tr><tr><td>MLC</td><td>7.98</td><td>3.89</td><td>8.74</td><td>3.76</td><td>9.53</td><td>3.80</td><td>8.87</td><td>3.85</td></tr><tr><td colspan="9">Parts of Speech</td></tr><tr><td>Nouns &amp; Pronouns</td><td>3.58</td><td>0.86</td><td>3.40</td><td>0.73</td><td>3.35</td><td>0.63</td><td>3.42</td><td>0.73</td></tr><tr><td>Adjectives</td><td>0.56</td><td>0.62</td><td>0.53</td><td>0.59</td><td>0.62</td><td>0.53</td><td>0.58</td><td>0.58</td></tr><tr><td>Adverbs</td><td>0.26</td><td>0.48</td><td>0.27</td><td>0.44</td><td>0.35</td><td>0.42</td><td>0.30</td><td>0.44</td></tr><tr><td>Verbs</td><td>1.67</td><td>0.65</td><td>1.70</td><td>0.56</td><td>1.66</td><td>0.52</td><td>1.68</td><td>0.57</td></tr><tr><td>Articles</td><td>0.85</td><td>0.55</td><td>0.89</td><td>0.54</td><td>0.99</td><td>0.50</td><td>0.92</td><td>0.53</td></tr><tr><td>Prepositions</td><td>0.84</td><td>0.63</td><td>1.01</td><td>0.57</td><td>1.04</td><td>0.52</td><td>0.98</td><td>0.57</td></tr><tr><td colspan="9"> Lexical Complexity</td></tr><tr><td>Lexical density</td><td>0.50</td><td>0.08</td><td>0.50</td><td>0.08</td><td>0.50</td><td>0.06</td><td>0.50</td><td>0.07</td></tr><tr><td>AWL</td><td>3.93</td><td>0.52</td><td>4.08</td><td>0.50</td><td>4.20</td><td>0.48</td><td>4.09</td><td>0.51</td></tr></table></body></html>

$\circ$ Articles: $( \mathrm { F } ( 2 , 1 4 2 5 ) { = } 9 . 4 1 $ $\mathbf { p } < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } =$ .01). Level 3 responses had significantly higher incidence of articles than did level 1 and 2 responses. The difference between levels 1 and 2 was not significant. $\circ$ Prepositions: $( \mathrm { F } ( 2 , 1 4 2 5 ) = 1 7 . 4 8$ $\mathbf { p } < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } = . 0 4 )$ . Level 1 responses had significantly lower incidence of prepositions than did level 2 and 3 responses. The difference between levels 2 and 3 was not significant. . Lexical complexity: Only AWL varied significantly across grade levels: $( \mathrm { F } ( 2 , 1 4 2 5 ) = 3 2 . 5 5$ $\mathbf { p } < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } = . 0 4 )$ . All pairwise comparisons were significant at $\mathbf { p } < . 0 1$ . Level 3 responses had a significantly higher AWL index than did level 2 responses, which in turn had a significantly higher AwL index than did level 1 responses.

As a follow-up to the analyses above, discriminant function analysis (DFA), with writing grade level as the outcome and allin. guistic features as predictors, was conducted to identif which writing fatures best distinguish between the three writing grade lels. DFA revealed two discriminant functions. The first explained $9 6 . 2 \%$ of the variance (canonical $R ^ { 2 } = 0 . 4 8 )$ , while the second explained only $3 . 8 \%$ of the variance (canonical $R ^ { 2 } = . 0 4 )$ . In combination, these discriminant functions significantly differentiated the three grade levels, $\varLambda { = } 0 . 5 0$ $X ^ { 2 } ( 4 0 ) = 9 8 3 . 8 8$ $p < . 0 0 1$ . Removing the first function indicated that the second function significantly differentiated the three grade levels too, $\varLambda \mathrm { = } 0 . 9 7$ $X ^ { 2 } ( 1 9 ) = 5 0 . 8 2$ $p < . 0 0 1$

Table 5 reports the loadings of the linguisic features on the two functions i. correlations between each linguistic feature and each function). It shows that fluency (.70), mechanics error ratio $( - . 3 0 )$ , grammatical error ratio (-.33), AWL (.22), and lexical error ratio $( - . 2 2 )$ loaded the highest on function 1, while fluency (.41), mechanics errors ratio (.39) and grammatical error ratio (.37)

Table 5 Loadings of Linguistic Features on Two Functions.   

<html><body><table><tr><td rowspan="2">Linguistic Feature</td><td colspan="2">Function</td></tr><tr><td>1</td><td>2</td></tr><tr><td>Number of Words</td><td>.70</td><td>.41</td></tr><tr><td>Grammatical Errors</td><td>-.33</td><td>.37</td></tr><tr><td>Mechanics Errors</td><td>-.30</td><td>.39</td></tr><tr><td>AWL</td><td>.22</td><td>-.03</td></tr><tr><td>Lexical Errors</td><td>-.22</td><td>.13</td></tr><tr><td>MLC</td><td>.16</td><td>.05</td></tr><tr><td>MLS</td><td>.15</td><td>-.04</td></tr><tr><td>Prepositions</td><td>.15</td><td>-.32</td></tr><tr><td>Adjectives</td><td>.06</td><td>.28</td></tr><tr><td>Adverbs</td><td>.08</td><td>.24</td></tr><tr><td>Nouns &amp; Pronouns</td><td>-.11</td><td>.17</td></tr><tr><td>Articles</td><td>.12</td><td>.16</td></tr><tr><td>lexical density</td><td>.02</td><td>.16</td></tr><tr><td>c/S</td><td>.01</td><td>-.14</td></tr><tr><td>Verbs</td><td>-.04</td><td>-.14</td></tr><tr><td>DC/C</td><td>.00</td><td>.09</td></tr></table></body></html>

incidence of adjectives (.28), and incidence of adverbs (.24) loaded the highest on the second function. Fluency loaded higher on function 1 than it did on function 2, while the ratios of grammatical and mechanics erors loaded negatively on function 1 and positively on function 2. As the post-hoc pairwise comparisons following MAnoVA above showed, the three grade levels differed significantly on all features associated with function 1. Level 3 responses were significantly longer $\scriptstyle ( M = 2 3 . 6 9$ words), had higher AWL $( M = 4 . 2 0 )$ , and had significantly lower rates of mechanics $( M { = } 0 . 1 6 )$ , grammatical $( M = 0 . 2 1 )$ and lexical errors $( M = 0 . 0 9 )$ than did responses at grade level 2, which in turn, were significantly longer $( M { = } 1 8 . 2 0 )$ , had higher AWL $( M { = } 4 . 0 8 )$ , and had significantly lower rates of mechanics $( M = 0 . 2 6 )$ , grammatical $( M = 0 . 3 4 )$ and lexical errors $M = 0 . 1 5$ ) than did responses at grade level 1, which were 14.06 word long on average, had AWL f 3.93, and included an average of 0.51 mechanics, 0.62 grammatical, and 0.25 lexicalerrors per 10 words (see Table 4).

For the two features that loaded only on function 2, generall, level 2 responses had significantly lower incidence of adjectives $M =$ 0.53 per 10 words) and adverbs $( M = 0 . 2 7 )$ than did level 3 responses $\scriptstyle { M = 0 . 6 2 }$ and 0.35, respectively). Additionally, level 1 responses had significantly lower incidence of adverbs $( \mathrm { M } = 0 . 2 6 )$ than did level 3 responses $( \mathbf { M } = 0 . 3 5 )$ (see Table 4).

Table 6 shows the average discriminant score (or multivariate mean) for each writing grade level on each function. It shows that function 1 distinguished mainly between grade level 1 responses (centroid $= - 1 . 4 7 )$ and grade level 3 responses (centroid $= 1 . 0 2$ ), with grade level 2 responses being in the middle (centroid $= - 0 . 1 6 )$ , while the second function differentiated between grade level 2 (centroid $= - 0 . 2 5 )$ and the other two grade levels. Fig. 3 displays the discriminant function plot. It shows that the first function distinguished grade level 3 from grade levels 1 and 2, while the second function differentiated between grade lels 2 and 1. The two functions correctly classified $6 5 \%$ of the cases; $5 8 \%$ for grade level 1, $6 0 \%$ for level $2 \%$ , and $7 4 \%$ for grade level 3.

Correlation analyses supported the DFA results. First, as Table 7 shows, the strength of the Pearson $r$ correlations between writing features and writing grades did not vary across task dificulty levels. Second, when both difficult levels are combined, fluency (number of words) has the strongest correlation with writing grades $\left( r = . 6 1 \right)$ , followed by grammatical error ratio $( r = - . 3 2 )$ , mechanics error ratio $( r = - . 3 2 )$ , lexical error ratio $( - . 2 2 )$ , and AWL $( r = . 2 1 )$ . However, the incidences of adjectives $\left( r = . 0 6 \right)$ and adverbs $( r = . 0 7 )$ were weakly correlated with writing grades.

# 4.3. RQ3: variability between tasks within task difficulty level

To examine whether inguistic features and scores varied significantly between tasks (nested) within each task difficulty level. writing grades and inguistic features were compared acros the tasks with the largest number of responses within each task difficulty level. The dataset included 335 P tasks, but most tass had few responses asociated with them. For ifficult lel , only thee tass had nine or more response, resulting in 29 responses.For dificulty level C, there were ixtasks with ten or more responses, with the number of responses per ask ranging between 10 and 13, resulting in 68 responses. For both dfficult levels, there was no significant effect for task (within task difficulty) on writing grades at $\mathbf { p } < . 0 1$ . Additionally, none of the linguistic features varied significantly across tasks within leve Fr leve tasks, ony the ratio f grammatica errors varied significanty across ass wthi ask difficulty level: $\operatorname { F } ( 5 , 6 1 ) = 5 . 5 9$ $\mathbf { p } < . 0 0 1$ $\dot { \mathsf { n } } ^ { 2 } = . 3 1$ . This result indicates that some tasks nested within task difficulty level C elicited significantly more rammatical erors than did other tass that are asumed to be comparable. Thee ifferences in grammatical accuracy, however, were not associated with significant differences in writing grades across tasks within difficulty level C.

# 5. Discussion

This study aimed to evaluate several key assumptions underlying the DET explanation and generalization inferences by examining how the linguistic characterisics fresponses to the DET PD tass vary in relation to task and test taker variables in the 2020 version of the DET. The findings provide a first detailed description of the linguistic features engaged by the DET PD task as captured by the various NLP ools described in the Method section as well as evidence concerning key assumptions underlying the interpretation of the DET writing grades. First, the findings indicate that the DET PD task does require and elicit the linguistic skill intended by test developers a retd in the rating criri for the  wing tasks, that i, lingistic kill elat o fleny, acuracy, and inguistic complexity.

Second, task diffculty level did not have ignificant effects ontest takers writing performance, operationalized as writing grades and the inguisti features examined in this study, on the 2020 versin of the DE. As such, the findings do not support assumption in Fig. 2. ore diffiult PD tass do not sm to be more challenging r  rquire dfferent language skill than es ifficlt ones. This conclusion raises questions about whether lel B and C tasks actually diffe intheir diffculty and how task difficulty is defined and determined. As noted above, in the most reent version of the DET (2023), writing task prompts, including PD tasks, are assigned to est takers randomly, rather than based on task dificult. The findings of this study validate this decision, as they do not substantiate the assumption that PD tasks with different levels of difficulty affect test takers' writing performance differently.

Third, differences in test-takers overallLP were sgnificantly asociatd with differences in ther writing grades and the linguistic characterisics f their written responses. As expected, test-takers with higher ELP performed beter than did tes-takers with lower ELP. Generally, they wrote significantly longer responses with significantl fewer linguistic erors that obtained significantly higher writing grades than did test-takers with lower ELP. Additionally, the responses of test-takers with higher ELP tended to have higher clausal complexity (i.e., higher MLC), lower complexity by subordination (DC/C), fewer nouns and pronouns, and more articles, prepositions, and sophisticated words than did the responses of low-ELP test takers. These indings generally support assumption $^ { b }$ in Fig. 2 and are consistent with previous studies that found that more proficient test takers tend to write longer responses, use more complex vocabulary and structures, and make fewer language errors than their essproficient counterparts (e.g., umming et a., 005; Gebril & Plakans, 2013). In the current study, more proficient tst takers tended to use more complex clauses but t rely less on complexity by subordination (DC/C) and to use fewer nouns and pronouns than did low-proficiency test takers.

Table 6 Functions at Group Centroids.   

<html><body><table><tr><td rowspan="2">Writing grade Level</td><td colspan="2">Function</td></tr><tr><td>1</td><td>2</td></tr><tr><td>1</td><td>-1.47</td><td>0.19</td></tr><tr><td>2</td><td>-0.16</td><td>-0.25</td></tr><tr><td>3</td><td>1.02</td><td>0.12</td></tr></table></body></html>

![](img/3bd1994f0e8aa26dbb602d64d66d41330638237932466b17e4b3fddf36478a06.jpg)  
Fig. 3. Centroids of Writing Grade Levels on two Functions.

Table 7 Correlations between Writing Features and Writing grades by Task Difficulty Level.   

<html><body><table><tr><td></td><td colspan="3">Task Difficulty Level</td></tr><tr><td></td><td>Both Levels</td><td>Level B</td><td>Level C</td></tr><tr><td>Fluency</td><td></td><td></td><td></td></tr><tr><td>Number of Words</td><td>.61**</td><td>.61**</td><td>.61**</td></tr><tr><td>Linguistic Accuracy</td><td></td><td></td><td></td></tr><tr><td>Grammatical Errors</td><td>-.32**</td><td>-.32**</td><td>-.33**</td></tr><tr><td>Lexical Errors</td><td>-.22**</td><td>-.23**</td><td>-.20**</td></tr><tr><td> Mechanics Errors</td><td>-.32**</td><td>-.34**</td><td>-.29**</td></tr><tr><td>Syntactic Complexity</td><td></td><td></td><td></td></tr><tr><td>Clauses per sentence</td><td>.01</td><td>-.02</td><td>.04</td></tr><tr><td>Dependent clauses per clause</td><td>-.01</td><td>.03</td><td>-.04</td></tr><tr><td>Mean length of clause</td><td>.14**</td><td>.14**</td><td>.15**</td></tr><tr><td>Mean length of sentence</td><td>.14**</td><td>.14**</td><td>.15**</td></tr><tr><td>Parts of Speech</td><td></td><td></td><td></td></tr><tr><td>Nouns &amp; Pronouns</td><td>.12**</td><td>-.10**</td><td>-.14**</td></tr><tr><td>Adjectives</td><td>.06*</td><td>.04</td><td>.09*</td></tr><tr><td>Adverbs</td><td>.07**</td><td>.02</td><td>.12**</td></tr><tr><td>Verbs</td><td>-.01</td><td>-.07</td><td>.05</td></tr><tr><td>Articles</td><td>.13**</td><td>.15**</td><td>.10**</td></tr><tr><td>Prepositions</td><td>.13**</td><td>.16**</td><td>.10*</td></tr><tr><td>Lexical Complexity</td><td></td><td></td><td></td></tr><tr><td>Lexical density</td><td>.01</td><td>-.03</td><td>.03</td></tr><tr><td>Average Word Length</td><td>.21**</td><td>.19**</td><td>.22**</td></tr></table></body></html>

Fourth, the findings confirm that differences in the linguistc characteristics of test-takers' written responses are associated with differences in their writig grades. Speifical, reponse at different grade levels differed significantly on most of the linguistic features examined in the study. DFA identified two dimensions along which responses at different grade levels varied: one that distinguishes between the three grade levels and includes fluency, accuracy, and lexical sophistication, and one that distinguishes between grade levels 2 and 3 and includes fluency, mechanics and grammatical eror ratios, and incidence of adjectives and adverbs. The association between linguistic fatures and grade level did not vary cross task diffculty levels, indcating that the same featres are associated with writing grade levels regardess of task difficulty level. Overall level 3 responses were significantly longer, included significantly fewer errors, had higher lexical sophistication than did level 2 responses. The latter were, in turn, significantly longer, included significantl fewer errs, had higher lexcal sophistication than did level 1 responses. Additionall, lel 3 responses had a significantly higher clausal complexity and incidence of advers and artices than did level 2 responses, while level 1 responses had significantly lower global complexity and incidence of prepositions and higher incidence of nouns and pronouns. Finll, correlation analyses indicated that fluency has the strongest association with writing grades, followed by accuracy and lexical sophistication. These findings indicate that the DET scoring procedures do capture variation in the linguistic aspects that the DET intends to ases.

Taken together, these findings support assumptions $d$ and $g$ in Fig. 2 and are consistent with other studies (e.g., Banerjee et al., 2007; Cumming et l., 205; Gebril & Plakans, 2009, 2013; Knoch et al., 2014; Riazi & Knox, 2013; Wolf et al., 2018). Most previous studies found that text length is the strongest predictor of writing scores (e.g., Crossey & McNamara, 2016; Cumming et al., 2005; Riazi & Knox, 2013; Wolfe-Quintero et al., 1998). Crossley and McNamara (2016) argued that this is the case because text length is closely associated with text development. Linguisic accuracy and complexty have also been found to be significantly associated with writing scores. Riazi and Knox (2013), for example, found that IELTS scripts with higher scores tended to be longer and to use more complex vocabulary and syntactic structures than did low-scoring esays. Baneree et al. (2007) found that grammaticalaccuracy and lexical sophistication were significanly assciated with IELS writing scores. Like this study, Banerjee et al. aso found that different linguistic features were more alient at different core levels. Similarl, Gebril & Plakans (209, 2013) found that different linguistic features distinguished responses at different score levels. Gebril and Plakans (2013) speculated that this might be because different linguistic features (and their interactions) may influence writing scores at different levels differentl, with some influencing writing scores at the lower level more than at higher levels and vice versa. It should be noted here that the two DFA functions correctly classifed only two thirds of the responses in the study and were more successful in classfying high scoring responses (three quarters for grade leve3than ow cori eons lightly more than half for grde le1). One son for this i that the linguistic features examined in this study do not cover allthe criteria used in the  rating cale, since task releance was not included. t is als ossible that adding other writing features not examined in this study, such as connections between ideas and sentence, might improve the accuracy of the classification.

Fifth, test taker hd significant effects on test takers comprehnsion scores and wrting grades and the linguistic feature oftheir responses to the DET PD task, a finding that challenges assumption c in Fig. 2. Overall, the English speakers had the highest comprehension score, followed y the Spanish, Mandarin, and Arabic speakers, sugesting that the four 1 groups differed in terms of their overall ELP. The Mandarin group had significantly higher writing grades than did the Arabic and Spanish groups. L1 had significant smal effct on response length, global and clausal complexity, the incidence of nouns and pronouns and verbs, and lexical density and sophistication. For example, compared to the other L1 groups, the English group used significantly more sophisticated words, while the Spanish group wrote significantl longer responses that included significantly more vers and had significantl higher global complexity and significantly lower clausal complexity and lexical density. While the significant differences in overall ELP between the four  groups can explain why they differed in their writing performance, L1 effects were generall independent of differences in ELP as indicated by the non-significant L1-b-ELP interaction effecs. It should be noted here that other studies on other writing ts such as the o found sinficant differene inthe iitc chractristics of reons wite  tet takers from different L1 backgrounds (e.g, Banerjee et al., 2007; Riazi & Knox, 2013). So, the finding that tests takers from different 1 backgrounds varied in terms of the linguistic characteristics of their responses to the DET PD tass is not surprising. 1 may be a proxy for other variables that are associated with writing ability but were not measured in this study such as education background, literacy skills, and student writing experience and motivation. As such, differences in writing grades and feature aross 1 groups might be construct-relevant. Finally, gender did not have significant effcts on comprehension and writing grades, but female test-takers produced significantly longer descriptions than did their male counterparts. This finding provides partial support fr assumption c in relation to gender effects on test taker performance.

Sixth, the findings indicated that, except for grammatical error ratio, which varied significantly acrosstasks within tas difficulty level C, tass nt thin sk dict eld nt aet therens cre or listic charactristic. Hwr, ifferences in grammatical accuracy acros tasks nested within task difficulty level C were not associated with significant differences in writing grades across these tasks. This finding supports assumption $f$ in Fig. 2, i.e., that performance on the DET PD tasks is not affected by variation in the content and/or characteristics of PD tas that are nested within the same task dificulty level and, so, assumed to be comparabl. Adtionally, the lingistic feres associated with writing grades dd not vary acros task difficulty leel, a finding that supports assumption $^ { g , }$ i.e., that the criteria for evaluating performance on the PD tasks do not vary depending on task difficulty level.

# 5.1. Limitations and implications

One issue the findings highlighted is that responses to the DET PD task tend to be very short. Although tes takers taking the DET must respond to hree PD tasks and one independent task with a written prompt that requires a longer response (50 words or more,the PD task o not em to elicit a ufficient sample to judget takers witing abilitie. The short reonses preented seeral chllenges for analysing the data. For example, it was not possible to analyse the responses in this study in terms of important writing features such as coherence and cohesion. Addtionally, as noted above, the limited length of the responses might have affcted the accuracy of some of the measures used in the study. As a result, the findings above need to be interpreted with caution.

One possible reason the PD tasks elicited short responses may have to do with the number and content of the pictures included in the task. For example, each of the PD tasks in Fig. 1 above includes one picture that shows a person or an animal in a particular state. rather than multiple pictures showing  story or an activity. It may be ifficult for  leners, particularly during a timed test, to think of what to write aout the picture other than a single, simple sentence that names the object and decribes some of its visible attributes (e.g., gender, color, shape). To elicit longer responses, it may be necessary to encourage test takers to spend more time on the PD task and to include multiple pictures that show an activity, a process and/or a series of events (e.g., a story) that can be described in some detail Such pictures could prompt not only longer responses but also the use of more complex language and other important writing features (e.g., coherence, register, text organization).

Another isue is that fluency (response length) and inguistic accuracy were the strongest predictors of writing grades suggesting that response length, and to some extent linguistic accuracy, play a major role in determining the DET writing grades. This is n issue with most writing asessments that use automated scoring systems (e.g., Chodorow & Burstein, 2004), although text length is one of the strongest predictors of human ratings as wel, perhaps because response length can be an indicator of text development or \*the amount of content that a response] contains" to (Crossey & McNamara, 2016, p. 354). Another possible explanation is that the PD task elicits short responses that do not allow the examination or evaluation of other aspects of writing than response length and accuracy. Revising the PD task, as discussed above, can help alleviate this problem.

A third issue is that the written responses in this study were analysed primarily in terms of their inguistic characteristics using computer programs. No manual or qualitative coding, analysis or rating were done, given the large corpus in the study. However this means that the analyses did not consider some important aspects of writing such as the type, amount, relevance, qualit, coherence, and accuracy of information conveyed in the responses. King and Dickinson (2018), for example, analyzed picture descriptions in terms of several content-related features, such as core event (Does the response capture the core event depicted in the image?"), verifiabilit ("Does the response contain only information that istrue and verifiable based on the image?), and interpretability ("Does the response evoke a clear mental image, even if dfferent from the item image?") (p.104). These questions are closely related to task relevance, one of the criteria on the DET rating scale that was not included in this study. The exclusion of this and other important writing feature (e.g., cohesion) might explain why the two DFA functions were able to successfull classify only tow thirds of the responses in this study. Consequently, future analyses could involve the manual analysis of the longest responses in the corpus to examine whether, for example, the picture descriptions include details that are centrally relevant to the theme of the picture, how the details are organized, whether rrelevant or incorrect infomation is included, and what stance the writers adopt towards what is being described (e.g., doubt, concern), (cf. Coker, 2006; Hemphill et al., 1994; King & Dickinson, 2018; Schleppegrell, 1998).

A final concen pertains to the potential substntial variabilit in the linguistic features f the responses i this study acros picture prompts. As noted earlier, the 1439 test takers in this study responded to 335 prompts from the 2020 version of the DET, with an average of approximately four testakers responding to each prompt. I i posible that the variation across prompts inluenced the linguistic features of the responses. Unfortunately, due to the limited number of test takers per prompt, it was not feasible ostatistically model prompt effct n the linguistic indices examined in this study. o address this limitation, future studies could include multiple prompts, each with a large number of responses, and use multilevel modeling to examine the efects of picture prompts on variability in the linguistic characteristics of test takers' responses.

Further studies could also examine theffects of task and test taker variable i.., task difficulty, test taker ELP, L1, and gnder on the strength of the associations between the linguistic characteristics of est takers responses to PD tasks and their writing grades using multilel modeling. Furthermore, to beter understand the efects of these variables on test takers' performance on the DET PD writing tasks, future studie should examine the writing processes egaged by the DET PD tasks; whether and how these processes vary across task difficulty lels and test-taker ELP levels; and how performance on the DET PD tasks compare to performance on non-test real life tasks. Such research can shed more light on some of the key assumptions underlying the extrapolation inference of the DET validity argument.

# CRediT authorship contribution statement

Barkaoui Khaled: Conceptualization, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Resources, Software, Supervision, Validation, Visualization, Writing - original draft, Writing - review & editing.

# Data availability

The authors do not have permission to share data.

# Acknowledgements

I would like to thank Rahim Dhupalia for heling with the cleaning, preparation, and organization of the data files, and for conducting the computer analyse of the texts in the study; and Ruobing Li and Shuyao Xu for conducting error analyes for the study. This study was funded by a Duolingo English Test Research Grant. However, the opinions expressed in the paper are those of the author.

Appendix. : Test statistics for significant pairwise comparisons

Table A Statistics for Significant Pairwise Comparisons by L1 Group.   

<html><body><table><tr><td rowspan="2"></td><td colspan="2">L1 Groups</td><td rowspan="2"></td><td rowspan="2">SE</td><td rowspan="2">Sig</td><td colspan="2">95% CI for Difference</td></tr><tr><td>Group 1</td><td>Group 2 Mean Difference</td><td>Lower Bound</td><td>Upper Bound</td></tr><tr><td>Writing grades</td><td> Mandarin</td><td>Arabic</td><td>0.60</td><td>0.13</td><td>0.00</td><td>0.26</td><td>0.95</td></tr><tr><td rowspan="3">Length</td><td rowspan="3"> Spanish</td><td> Spanish</td><td>0.62</td><td>0.09</td><td>0.00</td><td>0.37</td><td>0.87</td></tr><tr><td>Arabic</td><td>2.13</td><td>0.63</td><td>0.00</td><td>0.46</td><td>3.80</td></tr><tr><td>English</td><td>1.70</td><td>0.53</td><td>0.01</td><td>0.29</td><td>3.10</td></tr><tr><td rowspan="4">Mechanics Errors</td><td rowspan="3">Mandarin</td><td> Mandarin</td><td>1.80</td><td>0.41</td><td>0.00</td><td>0.73</td><td>2.88</td></tr><tr><td>Arabic</td><td>-0.14</td><td>0.04</td><td>0.00</td><td>-0.25</td><td>-0.03</td></tr><tr><td>English</td><td>-0.11</td><td>0.03</td><td>0.01</td><td>-0.20</td><td>-0.02</td></tr><tr><td></td><td></td><td></td><td>0.03</td><td>0.00</td><td>-0.20</td><td>-0.04</td></tr><tr><td rowspan="3">c/S</td><td> Spanish</td><td>Spanish Arabic</td><td>-0.12 0.40</td><td>0.09</td><td>0.00</td><td>0.18</td><td>0.63</td></tr><tr><td></td><td>English</td><td>0.30</td><td>0.07</td><td>0.00</td><td>0.11</td><td>0.49</td></tr><tr><td></td><td>Arabic</td><td>0.270</td><td>0.077</td><td>0.003</td><td>0.067</td><td>0.473</td></tr><tr><td rowspan="3">MLC Nouns &amp; Pronouns</td><td>Mandarin English</td><td> Spanish</td><td>1.082</td><td>0.335</td><td>0.007</td><td>0.198</td><td>1.966</td></tr><tr><td> Mandarin</td><td>English</td><td>-0.25</td><td>0.06</td><td>0.00</td><td>-0.40</td><td>-0.11</td></tr><tr><td></td><td>Arabic</td><td>-0.23</td><td>0.07</td><td>0.01</td><td>-0.41</td><td>-0.05</td></tr><tr><td>Verbs</td><td>Arabic</td><td> Spanish</td><td>-0.20</td><td>0.06</td><td>0.00</td><td>-0.36</td><td>-0.05</td></tr><tr><td>Lexical Density</td><td>English</td><td>Spanish</td><td>0.02</td><td>0.01</td><td>0.00</td><td>0.01</td><td>0.04</td></tr><tr><td rowspan="2">AWL</td><td>English</td><td> Mandarin</td><td>0.18</td><td>0.04</td><td>0.00</td><td>0.08</td><td>0.28</td></tr><tr><td></td><td> Spanish</td><td>0.14</td><td>0.04</td><td>0.01</td><td>0.02</td><td>0.26</td></tr></table></body></html>

Table B Statistics for Significant Pairwise Comparisons by Writing grade Level.   

<html><body><table><tr><td rowspan="2">Linguistic Feature</td><td colspan="2">Grade level</td><td rowspan="2">Mean Difference</td><td rowspan="2"></td><td rowspan="2"></td><td colspan="2">95% CI for Difference</td></tr><tr><td>Level 1</td><td>Level 2</td><td>Sig Lower Bound</td><td>Upper Bound</td></tr><tr><td rowspan="3">Length</td><td>1</td><td>2</td><td>-4.12</td><td>0.39</td><td>0.00</td><td>-5.05</td><td>-3.18</td></tr><tr><td>2</td><td>3</td><td>-9.57</td><td>0.38</td><td>0.00</td><td>-10.49</td><td>-8.65</td></tr><tr><td></td><td>3</td><td>-5.45</td><td>0.34</td><td>0.00</td><td>-6.26</td><td>-4.64</td></tr><tr><td rowspan="3">Grammatical Errors</td><td>1</td><td>2</td><td>0.29</td><td>0.03</td><td>0.00</td><td>0.21</td><td>0.38</td></tr><tr><td></td><td>3</td><td>0.42</td><td>0.03</td><td>0.00</td><td>0.34</td><td>0.50</td></tr><tr><td>2</td><td>3</td><td>0.13</td><td>0.03</td><td>0.00</td><td>0.06</td><td>0.20</td></tr><tr><td rowspan="3">Lexical Errors</td><td>1</td><td>2</td><td>0.10</td><td>0.02</td><td>0.00</td><td>0.05</td><td>0.15</td></tr><tr><td></td><td>3</td><td>0.16</td><td>0.02</td><td>0.00</td><td>0.11</td><td>0.21</td></tr><tr><td>2</td><td>3</td><td>0.06</td><td>0.02</td><td>0.00</td><td>0.02</td><td>0.10</td></tr><tr><td rowspan="3">Mechanics Errors</td><td>1</td><td>2</td><td>0.25</td><td>0.03</td><td>0.00</td><td>0.17</td><td>0.32</td></tr><tr><td>2</td><td>3</td><td>0.34</td><td>0.03</td><td>0.00</td><td>0.27</td><td>0.41</td></tr><tr><td></td><td>3</td><td>0.09</td><td>0.03</td><td>0.00</td><td>0.03</td><td>0.16</td></tr><tr><td rowspan="3">MLC</td><td>1</td><td>3</td><td>-1.45</td><td>0.26</td><td>0.00</td><td>-2.08</td><td>-0.83</td></tr><tr><td>2 1</td><td>3</td><td>-0.76</td><td>0.23</td><td>0.00</td><td>-1.31</td><td>-0.21</td></tr><tr><td></td><td>2</td><td>-1.15</td><td>0.38</td><td>0.01</td><td>-2.05</td><td>-0.24</td></tr><tr><td rowspan="2">Nouns and Pronouns</td><td>1</td><td>3</td><td>-2.01</td><td>0.37</td><td>0.00</td><td>-2.90</td><td>-1.12</td></tr><tr><td></td><td>2</td><td>0.16</td><td>0.05</td><td>0.00</td><td>0.04</td><td>0.28</td></tr><tr><td rowspan="2">Adjectives</td><td>2</td><td>3</td><td>0.21</td><td>0.05</td><td>0.00</td><td>0.09</td><td>0.33</td></tr><tr><td></td><td>3</td><td>-0.10</td><td>0.03</td><td>0.01</td><td>-0.18</td><td>-0.02</td></tr><tr><td>Adverbs</td><td>2</td><td>3</td><td>-0.08</td><td>0.03</td><td>0.01</td><td>-0.15</td><td>-0.02</td></tr><tr><td rowspan="2">Articles</td><td>1 2</td><td>3</td><td>-0.14</td><td>0.04</td><td>0.00</td><td>-0.23</td><td>-0.06</td></tr><tr><td></td><td>3</td><td>-0.10</td><td>0.03</td><td>0.00</td><td>-0.18</td><td>-0.03</td></tr><tr><td rowspan="3">Prepositions</td><td>1</td><td>2</td><td>-0.19</td><td>0.04</td><td>0.00</td><td>-0.28</td><td>-0.09</td></tr><tr><td>1</td><td>3</td><td>-0.22</td><td>0.04</td><td>0.00</td><td>-0.32</td><td>-0.13</td></tr><tr><td></td><td>2</td><td>-0.15</td><td>0.03</td><td>0.00</td><td>-0.23</td><td>-0.07</td></tr><tr><td rowspan="3">AWL</td><td></td><td>3</td><td>-0.27</td><td>0.03</td><td>0.00</td><td>-0.36</td><td>-0.19</td></tr><tr><td>2</td><td>3</td><td>-0.12</td><td>0.03</td><td>0.00</td><td>-0.20</td><td>-0.05</td></tr></table></body></html>

# References

Reports, 7(5), 1-69.   
Boers, F. (2018). Picture prompts and some of their uses. Language Teaching Research, 22(4), 375-378.   
Bryant  ier 1c ion an  f t ori  of eg f theo r sic  Pa  5.er or tostc aae a (https://www.aclweb.org/anthology/P17-1074).   
s  4 Available at: (https://duolingo-papers.s3.amazonaws.com/other/det-assessment-ecosystem.pdf).   
Cde,,   r, . c ,2ish t  . e a /is.cm/ other/technical_manual.pdf).   
Chaell  208. t  , iht  .)   fo the t o s s a Foreign Language (pp. 319-352). New York: Routledge.   
Chodorow, M, & Bursein, J. (2004). Beyond esay ength: alating atrs pefmance on EFL essys. S Rearch Rrt Sries, 204(1). -38.   
Cohen, J. (1969). Statistical Power Analysis for the Behavioral Sciences. New York: Academic Press.   
Cer   f     , , 471-488.   
Coer, DL 012)ii wing ir i  P .),    of  tie . 15972.  ork Psychology Press.   
Crossey, .  & Mcamara, .. 2016). ay more ad be more coherent How text eabortion and cohesion can ince witing qualit. Jonal f Wriing Research, 7(3), 351-370.   
a y   J00f      r next generation TOEFL. Assessing Writing, 10, 5-43.   
De     1).   f r r i e Processes, 14, 469-495.   
Dulingo,201. ls of t ig d iit or thingish et. aableine 2 t  s of  aniaiity 12-14-2020 (d23cwzsbkjbm45.cloudfront.net).   
Duolingo,2023. Duolingo English Test Official Guide 2023. Duolingo. (https://englishtest.duolingo.com/prepare/guide).. 26(1), 59-84.   
Gei      , Foreign Language Assessment, 7(1), 47-84.   
Geril,  Pla 13 t f te  th ne  i. e Assessment Quarterly, 10(1), 9-27.   
asi .  np t h  k design. Language Learning, 51(3), 401-436. Building Educational Applications (pp. 101-109). New Orleans, Louisiana: Association for Computational Linguistics.   
Knoch, U., & Chapelle, C. A. (2018). Validation of rating proceses within an argument-based framework. Language Testing, 35(4),47-499. Writing test (TOEFL iBT Report No. 23, ETS Research Report No. RR-14-43). Princeton, NJ: Educational Testing Service.   
yle ,2016. ering yctic nt in  witing Fin nd n f sctic omplxt and ud ndes of ytic shistication (Doctoral Dissertation).   
LaFr       a manual-current.pdf).   
LaFlair, G.T.,2020. Duolingo English Test: Subscores [White paper]. Duolingo, Inc. https://doi.org/10.46999/wBQ14443.   
Li, J. (2018.tlisng mpait r wting s th te prms of tet s e  Qrl, 15(4), 368386.   
Lu, X. (2010). Automatic analysis f yntactic complexity i second language writing. Inenational Journl of Corpus ingustic, 15, 474 496.   
Lu, X. (2012). The relationship of lexical richnes to the quality of ESL learners oral narratives. The Moden Language Jounal, 96, 190-208. (pp. 50-68). New York: Routledge.   
Qi,  (019 - ie    r Applied Linguistics in Language Teaching, 60(2), 383-409.   
Rizi  3tt tWriting Test. Task 2. In IELTS Research Reports vol. 2 (pp. 1-89). IELTS Australia and British Council. doi.org/10.1016/j.edurev.2010.12.001   
Sato 0 n    g Research, 22(4), 398-417.   
Schleppegrell M. J. (1998). Grammar as resource: writing a description. Research in the Teaching of English, 32(2), 182-211.   
Wagner, E., & Kunnan, A. J. (2015). The Duolingo english test. Language Assessment Quarterly, 12(3), 320-331.   
Wer C , . . 20. iin es fo  vil s aity a c  of c akn et  tin 3(2, 167-19.   
Wlf, MK, h, ., Wan, & tawa,  . 2018). oung eent  stnt witig skll dement Inights from aset dt. gue Assessment Quarterly, 15(4), 311-329.   
ole ki,   .       f,     it Hawaii.   
Wu H      (194).  nnk" i oa ois nd French under varying instructions. Discourse Processes, 18(2), 141-164.   
, .   0 i ttie of NLP for Building Educational Applications (pp. 149-158). Available at: (htps:/www.aclweb.org/anthology/W19- 4415.pdf).   
Xu, ., ,  012).-kn r  -ta w t a  st  12.ig 17(3 174190. ECPE. Language. Testing, 37(2), 189-214.

Khald Bai    t ot    d     (2) assessment, L2 writing, L2 program evaluation, longitudinal and mixed-methods research, and English for Academic Purposes (EAP).