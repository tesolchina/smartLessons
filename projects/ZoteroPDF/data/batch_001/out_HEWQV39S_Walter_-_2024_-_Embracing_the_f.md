# Embracing the future of Artifcial Intelligence in the classroom: the relevance of AI literacy, prompt engineering, and critical thinking in modern education

Yoshija Walter1

\*Correspondence: yoshija.walter@gmail.com; yoshija.walter@kalaidos-fh.ch

1 Kalaidos University of Applied Sciences, Jungholzstrasse 43, 8050 Zurich, Switzerland

# Abstract

The present discussion examines the transformative impact of Artifcial Intelligence (AI) in educational settings, focusing on the necessity for AI literacy, prompt engineering profciency, and enhanced critical thinking skills. The introduction of AI into education marks a signifcant departure from conventional teaching methods, ofering personalized learning and support for diverse educational requirements, including students with special needs. However, this integration presents challenges, including the need for comprehensive educator training and curriculum adaptation to align with societal structures. AI literacy is identifed as crucial, encompassing an understanding of AI technologies and their broader societal impacts. Prompt engineering is highlighted as a key skill for eliciting specifc responses from AI systems, thereby enriching educational experiences and promoting critical thinking. There is detailed analysis of strategies for embedding these skills within educational curricula and pedagogical practices. This is discussed through a case-study based on a Swiss university and a narrative literature review, followed by practical suggestions of how to implement AI in the classroom.

# Introduction

In the evolving landscape of education, the integration of Artifcial Intelligence (AI) represents a transformative shift, stipulating a new era in learning and teaching methodologies. Tis article delves into the multifaceted role of AI in the classroom, focusing particularly on the primacy of prompt engineering, AI literacy, and the cultivation of critical thinking skills.

Te advent of AI in educational settings transcends mere technological advancement, reshaping the educational experience at its core. AI’s role extends beyond traditional teaching methods, ofering personalized learning experiences and supporting a diverse range of educational needs. It enhances educational processes, developing essential skills such as computational and critical thinking, intricately linked to machine learning and educational robotics. Furthermore, AI has shown signifcant promise in providing timely interventions for children with special educational needs, enriching both their learning experiences and daily life (Zawacki-Richter et al., 2019). However, integrating AI into education is not without its challenges. It requires a systematic approach that takes into account societal structural conditions. Beyond algorithmic thinking, AI in education demands a focus on creativity and technology fuency to foster innovation and critical thought. Tis requires a paradigm shift in how education is approached in the AI era, moving beyond traditional methods to embrace more dynamic, interactive, and student-centered learning environments (Chiu et al., 2023).

Tis article sets the stage for a comprehensive exploration of AI’s role in modern education. It underscores the need for an in-depth understanding of prompt engineering methodologies, AI literacy, and critical thinking skills, examining their implications, challenges, and opportunities in shaping the future of education. Whereas previous papers have already hinted at the importance of recognizing the relevance of AI in the classroom and suggested preliminary frameworks (Chan, 2023), the present discussion claims that there are three prime skills necessary for the future of education in an AI-adopted world. Tese three skills are supplanted with practical application advice and based on the experience of lecturers at a University of Applied Sciences. As such, the present paper is a conceptual discussion of how to best integrate AI in the classroom, focusing on higher education. While this means that it may predominantly be relevant for adult students, it is believed that it may be useful for children as well.

# Methodological remarks

Te current paper entails a conceptual discussion about the proper use of AI in terms of the necessary skillset applied. It is based on a two-step approach:

a. Among others, it is based on intense informal discussions with students and lecturers at a Swiss University of Applied Sciences, as well as the present author’s teaching experience at this school. Woven together, this leads to a case study for an outlook of how a necessary skillset of AI use in the educational setting may be benefcially honed. Tere are some open questions that emerge from this, which can be addressed by fndings from the literature.   
b. Upon the discussion of the real-life case in the university, the need for further clarifcations, answers and best practices is then pursued by a narrative literature review to complete the picture, which eventually leads to practical suggestions for higher education.

Te informal discussions with students and personnel were unstructured and collected where feasible in these early days of AI use to gather a holistic and trustworthy picture as possible about the explicit and implicit attitudes, fears, chances, and general use of the technology. Hence, this included teacher-student discussions in classroom settings with several classes where students were asked to voice their ideas in the plenum and in smaller groups, individual discussions with students during the breaks, lunch talks with professors and teachers, as well as gathering of correspondence about the topic in the meetings that were held at the university. Taken together, this provided enough information to weave together a solid understanding of the present atmosphere concerning attitudes and uses of AI.

# The emergence of AI in education

Te introduction of ChatGPT (to date one of the most powerful AI chatbots by OpenAI) in November 2022 is signifcantly transforming the landscape of education, marking a new era in how learning is approached and delivered. Tis advanced AI tool has redefned educational paradigms, ofering a level of personalization in learning that was previously unattainable. ChatGPT, with its sophisticated language processing capabilities, is quickly becoming a game-changer in classrooms, to provide tailored educational experiences that cater to the unique needs, strengths, and weaknesses of each student. Tis shift from traditional, uniform teaching methods to highly individualized learning strategies will most likely signify a major advancement in educational practices (Aristanto et  al., 2023). ChatGPT’s role in personalizing education is particularly noteworthy. By analyzing student data and employing advanced algorithms, GPT and other Large Language Models (LLMs) can create customized learning experiences, adapting not only to academic requirements but also to each student’s learning style, pace, and preferences. Tis leads to a more dynamic and efective educational environment, where students are actively engaged and involved in their learning journey, rather than being mere passive recipients of information (Steele, 2023). Furthermore, LLMs have shown remarkable potential in supporting students with special needs. Tey provide specialized tools and resources that cater to diverse learning challenges, making education more accessible and inclusive (Garg & Sharma, 2020). Students who might have found it difcult to keep up in a conventional classroom setting can now beneft from AI’s ability to tailor content and delivery to their specifc needs, thereby breaking down barriers to learning and fostering a more inclusive educational atmosphere (Rakap, 2023). In all of this, the integration of language models like GPT into educational systems is not just a mere enhancement but has the potential to become an integral part of modern teaching and learning methodologies. While adapting to this AI-driven approach presents certain challenges, the benefts for students, educators, and the educational system at large are substantial (for in-depth reviews, see Farhi et  al., 2023; Fullan et  al., 2023; OttenbreitLeftwich et al., 2023). ChatGPT in education can be a signifcant stride towards creating a more personalized, inclusive, and efective learning experience, preparing students not only for current academic challenges but also for the evolving demands of the future.

However, the many precious possibilities in positively transforming the education systems through AI also comes with some downsides. Tey can be summarized in several points (Adiguzel et al., 2023; Ji et al., 2023; Ng et al., 2023a, 2023b, 2023c; Ng et al., 2023a, 2023b, 2023c):

1. Teachers feeling overwhelmed because they do not have much knowledge of the technology and how it could best be used.   
2. Both teachers and students not being aware of the limitations and dangers of the technology (i.e. generating false responses through AI hallucinations).   
3. Students uncritically using the technology and handing over the necessary cognitive work to the machine.   
4. Students not seeking to learn new materials for themselves but instead wanting to minimize their eforts.   
5. Inherent technical problems that exacerbate malignant conditions, such as GPT-3, GPT-3.5 and GPT-4 mirroring math anxiety in students (Abramski et al., 2023).

In order for all parties to be best prepared for using AI in education, based on a case study and a subsequent literature analysis, there are three necessary skills that can remedy these problems, which are AI literacy, knowledge about prompt engineering, and critical thinking. A more detailed analysis of the challenges is discussed, followed by suggestions for practical applications.

# Case study at a swiss educational institution

# The educational difculty of AI in academic work

Te present case study deals with the introduction and the handling of Artifcial Intelligence at the Kalaidos University of Applied Sciences (KFH) in Zurich, Switzerland. To date, KFH is the only privately owned university of applied sciences in the country and consists of a departement of business, a department of health, a department of psychology, a department of law, and a department of music.  Since the present author has a lead position in the university’s AI-Taskforce, he has frsthand and intimate knowledge about the benefts and challenges that arose in the past year when AI chatbots suddenly became much more popular, including the fears surrounding this topic by both staf and students.

Like many other universities, KFH has had signifcant challenges with fnding an adequate response to the introduction of ChatGPT and its following adoption by students, lecturers, and supervisors. It was deemed important by the AI-Taskforce as well as the school’s leadership that there was going to be a nuanced approach towards handling the new technology. Whereas some institutions banned LLMs right away, others embraced them wholeheartedly and barely enforced any restrictions in their use. KFH was eager to fnd some middle ground since it seemed clear to the leadership that both extremes may be somewhat problematic. Te major reasons are summarized in Table 1.

# The quest for a middle ground

Discussions with students in the classroom at KFH have shown that one year after the introduction of ChatGPT, only few have not yet used it. Te general atmosphere is that they are enthusiastic about the new AI that can help them with their workload, also the ones due in the classroom and the help they get to write their papers. However, students are also keenly aware that it is “just a machine” and that there should be some practical and ethical principles that ought to be abided by. Tey name the following reasons:

1. Te use of AI should be fair, as in that no student is at an unfair advantage or disadvantage. 2. It should be clear how the expectations of the school look like so that students know exactly what they are allowed and what they are not allowed to do.

Table 1 Central issues with banning or unrestricting AI at schools   

<html><body><table><tr><td></td><td>Prohibit the use of Al for students.</td><td>Allowing unrestricted use of Al for students</td></tr><tr><td>Core idea</td><td>Upon the introduction of ChatGPT and comparable Al models, some educational institutions have banned their use for students&#x27; their students to use them for their academic theses and papers There are some strong reasons to prohibit the use of Al in academic papers:.</td><td>Upon the introduction of capable LLMs such as ChatGPT, some institutions have fully allowed papers and tasks with no or only little limitations There are some arguments leading educators to wholeheartedly accept the full and mostly</td></tr><tr><td>Key reasons</td><td>: Students are often poorly trained in how to use these systems . There is a high risk that students do not&quot;think for themselves&quot; anymore and hand over the work to machines . Evaluating what is the proper work of the student and what is the work of an Al is mostly impossible . There are manifest technical problem such as Al hallucinations leading to the models invent- - The more students are sheltered from the ing things that may not be true</td><td>unrestricted use of Al by their students: . It is the job of educators to teach students how to use new technologies : Handing full responsibility to students may be the only way to help them learn to deal with the benefits and challenges of AI. : Al models will become integrated in all spheres of academia, the job market, and daily lives, and as such will be inescapable full scope of Al, the less they might learn its responsible use : Al is here to stay and hence sooner or later must be dealt with</td></tr><tr><td></td><td>Key problems The major problems with prohibiting Al in the work of students is twofold: (1) It is almost impossible for the school to control and make sure that students do not in fact use these sys- tems. Very often, disallowing something with a. high demand creates illegal use. (2) Also, since the technology will most likely be integrated into all aspects of people&#x27;s lives, it would be valuable to learn its proper and responsible use through the help of their educators</td><td>Even if educators provide very generous guide- lines and best practices, the incentive to hand over the heavy load of one&#x27;s cognitive work to the computer may be very high. This leads to three main problems: (1) It is not clear if stu- dents have learned anything. (2) It is challeng- ing to discern if students in fact did any of the cognitive work themselves and how this should be graded (after all, it is neither fun nor useful for teachers to grade a text purely or mostly written by ChatGPT). (3) And it is almost impossible for evaluators to make sure that students did not fall prey to any of the hallucinatory problems that arise from an LLM</td></tr></table></body></html>

3. Many feel that they do not know enough about the potentials and limitations of these systems, so some are afraid to use it incorrectly.   
4. Te problems of AI hallucinations and misalignment are still not widely known: Many students are still surprised to learn that AI can make up things that may not be true while sounding highly convincing.   
5. Some of the students having a clear understanding of the hallucinatory AI problems still feel ill equipped to deal with them.

As such, KFH has the intent to help its students to learn to deal with AI in a responsible fashion. For the members of the AI-Taskforce and the university’s leadership, this has come to mean that the use of ChatGPT and other LLMs are neither prohibited nor allowed without restrictions. Just exactly how such a framework would look like and could be implemented was subject to intense debate. The final compromise was a document internally labelled as “The AI-Guidelines” (in German: “KI-Leitfaden”) that set the rules and furnished examples of what would be deemed acceptable and unacceptable use of AI for students when they implemented it for their papers. The main gist was to tell students that they are explicitly allowed and encouraged to use the new technology for their work. They should experiment with it and see how they can use the outputs for their own theses. The correct use would be to handle AI not as their tutor, teacher or ghostwriter, but as their sparring partner. Just like with any other human sparring partner, it can provide interesting ideas and suggestions. It may provide some directions and answers that the student might have not thought of. However, at the same time, the sparring partner is not always right and should not be unconditionally trusted. It is also not correct to use a sparring partner’s output as one’s own, which in a normal setting would be considered plagiarism (although according to internal documents, technically speaking, copying an artificially generated text would not be classified as plagiarism, but would be unethical to the same degree). The same is true for how students would be allowed to interact with AI: They should use it if it helps them, but they are not allowed to copy any text ad verbatim and they also must make it clear how exactly they have used it. In making it clear how they have used AI, they must be transparent about the following (and document this in a table in the appendix):

Declaring which model was implemented

Example: OpenAI’s GPT-4 and Dall-E 3, Google’s Bard, or Anthropic AI’s Claude-2.

Explaining how and why it was used

Example:   
Using the LLM to brainstorm about some models as adequate frameworks for the applied research question.

Explaining how the responses of the AI were critically evaluated

Example:   
The results were checked through a literature review to see if the AI’s suggestions were true and made sense.

Highlighting which places in the manuscript the AI as used for

Example: Chapter 2 “Theory” (pp. 10–24).

There were two major motivations for prompting students to declare these points: First, the institution wanted to enforce full transparency on how AI was used. Second, students should become keenly aware that they must stay critical towards an AI’s output and must hence report on how they made sure that they did not fall prey to the classic AI problems (such as hallucinations) as well as to make sure that the work still remains of their own making. This is why we considered our third point in the documentation requirements (the need for critical reflection) our most crucial innovation – something that we did not find in other schools and universities. This led to the formulation of binding guidelines, which is depicted in Table 2.

Table 2 A sketch of the so-called “Guidelines for the Use of Artifcial Intelligence Instruments for Written Papers at the Kalaidos University of Applied Sciences”   

<html><body><table><tr><td></td><td>Article Title and summary.</td></tr><tr><td>1</td><td>Purpose and Scope Outlines the use of Al generative models in academic writing at KFH, emphasizing adherence to scien.</td></tr><tr><td>2</td><td>tific and ethical principles without diminishing student independence Permitted Use of AI</td></tr><tr><td>2.1</td><td>Ethical and Scientific Principles Al use is allowed under strict adherence to ethical and scientific standards. Students must ensure proper handling of sources and maintain transparency about Al use in their work</td></tr><tr><td>2.2</td><td>Permitted Use of AI All types of generative models for image, text, or sound creation are permissible, but transparency in their use and thus documentation in the appendix is required</td></tr><tr><td>2.3</td><td>Creation of Text Material. Direct copy-pasting of Al-generated texts is prohibited. Al should be used as an &quot;informed conversa- tional partner&quot; and critical engagement with Al-generated text is necessary</td></tr><tr><td>2.4</td><td>Creation of Images Use of generative models for image creation is allowed. Images created using Al must be properly credited and documented</td></tr><tr><td>2.5</td><td>Documentation in the Appendix The use of Al in academic writing must be documented in a table in the appendix, specifying the AI tools used, their application, the critical review process, and the location in the manuscript this applies to</td></tr><tr><td></td><td>Prohibited Use of AI Directly using texts from Al or other people as part of academic work is forbidden. This applies to all forms of writing, and any violation will be treated commensurate with plagiarism</td></tr><tr><td>4</td><td>Exceptions Exceptions to these guidelines are possible if the academic assignment specifies different requirements</td></tr><tr><td>5</td><td>Effective Date The guidelines became effective on July 1, 2023, and supplemented existing regulations and guidelines for academic writing at KFH</td></tr></table></body></html>

The German title was: «Leitfaden zur Benutzung von Instrumenten der Künstlichen Intelligenz bei schriftlichen Arbeiten an der Kalaidos Fachhochschule.»

# Problems with the adopted response

Te institution’s primary response to the problem of AI generated content for academic papers was the implementation of these “AI guidelines”. While the guidelines are a necessary step towards regulating AI use, there are signifcant problems with the approach that has been used hitherto. One of the most substantial issues is the fact that their efectiveness hinges on student compliance, which is not guaranteed. Many students might not thoroughly read these documents, leading to a gap in understanding and adherence. Since reading the documents is voluntary, it is possible that not all have read them before using AI in their work. At the same time, there is also currently no vessel to check whether they in fact have read them or not.

To date, a signifcant issue is the lack of comprehensive training in AI capabilities for students. Merely providing a document on AI use is not sufcient for fostering a deep understanding of AI technology, its potential, and its limitations. Tis lack of training could lead to misuse of AI tools, as many students might not be aware of how to properly integrate these technologies into their academic work. Monitoring the use of AI in student assignments poses another challenge. It is difcult to verify whether a piece of work has been created with the aid of AI, especially as these tools become more sophisticated. Tis uncertainty makes it hard to ensure that students are following these guidelines, and it is equally difcult to make sure that nobody is gaining an unfair advantage. Moreover, a signifcant number of students may not be fully aware of how to responsibly use AI tools, nor understand their limitations. Tis lack of knowledge can result in a reliance on AI-generated content without critical evaluation, potentially undermining the quality and integrity of academic work. At the same time, students might also miss out on the opportunity to enhance their learning and critical thinking skills through the proper use of AI.

None of this can be remedied by simply providing a document and hoping that students would read it and abide by its ideals. Addressing these issues requires more than just setting guidelines; it calls for a holistic approach that includes educating students about AI, its ethical use, and limitations.

# Potential solutions to the problems

To equip both students and teachers to become apt in the use of AI for their academic purposes, a new “culture of AI” seems in order. An AI-culture should permeate academic life, creating an environment where AI is not feared but readily used, understood and – most importantly – critically evaluated. A potential avenue would be the implementation of regular workshops and meetings for teachers, supervisors, and students. Tese sessions should focus on up-to-date AI developments, ethical considerations, and best practices. By regularly engaging with AI topics, the academic community can stay informed and profcient in managing AI tools and concepts. Tis should help to deeply ingrain the understanding of AI’s technical, practical, and social challenges.

Workshops and initiatives should “hammer in” the issues surrounding the complexities and implications of AI. Technological education should not be superfcial but should delve into real-world scenarios, discussing how theory and practice converge, and providing students as well as educators with a robust understanding of AI’s role in society and education. A further possibility is to integrate AI into every academic module wherever teacher’s see ft, as to ofers consistent exposure and understanding of AI across various disciplines. Tis strategy ensures that students recognize the relevance of AI in diferent felds, preparing them for a future where AI is ubiquitous in professional environments. Perhaps deliberate classes of how to use AI could serve as a pillar in this educational model. Tese classes, covering a range of topics from basic principles to advanced applications and ethical considerations, could ensure that every student acquires a baseline understanding of AI, regardless of their major or feld of study. Making these classes mandatory would ensure that every student at least once has been confronted with the necessary ins-and-outs and has at least a basic understanding of the AI guidelines. Beyond the classroom, voluntary collaborations and partnerships with AI experts, tech companies, and other educational institutions can provide invaluable insights and resources. Tese collaborations could bridge the gap between theoretical knowledge and practical application, giving students a more comprehensive understanding of AI’s real-world implications. However, perhaps students may have interesting ideas themselves of how a responsible culture of AI could be fostered. Encouraging student-led AI initiatives, such as projects and clubs, can motivate a hands-on learning environment. Tese initiatives may promote peer learning, innovation, and practical application of AI knowledge. By actively engaging in AI projects, students can develop critical thinking and problem-solving skills that are essential in navigating the complexities of an accelerating digital world. In other words, providing AI regulations is a good frst step, but creating ways for students and lecturers to engage more deeply with the topic would probably enhance these measures and might help to foster a respective culture.

# AI in the classroom

Naturally, Artifcial Intelligence is not only relevant for creating papers, but it has also the potential to create novel classroom experiences. Although it is still rare for teachers to strongly adopt and work with AI in their lectures, some have already leaped forward and reported to implement the technology in several ways. Table 3 illustrates the main use-cases of how staf at the university has hitherto been using AI models.

Table 3 Illustration of examples how teachers are using AI in their classrooms   

<html><body><table><tr><td>Use-Case</td><td>Description</td><td>Evaluation</td></tr><tr><td>Al Experiments</td><td>Some teachers have assigned their students to create accounts at major AI providers. As such, they get access to models like ChatGPT by OpenAl or Bard by Google. Once they have it, teachers can prompt students with specific tasks, like for example: &quot;Go and experiment with GPT to discover how to best find good sources for academic papers. Then</td><td>This is an easy way to get students into the&quot;doing&quot;-stage and to gather first-hand experiences. It is also not difficult to implement since it can be combined with just about any class and topic. However, it only works if one has access to free accounts or if the school provides subscriptionse</td></tr><tr><td>Case Study Construction</td><td>three&quot; Some supervisors and lecturers have used LLMs to create case studies that they can then use in their classes for the students to work through, either alone or in groups. This helps them to connect the theories with ideas of how to apply them in real life.</td><td>Constructing case studies sounds like a good idea to generate ideas of how to engage the students better with the presented material. The problem is that prompting the model correctly to get a high-quality case study can take a long time and at times one may be more effec- tive simply doing it oneself.</td></tr><tr><td>AI Recommendation</td><td>Creating curricula for one&#x27;s classes is a complex and time-consuming task. It requires a vision for social interaction, practical engagement and theo- retical understanding. Al tools (such as teachino) can help creating curricula and making interactive suggestions how one can set up the class</td><td>Al tools can greatly help to be more effective and efficient in the construction of curricula. If used as patient sparring partner, it can enhance the classroom setting. At the same time, there is the downside that the Al does not share one&#x27;s experiences and to &quot;indoctrinate&quot; them into the system can sometimes take considerable time</td></tr><tr><td>Gamification</td><td>There are teachers that have now used Al-driven games to enhance the learn- ing experience of students. This leads to interactive settings where students can apply what they have learned in a fun and engaging way</td><td>Gamification is a valuable tool that often excites students and teachers alike. However, they can sometimes be rather expensive and not all schools are willing to account for them in their budgets</td></tr><tr><td></td><td>Immersive &amp; Virtual Reality Virtual Reality, Augmented Reality or Mixed Reality - there are many ways in which students can be introduced into an Al-powered virtual world, which can also be used for a learning setting. At the moment, some lecturers at the current university are applying these technologies</td><td>Using immersive technologies is highly engaging for students and creates an engaging learning environments. The problem is that there is not always a budget to include them and not all teach- ers know how to use them. Sometimes, it is not a straight-forward use-case for certain learning tasks.</td></tr></table></body></html>

Discussions with teachers have shown that one of the biggest constraints to implement AI tools in the classroom is their fear of using them, predominantly due to the fact that they might not know enough about them and assuming that they might use them wrongly. At the same time, students may also not be adept users and if the teachers do not feel like professionals themselves, this exacerbates the problem. Although the topic of human–computer-interactions is a truly pertinent one and gains a lot of attention in the scientifc community, practitioners are often left behind and as such, at KFH there are currently no workshops and programs helping both teachers and students to improve in these matters. Moreover, since the digital world and AI technology is evolving so fast, many feel that it is incredibly difcult to stay on top with the developments. One of the marked challenges at the KFH is the ostensible fact that there is no dedicated person or group that is tasked with staying on top of the matter. To date, it is up to each and every individual to deal with it as one pleases and there is no paid position for this, meaning that employees would have to do all of the work on the side in their own time.

Tere are several recommendations that could help out with these problems and that might help foster an AI-driven culture in the classrooms:

1. Workshops: Te school could provide workshops specifcally tailored to help teachers understand what is going on in the world of AI and what tools there are to aid them in creating an AI-inclusive classroom environment.   
2. Regular Updates: Tere could be outlets (i.e. in the form of newsletters, lunch-meetings, online-events, etc.) that aim towards keeping staf and lecturers up-to-date so that people are aware of the newest tools, apps, and approaches that could be useful for their lectures.   
3. Financial Budget: At the moment, there is no fnancial aid to get trained on AI topics at this particular school and if staf wanted to do something, they efectively have to do it on their own. Tere should be a budget dedicated to helping employees to become knowledgeable in the feld. In any other feld, it would be erroneous to assume that employees would have to be asked to learn a language or another important skill like handling a student administration system and do this entirely in their free time with no fnancial aid. Yet, at the moment this is how the institution is faring with AI.   
4. Guidelines and Best Practices: To date, apart from the “AI guidelines” for students, there are no written guidelines, tips and tricks, nor any suggestions for how to best use AI in the work and school context available. Tey might help providing some guidance.   
5. Paid positions: Instead of purely relying on internal “freelancers” that have an intrinsic motivation to deal with technologies, it would be wise to create positions where experts have a say and can help shape the AI culture in the institution. Tis is commensurate with the third recommendation suggesting that AI would need to be budgeted.

Although these frst recommendations based on the case-study may be helpful, further clarifcations informed by the literature are necessary, specifcally when it comes to the question of how AI literacy can be fostered at schools, how prompt engineering can be used as a pedagogical tool, and how students can improve their critical thinking skills through AI. A deeper look into the respective challenges and opportunities is warranted, followed by more generalizable practical suggestions for the use of AI in the classroom, that are not only based on this particular case-study but are enriched by fndings from the literature more broadly.

# AI literacy in the classroom

Te concept of AI literacy emerges as a cornerstone of contemporary learning. In its essence, it deals with the understanding and capability to interact efectively with AI technology. It encompasses not just the technical know-how but also an awareness of the ethical and societal implications of AI. In the modern classroom, AI literacy goes beyond traditional learning paradigms, equipping students with the skills to navigate and harness the power of AI in various aspects of life and work. It represents a fundamental shift in education, where understanding AI becomes as crucial as reading, writing, and arithmetic (Zhang et al., 2023).

Te current state of AI literacy in education refects a burgeoning feld, ripe with potential yet facing the challenges of early adoption. Educators and policymakers are beginning to recognize the importance of AI literacy, integrating it into curriculums and educational strategies (Casal-Otero et al., 2023; Chiu, 2023). However, this integration is in its nascent stages, with schools exploring various approaches to teaching this complex and ever-evolving skillset. Te challenge lies in not only imparting technical knowledge but also in fostering a deeper understanding of AI’s broader impact – be this on a social, psychological, or even economic level. Due to its importance, there are frst AI-LiteracyScales emerging using questionnaires that can be handed to students $\mathrm { N g }$ et  al., 2023). Although to date there is no stringent consensus on the full scope of the term, it may be argued that AI literacy consists of several sub-skills:

# • Architecture:

Understanding the basic architectural ideas underlying Artifcial Neural Networks (only on a basic need-to-know basis). Tis should primarily entail the knowledge that such systems are nothing more than purely statistical models.

# • Limitations:

Understanding what these models are good for and where they fail. Most poignantly, students and teachers should understand that such statistical models are not truthgenerators but efective data processors (like sentence constructors or image generators).

# • Problem Landscape:

Understanding where all the main problems of AI systems lie, due to the fact that they are only statistical machines and not truth-generators. Tis means that students and teachers ought to know the major pitfalls of AI, which are:

i. AI hallucination: AI can “invent” things that are not true (while still sounding authoritative).   
ii. AI alignment: AI can do something else than what we instructed it to so (sometimes so subtly that it sometimes goes unnoticed).   
iii. AI runaway: AI becomes self-governing, meaning that it sets up certain instrumental goals that was not present in our terminal instructions (for a detailed philosophical analysis of this problem, see Bostrom, 2002, 2012)   
iv. AI discrimination: Due to skewed data in its training, an AI can be biased and lead to discriminatory conclusions against underrepresented groups.   
v. AI Lock-In problem: An AI can get stuck within a certain narrative and thus loses the full picture (experiments and a full explanation of this can be found in Walter, 2022).

# • Applicability and Best Practices

Understanding not only the risks but also the many ways AI can be benefcially used and implemented in daily life and the context of learning. Tis also includes a general understanding of emerging best practices using AI in the classroom (Southworth et al., 2023).

# • AI Ethics:

Understanding the major AI basics, its limitations and risks, as well as potential problems and how it can be used should lead to a nuanced understanding of its ethics. Students and teachers should develop a sense of justice, which governs them to converge on how to virtuously implement AI models in educational settings.

It was shown that early exposure to technology concepts can signifcantly infuence students’ career paths and preparedness for the future (Bembridge et al., 2011; Margaryan, 2023). By introducing AI literacy at a young age, students develop a foundational understanding that paves the way for advanced learning and application in later stages of education and professional life. Tis early adoption of AI literacy is crucial in preparing a generation that is not both adept at using AI as well as capable of innovating and leading in a technology-driven world. Tis makes the development of AI literacy at schools and universities an important feature of every student. Furthermore, its role extends beyond academic achievement; it is about preparing students for the realities of a future where AI is ubiquitous. In careers spanning from science and engineering to arts and humanities, an understanding of AI will be an invaluable asset, enabling individuals to work alongside AI technologies efectively and ethically. As such, AI literacy is not just an educational objective but a vital life skill for the twenty-frst century.

One concrete suggestion is to provide “AI literacy courses” that have the deliberate intent to foster the associated skills in students. In order to have a well-rounded and holistic class, an AI literacy program should entail several key components (Kong et al., 2021; Laupichler et al., 2022; $\mathrm { N g }$ et al., 2023c):

1. Introduction to AI Concepts: Basic defnitions and understanding of what AI is, including its history and evolution. Tis should cover diferent types of AI, such as narrow AI, general AI, and superintelligent AI.

2. Understanding Machine Learning and Technical Foundations: An overview of machine learning, which is a core part of AI. Tis includes understanding diferent types of machine learning (supervised, unsupervised, reinforcement learning) and basic algorithms. Tis can also be enriched through more technical foundations, like an introduction for programming with AI.   
3. Proper Data Handling: Discussion on the importance of data in AI, how AI systems are trained with data, and how one can protect oneself against piracy and privacy concerns.   
4. AI in Practice: Real-world applications of AI in various felds such as healthcare, fnance, transportation, and entertainment. Tis should include both the benefts and challenges of AI implementation.   
5. Human-AI Interaction: Understanding how humans and AI systems can work together, including topics like human-in-the-loop systems, AI augmentation, and the future of work with AI.   
6. AI and Creativity: Exploring the role of AI in creative processes, such as in art, music, and writing, and the implications of AI-generated content.   
7. Critical Thinking about AI: Developing skills to critically assess AI news, research, and claims. Understanding how to diferentiate between AI hype and reality.   
8. AI Governance and Policy: An overview of the regulatory and policy landscape surrounding AI, including discussions on AI safety, standards, and international perspectives.   
9. Future Trends and Research in AI: A look at the cutting edge of AI research and predictions for the future development of AI technologies.   
10. Hands-on Experience: Practical exercises, case studies, or projects that allow students to apply AI concepts and tools in real or simulated scenarios.   
11. Ethical AI design and development: Principles of designing and developing AI in an ethical, responsible, and sustainable manner. Tis also includes the risk for biased AI and its impact on society.   
12. AI Literacy for All: Tailoring content to ensure it is accessible and understandable to people from diverse backgrounds, not just those with a technical or scientifc background.   
13. Prompt Engineering: Understanding what methods are most efective in prompting AI models to follow provided tasks and to generate adequate responses.

At the moment, there are specifc projects that attempt to implement AI literacy at school (Tseng & Yadav, 2023). Te deliberate goal is to eventually lead students towards a responsible use of AI, but to do so, they need to understand how one can “talk” to an AI so that it does what it is supposed to. Tis means that students must become efective prompt engineers.

# Prompt engineering as a pedagogical tool

Prompt engineering, at its core, involves the strategic crafting of inputs to elicit desired responses or behaviors from AI systems. In educational settings, this translates to designing prompts that not only engage students but also challenge them to think critically and creatively. Te art of prompt engineering lies in its ability to transform AI from a mere repository of information into an interactive tool that stimulates deeper learning and understanding (cf. Lee et al., 2023). Te relevance of prompt engineering in education cannot be overstated. As AI becomes increasingly sophisticated and integrated into learning environments, the ability to efectively communicate with these systems becomes crucial. Prompt engineering empowers educators to guide AI interactions in a way that enhances the educational experience. It allows for the creation of tailored learning scenarios that can adapt to the needs and abilities of individual students, making learning more engaging and efective (Eager & Brunton, 2023). One of the most signifcant impacts of prompt engineering is its potential to enhance learning experiences and foster critical thinking. By carefully designing prompts, educators can encourage students to approach problems from diferent perspectives, analyze information critically, and develop solutions creatively. Tis approach not only deepens their understanding of the subject matter but also hones their critical thinking skills, an essential competency in today’s fastpaced and ever-changing world. As one particular study showed, learning to prompt efectively in the classroom can even help students realize more about the limits of AI, which inevitably fosters their AI literacy (Teophilou et  al., 2023). Moreover, AI has the potential to lead to highly interactive and playful teaching settings. With the right programs, it can also be implemented in game-based learning through AI. Tis combination has the potential to transform traditional learning paradigms, making education more accessible, enjoyable, and impactful (Chen et al., 2023).

Just recently, there are a handful of successful prompting methodologies that have emerged, which are continuously being improved. Prompt engineering is an experimental discipline, meaning that through trial and error, one can slowly progress to create better outputs by revising and molding the input prompts. As a scientifc discipline, AI itself can help to fnd new ways to interact with AI systems. Te most relevant prompting methods are summarized in Table 4 and are explained thereafter.

Tere are two major forms of how a language model can be prompted: (i) Zero-Shot prompts, and (ii) Few-Shot prompts. Zero-Shot prompts are the most intuitive alternative, which most likely all of us predominantly use when interacting with models like ChatGPT. Tis is when a simple prompt is provided without much further details and then an unspecifc response is generated, which is helpful when one deals with broad problems or situations where there is not a lot of data. Few-Shot prompting is a technique where a prompt is enriched with several examples of how the task should be completed. Tis is helpful in case one deals with a complex query where there are already concrete ideas or data available. As the name suggests, these “shots” can be enumerated (based on Dang et al., 2022; Kojima et al., 2022; Tam, 2023):

Zero-Shot prompts: Tere are no specifc examples added.   
One-Shot prompts: One specifc example is added to the prompt.   
Two-Shot prompts: Two examples are added to the prompt. Tree-Shot prompts: Tree examples are added to the prompt.   
Few-Shot prompts: Several examples are added to the prompt (unspecifed how many).

<html><body><table><tr><td> Prompting Methodology</td><td>Acronym Description</td><td></td><td>Input Example</td><td> Landmark paper</td></tr><tr><td>Input-Output Prompting</td><td>IOP</td><td>The classic form of prompting: simple input, simple output</td><td>&quot;Tell me what an LLM is&quot;</td><td>(P. Liu et al., 2021)</td></tr><tr><td>Chain-of-Thought Prompting</td><td>CoT</td><td>The Al should slowly elaborate on how a given response is generated</td><td>&quot;Take a deep breath and tell me step-by-step how to solve this problem&quot;</td><td>(Wei et al., 2023)</td></tr><tr><td>Role-Play or Expert-Prompting</td><td>EP</td><td>The Al should assume the role of a person or an expert before providing an answer.</td><td>&quot;Imagine that you are a particle physicist knowing everything about quantum physics. Now give me an introduction to neutrinos&quot;</td><td>(Xu et al., 2023)</td></tr><tr><td>Self-Consistency Prompting</td><td>Sc</td><td>The Al should generate several responses and discern itself, which would be the best answer.</td><td>&quot;Provide me step-by-step with five ideal answers and discuss. which would be the one. Explain why.&quot;</td><td>(Wang et al., 2023)</td></tr><tr><td>Automatic Prompt Engineer</td><td>APE</td><td>The Al model is provided with several examples and it should help us to find an ideal prompt to arrive at these examples (we can then further work with the resulting prompt)</td><td>&quot;Here are some images. Please tell me how a good prompt would look like to generate pictures in this style&quot;.</td><td>(Zhou et al., 2023)</td></tr><tr><td>Generated Knowledge Promptinge</td><td>GKn</td><td>Before prompting the Al with our actual task, we first let the. model generate knowledge about the topic so that it already has set the right scene for its responses.</td><td>&quot;Provide me with ten facts about dolphins. Then, using these facts, write a poem about dolphins that would be actually true.</td><td>(Liu et al., 2022)</td></tr><tr><td>Tree-of-Thought Prompting</td><td>ToT</td><td>The Al is provided with a complex setting where it is prompted. to use its arguments like a chess game, providing several lines of. thoughts and go back again if there are inconsistencies, eventu- ally to converge on the best response.</td><td>There is no simple example of ToT-Prompting (see below): First, the ToT-context is provided Then, second, the task is provided that works within the confine-</td><td>(Yao et al., 2023)</td></tr></table></body></html>

Tese prompting methods have gradually developed and became more complex, starting from Input–Output Prompting all the way to Tree-of-Tought Prompting, which is displayed in Table 4.

When people usually start prompting an AI, they begin with simple prompts, like “Tell me something about…”. As such, the user inserts a simple input prompt and a rather unspecifc, generalized output response is generated. Te more specifc the answer should be, the more concrete and narrow the input prompt should be. Tese are called Input–Output prompts (IOP) and are the simplest and most common forms of how an AI is prompted (Liu et al., 2021). It has been found that the results turn out to be much better when there is not simply a straight line from the input to the output but when then AI has to insert some reasoning steps (Wei et al., 2023). Tis is referred to as Chainof-Tought (CoT) prompting where the machine is asked to explain the reasoning steps that lead to a certain outcome. Te framework that historically has worked well is to prompt the AI to provide a solution “step-by-step”. Practically, it is possible to give ChatGPT or any other LLM a task and then simply add: “Do this step-by-step.” Interestingly, experiments have further shown that the results get even better when at frst the system is told to “take a deep breath”. Hence, the addendum “Take a deep breath and do it stepby-step” has become a popular addendum to any prompt (Wei et al., 2023). Such general addendums that can be added to any prompt to improve the results are sometimes referred to as a “universal and transferrable prompt sufx”, which is frequently employed as a method to successfully jailbreak an LLM (Zou et al., 2023).

Yet another prompt engineering improvement is the discovery that narrative role plays can yield signifcantly better results. Tis means that an LLM is asked to put itself in the shoes of a certain person with a specifc role, which then usually helps the model to be much more specifc in the answer it provides. Often, this is done via a specifc form of role play, known as expert prompting (EP). Te idea is that the model should assume the role of an expert (whereas frst the role of the expert is explained in detail) and then the result is generated from an expert’s perspective. It has been demonstrated that this is a way to prompt the AI to be a lot more concrete and less vague in its responses (Xu et al., 2023). Building explicitly on CoT-prompting, yet a further improvement was detected in what has come to be known as Self-Consistency (SC) prompting. Tis one deliberately works with the CoT-phrases like “explain step by step…”, but it adds to this that not only one line of reasoning but multiple of them should be pursued. Since not all of these lines may be equally viable and we may not want to analyze all of them ourselves, the model should extend its reasoning capacity to discern which of these lines makes the most sense in light of a given criterion. Te reason for using SC-prompting is to minimize the risk of AI hallucination (meaning that the AI might be inventing things that are not true) and thus to let the model hash out for itself if a generated solution might be potentially wrong or not ideal (Wang et al., 2023). In practice, there may be two ways to enforce self-consistency:

Generalized Self-Consistency: Te model should determine itself why one line of reasoning makes the most sense and explain why this is so.

Example: “Discuss each of the generated solutions and explain which one is most plausible.”

Criteria-based Self-Consistency: Te model is provided with specifc information (or: criteria) that should be used to evaluate which line of reasoning holds up best.

Example:

“Given that we want to respect the fact that people like symmetric faces, which of these portraits is the most beautiful? Explain your thoughts and also include the notion of face symmetry.”

Sometimes, one may feel a little uncreative, not knowing how to craft a good prompt to guide the machine towards the preferred response. Tis is here referred to as the prompt-wise tabula-rasa problem, since it feels like one is sitting in front a “white paper” with no clue how to best start. In such cases, there are two prompt techniques helping us out there. One is called the Automatic Prompt Engineer (APE) and the other is known as the Generated Knowledge Prompting (GKn). Te APE starts out with one or several examples (of text, music, images, or anything else the model can work with) with the goal to ask the AI which prompts would work best to generate these (Zhou et  al., 2023). Tis is helpful when we already know how a good response would look like but we do not know how to guide the model to this outcome. An example would be: “Here is a love letter from a book that I like. I would like to write something similar to my partner but I don’t know how. Please provide me with some examples of how I could prompt an AI to create a letter in a similar style.” Te result is then a list of some initial prompts that can help the user kickstart working on refnements of the preferred prompt so that eventually a letter can be crafted that suits the user’s fancy. Tis basically hands the hard work of thinking through possible prompts to the computer and relegates the user’s job towards refning the resulting suggestions.

A similar method is known as Generated Knowledge (GKn) prompting, which assumes that it is best to frst “set the scene” in which the model can then operate. Tere are parallels to both EP and APE prompting, where a narrative framework is constructed to act as a reference for the AI to draw its information from but only this time, as in APE, the knowledge is not provided by the human but generated by the machine itself (Liu et al., 2022). An example might be: “Please explain what linguistics tells us how the perfect poem should look like. What are the criteria for this? Can you provide me with three examples?”. Once the stage is set, one can start with the actual task: “Based on this information, please write a poem about…” Tere are two ways to create Generated Knowledge tasks: (i) the single prompt approach, and (ii) the dual prompt approach. Te frst simply places all the information within one prompt and then runs the model. Te second works with two individual steps:

Step 1: First some facts about a topic are generated (one prompt) Step 2: Once this is done, the model is prompted again to do something with this information (another prompt)

Although AI systems are being equipped with increasingly longer context windows (which is the part of the current conversation the model can “remember”, like a working memory), they have been shown to rely stronger on data at the beginning and et the end of the window (Liu et  al., 2023). Since hence there is evidence that not all information within a prompt is equally weighed and deemed relevant by the model, in some cases the dual prompt or even a multiple prompt approach may yield better results.

To date, the perhaps most complicated method is known as Tree-of-Tought (ToT) prompting. Te landmark paper by Yao et  al. (2023) introducing the method has received signifcant attention in the community as it described a signifcant improvement and also highlights shortcomings of previous methods. ToT uses a combination of CoT and SC-prompting and builds on this the idea that one can go back and forth, eventually converging on the best line of reasoning. It is similar to a chess game where there are many possibilities to make the next move and in ones head the player has to think through multiple scenarios, mentally going back and forth with certain fgures, and then eventually deciding upon which would be the best next move. As an example, think of it like this: Imagine that you have three experts, each having difering opinions. Tey each lay out their arguments in a well-thought-through (step-by-step) fashion. If one makes an argumentative mistake, the expert concedes this and goes a step back towards the previous position to take a diferent route. Te experts discuss with each other until they all agree upon the best result. Tis context is what can be called the ToT-context, which applies regardless of the specifc task. Te task itself is then the query to solve a specifc problem. Hence a simplifed example would look like this:

# 1. ToT-Context:

“Imagine that there are three experts in the feld discussing a specifc problem. Tey each lay out their arguments step-by-step. Tey all hold diferent opinions at the start. After each step, they discuss which arguments are the best and each must defend its position. If there are clear mistakes, the expert will concede this and go a step back to the previous position to take the route of a diferent argument related to the position. If there are no other plausible routes, the expert will agree with the most likely solution still in discussion. Tis should occur until all experts have agreed with the best available solution.”

2. Task:

“Te specifc problem looks like this: Imagine that Tomas is going swimming. He walks into the changing cabin carrying a towel. He wraps his watch inside the towel and brings it to his chair next to the pool. At the chair, he opens the towel and dries himself. Ten he goes to the kiosk. Tere he forgets his towel and jumps into the pool. Later, he realizes that he lost his watch. Which is the most likely place where Tomas lost it?”

Te present author’s experiments have indicated that GPT-3.5 provides false answers to this task when asked with Input–Output prompting. However, the responses turned out to be correct when asked with ToT-prompting. GPT-4 sometimes implements a similar method without being prompted, but often it does not do so automatically. A previous version of ToT was known as Prompt Ensembling (or DiVeRSe: Diverse Verifer on Reasoning Steps), which worked with a three-step process: (i) Using multiple prompts

to generate diverse answers; (ii) using a verifer to distinguish good from bad responses;   
and (iii) using a verifer to check the correctness of the reasoning steps (Li et al., 2023).

Sometimes, there sems to be a degree of arbitrariness regarding best practices of AI, which may have to do with the way a model was trained. For example, saying that that GPT should “take a deep breath” in fact appears to result in better outcomes, but it also seems strange. Most likely, this may have to do with the fact that in its training material (which nota bene incorporates large portions of the publicly available internet data) this statement is associated with more nuanced behaviors. Just recently, an experimenter stumbled upon another strange AI behavior: when he incentivized ChatGPT with an imaginary monetary tip, the responses were signifcantly better – and the more tip he promised, the better the results became (Okemwa, 2023). Another interesting feature that has been widely known for a while now is that one can disturb an AI with so-called “adversarial prompts”. Tis was showcased by Daras and Dimakis (2022) in their paper entitled “Discovering the Hidden Vocabulary of DALLE- $2 ^ { \dprime }$ with two examples:

Example 1: Te prompt “a picture of a mountain” (showing in act a mountain” was transformed into a picture of a dog when the prefx “turbo lhaf✓” was added to the prompt.

Example 2: Te prompt “Apoploe vesrreaitais eating Contarra ccetnxniams luryca tanniounons" reliably generated images of birds eating berries.

To us humans, nothing in the letters “turbo lhaf✓” has anything to do with a dog. Yet, Dall-E always generated the picture of a dog and transformed, for example, the mountain into a dog. Likewise, there is no reason to assume that “Apoploe vesrreaitais” has anything to do with birds and that “Contarra ccetnxniams luryca tanniounons” would have anything to do with berries. Still, this is how the model interpreted the task every time. Tis implies that there are certain prompts that can modify the processing in unexpected ways based on the procedure of how the AI is trained. Tis is still poorly understood since to date there is yet no clear understanding how these emergent properties awaken from the mathematical operations within the artifcial neural networks, which is currently the object of research in a discipline called Mechanistic Interpretability (Conmy et al., 2023; Nanda et al., 2023; Zimmermann et al., 2023).

# Fostering critical thinking with AI

Critical thinking, in the context of AI education, involves the ability to analyze information, evaluate diferent perspectives, and create reasoned arguments, all within the framework of AI-driven environments. Tis skill is increasingly important as AI becomes more prevalent in various aspects of life and work. In educational settings, AI can be used as a tool not just for delivering content, but also for encouraging students to question, analyze, and think deeply about the information they are presented with (van den Berg & du Plessis, 2023). Te use of AI in education ofers unique opportunities to cultivate critical thinking. AI systems, with their vast databases and analytical capabilities, can present students with complex problems and scenarios that require more than just rote memorization or basic understanding. Tese systems can challenge students to use higher-order thinking skills, such as analysis, synthesis, and evaluation, to navigate through these problems. Moreover, AI can provide personalized learning experiences that adapt to the individual learning styles and abilities of students. Tis personalization ensures that students are not only engaged with the material at a level appropriate for them but are also challenged to push their cognitive boundaries. By presenting students with tasks that are within their zone of proximal development, AI can efectively scafold learning experiences to enhance critical thinking (Muthmainnah et al., 2022).

As such, the integration of critical thinking in AI literacy courses is an important consideration. As students learn about AI, its capabilities, and its limitations, they are encouraged to think critically about the technology itself. Tis includes understanding the ethical implications of AI, the biases that can exist in AI systems, and the impact of AI on society. By incorporating these discussions into AI literacy courses, educators can ensure that students are not only technically profcient but also ethically and critically aware $\mathrm { N g }$ et al., 2021). Tere are a number of challenges that students face in a rapidly evolving world under the infuence of Artifcial Intelligence and critical thinking skills seem to be the most successful way to equip them against the problems at hand. Table 5 sketches out some of the major problems students face and how critical thinking measures can counteract them.

Te idea of teaching scafolding helps to foster students in their critical thinking skills in a digital and AI-driven context. Tere are several forms of scafolding that lecturers, teachers, supervisors and mentors can apply (Pangh, 2018):

Prompt scafolding: Te teacher provides helpful context or hints and also asks specifc questions to lead students on the path to better understand and transpire a topic. Explicit refection: Te teacher helps students to think through certain scenarios and where the potential pitfalls lie. Praise and feedback: Te teacher provides acknowledgments where good work has been done and gives a qualitative review on how the student is doing.   
• Modifying activity: Te teacher suggests alternative strategies how students can benefcially work with AI, thereby fostering responsible use. Direct instruction: Trough providing clear tasks and instructions, students learn how to navigate the digital world and how AI can be used.   
Modeling: Te teacher highlights examples of where students make mistakes in their proper use of digital tools and helps them where they have difculties to interact.

Tis goes to show that critical thinking is a key resource for dealing adequately with an AI-driven world and that educators play a vital role in leading students into digital maturity.

# Summary of main challenges and opportunities of AI in education

AI in education presents signifcant challenges and opportunities. Key challenges include the need for ongoing professional development for educators in AI technologies and pedagogical practices. Teachers require training in prompt engineering and AI integration into curricula, which must be restructured for AI literacy. Tis multidisciplinary approach involves computer science, ethics, and critical thinking. Rapid AI advancements risk leaving educators behind, potentially leading to classroom management issues if students surpass teacher knowledge.

<html><body><table><tr><td>Al Challenges</td><td>Description</td><td>Critical Thinking Measures</td><td>Sources</td></tr><tr><td>Information Quality</td><td>Misinformation, biased information and hallucina- tions from Al Sources, including social problems like Deep-Fakes</td><td>Implement critical media literacy programs to teach students how to identify and analyze biases and. misinformation in Al-generated content</td><td>(Alkaissi et al., 2023; Ivanov, 2023; Katarzyna et al., 202) Theophilou et al., 2023)</td></tr><tr><td>Al Dependency</td><td>Over-reliance on Al for problem solving, decision mak- Foster a problem-based learning environment where ing, and cognitive tasks</td><td>students are encouraged to first use analytical reason- ing before turning to Al solutions</td><td>(Chan &amp; Tsi, 2023; Groza &amp; Marginean, 2023; Ivanov, 2023; Malik et al., 2023)</td></tr><tr><td>Al Ethics</td><td>Ethical dilemmas posed by Al, such as personal autonomy or discrimination</td><td>Integrate ethics into the curriculum with a focus on Al-related issues, encouraging debate and discussion on ethical dilemmas</td><td>(Akgun &amp; Greenhow, 2022; Ivanov, 2023; Jeyaraman et al., 2023; Nguyen et al., 2023; Rane, 2023; Williams, 2021)</td></tr><tr><td> Pace of Technology</td><td>Problems with keeping up-to-date with the rapid technological changes and fears concerning displace- ments in the job market as well as academia</td><td>Provide workshops for career guidance that empha- size adaptability and the importance of continuous learning in an Al-evolving job landscape. Teach an agile mindset and provide sources to learn the newest developments. Emphasize non-propositional skills (the how&quot;) over propositional knowledge (&quot;the what&quot;), which is more timeless. Spot latent anxiety in</td><td>(Ahmad, 2019; Fui-Hoon Nah et al., 2023; Motlagh et a 2023; Roll &amp; Wylie, 2016)</td></tr><tr><td> Social Isolation</td><td>Decreased human interaction due to increased absorption by Al, the digital world and time on the screen</td><td>students and offer guidance to reduce them. Promote activities that require teamwork and face- to-face interaction to balance the solitary nature of screen time and Al interactions</td><td>(Ali &amp; Smith, 2015; Baker et al., 2018; Guilherme, 2019; Jelodar et al., 2021; Locsin et al., 2021)</td></tr><tr><td>Loss of Independent Thought and Creative Skillse</td><td>Since cognitive and creative work can be handed to Al Encourage projects that require out-of-the-box models, it may diminish students&#x27; skills in developing original thought and creative processes</td><td>thinking, using Al as a tool for assistance rather than the primary source of ideas. Use a mix of tasks where sometimes students are not allowed to use Al and where sometimes they must use Al</td><td>(Fui-Hoon Nah et al., 2023; Ivanov, 2023; Minn, 2022; Zhan et al., 2022)</td></tr><tr><td></td><td>Evolving Learning Capacities Al can lead to changes in learning styles and might reduce general attention span in case of low interac- tivity</td><td>Adapt teaching methods to cater to diverse learning Styles influenced by Al and technology, including interactive and multimodal learning approaches. Al assistants and platforms can help teachers quickly adapt to new formats</td><td>(Fui-Hoon Nah et al., 2023; Ivanov, 2023; Rane, 2023; Taylor &amp; Boyer, 2020)</td></tr><tr><td>Data Privacy Concerns</td><td>In the digital world, data is constantly gathered and AlEducate students about data privacy, including how models are trained on them.</td><td>their data is used by Al systems and ways to protect their digital footprint</td><td>(Attai, 2019; Kouroupis &amp; Vagianos, 2023; Serholt et al. 2017)</td></tr></table></body></html>

Equitable access to AI tools is crucial to address the digital divide and prevent educational inequalities. Investment in technology and fair access policies are necessary, especially for underprivileged areas. Another challenge is avoiding AI biases, requiring diverse, inclusive training datasets and educator training in bias recognition. Additionally, balancing AI use with human interaction is vital to prevent social isolation and promote social skills development.

Opportunities in AI-integrated education include personalized learning systems that adapt to individual student needs, accommodating various learning styles and cognitive states. AI can assist students with special needs, like language processing or sensory impairments, through tools like AI-powered speech recognition. Ethical AI development is essential, focusing on transparency, unbiased content, and privacy-respecting practices. AI enables innovative content delivery methods, such as virtual and augmented reality, and aids in educational administration and policymaking. It also fosters collaborative learning, connecting students globally and transcending cultural barriers.

# Practical suggestions

# Enhancing AI literacy

In the quest to enhance AI literacy in the classroom and academia, a nuanced approach is essential. Te creation of AI literacy courses would be a valuable asset. Tese courses should be weaved into the existing curriculum, covering essential AI concepts, ethical considerations, and practical applications. It is crucial to adopt an interdisciplinary approach, integrating AI literacy across various subjects to showcase its broad impact. Te role of AI as an educational tool in the future should not be overlooked. Integrating AI-driven tools for personalized learning can revolutionize the educational landscape, catering to individual learning styles and needs. AI can also function as a teaching assistant, assisting in grading, feedback, and generating interactive learning experiences. Furthermore, its role in research and project work should be encouraged, allowing students to use AI for data analysis and exploration of new ideas, while fostering a critical and ethical approach.

Specifc AI tools can help to enhance the educational toolkit. Teachino (www.teach ino.io), for instance, can be instrumental in curriculum development and classroom management. Perplexity (www.perplexity.ai) can enhance knowledge retrieval through its natural language processing capabilities and its ability to connect the information to external sources. Apps like HelloHistory (www.hellohistory.ai) can bring ancient personas to life, thus creating a personalized and interactive teaching setting. Additionally, tools like Kahoot! (kahoot.it) and Quizizz (quizizz.com) can gamify learning experiences, and Desmos (www.desmos.com) can ofer interactive ways to understand complex mathematical concepts. Lecturers are advised to try to stay informed about the ongoing developments in the AI-tools-landscape since it is constantly evolving, which can be seen in the popular AI app called Edmodo that once entertained millions of students but does not exist anymore (Mollenkamp, 2022; Tegousi et al., 2020).

Educator profciency in AI is just as important. Regular training and workshops for educators will ensure they stay updated with the latest AI technology advancements. Establishing peer learning networks and collaborations with AI professionals can bridge the gap between theoretical knowledge and practical application, enriching the teaching experience. Central to all these eforts is the fostering of a critical and ethical approach to AI. Ethical discussions should be an integral part of the learning process, encouraging students to contemplate AI’s societal impact. Case studies and hypothetical scenarios can be utilized to explore the potential benefts and challenges of AI applications. Moreover, assessments in AI literacy should test not only technical knowledge but also the ability to critically evaluate the role and impact of Artifcial Intelligence.

# Advancing prompt engineering with teachers and students

Te advancement of prompt engineering within educational settings ofers a unique avenue for enriching the learning experience for both teachers and students. Te cornerstone of implementing prompt engineering is to educate all parties involved about its methodologies. Tis involves not only teaching the basic principles but also delving into various prompt types, such as the diference between zero-shot and few-shot prompting, and the application of techniques like chain-of-thought or self-consistency prompts. Educators should receive training on how to design prompts that efectively leverage the capabilities of AI models, enhancing the learning outcomes in various subjects.

Collaboration between the lecturers and the students plays a pivotal role in the successful integration of prompt engineering in education. Class-wide collaborative sessions where students and teachers come together to experiment with diferent prompts can be highly efective. Tese sessions should focus on identifying which types of prompts yield the best results for diferent learning objectives and AI applications. Sharing experiences on what works and what does not can lead to a collective understanding and refnement of techniques. Such collaborative exercises also foster a community of learning, where both teachers and students learn from each other’s successes and challenges. Creating exercises for each educational module that incorporate prompt engineering is another critical step. Tese exercises should be designed to align with the learning objectives of the module, ofering students hands-on experience in using prompt engineering to solve problems or explore topics. For instance, in a literature class, students could use prompt engineering to analyze a text or create thematic interpretations. In a science class, prompts could be designed to explore scientifc concepts or solve complex problems. Tese exercises should encourage students to experiment with diferent types of prompts, understand the nuances of each, and observe how subtle changes in phrasing or context can alter the AI’s responses. Tis not only enhances their understanding of the subject matter but also develops critical thinking skills as they analyze and interpret the AI’s output. To further enrich the learning experience, these exercises can be supplemented with refective discussions. After completing a prompt engineering exercise, students can discuss their approaches, challenges faced, and insights gained. Tis refection not only solidifes their understanding but also encourages them to think critically about the application of AI in problem-solving. Such exercises are especially powerful because both the students as well as the teaching staf learn a lot about the technology at the same time.

# Critical thinking with AI in the classroom

Workshops may be a useful tool for fostering critical thinking skills in modern education. Tese workshops should not only focus on the technicalities of AI but also on developing critical thinking skills in the context of AI use. Tey should include hands-on activities where students and teachers can engage with AI tools, analyze their outputs, and critically assess their reliability and applicability. Te workshops can also cover topics such as identifying biases in AI algorithms, understanding the limitations of AI, and evaluating the ethical implications of AI decisions. Case studies play a pivotal role in understanding the ethical dimensions of AI. Tese should be carefully selected to cover a wide range of scenarios where the ethical implications are highlighted. Trough these case studies, students can examine real-world situations where the decisions made by AI have signifcant consequences, encouraging them to think about the moral and societal impacts of AI technologies. Te discussions should encourage students to debate diferent viewpoints, fostering an environment of critical analysis and ethical reasoning. Establishing institutional channels where students and teachers can bring their AIrelated problems is essential to foster a culture of open communication and continuous learning. Tese channels can function like an innovation funnel, where ideas, concerns, and experiences with AI are shared, discussed, and explored. Tis could take the form of online forums, regular meet-ups, or suggestion boxes. Tese platforms can act as incubators for new ideas on how to use AI responsibly and efectively in educational settings.

Creating a culture of AI adoption in educational institutions is crucial. Tis culture should be built on the principles of ethical AI use, continuous learning, and critical engagement with technology. It involves not just the implementation of AI tools but also the fostering of an environment where questioning, exploring, and critically assessing AI is encouraged. Tis culture should permeate all levels of the institution, from policy-making to classroom activities. Encouraging students to question and explore AI’s potential and limitations can lead to a deeper understanding and responsible use of these technologies. Tis includes facilitating discussions on topics such as AI’s impact on job markets, privacy concerns, and the implications of AI in decision-making processes. By encouraging critical thinking around these topics, students can develop a nuanced understanding of AI, equipping them with the skills necessary to navigate an AI-driven world.

# Conclusion: navigating the complexities and potentials of AI in education

Te AI in the realm of education marks a transformative era that is redefning the teaching and learning methodologies fundamentally. Tis paper has critically examined the expansive role of AI, focusing particularly on the nuances of AI literacy, prompt engineering, and the development of critical thinking skills within the educational setting. As we delve into this new paradigm, the journey, although flled with unparalleled opportunities, is fraught with signifcant challenges that need astute attention and strategic approaches. One of the most compelling prospects ofered by AI in education is the personalization of learning experiences. AI’s capacity to tailor educational content to the unique learning styles and needs of each student holds the potential for a more engaging and efective educational journey. Moreover, this technology has shown remarkable promise in supporting students with special needs, thereby enhancing inclusivity and accessibility in learning environments. Additionally, the focus on AI literacy, prompt engineering, and critical thinking skills prepares students for the complexities of a technology-driven world, equipping them with essential competencies for the future. However, these advancements bring forth their own set of challenges. A primary concern is the preparedness of educators in this rapidly evolving AI landscape. Continuous and comprehensive training for teachers is crucial to ensure that they can efectively integrate AI tools into their pedagogical practices. Equally important are the ethical and social implications of AI in education. Te integration of AI necessitates a critical approach to address biases, ensure privacy and security, and promote ethical use. Another signifcant hurdle is the accessibility of AI resources. Ensuring equitable access to these tools is imperative to prevent widening educational disparities. Additionally, developing a critical mindset towards AI among students and educators is fundamental to harness the full potential of these technologies responsibly. Te perhaps most signifcant danger is that both students and educators use AI systems without respecting their limitations (e.g. the fact that they may often hallucinate and provide wrong answers while sounding very authoritative on the matter).

Looking towards the future, several research and development avenues present themselves as critical to advancing the integration of AI in education:

1. Curriculum Integration: Future research should explore efective methods for integrating AI literacy across various educational levels and disciplines.   
2. Ethical AI development:Investigating how to develop and implement AI tools that are transparent, unbiased, and respect student privacy is essential for ethical AI integration in education.   
3. AI in Policy Making: Understanding how AI can assist in educational policy-making and administration could streamline educational processes and ofer valuable insights.   
4. Cultural Shifts in Education: Research into how educational institutions can foster a culture of critical and ethical AI use, promoting continuous learning and adaptation, is crucial.   
5. Longitudinal Studies: Tere is a need for longitudinal studies to assess the long-term impact of AI integration on learning outcomes, teacher efectiveness, and student well-being. So far, this has not been possible due to the novelty of the technology.

Te future of education, augmented by AI, holds vast potential, and navigating its complexities with a focus on responsible and ethical practices will be key to realizing its full promise. Te present paper has argued that this can be efectively done, amongst others, through implementing AI literacy, prompt engineering expertise, and critical thinking skills.

# Acknowledgements

All staf and students of the Kalaidos University of Applied Sciences are warmly thanked for their continuous activity and discussions about the topic amongst themselves and with the author.

# Funding

There was no external funding for this research.

Data availability No additional data is associated with this paper.

# Declarations

Competing interests There are no competing interests.

Received: 12 December 2023 Accepted: 9 February 2024   
Published online: 26 February 2024

# References

Abramski, K., Citraro, S., Lombardi, L., Rossetti, G., & Stella, M. (2023). Cognitive Network Science Reveals Bias in GPT-3, GPT-3.5 Turbo, and GPT-4 Mirroring Math Anxiety in High-School Students. Big Data and Cognitive Computing, 7(3), Article 3. https://doi.org/10.3390/bdcc7030124   
Adiguzel, T., Kaya, M. H., & Cansu, F. K. (2023). Revolutionizing education with AI: Exploring the transformative potential of ChatGPT. Contemporary Educational Technology, 15(3), ep429. https://doi.org/10.30935/cedtech/13152   
Ahmad, T. (2019). Scenario based approach to re-imagining future of higher education which prepares students for the future of work. Higher Education, Skills and Work-Based Learning, 10(1), 217–238. https://doi.org/10.1108/ HESWBL-12-2018-0136   
Akgun, S., & Greenhow, C. (2022). Artifcial intelligence in education: Addressing ethical challenges in K-12 settings. AI and Ethics, 2(3), 431–440. https://doi.org/10.1007/s43681-021-00096-7   
Ali, A., & Smith, D. T. (2015). Comparing social isolation efects on students attrition in online versus face-to-face courses in computer literacy. Issues in Informing Science and Information Technology, 12, 011–020.   
Alkaissi, H., McFarlane, S. I., Alkaissi, H., & McFarlane, S. I. (2023). Artifcial Hallucinations in ChatGPT: Implications in Scientifc Writing. Cureus, 15(2). https://doi.org/10.7759/cureus.35179   
Alsunni, A. A., & Latif, R. (2021). Higher emotional investment in social media is related to anxiety and depression in university students. Journal of Taibah University Medical Sciences, 16(2), 247–252. https://doi.org/10.1016/j.jtumed. 2020.11.004   
Aristanto, A., Supriatna, E., Panggabean, H. M., Apriyanti, E., Hartini, H., Sari, N. I., & Kurniawati, W. (2023). The role of Artifcial Intelligence (AI) at school learning. Consilium: Education and Counseling Journal, 3(2), Article 2. https://doi.org/10. 36841/consilium.v3i2.3437   
Attai, L. (2019). Protecting student data privacy: Classroom fundamentals. Rowman & Littlefeld Publishers.   
Baker, S., Warburton, J., Waycott, J., Batchelor, F., Hoang, T., Dow, B., Ozanne, E., & Vetere, F. (2018). Combatting social isolation and increasing social participation of older adults through the use of technology: A systematic review of existing evidence. Australasian Journal on Ageing, 37(3), 184–193. https://doi.org/10.1111/ajag.12572   
Bembridge, E., Levett-Jones, T., & Jeong, S.Y.-S. (2011). The transferability of information and communication technology skills from university to the workplace: A qualitative descriptive study. Nurse Education Today, 31(3), 245–252. https:// doi.org/10.1016/j.nedt.2010.10.020   
Bostrom, N. (2002). Existential risks: Analyzing human extinction scenarios and related hazards. Journal of Evolution and Technology, 9. https://ora.ox.ac.uk/objects/uuid:827452c3-fcba-41b8-86b0-407293e6617c   
Bostrom, N. (2012). The superintelligent will: Motivation and instrumental rationality in advanced artifcial agents. Minds and Machines, 22(2), 71–85. https://doi.org/10.1007/s11023-012-9281-3   
Casal-Otero, L., Catala, A., Fernández-Morante, C., Taboada, M., Cebreiro, B., & Barro, S. (2023). AI literacy in K-12: A systematic literature review. International Journal of STEM Education, 10(1), 29. https://doi.org/10.1186/s40594-023-00418-7   
Chan, C. K. Y. (2023). A Comprehensive AI Policy Education Framework for University Teaching and Learning (arXiv:2305. 00280). arXiv. https://doi.org/10.48550/arXiv.2305.00280   
Chan, C. K. Y., & Tsi, L. H. Y. (2023). The AI Revolution in Education: Will AI Replace or Assist Teachers in Higher Education? (arXiv: 2305.01185). arXiv. https://doi.org/10.48550/arXiv.2305.01185   
Chen, C.-H., Law, V., & Huang, K. (2023). Adaptive scafolding and engagement in digital game-based learning. Educational Technology Research and Development, 71(4), 1785–1798. https://doi.org/10.1007/s11423-023-10244-x   
Chiu, T. K. F. (2023). The impact of Generative AI (GenAI) on practices, policies and research direction in education: A case of ChatGPT and Midjourney. Interactive Learning Environments, 1–17. https://doi.org/10.1080/10494820.2023.22538 61   
Chiu, T. K. F., Xia, Q., Zhou, X., Chai, C. S., & Cheng, M. (2023). Systematic literature review on opportunities, challenges, and future research recommendations of artifcial intelligence in education. Computers and Education: Artifcial Intelligence, 4, 100118. https://doi.org/10.1016/j.caeai.2022.100118   
Conmy, A., Mavor-Parker, A. N., Lynch, A., Heimersheim, S., & Garriga-Alonso, A. (2023). Towards Automated Circuit Discovery for Mechanistic Interpretability (arXiv:2304.14997). arXiv. https://doi.org/10.48550/arXiv.2304.14997   
Dang, H., Mecke, L., Lehmann, F., Goller, S., & Buschek, D. (2022). How to Prompt? Opportunities and Challenges of Zero- and Few-Shot Learning for Human-AI Interaction in Creative Applications of Generative Models (arXiv:2209.01390). arXiv. https://doi.org/10.48550/arXiv.2209.01390   
Daras, G., & Dimakis, A. G. (2022). Discovering the Hidden Vocabulary of DALLE-2 (arXiv:2206.00169). arXiv. https://doi.org/ 10.48550/arXiv.2206.00169   
Eager, B., & Brunton, R. (2023). Prompting Higher Education Towards AI-Augmented Teaching and Learning Practice. Journal of University Teaching & Learning Practice, 20(5). https://doi.org/10.53761/1.20.5.02   
Farhi, F., Jeljeli, R., Aburezeq, I., Dweikat, F. F., Al-shami, S. A., & Slamene, R. (2023). Analyzing the student views, concerns, and perceived ethics about chat GPT usage. Computers and Education: Artifcial Intelligence, 5, 100180. https://doi. org/10.1016/j.caeai.2023.100180   
Fui-Hoon Nah, F., Zheng, R., Cai, J., Siau, K., & Chen, L. (2023). Generative AI and ChatGPT: Applications, challenges, and AI-human collaboration. Journal of Information Technology Case and Application Research, 25(3), 277–304. https://doi. org/10.1080/15228053.2023.2233814   
Fullan, M., Azorín, C., Harris, A., & Jones, M. (2023). Artifcial intelligence and school leadership: Challenges, opportunities and implications. School Leadership & Management, 1–8. https://doi.org/10.1080/13632434.2023.2246856   
Garg, S., & Sharma, S. (2020). Impact of artifcial intelligence in special need education to promote inclusive pedagogy. International Journal of Information and Education Technology, 10(7), 523–527. https://doi.org/10.18178/ijiet.2020. 10.7.1418   
Groza, A., & Marginean, A. (2023). Brave new world: Artifcial Intelligence in teaching and learning (arXiv:2310.06856). arXiv. https://doi.org/10.48550/arXiv.2310.06856   
Guilherme, A. (2019). AI and education: The importance of teacher and student relations. AI & SOCIETY, 34(1), 47–54. https://doi.org/10.1007/s00146-017-0693-8   
Ivanov, S. (2023). The dark side of artifcial intelligence in higher education. The Service Industries Journal, 43(15–16), 1055–1082. https://doi.org/10.1080/02642069.2023.2258799   
Jasso-Medrano, J. L., & López-Rosales, F. (2018). Measuring the relationship between social media use and addictive behavior and depression and suicide ideation among university students. Computers in Human Behavior, 87, 183–191. https://doi.org/10.1016/j.chb.2018.05.003   
Jelodar, H., Orji, R., Matwin, S., Weerasinghe, S., Oyebode, O., & Wang, Y. (2021). Artifcial Intelligence for Emotion-Semantic Trending and People Emotion Detection During COVID-19 Social Isolation (arXiv:2101.06484). arXiv. https://doi.org/10. 48550/arXiv.2101.06484   
Jeyaraman, M., Ramasubramanian, S., Balaji, S., Jeyaraman, N., Nallakumarasamy, A., & Sharma, S. (2023). ChatGPT in action: Harnessing artifcial intelligence potential and addressing ethical challenges in medicine, education, and scientifc research. World Journal of Methodology, 13(4), 170–178. https://doi.org/10.5662/wjm.v13.i4.170   
Ji, H., Han, I., & Ko, Y. (2023). A systematic review of conversational AI in language education: Focusing on the collaboration with human teachers. Journal of Research on Technology in Education, 55(1), 48–63. https://doi.org/10.1080/ 15391523.2022.2142873   
Katarzyna, A., Savvidou, C., & Chris, A. (2023). Who wrote this essay? Detecting AI-generated writing in second language education in higher education. Teaching English with Technology, 23(2), 25–43.   
Kojima, T., Gu, S. (Shane), Reid, M., Matsuo, Y., & Iwasawa, Y. (2022). Large Language Models are Zero-Shot Reasoners. Advances in Neural Information Processing Systems, 35, 22199–22213   
Kong, S.-C., Man-Yin Cheung, W., & Zhang, G. (2021). Evaluation of an artifcial intelligence literacy course for university students with diverse study backgrounds. Computers and Education: Artifcial Intelligence, 2, 100026. https://doi.org/ 10.1016/j.caeai.2021.100026   
Kouroupis, K., & Vagianos, D. (2023). IoT in education: Implementation scenarios through the lens of data privacy law. Journal of Politics and Ethics in New Technologies and AI, 2(1), Article 1. https://doi.org/10.12681/jpentai.34616   
Laupichler, M. C., Aster, A., Schirch, J., & Raupach, T. (2022). Artifcial intelligence literacy in higher and adult education: A scoping literature review. Computers and Education: Artifcial Intelligence, 3, 100101. https://doi.org/10.1016/j.caeai. 2022.100101   
Lee, U., Jung, H., Jeon, Y., Sohn, Y., Hwang, W., Moon, J., & Kim, H. (2023). Few-shot is enough: Exploring ChatGPT prompt engineering method for automatic question generation in english education. Education and Information Technologies. https://doi.org/10.1007/s10639-023-12249-8   
Li, Y., Lin, Z., Zhang, S., Fu, Q., Chen, B., Lou, J.-G., & Chen, W. (2023). Making Large Language Models Better Reasoners with Step-Aware Verifer (arXiv:2206.02336). arXiv. https://doi.org/10.48550/arXiv.2206.02336   
Liu, J., Liu, A., Lu, X., Welleck, S., West, P., Bras, R. L., Choi, Y., & Hajishirzi, H. (2022). Generated Knowledge Prompting for Commonsense Reasoning (arXiv:2110.08387). arXiv. https://doi.org/10.48550/arXiv.2110.08387   
Liu, N. F., Lin, K., Hewitt, J., Paranjape, A., Bevilacqua, M., Petroni, F., & Liang, P. (2023). Lost in the Middle: How Language Models Use Long Contexts (arXiv:2307.03172). arXiv. https://doi.org/10.48550/arXiv.2307.03172   
Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., & Neubig, G. (2021). Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing (arXiv:2107.13586). arXiv. https://doi.org/10.48550/arXiv.2107.13586   
Locsin, R. C., Soriano, G. P., Juntasopeepun, P., Kunaviktikul, W., & Evangelista, L. S. (2021). Social transformation and social isolation of older adults: Digital technologies, nursing, healthcare. Collegian, 28(5), 551–558. https://doi.org/10. 1016/j.colegn.2021.01.005   
Malik, A. R., Pratiwi, Y., Andajani, K., Numertayasa, I. W., Suharti, S., & Darwis, A. (2023). Exploring artifcial intelligence in academic essay: Higher education student’s perspective. International Journal of Educational Research Open, 5, 100296. https://doi.org/10.1016/j.ijedro.2023.100296   
Margaryan, A. (2023). Artifcial intelligence and skills in the workplace: An integrative research agenda. Big Data & Society, 10(2), 20539517231206804. https://doi.org/10.1177/20539517231206804   
Minn, S. (2022). AI-assisted knowledge assessment techniques for adaptive learning environments. Computers and Education: Artifcial Intelligence, 3, 100050. https://doi.org/10.1016/j.caeai.2022.100050   
Mollenkamp, D. (2022, August 16). Popular K-12 Tool Edmodo Shuts Down—EdSurge News [Technology Blog]. EdSurge. https://www.edsurge.com/news/2022-08-16-popular-k-12-tool-edmodo-shuts-down   
Motlagh, N. Y., Khajavi, M., Sharif, A., & Ahmadi, M. (2023). The Impact of Artifcial Intelligence on the Evolution of Digital Education: A Comparative Study of OpenAI Text Generation Tools including ChatGPT, Bing Chat, Bard, and Ernie (arXiv: 2309.02029). arXiv. https://doi.org/10.48550/arXiv.2309.02029   
Muthmainnah, U., Ibna Seraj, P. M., & Oteir, I. (2022). Playing with AI to Investigate Human-Computer Interaction Technology and Improving Critical Thinking Skills to Pursue 21st Century Age. Education Research International, 2022, 1–17. https://doi.org/10.1155/2022/6468995   
Nanda, N., Chan, L., Lieberum, T., Smith, J., & Steinhardt, J. (2023). Progress measures for grokking via mechanistic interpretability (arXiv:2301.05217). arXiv. https://doi.org/10.48550/arXiv.2301.05217   
Ng, D. T. K., Lee, M., Tan, R. J. Y., Hu, X., Downie, J. S., & Chu, S. K. W. (2023a). A review of AI teaching and learning from 2000 to 2020. Education and Information Technologies, 28(7), 8445–8501. https://doi.org/10.1007/s10639-022-11491-w   
Ng, D. T. K., Leung, J. K. L., Su, J., Ng, R. C. W., & Chu, S. K. W. (2023b). Teachers’ AI digital competencies and twenty-frst century skills in the post-pandemic world. Educational Technology Research and Development, 71(1), 137–161. https:// doi.org/10.1007/s11423-023-10203-6   
Ng, D. T. K., Leung, J. K. L., Chu, S. K. W., & Qiao, M. S. (2021). Conceptualizing AI literacy: An exploratory review. Computers and Education: Artifcial Intelligence, 2, 100041. https://doi.org/10.1016/j.caeai.2021.100041   
Ng, D. T. K., Su, J., Leung, J. K. L., & Chu, S. K. W. (2023). Artifcial intelligence (AI) literacy education in secondary schools: A review. Interactive Learning Environments, 1–21. https://doi.org/10.1080/10494820.2023.2255228   
Ng, D. T. K., Wu, W., Lok Leung, J. K., & Wah Chu, S. K. (2023). Artifcial intelligence (AI) literacy questionnaire with confrmatory factor analysis. IEEE International Conference on Advanced Learning Technologies (ICALT), 2023, 233–235. https:// doi.org/10.1109/ICALT58122.2023.00074   
Nguyen, A., Ngo, H. N., Hong, Y., Dang, B., & Nguyen, B.-P.T. (2023). Ethical principles for artifcial intelligence in education. Education and Information Technologies, 28(4), 4221–4241. https://doi.org/10.1007/s10639-022-11316-w   
Okemwa, K. (2023, December 4). ChatGPT will provide more detailed and accurate responses if you pretend to tip it, according to a new study [News Portal]. Windows Central. Retrieved from https://www.windowscentral.com/software-apps/ chatgpt-will-provide-more-detailed-and-accurate-responses-if-you-pretend-to-tip-it-according-to-a-new-study   
Ottenbreit-Leftwich, A., Glazewski, $\mathsf { K } _ { \cdot , \cdot }$ Jeon, M., Jantaraweragul, $\mathsf { K } _ { \cdot , \cdot }$ Hmelo-Silver, C. E., Scribner, A., Lee, S., Mott, B., & Lester, J. (2023). Lessons Learned for AI Education with Elementary Students and Teachers. International Journal of Artifcial Intelligence in Education, 33(2), 267–289. https://doi.org/10.1007/s40593-022-00304-3   
Pangh, C. (2018, October 24). Scafolding (Rolle der Lehrkraft) [Lehrerinnenfortbildung: Baden-Württemberg]. Bildungsplan 2016. Retrieved from https://lehrerfortbildung-bw.de/u_sprachlit/deutsch/gym/bp2016/fb6/2_heterogenitaet/3_ reziprok/4_scafold/   
Rakap, S. (2023). Chatting with GPT: Enhancing individualized education program goal development for novice special education teachers. Journal of Special Education Technology, 01626434231211295. https://doi.org/10.1177/01626 434231211295   
Rane, N. (2023). Enhancing the Quality of Teaching and Learning through ChatGPT and Similar Large Language Models: Challenges, Future Prospects, and Ethical Considerations in Education (SSRN Scholarly Paper 4599104). https://doi.org/10. 2139/ssrn.4599104   
Roll, I., & Wylie, R. (2016). Evolution and revolution in artifcial intelligence in education. International Journal of Artifcial Intelligence in Education, 26(2), 582–599. https://doi.org/10.1007/s40593-016-0110-3   
Serholt, S., Barendregt, W., Vasalou, A., Alves-Oliveira, P., Jones, A., Petisca, S., & Paiva, A. (2017). The case of classroom robots: Teachers’ deliberations on the ethical tensions. AI & SOCIETY, 32(4), 613–631. https://doi.org/10.1007/ s00146-016-0667-2   
Southworth, J., Migliaccio, K., Glover, J., Glover, J., Reed, D., McCarty, C., Brendemuhl, J., & Thomas, A. (2023). Developing a model for AI Across the curriculum: Transforming the higher education landscape via innovation in AI literacy. Computers and Education: Artifcial Intelligence, 4, 100127. https://doi.org/10.1016/j.caeai.2023.100127   
Steele, J. L. (2023). To GPT or not GPT? Empowering our students to learn with AI. Computers and Education: Artifcial Intelligence, 5, 100160. https://doi.org/10.1016/j.caeai.2023.100160   
Tam, A. (2023, May 23). What Are Zero-Shot Prompting and Few-Shot Prompting [Online-Course]. Machine Learning Mastery. Retrieved from https://machinelearningmastery.com/what-are-zero-shot-prompting-and-few-shot-prompting/   
Taylor, M. E., & Boyer, W. (2020). Play-based learning: Evidence-based research to improve children’s learning experiences in the kindergarten classroom. Early Childhood Education Journal, 48(2), 127–133. https://doi.org/10.1007/ s10643-019-00989-7   
Tegousi, N., Drakopoulos, V., Tegousi, N., & Drakopoulos, V. (2020). Educational social networking services: The case of edmodo in the teaching practice. Trends in Computer Science and Information Technology, 5(1), 058–064. https://doi. org/10.17352/tcsit.000024   
Theophilou, E., Koyutürk, C., Yavari, M., Bursic, S., Donabauer, G., Telari, A., Testa, A., Boiano, R., Hernandez-Leo, D., Ruskov, M., Taibi, D., Gabbiadini, A., & Ognibene, D. (2023). Learning to Prompt in the Classroom to Understand AI Limits: A Pilot Study. In R. Basili, D. Lembo, C. Limongelli, & A. Orlandini (Eds.), AIxIA 2023 – Advances in Artifcial Intelligence (pp. 481–496). Springer Nature Switzerland. https://doi.org/10.1007/978-3-031-47546-7_33   
Tseng, Y. J., & Yadav, G. (2023). ActiveAI: Introducing AI literacy for middle school learners with goal-based scenario learning (arXiv:2309.12337). arXiv. https://doi.org/10.48550/arXiv.2309.12337   
van den Berg, G., & du Plessis, E. (2023). ChatGPT and generative AI: Possibilities for its contribution to lesson planning, critical thinking and openness in teacher education. Education Sciences, 13(10), Article 10. https://doi.org/10.3390/ educsci13100998   
Walter, Y. (2022). A Case Report On The “A.I. Locked-In Problem”: Social concerns with modern NLP (arXiv:2209.12687). arXiv. https://doi.org/10.48550/arXiv.2209.12687   
Wang, X., Wei, J., Schuurmans, D., Le, $\mathrm { \Delta Q } . ,$ Chi, E., Narang, S., Chowdhery, A., & Zhou, D. (2023). Self-consistency improves chain of thought reasoning in language models (arXiv:2203.11171). arXiv. https://doi.org/10.48550/arXiv.2203.11171   
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & Zhou, D. (2023). Chain-of-thought prompting elicits reasoning in large language models (arXiv:2201.11903). arXiv. https://doi.org/10.48550/arXiv.2201.11903   
Williams, R. (2021). How to train your robot: project-based ai and ethics education for middle school classrooms. Proceedings of the 52nd ACM Technical Symposium on Computer Science Education, 1382. https://doi.org/10.1145/3408877. 3439690   
Xu, B., Yang, A., Lin, J., Wang, Q., Zhou, C., Zhang, Y., & Mao, Z. (2023). Expertprompting: Instructing large language models to be distinguished experts (arXiv:2305.14688). arXiv. https://doi.org/10.48550/arXiv.2305.14688   
Yao, S., Yu, D., Zhao, J., Shafran, I., Grifths, T. L., Cao, Y., & Narasimhan, K. (2023). Tree of thoughts: Deliberate problem solving with large language models (arXiv:2305.10601). arXiv. https://doi.org/10.48550/arXiv.2305.10601   
Zawacki-Richter, O., Marín, V. I., Bond, M., & Gouverneur, F. (2019). Systematic review of research on artifcial intelligence applications in higher education—Where are the educators? International Journal of Educational Technology in Higher Education, 16(1), 39. https://doi.org/10.1186/s41239-019-0171-0   
Zhan, Z., He, G., Li, T., He, L., & Xiang, S. (2022). Efect of groups size on students’ learning achievement, motivation, cognitive load, collaborative problem-solving quality, and in-class interaction in an introductory AI course. Journal of Computer Assisted Learning, 38(6), 1807–1818. https://doi.org/10.1111/jcal.12722   
Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., & Breazeal, C. (2023). Integrating ethics and career futures with technical learning to promote AI literacy for middle school students: An exploratory study. International Journal of Artifcial Intelligence in Education, 33(2), 290–324. https://doi.org/10.1007/s40593-022-00293-3   
Zhou, Y., Muresanu, A. I., Han, Z., Paster, K., Pitis, S., Chan, H., & Ba, J. (2023). Large language models are human-level prompt engineers (arXiv:2211.01910). arXiv. https://doi.org/10.48550/arXiv.2211.01910   
Zimmermann, R. S., Klein, T., & Brendel, W. (2023). Scale alone does not improve mechanistic interpretability in vision models (arXiv:2307.05471). arXiv. https://doi.org/10.48550/arXiv.2307.05471   
Zou, A., Wang, Z., Kolter, J. Z., & Fredrikson, M. (2023). Universal and transferable adversarial attacks on aligned language models (arXiv:2307.15043). arXiv. https://doi.org/10.48550/arXiv.2307.15043

Publisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional afliations.