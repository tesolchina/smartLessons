# Exploring public perceptions of generative AI and education: topic modelling of YouTube comments in Korea

Hyo-Jeong So, Hyeji Jang, Minseon Kim & Jieun Choi

To cite this article: Hyo-Jeong So, Hyeji Jang, Minseon Kim & Jieun Choi (2024) Exploring public perceptions of generative AI and education: topic modelling of YouTube comments in Korea, Asia Pacific Journal of Education, 44:1, 61-80, DOI: 10.1080/02188791.2023.2294699

To link to this article: https://doi.org/10.1080/02188791.2023.2294699

# Exploring public perceptions of generative AI and education: topic modelling of YouTube comments in Korea

Hyo-Jeong So $\textcircled { 1 0 }$ , Hyeji Jang, Minseon Kim and Jieun Choi

Department of Educational Technology, Ewha Womans University, Seoul, Korea

# ABSTRACT

This study aims to investigate the public’s perceptions regarding the integration of Generative AI (GenAI) in education by analysing comments on YouTube news clips. The study collected public comments from YouTube news clips disseminated by three prominent broadcasters in South Korea between December 2022 and June 2023. Two dimensions of public perceptions were examined: sentiments and prevalent topics. Employing machine learning techniques, we conducted sentiment analysis and topic modelling on the crowdsourced dataset of 18,566 comments from 66 YouTube news clips. The first research question focused on public sentiments towards GenAI and education. Findings reveal a predominance of neutral sentiments. Rather than adopting extreme positions of complete acceptance or rejection, the public displayed an inclination to appreciate the intricate nuances of GenAI’s implications. The second research question sought to identify the main topics emerging from public comments on GenAI and education. We identified 11 distinct topics where two topics are directly linked to educational implications: demands for changes in learning and assessment methods, and the use of GenAI in higher education. Based on the key findings, we draw implications that can inform a broader understanding of public sentiment and perspective towards GenAI and education.

ARTICLE HISTORY Received 13 August 2023 Accepted 3 December 2023

# KEYWORDS

Generative AI; ChatGPT; topic modelling; public perceptions; YouTube

# Introduction

The rise of Generative Artificial Intelligence (GenAI), represented by online platforms like ChatGPT, Bard, and DALL·E, has brought about a significant turning point, reshaping the landscape of AI’s role in education. GenAI, which mimics human-like creation, generates various types of content such as images and text by utilizing advanced machine learning models (Lim et al., 2023). ChatGPT, introduced by OpenAI in November 2022, is the best-known GenAI that can generate new content in response to human prompts and through a series of responses. The advent of GenAI has the potential to synergistically enhance human creativity, which has been regarded as an attribute unique to humans (Eapen et al., 2023)

Concomitantly, growing concerns have emerged regarding the adoption of GenAI in education settings. These concerns involve issues such as inaccuracies in responses generated by ChatGPT, potential challenges related to the originality of student work and the risk of plagiarism, and the potential decline in students’ critical problem-solving abilities. Eminent linguist Noam Chomsky has voiced reservations about the use of GenAI, commenting that ChatGPT is “basically high-tech plagiarism” and “a way of avoiding learning” (Dwivedi et al., 2023). Moreover, the potentially negative impacts associated with ChatGPT have generated anxiety across various educational institutions, naturally leading to the enactment of regulatory measures. Some educational institutions have chosen to limit or ban the use of ChatGPT in student assignments as well as urging instructors to provide students with tasks that lie beyond the capabilities of ChatGPT (Nam, 2023).

The ongoing discourse surrounding GenAI, especially exemplified by ChatGPT, highlights what scholars have termed “digital dissonance” (Clark et al., 2008) or “digital disconnect” (Selwyn, 2006). These concepts describe the situation where a new technology introduces conflicting tensions in education, stemming from an incomplete understanding of potentially positive and negative impacts. Throughout the history of educational technology, instances of such dissonance and disconnect abound, including the usage of social networking platforms and mobile devices. The utilization of mobile devices often clashes with school regulations, leading to a discord between students’ daily lives and their educational environment (Clark et al., 2008). As the education landscape enters a novel phase under the potential influence of GenAI, it becomes imperative to understand what people perceive about the current phenomenon of digital dissonance and disconnect with GenAI in education.

Against this backdrop, the present study aims to examine how the general public perceives GenAI and education, using public comments from YouTube news clips as our source of insight. The motivation for this research comes from two main ideas. Firstly, it is posited that the public’s stance on integrating emerging technology like GenAI as an educational tool is profoundly influenced by how mass media – such as television and newspapers – portrays it to the viewership. Within the domain of persuasive communication, the influence of mass media over people’s attitudes and perceptions on various societal topics has been extensively documented (Perloff, 2020). This premise is rooted in the seminal work of McCombs and Shaw (1972) on public communication, which introduced the concept of agenda-setting – a function whereby mass media channels public attention towards specific subjects. The authors argue that an implicit form of learning occurs through media consumption, whereby individuals “learn not only about a given issue, but also how much importance to attach to that issue from the amount of information in a news story and its position” (McCombs & Shaw, 1972, p. 176). In light of this, this study uses television news and viewers’ comments to understand how the public learns about the emergence of GenAI, potentially shaping their attitude towards GenAI’s potential in education.

The second premise posits that social media has evolved into an arena for knowledge sharing and building. As traditional mass media transitions to digital platforms, social media emerges as a pivotal space for communication, facilitating the instant exchange of ideas and debates. Within the domain of public perceptions, extant research demonstrates the efficacy of social media as a space for idea sharing and generation, often focusing on its role in framing political discourses (e.g., elections) and the spread of fake news and misleading information (Rampersad & Althiyabi, 2020). Given the pivotal role of social media for public expression, this study chose YouTube comments for investigating public perceptions concerning GenAI and education. The choice of YouTube as the primary data source, among various social media platforms, stems from this study’s emphasis on crowdsourcing public perceptions. Furthermore, YouTube stands out as one of the most frequently accessed social media platforms in South Korea. Regarding the penetration rate, South Korea ranks seventh in YouTube views by country, accumulating 204 billion views per month, translating to an average of 4,000 views per person (GMI, 2023). As of October 2023, it maintains an $8 9 . 9 \%$ YouTube penetration rate among its 46 million users, signifying YouTube’s widespread use within the social media landscape in South Korea (Kemp, 2023).

In essence, this study aims to explore the public’s perception regarding the influence of GenAI in education, through the analysis of public comments within YouTube news clips. We crowdsourced public comments spanning from 1 December 2022 to 30 June 2023 in YouTube news clips that addressed GenAI and education as main topics, disseminated by the three leading broadcasters in South Korea through their respective YouTube channels. Two aspects of public perceptions were explored through the analysis of crowdsourced data: (a) sentiments expressed in comments and (b) topics frequently discussed by the public. Methodologically, we used a machine learning technique in sentiment analysis and topic modelling to identify latent sentiments and topics in the textual data of YouTube comments. The overarching research questions that guided the current study are as follows:

(1) What are the sentiments expressed in the public comments on YouTube news clips about GenAI and education?   
(2) What are the main topics that the public perceives about GenAI and education, as evidenced by crowdsourced data from comments on YouTube news clips?

# Theoretical background

# Generative AI and education

Generative AI (GenAI) is defined as a computer technology that creates artefacts through unsupervised or partially supervised learning based on vast volumes of data. GenAI has gained popularity with the introduction of ChatGPT, which is an AI system on large language models (LLM) designed to facilitate conversational interactions between the system and users (OpenAI, n.d..).

In education, researchers have explored the potential of integrating GenAI across various academic disciplines and student groups. In the context of biology education, ChatGPT has demonstrated an acceptable level of accuracy in its responses to inquiries, achieving an $8 0 \%$ success rate (Das et al., 2023). In the medical field, ChatGPT has exhibited proficiency by obtaining a passing grade in a specialized medical examination equivalent to that of a third-year medical school student (Gilson et al., 2023). Additionally, ChatGPT was used in safety education and training, enhancing students’ hazard recognition abilities (Uddin et al., 2023). Wang et al. (2023) noted that AI technologies, including Generative AI, chatbots, and analytics tools, offer significant advantages to international students struggling with English-language studies. These technologies provide personalized learning resources and adaptive feedback, thereby contributing to the academic success of international students.

In the field of language learning, Yan (2023) examined how L2 (second language) students engaged with ChatGPT for writing purposes. This investigation revealed students’ concerns regarding academic integrity and educational equity when employing ChatGPT for writing assistance. Within the context of South Korea, Kim (2023) explored the cognitive processes of high school students while tackling English reading questions in the College Scholastic Ability Test, locally known as “Su-neung”. The research revealed that ChatGPT displayed impressive performance in addressing factual information and drawing inferences from textual content.

Furthermore, the analysis of the implications of GenAI within the educational domain indicates both its promising prospects and the inherent challenges. As delineated in Table 1, the scholarly discourse reveals prevalent themes about the potential benefits of ChatGPT in education (Farrokhnia et al., 2023; Kasneci et al., 2023; Rahman & Watanobe, 2023; Rawas, 2023). These themes underscore the enhancement of information accessibility, the facilitation of personalized learning, the reduction of teaching workloads, the automation of grading and assessment, and the provision of intelligent tutoring as key advantages, collectively enriching the educational experience for both educators and students. However, the integration of AI models like ChatGPT in educational settings also engenders interrelated concerns, as observed across the literature. These encompass (a) issues relating to academic integrity, encompassing the perils of plagiarism and copyright infringements; (b) educational implications, including concerns about the decline in cognitive skills and an overreliance on AI models; (c) ethical and bias considerations, with a focus on the diminished human interaction; (d) data privacy and security; and (e) technical and implementation challenges (e.g., cost). While extant research underscores GenAI’s potential to reshape educational practices fundamentally, it concurrently highlights the existence of distinct challenges that necessitate further scholarly inquiry to unravel the intricate facets of GenAI’s application in educational contexts.

Table 1. Opportunities and challenges of GenAI in education.   

<html><body><table><tr><td>Authors &amp; Context</td><td>Opportunities</td><td>Challenges</td></tr><tr><td>Farrokhnia et al. (2023) Higher education</td><td>Increasing accessibility of information, Facilitating Lack of understanding of the context, Threatening personalized learning, Facilitating complex learning, Decreasing teaching work. load</td><td>academic integrity, Perpetuating discrimination in education, Democratization of plagiarism in education/research, Declining in high-order cognitive skills</td></tr><tr><td>Kasneci et al. (2023) General education</td><td>Create educational content, Improve student engagement and interaction, Personalize learning experiences</td><td>Copyright issues, Bias and fairness Learners&#x27; and teachers&#x27; heavy reliance on the model, Difficulty in distinguishing model- generated answers, Cost of training and maintenance, Data privacy and security, Lack of</td></tr><tr><td>Rawas (2023) Higher education</td><td>Personalized learning, Interactive learning, Automated grading, Intelligent tutoring</td><td>adaptability, etc. Bias and ethics, Lack of human interaction, Privacy and security, Technical issues, Cost and implementation Difficulty in evaluating the ChatGPT-generated answers and texts</td></tr><tr><td>Rahman and Watanobe (2023) General education &amp; Coding education</td><td>Rapid assessment and evaluation, Solving complex problems, Developing reading and writing skills, Personalized guidance, Debugging and code optimization</td><td>Integrity of assignments and online exams, Difficulty in evaluating the ChatGPT-generated answers and texts, Ethical implications and potential biases, Critical thinking and problem- solving skills</td></tr></table></body></html>

# Public perceptions of generative AI and education on social media

Within the history of educational technology, the advent of emerging technologies has frequently elicited anticipation for introducing innovative approaches to teaching and learning (Selwyn, 2013). During the initial phase of introducing emerging technologies, both optimistic and sceptical viewpoints coexist, arising from divergent values and unsettled opinions. The integration of emerging technologies into educational settings, thus, is intricately intertwined with socio-cultural dynamics. Various socio-cultural factors, such as the pedagogical legitimacy of technology utilization and the alignment with established policies, intermingle with the technical attributes such as the functionality and maturation of the technology itself (Kye et al., 2017). This intricate interplay delineates the complexity of adopting emerging technologies within the educational context.

Understanding the collective sentiments held by the wider public regarding the potential merits and drawbacks of emerging technologies holds significance for researchers, educators, and other education stakeholders. The insights from the public views can help these individuals develop strategic considerations essential for the informed and purposeful integration of these technological innovations within educational domains. Given the inherently democratic nature of communication, social media emerges as a legitimate platform that scholars have explored public perceptions concerning using emerging technologies in education. In Table 2, we synthesized research studies that used social media to explore public perceptions about GenAI and/or ChatGPT in education and associate domains.

As seen in Table 2, Twitter appears as the most popular medium to aggregate public narratives about GenAI and/or ChatGPT. The studies conducted by Leiter et al. (2023) and Taecharungroj (2023) identified key dimensions of early-stage perceptions that the public held about the educational utilization of ChatGPT. Leiter et al. (2023) conducted a sentiment analysis encompassing over 300,000 tweets to examine the prevailing perceptions of ChatGPT within Twitter. The findings reveal that ChatGPT was associated with positive sentiments and the emotion of joy. Moreover, the study analysed more than 150 scientific papers about ChatGPT. The analysis indicates a positive outlook of ChatGPT within the medical field but mixed perceptions in the education domain, characterized by ChatGPT’s potential to disrupt traditional education and ethical concerns. Taecharungroj (2023) explored 233,914 tweets utilizing the Latent Dirichlet Allocation (LDA) topic modelling algorithm. The findings revealed that the tweets were mostly clustered around three overarching topics – news, technology, and reactions – encompassing five functional domains of ChatGPT: creative writing, essay composition, prompt generation, code scripting, and question answering.

Table 2. Previous research that used crowdsourced data in social media.   

<html><body><table><tr><td>Research</td><td>Data</td><td>Analysis method</td><td>Key findings</td></tr><tr><td>Haensch et al. (2023)</td><td>TikTok</td><td>Content analysis</td><td>More videos promoted the use of ChatGPT in a positive light Lack of critical videos on limitations and ethical concerns</td></tr><tr><td>Leiter et al. (2023)</td><td></td><td>Twitter Sentiment analysis</td><td>Mixed views in the education domain More positive perceptions in other fields like the medical domain</td></tr><tr><td></td><td></td><td>Li et al. (2023)Twitter BERT-based topic modelling, Social network analysis</td><td>5 areas of concern: academic integrity, impact on learning outcomes and skill development, limitation of capabilities,</td></tr><tr><td>(2023)</td><td></td><td>Taecharungroj Twitter LDA topic modelling</td><td>policy and social concerns, and workforce challenges 3 main themes: news, technology, and reactions 5 functional domains: creative writing, essay writing, prompt</td></tr><tr><td>Tlili et al. (2023)</td><td></td><td>Twitter Social network analysis, sentiment analysis</td><td>writing, code writing, and answering questions More positive sentiments than negative sentiments The majority were non-categorized sentiments, indicating neu- tral stances</td></tr></table></body></html>

Other studies in Table 2 focused on eliciting specific implications within the educational domain. Li et al. (2023), for instance, employed a BERT-based topic modelling and social network analysis to explore the public discourse about ChatGPT’s educational implications, using Twitter as a primary data source. Their findings indicated a spectrum of concerns and anxieties, clustered within five categories: academic integrity, impact on learning outcomes and skill development, limitation of capabilities, policy and social concerns, and workforce-related challenges. In a similar vein, Tlili et al. (2023) used Twitter to understand the public discourse on the use of ChatGPT in education. Through a sentiment analysis of tweets, the study found that the positive sentiments outweigh the negative sentiments. A substantial proportion $( 9 2 . 5 \% )$ of tweets existed in an unclassified sentiment, indicative of a prevailing state of indecision and neutrality regarding the educational use of ChatGPT. Haensch et al. (2023) used TikTok to unpack learners’ perceptions of ChatGPT. The study analysed the 100 most popular videos under the hashtag #chatGPT on TikTok, with a cumulative viewership exceeding 250 million. More than half (53 out of 100) of the examined TikTok videos portrayed ChatGPT’s merits such as essay composition and question answering. Positive videos received more likes, shares, and views than critical videos. The researcher raised the concerns that inherent limitations and ethical issues of ChatGPT were given minimal attention within the TikTok discourse.

Overall, the collective body of existing literature reveals the complex nature of public perceptions regarding ChatGPT’s role in education. While some optimistic viewpoints emphasize the technology’s potential for transformation, numerous studies underscore the challenges and ethical implications. Thus, moving beyond the binary stance of complete acceptance or rejection, it becomes essential to examine the intricate dynamics of adopting emerging technologies like GenAI in education. This deeper understanding is fundamental to effectively integrating such technologies into the teaching and learning processes. Thus, this study aims to examine the multifaceted nature of GenAI and education by analysing public comments on YouTube. This study concentrates on TV news clips and the accompanying YouTube comments, shedding light on general perceptions rather than those held by specific groups. To the best of our knowledge, this is the first research to report the perception of the Korean public regarding GenAI and its impact on education through the analysis of YouTube comments.

# Method

# Data collection

This study aims to explore public perceptions regarding the integration of GenAI in educational settings through the analysis of public discourse present in news clips hosted on YouTube channels. The initial data collection phase involved the identification of eligible news clips accessible on the YouTube platform. We carried out a systematic search for news clips disseminated by three major broadcasting entities: KBS (Korea Broadcasting System), MBC (Munhwa Broadcasting Corporation), and SBS (Seoul Broadcasting System). These free-to-air national TV networks, accessible without a subscription, have a broad viewership in South Korea. Furthermore, as of October 2023, their YouTube news channels boast substantial subscriber bases, with KBS News having 2.61 million subscribers, MBC News with 3.86 million, and SBS News with 3.85 million subscribers.

Table 3. Inclusion and exclusion criteria in collecting news clips.   

<html><body><table><tr><td colspan="2">Inclusion Exclusion</td></tr><tr><td>News clips that contain the educational utility of GenAl. News clips that contain the broader implications for</td><td>News formats that are not straight news (e.g., inter- views, debates, and documentaries)</td></tr><tr><td>education News clips that include GenAl&#x27;s impact on societal dimen-</td><td>News clips with limited viewer engagement (i.e., comprising fewer than 10 comments)</td></tr><tr><td>sions associated with education (e.g., changes in job mar- kets, ethical and moral issues, etc.)</td><td>News clips that focuse solely on technical functions of GenAI and/or ChatGPT (e.g., performance evaluation)</td></tr></table></body></html>

The selection of relevant videos was guided by specific keywords related to the present study such as “Generative AI”, “ChatGPT”, “education”, “learning”, and combinations thereof. The timeframe for this search was spanning from 1 December 2022 to 30 June 2023, considering that news media started featuring GenAI following the introduction of ChatGPT in late November 2022. In collecting news clips, we applied a set of inclusion and exclusion criteria that systematically guided the collection process, as summarized in Table 3.

As illustrated in Figure 1, the PRISMA procedure was used to screen news clips suitable for our analysis. During the identification phase, a total of 164 news clips were identified on YouTube, all of which referred to the educational use and implications of GenAI and/or ChatGPT. In the screening phase, 79 clips were excluded since they were non-straight news formats (e.g., interviews, debates, documentaries) or they had limited viewer engagement with less than 10 user comments. During the inclusion stage, we reviewed 85 eligible clips and excluded 19 clips because of the lack of educational implications (e.g., reporting purely technical issues). Consequently, we identified a final set comprising 66 news clips suitable for our in-depth analysis.

The subsequent step was to identify the corpus of viewers’ comments for analysis. In 66 news clips identified earlier, there was a total of 23,048 comments from viewers. While YouTube integrates automated comment filtering mechanisms to detect and conceal potentially inappropriate or spamrelated content, our examination revealed a substantial number of comments containing offensive language and other forms of inappropriate content. Consequently, we conducted a manual filtration process, which resulted in excluding 1,299 disruptive comments containing political or sexual content irrelevant to the topics of news clips. This process left 21,749 YouTube comments eligible for this study.

As YouTube statistics are exclusively accessible to channel administrators, gathering demographic data for the commenters was unattainable. According to the most recent global report (GMI, 2023), the gender distribution on YouTube is nearly even, with males and females each constituting $5 0 \%$ of the user base. For South Korean users, the 2022 report (Cho, 2022) indicates that YouTube ranks as the second most frequently used app in the country, boasting 44.98 million users. Predominantly, users are in their forties $( 2 3 . 5 \% )$ , followed by individuals in their twenties $( 1 8 . 4 \% )$ and thirties $( 1 8 . 3 \% )$ . Drawing from these statistics, it is reasonable to surmise that our viewers fall within the age range of their twenties to forties, with near gender parity. However, this is speculative in nature and underscores one of the limitations inherent in research conducted with crowdsourced data from social media platforms.

![](img/f526ee6bd7e507d09822291db646e23bee28458a047fd8ecd20db8ce5bbf4694.jpg)  
Figure 1. PRISMA flowchart of the news clip selection process.

# Data analysis

# Sentiment analysis

Sentiment analysis, also known as opinion mining, is a natural language processing (NLP) technique to classify “people’s opinions, sentiments, evaluations, appraisals, attitudes, and emotions towards entities” (Liu, 2022, p. 1) such as certain products, issues, and topics. Methodologically, sentiment analysis is used to automatically identify whether the expressed sentiment in the text is positive, negative, or neutral. For sentiment analysis, we used an R package to explore what kinds of sentiments the Korean public tends to associate with the use of GenAI and education.

In conducting sentiment analysis, we adhered to the procedural guidelines proposed by Kim (2021), with specific attention to the composition of textual data in the Korean language. As part of our preprocessing, we initially tokenized the comments on a word-by-word basis. To determine sentiments, we employed the KNU sentiment lexicon, a well-established Korean sentiment dictionary (Park et al., 2018). This lexicon comprises 14,854 sentiment-related words, each assigned a polarity rating on a scale of −2, −1, 0, 1, or 2, reflecting the intensity of emotions conveyed. A score closer to 2 indicates more positive emotions, while a score closer to $^ { - 2 }$ signifies more negative emotions. Using this lexicon, we calculated sentiment scores for words within a sentence and aggregated them to identify the overall sentiment expressed in the sentence. Sentiment scores were categorized as positive if the score was greater than or equal to 1, neutral if it fell between −1 and 1 (exclusive), and negative if it was less than or equal to −1. A selection of sentiment classification examples can be found in Table 4.

To ensure robustness, we conducted external validation through three human experts who specialize in educational technology and are knowledgeable about the content topic (i.e., GenAI in education). We provided them with a random sample of 15 YouTube comments from the data source and requested them to classify each comment as positive, neutral, or negative in sentiment. The accuracy percentage was subsequently calculated based on their responses.

Table 4. Examples of the sentiment classification.   

<html><body><table><tr><td>Sentiment</td><td>Example</td></tr><tr><td>Positive</td><td>I&#x27;m a university student right now. It&#x27;s truly amazing how helpful it is when I study for my Python midterm exam. If you input a code with an error, it automatically corrects it. If i is used for educational purposes, it&#x27;s a great Al. It&#x27;s a shame that good technologies are hindered by ethical issues.</td></tr><tr><td>Neutral</td><td>There&#x27;s no way to stop it. You can&#x27;t detect whether a piece of text has been obtained through ChatGPT. The original plagiarism detection software catches it if there are six words in a sentence. But ChatGPT? It&#x27;s uncontrollable now. The only way is to make the boundary for usage stricter.</td></tr><tr><td>Negative</td><td>I think it&#x27;s a misguided idea. Self-questioning and the ability to articulate and explain one&#x27;s thoughts to others are crucial processes that lead to deeper understanding. Simply allowing GPT to readily provide answers can potentially harm the learner&#x27;s ability for self-improvement.</td></tr></table></body></html>

# LDA-based topic modelling

LDA-based topic modelling was conducted using R4.2.1 and RStudio $2 0 2 3 . 0 3 . 0 + 3 8 6$ to identify themes embedded within viewer comments. In topic modelling, the Latent Dirichlet Algorithm (LDA) is a widely utilized machine learning algorithm, which automatically detects the semantic structures of topics from textual data sources (Ekin et al., 2023). First, in the pre-processing phase, the distinct() function from the dplyr package was employed to identify concise comments containing three or less words that were not conducive to the topic model creation (Kim, 2021). Second, we used the KoNLP package to dissect the morphological composition of Korean texts and extract nouns. A pool of stop-words, which are general words with minimal or no value to meaningful topic extraction (e.g., who, self, instead, you, all, etc.) was integrated to systematically clean the text and to formulate a Document-Term Matrix (DTM). Third, further refinement was done through hyperparameter tuning to determine an optimal number of topics $( K )$ for LDA-based topic modelling. The hyperparameter technique involved exploring multiple potential topic models through four performance metrics, namely the Arun2010 (Arun et al., 2010), CaoJuan2009 (Cao et al., 2009), Deveaud2014 (Deveaud et al., 2014), and Griffiths 2004 (Griffiths & Steyvers, 2004).

We set the range of topic models between 2 and 20 topics and examined the performance indicators of the four metrics to decide on an optimal number of topics. Lastly, the topicmodels package facilitated the execution of LDA-based topic modelling (Grün & Hornik, 2011). We applied LDA() function to create the LDA models and to figure out beta and gamma. Beta (β) represents the probability of a word appearing in each topic while gamma(γ) represents the probability that a comment appears in each topic. To determine which topic the comment is more likely to appear on, the topic with the highest gamma value was extracted for each comment and the topic number was assigned to the comments.

To assess topic validity, we employed three methods recommended in the literature, of topic modelling (e.g., Maier et al., 2018; Quinn et al., 2010). Firstly, we evaluated intra-topic semantic validity, focusing on the semantic coherence and relevance of topics (Nguyen & Jenkins, 2020). This entailed organizing all comments based on topics, sorted in descending order of their gamma values, which represent the likelihood of a comment’s association with each topic. Secondly, human judgement played a pivotal role in creating meaningful topic labels. We examined the top 10 keywords and their corresponding comments within each topic through multiple rounds of discussions to formulate semantically representative and meaningful topic labels. Third, we conducted external validation of the topic modelling results by engaging three domain experts, who also participated in the validation of sentiment analysis. They were asked to evaluate the topic labels alongside the keywords and representative comments on the survey that probed the relevance and mutual exclusivity of the topic labels on a five-point Likert scale ( $1 =$ strongly disagree, $5 =$ strongly agree). Based on their responses, we calculated the Content Validity Index (CVI) and Interrater Agreement (IRA), as suggested by Rubio et al. (2003).

![](img/3e6fee7dd9a36b95bedb2f33a87b2cfae73ca15740ca8281dbdcab14732e7ff4.jpg)  
Figure 2. Monthly number of news clips related to GAI in education on YouTube.

# Results

# Overall trends of news clips on GenAI and education

To understand the overall trend of news clips centred on GenAI and education, we analysed their release months and main themes. As illustrated in Figure 2, news clips concerning GAI and education first emerged in December 2022 and gained momentum in February $( n = 2 9 )$ and March $( n = 1 7 )$ in 2023. The number of news clips showed a marked decline from April onwards, indicative of waning attention on GenAI as a TV news topic.

To understand the intricate relationship between viewer comments and the content of news clips, we identified the prevailing themes within each news clip. This analysis adopted a bottomup approach by three researchers who watched each news clip, read the accompanying news scripts, and engaged in discussions to delineate the most prominent themes in the news content. The news clips were categorized into five overarching themes: education, ethics, society, technology, and industry. The “Technology” theme was assigned specifically when a news clip predominantly presents technical aspects and performances. A selection of news clip titles exemplifying these themes is presented in Table 5. It is imperative to highlight that while this study primarily focuses on the educational dimensions of GenAI, these clips explored broader facets of GenAI, including its societal impacts, its influence on job markets, and ethical considerations, underscoring the multifaceted nature of GenAI.

Table 5. Sample news titles on GenAI and education.   

<html><body><table><tr><td>Title</td><td>Broadcaster</td><td>Themes</td></tr><tr><td>ChatGPT&quot; Passes Doctor and Lawyer Exams. Shock Beyond &quot;AlphaGo&quot;</td><td>MBC</td><td>Education, Society</td></tr><tr><td>What Are the College Scholastic Ability Test (CSAT) Scores Achieved by &#x27;ChatGPT&#x27;?... Urgent KBS Need for Ethical Consensus Amidst Soaring Popularity.</td><td></td><td>Education, Ethics</td></tr><tr><td>Can We Stop It, or Should We Recommend It?... Universities in Turmoil Over ChatGPT</td><td>SBS</td><td>Education, Ethics</td></tr><tr><td>Finally Released GPT-4... Korean Language Proficiency Improved in Photo Recognition A Book Finished in Just 7 Hours... The Era of Al Publishing?</td><td>KBS MBC</td><td>Technology Society, industry</td></tr></table></body></html>

![](img/aca28e4e01f93a45a558d8c761f9ee991434af660ae1f8af5d032d89cd5ca745.jpg)  
Figure 3. Mapping news clips themes and release month.

Illustrated in Figure 3, a visual representation was created to juxtapose the themes of news clips and their corresponding release months. In coding news clip themes, we allowed dual-coding since a single news clip might address multiple themes. Overall, 30 news clips were prominently associated with educational facets of GenAI. During the peak in February 2023, diverse themes were covered in the TV news, with 18 news clips prominently featuring GAI in education. Themes around ethical considerations $( n = 3 5 )$ , societal implications $( n = 3 0 )$ ), and impacts on the industry sector $( n = 2 2 )$ ) appeared consistently across months.

# Sentiment analysis

As shown in Figure 4, the sentiment analysis indicates that positive sentiments $( 1 3 . 8 6 \% )$ slightly outweigh negative sentiments $( 1 2 . 6 6 \% )$ . The majority of comments $( 7 3 . 4 8 \% )$ in the dataset were identified as neutral. The result implies that most public comments show a neutral position towards the use of GenAI in education rather than having an opinionated view. We also analysed the top 10 keywords associated with positive or negative sentiments. “Good” appears as the top keyword associated with positive sentiments, followed by “intelligent”, “outstanding”, “incredible”, “best”, “easily”, “appropriate”, “proper”, “logical”, and “positive”. On the other hand, “wrong”, “terrible” and “foolish” frequently appeared to describe negative sentiments. Other keywords associated with negative sentiments include “bad”, “difficult”, “dangerous”, “fake”, “worried”, “negative”, and “severe”. To validate our sentiment analysis results, three experts classified randomly selected comments into positive, neutral, or negative sentiments. Their evaluations demonstrated an $8 4 \%$ accuracy, with an average rating of 12.6 out of 15, indicating the acceptable level of agreement between the machine learning technique and human judgement in our sentiment analysis results.

![](img/768e3a926217e20c381df61f2e31f24dca336144e43b6791c84157dcdda78931.jpg)  
Figure 4. Sentiment analysis of the public comments.

# LDA-based topic modelling

In this study, we gathered 21,749 comments from 66 news clips and performed topic modelling analysis. During the preprocessing phase, comments with three or more words were extracted, resulting in the analysis of 18,566 comments $( 8 5 . 3 7 \%$ of the total). The remaining 3,183 comments $( 1 4 . 6 3 \% )$ were excluded from the analysis due to their brevity, containing less than three words, or not aligning with any discernible topics. By using hyperparameter tuning, 2 to 20 topic models were created. Through four metrics in Figure 5, we identified the performance indicators of each model and determined the optimal number of topics. Griffiths2004 and Deveaud2014 imply a more appropriate number of latent topics when the performance indicator is close to 1. In the case of CaoJuan2009 and Arun2010, the smaller the performance indicator is, the more appropriate number of latent topics is. Among the four metrics, we chose to decide the optimal topic number using Griffiths2004, CaoJuan2009, and Arun2010 as Deveaud2014 unusually showed a continuous decline. As shown in Figure 5, we observed a continuous decline in Arun2010 and a sharp drop at 12 in CaoJuan2009. Although CaoJuan2009 shows a sharp drop at 12, a similar performance in topics 11 and 12 is observed with Griffith2004. Generally, the number of topics is determined at the point where the performance indicator ceases to exhibit significant improvement despite the increase in the number of topics (Kim, 2021). Therefore, we decided on 11 as the optimal number of topics for our dataset.

To assign topic labels, we considered keywords associated with each topic and their corresponding gamma values. The distribution of 11 topics and their respective top 10 keywords is presented in Table 6. The results show a relatively even distribution of 11 topics throughout the comments. Toprated topics were the risk of personal data leakage $( 1 0 . 4 6 \% )$ , realizing the envisioned future with GenAI $( 1 0 . 1 0 \% )$ , replacing human jobs in the legal field $( 9 . 7 7 \% )$ , demands for changes in learning and assessment methods $( 9 . 3 6 \% )$ , and controversial views on the use of GenAI in work settings.

Appendix A presents the list of sample comments on YouTube representing each topic label. While the list is not exhaustive due to the space limit, these examples give some ideas about what are the issues that the public shared and debated. On the whole, the topic labels and the distribution of comments indicate public opinions on diverse topics. These topics encompass not only the direct implications of GenAI on education such as assessment, but also extend to broader issues such as data security, job replacement, workforce transformation, and changes in work settings.

![](img/31479eac68b7e57a654468f66d87934d27a99dabb4cd00550e6dea0e020fb204.jpg)  
Figure 5. Performance indicator graph.

Table 6. Topic labels, representative keywords, and topic proportions.   

<html><body><table><tr><td>Topic #</td><td>Topic label</td><td>Top 10 keywords</td><td>No. of comments</td><td>(%)</td></tr><tr><td>1</td><td>The risk of personal data leakage</td><td>number, Google, personal information, request, credit card, Naver, Kakao, verification, suspicion, responsibility</td><td>1,941</td><td>10.46%</td></tr><tr><td>2</td><td>with GenAI</td><td>Realizing the envisioned future Terminator, domination, earth, world, Skynet, annihilation, war, weapon, termination, seriousness</td><td>1,875</td><td>10.10%</td></tr><tr><td>3</td><td>Replacing human jobs in the legal field</td><td>introduction, judges and prosecutors, precedent, nation, citizens, crime, justice, judiciary, legal profession, interpretation</td><td>1,813</td><td>9.77%</td></tr><tr><td>4</td><td>Demands for changes in. learning and assessment methods</td><td>creativity, K-CSAT, school, process, method, assessment, mathematics, correct answer, memorization, direction, concept</td><td>1,738</td><td>9.36%</td></tr><tr><td>5</td><td>Controversial views on the use of GenAl in work settingse</td><td>Samsung, hacking, coding, work, conversation, management, government official, leakage, company, open, employee</td><td>1,704</td><td>9.18%</td></tr><tr><td>6</td><td>Reliability and accuracy of. GenAI responses</td><td>intelligence, accuracy, information, falsehood, fact, tool, dependence, check, function, limit</td><td>1,615</td><td>8.70%</td></tr><tr><td>7</td><td>GenAl with creative abilities</td><td>response, field, painting, language, word, imagination,. creation, composition, novel, expertise</td><td>1,611</td><td>8.68%</td></tr><tr><td>8</td><td>Restructuring international power relations in the era of GenAI</td><td>possibility, existence, country, resistance, economy, slave, opponent, disregard, negativity, competition</td><td>1,589</td><td>8.56%</td></tr><tr><td>9</td><td>The use of GenAl in higher education</td><td>research, job, prohibition, basics, evolution, system,. organization, university student, intelligence, professor</td><td>1,576</td><td>8.49%</td></tr><tr><td>10</td><td>The impact of GenAI on the industrial market</td><td>computer, transformation, practitioner, science, market, industry, threat, past, error, speed</td><td>1,552</td><td>8.36%</td></tr><tr><td>11</td><td>and concerns regarding GenAI</td><td>The coexistence of expectations situation, control, abuse, concern, behavior, impossibility, curiosity, preparation, individual, comparison</td><td>1,552</td><td>8.36%</td></tr></table></body></html>

For the validation of the topic labels, three domain experts examined the topic labels, associated keywords, and representative comments, and indicated their agreement on a 5-point Likert scale. Both the Content Validity Index (CVI) and Inter-Rater Agreement (IRA) were 1.0, surpassing the acceptable level of .80 (Polit & Beck, 2006; Rubio et al., 2003).

# Classification of topics

As we observed that 11 topics extracted through topic modelling encompassed a broad spectrum of issues surrounding GenAI and education, we attempted to classify and visualize them towards meaningful interpretations. This process was undertaken manually by the research team through iterative discussions. Initially, we aligned 11 topics with the five prevailing themes present in the news clips, namely education, ethics, society, technology, and industry. We positioned education as the overarching theme, while the remaining four themes formed the peripheral aspects linked to education. With this framework in place, each of the identified topics was allocated to the dimensions that best aligned with their content. The classification of 11 topics within the thematic framework is visualized in Figure 6. It appears that no topic was placed under the theme “Technology”. This might be associated with our exclusion criteria to remove news clips that only focus on technical aspects.

Two topics (4 & 9) solely focus on educational issues. In Topic 4 “Demands for changes in learning and assessment methods”, the public comments pointed out the limitations of traditional didactic education and the need to reframe current education systems due to the emergence of GenAI.

![](img/7d8e0f696b2f98a1292b9330392ca13c313f602bb1f1ca80e46fa9f177dc15c2.jpg)  
Figure 6. A visualization of topic classifications.

Numerous comments emphasized that learning and assessment methods need to shift towards problem-based and discussion-centred learning, which can foster higher-order cognitive skills. In Topic 9, the public comments mainly deal with “The use of GenAI in higher education”. The public discussed the potential issues that could arise from using ChatGPT when writing or evaluating assignments at a university where academic integrity is an essential value.

The theme “Society” appears to have the most topics classified. (Topics 2, 6, 7. 8, 10, 11). The public comments under Topic 2 “Realizing the envisioned future with GenAI”’ often mentioned the futuristic images depicted in famous movies like “Terminator” and “The Matrix” and also raised the concern that humans would be controlled by GenAI in the future as those movies depicted. Topic 7 represents the public views on “Human creativity and creation”. Specifically, the public was debating whether creation pertains to the realm of human uniqueness, or is replaceable by AI. Topic 8 “Restructuring international power relations in the era of GenAI” represents the public perception concerning the impact of GenAI in the broader international landscape. Viewers shared their opinions about the emerging restructure of power relations between nations with AI and those without AI. Topic 11 “Coexistence of expectations and concerns regarding GenAI” underscores the complex landscape of GenAI in the initial phase of adoption. Public comments on this topic centred on comparing the positive and negative aspects of GenAI, which includes the need to control its use to prevent potential harm.

Five topics (1, 3, 5, 7, 10) were clustered under the theme of “Industry”. Under Topic 1 “The risk of personal data leakage”, many comments shared concerns about passing personal data to companies developing GenAI and the need for regulations. In Topic 3 “Replacing human jobs in the legal field”, the prevailing comment was that if GenAI were to learn from legal precedents, it could render more impartial judgements than humans. Opposing voices coexist such as asserting that human interpretation of the law is still necessary for making fair judgements. Topic 5 mainly includes comments related to data security and “Controversies regarding the use of GAI in work settings”. Relevant comments were discussing the need to exercise caution when using ChatGPT for tasks involving confidential information and the necessity for measures to prevent the leakage of sensitive information. Comments under Topic 10 “The impact of GenAI on the industrial market” shared public concerns about the disappearance of existing jobs and the emergence of new occupations.

All topics under the theme of “Ethics” (Topics 1, 5, 6) were placed in other themes, indicating that ethics are closely related to other domains that GenAI is used. In Topic 6, the viewer comments mainly focused on the reliability and accuracy of responses generated by GenAI. The relevant comments emphasized that humans should not rely solely on the information provided by ChatGPT and highlighted the need to exercise caution since ChatGPT often makes errors or provides false information.

# Discussion

# Implications of key findings

This study aimed to explore the educational implications arising from public perceptions expressed within YouTube news clip comments regarding GenAI in education. Our approach encompassed the collection of public comments extracted from 66 news clips sourced from the YouTube channels of three major broadcasting entities in South Korea. A total of 18,566 comments by Korean viewers were analysed through a combination of sentiment analysis and LDA-based topic modelling. In this section, we revisit the research questions and draw implications from the key findings.

Regarding the first research question, which revolves around public sentiments concerning the integration of GenAI in education, our results showed the dominance of neutral sentiments. While positive sentiments (e.g., good, outstanding, intelligent) slightly outweigh the negative ones (e.g., wrong, terrible, foolish), the majority of public comments conveyed a neutral disposition towards GenAI in education. This observation aligns with the findings by Leiter et al. (2023) and Tlili et al. (2023), which observed the prevalence of neutral or mixed sentiments amongst individuals in their perception of ChatGPT’s role in education.

Through the close analysis of these comments, we found that the neutral sentiments often signify a nuanced interplay between positive and negative viewpoints held by the public. Viewers tended to share experience-based or observation-based opinions over abstract ideas. In the past, the general public had limited opportunities to interact with GenAI in their daily lives. The advent of ChatGPT marked a pivotal moment as this online platform became easily accessible, as evidenced by the exponential surge in user registrations on the platform. We speculate that the increased ease of hands-on experiences with GenAI likely helped people better understand both its positive and negative aspects. That is, instead of having extreme views of either fully embracing or completely rejecting this emerging technology, individuals were able to see its complexities.

The second research question aimed to identify the main topics perceived by the public regarding the intersection of GenAI and education. Our analysis, based on LDA-based topic modelling, examined 18,566 comments from Korean viewers, unveiling 11 distinct topics. These topics were evenly distributed within the comments, signifying a lack of dominance by any single topic. This diversity in topics indicates the public’s engagement with a wide spectrum of GenAI-related educational issues on the YouTube platform.

Referring to Tables 1 and 2, which synthesize the key findings from relevant literature regarding GenAI’s role in education, we observed an overlap with several core issues and themes previously reported (e.g., Farrokhnia et al., 2023; Kasneci et al., 2023; Rawas, 2023). These recurring themes encompass concerns related to data privacy and security (Topic 1), concerns about declining cognitive skills (Topics 7 & 10), and academic integrity, including potential issues such as plagiarism and inaccuracies in GenAI-generated responses (Topics 6 & 9). Our findings also align with the work of Li et al. (2023), who identified themes like academic integrity, policy and societal concerns, and workforce challenges through the topic modelling of Twitter data. However, our study goes further by revealing a more diverse range of topics within public comments, such as international power relations (Topic 8) and the impact on the industrial job market (Topic 10). This broader spectrum of topics may be attributed to the nature of TV news clips, which aim to address significant societal issues and implications in their narratives.

Since these 11 topics covered diverse issues related to GenAI and education, we mapped them with five main themes found in the news clips: education, ethics, society, technology, and industry. Mapping topics and themes showed that people’s opinions about GenAI in education are complex – some topics fit into more than one theme. Out of the 11 topics identified, two topics were directly tied to educational implications: Topic 4 “Demands for changes in learning and assessment methods”, and Topic 9 “The use of GAI in higher education”.

Notably, GenAI emerged as a boundary object (Akkerman & Bakker, 2011; Star, 1989), serving as a bridge between public reflections regarding existing issues within the education system and their advocacy for fundamental changes in the ways students learn and are assessed in schools. Topic 4, in particular, expresses the boundaries of current education systems and ushering in potential changes for the future of education and society. Frequent comments on assessment issues were unsurprising, given South Korea’s heavily exam-oriented education. Public discourse revolved around the negative consequences of high-stakes exams like the K-CSAT (su-neung, university entrance exam) and the prevalence of teacher-centric pedagogies that lead to passive learning and rote memorization for exams. For the public, GenAI served as a timely catalyst for reflecting on the reality of South Korea’s education systems, providing an avenue to express opinions advocating fundamental shifts in the current educational paradigm.

Topic 9, exploring the utilization of GenAI in higher education, emerged as a distinct topic while there were no topics directly related to K-12 education. This observation could potentially suggest that, at this juncture, the public is more concerned about the utilization of GenAI, especially ChatGPT, in higher education contexts since news clips often featured issues that happened with university students such as essay writing and potential plagiarism. Similar issues about GenAI in higher education were reported in the studies by Tlili et al. (2023) and Li et al. (2023), where both studies suggested the need for students to ethically use GenAI in their assignments.

Interestingly, the topic that garnered the most comments revolved around the concern of personal data (Topic 1). The public seemed to possess a basic understanding of GenAI, such as ChatGPT, as a large data-based model. This understanding was often provided in the opening of the news clips, along with mentions of prominent IT companies like Google, Naver, and Kakao. Moreover, the public demonstrated awareness that the advent of GenAI could reshape power dynamics on the global stage (Topic 8). This awareness extended to the potential disparities between nations that possess GenAI technology and those that do not, as well as the consequential impacts of GenAI on international political dynamics.

Despite the news clips primarily focusing on the educational aspects of GenAI, the public comments ventured into broader issues where education intersects with larger implications. For instance, discussions extended beyond education to encompass topics like the potential displacement of human jobs (Topic 3), the potential decline in human creativity (Topic 7), and shifts in the structure of the job market (Topics 5 & 10). Since the main goal of education is to prepare students for future careers, these concerns about employment and creativity hold considerable relevance. Additionally, there was an underlying recognition that changes in the industrial landscape will invariably reverberate back to the education system. This prompts stakeholders to consider how best to educate and guide students in shaping their career trajectories.

In summary, this study highlights the coexistence of sentiments in public comments, with increased access to GenAI experiences leading to a more informed viewpoint. The identification of 11 distinct topics within the public comments on YouTube underscores the intricate and overlapping nature of people’s opinions regarding GenAI’s role in education, spanning across a range of themes.

# Limitations and areas for future research

This study has a few limitations that should be acknowledged. Firstly, the data utilized for this research were obtained from YouTube channels affiliated with major South Korean broadcasters, which means the analysis of news clips and comments was confined to the Korean language and context on YouTube. This choice was made due to YouTube’s extensive reach and popularity in South Korea. However, focusing solely on YouTube comments in this study means that the findings may not fully encompass the diverse and credible opinions of the Korean public. Future research should aim to broaden the scope by exploring public perceptions of GenAI and education through other social media platforms and survey methods. Secondly, the specificity of the findings to the South Korean education system restricts their generalizability to diverse cultural and educational contexts. To ascertain whether the public perceptions observed in this study are universal across various countries or are unique to particular settings, future research should encompass data collection from different countries.

Thirdly, this study lacks demographic insights into the commenters included in the analysis. It is plausible that the public perceptions captured in this study may not accurately represent the broader Korean population concerning gender and age, potentially skewed towards a younger, more socially active demographic commonly found on social media platforms. Fourthly, it is important to acknowledge the limitations inherent in both machine learning and manual labelling in semantic analysis and topic modelling. Due to constraints in data size and the intricacies of the Korean language, machine learning algorithms may miss certain latent topics and nuanced expressions in sentiments. Furthermore, manual topic labelling is subjective, suggesting the need for more objective topic labelling methods like automatic labelling based on text summaries (Wan & Wang, 2016). Future studies should employ advanced text mining techniques to delve deeper into the semantic content of comments.

# Conclusion

The emergence of GenAI tools represents a pivotal milestone, potentially reshaping the landscape of AI’s role in education. Nonetheless, the potential drawbacks associated with these tools have stirred concerns within educational institutions. This study was motivated by the current digital dissonance and disconnection, where both educators and students lack a comprehensive understanding of the potential impact of GenAI on teaching and learning. Through the analysis of crowdsourced data from YouTube, this research uncovers neutral public perceptions towards GenAI’s integration in education, encompassing both positive and negative outcomes. Education is a complex domain, intricately interwoven with cultural, economic, and technological dimensions. This complexity was mirrored in our findings, revealing the multifaceted nature of public perceptions surrounding GenAI in education. We hope that the insights drawn from this study will serve as a useful resource for researchers, educators, and policymakers. These insights shed light on the perceived opportunities and challenges, as well as the desired transformations envisioned by the public with the advent of GenAI in education.

# Disclosure statement

No potential conflict of interest was reported by the author(s).

# Notes on contributors

Hyo-Jeong So is a professor of Educational Technology at Ewha Womans University in Seoul, South Korea. Her main research interests include mobile learning, computer-supported collaborative learning (CSCL), and informal learning. She is particularly interested in examining how to integrate emerging technologies for teaching and learning from collaborative knowledge building perspectives.

Hyeji Jang is a graduate student in Educational Technology at Ewha Womans University in Seoul, South Korea. Her research interests include technology-enhanced learning design and teacher education. Recently, she has studied the design and evaluation of recommender systems for mobile language learning applications and research trends for the use of emerging technologies in education.

Minseon Kim is a graduate student in Educational Technology at Ewha Womans University in Seoul, South Korea. She holds a bachelor’s degree in English Education and has previously worked as an English teacher in a secondary school. She is interested in the application of AI in the context of English as a Foreign Language (EFL) education.

Jieun Choi is a graduate student at Ewha Womans University in Seoul, South Korea where she is pursuing her doctorate degree in Educational Technology. After obtaining a master’s degree in Educational Technology from the same university, she worked as an instructional designer at a university. She is interested in learning design through leveraging the affordances of AI technologies.

# ORCID

Hyo-Jeong So $\textcircled{1}$ http://orcid.org/0000-0002-1713-9653

# References

Akkerman, S.F., & Bakker, A. (2011). Boundary crossing and boundary objects. Review of Educational Research, 81(2), 132–169. https://doi.org/10.3102/0034654311404435   
Arun, R., Suresh, V., Veni Madhavan, C. E., Narasimha Murthy, M. N. (2010). On finding the natural number of topics with latent dirichllocation: Some observations. In M. J. Zaki, J. X. Yu, B. Ravindran & V. Pudi (Eds.), Advances in knowledge discovery and data mining (pp. 391–402). Springer.   
Cao, J., Xia, T., Li, J., Zhang, Y., & Tang, S. (2009). A density-based method for adaptive LDA model selection. Neurocomputing—16th European Symposium on Artificial Neural Networks, 1775–1781.   
Cho, A. (2022, December 21). KakaoTalk YouTube Naver. . . the most frequently used apps by Koreans this year. The Korea Economic Daily. https://www.hankyung.com/article/202212210552g

Clark, W., Logan, K., Luckin, R., Mee, A., & Oliver, M. (2008). Beyond web 2.0: Mapping the technology landscapes of young learners. Journal of Computer Assisted Learning, 25(1), 56–69. https://doi.org/10.1111/j.1365-2729.2008.00305.x

Das, D., Kumar, N., Longjam, L.A., Sinha, R., Roy, A.D., Mondal, H., & Gupta, P. (2023). Assessing the capability of ChatGPT in answering first-and second-order knowledge questions on microbiology as per competency-based medical education curriculum. Cureus, 15(3). e36034. https://doi.org/10.7759/cureus.36034   
Deveaud, R., SanJuan, E., & Bellot, P. (2014). Accurate and effective latent concept modeling for ad hoc information retrieval. Document Numérique, 17(1), 61–84. https://doi.org/10.3166/dn.17.1.61-84   
Dwivedi, Y.K., Kshetri, N., Hughes, L., Slade, E.L., Jeyaraj, A., Kar, A.K., Baabdullah, A.M., Koohang, A., Raghavan, V., Ahuja, M., Albanna, H., Albashrawi, M.A., Al-Busaidi, A.S., Balakrishnan, J., Barlette, Y., Basu, S., Bose, I., Brooks, L., Buhalis, D., Wirtz, J., & Wright, R. (2023). Opinion paper: “So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy. International Journal of Information Management, 71, 102642. https://doi.org/10.1016/j.ijinfomgt.2023.102642   
Eapen, T.T., Finkenstadt, D.J., Folk, J., & Venkataswamy, L. (2023). How generative AI can augment human creativity. Harvard Business Review, 101(4), 56–64.   
Ekin, C.C., Polat, E., & Hopcan, S. (2023). Drawing the big picture of games in education: A topic modeling-based review of past 55 years. Computers & Education, 194, 104700. https://doi.org/10.1016/j.compedu.2022.104700   
Farrokhnia, M., Banihashem, S.K., Noroozi, O., & Wals, A. (2023). A SWOT analysis of ChatGPT: Implications for educational practice and research. Innovations in Education and Teaching International, 1–15. https://doi.org/10.1080/14703297. 2023.2195846   
Gilson, A., Safranek, C.W., Huang, T., Socrates, V., Chi, L., Taylor, R.A., & Chartash, D. (2023). How does CHATGPT perform on the United States medical licensing examination? The implications of large language models for medical education and knowledge assessment. JMIR Medical Education, 9(1), e45312. https://doi.org/10.2196/45312   
GMI. (2023, October 26). YouTube users statistics 2023. https://www.globalmediainsight.com/blog/youtube-usersstatistics/   
Griffiths, T.L., & Steyvers, M. (2004). Finding scientific topics. Proceedings of the National Academy of Sciences, 101 (suppl.1), 5228–5235. https://doi.org/10.1073/pnas.0307752101   
Grün, B., & Hornik, K. (2011). Topicsmodels: An R package for fitting topic models. Journal of Statistical Software, 40(13), 1–30. https://doi.org/10.18637/jss.v040.i13   
Haensch, A.C., Ball, S., Herklotz, M., & Kreuter, F. (2023). Seeing ChatGPT through students’ eyes: An analysis of TikTok data. https://doi.org/10.48550/arXiv.2303.05349   
Kasneci, E. Seßler, K. Küchemann, S. Bannert, M. Dementieva, D. Fischer, F. Grasser, U. Groh, G. Günnemann, S. Hüllermeier, E. Krusche, S. Kutyniok, G. Michaeli, T. Nerdel, C. Pfeffer, J. Poquet, O. Sailer, M. Schmidt, A. . . . Kasneci, G.(2023). ChatGPT for good? On opportunities and challenges of large language models for education. Learning & Individual Differences, 103, 102274. https://doi.org/10.1016/j.lindif.2023.102274   
Kemp, S. (2023 , February 13). Digital 2023: South Korea. Datareportal. https://datareportal.com/reports/digital-2023- south-korea   
Kim, R. (2023). Effects of ChatGPT on the cognitive processing of K-CSAT English reading tasks by Korean high school learners: A preliminary study. Secondary English Education, 16(2), 179–205. https://doi.org/10.20487/kasee.16.2. 202305.179   
Kim, Y. (2021). Do it! R text mining. EasysPublishing.   
Kye, B.K., Park, T.J., & Cha, H.J. (2017). An exploratory study on the domestic educational utilization of ICT convergence emerging technologies and trends. Educational Information & Media Research, 23(4), 709–734. https://doi.org/10. 15833/KAFEIAM.23.4.709   
Leiter, C., Zhang, R., Chen, Y., Belouadi, J., Larionov, D., Fresen, V., & Eger, S. (2023). ChatGPT: A meta-analysis after 2.5 months. https://doi.org/10.48550/arXiv.2302.13795   
Lim, W.M., Gunasekara, A., Pallant, J.L., Pallant, J.I., & Pechenkina, E. (2023). Generative AI and the future of education: Ragnar ̈ok or reformation? A paradoxical perspective from management educators. The International Journal of Management Education, 21(2), 100790. https://doi.org/10.1016/j.ijme.2023.100790   
Liu, B. (2022). Sentiment analysis and opinion mining. Springer Nature.   
Maier, D., Waldherr, A., Miltner, P., Wiedemann, G., Niekler, A., Keinert, A., Pfetsch, B., Heyer, G., Reber, U., Häussler, T., Schmid-Petri, H., & Adam, S. (2018). Applying LDA topic modeling in communication research: Toward a valid and reliable methodology. Communication Methods and Measures, 12(2–3), 93–118. https://doi.org/10.1080/19312458. 2018.1430754   
McCombs, M.E., & Shaw, D.L. (1972). The agenda-setting function of mass media. Public Opinion Quarterly, 36(2), 176–187. https://doi.org/10.1086/267990   
Nam, S.H. (2023). Korea university issues guidelines on using ChatGPT. https://www.korea.ac.kr/user/boardList.do? boardId=366&siteId=en&page=1&id=en_060101000000&boardSeq=495142&command=albumView   
Nguyen, H., & Jenkins, J. (2020). In or out of sync: Federal funding and research in early childhood. AERA Open, 6(4), 2332858420979568. https://doi.org/10.1177/2332858420979568   
OpenAI. (n.d). Educator considerations for ChatGPT. https://platform.openai.com/docs/chatgpt-education   
Park, S.M., Na, C.W., Choi, M.S., Lee, D.H., & On, B.W. (2018). KNU Korean sentiment lexicon: Bi-LSTM-based method for building a Korean sentiment lexicon. Journal of Intelligence and Information Systems, 24(4), 219–240.   
Perloff, R.M. (2020). The dynamics of persuasion: Communication and attitudes in the twenty-first century. Routledge.   
Polit, D.F., & Beck, C.T. (2006). The content validity index: Are you sure you know what’s being reported? Critique and recommendations. Research in Nursing & Health, 29(5), 489–497. https://doi.org/10.1002/nur.20147   
Quinn, K.M., Monroe, B.L., Colaresi, M., Crespin, M.H., & Radev, D.R. (2010). How to analyze political attention with minimal assumptions and costs. American Journal of Political Science, 54(1), 209–228. https://doi.org/10.1111/j.1540- 5907.2009.00427.x   
Rahman, M.M., & Watanobe, Y. (2023). ChatGPT for education and research: Opportunities, threats, and strategies. Applied Sciences, 13(9), 5783. https://doi.org/10.3390/app13116716   
Rampersad, G., & Althiyabi, T. (2020). Fake news: Acceptance by demographics and culture on social media. Journal of Information Technology & Politics, 17(1), 1–11. https://doi.org/10.1080/19331681.2019.1686676   
Rawas, S. (2023). ChatGPT: Empowering lifelong learning in the digital age of higher education. Education and Information Technologies, 1–14. https://doi.org/10.1007/s10639-023-12114-8   
Rubio, D.M., Berg-Weger, M., Tebb, S., Lee, E.S., & Rauch, S. (2003). Objectifying content validity: Conducting a content validity study in social work research. Social Work Research, 27(2), 94–104. https://doi.org/10.1093/swr/27.2.94   
Selwyn, N. (2006). Exploring the ‘digital disconnect’ between net‐savvy students and their schools. Learning, Media and Technology, 31(1), 5–17. https://doi.org/10.1080/17439880500515416   
Selwyn, N. (2013). Distrusting educational technology: Critical questions for changing times. Routledge.   
Star, S.L. (1989). The structure of ill-structured solutions: Boundary objects and heterogeneous distributed problem solving. In L. Gasser & M. Huhns (Eds.), Distributed artificial intelligence (pp. 37–54). Morgan Kaufmann.   
Taecharungroj, V. (2023). “What can ChatGPT do?” Analyzing early reactions to the innovative AI chatbot on Twitter. Big Data and Cognitive Computing, 7(1), 35. https://doi.org/10.3390/bdcc7010035   
Tlili, A., Shehata, B., Adarkwah, M.A., Bozkurt, A., Hickey, D.T., Huang, R., & Agyemang, B. (2023). What if the devil is my guardian angel: ChatGPT as a case study of using chatbots in education. Smart Learning Environments, 10(1), 15. https://doi.org/10.1186/s40561-023-00237-x   
Uddin, S.J., Albert, A., Ovid, A., & Alsharef, A. (2023). Leveraging ChatGPT to aid construction hazard recognition and support safety education and training. Sustainability, 15(9), 7121. https://doi.org/10.3390/su15097121   
Wang, T., Lund, B.D., Marengo, A., Pagano, A., Mannuru, N.R., Teel, Z.A., & Pange, J. (2023). Exploring the potential impact of artificial intelligence (AI) on international students in higher education: Generative AI, chatbots, analytics, and international student success. Applied Sciences, 13, 6716. https://doi.org/10.3390/app13116716   
Wan, X., & Wang, T. (2016, August). Automatic labeling of topic models using text summaries. Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, Berlin, Germany (Vol. 1, pp. 2297–2305).   
Yan, D. (2023). Impact of ChatGPT on learners in a L2 writing practicum: An exploratory investigation. Education and Information Technologies, 28(11), 1–25. https://doi.org/10.1007/s10639-023-11742-4

Appendix A. Sample comments for topic labels   

<html><body><table><tr><td colspan="3"></td></tr><tr><td colspan="3"></td></tr><tr><td colspan="3">Topic label 1</td></tr><tr><td></td><td>The risk of personal data leakage</td><td>The moment you enter your personal information (such as name, social security number, address, and phone number) on your computer or cell phone!~ it is no longer personal information~ At the moment it changes to public information!~please keep this in mind. Wow, I feel like the day when Terminator becomes a reality is not far off. ... It</td></tr><tr><td>2</td><td>Realizing the envisioned future with GAI Replacing human jobs in the legal</td><td>seems that human arrogance is creating a new apex predator. ... I really think that one day, even if not exactly in the same context as The Matrix, machines will rule over humans...... I hope that Al judges and prosecutors will be introduced and applied to the</td></tr><tr><td>3</td><td>field</td><td>judiciary as soon as possible. Al judges and prosecutors who can judge themselves without any constraints by averaging the accumulated precedents and prosecutions by sentence weight can quickly resolve the accumulated court backlog and improve reliability.... Demands for changes in learning and To deal with the Al era, it is important to improve the education system and</td></tr><tr><td>4</td><td>assessment methods</td><td>provide education that allows students to participate and think creatively. Instead of the traditional rote learning method, we should actively introduce discussion, problem solving, and project-based learning so that students can express their thoughts, interact freely, and learn. ..., it is necessary to provide education that fosters human strengths such as problem-solving skills,</td></tr><tr><td>5</td><td>Controversies regarding the use of GAI in work settingse</td><td>creativity, collaboration skills, and self-directed learning skills. .. .. - I understand that profit-seeking companies or special facilities where security is important can restrict the use of new or current technologies because security is important .. - ChatGPT should be used carefully. Technology leakages are hundreds of</td></tr><tr><td>6</td><td>Reliability and accuracy of GAI responses</td><td>times more important than work efficiency. ChatGPT can sometimes copy and paste content from the Internet, which can lead to errors. ... It should never be trusted, and it should never be used. This is because you could end up believing distorted information ..</td></tr><tr><td>7</td><td>Generative Al with creative abilities</td><td>Humans do not have great creativity or imagination. They are just the results of applying the knowledge, experience, and values they have learned. The arts that were once thought to be impossible for Al to follow are already being composed and drawn by Al. Just because you use existing information does not mean you are not creative. In fact, small variations are the basis of</td></tr><tr><td>8</td><td>Restructuring international power relations in the era of GAI</td><td>creativity. -like the current Nuclear Non-Proliferation Treaty, NPT, some countries that have weaponized Al or have such technology may operate on the concept of kicking the ladder so that other countries cannot acquire the technology. ..., it is likely that the logic of power will be applied to limit countries that do not have it, just like nuclear weapons .. . -Regulating emerging technologies is an act of giving opportunities to other</td></tr><tr><td>9</td><td> The use of GAI in higher education</td><td>competitive countries and regressing oneself! I think it would be a good thing. Could Al be used to help students explore academic subjects quickly and deeply within the four-year college period? Honestly, I think it depends on the professors and college students. Rather than judging whether it is good or bad, we should focus on how to utilize the</td></tr><tr><td>10</td><td>The impact of GAI on the industrial market</td><td>newly emerging technology.. It is possible that human society may one day hand over all aspects of law, medicine, science, industry, trade, and legislation to Al. In fact, that might be better. Humans will only work in areas that require physical labour, such as agriculture, fishing, and healthcare (nursing or caring, not diagnosis). ... This</td></tr><tr><td>11</td><td>The coexistence of expectations and concerns regarding GAI</td><td>would be a huge threat to the professional workforce. The positive aspect is that the convenience and scope of individuals&#x27; use of knowledge can be greatly expanded, and the negative aspect is that there may be many cases where others&#x27; knowledge is presented as their own....</td></tr></table></body></html>