# A multi-faceted evaluation of the impact on students of an Australian university-wide academic language development program

Rosalie Goldsmith\*, Caroline Havery, Emily Edwards, Neil James, Aurora Murphy. Pamela Mort, Deborah Nixon, Gemma O'Donoghue, Jin Sug Yang, Joseph Yeo

University of Technology Sydney, Australia

# ABSTRACT

In espon tothe g o sur ll tnts a lg mt tht the uity st, he aci anguage and learning team at an Australian universty has established the Academic Language Development (ALD) program. This program screns all commencig students at the university and offers n innovative whole-fintitution approach to discipline-specific language development. The purpose fths paper is to rort on a l-cale, long-tem and muli-factd aluation of the AD progm considering the impact f aending compulsory language development uorials on 3922 students, the majority of whom were 2 users of English urveys have een carried out and daa olete on amic lanage eeloment, acic ume, stdet petions of their conidnce, and ther gans from aening the tutorials.  particular focus f this analsisis on the affctie apects of language delopment. In addition to developing academic anguage proficiency, the findingshow that students benefited in multipl ways from the ALD program. Key themes emerged from the data around con fide, y,  ction a  as a aiit toigarst laehis pa ofe ie apoch to the evalutinf langa rograms that wl be releant to toe chig and erhing isicll ir rts aros fatie in hiher education.

# 1. Introduction

# 1.1. Background

It has been increasingly acknowledged during the last two decades that higher education intitutions need to ensure allstudents have the linguisti reources to succed in their university studies eg, Murray, 2014 Lughlin & Arkoudis 009). In Australia, this concern was noted in The Good Practice Principles (DEEwR, 2009), a set of principles which can be used to audit a universty's performance in what the document refers to as English language'. The drivers for the development of the principles were the widening participation agenda, which opened universties up to students from non-traditional pathways, as well asthe increasing numbers of international students. These changes to student cohorts mean that, according to The Good Practce Principles, it can no longer be assumed that students enter ther universty study with the level f academic language proficiency required to participateffectively in their studies (DEwR 2009, p. 2). Notably, the document i not referring only to intenational students, but toall students who may need to develop their academic language throughout thir degree. Similar concerns have been noted in the UK; here though the reference is to intenational students only (Quality Assurance Agency, 2009). Our focus i this paper is to evaluate initiatives we have implemented to try and ensure thatall students who enter universty, regardles of their language background, do develop the academic language required to participate in their degrees.

In recognition of ther responsibility to develop students academic language, many universtie provide different lels of language support. These levels of support are categorised in the literature from adjunct to embedded, using the Jones, Bonnano and Scouller classfication (2001) (se e.g, Fenton-Smith & Humphreys, 2015, for a more detailed explanation); here we provide a brie overview. The first is the referral to student writing or learning centres where students can access a variety of generic academic language resources and services, for example, one-to-one consultations with a leaning adviser or peer learning adviser (e.g., Walkinshaw et al., 2015.) This aproach is ften refrred toas the olt-n aproch and i classfied asajunct (weak) it has bee criticised beauseit is not contextualised within the discourse of students specific disciplines and can be een as promoting adeficit model of teaching and learning" (Murray, 2016, p. 85). Fenton-Smith and Humphreys (2015, p. 42) point out that such measures have limite suces, as documented in the literature. The second type of support i rferred to as integrated approaches to developing language: those which are discipline- or subject-specific, but which are delivered by a language specialist rather than by the discipline specialist (Fenton-- Smith & Humphreys, 2015).

Thirdly is the embedding of academic language into degree programs so that all students learn how to communicate in their disciplines (e.g., Murray & Nallaya, 2016). There is extensive litrature which argues for the embedding of academic language as the most effective way to develop students' academic language. For example, Harper (2013) notes that contextualised language devel. opment within the discipline and embedded language development across the curriculum are likely to be the most effctive strategies. This discipline-specific approach ranges from discipline-specific language-focused adjunct tutorials and workshops for specific assesment tass and/or for students identified as needing additional support ., Fnto-mith & Humphreys, 2015) to faculty-based embedding of academic language (e.g., Briguglio & Watson, 2014; Maldoni & Lear, 2016; San Miguel et al., 2013; Wingate, 2015). Finally, there are ntiatives that focus on postenrolment language asessments (PELAs), which aim to identify students who most need academic language development. Some of these initiatives focus on all students but are faculty-specific (e.g., San Migel et a., 2013). Others are a whole-of-institution approach but only focus on international students (e.g., Fenton-Smith et al., 2017; Fenton-Smith et al., 2018). Follow-up academic language development for these students varies across intitutions and can be compulsory or voluntary, generic or iscipline-specific. For further discussion of these various types of programs, see Edwards et al. (2021).

However, there are few programs which have implemented a universty-wide approach to addressing academic language devel. opment either through embedding academic language and literacy for ll students, or by implementing a PELA followed by discipline. specific academic language development. In this paper, we report on the evaluation of an institution-wide program that screens students on entry for academic language and provides discipline-specific academic language development for students who are below a specified threshold on a PELA. Our program is unusual in that is institution-wide, screns all students regardless of language background, and provides discipline-specific academic language development to students particularly in thir frst year of study, but also throughout their degree.

The purpose of the current paper i twofold. The first goal is to present findings from our evaluation of the program to demonstrate the impact on students participating in compulsory language development tutorials in their first year of universty. Secondly, we outline an innovative approach for evaluating academic language program development that is large-scale, long-term, and multifaceted, and includes evaluation of the affctive aspects of academic language development. After a brief note on terminology, we provide an overview of the context of our institution-wide program. Following the section on context, we review the related literature.

# 1.2. A note on terminology

In this paper, we use the term academic language development, asi implies the specific context of the language development being undertaken.

# 2. Context: the ALD program

The institution-wide program that we have developed at our universit in Australiais referred to as the Academic Language Development (ALD) Program. We have described this program and how it operates in detail in Edwards et al. (2021) and in Goldsmith and Hunter (2021), so here we offr a brief summary of the program's four stages. Next, we focus in more depth on the features of the first-year language development tutorials that are evaluated in this paper, and on the first milestone task as a discipline-specific assessment of language.

# 2.1. The four stages of the ALD program

At the commencement of semester, all incoming students are screened for academic language using an online scrning task, or an alternative tas for studnts wit aessbility nes (see 2.2for further infomation about the cring task). The asks are embedded into core courses inall faculties. Students who receive a result that indicates a need for academic language development (Basic level) must attend compulsory academic language development tutorials (LDTs) that re aligned with one of their core disciplinary courses. At the end of semester, allstudents language is evaluated via an existig asessment task (known as a milestone task) in the same core disciplinary courses. Students achieving a level below the threshold set by the faculty must attend further language development classes. Further milestone asessments are aligned with graduate arbute and embedded into degree programs. Fig.1 illutrates the

four stages.

# 2.2. Language screening task

The language screning task is the Academic English Screening Task (AEST) developed by the Language Testing Research Centre at the University of Melbourne. The AEST is a valid and reliable sreening task (Elder & Knoch, 2009), and \*is based on the principle of universal testing, to allow for allstudents at risk to be identified" (University of Melbourne LTRC, 2022). Students at rsk are those "who are likely to experience dfficultie in coping with the nglish language demands oftheir academic study (lder & Knoch, 2009. The AEST comprises two sub-tasks: a clozeelide task and a speed-reading task, which are completed online within a 40-min timeframe (see Elder and Knoch, 2009, for a more detailed description and validation) and is referred to at University X as the online post-enrolment language asessment (OPELA). The task is completed by all commencing students in orientation week or week 1 of semester in core commencing courses, and results are available immediately. There are three possible results: Basic; Intermediate; Good. See Edwards and colleagues (2021) for more details about how OPELA is used toscreen and allocate students in need of language support.

# 2.3. Features of the language development tutorials (LDTs)

The design of the LDTs is based on four research-based principles (see, 2021a). Firstly, the LDTs help students develop discipline. specific academic language, focusing on the asessment tasks in their core courses (e.g., Arkoudis & Kelly, 2016); secondly, the LDTs help students to build language confidence, academic identities and a sense of community, which help them develop thir academic language (Bond, 2019; Cho0i, 2021; Edwards & Roger, 2015) hirdly, the LDTs help students become independent language learners by developing goal-seting activities and gaining the confidence to aces institutional support services (Rochecouste & Oliver, 2014); finally, the LDTs help students to sustain their motivation for academic language development (Dooey et al., 2012.

While the ALD program mostly has an impact on students with English as an additional language, both international and domestic, adistinctive featre of the ALD program is that ll commencing students are included. This feature is unusual as other programs may e directed at only international students, or those students who require an external English language proficiency test for admissin (e., Fenton-Smith, 2017). The ALD program recognises that some domestic students may also need additional language support to enable them to participate in their university education more full. In contrast to the general language development programs provided by most other Australian universities, the LDTs help students understand course content by focusing on discipline-specific academic language development. The Academic Language and Learning (ALL) team members have developed expertise in the disciplinary discourse facultie, as well as being familiar with the content f the core courses in which the DTs are mbedded. This expertise has enabled the ALL team to design LDT materials that are highly relevant to students' needs, and that motivate students to improve their academic language. The teaching activities are derived from discipline areas and students learn effective communication strategies Which relate to the specifi requirements of their dee programs ., a written rport in ursing course is diffrent from  written report in a business courses). Tutorials run for $^ { 1 . 5 \mathrm { h } }$ per week for nine or ten weeks, and are taught by tutors who have an English Language Teaching background, under the guidance of the ALL team.

Another feature of the tutorials is the mandatory attendance requirement. Students are required to have $8 0 \%$ participation in the LDTs. If students do not fulfil this requirement, their course grade is withheld until they complete additional academic language development activities. In their frst LDT, students complete a writing task to further screen out those who do not need academic language development It is also a diagnostic task to provide early feedback on students' writing to help them set language learning goals.

![](img/e46e51ec49f0a5a8731f196a6c64b8a1ce1c1d61688929edc98bb09fec262005.jpg)  
Fig. 1. Stages of the ALD program.

# 2.4. Milestone assessment tasks

In each core disciplinary course, after completing OPELA at the start of semester,all students are assessed for academic language development towards the end of semester via language levels aplied to an existing asessment task in that course. This is known as the first milestone task The asesment task nds to have a writte r poken component and tobe submitted ear the end f semester, if necessary, the LL team member works with the course coordinator to ensure the task is easily assesable for language. The milestone task is evaluated using athree-level language framework developed by the AL team, in ddition to the course asessment criteria, with the language levels being 1: Unsatisfactory, 2: Needs developing, and 3: Satisfactory see Edwards et al., 2021 for more details on this framework).

The course coordinator and course tutors assign these language levels to the milestone task while asigning grades for the existing assessment criteria. The ALL team member offers paid training and marking moderation meetings each semester for each course involved in the ALD program. This process not only allows for a degree f standardisation, but also for course academics to negotiate What the different levels of language (1, 2 and 3) mean as applied to their specific course. Further milestone tasks are similarly embedded into courses at later stages in the degre, allowing students to track their language development throughout thir degree programs. Students who do not meet the language thresholds set by the faculty at any of the milestone points are referred to further academic language development activities.

# 3. Literature review

Although there is a wide range of academic language development activities to support student learning in higher education, the evaluation of such activitie i often piecemeal, ad hoc, or even non-existent. In particular, there is a paucity of evaluative studies related to whole-of-institution approaches that implement an academic language screening task for all students with compulsory academic language development for students who achieve below a specified threshold. Fenton-Smith et al. (2018) is one of the very few institution-wide studies to date of which the authors are aware.

Other evaluations of academic language programs fer insights into methods of evaluation. These programs range from those that are embedded into some discipline areas but not all(e.g., Maldoni & Lear, 2016), to programs that are only embedded into specific fatierrMlr, 2019 or ifi r eilet a., 02M of t rs ffeoll sunts regardless of language background, but atedance is on a voluntary basis (e.g., Maldoni & Lear, 2016; Murray & Mullr, 2019). The lack of institution-wide evaluatio studies of PELAs and the impact f fllow-up academic language development may reflect the fact that few institutions have the structures in place to deliver such programs. Fenton-Smith e l. 2018) provide an extensive evaluation of their institution-wide academic language program offered to international students. They measured a range of outcomes including English language proficiency, which was assessed by IELTS scores prior to and post the academic language program, as well s focus groups to gather student perceptions of language improvements. Academic outcomes were measured by comparing the GPA scores of students who had participated in the program with those who had not. They also considered academic integrity, retention, and learner autonomy beyond the classroom. Students who participated in the evaluation showed small but significant gains in spoken English language according to IELTS scores. Only students with the lowest pre-test scores on the IELTS showed significant gains in reading, writing, and listening. Fenton-Smith et a. (2018) point out that this i to be expected, as the program was only one semester long. They also note the limitations of using an S test as a measure of improvement, as the test i not deigned to demonstrate hort-term gains (Green, 2005, as cited in Fenton-Smith et al., 2018), and it willikely not show any potential improvements in discipline-specific academic language since it focuses on general academic proficiency. Further positive outcomes of ths academic language program were reductions in breaches of academic integrity amongst international students and an improvement in retention data. The eval. uation also drew on student feedback using student feedback surveys, focusing on overal improvement in satisfaction scores. Unlike many evaluation studies of academic language programs that focus on academic outcomes only (Hamilton et al., 2019), Fenton-Smith et al. (2018) evaluated the development of learner autonomy, which was explicitly included in their program. Many students $( 6 3 \% )$ found valuable extra-curricular services for the first time, as a result of participating in the language program.

Maldoni and Lear's (2016) evaluation, while not across a whole institution, is significant as it covered nine courses across four discipline areas over a ten-year period. Drawing on academic outcomes for the courses in which the academic language programs were embedded, they found that students who attended the program had higher pass rates than students who did not attend. They also found that those students who attended regularly (more than thre sessions) performed beter in their academic cours than those students Who attended irregularl. Responses in student surveys indicated that students believed the program helped them beter understand course content and asessment tasks, and participate more confidently in tutorial. However, although this program was large and longstanding, it was not compulsory for students to attend. Maldoni and Lear (2016) state that although students who were deemed to be at risk' due to their language level were referred to the program, the majority of these students did not attend. Furthermore, the program was not embedded systematically into universt structures. Itrelied insted on ad hoc funding and the willingnes of faculty academics, which in the long term remains an unsustainable approach, as noted by the authors themselves.

The majorit of evaluations of language programs refer to programs on a smaller scale that embed academic language development within specific faculties. These programs include those that are fully integrated into the teaching of discipline subjects and are completed by all students (e.g., Calvo et al., 2020) and academic language programs that are offered as adjunct to students disciplinary courses and are voluntary (Murra & Muller, 2019, to credit-bearing courses for all students. Several of the programs incorporated PELAs (Dooey & Greller, 2020; San Miguel etal., 2013) but they are limited in that they were only implemented in one faculty. While Dooey and Grelliers study did include compulsory language development for students who achieved below a specified threshold in the PELA, the number of participants was small $( n = 4 0 )$

The above evaluations use a range of mechanisms and focus mainly on measuring attendance, and the efect of participation on academic outcomes. Several studes use participation rates for an in-discipline or course-specific intervention to compare how students perform in their asssments within the discipline. A consistent finding amongst these studies is that regular attendance by students results in highr course grades than students who did not participate, or who had ow attendance (Calvo et al, 2020; Dooe & Grellier, 2020; Murray & Muller, 2019). These studies indicate that academic language programs can have a positive impact on academic Ssuccess.

Most evaluations of academic language programs, whether for allstudents or for a specific cohort with low levels of academic language have focused on the cognitive aspects of language learning, measured via language tests and academic grades, rather than other dimensions of learning, such as social connections, confidence and personal well-being. Several evaluations have reported on gains in confidence with academic language that students achieved as a result of attending programs (Calvo et al., 2020; Dooey & Grellier, 2020). One small study reported on students improved sense of well-being feeling more comfortable), which was related to being with students who had a similar language level, to the attitude of the teacher, to better understanding course content, and to making friends in class (San Miguel et al., 2013). As noted above, Fenton-Smith et al. (2018) also considered the development of learner autonomy in their institution-wide evaluation. The learner autonomy aspect of their program had been evaluated earlier (Fenton-Smith & Michael, 2013), where the authors found that building in an activity that encouraged students to aces university services resulted in students feling more confident. ome students also reported on the social benefit they gained during the program through developing friendships and feeling more comfortable in a new culture. These studies indicate that language programs go beyond academic outcomes.

As noted by Hamilton e al. (2019), there is no systematic way of evaluating programs acrossthe academic language development field. They found that many evaluations demonstrate impact by measuring attendance at programs and performance in academic courses, which is understandable given the focus of universties on quantifiable outcomes. They argue for a standardised model for evaluating language programs and propose a useful evaluation framework (the ICALLD evaluation model), much of which aligns to the approach we have taken to evaluating their institution-wide strategy. However, the ICALLD model focuses on how to evaluate rather than what to evaluate. We argue that there is a need to explicitly consider not only the cognitive aspects of language learning but also the affective aspects, which necessitates a strong emphasis on student voices through surveys and focus groups. Our argument for including the affctive apects of language larning in evaluations is based onthe theoretical underpinning of th ALD program, that is, a sociocultural perspective on language learning.

# 4. A sociocultural perspective on academic language development

The current study is informed by a sociocultural perspective which views academic language development as a process of socialisation into academic discourse communities (Duff, 2010) and which acords equal importance to both cognition and emotion (Lantolf, 200; Lantolf & Swain, 2019). Academic discourse socialisation is a dynamic process that is socially, culturally and historically situated and, through interactions with peers and more established members of academic discourse communities, involves newcomers lerning to participate successully in those communities (uff, 2010). Within the feld of applied linguistics, there has been a recent affective turn' preceded by a 'social turn', with many researchers now focused on considering the role of emotion in language teaching and learning, as embedded in and mediated by the sociocultural contexts of language use (Bigelow, 2019; Douglas Fir Group, 2016; Gkonou et al., 2020). The Douglas ir Group (2016) propose that \*language competencies are complex, dynamic and holistic' (p. 26), and Lantolf and Swain (2019) argue that "emotions are integral to thinking" (p. 529), with affect and cognition considered inseparable aspects of the learning process.

From this sociocultural perspective, when evaluating students' academic language development, it is important to consider not only the cognitive development of their anguage knowledge and skill as demonstrated by aessment task performance, but as their feelings and perceptions of the learning experience, and developments in their self-confidence, self-fficacy, and agency. Academic language development is also about making connections, building relationships, engaging with others, and becoming members of discipline and professional communities (Douglas Fir Group et al., 2016; Duff, 2010).

Some recent studies within higher education have emphasised how the initia tages of transitioning to university involve an array of emotional experiences. For instance, Gravett and Kinchin (2020) acknowledge that students transition into academic culture is necessarily emotional but argue that it i especially challenging for intenational students. These students may perceive themselves to already be at a disadvantage due to language, cultural and social barrer, and without apropriat support may be negatively impacted i terms of their student agency and confidence. Indeed, Gravet and Kinchin (2020) ague that failure by universities to scaffold and welcome' students into academic culture has a negative impact on student agency and confidence, and that this is particularly acute for inteational students. It i usful to establish at this point what we understand student agency to comprise, as it is a widely used term which has many interpretations. This paper uses the term student agency' as it is defined by the OECD: Student agency is  deind as the capacit to st a goal, rflect and act reonsbly to ffect change  is about acting rather than being acted upon; shaping rather than being shaped; and making responsible decisions and choices rather than acepting those determined by others" (OECD, 2019, p. 1). Student agency is supported through the ALD program by structuring individual language goal-setting into classes and emphasising the importance of taking responsibility to develop one's own academic language capabilities. Subject-specific

LDTs emphasise individual academic goal-setting.

# 5. Research approach and strategies

In this paper, we adopt the terminology approach' and strategies to describe our research proces (see Kamberelis & Dimitriadis 2005). Strategies refer to \*the specific practices and procedures researchers deploy to collect and analyse data and to report thir findings" (Kamberelis & Dimitriadis 2005,p. 18). Our approach to data analysis was informed by pragmatism as a research paradigm which supports the use of a mix of modes of analysis also known as mixed methods, and a continuous cycle of abductive reasoning (McKinley, 2020), whil being guided primarily by the researchers' desire to produce socially useful knowledge (Feilzer, 2010). We used mixed methods, collcting quantitatie data to measure students' language levels, attendance and achievement, and qualitative data to evaluate students' perceptions and experiences. We used abductive reasoning to move between deductive thinking for analysing the quantitative data and inductive thinking to analyse the qualitative data. This provided a nuanced understanding and exploration of th reearch question: \*hat are the measurable benefit for students atending the Language Development torials (LDTs) s part of the ALD program?"

# 5.1. Participants

The participants in this study were 3922 students who were identified through a language screening task as needing academic language development and who then atended the compulsory LDTs for one semester between Semester 1 2019 and Semester 1 2021 inclusive (five semesters).They were either undergraduate or postgraduate (coursework) commencing students who were enrolle in one of the core disciplinary courses selected to be part of the ALD program, and the majority of these students were 2 users of English Students from all faculties acros the university were included in this study. Participants were determined by cllcting the students academic language screning results using the OPELA task (as described in 2.2). Students who received a Basic language proficiency were directed to join an LDT. Intitutional ethical approval was granted for the study, and l participants provided informed consent for their participation. It was made clear that participants could withdraw at any time, and it was fully explained that data would be treated confidentiall. Participants were de-identified at the point of data collection and are referred to only by the name of the faculty in which they are enrolled.

# 5.2. Data collection and analysis strategies

The data collction and analysis strategies are summarised in Table 1. We collected both quantitative and qualitative data to measure the following: academic language levels, academic outcomes, student satisfaction, perceptions of academic language proficiency, language confidence, perceived gains from LDTs (including course content and assessment understanding, self-directed learning), and perceptions of the LDT experience.

# 5.2.1. Attendance and achievement data

We tracked large amounts of data over the course of each participant's first semester of involvement in the ALD program. As shown in Table 1, we collcted milestone language levels, course grades (of the core disciplinary courses in which ALD was embedded) and LDT attendance data to determine whether attendance at LDTs resulted in better outcomes in the academic language students used in the milestone tasks and beter outcomes in terms of their overall course grades. Focusing on these course grades rather than GPA was deemed as more informative since the language assessment and suport had been tailored to the courses. It was not possibleto collect all the participants' milestone levels (only 2415 rather than the full sample size of 3922) as some students did not have their task assessed or recorded.

# 5.2.2. Student surveys and focus groups

Using student entry and exit surveys and focus groups allowed us to measure and explore the affective aspects of language development, and we also wanted to highlight student voice in evaluating academic language courses, in line with Gaffas (2019) argument about students being \*important insiders" (p. 2). In order to measure students' perceptions of their LDT experience, they were invited to complete surveys at the beginning and end of the teaching semester in which they had participated in LDTs (see Appendix A for sample survey questions). The surveys were conducted online and consted of five (enry survey) to seven (exit survey) main questions, as well as questions collcting biographic data. Some questions were replicated in both entry and exit surveys in order to compare results. Surveys were anonymous, but student IDs were collected in order to match entry and exit survey data, then the data was de-identified. The survey sample size was 1697 when unmatched, and 829 when matched (see data analysis srategies below).

Table 1 Summary of data collection and analysis strategies.   

<html><body><table><tr><td colspan="3">Data collection strategies</td><td>Data analysis strategies</td></tr><tr><td>Category of data</td><td>Method of collecting data</td><td>Student sample size</td><td></td></tr><tr><td rowspan="3">(1) Attendance and achievement data</td><td>Milestone language levels</td><td>2415</td><td>STATA analysis</td></tr><tr><td>Subject grades</td><td>3922</td><td> STATA analysis</td></tr><tr><td>LDT attendance data</td><td>3922</td><td>STATA analysis</td></tr><tr><td rowspan="4">(2) Student satisfaction, perceptions, and experiences</td><td> Student surveys x 2 (LDT</td><td>1697 (unmatched) 829</td><td> Matching and comparison of quantitative data Inductive</td></tr><tr><td>entry, LDT exit)</td><td>(matched)</td><td>thematic analysis of qualitative data</td></tr><tr><td>Student focus groups (end of</td><td>28 groups x 2-3 students</td><td>Inductive thematic analysis of qualitative data</td></tr><tr><td>semester)</td><td>in each</td><td></td></tr></table></body></html>

In both surveys, students were asked to rate their lel of Englis language skill or ucesful study at this university, on a5-point Likert cale from 'very low' to very good' They were also asked to rate their confidence levels (using 5-point Likert scale) in areas such as reading academic texts; speaking in academic contexs; using grammar corrctly and other macroskils germane to participation in tutorials and seminars, and completing assessment tasks. The final questions in the entry survey related to how students felt about attending the LDTs and what they hoped to gain from the experience. The exit survey differed in that th final questions revolved around measuring overal satsfaction with LDTs: what students flt they had gained in terms of self-eficacy, slf-directed learning, and suggestions for improving the LDTs. Most of the questions were closed-ended, but we also included open-ended questions such as 'Do you have any suggestions for improvements in the LDTs?'.

Focus groups were used to explore some of the themes from the surveys in more depth and were conducted at the end of each semester in 2019 and 2020. The questions for the focus groups were designed to stimulate a discssion that ranged acrossal faculties and considered students' reflections and affctive experiences (levels of comfort and confidence) of the LDTs. All students who participated in the LDTs were invited to attend. Informed consent was collcted from students before taking part in the focus groups. The firs four questions encouraged afocus on the experience of the LDTs: what was larnt; oerall experience and the eficacy of the learning cycle. The remaining four questions asked students to think about the future, their comfort with language and communication skill, confidence levels, and suggestions for improvement (see Appendix B for the focus group questions). We conducted 28 focus groups with students across all faculties, with two to three students in each focus group.

# 5.3. Data analysis strategies

# 5.3.1. STATA analysis

To analyse the tracking data (student' milestone language levels, course grades and LDT attendance data), we used STATA, a statistical analysis application that enables the analysis of large data sets.

We conducted univariate and multivariate analysis to examine whether students meting LDT attendance requirements receive higher language levels and course marks than students not meeting LDT attendance requirements. Two dependent variable are used to measure language levels and course marks of students: Milestone language level is measured as an indicator variable given 1 if a student has received unsatisfactory milestone language level, zero otherwise; course marks is astudent's course mark ranging between 0 and 100. The key independent variable is Met attendance requirment, adummy variable capturing whether a student has met LDT attendance requirement. Furthermore, in the multivariate regresion analyis, several variables are included in the regresion model to control for student characteristics (English as a first language, international, undergraduate and pathway students), the time variant for semesters and years (Spring and Autumn semesters from 2019 to 2021), and faculties. The definitions of the variables are shown in Appendix C.

# 5.3.2. Matching and comparison of quantitative survey data

At the end of each semester, we used unique student IDs to match the entry and exit survey data, and this resulted in a sample sizeof 829 matched surveys. The students confidence and readiness were then summarised to determine the cohort's overall result. We also analysed the exit surveys alone, which resulted in a sample size of 1697 exit surveys. Quantitative survey data was then collated in tables and presented in bar charts.

# 5.3.3. Inductive thematic analysis of qualitative data

We conducted an inductive thematic analysis of the qualitative data derived from the open-ended survey questions and tran. scriptions of the focus groups to identify key terms, key themes, and dominant practices (Braun & Clarke, 2006). This involved two researchers reading through all the transcripts of focus group interviews to identify key terms. From this analysis emergent themes began to appear. These terms were used to create categories, which were then grouped into sub-themes (Creswel, 2014). Two other researchers then read through the transcripts and noted emergent themes which were added to the list of potential themes identified by the first three researchers. The four researchers critially compared and discused the themes, combining some and removing others that were deemed not to be significant, until agrment on the themes was reached. The final list of themes was compiled, with their associated participant quotes from the transcripts.

The focus group transcriptions from each semester were analysed separately, and then the analyses were combined. We found recurring themes each semester, but also new themes emerged. At the end of this process, we held a goup analysis meeting to review the sets of categories and sub-themes and to combine them.

Our inductive approach to the analysis of student data led us to examine what emerged from the thematic analysis, rather than specific themes we were expecting to find (Braun & Clarke, 2006). Notwithstanding an inductive approach, the themes were pre-figured to a substantial extent by the survey and interview questions that were asked of the students.

# 5.3.4. Combining analysis across all data sets

The final part of our data analysis process was to combine the analyses from the different strategies to look for common studen!

outcomes across the data sets.

# 6. Findings

The analyses of quantitative and qualitative data show that there were five main outcomes for students from the LDTs: improved academic language skills abetter overallresult for the discipline course where the ALD program was embedded; improved language confidence; a more developed sense of agency; and greater social connections. We present the findings below aording to these five main outcomes. Where student comments are included, we use the following laeling format: [Focus group/survey, year fculty]. The acronym FEIT stands for the Faculty of Engineering, and DAB stands for the Faculty of Architecture.

# 6.1. Improvements in academic language skills

One of the key outcomes of the LDTs was an improvement in academic language kills as indicated by students performance in the milestone task on completion of LDTs and as reported by student surveys and focus groups.

Table 2 shows the result of the efect of LDT attendance requirement on milestone language level. The finding shows that the coefficient on Met attendance requirement $( - 0 . 3 8 3 ^ { * * } )$ is significant and negative at the $5 \%$ level, indicating that those students who met attendance requirement of the LDTs are les likely to receive an unsatisfactory language outcome for their milestone task one.

Improvements in academic language skills were also evident in students' perceptions of the benefits of the LDTs. Survey results showed that by the end of the LDTs students flt more prepared for study in terms of their academic language level. As shown in Fig. 2, in the start-of-semester surveys, $2 8 \%$ of students felt that they had a low or very low level of language for academic study, with only $2 0 \%$ believing they had a good or very good level. In the end-of-semester surveys, $3 9 \%$ of students reported that they had a good or very good level of language for academic study, showing an improvement $( + 1 9 \% )$ in this cohort's perceptions of their academic language level for university study. Equally, there was a drop $( - 1 8 \% )$ in the number of students who felt that they only had a low or very low level of language for academic study.

End of semester survey results $( n = 1 6 9 7 )$ from 2019 to 2021 also showed that students thought the LDTs had helped them to improve their language skills. The vast majority $( 8 5 \% )$ of students agreed or strongly agreed that attending LDTs helped them build strategies to develop their anguage skill and gave them a greater understanding of disciplinary course content t sems that improved language skills may have helped students better understand the content of their courses.

Thematic analys of focus groups also showed that students felt they had improved their academic language skill, in assessment writing, speaking, vocabulary and reading. In terms of assessment writig, students perceived they had improved in using evidence and paraphrasing; using appropriate academic language; and preparing and structuring assignment i a way that met the expectations of their discipline areas, which some students noted were different from assignments they had previously written at schoo. omments from FEIT and DAB students illustrated these themes in terms of the levels of comfort they felt when speaking in tutorials:

Table 2 The effect of attending an LDT on milestone task one.   

<html><body><table><tr><td>VARIABLE</td><td>Milestone language level - Unsatisfactory</td></tr><tr><td>Met attendance requirement</td><td>0.383**</td></tr><tr><td>Constant</td><td>(-1.993) 0.013 (0.019)</td></tr><tr><td>Observations</td><td>2415</td></tr><tr><td>Controls</td><td>Yes</td></tr><tr><td>R2</td><td>0.0845</td></tr><tr><td> p-value</td><td>0</td></tr><tr><td>Chi2</td><td>138.3</td></tr><tr><td>Log_likelihood</td><td>1172</td></tr></table></body></html>

Note: The table presents the results of estimating a logistic regression examining the effect of Met attendance requirements on Milestone language level - Unsatisfactory. The table shows the coefficients of variables with t-stat in parentheses and \*\*\* \*\*, \* indicate the significance at the 1, 5 and 10 percent levels, respectively. The dependent variable is Milestone language level - Unsatisfactory, an indicator variable given 1 if a student received an unsatisfactory result, 0 otherwise. The key independent variable is Met attendance requirement measured as an indicator variable given 1 if a student has met attendance requirement, 0 otherwise. Control variables for Student characteristics, the time variant, and enrolled faculty are included in the regression model but not shown. Control variables for Student characteristics are English ${ \bf \dot { 1 } } =$ Students first language is English, $0 =$ English as second language), International ( ${ \mathrm { . } } 1 = { \mathrm { I n } } $ ternational student, $0 =$ Domestic student), Undergrad ${ \boldsymbol { \mathrm { 1 } } } =$ student enrolled in undergraduate course, $0 =$ student enrolled in postgraduate course), and College X pathway ( ${ \mathrm { ~  ~ \cdot ~ } } { \mathrm { ~  ~ \cdot ~ } } { \mathrm { ~  ~ \cdot ~ } }$ Admitted from College X pathway, $0 =$ admitted from other pathways). Control variables for the time variant are indicator variables for years over three years for both Autumn and Spring semesters. Control variables for enrolled faculties are indicator variables for eight faculties.

![](img/b20ad8d1e1ee8a07e9a779f32f04053f4bd6f97ee44d5802e02a6cecb1a2c689.jpg)  
Fig. 2. Students' perceptions of their language level for academic study at University X, 2019-2021 $( n = 8 2 9 )$ Note: Percentages rounded to the nearest whole number.

"As an international, I don't know . how to writeassignments, especially via online studies .. because in my country I never did these kind ofassignments . I learn how to reference ... and how to reearch an assignment. o ...that is very useful in my research." [Focus group, 2020, Health]

In terms of speaking skill, students commented that they had made improvements in giving presentations, participating in class and speaking with other students. Students also felt they had increased their vocabulary and reading skills.

# 6.2. Better results in discipline course

The result of univariate analysis (t-test) of attendance at LDTs and the marks students reeived for the discipline course to which the LDT was aligned showed that students who rceived a Basic level on the language screening task and then attended the LDTs achieved higher course marks on average compared to students who received Basic' but did not attend the required number of LDTs. Table 3 shows that students who attended more than $8 0 \%$ of the LDTs achieved higher average course marks (65.92) than those who did not attend (49.62) more than $8 0 \%$ of their scheduled LDTs, and the mean of the course marks of these two groups are statistically different from each other. This result represents a difference betwee faiing the course (marks under 50) and receiving a Credit or higher (marks above 65), and suggests that the LDTs are helping students to understand their discipline course content and complete course assessment tasks effectively.

Table 4 shows the result of the effect of LDT attendance requirement on course marks. The finding shows that the cofficient on Met attendance requirement $( 1 6 . 1 1 3 ^ { * * * } )$ is significant and positive at the $1 \%$ level, suggesting that those students who met attendance requirement of the LDTs receive higher course marks that those students who did not meet the attendance requirement.

# 6.3. Increased language confidence

Survey data also showed that students who attended LDTs increased their academic language confidence. As can be seen in Fig. 3, student survey results $\left( n = 8 2 9 \right.$ ) indicate that only $2 8 . 5 \%$ of students felt somewhat or very confident about their academic language at the start of semester, compared to $4 8 \%$ of students by the end of semester. To evaluate this growth in confidence, we examined the mean score of the reported academic language confidence between the start-of-semester LDT survey, and the end-of-semester LDT survey. Table 5 shows the results of the comparison between the two mean scores. The results show that there was a significant difference between student responses at the start-of-semester LDT survey $( \mathbf { M } = 3 . 0 7 )$ ) and student responses at the end-of-semester LDT survey $\mathbf { \boldsymbol { M } } = 3 . 4 9 \_$ . These results indicate that attending LDTs improved the academic language confidence of students.

A perceived growth in confidence was also evident from analysis of student focus group data. Students who attended LDTs perceived that they had increased in language confidence, which is essential in learning an additional language (Edwards & Roger,

Table 3 Univariate test of Subject marks by LDT attendance, all faculties 2019-2021 $( \mathtt { n } = 3 9 2 2 )$   

<html><body><table><tr><td colspan="2">Students who met LDT attendance requirements</td><td colspan="3">Students who did not meet attendance requirements</td></tr><tr><td>Obs.</td><td>Subject mark (mean)</td><td>Obs.</td><td>Subject mark (mean)</td><td>Subject mark difference</td></tr><tr><td>3546</td><td>65.92</td><td>376</td><td>49.62</td><td>16.30***</td></tr></table></body></html>

Note: \*\*\* significance at the 1 percent level.

Table 4 The effect of attending an LDT on course marks.   

<html><body><table><tr><td>VARIABLE</td><td>Subject marks</td></tr><tr><td>Met attendance requirement</td><td>16.113***</td></tr><tr><td>Constant</td><td>(12.176) 54.507*** (14.116)</td></tr><tr><td>Observations</td><td>3922</td></tr><tr><td>Controls</td><td>Yes</td></tr><tr><td>R2</td><td>0.180</td></tr><tr><td> p-value</td><td>0.000</td></tr></table></body></html>

Note: The table presents the results of estimating a OLS regression examining the effect of Met attendance requirements on Subject marks. The table shows the coefficients of variables with t-stat in parentheses and $^ { * * * } , ^ { * * } , ^ { * }$ indicate the significance at the 1, 5 and 10 percent levels, respectively. The dependent variable is course marks ranging between O and 100. The key independent variable is Met attendance requirement measured as an indicator variable given 1 if a student has met attendance requirement, O otherwise. Control variables for Student characteristics, the time variant, and enrolled faculty are included in the regression model but not shown. Control variables for Student characteristics are English $\mathbf { 1 \lambda = }$ Students first language is English, $0 =$ English as second language), International ( ${ \bf \nabla } \cdot { \bf 1 } =$ International student, $0 =$ Domestic student), Undergrad ( ${ \bf \nabla } ^ { 1 } =$ student enrolled in undergraduate course, $0 \ =$ student enrolled in postgraduate course), and College X pathway ${ } ^ { 1 = }$ Admitted from College X pathway, $0 =$ admitted from other pathways). Control variables for the time variant are indicator variables for years over three years for both Autumn and Spring semesters. Control variables for enrolled faculties are indicator variables for 8 faculties: Business, DAB, FASS, FEIT, Health, Law, and Science.

![](img/76e54519fe7bffec145152a79014341a8d82041c947ea3b86c0aad50a6db8346.jpg)  
Fig. 3. Figure showing changes in students' overall academic language confidence between start- and end-of-semester LDT surveys $( n = 8 2 9 )$

2015). In focus groups,students referred to the confidence they had gained in speaking with other students and in making pre sentations. They alo referred to the confidence they had gained i ening ademic skill. Students referred to this i terms of how they were able to practise their language skill and more full participate in tutorial even if they made mistakes Focus group, 2020, Law].

TaDie 5 Two sample t-est showing stdents overal academic languag confidence comparing stat ad end-f-semester L surveys, from Autm 2019 to Autumn 2021 $( \mathbf { n } = 8 2 9 ,$   

<html><body><table><tr><td></td><td>Start Obs.</td><td>Start Mean</td><td>End Obs.</td><td>End Mean</td><td>Std Dev.</td><td>Improvement. (difference)</td></tr><tr><td>Overall language confidence</td><td>829</td><td>3.07</td><td>829</td><td>3.49</td><td>0.031</td><td>0.42***</td></tr></table></body></html>

Note: Welchs t-test, \* significance at the 1 pecent lel. Men of 9 confidence questions is measured a a simple average of all9 questions. $n = 8 2 9$ are students who answered all 9confidence questions of the survey in both the Start of semester and End of semester surveys.

# 6.4. Agency

As outlined in the literature review, student agency is sen as the ability to set goals and to act responsibly to bring about change. Students developed their sense of agency in the LDTs in several ways. Many of the LDTs required students to set specific language learning goals, using the SMART goal-setting approach (Specific, Measurable, Achievable, Realistic, Timely). This strategy encouraged students to focus on their individual language needs and to identify which aspects of academic language they needed to develop in order to perform well at universt. As part of goal setig, tutors encouraged students to focus on their course asessments and to accessresources provided by the University  centralised study support centre and the broader universt. In end-of-semester surveys $( n = 1 6 9 7 )$ , most students $( 8 4 . 5 \% )$ agreed or strongly agreed that they had developed their ability to set language goals.

Student comments from surveys and focus groups about the goal-setting exercises (referred to as learning cycles again mention building confidence and a greater ability to manage readings amongst the benefits:

I've got two learning cycles .. to improve my writig skills and reading skill. So that's pretty helpful. I read a lot of articles during this semester so I think this course really helped me to improve many things in my [life]. [Focus group, 2020, Business]

In addition, students commented that participating in the LDTs helped them to learn how to adapt to university life and to access resources at university, such as the library, student-facing language support services, and online grammar and avoiding plagiarism resources.

In the end-of-semester surveys $( n = 1 6 9 7 )$ , approximately $7 4 \%$ of students agreed or strongly agreed that, 'As a result of the LDTs, I aave attended at least one activity organised by [university support service] online'.

The following comment provides a snapshot of what this student found useful.

'I signed up for that communication [student support service] . they had many links or support ways in University X to help you with specific goals, such as English or presentation, academics, I plan to use that throughout my holidays .. I wasn't prepared for university but these things, now I'm aware f, I wil tend to be more prepared for the next leson from here on out." [Focus group, 2019, FEIT]

Further comments from students show that through thir participation in the LDTs, students developed awareness of the range of upport services and resources at the university, and that in many cases they were utilising these resources. Further, the students lanned to continue to avail themselves of a range of support services including services such as Grammarly.

# 6.5. Social connections

Finally, students reported that they developed social connections within the LDTs, which helped them feel motivated and engaged about both language learning and course learning. These social connections also helped students develop a sense of belonging. Students made friends in the LDTs, and felt it was easier to speak with other L2 students. The smallr classizes encouraged students to talk to one another, as did the language activities which focused on discussions. Another aspect of the role of fect in language learning is that of students feeig comfortable or feeing at ease tudents expressed a sense of being comfortable in the tutorials, and of experiencing enjoyment in the learning activities.

It was common to see student comments about feeling comfortable' in the clas, or in exchanging ideas with other students. When students tlked about being or feeling comfortabl, they referred to: felig comfortable talking to the tutors; being comfortable in general); and being comfortable with English. Students expressed asense of enjoyment when participating in the LDTs, commenting that it was both helpful and fun. In addition, the opportunity to interact with students studying the same course and with similar linguistic challenges was commented on by several students as making them feel more comfortable and confident.

# 7. Discussion

The aims of this paper were twofold: firstly, to report on the significant measurable benefits for students attending LDTs as part of an institution-wide ALD program; secondly, to outline a comprehensive and innovative approach for evaluating language programs that is large scale, long term and multi-faceted, and that addresses both the cognitive and the affective aspects of language development.

Firstly, our study confirms previous research, both intitution-wide (Fenton-Smith et al, 2018) and on a smallr scale (e.g., Calo et al., 2020; Dooey & Grellier, 2020; Leopold, 2011; Murray & Muller, 2019) that attendance at LDTs results in better student outcomes, not only in terms of gains i academic language proficiency but also in improved course grades. Of particular importance is the finding that students identified as needing support and who atended the LDTs showed higher levels of discipline language compared to those who did not meet attendance requirements, as evidenced by results from the first milestone assessment. This finding differs from Fenton-Smith et al.'s (2018) institution-wide study, which found that short-term gains were not significant following their language program. However, as noted by the authors, the tool they used to measure language gains (IELTS) was not designed to measure short-term gains in discipline-specific language. Because our study observed students (significant) perceived short-term gains in academic language as well as their achievement of discipline-specific language in the milestone task at the end of semester, we propose that this type of language asessment may be more efective in measuring academic language production in context than standardised tests such as IELTs. Gains in academic language could then be tracked over time if milestone tass are embedded into assessments across degree programs, and this is the next stage of our research.

Secondly, our study also supports previous research which shows that ttendance a iscipline-specific LDs resuls in higher course marks (e.g., Calvo et al., 2020; Dooey & Grellier, 2020; Maldoni & Lear, 2016). Our findings also suggests that attendance at the LDTs has a positive impact on both students' understanding of course content and completion of asessment tasks (Maldoni & Lear, 2016; San Miguel et al., 2013).

A third area where our study makes an important contribution is the role that affect plays in academic language development programs. Although it is esential or ALL units to present reportable data on academic outcomes to university management to ensure ongoing funding, there i also an increasing awarenessin higher education instiutions of the importance ofaffect in leaning. Key concepts relating to afect include confidence, social conections, agency (and educational frailty as the flipside to agency (Gravett & Kinchin, 2020). In response, across some sections of the universty sector, the development and evaluation of academic language development programs have considered not only the positive impact of programs on students academic sills but also these more affective aspects. Several evaluations have reported on gains in confidence with academic language that students achieved as a result of attending programs (Calvo et al., 2020; Dooey & Grellier, 2020; 0Neillet al., 2022). Similarly, confidence emerged as a major finding from our study, with students reporting asignificant growth in language confidence that led to greater social connections by the end of the LDTs.

While we did not explicitly set out to measure social connections in our study, it emerged from the focus group and survey comments as a key benefit of atending the LDTs. Forming friendships and making social connections can initilly appear as peripheral to university learning, but educational theorists Felton and Lambert (2020) locate these at the centre of academic engagement. Their notion of eationship richducatio understands that in order to suce at univrsty, stdnts must fl like they belong. Belonging at university means building connections with peers and stff as well as connections to academic currculum (Pacansky-Brock et al., 2020). Social connectons aid academic learning, as they provoke passion, motivation and enable greater willingnessto acces to support. Felton and Lambert (2020) observe that particularly for marginalised students, connections to peers keeps them engaged and from dropping out of university study. Furthermore, a sense of connection with the university can also be developed by strengthening students' understanding of the academic language used in their discipline. Commencing university students report their \*considerable uncertainty" about \*what was expected of them with regard to academic skills (Goldingay et al., 2014, p. 46). The better understanding of core academic practice reported in our study, such as learning how to reference as well a the growth in agency developed through the seting of learning goals, may enable students in feeling that they are becoming members of the academy. As noted by Gravett and Kinchin (2020), if students are unfamiliar with core academic practices such as referencing, they can feel anxious and devoid of agency. This study shows that students participation in the LDTs may amelorate these experiences.

Many of the domestic and international students who attend LDTs speak English as an additional language. It can be particularly challenging for students from linguistically diverse backgrounds to develop social connections because they may have lower levels of academic preparednessthan native peakers of English (Palmer e l., 2018). Linguistically diverse students may also have fewer social networks at niversities, espeill if they move to Australiato study. Many intnational stdents describe thedifficult they have n making friends outside their own language groups. One Australian study found that only $2 2 \%$ of international students had made friends with local students, just $6 \%$ had been invited to the home of a local student, and only $3 5 \%$ of international students feel part of the university community (Arkoudis et al., 2019). Our study shows that academic language programs can play an important role n helping students from linguistically diverse backgrounds develop social connections. The development of social connections evidenced in our study was partly due to being ina class with students who were, as one student in our study said, inth same boat, supporting the finding (San Migel et a., 2013) that being in a class where the majorit f students are 2 students create  sense f ase and maes it easier to talk with other students.

The comprehensive evaluation approach that we have outlined in this paper, which analyses extensive data on academic language development, academic outcomes, student perceptions of their confidence and other gains from attending LDTs, provides a rich picture of the impacts of the ALD program. The use of asociocultural perspective on language development in our study, a perspective that acknowledges the unity between cognition and emotion, reveals how critical it i to consider students affctive experiences of language learning within higher education. We propose that ffective dimensions of language learning be added to the evaluation model used by Fenton-Smith et al. (2018) and the ICALLD evaluation model rcommended by Hamilton et al. (2019); specifically, eelings of academic language confidence and the development of social connections. A more holistic view of language development willprovide the field with a deeper understanding of the complex nature of language learning in higher education, and of how best to support discipline-specific academic language development.

# 8. Conclusion

This paper contributes to the limited range of institution-wide ALD programs in which commencing students are screened for academic language proficiency and are subsequently supported and monitored for their disciplinary language skill development throughout the course of their degree program. It also presents a long-term and multi-faceted approach to evaluate such an institutionwide ALD program, which takes into account the cognitive as well as affective aspects of language development.

The results of our study indicate the positive benefits students can gain from language development programs which are under. pinned by a sociocultural framework that considers the criticl role faffect in language learning and teaching. The improved language skill and growth in confidence in using language, the further development fa sense of agency, and the building of social connections and belonging are all important elements of the language development and learning processe, all of which contribute to improved understanding of disciplinary knowledge and academic performance.

We acknowledge some limitations of our study. Firstly, some of the themes that emerged from the data analysis, such as social connections, were not included as areas of investigation in the original urvey and interview questions. In any further surveys and focus group interviews, we wil include pecific questions to ask students about developing social connections through attendance at the LDTs. Secondly, we do not disaggregate international and domesic students in the fcus groups and the surveys, soit is not possible to determine the extent to which the LDTs addres the nees of one group more than another. However, at the time of our study, this was not a priority.

Future steps in the development of our evaluation approach will address the longer-term impact of the program and a deeper exploration of the role that social connection plays in academic language development programs. We plan to track students achievement in milestone tasks over degree programs, which would help our understanding of the long-term impact of the program, as well as providing University X students with the opportunity to access reportable academic language development.

# Declaration of competing interest

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

# Appendix A. Supplementary data

Supplementary data to this article can be found online at https://doi.org/10.1016/j.jeap.2022.101192.

# References

Ari ,  019  e7 (5), 799-813. https://doi.org/10.1007/s10734-018-0302 $- \mathbf { X }$   
Ar i of Australia. Retrieved https://www.ieaa.org.au/documents/item/664. (Accessed 25 January 2021). from.   
,        . Ortega , Sma, J, wain,  Taoe,  (2016).  trandciinary rmwork for A  a muingal od. he og al, 100\$1, 19-47. https:/doi.org/10.1111/modl.12301   
Bigw019. the  g  g Th , 1 15-5././0.111 modl.12569   
nd, .01     it n, 49.0.1080 13562517.2019.1593129   
Braun, V., & Clarke, V. (2006). Using thematic analysis in psychology. Qualitative Research in Psychology, 3(2), 77-101.   
Briggo  . 014)E ih  t ge f  p Language and Literacy, 37(1), 67-74.   
Calo, .  ,    -. 2i   t rate inclusive practice intervention in the United Kingdom. Sustainability, 12(3), 1155. https://doi.org/10.3390/su12031155   
Cho . t  7-4. https://doi.org/10.1080/13562517.2019.1657398   
Creswell, J. W. (2014). Research design: Qualitative, quantitative and mixed methods approaches (4th ed.). SAGE Publications.   
i Australian universities. Canberra, Australia.   
Doey, . r,  0   t-. f  12) 106-119.   
Doy, i  .    i it Journal, 28(1), 3-19. https://www.englishaustralia.com.au/documents/item/175.   
Duff, . 0  tin n e ie.  e of ed ic, 30, 169-192. h/g/10.1017 S0267190510000048   
Edwards, , ldsmt, R, ary,  James,  (2021). An institin-wide straty for ongoig, embedd admic lange deelomnt: esign, mpleen d .  f    1 -71.i f /x./e/view 745.   
Edwards, ,  Roger, P. S. (2015). Sking out challnges to develop 2 self-conidece a language lener's journe to proficiency. Te1j, 18(4)   
Elder, C., & Knoch, U. (2009). Report on the development and trial of the academic nglish crening et (AEST). University of Melbourne.   
Fer,  10   l icati o thery  pi    f t Research, 4(1), 6-16.   
Felton, P, & Labert . (2020. Rionship-richcation: Hw an contions di uces i colle. Jns Hins Universit Pr.   
Fen-Smt . mpe . 2015).  ss v ni  ad g sut mhn r   corork students: The case for adjunct tutorials. Journal of Englis for Academic Purposes, 20, 40-55. htps://doi.org/10.1016/jeap.2015.05.001   
-m   8tfit-cth  e. Journal of English for Academic Purposes, 31, 72-83. https:/doi.org/10.1016/j.jeap.2017.12.001   
Fn-Smt , mpey , nh , el,  o  017). ig rt-wide cr- sh e ent programme: ssues emerging from practice. Studie i Higher Education, 42(3), 463-479. htps://doi.org/10.1080/03075079.2015.1052736 Education, 18(8), 933-949. https://doi.org/10.1080/13562517.2013.827644   
Gaffas 019  t   r s  r  a  i for Academic Purposes, 42, 1-13.   
Gkonou, C., Dewaele, J.-M., & King, J. (Eds.). (2020). The emotiondl ollercoaster of language teaching. Multilingual Matters.   
y       1     u a to   k     thet  ge, (1) 43. https://doi.org/10.5204/intjfyhe.v5i1.194   
lsmit  , 1) ie  i   k . he retention success.   
Graet, ,  Kich 2020. g and mt xpig rert   th hhr   epri Education, 25(1), 84-97. https://doi.org/10.1080/13562517.2018.1541883   
Hmo, J,  h   . 019. if     pinif c Language and Learning Development (ICALLD). http:/ataanz.org/wp-content/uploads/2020/08/ICALLD Evaluation Report_final_pdf.   
Harper, . 2013. om principlet practice: mleming an Eglish aag roficey mdel at iA Jal of Ac ge a ng 72) A150-A164. Retrieved from https:/journal.aall.org.au/index.php/jall/article/view/262.   
Kamberelis, G., & Dimitriadis, G. (2005). On qualitative inquiry. Teachers College Press.   
Lantolf, J. P. (Ed.). (2000). Sociocultural theory and second language learning. Oxford University Press.   
Lantlf  wi  2019. teinct l  r. The  , (103), 5-530. /o. org/10.1111/modl.12574   
Lepold 11i  t   ish a, 1, 67-18.   
an  0   i 3./ul/ vol13/iss3/2.   
McKinley, N. (2020). Introduction. In McKinley, & H. Rose (Eds.), The Routdge handbook of rerch methods i applied linusic. Routledge.   
uay, 014 t  t ti  - h     7./. org/10.1080/15434303.2013.824975   
Murray, N. (2016). Standards of English in Higher Education. Cambridge University Press.   
ua 0        n 43(10), 1348-1362. https://doi.org/10.1080/0309877X.2018.1483015   
uray,   016). n  i nt  ri  .   gi, , 296-1312. https://doi.org/10.1080/03075079.2014.981150   
ogh  009  .   
OECD. (2019).Student agency for 2030. 0ECD future of education and skils 2030. https://www.oecd.org/education/2030-project.   
eil  r,  r,  n  (02h t of  itr c nt t ti tain university. Journal of Academic Language and Learning, 16(1), 35-58.   
Paansky-k er,   i-o 2020) ui h io    o 2)   
Paer  0   . 2, 49-61.   
ul. quality assurance agency for higher education. http://dera.ioe.ac.uk/445/2/FinalReportApril09.pdf. (Accessed 5 April 2014).   
chste,  ir 14h  thi   g13-. /. au/herdsa-re-view-higher-education-vol-1/63-81.   
SanMigel, d   . 013. gg ig i fo    d.     w Marginalised Populations, 44(1), 21-31. https://doi.org/10.5172/conu.2013.44.1.21   
nivrty  t  2). h/ / made-tests.   
iha , d   015       3) 1-. . org/10.1177/2158244015607936   
Wate, .015.y   t   ii   tin   s .

Roali i p s  r  tt     icatin pracir    r th  aangae development, professional learning, and developing professional identity. Email: rosalie.goldsmith@uts.edu.au

eborah n raon i r wth the d g ad g t Hr h  tdie f dment, mtio, my ad te cnstiti         r,  and geography.

Gma   r t rt f . h e i i  a xtitt learning design and the development of professional skills.

JinSug ang    at  th h ati     i ci ili  is xperid n mg  o a e iti d aprat d, d n id efil.

Joseph Yeo: Joseph Yeo is a lecturer with the Academic Language $\&$ Learning team at UTs. He has a background in linguistics and e-Learning, and has worked extesively wh e f gish or mny r. e wks cll h the hof i to me ion prctie tht the cri