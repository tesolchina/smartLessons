# The impact of learning support facilitated by a robot and IoT-based tangible objects on children’s game-based language learning

Ya-Wen Cheng, Yuping Wang, Yu-Jie Cheng & Nian-Shing Chen

To cite this article: Ya-Wen Cheng, Yuping Wang, Yu-Jie Cheng & Nian-Shing Chen (2024) The impact of learning support facilitated by a robot and IoT-based tangible objects on children’s game-based language learning, Computer Assisted Language Learning, 37:7, 2142-2173, DOI: 10.1080/09588221.2022.2152053

To link to this article: https://doi.org/10.1080/09588221.2022.2152053

# The impact of learning support facilitated by a robot and IoT-based tangible objects on children’s game-based language learning

Ya-Wen Chenga $\textcircled{1}$ , Yuping Wangb, Yu-Jie Chengc and Nian-Shing Chend $\textcircled{1}$

a Department of Early Childhood Education, Asia University, Taichung, Taiwan; bSchool of Language and Linguistics, Griffith University, Nathan, Australia; c Department of Information Management, National Sun Yat-sen University, Kaohsiung, Taiwan; dInstitute for Research Excellence in Learning Sciences and Program of Learning Sciences, National Taiwan Normal University, Taipei, Taiwan

# ABSTRACT

Existing research has established immense importance in contextual learning for second language development. However, to provide real-life context in the learning of a foreign language is challenging. To help create such a learning environment, our previous research developed an innovative system called the R&T System, utilizing robots (R) and tangible objects (T) with Internet of Things (IoT sensors). As the R&T system is still new, there is no sufficient knowledge about what learning obstacles learners would encounter in such a context-rich environment and how best to support them. To explore these issues, in the current study, we designed an English vocabulary game to engage learners to interact with the R&T System. Adopting an action research methodology, we first conducted a pilot study with 12, fourth grade students to identify learning obstacles in a game setting. They were randomly assigned to two groups, one with learning support and the other without learning support. The experiment lasted for four weeks. Both pre-test and post-test on English vocabulary were used to measure the effectiveness of these learning support mechanisms. From the video recordings of the participants’ engagement with the R&T System, the results reveal that the learning support mechanisms had positive impact on the participants’ learning performance and significantly reduced the occurrences of learning obstacles. This research could serve as a useful reference for future research when designing learning support for contextual vocabulary learning supported by a robotic system.

Abbreviations:  RALL: robot assisted language learning; MALL: mobile assisted language learning; IoT: Internet of Things; R&T system: a system integrating robot and tangible IoT-based objects; LS: learning support; LO: learning obstacles

# KEYWORDS

Learning support; IoT-based tangible toys; educational robot; robot facilitate language learning

# 1.  Introduction

Contextual learning is important, as it helps learners to connect the content that they are learning to real-life scenarios (Dewi & Primayana, 2019). Research shows that rich contextual information can help learners comprehend learning materials better and retain what they learn more effectively (Hwang et  al., 2016; Franciosi, 2017). In language learning, the importance and necessity of contextual learning environments have also been recognized (Chen et  al., 2018; Lan, 2015; Lan et  al., 2018), particularly in vocabulary learning (Lin & Lin, 2019).

Vocabulary learning is essential to language learning, as it is regarded as the foundation for learning any additional languages (Lee & Yoon, 2019). However, in the conventional classroom context, vocabulary has often been taught in a decontextualized setting and even through rote learning in some countries where English is a foreign language (Chen & Li, 2010). Despite the challenges in providing real-life contexts for second language development (Lan, 2015; Lin, Hwang, Fu, & Chen et  al., 2018), recent research has reported the incorporation of various technologies to facilitate contextual vocabulary learning. Lin and Lin (2019) reviewed the use of mobile technology to facilitate contextual vocabulary learning and found that the key advantage of mobile language learning is learners can be situated in real-life environments. Virtual worlds are also used to create a real-life like context in which learners interact with virtual avatars. Another example can be found in our recent research which proposed a R&T system (Robot and Tangible IoT-based objects system) that integrates robot with tangible objects equipped with Internet of Things (IoT) sensing devices (Cheng et al., 2020; see Appendix A for a more detailed description about the R&T learning system). This is an innovative approach that supports the creation of contextual learning environments, in which learners interact with a robot and IoT-based objects in a real-life context. Such a system facilitates real life scenarios such as shopping and cooking, in which the robot often acts as a physical pedagogical agent mediating interaction between learners and IoT-based objects. With the help of sensing devices attached to the objects, the robot can perceive the objects and learners’ behaviors synchronously and respond accordingly, such as prompting contextual feedback to engage learners. The IoT-based objects can be real objects such as a real cup or a toy banana. The use of tangible objects helps create join attention between the robot and the leaner, allowing learners to interact with robots continuedly and to facilitate learner-robot collaborative learning. Besides, these tangible objects can also be used to create diverse learning scenarios, to better engage learners in deep and authentic language learning. For example, used in vocabulary learning by children, the R&T system allows learners to match words with the real objects to complete a real-life task. In addition, holding or manipulating a tangible object also promotes sensorimotor interaction (Sullivan, 2018; Shapiro & Stolz, 2019). Such an interaction can also lead to a deeper understanding of the meaning and syntactic knowledge of the words, as the embodied cognition approach suggests (Wellsby & Pexman, 2014). The above discussed importance of contextual learning and what the R&T system can offer for contextual learning led us to the decision of using a vocabulary game to explore the effectiveness of learning support.

Nonetheless, creating a contextual learning environment does not guarantee effective learning. Without proper learning support, learners may easily get confused or distracted. Learning support in this research refers to a variety of instructional methods or resources that are provided in an effort to facilitate effective learning and/or help learners overcome learning problems they encounter during learning. The current study is a continuation of our previous research investigating how contextual language learning can be supported by the R&T system. The R&T system supported learning is still new to us and is more complicated than robot-learner only interaction. It is complicated in the sense that learners need to adapt to the new learning modality while comprehending learning material at the same time. When conducting a learning activity, learners also need to multitask, e.g. to manipulate tangible objects while listening to the robot’s instructions and conversing with the robot in the target language. Learners also depend on the robot to tell them what to do, and how to solve a problem. Needless to say, learners need support in many ways in such an engaging learning environment. However, as the learning environment is still new to us, we do not have sufficient knowledge about what learning problems or challenges learners may encounter and what kinds of support are needed to meet the needs of learners working in such an environment. These are the issues that this research aims to investigate.

The present study thus aims to (1) explore the potential learning problems that learners encounter in a contextual game-based learning environment supported by the R&T system, and the learning support that the system can provide; (2) to investigate the impact of such learning support. Findings from this research will help answer the following three research questions:

1. What kinds of learning support do learners need in game-based language learning facilitated by a R&T system?   
2. What impact does the learning support facilitated by R&T system have on game-based vocabulary learning?   
3. What impact does the learning support facilitated by R&T system have on reducing learning obstacles in game-based vocabulary learning?

# 2.  Literature review

# 2.1.  Second language vocabulary learning and contextual, situated and authentic learning

This section briefly reviews the approaches and difficulties in second language vocabulary learning. This is followed by a discussion on the learning theories and approaches that informed the design and development of game-based vocabulary learning supported by an R&T system in the current research.

# 2.1.1.  Approaches and difficulties in second language vocabulary learning

Studies have shown that vocabulary learning plays a critical role in second language learning and that the lack of vocabulary knowledge is a key obstacle in mastering L2 (Surmanov & Azimova, 2020). The difficulties in vocabulary acquisition have long been recognized, for example, in terms of the large vocabulary size needed for proficiency and the depth of vocabulary knowledge for each lexical item (see Schmitt, 2008 for a review). The complexity and multifaceted nature of vocabulary learning have catalyzed a great number of approaches and strategies for maximizing effective vocabulary learning, such as explicit learning on forms (see Laufer, 2005 for a reviewer), incidental learning and task-based learning on meaning (e.g. Van den Branden, 2006), and repeated exposure (Nation, 2001). In this research, we adopted the meaning focused learning approach, which emphasizes on learning language features through using them in appropriate contexts, rather than focusing explicitly on language forms (Doughty & Williams, 1998).

# 2.1.2.  Contextual learning environment

Contextual learning stems from a constructive theory of teaching and learning that sees learning as a process of continuous self-construction (Piaget, 1971). It is facilitated by a range of theories and approaches such as active learning, authentic learning, and problem solving and situated learning (see Lankard, 1995). Contextual learning is important because through learning ‘in an integrated, multidisciplinary manner and in appropriate contexts’, learners are ‘able to use the acquired knowledge and skills in applicable contexts’ (Berns & Erickson, 2001). Thus, a real-life shopping scenario was adopted to design learning activity using IoT-based tangible objects.

Context is also an important factor in second language learning (Caldwell‐Harris, 2021). The meaning focused and the interactionist approaches in second language learning emphasizes on learning languages through social interaction in a meaningful context of one’s society, cultural and personal life experiences (Eun & Lim, 2009). Context includes all the phenomena learners come in contact with while language input and output occur (Prince, 1996), among which the objects and people that learners interact with play a major contributing role (Rowe & Weisleder, 2020; Godwin-Jones, 2018).

Schouten-van Parreren (1989) asserted the importance of contextual vocabulary learning, stating that the memorization of a word is highly related to one’s cognitive process of the word, including inferencing the meaning of the word from the context it is used. Furthermore, studies have pointed out that contextual vocabulary learning involves multiple expansions of the meaning of the word through various encounters (Kramsch & Thorne, 2002). Hwang et  al. (2016) also pointed out that the contextual encountering of a word allows one to comprehend the meaning of the word more accurately and use the word more easily and appropriately than learning a word in a de-context environment. However, contextual learning environments, especially authentic ones, are not readily available to many language learners, and this is especially true for learners learning English in non-English speaking countries. Game-based learning is one solution to this issue, as it offers possibility for integrating learning contents into stories to immerse learners in emulated scenarios, often supported by technologies (Chen & Lin, 2016; Fu et  al., 2019; Hwang & Wang, 2016; Lan et  al., 2018).

# 2.1.3.  Situated learning activity

Situated learning occurs in a contextual learning environment, in which a real or emulated scenario is implemented, e.g. going shopping, with the aim to provide opportunities for learners to create meaning from authentic experiences in the process of completing hands-on activities (Stein, 1998; Donaldson et  al., 2020). Learners become involved in hands-on activities while given or encountered a specific problem in an authentic context, like identifying a thief while doing shopping. These types of hands-on activities, in turn, embodies the beliefs and behaviors learners have acquired (Renkl, 2001). Applying these elements to vocabulary learning, a situated learning activity should be designed to encourage learners’ active interaction with others in a context relating to real life situations.

# 2.1.4.  Authentic learning experience

Authentic learning happens when learners are fully engaged in a situated learning activity, especially through embodiment participation. There is growing attention to physical actions as a contributing factor to effective language learning (Ortega, 2017). Physical actions such as gestures, the manipulation of objects and deictic verbal expressions can engage one’s attention in interaction (Svennevig, 2018), improve understanding and retention. Embodied learning becomes an integral part of situated learning, emphasizing that the mind and body are inter-linked and that actions give rise to meaning (Skulmowski & Rey, 2018; Kosmas et  al., 2019). Furthermore, embodied actions occurring in learning, e.g. the manipulating of objects and spaces during a game, may produce emotion investment and retention (Godwin-Jones, 2018). This is because adding motoric modality in learning can activated more neural pathways and result in memory trace (Johnson-Glenberg, 2018).

The above-mentioned theories and approaches to learning provide a theoretical foundation and guidance for the learning design of this study. Translating these theories into our learning design, we created contextual environments in which learners learn vocabulary by completing scenarios-based tasks, interacting with the robot and IoT-based tangible objects (e.g. toys or real objects), through speech and physical actions. For example, when learning fruits, we created a shopping scene mimicking a real-world supermarket where learners need to pick up real or toy grocery items attached with either a near field communication (NFC) tag or a barcode and scan the items at the checkout counter. In completing this task, learners would actively engage in collaborative, situated, authentic and hands-on learning, which may lead to their successful application of these vocabularies to real life situations.

# 2.2.  Learning problems in robot supported learning

A large body of literature have reported the advantages of using robots as a pedagogical agent in learning (Belpaeme et  al., 2018), with a focus on the positive aspects of robot in education. In the past five years, studies concerning the use of robots for language learning have largely focused on how to design a social robot, the impact of social robots on learning and proposing guidelines for the design of social robots (Belpaeme et  al., 2018; Kim & Smith, 2017). However, a major gap still exists in Robot Assisted Language Learning (RALL): the lack of research into how learners should be supported in a robot game-based language learning environment, and what kinds of learning support mechanisms can and should be designed into a robotic system.

Learning problems occur when something happens that interrupts the flow of the task, resulting in interaction breakdowns. Learning problems can be observed through the following indicators, learners’ actions, learners’ understanding and learners’ engagements (Iacovides et  al., 2015). That is, learning obstacles can be detected when learners exhibit emotional states, become inactive, engage in off-track activities or seek external assistances rather than from the robot (Serholt, 2018). Serholt (2018) identified several interaction breakdowns in a robot game-based learning activity, including occasions when the robot failed to engage learners at the beginning, and when the robot was not able to detect learner’s problems and failed to provide a correct scaffold. Incorrect scaffolding occurred largely because of the robot lacking perception of learners’ learning problems, which often led to more confusion and negative learning experiences. In particular, learning problems that occur in an earlier learning stage may cause more learning obstacles in the ensuing learning stages. For example, if the robot fails to engage children when it is giving instructions of a learning task at the start, children would not know what to do next and would quickly disengage from the task.

The occurrence of learning problems in a RALL activity can be contributed to many factors, including language issues, technical issues, learner- robot interaction and environmental factors (Chiang et  al., 2020). Increasing research has shown evidence that both cognitive and non-cognitive factors play an important role in learners’ learning performance. Cognitive learning factors include content knowledge, the general cognitive abilities, e.g. the ability to reason, plan, solve abstract problems, comprehend complex ideas, and manipulate complex materials. Non-cognitive factors are related to learners’ affective state (e.g. motivation), attitude and learning behaviors (Semeraro et  al., 2020). This understanding informs our classification of the learning obstacles identified in this study into cognitive and non-cognitive categories.

Though the above studies have pointed out practical problems in a robot game-based learning environment, these studies were not conducted in the context of learning a second language and nor were they related to a contextual learning environment involving the use of tangible IoT-based objects. Hence, it is necessary for the present study to conduct a pilot study to explore learning issues encountered by learners in the R&T system- supported learning environment. Such data will inform the design of our learning support.

# 2.3.  Research relating to the design of learning support for RALL

RALL is a cross-disciplinary field that needs to consider multiple factors, such as age, the selection of target words, the amount of language input, and learner-robot interaction (Belpaeme et  al., 2018). Existing studies have proposed guidelines focusing on designing robots’ social behaviors, including verbal and non-verbal, to support effective interaction and language learning. The following pedagogical considerations are worth noting when designing learner-robot interaction.

First, temporary contingency is perceived to facilitate learner-robot interaction in second language learning (Vogt et  al., 2017). A temporary contingency response refers to social feedback made by a conversation partner, such as nodding or making a ‘uhm’ sound while listening. Contingecy responses are an integral part of interaction as they provide spontaneous and meaningful reaction indicating attention being made to the speech (Masek et  al., 2021). In this study, the robot provides temporary contingency responses through three channels: verbal responses, facial expressions, and gestures.

Studies have shown that receiving temporary contingent responses during conversation is crucial to learners’ language development (Bornstein et  al., 2022). Temporary contingent response is a way of keeping the conversation and interaction going, indicating that the listener is listening and is about to respond. However, currently, the robot has not yet been able to produce as timely a response as a human does. To mask the delay in the robot’s responses, a back- channel signal, such as the ‘uhm’ sound can be used prior to the robot’s responses to indicate that the robot is attentive and is ready to respond.

Second, semantic representation should be designed into learner-robot interaction. Considerable evidence from experimental research has indicated that gestures are tightly linked with language production and comprehension (Dargue et  al., 2019). The use of gestures is important in second language learning, since gestures have the ability of supplying information that is needed to convey the meaning of the speech and increase understanding of the speech. The use of gestures in second language learning is found to be enhancing retention in learning vocabulary and comprehension (Andrä et  al., 2020). Iconic, metaphoric, deictic and beat gestures are common types that illustrate concrete information, abstract information, direct spatial awareness and mark the importance of the phrase (McNeill, 1992). In this research, we focused on developing iconic gestures that involve the body movements of the robot to help convey semantic content related to the robot’s speeches.

Third, social presence is an integral part of learner-robot interaction. Social presence refers to the perception of immediacy and intimacy of a conversational partner in computer mediated interaction (Short et  al., 1976). When applying social presence in human-computer interaction, social presence is a feeling that the conversational partner is real and is able to interact and respond to human queries (Kilteni et  al., 2012). People feel more immersed, satisfied when interacting with a computer agent with social presence attributes (Bente et  al., 2008). Social presence is also found to be associated with various positive interaction outcomes, e.g. trust and enjoyment (Hassanein & Head, 2007). Social presence can be shown by verbal and non-verbal cues, through gestures, facial expression, and embodied appearances (Gunawardena & Zittle, 1997). As gestures are important in contributing to the embodiment level of a pedagogical agent and an effective feature of the persona of a pedagogical agent (Davis, 2018), this study enhanced the robot’s social presence through making gestures.

Fourth, robot should be able to monitor learners’ behaviors (Vogt et  al., 2017). Providing effective learning support requires robots to be able to understand what learners’ physical and mental status is. That is, the robot should be able to perceive learners’ behaviors, including verbal and non-verbal behaviors, to provide timely and meaningful feedback, leading to zone of proximity adaptivity. However, the current state of art of speech recognition is not mature enough to recognize learners’ speech correctly, especially in recognizing young children’s speech (Fringi et  al., 2015; Kennedy et  al., 2017). Remedies can be done through monitoring learners’ non-verbal behaviors through visual recognition of objects and recognize learners’ action through sensors attached to tangible objects.

Fifth, scaffolding for cognitive support should be provided during learner-robot interaction. The design of learning support usually draws on established theories such as Vygotsky’s Zone of Proximal development (ZPD)(L. Vygotsky, 1930) and the principles of instructional scaffolding (Wood et  al., 1976; Wood & Wood, 1996). ZPD states that the child’s more advanced peers can scaffold others in acquiring skills that are beyond their existing skill levels (Kory-Westlund & Breazeal, 2019; Vygotsky, 1980). Grounded in ZDP, RALL research and practice have framed the robot as a peer or teaching aid to provide scaffolding for learning. The above five pedagogical considerations were taken into account when we designed the learning support in the current study.

# 3.  Methodology

Because our objective was to develop innovative and transformative learning support mechanisms for the R&T system-supported learning, we adopted an action research methodology. This approach has long been recognized as an effective methodology to the inquiry of a practical problem through cycles of planning, action, observation, critical reflection, and improvement (see Reason & Bradbury, 2001; McNiff, 2017). Guided by this approach, this empirical study was conducted in two phases. In Phase 1, a pilot study was conducted to explore learning problems and challenges experienced by students conducting game-based vocabulary learning in the R&T system-supported environment. We conducted the pilot study using a humanoid robot, Kebbi robot, and we programmed Kebbi using an R&T authoring tool. Upon reflection of the findings from the pilot study, we designed, developed and integrated learning support mechanisms into the R&T system. This was followed by Phase 2 in which these learning support mechanisms were evaluated by students to assess their effectiveness and inform future improvement and development of learning support in RALL

# 3.1.  Phase 1

# 3.1.1.  The pilot study

The aim of Phase 1 was to answer RQ 1 - What kinds of learning support are needed in a game-based vocabulary learning environment facilitated by a R&T system. To this end, we conducted a pilot study in 2019, in which a game called ‘Rookie Officer’s Challenges’ using the R&T learning system was played by two fourth graders (age 11) and one second grader (age 9) individually. Each child played four sessions individually. The children’s process of completing the game was video recorded and observed by our research team, who also took field notes as the game was being conducted.

The game is about solving a theft case in a supermarket. The learner is to play the role of a ‘rookie officer’ to collaborate with the robot, who acts as a senior police officer, to investigate the case. Learners need to complete four tasks in four learning sessions to catch the thief. In Session One, learners are required to learn to use three detecting gadgets which are IoT sensing devices that help them to investigate the case. They are a toy scale that can read near field communication (NFC) tags, a barcode reader that can scan QR codes and barcodes, and a repeat button (a touch sensor on the robot’s belly that repeats and further explains task statements). Leaners need to pass a test at the end of Session One to be a qualified officer and move on to Session Two, by correctly scanning specific items as instructed by the robot. In Session Two, the robot officer happens to run out of energy, and the rookie officer needs to use the three gadgets to provide food items such as apples and bananas to recharge the robot officer. In Session Three, the robot officer found two eyewitnesses of the theft. The rookie officer needs to listen to the witnesses’ testimonies form a prerecorded audio file to identify the thief using the gadgets. In Session Four, the rookie officer needs to use the gadgets to collect five of the thief ’s fingerprints.

The goal of the game was for children to learn English vocabulary in a contextual learning environment. There are several factors involved in our decision to focus on vocabulary learning. Apart from the importance of contextual vocabulary learning and the consideration that the R&T system affords a rich contextual vocabulary learning environment (see discussion in Introduction), we also took the level of English proficiency of the children into consideration. A review of the English curricula used in primary schools in Taiwan indicates that vocabulary learning is the key content for the fourth graders as they only possess a very basic level of English with limited vocabulary. Using flashcards or a vocabulary list to memorize individual words is still a prevalent practice in schools in Taiwan. Such a de-contextualized approach fails to enhance lanague learning (Chen et  al., 2018). We therefore decided to transform the existing pedagogy and provide an interactive and contextual learning environment supported by the R&T system.

Although there was a second grader participating in the pilot study, the game was primarily designed for the fourth graders who had been studying English two hours a week for one year. The rationale for targeting the fourth graders in the pilot study and the subsequent evaluation of the learning support is twofold. Their English proficiency was just enough to understand simple task instructions from the robot, and they were mature enough to work with the R&T system individually without the supervision of a teacher. Thus, the key target words (e.g. names of food, colors) to be learned in the game are the required vocabulary specified in the curriculum for $4 ^ { \mathrm { t h } }$ graders in elementary schools in Taiwan (See Appendix B, Target vocabularies). For example, when learning the color white, in the game, the robot would say: ‘oh no, I’m running out of energy, I need energy from white colored food, could you please bring me a white colored food?’.

Figure 1 shows the learning environment, which consists of a robot, a tablet and a set of toy supermarket. The toy supermarket shelves are stocked with various items, including, fruits, cookies, milk bottles, vegetables, stationaries, and a clothes catalogue. All of the toy items are attached with either an NFC tag or a barcode. The students were also provided with a toy scale with an NFC tag, a barcode scanner and a touch sensor on the robot’s belly. The tablet plays the role of a teaching aide by displaying pictures related to the robot’s instructions for further clarification. The game is run on our R&T learning system supported by graphical programming interface (See Appendix A).

![](img/a1d79ece125e340bd4adb78fff97fa991e0c92142abace82c80c789e5120e975.jpg)  
Figure 1. T he game environment.

![](img/1c4dc93b45e8b7097c9c35ff262eb2e2357ab907776cee35055850876147eafb.jpg)  
Figure 2. T he overall flow of a learning task.

As the scenario shows, the game encourages extensive interaction between the robot and the learner, in which the learner needs to listen to the robot’s instructions to complete the given tasks, e.g. what to do, and where to look for the required items. Figure 2 shows the overall flow of a learning task. Each learning task begins with the robot delivering a task instruction, e.g. the robot cries out that he is running out of energy and asks the learner to look for food items in five different colors. The learner needs to follow the robot’s instruction to look for the specific items the robot requires and use the barcode scanner to scan the items. The learner can also ask the robot to repeat the task instructions by touching the robot’s belly. When the learner successfully scans an item, the robot reads aloud the name of the item. If it is the correct item that the robot has asked for, then the robot would issue a procedural instruction to the learner to proceed to the next stage, e.g. ‘Next, you need to look for a green capsicum’. If a wrong item is scanned, the robot will ask the learner to try again, until the right item is scanned.

# 3.1.2.  Findings, reflection and development of learning support mechanisms

To find patterns of child-robot interaction, i.e. interaction breakdowns in this pilot study, content analysis was adopted to analyze the data contained in the field notes taken by researchers and the video recordings of the children’s game completion. Two researchers watched the videos and marked the timestamps whenever a breakdown occurred. These included occasions when a child called researchers or peers for help, walked away from their own cubicles to chat with others, stopped interacting with the robot, failed to follow instructions or did something unrelated to the game. A technical issue such as the system’s failure to respond was also counted as an interaction breakdown. The two researchers then compared and confirmed these breakdowns with those recorded in the field notes and categorized them into five types of learning obstacles. This was followed by the design and development of learning support mechanisms to dress these obstacles. Each of these obstacles together with our reflection and the corresponding learning support mechanisms developed are discussed below.

First, the children had difficulty understanding some of the task instructions. While listening to the task instructions, they were oftentimes turned to the teachers for help because they did not understand what the robot was saying. Informed by studies on the importance of gestures in vocabulary acquisition (Lewis & Kirkhart, 2020), we developed a learning support mechanism in which the robot makes iconic gestures to help convey what it says. For instance, the robot makes a taekwondo gesture mimicking the action of catching the thief.

Second, we observed that the children were impatient in listening to the instructions, as they would start scanning items when the robot was still giving instructions, thus missing or misunderstanding some instructions. As a result, the children would quickly become disengaged because they did not know what to do. Our field note data also show that different from interacting with a tablet or a mobile device, when interacting with a robot, the children tended to make a lot of physical contacts with the robot, e.g. holding the robot’s hands and touching its head, to see how the robot would react. To better engage the learner and keep them focused on the task on hand, we had the robot make a variety of gestures while talking, much like what a real person does, such as waving both hands or with one hand on the hip and the other up in the air. These gestures were created to enhance the social presence of the robot, which has been seen to be crucial for the acceptance of robot in human-robot interaction (Shin & Choo, 2011; Davis, 2018). We believe such acceptance should lead to better learner engagement.

Third, the children tended to rush to scan the items one after another, without waiting for the robot’s response after each scan. This non-stop scanning would often lead to a system breakdown. This is because the robot takes relatively longer time than humans to respond to commands. The participants, who were not used to the delay, were not sure if the action they performed was perceived by the learning system and often rushed to make another move.

In view of this issue, we enabled the R&T learning system to play an instant sound effect as a response to children’s action. For instance, when learners scan a correct object, the R&T system would play a happy sound first, then followed by the robot’s response: ‘Great! this is a banana’. Such contingent responses made the robot’s delayed responses appear more natural and less observable, and were perceived by Vogt et  al. (2017) to be potentially beneficial to robot-learner interaction in second language learning.

Fourth, the pilot study indicated that the children didn’t always follow the activity procedure. Sometimes they just deviated from the task and started playing either with the toys or with the robot. To tackle this issue, we developed a reengaging mechanism that monitors the learner’s distraction behaviors and reengages learners by regularly calling their attention if no action from the learner is detected for a certain period of time. For example, the robot would say: ‘Are you still there?’ or ‘please try again’. Vogt et  al. (2017) also recognized the importance of monitoring children’s non-verbal behaviors and reengaging them in learning. They proposed some strategies, but did not cover the above strategy we developed.

Fifth, the children often lost interest in completing a learning task when they could not perform the correct actions that the robot requested. This occurred because the children were not able to work out the correct answer. We thus developed a scaffolding mechanism informed by the theories and principles of scaffolding learning (Wood et al., 1976; Wood & Wood, 1996). This mechanism allows learners to work out the correct answer by themselves first, and provides hints only when learners have failed five attempts. In other words, instead of providing learners with the correct answers straight away, the robot would provide various clues for the children to figure out the answer themselves. This is also an indirect way to indicate to the children that their answer was incorrect. This inexplicit way of providing feedback on wrong answers may help encourage children to persist and avoid disengagement (e Haas et  al., 2016; Haas et  al., 2017). When providing a hint, the robot would point at the tablet and draw the learner’s attention to a very blurry picture of the correct answer (e.g. the shape, the color, or the location of the objects the learner is looking for). For example, after a child fails 5 attempts in finding a blue fingerprint, the robot would point to the tablet which displays a blurry picture of the blue fingerprint hidden underneath a cookie box.

Table 1 summarizes the pedagogical underpinnings, types and system function designs of the learning support we developed. These learning support mechanisms are embedded in the learning task flow (See Appendix E).

# 3.2.  Phase 2

This phase was designed to evaluate the learning support mechanisms in order to answer RQ 2 and 3 about the impact of these learning

Table 1. Learning support and the corresponding functionality design.   

<html><body><table><tr><td>Pedagogical underpinning</td><td>Learning support mechanism</td><td>Corresponding system function designe</td></tr><tr><td>Semantic representation</td><td>LS1: Enhancing Semantic cues</td><td>The robot makes iconic gestures to better explain semantic content when giving instructions, e.g. moving arms. back and forth to convey the</td></tr><tr><td>Social presencee</td><td>LS2: Enhancing the robot&#x27;s social presencee</td><td>meaning of running.. The robot makes human-like gestures while giving task instructions to better engage the learner, e.g. the robot waves his arms and points to the toy shelf while talking to the</td></tr><tr><td>Temporal contingency</td><td>LS3: Temporal contingent responses</td><td>child. The R&amp;T system makes sound effects to respond to the learner&#x27;s action, masking the time delay between the learner&#x27;s action and the robot&#x27;s</td></tr><tr><td>Monitoring and engaging</td><td>LS4: Engaging and reengaging the learner</td><td>speech. The robot monitors and reengages the learner by calling their attention when detecting no action from the</td></tr><tr><td>ZPD and Scaffolding</td><td>LS5: Proving scaffoldings to answers</td><td>learner. Scaffolded answers and hints are provided on a tablet after the learner. has failed to work out the correct answer in five attempts.</td></tr></table></body></html>

Note: LS: Learning support.

support mechanisms on students’ vocabulary learning and reducing learning obstacles.

# 3.2.1.  The participants

12 fourth graders, aged 9-10, who had studied English for one year, were recruited from Yunlin elementary school in Taiwan through convenience sampling. The participants were randomly assigned to a control group and an experiment group. Each group had six participants, composed of three female children and three male children.

# 3.2.2.  Procedure

Figure 3 shows the evaluation procedure. The evaluation started with a pretest, followed by an introduction session. In the introduction session, the researcher introduced the R&T learning system and the game, ‘Rookie Officer’s Challenges’, to the participants. Immediately after that, four learning sessions were conducted in two weeks, and each learning session lasted about 20 minutes. Both the control and experiment groups used the same game and R&T learning system as the ones used in the pilot study. The only difference was that the control group interacted with R&T system without learning support, while the experiment group had learning support. The participants were given a posttest three days after the last session. Please see Appendix D for the setting of experiment sight.

![](img/578603432e5c3bffd794ff063a3a02b901c748f3d763f8d17c4cd42bb00a805a.jpg)  
Figure 3. T he experiment procedure.

# 3.2.3.  Instrument

Pre-test: the pre-test is a vocabulary test consisting of 20 multiple-choice questions. The test was designed covering vocabularies that our participants had learned and vocabularies that are used in the learning activities (See examples of per-test and delayed post-test in Appendix C). The pre-test was conducted 3 days before the experiment. The total score of the pre-test is 100.

Post-test: Same as the pre-test, the post-test is also a vocabulary test, with 20 multiple-choice questions. The post-test was designed with the same structure and questions as the pre-test, to ensure that the post-test results are comparable with those of the pre-test. The post-test was conducted three days after the last learning session to assess participants’ learning gains. The post-test was conducted in the same way as the pre-test was and the total score of the post-test was also 100.

Video recording: One camera was set up in each cubicle to record the learning process of each participant during the learning sessions. With 12 learners each participating in four learning sessions, 48 videos recordings were collected, with each lasting about 20 minutes.

# 3.2.4.  Data collection and analysis

To answer the second research question regarding the impact of learning support on the children’s vocabulary learning performance, this study assessed participants’ English vocabulary using a vocabulary pre-test and post-test. 12 pre-test and post-test scores were collected, and they were analyzed with a nonparametric statistic method, Mann Whitney U Test.

To answer the third research question about the effectiveness of the learning support in reducing learning obstacles, this study first analyzed all participants’ learning behaviors to compare the number of learning obstacles that both groups had encountered. The learning obstacles were identified and analyzed with the following protocols. First, one camera was set up in each cubicle to record children’s verbal interaction with the robot and behaviors during the learning sessions. Second, the video recordings were first analyzed by one researcher using card sorting method and verified by two other researchers. At the end, seven types of learning obstacles were identified (See Table 2). The first five learning obstacles (LO1-LO5) are similar to the learning obstacles identified in the pilot study. However, two new learning obstacles (LO6, LO7) emerged in the experiment. Table 2 also shows that we further categorized the seven learning obstacles into cognitive (LO1,6.7) and non-cognitive learning obstacles (LO2,3,4,5). Learning obstacles related to solving the tasks assigned by robot were classified as cognitive and the rest like distraction, lost interest and wondering around were classified as non-cognitive. The learning obstacles were coded by two coders with inter-rater reliability kappa of 0.80.

# 4.  Results

# 4.1.  The impact of learning support on children’s vocabulary language learning performance

The pre-test scores of the control group range from 60 to 85, while the pre-test scores of the experiment group range from 80 to 90.

Table 2. Coding scheme of learning obstacles (LO).   

<html><body><table><tr><td>Code number</td><td>Description of LO</td><td>Examples</td><td>Type of LO</td></tr><tr><td>LO1</td><td>Difficulty in understanding the robot&#x27;s instructions</td><td>The participants did not know what to do after the robot gave task descriptions. The participants did not know what</td><td>Cognitive</td></tr><tr><td>L02</td><td>Being distracted</td><td>the robot asked for. While the robot was giving instructions, the participants looked at the toys or started to play with</td><td>Non-cognitive</td></tr><tr><td>L03</td><td>Repetitively scanning objects</td><td>the toys or the robot. The participants kept scanning objects without waiting for the robot&#x27;s</td><td>Non-cognitive</td></tr><tr><td>L04</td><td>Deviation from task</td><td>response. The participants talked to others or</td><td>Non-cognitive</td></tr><tr><td>L05</td><td>completion Loss of interest in completing the tasks</td><td>walked around the experiment site. The participants stopped trying to find the correct answer after they failed</td><td>Non-cognitive</td></tr><tr><td>L06</td><td>after failing to work out the correct answers Misusing the sensing</td><td>a few attempts and started to play with the toys. The participants used a bar code</td><td>Cognitive</td></tr><tr><td>LO 7</td><td>devices Misconception of learning content</td><td>scanner to scan an FNC tag The participants mistook a green apple for a green bell pepper.</td><td>Cognitive</td></tr></table></body></html>

The post-test scores of the control group range from 45 to 90; while the post-test scores of the experiment group range from 80 to 90 (See Appendix F for the boxplot of both groups’ pre-test and post-test).

A Mann-Whitney’s test was conducted to assess if the children in both groups had equivalent prior knowledge. An outlier was identified and removed from our data to avoid distorting statistical analysis. This resulted in the sample size of control group being 6 and experiment group becoming 5. Table 3 shows the Mann-Whitney Test results of the children’s pre-test and post-test score. The mean and standard deviation of the pre-test were 75.83 and 9.17, respectively for the control group, and 82 and 4.47 for the experiment group. The Mann Whitney’s test result shows that there was no significant difference in the pre-test scores between the two groups ( $U = 1 0 . 0 0 0$ , $ { p } = 0 . 2 9 0  { \mathrm { ~ \ r ~ } }$ , indicating that the children in both groups had an equivalent level of prior knowledge on the target vocabulary and sentences. To evaluate the effect of learning support on the children’s learning gains, a Mann-Whitney’s test was conducted to compare the post-test scores of both groups. The mean and standard deviation of the post-test were 71.67 and 15.06, respectively for the control group, and 88 and 4.47 for the experiment group. The Mann Whitney’s test result shows that there is a significant difference in the post-test scores between the two groups ( $U { = } 3 . 5 0 0$ , $ { p } = 0 . 0 2 7 ,$ ). The children in the experiment group had better learning performance than those in the control group, indicating that learning support facilitated by the R & T System has the potential to enhance learning performance.

# 4.2  The impact of learning support on the occurrences of learning obstacles

To answer the third research question -what is the impact of learning support facilitated by the R&T system on reducing children’s learning obstacles”, the participants’ behaviors were recorded and analyzed. Figure  4 shows the numbers of learning obstacles experienced by the control and experiment groups respectively. Overall, the number of learning obstacles that the experiment group encountered was lower than that in the control group across the seven types of learning obstacles, indicating that the learning support provided might have helped to reduce the learning obstacles that the children encountered during learning.

Table 3. M ann-Whitney’s test results of the children’s pre-test and post-test score.   

<html><body><table><tr><td></td><td>Group</td><td>N</td><td>Mean</td><td>SD</td><td>Mean Rank</td><td>Sum of Ranks</td><td>Mann- Whitney U</td><td>z</td><td>p</td></tr><tr><td>Pre-test</td><td>Control group</td><td>6</td><td>75.83</td><td>9.17</td><td>5.17</td><td>31.00</td><td>10.000</td><td>1.06</td><td>.290</td></tr><tr><td></td><td>Experiment group</td><td>5</td><td>82.00</td><td>4.47</td><td>7.00</td><td>35.00</td><td></td><td></td><td></td></tr><tr><td></td><td>Post-test Control group</td><td>6</td><td>71.67</td><td>15.06</td><td>4.08</td><td>24.50</td><td>3.500</td><td>2.21</td><td>.027*</td></tr><tr><td></td><td>Experiment group</td><td>5</td><td>88.00</td><td>4.47</td><td>8.30</td><td>41.50</td><td></td><td></td><td></td></tr></table></body></html>

![](img/17045c0f637d242c1ac660e97297c0cbd5c7fe48b9297605774a2f20ed4c5a9e.jpg)  
Figure 4. T he numbers and distribution of learning obstacles encountered by the control and experiment groups.

![](img/5a99d9fc6045ea0e9c2fb3c5cda668c7054f7025dca6b6c0cbc81cc4f577120b.jpg)  
Figure 5. T he number of cognitive and non-cognitive learning obstacles.

With respect to cognitive and non-cognitive learning obstacles, the result shows that the control group encountered more non-cognitive learning obstacles than cognitive ones, but an opposite trend emerged with the experiment group, who encountered more cognitive learning obstacles than non-cognitive ones as shown in Figure 5. This result could indicate that learning support is more effective in reducing non-cognitive learning obstacles. The figure also demonstrates that as far as the combined number of cognitive and non-cognitive learning obstacles encountered by each group is concerned, the total number for the group with learning support is significantly lower (by $6 9 \%$ than that for the other group. This difference could lead to our conclusion that leaning support could help reduce both cognitive and non-cognitive types of learning obstacles.

# 5.  Discussion

Overall, data from the recorded sessions show that the learning support proved to be highly effective as the experiment group outperformed the control group, in terms of vocabulary learning, and that the experiment group encountered fewer learning obstacles during task completion in comparison to the control group. It is worthwhile to have a closer look at how each learning support mechanism worked to facilitate the children’s task completion.

The first learning support (LS1) - providing more semantic representations through gestures - did reduce the level of difficulty in understanding the robot’s instructions (LO1). This finding echo what has been reported in the literature in regard to the facilitative effects of using virtual agent/robot-initiated gestures in vocabulary teaching. These effects include improving learning performance and maintaining longer retention (de Wit et  al., 2018; Tanaka & Matsuzoe, 2012; Bergmann & Macedonia, 2013). Furthermore, by mirroring key semantic features of a new word, gestures, together with oral explanations, effectively served as a scaffolding helping the children to guess or better comprehend the meaning of an unknow word. Similar results were also reported by Bergmann and Macedonia (2013).

However, LO1 was still the most frequently occurring learning obstacle in both groups as shown in Figure 4. There could be many factors contributing to the difficulty in understanding the robot’s instructions. For example, the current affordance of the iconic gestures provided by Kebbi robot are still very limited, because the robot doesn’t have fingers to make fine gestures as a human does (Vogt et  al., 2017; van den Berghe et  al., 2019). Another reason for the difficulty in understanding the robot’s instruction was that the target words used in this experiment were not easy to be represented by hand gestures, e.g. colors. Our findings suggest that adopting multiple channels, such as auditory, visual and kinesthetic channels to help create a rich contextual environment could facilitate better comprehension. When using an auditory channel, we could adjust the tone of the robot’s voice to highlight the important semantic parts of a speech. Through a visual channel, key information could be displayed (e.g. on a tablet) to create a meaningful and context-rich environment for comprehension (Demir-Lira et  al., 2020). A combination of gestures including deictic, iconic, beat and metaphoric gestures could promote kinesthetic learning and authentic learning, resulting in better learning (Huang & Mutlu, 2013; Belpaeme et  al., 2018, Dargue et  al., 2019).

Data from our field notes, the recorded videos and the statistical results shown in Figure 4, all indicated that the second learning support (LS2)—increasing the robot’s social presence through gestures - was very effective in engaging the learners. Previous studies also confirmed that the enhancement of robot’s social presence through gestures can promote learner engagement (Szafir & Mutlu, 2012; Chen et  al., 2021). This is because social behaviors made by the robot, e.g. gesturing while talking, personify the robot, and encourage learners to interact with the robot in a more personal and meaningful way. (Koelsch et  al., 2021; Kim et  al., 2022; Chen et  al., 2021; Yan et  al., 2004; Bethel, 2009). We observed that the participants in the experiment group kept their eyes on the robot most of the time and rarely get distracted when listening to the robot while watching the robot’s gestures. Moreover, data from our field notes at the scene also show that the experiment group tended to apply more social norms in comparison to the control group when interacting with the robot, treating the robot more as a social being and interacted with it socially e.g. gazing at the robot while it was talking and holding the robot’s hands when listening to the robot expecting that it would response to their touches. To enhance the robot’s social presence, we suggest adopting various social behaviors and gestures for the robot to respond to learners’ actions, e.g. showing a happy or shy face when children touch the robot’s body, turning its head following children’s movements, making eye contact or nodding its head while listening to indicate that the robot is attentive to children’s action.

With regard to our third learning support (LS3), our consolidated data show that providing a temporary response (e.g. a happy beep sound) to the learner’s action allowed the children in the experiment group to slow down and wait for the robot’s verbal response before scanning the next object. However, as the learning activity in this study did not involve learners proactive speaking to the robot, it is not clear to us if this learning support is capable of providing temporary contingency in a child-robot conversational interaction. We suggest future studies evaluate the potential of this kind of learning support in providing conversational buffers in learner-robot conversations to camouflage time delays in turn taking.

Also, our fourth learning support (LS4—Monitoring and re-engaging) proved to be effective. When the robot called out to the participants after detecting no action from them, the participants usually returned to their cubicles and refocused on the learning task, as the re-engaging strategy was activated through contextual relevant inputs. Figure 4 shows that only three disengagement cases occurred in the experiment group, much lower than the 14 occurrences in the control group.

Our fifth learning support (LS5) was providing a scaffolding for children to work out correct answers. In this study, providing hints after five attempts served as a contingent response to personalize targeted support for the learners to work out the correct answers. The data from the recorded sessions show that displaying hints on a tablet indeed helped the participants figure out the correct answers, as the participants could soon find the correct items and complete the task after following the hints in most cases. This finding supports what we discussed in the literature review. That is, contingent support helps learners to persist in the learning activity and avoid disengagement (Willemsen et  al., 2018; e Haas et  al., 2016; Haas et  al., 2017).

In addition to the five learning obstacles identified in the pilot study, two new learning obstacles (LO6, LO7) emerged during this experiment. The first one is that when the robot asked children to bring him a green apple, the child scanned a green pepper instead. This is because the toy bell pepper is similar the toy apple in shape and size, and that the child confused an apple with a bell pepper. We conclude that this is a content or proficiency dependent learning obstacle which no learning support offered by a learning system can effectively eradicate. What we can do is to help the learner to choose the right answer by using multiple channels of support to facilitate children’s understanding, e.g. showing a picture that contains a green apple (required item) and a green bell pepper (children’s answer) on the tablet to illustrate the required answer. This can be accompanied by verbal responses to tell the learner that this is not the item that the robot asks for. The second obstacle is that children used the devices for a wrong purpose, e.g. using a barcode scanner to scan an NFC tag. This learning obstacle occurred because the participants were not familiar with the functionality of the sensing devices. We suggest a practice/training session before the task begins, in which the learner learns how to handle the different devices and gets familiar with the interaction channels that the R&T system provides.

The effectiveness of these learning support mechanisms was further testified by the results regarding the number of cognitive and non-cognitive learning obstacles experienced by both groups. Figure 5 shows that the experiment group experienced a much lower number of learning obstacles in total than the control group. A closer look at each group’s statistics further revealed that the experiment group encountered fewer non-cognitive learning obstacles than cognitive learning obstacle and a reversed trend happened to the control group. This difference indicates that learning support played a crucial role in reducing non-cognitive learning obstacles. In turn, with fewer non-cognitive learning obstacles, the participants could learn better, as the experiment group would have more capacity handling the cognitive learning problems.

We recognize the limitations of this study. First, the small number of participants limits the generalization of our findings. Due to the constraints of the cost of R&T learning systems, this study was not able to recruit many participants to provide a large sample size. Second, as this study was exploratory in nature, only one game scenario was used as the context for the integration of the proposed learning support. Future research should explore the needs of learning support for different types of learning activities and contexts. Third, the duration of the experiment was short as there were only four sessions needed for the completion of the game. A longitudinal study involving more learners and learning contexts is needed to refine the proposed learning support and develop a more comprehensive set of learning support mechanisms covering different types of learning needs.

# 6.  Conclusion

With the increasing interest in robot-facilitated language learning, there has been an urgent need for developing learning support that can be seamlessly integrated into the learning environment to effectively facilitate learners’ task completion and enhance engagement. This is precisely where the current study has focused on.

This study has made several contributions to the development of learning support for vocabulary learning in a contextual learning environment supported by the robot and IoT-based toys. First, we identified key learning issues in such a learning environment. Second, informed by established learning theories and design principles for robot-supported learning, and based on empirical data from our pilot study, we designed learning support to help learners to tackle these issues, providing evidence-based insights into the design principles for effective learning support. Third, the evaluation of these learning support mechanisms reveals the positive impact of such learning support on game-based learning facilitated by a R&T system. These learning support mechanisms and their design principles proved to be able to facilitate the specific needs of contextual, authentic and situated vocabulary learning in the R&T system supported environment. They will also be a useful reference to other studies in RALL.

# Disclosure statement

No potential conflict of interest was reported by the author(s).

# Funding

This research is supported in part by the Ministry of Science and Technology, Taiwan, under project numbers MOST 111-2410-H-003 -028 -MY3, MOST-109-2511-H-003-053-MY3 & MOST-108-2511-H-003-061-MY3. This work was financially supported by the ‘Institute for Research Excellence in Learning Sciences’ of National Taiwan Normal University (NTNU) from The Featured Areas Research Center Program within the framework of the Higher Education Sprout Project by the Ministry of Education (MOE) in Taiwan.

# Notes on contributors

Ya-Wen Cheng is an assistant professor in the Department of Early Childhood Education, Asia University, Taiwan. She received her Ph.D in Information Management from National Sun Yat-Sen University (NSYSU), Taiwan in 2021. Her research interests include Gamification and System Design in Learning Technology and Educational Robot.

Yuping Wang is an associate professor in the School of Humanities, Languages, and Social Science, Griffith University, Australia. Her research focuses on pedagogy in blended learning and online learning, with a particular interest in flipped classrooms, synchronous interaction and technology enhanced collaborative learning.

Yu-Jie Cheng is a master student in the Department of Information Management, National Sun Yat-Sen University (NSYSU). His research interests include Gamification and System Design in Learning Technology and Educational Robot.

Dr. Nian-Shing Chen is Chair Professor in the Institute for Research Excellence in Learning Science and Program of Learning Science at the National Taiwan Normal University, Taiwan. His current research interests include assessing e-Learning course performance; online synchronous teaching & learning; mobile & ubiquitous learning; gesture-based learning and educational robotics.

# ORCID

Ya-Wen Cheng $\textcircled{1}$ http://orcid.org/0000-0003-3621-0862   
Nian-Shing Chen $\textcircled{1}$ http://orcid.org/0000-0001-7768-0997

# References

Andrä, C., Mathias, B., Schwager, A., Macedonia, M., & von Kriegstein, K. (2020). Learning foreign language vocabulary with gestures and pictures enhances vocabulary memory for several months post-learning in eight-year-old school children. Educational Psychology Review, 32(3), 815–850. https://doi.org/10.1007/s10648-020-09527-z   
Belpaeme, T., Kennedy, J., Ramachandran, A., Scassellati, B., & Tanaka, F. (2018). Social robots for education: A review. Science Robotics, 3(21), eaat5954. https://doi. org/10.1126/scirobotics.aat5954   
Belpaeme, T., Vogt, P., Van den Berghe, R., Bergmann, K., Göksun, T., De Haas, M., Oudgenoeg-Paz, O., …, Pandey, A. K. (2018). Guidelines for designing social robots as second language tutors. International Journal of Social Robotics, 10(3), 325–334. https://doi.org/10.1007/s12369-018-0467-6   
Bente, G., Rüggenberg, S., Krämer, N. C., & Eschenburg, F. (2008). Avatar-mediated networking: Increasing social presence and interpersonal trust in net-based collaborations. Human Communication Research, 34(2), 287–318. https://doi.org/10.1111/ j.1468-2958.2008.00322.x   
Bergmann, K., & Macedonia, M. (2013, August). A virtual agent as vocabulary trainer: Iconic gestures help to improve learners’ memory performance. In International Workshop on Intelligent Virtual Agents (pp. 139–148). Springer.

Berns, R. G., Erickson, P. M. (2001). Contextual Teaching and Learning: Preparing Students for the New Economy, The Highlight Zone: Research $@$ Work No. 5, 2001. Retrieved August 4, 2022, from https://files.eric.ed.gov/fulltext/ED452376.pdf

Bethel, C. L. (2009). Robots without Faces: Non-Verbal Social Human-Robot Interaction [Doctoral dissertation]. Available from ProfQuest Dissertations & Theses Global database. UMI No. 3420462   
Bornstein, M. H., Hahn, C. S., Haynes, O. M., & Tamis-LeMonda, C. S. (2022). Maternal responsiveness to young children at three ages: Longitudinal analysis of a multidimensional, modular, and specific parenting construct. Parenting: Selected writings of Marc H. Bornstein (pp. 157–173). Routledge.   
Caldwell‐Harris, C. L. (2021). Frequency effects in reading are powerful—But is contextual diversity the more important variable? Language and Linguistics Compass, 15(12), e12444. https://doi.org/10.1111/lnc3.12444   
Chen, C. M., & Li, Y. L. (2010). Personalized context-aware ubiquitous learning system for supporting effective English vocabulary learning. Interactive Learning Environments, 18(4), 341–364. https://doi.org/10.1080/10494820802602329   
Chen, H. R., & Lin, Y. S. (2016). An examination of digital game-based situated learning applied to Chinese language poetry education. Technology, Pedagogy and Education, 25(2), 171–186. https://doi.org/10.1080/1475939X.2015.1007077   
Chen, Z.-H., Chen, H. H.-J., & Dai, W.-J. (2018). Using narrative-based contextual games to enhance language learning: A case study. Journal of Educational Technology & Society, 21(3), 186–198.   
Chen, Y. C., Gamborino, E., Fu, L. C., Yueh, H. P., & Yeh, S. L. (2021). Social presence in evaluations for a humanoid robot and its effect on children-robot relationship. In International Conference on Human-Computer Interaction (pp. 191–199). Springer.   
Cheng, Y.-W., Wang, Y., Yang, Y.-F., Yang, Z.-K., & Chen, N.-S. (2020). Designing an authoring system of robots and IoT-based toys for EFL teaching and learning. Computer Assisted Language Learning, 34(1–2), 6–34. https://doi.org/10.1080/095882 21.2020.1799823   
Chiang, Y-H. V., Zheng, Y.-J., Cheng, Y.-W., Chen, N.-S. (2020). Analyzing learners’ English learning process involving educational robots and IoTbased toys through the lens of zone of proximal development. In 2020 IEEE 20th International Conference on Advanced Learning Technologies (ICALT) (pp. 213–215). IEEE. https://doi. org/10.1109/ICALT49669.2020.00069   
Dargue, N., Sweller, N., & Jones, M. P. (2019). When our hands help us understand: A meta-analysis into the effects of gesture on comprehension. Psychological Bulletin, 145(8), 765. https://doi.org/10.1037/bul0000202   
Davis, R. O. (2018). The impact of pedagogical agent gesturing in multimedia learning environments: A meta-analysis. Educational Research Review, 24, 193–209. https:// doi.org/10.1016/j.edurev.2018.05.002   
de Wit, J., Schodde, T., Willemsen, B., Bergmann, K., de Haas, M., Kopp, S., & Vogt, P. (2018). The effect of a robot’s gestures and adaptive tutoring on children’s acquisition of second language vocabularies. In Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction (pp. 50–58). ACM.   
Demir-Lira, Ö. E., Kanero, J., Oranç, C., Koşkulu, S., Franko, I., Göksun, T., & Küntay, A. C. (2020, December). L2 vocabulary teaching by social robots: The role of gestures and on-screen cues as scaffolds. Frontiers in Education, 5, 599636. https://doi. org/10.3389/feduc.2020.599636   
Dewi, P. Y. A., & Primayana, K. H. (2019). Effect of learning module with setting contextual teaching and learning to increase the understanding of concepts. International Journal of Education and Learning, 1(1), 19–26. https://doi.org/10.31763/ ijele.v1i1.26   
Donaldson, T., Fore, G. A., Filippelli, G. M., & Hess, J. L. (2020). A systematic review of the literature on situated learning in the geosciences: Beyond the classroom. International Journal of Science Education, 42(5), 722–743. https://doi.org/10.1080/0 9500693.2020.1727060   
Doughty, C., & Williams, J. (Eds.) (1998). Focus on form in classroom second language acquisition. Cambridge University Press.   
e Haas, M., Vogt, P., Krahmer, E. (2016). Enhancing child–robot tutoring interactions with appropriate feedback. In Proceedings of the Long-Term Child–Robot Interaction Workshop at RO-MAN.   
Eun, B., & Lim, H. S. (2009). A sociocultural view of language learning: The importance of meaning-based instruction. TESL Canada Journal, 27(1), 12–26. https://doi. org/10.18806/tesl.v27i1.1031   
Franciosi, S. J. (2017). The Effect of computer game-based learning on FL vocabulary transferability. Educational Technology & Society, 20(1), 123–133.   
Fringi, E., Lehman, J., Russell, M. J. (2015). Evidence of phonological processes in automatic recognition of children’s speech. In 16th Annual Conference of the International Speech Communication Association (Dresden, Germany) (1621–1624).   
Fu, Q. K., Lin, C. J., Hwang, G. J., & Zhang, L. (2019). Impacts of a mind mapping-based contextual gaming approach on EFL students’ writing performance, learning perceptions and generative uses in an English course. Computers & Education, 137, 59–77. https://doi.org/10.1016/j.compedu.2019.04.005   
Godwin-Jones, R. (2018). Contextualized vocabulary learning. Language Learning &Technology, 22(3), 1–19.   
Gunawardena, C. N., & Zittle, F. J. (1997). Social presence as a predictor of satisfaction within a computer‐mediated conferencing environment. American Journal of Distance Education, 11(3), 8–26. https://doi.org/10.1080/08923649709526970   
Haas, M. D., Baxter, P., de Jong, C., Krahmer, E., Vogt, P. (2017). Exploring different types of feedback in preschooler and robot interaction. In Proceedings of the Companion of the 2017 ACM/IEEE International Conference on Human-Robot Interaction (pp. 127–128).   
Hassanein, K., & Head, M. (2007). Manipulating perceived social presence through the web interface and its impact on attitude towards online shopping. International Journal of Human-Computer Studies, 65(8), 689–708. https://doi.org/10.1016/j.ijhcs.2006.11.018   
Huang, C.-M., & Mutlu, B. (2013). Modeling and evaluating narrative gestures for humanlike robots. In Proceedings of Robotics: Science and Systems Conference, RSS13. (pp. 57–64).   
Hwang, G. J., & Wang, S. Y. (2016). Single loop or double loop learning: English vocabulary learning performance and behavior of students in situated computer games with different guiding strategies. Computers & Education, 102, 188–201. https://doi. org/10.1016/j.compedu.2016.07.005   
Hwang, W.-Y., Shih, T. K., Ma, Z.-H., Shadiev, R., & Chen, S.-Y. (2016). Evaluating listening and speaking skills in a mobile game-based learning environment with situational contexts. Computer Assisted Language Learning, 29(4), 639–657. https:// doi.org/10.1080/09588221.2015.1016438   
Iacovides, I., Cox, A. L., McAndrew, P., Aczel, J., & Scanlon, E. (2015). Game-play breakdowns and breakthroughs: Exploring the relationship between action, understanding, and involvement. Human–Computer Interaction, 30(3-4), 202–231. https:// doi.org/10.1080/07370024.2014.987347   
Johnson-Glenberg, M. C. (2018). Immersive VR and education: Embodied design principles that include gesture and hand controls. Frontiers in Robotics and AI, 5, 81. https://doi.org/10.3389/frobt.2018.00081   
Kennedy, J., Lemaignan, S., Montassier, C., Lavalade, P., Irfan, B., Papadopoulos, F., … Belpaeme, T. (2017). Child speech recognition in human-robot interaction: Evaluations and recommendations. In Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction (pp. 82–90).   
Kilteni, K., Groten, R., & Slater, M. (2012). The sense of embodiment in virtual reality. Presence: Teleoperators and Virtual Environments, 21(4), 373–387. https://doi. org/10.1162/PRES_a_00124   
Kim, Y., & Smith, D. (2017). Pedagogical and technological augmentation of mobile learning for young children interactive learning environments. Interactive Learning Environments, 25(1), 4–16. https://doi.org/10.1080/10494820.2015.1087411   
Kim, J., Xu, K., & Kelly, S. (2022). Perceived credibility of an AI instructor in online education: The role of social presence and voice features. Computers in Human Behavior, 136, 107383. https://doi.org/10.1016/j.chb.2022.107383   
Koelsch, L., Elisei, F., Ferrand, L., Chausse, P., Bailly, G., & Huguet, P. (2021). Impact of social presence of humanoid robots: Does competence matter? In International Conference on Social Robotics. (pp. 729–739). Springer.   
Kosmas, P., Ioannou, A., & Zaphiris, P. (2019). Implementing embodied learning in the classroom: Effects on children’s memory and language skills. Educational Media International, 56(1), 59–74. https://doi.org/10.1080/09523987.2018.1547948   
Kory-Westlund, J. M., & Breazeal, C. (2019). A long-term study of young children’s rapport, social emulation, and language learning with a peer-like robot playmate in preschool. Frontiers in Robotics and AI, 6, 81. https://doi.org/10.3389/frobt.2019.00081   
Kramsch, C., & Thorne, S. L. (2002). Foreign language learning as global communicative practice. In D. Cameron & D. Block (Eds.), Globalization and language teaching (pp. 93–110). Routledge.   
Lan, Y.-J. (2015). Contextual EFL learning in a 3D virtual environment. Language Learning & Technology, 19(2), 16–31.   
Lan, Y.-J., Botha, A., Shang, J., & Jong, M. S.-Y. (2018). Guest Editorial: Technology enhanced contextual game-based language learning. Journal of Educational Technology & Society, 21(3), 86–89.   
Lan, Y. J., Hsiao, I. Y., & Shih, M. F. (2018). Effective learning design of game-based 3D virtual language learning environments for special education students. Journal of Educational Technology & Society, 21(3), 213–227.   
Lankard, B. (1995). New ways of learning in the workplace. ERIC Clearinghouse on Adult, Career and Vocational Education, 161, 1–8.   
Laufer, B. (2005). Focus on form in second language vocabulary learning. Eurosla Yearbook, 5(1), 223–250. https://doi.org/10.1075/eurosla.5.11lau   
Lee, J. W., & Yoon, K. O. (2019). Alternative vocabulary learning approaches in EFL setting: Bottom-up or top-down? English Teaching, 74(3), 141–160. https://doi. org/10.15858/engtea.74.3.201909.141   
Lewis, T. N., & Kirkhart, M. (2020). Effect of iconic gestures on second language vocabulary retention in a naturalistic setting. International Review of Applied Linguistics in Language Teaching, 58(3), 263–287. https://doi.org/10.1515/iral-2016-0125   
Lin, C.-J., Hwang, G.-J., Fu, Q.-K., & Chen, J.-F. (2018). A flipped contextual game-based learning approach to enhancing EFL students’ English business writing performance and reflective behaviors. Journal of Educational Technology & Society, 21(3), 117–131.   
Lin, J. J., & Lin, H. (2019). Mobile-assisted ESL/EFL vocabulary learning: A systematic review and meta-analysis. Computer Assisted Language Learning, 32(8), 878–919. https://doi.org/10.1080/09588221.2018.1541359   
Masek, L. R., McMillan, B. T., Paterson, S. J., Tamis-LeMonda, C. S., Golinkoff, R. M., & Hirsh-Pasek, K. (2021). Where language meets attention: How contingent interactions promote learning. Developmental Review, 60, 100961. https://doi.org/10.1016/j. dr.2021.100961   
McNeill, D. (1992). Hand and mind: What gestures reveal about thought. University of Chicago Press.   
McNiff, J. (2017). Action research: All you need to know. Sage.   
Nation, I. S. P. (2001). Learning vocabulary in another language. Cambridge University Press.   
Ortega, L. (2017). New CALL–SLA research interfaces for the 21st century: Towards equitable multilingualism. CALICO Journal, 34(3), 285–316. https://doi.org/10.1558/ cj.33855   
Piaget, J. (1971). Psychology and epistemology: Towards a theory of knowledge (A. Rosin, Trans.). Grossman.   
Prince, P. (1996). Second language vocabulary learning: The role of context versus translations as a function of proficiency. The Modern Language Journal, 80(4), 478– 493. https://doi.org/10.1111/j.1540-4781.1996.tb05468.x   
Peter, R., & Hilary, B. (Eds.). (2001). Handbook of action research: Participative inquiry and practice. Sage.   
Renkl, A. (2001). Situated learning, out of school and in the classroom. In P. B. Baltes & N. J. Smelser (Eds.), International Encyclopedia of the Social & Behavioral Sciences (Vol. 21, pp. 14133–14137). Pergamon.   
Rowe, M. L., & Weisleder, A. (2020). Language development in context. Annual Review of Developmental Psychology, 2, 201–223. https://doi.org/10.1146/ annurev-devpsych-042220-121816   
Schmitt, N. (2008). Instructed second language vocabulary learning. Language Teaching Research, 12(3), 329–363. https://doi.org/10.1177/1362168808089921   
Schouten-van Parreren, C. (1989). Vocabulary learning through reading: Which conditions should be met when presenting words in texts. In P. Nation & Carter, R. (Eds.), Vocabulary Acquisition. Free University Press.   
Semeraro, C., Giofrè, D., Coppola, G., Lucangeli, D., & Cassibba, R. (2020). The role of cognitive and non-cognitive factors in mathematics achievement: The importance of the quality of the student-teacher relationship in middle school. PLoS One. 15(4), e0231381. https://doi.org/10.1371/journal.pone.0231381   
Serholt, S. (2018). Breakdowns in children’s interactions with a robotic tutor: A longitudinal study. Computers in Human Behavior, 81, 250–264. https://doi.org/10.1016/j. chb.2017.12.030   
Shapiro, L., & Stolz, S. A. (2019). Embodied cognition and its significance for education. Theory and Research in Education, 17(1), 19–39. https://doi.org/10.1177/1477878518822149   
Shin, D. H., & Choo, H. (2011). Modeling the acceptance of socially interactive robotics: Social presence in human–robot interaction. Interaction Studies, 12(3), 430–460. https://doi.org/10.1075/is.12.3.04shi   
Short, J., Williams, E., & Christie, B. (1976). The social psychology of telecommunications. Wiley.   
Skulmowski, A., & Rey, G. D. (2018). Embodied learning: Introducing a taxonomy based on bodily engagement and task integration. Cognitive Research: Principles and Implications, 3(1), 1–10.   
Stein, D. (1998). Situated learning in adult education. https://www.ericdi-gests.org/1998-3/ adult-education.html   
Sullivan, J. V. (2018). Learning and embodied cognition: A review and proposal. Psycholo g y L ear ning & Teaching, 1 7 (2 ), 128 –143. https:// doi. org/10.1177/1475725717752550   
Surmanov, S., & Azimova, M. (2020). Analysis of difficulties in vocabulary acquisition. The Journal of Legal Studies, 6(1), 144–153.   
Svennevig, J. (2018). “What’s it called in Norwegian?” Acquiring L2 vocabulary items in the workplace. Journal of Pragmatics, 126, 68–77. https://doi.org/10.1016/j.pragma.2017.10.017   
Szafir, D., Mutlu, B. (2012, May). Pay attention! Designing adaptive agents that monitor and improve user engagement. In Proceedings of the ACM Annual Conference on Human Factors in Computing Systems (CHI). (pp. 11–20). Austin, TX.   
Tanaka, F., & Matsuzoe, S. (2012). Children teach a care-receiving robot to promote their learning: Field experiments in a classroom for vocabulary learning. Journal of Human-Robot Interaction, 1, 78–95.   
van den Berghe, R., Verhagen, J., Oudgenoeg-Paz, O., Van der Ven, S., & Leseman, P. (2019). Social robots for language learning: A review. Review of Educational Research, 89(2), 259–295. https://doi.org/10.3102/0034654318821286   
Van den Branden, K. (Ed.). (2006). Task-based language education: From theory to practice. Cambridge University Press.   
Vogt, P., De Haas, M., De Jong, C., Baxter, P., & Krahmer, E. (2017). Child-robot interactions for second language tutoring to preschool children. Frontiers in Human Neuroscience, 11, 73. https://doi.org/10.3389/fnhum.2017.00073   
Vygotsky, L. (1930). Mind and society. Harvard University Press.   
Vygotsky, L. S. (1980). Mind in society: The development of higher psychological processes. Harvard university press.   
Wellsby, M., & Pexman, P. M. (2014). Developing embodied cognition: Insights from children’s concepts and language processing. Frontiers in Psychology, 5, 506.   
Willemsen, B., de Wit, J., Krahmer, E., de Haas, M., Vogt, P. (2018). Context-sensitive Natural Language Generation for robot-assisted second language tutoring. In Proceedings of the Workshop on NLG for Human–Robot Interaction (pp. 1–7).   
Wood, D., Bruner, J. S., & Ross, G. (1976). The role of tutoring in problem solving. Journal of Child Psychology and Psychiatry, 17(2), 89–100. https://doi. org/10.1111/j.1469-7610.1976.tb00381.x   
Wood, D., & Wood, H. (1996). Vygotsky, tutoring and learning. Oxford Review of Education, 22(1), 5–16. https://doi.org/10.1080/0305498960220101   
Yan, C., Peng, W., Lee, K. M., Jin, S. A. (2004). Can robots have personality? An empirical study of personality manifestation, social responses, and social presence in human-robot interaction. In Proceedings of the Annual Meeting of the International Communication Association. Hingham, MA.

# Appendix A:  The R &T learning system

This is a learning system we designed to integrate Robot and Tangible IoT-based Objects to provide a contextual language learning environment. As shown in Figure A1, the R&T learning system consists of a robot, a tablet and toys with IoT sensors and sensing devices. The R&T learning system is supported by an authoring tool with graphical programming interface, allowing non-technical professionals to create and specify interactions between the robot, IoT sensors and children (Cheng et  al., 2020). In this study, the robot was framed as a learning companion, playing games with children using English as a second language. A toy set is employed to create join attention between robot and children; while the tablet is to support the robot in delivering visual information, e.g. pictures and videos.

![](img/5504cee5d3386558a487dbafee0b548f843418b431b6c83f0f78ee69f3433b1e.jpg)  
Figure A1. R &T learning system.

The R&T system can work with various objects, e.g. playhouse toy sets, real story books and board game cards. In this study, a playhouse toy set was selected to simulate a supermarket scenario for children to learn vocabularies regarding food items, colors and shapes, which are closely related to their daily life experiences. The R&T system allows children to interact with the robot through multiple channels. Children can interact with the robot either by touching the sensors on robots’ belly, head and hands, talking to the robot, or showing a picture or a QR code to the robot. Children can also interact with the robot through the sensing devices embedded on the toy set, e.g. scanning barcodes using a barcode scanner or placing an object that has a near field communication (NFC) tag on an NFC reader.

# Appendix B:  Target vocabularies

Food items: carrot, egg, apple, orange, grapes, bell pepper, corn, milk bottle, apple juice, chocolate, cookie box, candy, cereal.   
Stationaries: ruler, pencil, marker, eraser.   
Clothes: jacket, pants, shirts.   
Colors: black, white, red, green, orange, yellow, purple, gray, blue   
Other vocabularies used in the game: police officer, eyewitness, scale, belly, thief, fingerprints, steal, scan, touch, hungry.

# Appendix C:  Example of pre-test questions

Please listen to the audio clip and answer the question by selecting a correct answer.

Audio1: Question 1, which one is a pineapple?. Audio 2: Question 2, what does it mean to put an egg on a scale?

![](img/6229b8593f2805326703d21c3624183295d8f0443ba19c7576990b19b5f6361b.jpg)

2. Answer

![](img/cd0c3047dd98a313190c0e6f893d058057ef1f7e0a346d19998f7275592e6b04.jpg)

# Appendix D:  The experiment site and setting

Figure D1 presents the experiment sites and settings. The children assigned to the same group were in the same room, but each sitting in different cubicles, as shown in Figure D1a. An R&T learning system was placed in each cubicle, consisting of a robot, a tablet and a set of IoT toys as shown in Figure D1b.

![](img/1e2a3f77e49bd2f6679f714d11c33a3dfdc1f0d247df69123b51f386c67d18d0.jpg)  
Figure D1. T he experiment sites and setting.

# Appendix E:  An example of embedding learning support in the completion of a learning task

![](img/2bc0aef16f4d1cf186f138411bd56662657187ae73932e1b003d51732b255ed3.jpg)  
Figure E1. An example of embedding learning support in the completion of a learning task.

# Appendix F:  Boxplot of both groups’ pre-test and post-test

![](img/9b114e1045e39454bf1e82313b2e06994037f26d10b0d84a5590cdd9ce584484.jpg)  
Figure F1. Boxplot of both groups’ pre-test and post-test.