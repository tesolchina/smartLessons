# Critical analysis of the technological affordances, challenges and future directions of Generative AI in education: a systematic review

Nan Wang, Xiao Wang & Yu-Sheng Su

To cite this article: Nan Wang, Xiao Wang & Yu-Sheng Su (2024) Critical analysis of the technological affordances, challenges and future directions of Generative AI in education: a systematic review, Asia Pacific Journal of Education, 44:1, 139-155, DOI: 10.1080/02188791.2024.2305156

To link to this article: https://doi.org/10.1080/02188791.2024.2305156

# Critical analysis of the technological affordances, challenges and future directions of Generative AI in education: a systematic review

Nan Wanga , Xiao Wanga and Yu-Sheng $\mathsf { S u } ^ { \mathsf { b } , \mathsf { c } }$

a School of Education Science, Nanjing Normal University, Nanjing, China; b Department of Computer Science and Information Engineering, National Chung Cheng University, Chiayi, Taiwan; c Department of Computer Science and Information Engineering, National Taiwan Ocean University, Keelung, Taiwan

# ABSTRACT

Generative artificial intelligence has been regarded as a transformative tool. While responsible and ethical applications could bring opportunities to education, their misuse could pose demanding challenges. It is necessary to clarify the technological affordances and challenges in a normative way to lay the foundation for future development. This study addressed the dearth of literature by performing a systematic review, aiming to (i) explore the utility and availability from the technological affordances perspective; (ii) summarize the current challenges in risks prevention; and (iii) propose possible directions for future research and practice. A total of 27 academic articles published in core journals between 2020 and 2023 were analyzed, and the inductive grounded approach was used to categorize the coding schemes. The findings revealed four technological affordances: accessibility, personalization, automation, and interactivity; and five challenges: academic integrity risk, response errors and bias, over-dependence risk, the widening digital divide, and privacy and security. We propose future directions, encourage educational organizations to formulate guidelines for the ethical use of AI in education, call on educators to embrace future trends in AI education instead of shunning its use, and guide students to treat it as a thought aid and reference, rather than relying on it entirely.

ARTICLE HISTORY Received 6 August 2023 Accepted 2 January 2024

# KEYWORDS

Generative AI; education; systematic literature review; technological affordance; challenges

# Introduction

The launch of ChatGPT sparked dramatic global attention to the application of generative artificial intelligence (Generative AI) (Kasneci et al., 2023; Peres et al., 2023; Y. Su et al., 2023). In the increasingly digital society, this has ignited our hope for Generative AI’s role in assisting education, while also awakening our concerns about its uncertain impact on educators and learners. Based on deep learning models, Generative AI can generate human-like content (e.g., code, words, images, 3D objects, and videos) in response to diverse prompts, which has stimulated considerable debate in the fields of academic research, art and design education (G.-J. Hwang & Chen, 2023; Lim et al., 2023). Optimists highlight the fact that Generative AI demonstrates a powerful ability to engage in intelligent dialogue in educational contexts (Kortemeyer, 2023; Stojanov, 2023). This is because Generative AI can process large amounts of data, automating tedious and repetitive tasks (Lund et al., 2023) such as assisting educators and learners with curriculum planning, paper editing, and data analysis (Cooper, 2023; Li et al., 2023). Generative AI can also generate personalized recommendations by analysing users’ needs and preferences (Cotton et al., 2023; Luo et al., 2023). In contrast, pessimists tend to emphasize its controversies and challenges (Barrot, 2023; Dwivedi et al., 2023). For example, some of the concerns are plagiarism and academic misconduct (Cotton et al., 2023), the proliferation of biased and false responses (Farrokhnia et al., 2023), and access gaps leading to further widening of the digital divide (Jeon & Lee, 2023). Kasneci et al. (2023) were also concerned that some students may become over-dependent on Generative AI, thus depriving them of opportunities to develop their high-order cognitive skills. The opportunities and challenges of Generative AI in education are still being debated and explored, so further research and practice are needed (Gašević et al., 2023; Yan, 2023).

Previous researchers have used short reviews or commentaries to demonstrate the potential of Generative AI in academic development and future education (G.-J. Hwang & Chen, 2023; Lim et al., 2023), but have rarely discussed the issue from the perspective of technological affordances (Huang et al., 2021). To leverage the full potential of Generative AI technology in education, the challenges are still generally under-researched; thus, a comprehensive overview is needed to establish a theoretical basis for research and practice (Dwivedi et al., 2023; Farrokhnia et al., 2023). Therefore, this study critically evaluated the technological affordances and challenges of Generative AI in education to accommodate the excitement and concerns about this new AI technology in a balanced way. The study utilized a systematic literature review method to analyse the existing literature. Overall, based on the literature review findings, this paper provides the following details: (i) going beyond merely reporting the roles of Generative AI in education, the utility and availability are analysed from the perspective of technological affordances (Kirschner et al., 2004); then (ii) the current challenges are discussed, and possible solutions to address them are provided; and (iii) the future directions of research and practices that can advance our understanding of Generative AI in education are explored, and recommendations for stakeholders (e.g., policymakers, educators and learners) regarding how to effectively use Generative AI to enhance education and learning experiences are provided.

# Literature review

# The technological affordances of Generative AI in education

Built on foundational models (e.g., large language models), Generative AI operates by learning from enormous datasets (e.g., articles, books), and predicts subsequent possible outputs (Lodge et al., 2023). Given the abundance of digitized resources, Generative AI can quickly learn a myriad of areas and respond immediately to user queries (UNESCO, 2023). Whether analysing massive amounts of data, designing software applications, or writing a cover letter for a job application, Generative AI users can harness the power of LLMs to produce a specific output (Dwivedi et al., 2023; Johri et al., 2023). For example, two months after launching in November 2022, ChatGPT reached 100 million users, setting a record as the fastest-growing consumer app (Lim et al., 2023). It can be integrated into websites and mobile applications to facilitate users’ access to information (Jeon & Lee, 2023; Kohnke et al., 2023). The popularity of ChatGPT stems from its ease of use, the potential for integration with diverse platforms and devices, and its capacity to generate structured text (Guo et al., 2022). Similarly, Google took prompt action by rolling out Bard, a Generative AI based on cutting-edge conversational capabilities (Dalalah & Dalalah, 2023). ChatGPT and Bard are text-based Generative AI, which can conduct thematic conversations with users or generate various types of text. Meanwhile, there are distinct Generative AI tools for different types of content creation. In the field of image generation, DALL-E, Midjourney and Stable Diffusion can draw images and artworks from a description in natural language; these applications therefore offer the potential for design education and enable students to focus on creative thinking (G.-J. Hwang & Chen, 2023). In the field of audio generation, Eleven Labs can render human intonation with unprecedented fidelity, and generate spoken audio using any style (Peres et al., 2023). Moreover, Generative AI is constantly iterating functions, enabling a higher degree of integration when working with different types of data. For example, Microsoft Copilot with Bing Chat, which originally supported text conversations, now integrates with Bing Image Creator, an AI-generated image tool powered by OpenAI’s image generator DALL-E model, to create high-quality images and artwork based on prompts (Microsoft Corporation, 2023). Therefore, the emergence of Generative AI is gradually reshaping the manner in which we work, learn and interact, thus requiring us to take action to be prepared for the future (G.-J. Hwang & Chen, 2023).

Technological affordance refers to the technology’s inherent design characteristics that facilitate users’ achievement of their intended objectives with ease (Kirschner et al., 2004). In educational research and practice, the emergence of Generative AI represents a substantial leap forward, opening up far-reaching opportunities (J. Su & Yang, 2022; Victor et al., 2023). Pavlik (2023) indicated that ChatGPT has been freely accessible to users since its launch, providing timely help around-the-clock. On the one hand, Generative AI provides learners with personalized learning pathways based on their unique learning preferences and requirements (Cotton et al., 2023). For young children, the interactive nature of Generative AI allows it to serve as a conversation practice partner, providing language learning support (Luo et al., 2023). Generative AI benefits middle school students by tailoring quizzes and worksheets (Yan, 2023). For college students, Generative AI can assist with writing tasks and research work (Li et al., 2023). These models can collect thematically specific information to generate summaries and text outlines (Barrot, 2023). On the other hand, Generative AI can automatically repeat time-consuming work, which has great prospects for promoting educational evaluation and transforming teaching methods (Peres et al., 2023; Stojanov, 2023). In terms of curriculum planning, Generative AI can assist in creating teaching materials, such as course designs, presentations, and exercises, thereby improving the efficiency of the teaching process (Cotton et al., 2023). In terms of assessment, Generative AI can automatically assess students’ work, which can alleviate teachers’ burdens (Zawacki-Richter et al., 2019). In terms of professional development, Generative AI can provide teachers with teaching resources and detailed explanations of teaching materials (Jeon & Lee, 2023). This can help teachers master key concepts and skills, and keep up with the latest educational ideas and technologies (Farrokhnia et al., 2023). Thus, previous studies have explored the roles of Generative AI in education (G.-J. Hwang & Chen, 2023; Lim et al., 2023). It is necessary to further clarify the technological affordances in a normative way and to make a concluding statement to enhance the learning experience for users of different ages and backgrounds (Huang et al., 2021).

# The current challenges for Generative AI in education

The application of new technology is often accompanied by diverse issues (Kasneci et al., 2023). As Generative AI is gradually becoming mainstream, it is important to reflect on its application risks (Lodge et al., 2023; Victor et al., 2023). Recent research has reported on its ethical and social challenges in the educational context (Farrokhnia et al., 2023; G.-J. Hwang & Chen, 2023). Data bias and technology abuse are some of these concerns. If there are potential biases in the model’s training data, the response may contain fabricated, factually incorrect, or absurd information (Dalalah & Dalalah, 2023). Furthermore, some educational institutions have expressed their concerns about academic integrity (Ahsan et al., 2022; Cotton et al., 2023). Using text-based Generative AI (e.g., ChatGPT, Bard) to compose papers and written content, and then presenting it as one’s own work violates basic academic honesty principles (Howell & Potgieter, 2023). Dwivedi et al. (2023) indicated that over-reliance on Generative AI may stifle higher cognitive skills. Due to concerns about technology abuse, some governments have banned the use of Generative AI tools (ABC News, 2023; Dibble, 2023). Similar trends have been noted in academic publishing (Lund et al., 2023). In fact, a few researchers believe that if ChatGPT is involved in designing, editing or writing academic papers or publications, then it should be recognized as an author (Dalalah & Dalalah, 2023). Another area of concern is accessibility and the digital divide (Farrokhnia et al., 2023). Although many applications were free to users in the early days, they are increasingly being put behind a paywall, and many uses are now only available for paid subscribers (Johri et al., 2023). Not all learners have equal access to advanced AI technologies, which will exacerbate the inequalities in existing education (Lim et al., 2023). In addition, the possible leakage of sensitive information in the process of data collection has also caused widespread concern (Dwivedi et al., 2023; Lund et al., 2023). Farrokhnia et al. (2023) used the SWOT analysis framework to outline ChatGPT’s weaknesses in education, including a lack of deep understanding and higher-order thinking skills, difficulty in evaluating the quality of responses, and a risk of bias and discrimination, but we speculate that what we saw on ChatGPT may be just the tip of the iceberg. Therefore, there is a need for a systematic review of the current challenges facing Generative AI in education to help alert people to and prevent the associated risks.

# Potential research and practice directions of Generative AI in education

Many scholars have emphasized the importance of ethical considerations, and have suggested that educational institutions update relevant policies and guidelines (Cotton et al., 2023; Gašević et al., 2023). Athabasca University (2020) has formulated and implemented a set of ethical guidelines to guide the application of AI, promoting learning agents, assessment accuracy and transparency. Relatedly, given that Generative AI is trained on specific data (Jeon & Lee, 2023), it is critical to evaluate errors in the model’s output to increase the transparency of biases (e.g., sexism, ageism, and racism) (Peres et al., 2023). Lim et al. (2023) indicated the importance of distributed accountability. That is to say, software developers, educational organizations, teachers, and students should share the responsibility of optimizing the opportunities presented by Generative AI, and effectively address associated challenges. In addition, more research and practice are required to explore the practicability of Generative AI-based learning from multiple perspectives (G.-J. Hwang & Chen, 2023; Luo et al., 2023). In addition to comparing the differences between students who learn based on Generative AI and those who learn using traditional methods, it is worthwhile to discuss whether Generative AI’s application could enhance learners’ performance and creative thinking (Farrokhnia et al., 2023). Therefore, more future research and practice are needed to help make better use of Generative AI technology to improve education (Farrokhnia et al., 2023; Yan, 2023).

# The research questions

This review focuses on the roles of Generative AI in education, aiming to discover the technological affordances and challenges. Then, the future research and practice direction of Generative AI in educational contexts is further discussed, which makes the description and analysis more extensive and comprehensive. The following three questions were proposed:

Research question 1 (RQ1): What are the technological affordances of using Generative AI in education?

Research question 2 (RQ2): What are the current challenges of using Generative AI in education?

Research question 3 (RQ3): What are the future directions of research and practice on the use of Generative AI in education?

# Method

# Literature search process

In view of the release of GPT-3 in 2020, and the launch of the large-scale language model GPT-4 by OpenAI in March 2023 (Dwivedi et al., 2023), which has attracted extensive attention from the academic community, the literature screening time was set between 2020 and 2023. A systematic search was performed in June 2023 in three major academic databases: Web of Science, Scopus, and Science Direct. Additionally, the reference lists of included studies were manually searched, and all records were stored in EndNote. Based on discussions in the research team, the following search terms for the literature search were defined: (Generative AI OR generative artificial intelligence OR ChatGPT) AND (teach\* OR educat\*). Peer-reviewed journal papers were reviewed first, guaranteeing the quality of the included literature (Korpershoek et al., 2016).

# Inclusion and exclusion process

A total of 173 articles were first identified. After removing duplicates, the remaining 161 articles were screened according to the inclusion and exclusion criteria (see Table 1): records had to be published in core journals and be written in the English language, published between 2020 and 2023, include analyses of the technological affordances and challenges of Generative AI, and focus on the education field. Subsequently, the titles and abstracts of all the records were rigorously reviewed, which led to 51 records being reviewed in full text. After reading the full-text papers, 17 articles were identified for this review. A forward and backward reference search was conducted for these articles to identify relevant records. Finally, 10 additional records were added, resulting in a total of 27 eligible papers. The detailed search and review process can be viewed in the PRISMA diagram (Moher et al., 2015) (see Figure 1).

# Data coding and analysis

To guide the interpretation of our analyses, the relevant information on the Generative AI implementations in the 27 records is reported, such as the geographic distribution of studies, the educational sector, the methods being used, and the roles of Generative AI in education. Table 2 displays that of the 27 included studies, affiliations of authors or organizations were spread across four continents, but were predominantly from Asia $( 4 4 \% )$ . The application was mainly concentrated in higher education $( n = 9 , 3 3 \% )$ . The most commonly used method was literature study $( n = 9 , 3 3 \% )$ , followed by quantitative survey $( n = 7 , 2 6 \% )$ ). By referring to the AIED (Using AI in education) model (G. Hwang et al., 2020), we categorized four roles of Generative AI in education, namely intelligent tutor, intelligent tutee, intelligent learning tool/partner, and domain expert (see Figure 2). First, Generative AI has the potential to summarize and demonstrate text content or artwork creation like an experienced tutor. An example is ChatGPT which combines the traits of intelligent assessment with tutoring to offer feedback to learners and provide data-driven reports for educators (Farrokhnia et al., 2023). Second, Generative AI can acquire experience and knowledge from interaction with humans, then encourage learners to serve as an advisor or tutor. For instance, if not satisfied with the images drawn by Midjourney, students can rate the pictures and provide detailed descriptions (G.-J. Hwang & Chen, 2023). When students assume the tutor role and interact with the Generative AIbased tutee, they can perceive things from a tutor’s perspective, thus enhancing curiosity or question-asking skills. Third, Generative AI can be a collaborative teammate or powerful tool in learning activities. For example, ChatGPT can help students quickly organize thoughts for writing (Li et al., 2023). Using Stable Diffusion to create artwork allows learners to focus on creative thinking instead of spending time drawing details (Peres et al., 2023). Fourth, by assigning the role of domain expert, it can hold discussions with users on specific issues and provide valuable advice. Channel is an example of Generative AI that analyzes human-provided prompts and offers visualizations to respond (Peres et al., 2023). Policymakers could comprehensively recognize the dilemmas and trends in the educational field, so as to formulate effective policies. Overall, using Generative AI in education has provided opportunities for developing better technology-enhanced educational environments and applications.

Table 1. Inclusion and exclusion criteria.   

<html><body><table><tr><td> Inclusion</td><td>Exclusion</td></tr><tr><td>Records published in English.</td><td>Records published in any other languages.</td></tr><tr><td>Records published between 2020 and 2023.</td><td>Records published before 2020.</td></tr><tr><td>Records published in core journals (SSCI).</td><td>Records that are not published in core journals (SSCI)..</td></tr><tr><td>Records focusing on education fields.</td><td>Records focusing on fields other than education.</td></tr><tr><td>Records that include analysis of the technological affordances and challenges of Generative Al.</td><td>Records that do not include analysis of the technological. affordances and challenges of Generative Al.</td></tr><tr><td>Records that include details about the use of Generative Al, rather than the algorithm development process..</td><td>Records exclusively focused on the algorithm development. process.</td></tr></table></body></html>

![](img/6eaac91a7986425834434bf08bb5ff9a1c6d13d3bf6610d3df5225570fb896fa.jpg)  
Figure 1. PRISMA diagram.

Table 2. The relevant information of the 27 included articles.   

<html><body><table><tr><td colspan="4">Contextual information</td></tr><tr><td colspan="2">Category</td><td>Na</td><td>%</td></tr><tr><td colspan="2">Country/Region</td><td></td><td></td></tr><tr><td rowspan="10">Educational sector</td><td>Asia</td><td>12</td><td>44</td></tr><tr><td>Europe</td><td>7</td><td>26</td></tr><tr><td>Oceania</td><td>4</td><td>15</td></tr><tr><td>North America</td><td>4</td><td>15</td></tr><tr><td></td><td></td><td></td></tr><tr><td>Higher education</td><td>9</td><td>33</td></tr><tr><td>Secondary education</td><td>1</td><td>4</td></tr><tr><td>Primary education</td><td>1</td><td>4</td></tr><tr><td>Early children education</td><td>1</td><td>4</td></tr><tr><td>Unspecified field</td><td>15</td><td>55</td></tr><tr><td>Methods</td><td></td><td></td><td></td></tr><tr><td></td><td>Literature study</td><td>9</td><td>33</td></tr><tr><td></td><td>Quantitative survey</td><td>7</td><td>26</td></tr><tr><td></td><td>Observations and interview</td><td>4</td><td>15</td></tr><tr><td></td><td>Exploratory research</td><td>3</td><td>11</td></tr><tr><td>Case study</td><td></td><td>3</td><td>11</td></tr><tr><td></td><td>Autoethnography</td><td>1</td><td>4</td></tr></table></body></html>

a The number of studies adds up to more than 27, as several studies described multiple functions of Generative AI.

![](img/fffb741d4eecd557c805019c800204dbf1cdd30535f70ede8e09d357bebd4399.jpg)  
Figure 2. Roles of generative AI in education.

To answer RQ1, RQ2, and RQ3—what are the technological affordances, the current challenges, and the future direction of research and practice of using Generative AI in education – the inductive grounded approach was used to categorize the coding scheme (Braun & Clarke, 2006). The following two examples illustrate how data can be analysed and encoded. The first example came from Yan’s (2023) study, which tried to apply ChatGPT in a writing practicum. The results revealed the potential applicability and affordance of ChatGPT, and demonstrated an automatic workflow that could maximize the writing efficiency. This example described here was encoded as the technological affordance for “automation”, because the most prominent element seems to be ChatGPT, which uses an automatic workflow. The second example came from the research by Cotton et al. (2023). It shows the concerns for academic integrity and plagiarism. The study also suggests strategies that can be adopted to ensure that these tools are used ethically and responsibly. We encoded this example as a current challenge of using Generative AI in education called “academic integrity risk”.

The major relevant themes were not predetermined before the analysis, but continuously emerged and were refined through the full analysis of the 27 records (see Table 3). Firstly, the first author read all records in their entirety and then coded them into themes. Subsequently, to improve the accuracy of the data analysis, nine papers were randomly selected $( 3 3 \%$ of all included articles) and were encoded by a trained coder. The inter-coder agreement was $89 \%$ . The trained coder and the first author discussed and resolved disagreements until consensus was reached.

# Results

# What are the technological affordances of using Generative AI in education?

The utilization of Generative AI in education presents a highly promising avenue. The inductive grounded approach was used by Huang et al. (2021) to identify the technological affordances of

Table 3. Coding category by research questions.   

<html><body><table><tr><td>Research question</td><td>Coding category</td><td>Explanation</td></tr><tr><td rowspan="3">1. What are the technological affordances of using Generative Al in education?.</td><td>Accessibility</td><td>Around-the-clock accessibility allows users to learn at any time.</td></tr><tr><td></td><td>Personalization Offer personalized feedback based on the context of</td></tr><tr><td>Automation</td><td>a given prompt.. Automatic workflow to repeat time-consuming tasks.</td></tr><tr><td rowspan="6">2. What are the current challenges of usinge Generative Al in education?</td><td> Interactivity</td><td>As an interactive conversation partner in written or oral form.</td></tr><tr><td>Academic integrity risk</td><td>Academic misconduct, such as cheating on examinations and plagiarism in research.</td></tr><tr><td>Response errors and bias</td><td>Information inaccuracies, classified as false, biased or non- existent.</td></tr><tr><td>Over- dependence</td><td>Risks of amplifying indolence and stifling high-order cognitive skills.</td></tr><tr><td>risk The widening digital</td><td>Disparities in device ownership, categorized as premium subscription offering, internet access, and use</td></tr><tr><td>divide Privacy and</td><td>prohibitions in some regions. Possible information leakage.</td></tr><tr><td rowspan="3">3. What are the future directions of research. and practice in the use of Generative Al in education?</td><td>security Direction for</td><td>Explore a particular topic in depth and systematically to</td></tr><tr><td>research Guidelines for</td><td>generate new knowledge, theories, methods and techniques.</td></tr><tr><td>practice</td><td>Turn theoretical results into practical applications and contribute to social development and economic benefits.</td></tr></table></body></html>

Table 4. Technological affordances of generative AI in education.   

<html><body><table><tr><td>Category</td><td>Example</td><td>Na</td><td>Sample studies</td></tr><tr><td>Accessibility</td><td>At the time level, provide users with timely help around-the-clock.</td><td>7</td><td>Kasneci et al. (2023) Jeon and Lee (2023)</td></tr><tr><td rowspan="2"></td><td>At the spatial level, make education accessible to learners via remote learning.</td><td>3</td><td>Cotton et al. (2023) Dwivedi et al. (2023)</td></tr><tr><td>Personalization Provide individualized recommendations based on the user&#x27;s preferences.</td><td>5</td><td>Mohamed (2023)</td></tr><tr><td rowspan="4">Automation</td><td>Tailor exams or quizzes based on students&#x27; needs and abilities.</td><td>2</td><td>Peters et al. (2023)</td></tr><tr><td>Automatic workflow to repeat time-consuming tasks.</td><td>6</td><td>Farrokhnia et al. (2023)</td></tr><tr><td>Speedy performance for response.</td><td>4</td><td>Jeon and Lee (2023)</td></tr><tr><td>Idiomatic and well-structured answers.</td><td>3</td><td>Howell and Potgieter</td></tr><tr><td>Interactivity</td><td>Promote learners&#x27; contextual language development and improve conversational skills.</td><td>6</td><td>(2023) Luo et al. (2023) Barrot (2023)</td></tr></table></body></html>

aThe number of studies adds up to more than 27, as several studies describe multiple technological affordances of Generative AI.

chatbots, that is, timeliness, ease of use, and personalization. Based on this, content analysis of all 27 articles revealed four categories of technological affordances of Generative AI: accessibility, personalization, automation, and interactivity (see Table 4).

# Accessibility

As the software developer of Generative AI relevant technical products (e.g., DALL-E, ChatGPT), OpenAI’s mission is to make intelligent tools benefit humanity (OpenAI, 2023). In pursuit of the goal and to facilitate the democratization of knowledge, at launch, ChatGPT was made freely accessible to people (Lim et al., 2023). Generative AI has around-the-clock accessibility (Dalalah & Dalalah, 2023), which grants users the opportunity to learn at any time, so they no longer need to wait for human help. For example, students in the study of Dwivedi et al. (2023) used ChatGPT to browse e-learning resources, increasing their engagement and learning outcomes in the course. Y. Su et al. (2023) suggested the integration of ChatGPT into argumentative writing classrooms due to its powerful text generation function. Moreover, it was also mentioned in three records (Cotton et al., 2023; Dwivedi et al., 2023; Kasneci et al., 2023) that Generative AI makes education accessible to students via remote learning. This could facilitate online learning and enable more equitable and inclusive education.

# Personalization

Trained on multi-topic data and scientific literature, Generative AI can offer personalized feedback based on the context of a given prompt, and identify patterns and relationships that humans might struggle to detect (G.-J. Hwang & Chen, 2023). For example, text-based Generative AI (e.g., ChatGPT, Bard) can generate personalized text learning materials with different structures (e.g., individual quizzes, study guides) based on students’ preferences (Luo et al., 2023). Dalalah and Dalalah (2023) indicated that even given a common topic, different students can communicate with ChatGPT differently with diverse inputs. Image-based Generative AI (e.g., Midjourney) allows students to customize pictures. If students are not satisfied with the images, they can provide detailed descriptions to ask Midjourney to redraw them (G.-J. Hwang & Chen, 2023). Since each person has unique learning preferences, abilities, and pace, Generative AI provides a more targeted experience by personalizing responses based on previous interactions and queries (Farrokhnia et al., 2023). The feature enables users to create unique requests that feel like real dialogue and communication that becomes more personalized.

# Automation

The workflow of Generative AI is automatic; it can automate repetitive time-consuming tasks (e.g., data processing, formatting), freeing up time for users to focus on higher-level work (e.g., rewriting, analysis) (Peters et al., 2023; Yan, 2023). Early user feedback suggested that many were impressed by the speed at which Generative AI learns and responds (Jeon & Lee, 2023). When given a topic, ChatGPT will respond with a short essay of about 300 words in no time (Yan, 2023). Magic Write (embedded in Canva Docs) can generate text in response to human-provided prompts, which can produce outlines, lists and content ideas, and a first draft appears in seconds (Peres et al., 2023). In addition to its speedy performance, the generated answers are well-structured and idiomatic (Kasneci et al., 2023). With Generative AI, teachers would now have more control over creating lesson materials than in the past, when they had to manually develop and revise materials (Jeon & Lee, 2023). To be specific, ChatGPT can automatically generate instructional design with a set of constraints and parameters (Farrokhnia et al., 2023). However, while Generative AI can automate tasks, the ultimate responsibility for the content and quality still belongs to human researchers.

# Interactivity

Generative AI has potential as an interlocutor, especially as an interactive conversation partner in written or oral form. Text-based Generative AI (e.g., ChatGPT, Bard) is also known as intelligent chatbots, that is to say, Generative AI could learn from interactions with users, which makes it an adaptable conversational agent. It could store and incorporate previous interactions into responses. Over time, this allows it to connect with context and communicate more naturally and coherently with users (Farrokhnia et al., 2023). For example, ChatGPT has demonstrated particular potential as a pedagogical tool in language education, including daily language practice and language assessments (Guo et al., 2022; Kasneci et al., 2023). Luo et al. (2023) also indicated the role of enhancing conversational social skills and fostering contextual language development for young children. Textbased Generative AI can explain words or concepts to children. It is also a natural responder and, unlike a parent or teacher who may get frustrated after answering several questions, because textbased Generative AI never gets tired or annoyed.

# What are the current challenges of using Generative AI in education?

To realize the potential of Generative AI, the application must be approached with caution, and the challenges should be critically assessed. After reading the 27 included papers, five categories of challenges were summarized, namely academic integrity risk, response errors and bias, overdependence risks, the widening digital divide, and privacy and security (see Table 5).

# Academic integrity risk

Generative AI makes it convenient to collect information, and its responses are presented in natural and human-like content. It is becoming increasingly difficult to distinguish between humangenerated and machine-generated content (Li et al., 2023), so there may be issues of academic integrity. Especially, using Generative AI during examinations or for assignments is academic misconduct. Kortemeyer (2023) found that ChatGPT can achieve a grade of 1.5 in standard introductory physics courses, enough to earn a course credit. G.-J. Hwang and Chen (2023) demonstrated that the pictures generated by Midjourney are almost indistinguishable from those drawn by students, which is both impressive and alarming. Therefore, if misused by students, it could raise serious academic integrity issues. Receiving help from Generative AI on tests also leads to an inaccurate assessment of the student’s abilities (Cotton et al., 2023). Therefore, researchers should have a sense of responsibility and take precautions to avoid improper use. Students are also expected to put in effort and time to obtain critical knowledge and skills through legitimate means to maintain academic integrity in all learning environments.

# Response errors and bias

The ability of Generative AI to evaluate the credibility of its training data is inadequate, which will affect the accuracy of the generated information, leading to unexpected responses or discriminatory outcomes (Farrokhnia et al., 2023; Kasneci et al., 2023). For example, without access to the Internet, ChatGPT has a limited reserve for world events since 2021 (Stokel-Walker & Van Noorden, 2023). This limitation could sometimes lead to responses that are outdated and inaccurate. Benefiting from real-time Internet access, Bard and Microsoft Copilot with Bing Chat do not have this limitation, but they offer few academic papers, and references may be substandard. They might even fabricate references that seem reasonable but do not point to realworld sources (Howell & Potgieter, 2023), leading to the spread of false or misleading information. Furthermore, Generative AI trained on biased data could even widen existing prejudices and inequities, negatively impacting educational practice and academic research. For instance, if textbased Generative AI is trained on biased text data that exhibit a preference for certain groups, it may result in discriminatory or inequitable outcomes for marginalized communities (e.g., cultural information about ethnic minorities may be ignored) (Kasneci et al., 2023). If image-based Generative AI is trained on distorted or group-specific image data, it may lead to students’ drawings being unfairly graded, further marginalizing those who are already educationally disadvantaged (Chiu, 2023). To mitigate this risk, consistent surveillance of a model’s performance may help detect and address biases early. Teachers and students should be instructed on how to critically evaluate information generated by Generative AI.

Table 5. Current challenges of generative AI in education.   

<html><body><table><tr><td>Category</td><td>Example</td><td>Na</td><td>Sample studies</td></tr><tr><td>Academic integrity risk.</td><td>Cheating in examinations or assignments.</td><td></td><td>8Y. Su et al. (2023) Kortemeyer (2023)</td></tr><tr><td>Response errors ande</td><td>Plagiarism and copyright issues in research.</td><td>6</td><td>Li et al. (2023) Yan (2023)</td></tr><tr><td>bias</td><td>Errors or inaccuracies in the data.</td><td></td><td>6 Farrokhnia et al. (2023)</td></tr><tr><td></td><td>Misleading information to enlarge existing biases and discrimination. Non-existent citations.</td><td>5 4</td><td>Stojanov (2023) Mohamed (2023) Howell and</td></tr><tr><td>Over-dependence on Generative AI</td><td>Stifling learners&#x27; high-order cognitive skills.</td><td></td><td>Potgieter (2023) 4Dwivedi et al. (2023)</td></tr><tr><td></td><td>Amplifying indolence and impeding learners&#x27; inclination to autonomously arrive at their own conclusions.</td><td></td><td>Barrot (2023) Kasneci et al. (2023)</td></tr><tr><td>Widening the digital divide</td><td>Enhancing access for the privileged while limiting it for the underprivileged who cannot afford the premium fee.</td><td></td><td> Lim et al. (2023)</td></tr><tr><td></td><td>Unequal access to the internet.</td><td></td><td>Cotton et al. (2023)</td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>Luo et al. (2023)</td></tr><tr><td></td><td>Some regions have tried to ban or restrict its use.</td><td></td><td></td></tr><tr><td></td><td></td><td>2 2</td><td></td></tr></table></body></html>

The number of studies adds up to more than 27, as several studies describe multiple challenges of Generative AI.

# Over-dependence on Generative AI

Although users can quickly access fine-grained information with the assistance of Generative AI, over-dependence has a negative impact on both learners and educators. For learners, it may impact their development of higher cognitive skills, such as creativity, problem-solving skills and critical thinking. Kasneci et al. (2023) revealed that using an AI system can simplify the process of reaching conclusions and finding solutions, which could affect students’ passion and motivation to conduct independent research and draw their own conclusions. Dwivedi et al. (2023) indicated that if students choose not to read deeply about a topic, but instead use Generative AI for quick and possibly superficial learning, their critical thinking and creativity could be stifled. For educators, overdependence on Generative AI makes it difficult to generate novel instructional design ideas and affects the quality of their interactions with students (Farrokhnia et al., 2023). Thus, Generative AI should be regarded as a complementary tool rather than as a replacement, assisting work under the control and supervision of human researchers.

# The widening digital divide

Some Generative AI tools include an accompanying premium subscription offering (Victor et al., 2023). This would run counter to the democratization of knowledge, and widen the digital divide by prioritizing access to knowledge for those who can afford it. With the rapid ascent and widespread adoption of Generative AI, spatial inequality and disparities in device ownership have created a digital divide that disproportionally impacts learners in remote areas (Lim et al., 2023). Cotton et al. (2023) emphasized that if a student uses text-based Generative AI to complete high-quality writing assignments, they may have an unfair advantage over others who are not using this tool. Meanwhile, some educational institutions have been quick to announce their attitudes towards Generative AI tools. The education departments of Queensland and New South Wales in Australia have announced their implementation of firewalls to ban ChatGPT (ABC News, 2023), while public schools in New York City have done the same (Lukpat, 2023). In fact, in most cases, these bans would exacerbate inequalities in technology use. More positive effects are more likely to occur when attempts are made to harness and integrate these new technologies rather than to ban them.

# Privacy and security

The potential ethical issues raised by the use of Generative AI need attention and consideration. The utilization of Generative AI generally entails the acquisition, analysis, and retention of user data. Text and picture data used to train Generative AI are often scraped from websites with no transparency, which may compromise users’ privacy and security (Zawacki-Richter et al., 2019). To be specific, if adequate measures of protection and security are not implemented, text-based Generative AI may leak or improperly use students’ personal information or learning data, and image-based Generative AI may violate data subjects’ portrait rights. Therefore, organizations utilizing Generative AI must maintain continuous monitoring of their systems, evaluate potential risks, and adjust their policies and procedures regarding the use of Generative AI accordingly. The implementation of data security protocols, such as encryption, password protection, and antivirus programmes, is imperative for educational institutions to fortify their defences against Generative AI to avoid potential vulnerabilities. Informed consent should be obtained to ensure that all users comprehend the intended purpose of the data and whether it may be disclosed to third parties. In general, it is important for education departments and students to approach Generative AI with ethics and transparency.

# What are the future directions of research and practice on the use of Generative AI in education?

Generative AI has sparked concern amidst a flurry of sensationalist papers and hasty prohibitions. The fact is that Generative AI is inherently impartial and can be trained to foster positive outcomes while mitigating negative ones among users in the field of education (Dwivedi et al., 2023). As a transformative resource, the promotion of ethical use awareness may offer a more enduring strategy for progress rather than implementing bans. Table 6 displays some guidelines about the future direction of research and practice.

Generative AI has the potential to enhance education; however, it is crucial to consider the academic integrity risks. Educational institutions and colleges are expected to reiterate that using painting or verbatim text generated by Generative AI to complete assignments clearly constitutes academic misconduct. In the future, strong anti-cheating measures should be implemented, including monitored examination environments and plagiarism detection software. On the one hand, the evaluation methods for teaching should be intricate and multifarious. Open-ended inquiries within a supervised setting, presentations or oral examinations may need to be considered, as they are difficult for Generative AI to replicate. On the other hand, the development and integration of plagiarism detection software is strongly encouraged among software developers. An example of adopting BERT-based classifiers comes from the study of Kasneci et al. (2023), which has accurately distinguished between reflections generated by ChatGPT and students’ original assignments. However, as Generative AI systems mature, developing reliable AI output detectors may turn into a cat-and-mouse game (Lim et al., 2023). The output detection is just one side; the other side of the coin is having a positive dialogue with users, including explicit discussions on how to apply Generative AI with honesty, transparency and integrity.

Table 6. Guidelines about the future directions of research and practice.   

<html><body><table><tr><td>Key implications</td><td>Direction for research</td><td>Guidelines for practice</td></tr><tr><td>Generative Al can offer users instant help around-the-clock, but may have implications for academic integrity.</td><td>How can we accurately distin- guish between students&#x27; ori- ginal work and Generative AI&#x27;s output? How can we effectively guide students to apply Generative Al with honesty, morality, and transparency? What policy measures can be taken to ensure the ethical</td><td>Adopt diverse assessment methods. Open-ended questions based on the invigilator environment. Use classifiers to detect plagiarism. Establish and regularly update ethi- cal guidelines for the appropriate utilization of Generative Al in education.</td></tr><tr><td>Generative Al can deliver useful information on a variety of subjects, although caution should be taken due to its susceptibility to disinformation and bias.</td><td>use of Generative Al? How can Generative AI be trained to produce reliable responses? How can we identify and address potential biases and other glitches in model outputs? How can we develop effective prompting strategies?</td><td>Train models with diverse and unbiased data. Describe the desired goal in specific and clear terms.</td></tr><tr><td>Generative Al can act as a catalyst for educational reform; thus, it is imperative for relevant departments to embrace rather than shun its use.</td><td>How can Generative AI be integrated into current curri- cula to enhance students&#x27; learning effect? How does the efficiency of Generative Al in teaching compare to that of traditional teaching methods?</td><td>Reinforce the application of Generative Al in education and advocate for its optimal implemen- tation, rather than imposing bans or restrictions. Educate students on the signifi- cance of honing their own skills, rather than depending on Al to accomplish tasks for them. Develop and implement robust data</td></tr></table></body></html>

Generative AI can handle large amounts of information and provide useful resources to users. However, the dataset utilized by Generative AI to generate recommendations may harbour inaccuracies and prejudices (Kasneci et al., 2023). This will lead to the spread of fabricated or deceptive information. Therefore, Generative AI should be applied with caution. Diverse and unbiased data should be used to continuously update models. Educators should also be provided with professional training on how to identify and mitigate biases and other errors in model outputs. To enable Generative AI to generate comprehensive and optimal responses, another practice area is the development of skills to prompt correctly. In fact, Generative AI is far from attaining a state of utmost autonomy. The responses it generates are intricately intertwined with the inputs it receives (Lim et al., 2023; Peres et al., 2023). Therefore, users are expected to describe the desired goal/ question and output format in clear and specific words, and avoid using overly ambiguous or general terms. The more contextual information offered to the Generative AI, the more accurate the generated response will be (G.-J. Hwang & Chen, 2023).

As history has demonstrated, prohibitions may not yield the anticipated outcomes, and effective governance and strategic regulation are crucial for achieving seamless integration (Dwivedi et al., 2023). Refraining from the use of Generative AI tools may exacerbate pre-existing inequalities, potentially impacting students who are already marginalized (Lim et al., 2023). Educational institutions should take a rational view of the emergence and subsequent application of Generative AI. There ought to exist well-defined regulations and protocols governing the utilization of Generative AI in education, ensuring that their use is responsible and ethical. In practice, educational institutions are expected to integrate activities that develop higher-order thinking skills into the curriculum. Learners should be encouraged to use additional authoritative resources such as books and articles to validate the information provided by Generative AI. Generative AI can be used to delve into alternative perspectives, rather than simply gathering answers.

# Discussion

The vast potential of Generative AI in academia is truly remarkable (Dwivedi et al., 2023; Jeon & Lee, 2023; Peres et al., 2023). It plays a variety of roles, including intelligent tutor, intelligent tutee, intelligent learning tool/partner, and domain expert. To release its potential in education, researchers must conduct a critical evaluation of the limitations and technical implications of Generative AI, ensuring that they are utilized responsibly and transparently. This review analyzes the current application of Generative AI in education, and proposes future research directions and practice guidelines.

# Technological affordances of using Generative AI in education

Evidence addressing the first research question indicated that Generative AI can bring efficient teaching and learning experiences to teachers and students through four types of technological affordances: accessibility, personalization, automation, and interactivity. The accessibility of Generative AI offers users instant responses (Dwivedi et al., 2023). When interacting with Generative AI, learners can obtain personalized learning resources (Dalalah & Dalalah, 2023). Yan (2023) indicated that Generative AI can develop and adapt educational programmes according to subject characteristics and students’ abilities. It can provide tailored learning support. Generative AI can also act as a tireless learning partner, efficiently processing large amounts of data and automating repetitive, time-consuming tasks (Jeon & Lee, 2023). This liberates additional time for users to focus on higher-level tasks. As a highly advanced large-scale language model, text-based Generative AI has the potential to promote the development of learners’ conversational and social skills (Peters et al., 2023).

# Current challenges of using Generative AI in education

The second research question explains five challenges to using Generative AI in education, including academic integrity risk, response errors and bias, over-dependence on Generative AI, the widening digital divide, and privacy and security. Previous research has reported on the academic integrity risks of Generative AI in education (Ahsan et al., 2022; Cotton et al., 2023). Kortemeyer (2023) revealed that students may abuse Generative AI-based technologies to complete tasks without fully understanding the concept of the assignments. This will seriously affect their knowledge acquisition and thinking development process. In addition, data quality and reliability issues also pose significant challenges. Generative AI trained on biased data may lead to the production of inaccurate outcomes in academic research. Moreover, the increasing reliance on technology has raised concerns about the development of learners’ advanced cognitive skills. This is because overreliance on Generative AI for expeditious and potentially superficial information acquisition may stifle students’ critical thinking and creativity (Dwivedi et al., 2023). At the same time, many students do not have access to advanced AI technologies, which will exacerbate the existing education gap and digital divide. Privacy and data security are also critical, and relevant departments must protect sensitive student information from potential leakage.

# The future directions of research and practice on the use of Generative AI in education

The findings of the third research question can enhance our understanding of future research and practice directions for Generative AI in education. Firstly, Generative AI can offer users immediate help around the clock, but may have implications for academic integrity. Adopting a variety of assessment methods or using plagiarism detection software can be effective ways to prevent academic misconduct (Kasneci et al., 2023; Lim et al., 2023). Meanwhile, it is important to establish ethical guidelines for the appropriate utilization of Generative AI in education. Secondly, Generative AI can deliver useful information on a variety of topics, although caution should be taken due to its susceptibility to disinformation and bias. Learners should be encouraged to detect the content generated by Generative AI, incorporating human expertise to review, validate, and interpret models. Finally, Generative AI can act as a catalyst for educational reform; thus, it is imperative for relevant departments to embrace rather than shun its use. Users should be trained to use Generative AI effectively and appropriately instead of banning its use as a learning assistant (Dwivedi et al., 2023). Educators and learners need to be guided in how to use Generative AI as a thought aid and reference for personal development. As for future research, how Generative AI can be integrated into existing curricula and to what extent students can benefit need further empirical research.

# Conclusion

While Generative AI upends common beliefs and practices that liberate educators and learners in learning, teaching, and research, it can also pose demanding challenges. Although this review reflects the optimism surrounding the potential of Generative AI as a revolutionary technology in education, it also emphasizes the imperative for further research to explore optimal strategies for integrating Generative AI into educational practices and mitigating identified risks.

# Implications

This review enriches the literature on Generative AI in education. First, it not only reports on the roles based on the AIED model (G. Hwang et al., 2020), but also analyzes the utility and availability from a technology affordance perspective (Kirschner et al., 2004). Second, this review explores several challenges associated with the application of Generative AI, and offers possible solutions. Third, this review focuses on the future research and practice direction of Generative AI in education, and provides specific guidance schemes. The findings also have practical value for stakeholders. Policymakers can perceive this review as an invaluable reference tool to guide them in formulating new educational policies and guidelines, ensuring the responsible and transparent utilization of Generative AI. Educators should rationally understand the new trend of technology-enabled education and learn how to wisely and correctly use Generative AI to improve educational quality. In order to help teachers accurately evaluate the value and risks of Generative AI, workshops and seminars can also be used to share experiences. Finally, learners need to further consolidate ethical values. They should critically reflect on how to rationalize the use of Generative AI to ensure true mastery of knowledge and skills.

# Limitations and future study

There are certain constraints inherent in this study. First, the literature inclusion and review work was conducted at the end of June 2023, a limitation that could have affected the results as it did not capture the latest progress in subsequent technological iterations of Generative AI. Second, the findings are restricted to Generative AI-related articles published in English, excluding relevant literature published in other languages. The third limitation is the inherent subjectivity of the qualitative analysis. Future studies may consider methodological triangulation (e.g., classroom observations, learning log analysis, and interview data) to improve the trustworthiness of the findings.

# Acknowledgements

This study was supported by the National Science and Technology Council, Taiwan, under grant NSTC 111-2410-H-019- 006-MY3 and NSTC 111-2423-H-153-001-MY3.

# Disclosure statement

No potential conflict of interest was reported by the author(s).

# Notes on contributors

Nan Wang is studying for a master’ s degree at Nanjing Normal University, China. Her research interests include Intelligent System, Information-based Instructional Design and Instructional Behavior Analysis.

Xiao Wang is studying for a master’ s degree at Nanjing Normal University, China. Her research interests include Intelligent System, Information-based Instructional Design and Instructional Behavior Analysis.

Yu-Sheng Su is currently an associate professor of department of computer science and information engineering at National Chung Cheng University, Taiwan. His research interests include Cloud Computing, Big Data Analytics, Intelligent System, and Metaverse.

# References

ABC News. (2023). Queensland to join NSW in banning access to ChatGPT in state schools. ABC News. https://www.abc. net.au/news/2023-01-23/queensland-to-join-nsw-in-banning-access-to/101884288 .

Ahsan, K., Akbar, S., & Kam, B. H. (2022). Contract cheating in higher education: A systematic literature review and future research agenda. Assessment & Evaluation in Higher Education, 47(4), 523–539. https://doi.org/10.1080/02602938. 2021.1931660   
Athabasca University. (2020). Principles for ethical use of personalized student data. https://www.athabascau.ca/ university-secretariat/_documents/policy/principles-for-ethical-use-personalized-student-data.pdf .   
Barrot, J. S. (2023). Using ChatGPT for second language writing: Pitfalls and potentials. Assessing Writing, 57, 100745. https://doi.org/10.1016/j.asw.2023.100745   
Braun, V., & Clarke, V. (2006). Using thematic analysis in psychology. Qualitative Research in Psychology, 3(2), 77–101. https://doi.org/10.1191/1478088706qp063oa   
Chiu, T. K. F. (2023). The impact of generative AI (GenAI) on practices, policies and research direction in education: A case of ChatGPT and Midjourney. Interactive Learning Environments, 1–17. https://doi.org/10.1080/10494820.2023. 2253861   
Cooper, G. (2023). Examining science education in ChatGPT: An exploratory study of generative artificial intelligence. Journal of Science Education and Technology, 32(3), 444–452. https://doi.org/10.1007/s10956-023-10039-y   
Cotton, D., Cotton, P. A., & Shipway, J.R. (2023). Chatting and cheating: Ensuring academic integrity in the era of ChatGPT. Innovations in Education and Teaching International, 1–12. https://doi.org/10.1080/14703297.2023.2190148   
Dalalah, D., & Dalalah, O. M. (2023). The false positives and false negatives of generative AI detection tools in education and academic research: The case of ChatGPT. The International Journal of Management Education, 21(2), 100822. https://doi.org/10.1016/j.ijme.2023.100822   
Dibble, M. (2023). Schools ban ChatGPT amid fears of artificial intelligence-assisted cheating. VOA News. https://www. voanews.com/a/schools-banchatgpt-amid-fears-of-artificial-intelligence-assisted-cheating/6949800.html .   
Dwivedi, Y. K., Kshetri, N., Hughes, L., Slade, E. L., Jeyaraj, A., Kar, A. K., Baabdullah, A. M., Koohang, A., Raghavan, V., Ahuja, M., Albanna, H., Albashrawi, M. A., Al-Busaidi, A. S., Balakrishnan, J., Barlette, Y., Basu, S., Bose, I., Brooks, L., Buhalis, D. . . . Wright, R. (2023). Opinion paper: “so what if ChatGPT wrote it?” multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy. International Journal of Information Management, 71, 102642. https://doi.org/10.1016/j.ijinfomgt.2023.102642   
Farrokhnia, M., Banihashem, S. K., Noroozi, O., & Wals, A. E. J. (2023). A SWOT analysis of ChatGPT: Implications for educational practice and research. Innovations in Education and Teaching International, 1–15. https://doi.org/10. 1080/14703297.2023.2195846   
Gašević, D., Siemens, G., & Sadiq, S. (2023). Empowering learners for the age of artificial intelligence. Computers and Education: Artificial Intelligence, 4, 100130. https://doi.org/10.1016/j.caeai.2023   
Guo, K., Wang, J., & Chu, S. K. W. (2022). Using chatbots to scaffold EFL students’ argumentative writing. Assessing Writing, 54, 100666. https://doi.org/10.1016/j.asw.2022.100666   
Howell, B. E., & Potgieter, P. H. (2023). What do telecommunications policy academics have to fear from GPT-3? Telecommunications Policy, 47(7), 102576. https://doi.org/10.1016/j.telpol.2023.102576   
Huang, W., Hew, K. F., & Fryer, L. K. (2021). Chatbots for language learning—are they really useful? A systematic review of chatbot‐supported language learning. Journal of Computer Assisted Learning, 38(1), 237–257. https://doi.org/10. 1111/jcal.12610   
Hwang, G.-J., & Chen, N.-S. (2023). Editorial position paper: Exploring the potential of generative artificial intelligence in education: Applications, challenges, and future research directions. Educational Technology & Society, 26(2). https:// doi.org/10.30191/ETS.202304_26(2).0014   
Hwang, G., Xie, H., Wah, B. W., & Gašević, D. (2020). Vision, challenges, roles and research issues of artificial intelligence in education. Computers and Education: Artificial Intelligence, 1, 100001. https://doi.org/10.1016/j.caeai.2020.100001   
Jeon, J., & Lee, S. (2023). Large language models in education: A focus on the complementary relationship between human teachers and ChatGPT. Education and Information Technologies, 28(12), 15873–15892. https://doi.org/10. 1007/s10639-023-11834-1   
Johri, A., Katz, A., Qadir, J., & Hingle, A. (2023). Generative artificial intelligence and engineering education. Journal of Engineering Education, 112(3), 572–577. https://doi.org/10.1002/jee.20537   
Kasneci, E., Sessler, K., Küchemann, S., Bannert, M., Dementieva, D., Fischer, F., Gasser, U., Groh, G., Günnemann, S., Hüllermeier, E., Krusche, S., Kutyniok, G., Michaeli, T., Nerdel, C., Pfeffer, J., Poquet, O., Sailer, M., Schmidt, A., Seidel, T. . . . Kasneci, G. (2023). ChatGPT for good? On opportunities and challenges of large language models for education. Learning and Individual Differences, 103, 102274. https://doi.org/10.1016/j.lindif.2023.102274   
Kirschner, P., Strijbos, J., Kreijns, K., & Beers, P.J. (2004). Designing electronic collaborative learning environments. Educational Technology Research & Development, 52(3), 47–66. https://doi.org/10.1007/bf02504675   
Kohnke, L., Moorhouse, B. L., & Zou, D. (2023). ChatGPT for language teaching and learning. RELC Journal, 54(2), 537–550. https://doi.org/10.1177/00336882231162868   
Korpershoek, H., Harms, T., De Boer, H., Van Kuijk, M., & Doolaard, S. (2016). A meta-analysis of the effects of classroom management strategies and classroom management programs on students’ academic, behavioral, emotional, and motivational outcomes. Review of Educational Research, 86(3), 643–680. https://doi.org/10.3102/0034654315626799   
Kortemeyer, G. (2023). Could an artificial-intelligence agent pass an introductory physics course? Physical Review Physics Education Research, 19(1). https://doi.org/10.1103/physrevphyseducres.19.010132   
Lim, W. M., Gunasekara, A., Pallant, J. L., Pallant, J., & Pechenkina, E. (2023). Generative AI and the future of education: Ragnarök or reformation? A paradoxical perspective from management educators. The International Journal of Management Education, 21(2), 100790. https://doi.org/10.1016/j.ijme.2023.100790   
Li, Y., Sha, L., Yan, L., Lin, J., Raković, M., Galbraith, K., Lyons, K., Gašević, D., & Chen, G. (2023). Can large language models write reflectively. Computers and Education: Artificial Intelligence, 4, 100140. https://doi.org/10.1016/j.caeai.2023.100140   
Lodge, J. M., Thompson, K., & Corrin, L. (2023). Mapping out a research agenda for generative artificial intelligence in tertiary education. Australasian Journal of Educational Technology, 39(1), 1–8. https://doi.org/10.14742/ajet.8695   
Lukpat, A. (2023). ChatGPT banned in New York City public schools over concerns about cheating, learning development. The Wall Street Journal. https://www.wsj.com/articles/chatgpt-banned-in-new-york-city-publicschools-over-concerns-about-cheating-learning-development-11673024059 .   
Lund, B. D., Wang, T., Mannuru, N.R., Nie, B., Shimray, S., & Wang, Z. (2023). ChatGPT and a new academic reality: Artificial intelligence‐written research papers and the ethics of the large language models in scholarly publishing. Journal of the Association for Information Science and Technology, 74(5), 570–581. https://doi.org/10.1002/asi.24750   
Luo, W., He, H., Liu, J., Berson, I.R., Berson, M. J., Zhou, Y., & Li, H. (2023). Aladdin’s genie or pandora’s box for early childhood education? Experts chat on the roles, challenges, and developments of ChatGPT. Early Education and Development, 35(1), 96–113. https://doi.org/10.1080/10409289.2023.2214181   
Microsoft Corporation. (2023). Microsoft Bing Chat. https://www.microsoft.com/en-us/edge/features/bing-chat?form $\mid =$ MT00D8   
Mohamed, A. M. (2023). Exploring the potential of an AI-based Chatbot (ChatGPT) in enhancing English as a foreign language (EFL) teaching: Perceptions of EFL faculty members. Education and Information Technologies. https://doi. org/10.1007/s10639-023-11917-z   
Moher, D., Shamseer, L., Clarke, M., Ghersi, D., Liberati, A., Petticrew, M., Shekelle, P., & Stewart, L.A. (2015). Preferred reporting items for systematic review and meta-analysis protocols (PRISMA-P) 2015 statement. Systematic Reviews, 4 (1), 1–9. https://doi.org/10.1186/2046-4053-4-1   
OpenAI. (2023). OpenAI. http://openai.com/   
Pavlik, J. V. (2023). Collaborating with ChatGPT: Considering the implications of generative artificial intelligence for journalism and media education. Journalism & Mass Communication Educator, 78(1), 84–93. https://doi.org/10.1177/ 10776958221149577   
Peres, R., Schreier, M., Schweidel, D., & Sorescu, A. (2023). On ChatGPT and beyond: How generative artificial intelligence may affect research, teaching, and practice. International Journal of Research in Marketing, 40(2), 269–275. https://doi. org/10.1016/j.ijresmar.2023.03.001   
Peters, M. A., Jackson, L., Papastephanou, M., Jandrić, P., Lazaroiu, G., Evers, C. W., Cope, B., Kalantzis, M., Araya, D., Tesar, M., Mika, C., Chen, L., Wang, C., Sturm, S., Rider, S., & Fuller, S. (2023). AI and the future of humanity: ChatGPT-4, philosophy and education – critical responses. Educational Philosophy and Theory, 1–35. https://doi.org/10.1080/ 00131857.2023.2213437   
Stojanov, A. (2023). Learning with ChatGPT 3.5 as a more knowledgeable other: An autoethnographic study. International Journal of Educational Technology in Higher Education, 20(1). https://doi.org/10.1186/s41239-023- 00404-7   
Stokel-Walker, C., & Van Noorden, R. (2023). What ChatGPT and generative AI mean for science. Nature, 614(7947), 214–216. https://doi.org/10.1038/d41586-023-00340-6   
Su, Y., Lin, Y., & Lai, C. (2023). Collaborating with ChatGPT in argumentative writing classrooms. Assessing Writing, 57, 100752. https://doi.org/10.1016/j.asw.2023.100752   
Su, J., & Yang, W. (2022). Artificial intelligence in early childhood education: A scoping review. Computers and Education: Artificial Intelligence, 3, 100049. https://doi.org/10.1016/j.caeai.2022.100049   
UNESCO. (2023). ChatGPT and artificial intelligence in higher education: Quick start guide. UNESCO. https://unesdoc. unesco.org/ark:/48223/pf0000385146   
Victor, B. G., Kubiak, S., Angell, B., & Perron, B. E. (2023). Time to move beyond the ASWB licensing exams: Can generative artificial intelligence offer a way forward for social work? Research on Social Work Practice, 33(5), 511–517. https://doi. org/10.1177/10497315231166125   
Yan, D. (2023). Impact of ChatGPT on learners in a L2 writing practicum: An exploratory investigation. Education and Information Technologies, 28(11), 13943–13967. https://doi.org/10.1007/s10639-023-11742-4   
Zawacki-Richter, O., Marín, V. I., Bond, M., & Gouverneur, F. (2019). Systematic review of research on artificial intelligence applications in higher education – where are the educators? International Journal of Educational Technology in Higher Education, 16(1). https://doi.org/10.1186/s41239-019-0171-0