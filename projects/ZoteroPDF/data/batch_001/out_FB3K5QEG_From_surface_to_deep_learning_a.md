# From surface to deep learning approaches with Generative AI in higher education: an analytical framework of student agency

Yunying Yang, Jinwen Luo, Miaoyan Yang, Runde Yang & Jiayin Chen

To cite this article: Yunying Yang, Jinwen Luo, Miaoyan Yang, Runde Yang & Jiayin Chen (2024) From surface to deep learning approaches with Generative AI in higher education: an analytical framework of student agency, Studies in Higher Education, 49:5, 817-830, DOI: 10.1080/03075079.2024.2327003

To link to this article: https://doi.org/10.1080/03075079.2024.2327003

# From surface to deep learning approaches with Generative AI in higher education: an analytical framework of student agency

Yunying Yanga , Jinwen Luob , Miaoyan Yangc , Runde Yangd and Jiayin Chene a School of Information Technology in Education, South China Normal University, Guangzhou, People’s Republic of China; b School of Education and Information Studies, University of California, Los Angeles, CA, USA; c Sociology Department, School of Sociology and Anthropology, Xiamen University, Xiamen, People’s Republic of China; $^ { \mathsf { d } } { \mathsf { B } } { \mathsf { I o c k } }$ Art Online, New York, NJ, USA; e Center for Human Geography and Urban Development, School of Geography and Remote Sensing, Guangzhou University, Guangzhou, People’s Republic of China

# ABSTRACT

Recent emergence of generative artificial intelligence (GenAI) technology has stimulated interests as well as concerns in their potential in teaching and learning. Situated in the new and transforming context, this study provides an avenue for students to introspectively explore their use of GenAI in a postgraduate course. Seventy-four students from three Chinese universities participated in this study. By analyzing student interviews conducted pre- and post-course, alongside their chat logs with GenAI and reflective journal entries detailing their learning approaches, the research uncovers a spectrum of student perspectives on GenAI’s impact, ranging from beneficial optimism, to cautious skepticism and adaptable pragmatism. Notably, student agency is identified as a crucial element in relation to these themes. This was articulated in four types of learning activities: receptive, resistive, resourceful, and reflective. The research underscores the importance of supporting and empowering student agency in the learning approaches aided by GenAI in education, highlighting its role in optimizing its use and enhancing autonomous, lifelong learning skills amidst the evolving technologically advanced learning landscape.

# ARTICLE HISTORY

Received 4 October 2023   
Accepted 1 March 2024

# KEYWORDS

Generative AI; GPT; student agency; learning approaches; higher education

# Introduction

The groundbreaking artificial intelligence (AI) chatbot ChatGPT, developed by OpenAI, has garnered significant recognition as the finest chatbot to have been developed thus far (Haleem et al. 2023). The Generative Pre-Trained Transformer (GPT) is a deep learning model designed to generate human-like text by leveraging advanced natural language processing (NLP) techniques. Generative AI (GenAI) tools, as exemplified by ChatGPT, have the potential to augment learner capacities in various ways (Haleem et al. 2023; Rudolph, Tan, and Tan 2023). This potential is enabled by the foundation models of GPT (as discussed by Bommasani et al. 2021), steming from their remarkable capacity to engage in nuanced conversations and provide informative responses that closely emulate human communication. One such way is the creation of adaptive quizzes and assessments that tailor to individual learners’ performance, providing appropriate challenges and personalized feedback for improved understanding (Rudolph, Tan, and Tan 2023). Also, GenAI tools can aid multilingual learners in improving their writing skills by providing suggestions on sentence structure, grammar, and style (Lund et al. 2023; Wambsganss, Janson, and Leimeister 2022). However, as more individuals leverage GenAI for writing support, concerns have arisen among educators that students might misuse GenAI as a shortcut, potentially undermining their human agency (Rudolph, Tan, and Tan 2023; Yu 2023).

Student agency is considered an active process of engagement and mastery over one’s learning (Hökkä, Vähäsantanen, and Mahlakaarto 2017). As a key aspect of deep learning experiences, it ensures that students actively engage with the content and feel accountable for their progress towards learning objectives (Stenalt 2020). When students excessively rely on GenAI to generate content for completing certain assignments, they may become less inclined to engage in independent thinking and problem-solving (Perera and Lankathilaka 2023). This lack of engagement can lead to a decrease in their ability to assess the accuracy, relevance, and ethical implications of the information presented, ultimately weakening their intellectual skills and critical thinking abilities (Chan 2023). In the face of concerns regarding overreliance on GenAI, many tertiary institutions prohibited the use of ChatGPT. This move partially adheres to the UNESCO guideline (2023) that emphasizes GenAI for education should be constructed with the protection of human agency at its core. However, entirely disregarding the use of GenAI and overlooking its potential benefits for students’ learning might be a deficiency.

While GenAI might have some potential negative effects on students’ agency, it also presents opportunities for their augment (Darvishi et al. 2024). For instance, the interactive feature of GenAI creates a highly engaging environment for students to take an active role in their learning by directing their inquiries. It is thus important to carefully consider how GenAI is integrated into education and to leverage its benefits. However, its connection to theoretical pedagogical frameworks has not been sufficiently explored, which presents significant challenges (Zawacki-Richter et al. 2019). Gimpel et al. (2023) advocate for a cautious incorporation of ChatGPT in course design, using it as a means to enhance, but not replace the role of educators during students’ learning process (see also Ali and Abdel-Haq 2021). In aligning with this perspective, lecturers should be reflexive about their learning goals for students, ensuring that they mesh with the transformative potential of ChatGPT to foster meaningful learning outcomes (Chan 2023). Furthermore, lecturers must thoughtfully consider how their assessment strategies can effectively gauge students’ performance, adapting to the evolving capabilities and expectations of learners in the age of AI (Rudolph, Tan, and Tan 2023; Shidiq 2023).

Apart from the challenges related to teaching practices, there could be differences in the way GenAI is integrated and utilized across various disciplines. According to Zawacki-Richter et al.’s (2019) systematic review, AI applications are more readily adopted and found effective in Computer Science and STEM teaching fields. Coding, data analysis, and algorithmic thinking are commonly taught in these fields, and they equip students to solve problems with AI assistance. In contrast, existing research is relatively deficient in exploring how AI applications can be effectively utilized to enhance students’ intellectual abilities in humanities and social science disciplines, which encompass critical thinking, interpretation, communication, and other skills that are central to these fields. In the non-STEM disciplines, the risk of students becoming overly reliant on AI-generated output is particularly significant. If students uncritically accept the output generated by GenAI without questioning its assumptions, analyzing its arguments, or personalizing it with their own perspectives and insights, they may inadvertently limit their intellectual growth and development. This could result in a superficial understanding of the subject matter, a lack of depth in analysis, and a diminished ability to form independent judgments and original ideas.

To address these concerns, this study is designed to investigate the ways by which GenAI might be properly integrated into education practices within non-STEM fields, such as humanities and social science disciplines. We have invited university faculties in these fields, asking them to consider using GenAI in their pedagogical practices and course designs. To meet their course design needs, a specialized GenAI application has tailored the base model of ChatGPT to better suit conversational interactions within an educational context. To find out whether or not the integration of GenAI is to augment students learning experiences that promote a higher level of understanding in these disciplines, the interaction between the AI system and students were documented. An analytical framework of student agency (Damşa et al. 2010; Ruohotie-Lyhty and Moate 2016) was utilized to delve into the extensive data collected. This framework enables us to understand how students exert control, make decisions, and take ownership over their learning process when interacting with GenAI. It also helps identify patterns and insights into the degree to which students demonstrate initiative, independence, and self-regulation during their learning journey while using GenAI. Through a semester-long teaching period, we aspire to understand and examine:

RQ1. What impact does GenAI have on students’ learning experiences?

RQ2. What’s the role of students agency in shaping their learning experiences with GenAI?

Specifically, the RQ2 opens up the inquiry to explore whether students actively learn through interactions with GenAI or passively rely on AI-generated outputs without learning. By answering these two research questions, we contribute to the understanding of the lessons learned from integrating GenAI into teaching practices in higher education.

# Student agency

Student agency is central to the process of self-regulated learning (SRL), denoting how students regulate, control and monitor their learning as they progress towards mastery (Biesta and Tedder 2007; Eteläpelto et al. 2013; Hökkä, Vähäsantanen, and Mahlakaarto 2017). It can manifest through actions, representing what students do, and in discourses, reflecting what students say (Lipponen and Kumpulainen 2011). From the perspective of social cognitive theory, intentionality is central to agency (Bandura 2001). At its core, intentionality embodies the autonomy, goal-directedness, and reflective regulation inherent in agency. This is a central theme that researchers are delving into and analyzing why students engage with GenAI (Stenalt 2020). Specifically, these studies focus on how students deliberately choose to interact with GenAI, whether they have clear objectives for using GenAI, and how they reflect upon and adjust their conversational strategies to more effectively leverage GenAI for learning and development. Accordingly, the examination of student ageny could enable a more nuanced analysis of how they navigate this technology during the SRL process.

Prior to choosing the appropriate analytical framework for studying how students initiate their learning activities with GenAI, it is essential to have a solid understanding of the role that student agency plays in shaping these activities. The theory of knowledge creation (Paavola and Hakkarainen 2005) might shed light on such interactions. Learning, from the perspective of knowledge creation, is the process of acuring new knowledge through the process of collaborative activities. Individuals with a stronger sense of agency are more likely to participate in productive collaborative activities aimed at the creation of shared knowledge objects. Within this view, GenAI appears to function as a learning companion for students through its conversational ability. Unlike typical search engines, GenAI not only gives students access to a wide range of informational resources, but is also capable of synthesizing them in response to students’ input (Darvishi et al. 2024). It is reasonable to infer that students with a lower sense of agency tend to predominantly consume AI-generated content (AIGC) in a passive manner, whereas those with a greater sense of agency are more likely to actively apply their judgment, intentions, and creativity to steer AI in producing original and relevant output.

A conceptual framework offered by Damşa et al. (2010) positions agency as knowledge- and process-related actions exerted by individuals in the context of above mentioned collaborative activities. The former focuses on the creation of knowledge objects. The interchange of knowledge among individuals involved is brought to light in this aspect, which culminates in the development of new insights or ideas. The later dimension pertains to the knowledge production process itself. At the core of this aspect lies individual intentionality, which manifests in purposeful, goal-oriented behaviors steering the trajectory of collaborative interactions and ultimately impact the quality and originality of the knowledge produced. This two-dimensional framework for articulating agency helps us achieve a comprehensive understanding of student interaction with GenAI by focusing on two distinct aspects: the end products of their engagement (knowledge objects) and the ways by which they engage (generation processes).

By adopting this analytical framework, we aim to gain deeper insights into the spectrum of student behavior, differentiating between those who merely consume AIGC passively and those who actively participate in shaping and steering the AI’s output during the learning process. This understanding enables us to explore the potential influence of these varying degrees of engagement on students’ learning activities they initiated with GenAI.

# Methodology

# Research design

In our investigation into the phenomenon of college students using GenAI tools in academic writing, we adopted a research design that capitalized on the integration of GenAI into a university course setting. Two professors from the social sciences and humanities fields, identified through our professional network, volunteered to participate. Their specific course – Ethnography over a six-week period was selected for two reasons. One is its significance in sociology (Hamilton, Smith, and Worthington 2008). And the other is that the course could allow for a dual assessment: evaluating the quality of students’ academic writing and their mastery of the methodology. The course assignment involved students conducting autoethnographies – self-reflexive narratives of their educational journeys.

The course provided students the opportunities to employ GreatGPT (pseudonym to protect research integrity), a GenAI tool featuring a user-friendly conversational interface similar to ChatGPT, powered by the GPT 3.5 language model. Students were allowed to retrieve relevant content and simulate discussions based on a collection of ethnographic readings assigned by the professors, as well as supplementary documents that students could optionally add themselves. Additionally, GreatGPT’s answers are based on text-based literature, and it cites the source while providing answers (see a snapshot from its interface, Figure 1). Adhering to the guidelines proposed by Gimpel et al. (2023) for incorporating ChatGPT into course design, the intervention was limited strictly to the introduction of GreatGPT without any additional manipulations.

![](img/340ce1019e426f18cd1a8a6fde52c2a9877fee687e0bf43247bf24bf8cac9a6a.jpg)  
Figure 1. A snapshot of GreatGPT’s interface. Note: To maintain research integrity, we respectfully included an image of the tool’s interface while masking any commercial branding. The GenAI tool was used by the students throughout the study in Chinese. For the ease of reading, the student’s conversations with the GenAI have been translated into English.

# Participants

Seventy-four postgraduate students enrolled across three universities consented to participate in the study after signing the informed consent forms, all of whom were registered in the courses taught by the two volunteer professors. A summary of the universites and participant demographics can be found in Table 1.

Table 2 provides descriptive statistics of the whole sample. University A stands out with the highest proportion of female participants and research experience, while University B leads in AI exposure. University C, on the other hand, has lower means in both female proportion and AI exposure compared to the other universities, and it also registers the lowest average research experience. Overall, AI mastery levels of students are quite similar across the three institutions, although University B shows a slightly higher average than the others.

# Data collection and analysis

To address the first research question, we gathered data through two collection approaches. Firstly semi-structured interviews were conducted both pre- and post-course, probing participants about their expectations before using GenAI, their experiences and reflections after engaging with GenAI, and their envisioned future applications of the GenAI technology. Here are some exemplar interview questions:

1. What is your expectation on GenAI?   
2. What is your experience with and reflection on GenAI?   
3. How do you position GenAI in your learning process?   
4. Do you think GenAI will change the patterns of study?

Second, we encouraged students to maintain reflective journals during the AI usage period, which chronicled their ongoing thoughts and experiences. As part of the free AI access agreement, students voluntarily submitted usage reports if they used the tool. These reflective journals served a dual purpose: stimulated continuous introspection on the suitability and impact of AI usage, and simultaneously promoted responsible and ethical engagement with the tool by justifying their AIrelated actions.

In order to tackle the second research question, we collected and analyzed two sets of data. The first part consisted of student assignments, specifically knowledge objects co-generated with the GenAI, which were evaluated by their instructors and categorized into three levels: limited, moderate, and advanced. The second data involved dialogue logs between students and the GenAI. These interaction records were collected only after obtaining students’ consent. Within this dataset, we identified two primary modes of knowledge production process: proactive and reactive actions. Specifically, proactive actions denote situations where students actively applied their critical thinking and decision-making to direct and shape the AI’s responses, essentially steering the course of its output according to their intentions. On the other hand, reactive actions represent the more immediate, reciprocal reactions from students in response to the AI’s outputs; that is, the actions taken by students in reaction to what the AI presented or suggested, rather than preemptively influencing it. Our analytical approach was to integrate these two dimensions to collectively portray the diverse learning activities exhibited by students as they used GenAI for learning, thereby mapping out how their sense of agency influenced these activities.

Table 1. A summary of research sites and participants.   

<html><body><table><tr><td colspan="2">University A</td><td>University B</td><td>University C</td></tr><tr><td>Characteristicse</td><td>A nationally recognized key university (985 Project)</td><td>A well-established university within its regional context</td><td>A regular university</td></tr><tr><td>Location</td><td>A prominent urban center.</td><td>A prominent urban center.</td><td> An inland area</td></tr><tr><td>Teacher participants</td><td>n=1</td><td>n=1</td><td>n=1</td></tr><tr><td>Student participants</td><td>n =25</td><td>n=21</td><td>n=28</td></tr></table></body></html>

<html><body><table><tr><td colspan="4">Sample</td><td colspan="4">University A</td><td colspan="4">University B</td><td colspan="4">University C</td></tr><tr><td>Sample Size</td><td colspan="4">74</td><td colspan="4">25</td><td colspan="4">21</td><td colspan="3">28</td></tr><tr><td></td><td>Mean</td><td> SD</td><td>Min</td><td>Max</td><td>Mean SD</td><td>Min</td><td>Max</td><td>Mean</td><td> SD</td><td>Min</td><td>Max</td><td>Mean</td><td> SD</td><td>Min Max</td></tr><tr><td>Female</td><td>0.66</td><td>0.48</td><td></td><td></td><td>0.72 0.46</td><td></td><td></td><td>0.52</td><td>0.51</td><td></td><td></td><td>0.71</td><td>0.46</td><td>:</td><td>1</td></tr><tr><td>Research Experience</td><td>0.53</td><td>0.5.</td><td></td><td></td><td>0.72 0.46</td><td></td><td></td><td>0.48</td><td>0.51</td><td>:</td><td>11</td><td>0.39</td><td>0.5</td><td>:</td><td>1</td></tr><tr><td>AI Exposure</td><td>1.42</td><td>1.29</td><td></td><td></td><td>1.52</td><td>1:12</td><td>114</td><td>1.81</td><td>1.57</td><td>:</td><td>6</td><td>1.04</td><td>1:14</td><td>:</td><td>6</td></tr><tr><td>ChatGPT Exposure</td><td>0.49</td><td>0.5</td><td></td><td>11614</td><td>0.48</td><td>0.51 02</td><td>13</td><td>0.57</td><td>0.51</td><td>01</td><td>13</td><td>0.43</td><td>0.5.</td><td>01</td><td>1</td></tr><tr><td>AI Mastery</td><td>2.26</td><td>0.64</td><td>01</td><td></td><td>2.28</td><td>0.46</td><td></td><td>2.43</td><td>0.6</td><td></td><td></td><td>2.11</td><td>0.79</td><td></td><td>4</td></tr></table></body></html>

# Findings

# RQ1: what impact does GenAI have on students’ learning experiences?

Upon learning that the GenAI tool would be introduced in their class for free use and could be utilized to support their coursework assignments, most of the students expressed a significant amount of enthusiasm and excitement, as indicated by the feedback received from the instrutors. Drawing from their pre-course interviews, the primary driver behind this anticipation was the influence of media coverage and reports, which instilled high expectations among the students. Many of them believed that GenAI, particularly ChatGPT, would undoubtedly prove to be a valuable asset in their learning endeavors. For instance, student Liu (We used pseudonyms for all participants) said, ‘GenAI is a tool that I haven’t used before, but I am very excited to learn that it will be used in our class and help us with our coursework.’ Similarly, Zhong stated, ‘The capabilities of ChatGPT have been extensively covered in the media, and I am sure that this tool will make a big difference in how we learn.’

During a six-week period in which GreatGPT was integrated into their educational journey, our student participants reported several advantages resulting from the utilization of GenAI. The improvements in learning efficacy of the subject matter were notable. For instance, student Ku reported, ‘It (GreatGPT) is capable in a quick retrieval of pertinent information, which greatly increased my efficiency and speed when processing academic materials.’ Unlike traditional search engines, GreatGPT is not only gives students access to a wide range of informational resources, but is also capable of synthesizing them in response to the students’ questions and ideas. So student Lu wrote such in her reflection:

I think one of the most powerful functions of GPT is that it has a strong capability to summarise learning materials. It can quickly summarise the main ideas and research logics of the articles, which greatly shorten the time of reading literatures.

Many students also highly appreciate the conversational feature of GreatGPT as a key part of making the learning process more enjoyable. For instance, student Shi said, ‘Reading academic literature is not fun, but chatting with the GreatGPT fostered a sense of shared reading, making the experience much more interesting.’ Several students also pointed out to the emotional empowering role of the AI tool. As student Luo shared in the reflection:

Before [GreatGPT], writing was a tortuous process for me … The process of writing was lonely and I hoped people talk to me all the time. GreatGPT’s conversational feature satisfied my needs. … It accepts all my questions and encourages me. It makes me feel that I am not writing alone.

While at the initial phrase of the course, many students’ positive experiences were largely predicated on the perceived utility of GenAI, a marked decline in their satisfaction emerged as the course progressed. Around the later phrases, the students expressed that GenAI had a rather limited impact on enhancing their proficiency in academic writing. For instance, one student pointed out that GreatGPT can only read the text, but fails to read beyond the text. The student listed several areas where GreatGPT falls short, including its inability to discern and interpret the historical background behind the text, the logical links between/among texts, and the emotional outpourings within and behind the text.

Regarding their expectation that GreatGPT would assist them in their writing, even when they fed it relevant reference materials, the students observed that the content generated by GreatGPT remained superficial. Many students reflected on that GreatGPT seemingly fails to capture the depth and complexity required for higher-level academic writing, despite having access to pertinent sources. It also fails to deliver outputs that met the students’ expectations in terms of creative or critical writing. As one of the students, Xiao commented:

I told it (GreatGPT) to write something, but it didn’t seem to really understand of the substance of the content I desired to be produced. I have a strong suspicion that it only performs some kind of shallow reading of literatures that are presented.

As indicated by the amount of reflective journals we received, it looks like some students have ceased using GreatGPT near the end of their writing process. This sentiment was reflected in the findings of post-course interviews, which revealed that they engaged minimally with GreatGPT as the course progressed, eventually giving up its use when they felt that it did not significantly assist them in their academic writing performance. Student Peng expressed during the interview:

I found that it (GreatGPT) is not quite as intelligent as ChatGPT. I was disappointed by its responses to my writing requests. Even so, it’s worth noting that ChatGPT, despite its superior performance, couldn’t generate creative writing pieces for me either. However, it was useful in provoking some novel research ideas.

For those students who have worked with different GenAI tools, they voice more critical views regarding the intelligence and impacts of these tools. Student Hui raised the concern that an over reliance on GreatGPT in the learning process might potentially hinder the development of critical thinking skills as well as intellectual growth inside the learner. The student also suggested, for this reason, teachers might not know how well their students really understand, which makes it harder for them to give good advice.

Through this level of scrutiny, we found a spectrum of experiences that oscillate between negative and positive, largely depending on the students’ perception of the AI’s efficacy in fulfilling their learning needs. Nevertheless, this analysis alone cannot sufficiently illuminate how the ways in which each students engage with the AI impact the resultant experience. Hence, to gain deeper insights, we adopted the conceptual framework put forth by Damşa et al. (2010) to investigate student engagement with GPT in a more nuanced manner, ultimately aiding us in answering our second research question.

# RQ2: what’s the role of students agency in shaping their learning experiences with GenAI?

For analytical purposes, we empirically investigate student agency by studying its observable elements; that are, the assignments they submitted and the converstaions they initiated with the GreatGPT. By examining the two-dual aspects of student agency within Damşa et al.’s (2010) framework – encompassing the knowledge objects generated by students (the knowledge dimension) and their interactive dialogues with GenAI (the process dimension), we classify student learning experiences into four main categories: resistive, receptive, resourceful, and reflective learning approaches. Hereafter, we provide an narrative description of each learning category.

# Resistive learning approach

In this learning pattern, students predominantly expressed resistance towards GreatGPT due to their skepticism. Student Sun shared how they tested the trustworthiness and validity of the information GreatGPT provided.

I once asked GreatGPT the dean of our faculty, who was an influential person in the field. However, GreatGPT said he did not know … Later, I consulted GreatGPT some statistics questions and it provided wrong answers to me [again]. The wrong answers it provided make me doubt about its trustworthiness.

Similarly, Jing wrote in her reflection:

At the beginning, I had great passion on it. After using it, I felt it was not that intelligent. Because I had very limited knowledge about this application, I was not able to explore more methods to experience its merits. I only used some basic functions of it. It did not help me produce new perspectives, nor new knowledge.

This highlights the connection between their skepticism and their knowledge deficit in evaluating and utilizing AI technologies effectively. We also observed that these students only used GreatGPT once in class during the second week when teachers arranged hand-on instructions for them. The background data also verified that they did not use GreatGPT after class. Considering GreatGPT as a useless tool, these students tended to diminish their inclination to use GreatGPT as an empowered resources in future learning pusuits.

# Receptive learning approach

In this learning pattern, students expressed interest in GreatGPT but showed little agentic power in human-technology relationship in the application process. Students exhibited a predominantly receptive attitude toward AIGC, meaning they were mainly consumers of the content produced by GenAI without questioning or assuming responsibility for the output. Instead of critically analyzing or manipulating the AI’s output to deepen their understanding, they tended to accept the information provided without much critical processing. As Qin wrote in his reflection:

When I first heard GPT, my reaction was like ‘wow, AI now can write papers!’ Before, I have never imagined that a Robot is capable of responding to my academic confusion. I was amazed that it would serve my needs. Generally speaking, I think it significantly promotes human learning. It would provide answers within seconds, which greatly shortened our time and reduced our efforts. I had used it to polish my article. I think it would significantly improve our academic outputs.

For Qin and other students in this learning pattern, on the one hand, they adopted receptive attitudes towards GreatGPT that it was a powerful learning tool; on the other, they became reactive rather than proactive learners with minimal engagement of personal, relational, and participatory resources.

# Resourceful learning approach

In this learning pattern, students showcased their resourcefulness by guiding GreatGPT to refine its output further, and strategically leveraged it to tackle more complex learning requirements set forth by their teachers. As Cao wrote in her reflection:

When I first used GPT, my expectation was that it would provide me with more comprehensive information and help me organize and refine the languages. I also expect it to do creative writing and provide fresh ideas. With more practice, I found that the instruction is the key to obtain the desired results and answers.

According to Cao, with more involvement, engagement, and practice of GreatGPT, she gradually learned that her agentic power is the key to the production of new knowledge. Our background data showed that students in this learning pattern learned to develop agency by asking meaningful what, how, and why questions. They were voluntarily embracing the new technology yet showed less reflexivity in the process of application. As Cao wrote further in her elaboration:

I was amazed that when I asked GPT to proofread my article, it had done much better job than me. It presented ideas in a much clearer and more concise way. It significantly improved the quality of my writing.

Believing GreatGPT to be a useful tool learning helper or learning guider, these students adopted a more active role by drawing on personal, relational, and participatory resources. Some students even showed agentic power by positioning GreatGPT as a learning companion for emotional support and solace. As Yu wrote in his reflection,

I learned from website that the number of counselling appointments significantly dropped with the emergence of ChatGPT. Why a language generative model can be so emotionally empowering for people? I tried it by myself and it was indeed good.

# Reflective learning approach

In this learning pattern, students embarked on a thought-provoking exploration process where they deeply engaged with GreatGPT by reflectively asking what, how, and why questions (see Figure 2). They were not just leveraging GreatGPT to serve immediate needs but rather refining their own thinking while guiding it to generate more relevant and personalized insights. For students in this learning pattern, GreatGPT was frequently positioned as a learning facilitator which was under the dominance of their agency. In these instances, the students assume the role of accountable learners, actively verifying the accuracy, relevancy, and originality of the GenAI’s output before accepting it as valid or useful. This reflects a higher level of engagement where students assert control over their learning process, ensuring that the AI serves their learning needs rather than accepting its outputs blindly. Hao wrote such in his reflection:

I think GreatGPT could be first positioned as a ‘listener’ in my study. By receiving my ideas and framework, it sorts out my thoughts. Then it could be regarded as a ‘knowledge extender’. That is, it continuously enriches my thoughts through the process of interactions with me.

For reflective learners, applying GreatGPT in learning was an actively mental process as well as a cognitive, motivational, and behavioral process. Compared with resourceful learning, reflective learners demonstrated more reflectivity and criticism in the application process of GreatGPT. On the one hand, they recognized the advantages of GreatGPT in learning by making the best use of it. On the other, they were deeply aware that in the human-technology relationship, human’s agency dominates the ways they interact and benefit from technology.

# Discussions and conclusions

In today’s educational landscape, students are increasingly being exposed to advanced AI technologies like ChatGPT. Our research findings show that students are eager to start using GenAI. Swayed by the extensive media coverage on GenAI, students were excited to learn how this cutting-edge technology will play a role in their coursework prior to the beginning of the course. During one methodology class (i.e. Ethnography), our participants were introduced to a GenAI tool (i.e. GreatGPT) and were encouraged to explore its utilities in the analysis and composition of academic literature. As part of the free GenAI access agreement, we asked students to maintain reflective journals recording their weekly usage and related thoughts if they chose to use the tool. Through an analysis of the reflective diaries that students kept while using GreatGPT, our research unveiled a wide range of viewpoints regarding its impacts as perceived by the students themselves. These views fell into three distinct categories: optimistic, skeptic, and pragmatic.

For students who espouse an optimistically beneficial view on GenAI’s impacts, they credit GenAI with greatly boosting their productivity by streamlining tasks such as text retrieval, text analysis, and text summarization. This streamlined process allows them to navigate and process large volumes of academic materials more efficiently. Additionally, they greatly value the conversational feature of the GenAI which turns reading and writing tasks into a more social activity by acting as a supporting companion that fights against the emotions of loneliness that come with these intellectual activities.

On the contrary, students who hold a cautiously skeptical stance regarding the impacts of GenAI argue that the technology has not yet demonstrated substantive utilities in academic work. In particular, when considering its performance in challenging tasks like interpreting intricate texts, spotting logical fallacies, and helping with creating well-organized and rigorous essay outlines, GenAI’s output becomes shallow, unreliable, and low-quality.

While there are strong disagreements about how useful GenAI is, some students adopt a pragmatically adaptive perspective toward its impacts. In order to make GenAI work for them, they teach it how to learn on their own. By working closely with GenAI to improve its responses, it promotes a collaborative relationship between humans and machines among them, mirroring the teamwork expected in many professional contexts today. This kind of pragmatic thinking emphasizes the instrumental nature of human-made tools. The adoption of this pragmatic mentality is associated with an increased likelihood of individuals seeking out knowledge about new technologies and developing their technical skills to obtain better outcomes (Zawacki-Richter et al. 2019).

![](img/0c4f56152731e1a211e48d91f094262d75d2739e56c5a4a652dc4f292c69b2ee.jpg)  
Figure 2. Examples of students’ usage prompts reflecting receptive, resourceful, and reflective learning.

Our research further investigates and elaborates on the tripartite perspectives of optimism, skepticism, and pragmatism, which reflects students’ distinctive ways of incorporating GenAI into their learning processes. By examing students’ chat logs with GenAI, our research shows that these viewpoints extend beyond the typical TAM model (technology acceptance model; Davis 1989) metrics of tool utility and usability. A key aspect related to these themes is the level of student agency they demonstrate when interacting with GenAI technology in their learning paths. Student agency signifies the fundamental capacity to act autonomously, make responsible decisions, and take charge of their educational paths, all of which shape their learning experiences (Darvishi et al. 2024; OECD 2018). Drawing from Damşa et al.’s (2010) conceptual framework, our study has uncovered four distinct categories of learning approaches that are characterized and driven by the manifestation of student agency.

Students in both the receptive and resistive groups only interacted with GenAI superficially throughout the course, especially towards the end; this is shown by their sparse journal entries and infrequent interaction logs. Nonetheless, the distinguishing feature between these two categories arises from the contrasting strategies while they are working on their assignments. For students involved in receptive learning activities, they directly embraced GenAI’s generated content, integrating it blindly into their homework tasks, which resulted in discernible parallels between their submissions and the AI-generated output. This finding aligns with widespread concerns, highlighting the issue of research integrity and plagiarism in writing (Lund et al. 2023). Conversely, students demonstrating resistive learning behaviors expressed dissatisfaction with the quality or relevance of GenAI’s contributions, thus they made the dicision to refrain from exploring the tool any more in an effort to serve their learning needs. Research shows that skepticism about technology’ s practical utility drives some to reject it (Rudolph, Tan, and Tan 2023; Wang, Liu, and Tu 2021). The use of diverse training databases is evidence of the recent focus on improving product designs and services, such as GenAI tools for academics and educators (Pavlik 2023). It is noteworthy that no further evidence to suggest significant differences in the academic performances among these two groups of students.

In contrast to the previous discussion, our study discovers that among students who exhibit higher levels of academic performance in their assignments, there is a notably increased frequency of GenAI usage. We have further delved deeper to distinguish between two learning experiences: resourceful and reflective. Students in the resourceful group exemplify a goal-oriented learning approach that taps into GenAI resources. By adjusting their prompts, students show that they have mastered the knowledge of strategically using GenAI. The ‘what’ queries that appear most frequently in their prompts indicate a concerted attempt to find answers or solutions through GenAI. This pattern of inquiry can be viewed as a characteristic of their shrewd and pragmatic use of GenAI, where efficiency and speed are prioritized in their learning approach. The thoughtful and efficient application of GenAI by resourceful learners is consistent with research that highlights the significance of adjusting to new technologies in order to achieve improved performance (Wambsganss, Janson, and Leimeister 2022). On the other hand, the reflective group students interact with AI in a manner that is marked by profound introspection. They integrate GenAI into their self-assessment practices, scrutinizing its outputs and examining how these contribute to their understanding of the topic at hand. Their reflective diaries contain critical thoughts about how AI-generated content extends their thinking, the reliability of the information provided, and the strategic ways in which they assimilate these insights into their scholarly endeavors. These reflective learning practices dovetail with today’s technologically advanced learning landscape that advocates for integrating technology to deepen learning and foster autonomous, lifelong learning competencies (Yu 2023).

Overall, this study offers an avenue for students to introspectively explore the practical usage of GenAI and sheds light on its impacts through their own perspectives. This investigation allows us to identify and categorize the learning activities initiated by students rooted in their agency. The significance of this study lies in its contribution to understanding how students with varying levels of agency interact with GenAI and adapt it to their academic pursuits. If GenAI is brought into higher education, it is intended that students will take responsiblity for their work, question assumptions, synthesize information from various sources, and come to conclusions that are well-reasoned instead of rushing to find quick answers or solutions (Shidiq 2023). However, the research has limitations, notably concerning sample size and diversity, as well as the specificity of the AI tool (i.e. GreatGPT) and learning contexts examined. Despite these constraints, the findings offer valuable insights for future research and practice. The importance and necessity of supporting and empowering student agency in order to optimize the application of GenAI in education is brought to light by this. Future studies should broaden the scope to encompass a wider array of AI applications, investigate their long-term impacts on students’ academic progress, and inspries educators to recognize and value their students’ autonomy and creative ways of using GenAI tools.

# Disclosure statement

No potential conflict of interest was reported by the author(s).

# Funding

This work was supported by National Social Science Fund of China [grant number 22BMZ093].

# References

Ali, M., and M. K. Abdel-Haq. 2021. “Bibliographical Analysis of Artificial Intelligence Learning in Higher Education: Is the Role of the Human Educator and Educated a Thing of the Past?” In Fostering Communication and Learning With Underutilized Technologies in Higher Education, edited by M. B. Ali and T. Wood-Harper, 36–52. Hershey, Pennsylvania: IGI Global.   
Bandura, A. 2001. “Social Cognitive Theory: An Agentic Perspective.” Annual Review of Psychology 52: 1–26. https://doi. org/10.1146/annurev.psych.52.1.1.   
Biesta, G., and M. Tedder. 2007. “Agency and Learning in the Lifecourse: Towards an Ecological Perspective.” Studies in the Education of Adults 39 (2): 132–149. https://doi.org/10.1080/02660830.2007.11661545.   
Bommasani, R., D. A. Hudson, E. Adeli, R. B. Altman, S. Arora, S. V. Arx, M. S. Bernstein, et al. 2021. On the Opportunities and Risks of Foundation Models. ArXiv (Cornell University). https://doi.org/10.48550/arxiv.2108.07258.   
Chan, C. K. Y. 2023. “A comprehensive AI policy education framework for university teaching and learning.” International Journal of Educational Technology in Higher Education 20 (1): 1–25. https://doi.org/10.1186/s41239-022-00368-0.   
Damşa, C. I., P. A. Kirschner, J. E. B. Andriessen, G. Erkens, and P. H. M. Sins. 2010. “Shared Epistemic Agency: An Empirical Study of An Emergent Construct.” Journal of the Learning Sciences 19 (2): 143–86. https://doi.org/10.1080/ 10508401003708381.   
Darvishi, A., H. Khosravi, S. Sadiq, D. Gašević, and G. Siemens. 2024. “Impact of AI Assistance on Student Agency.” Computers & Education 210: 104967. https://doi.org/10.1016/j.compedu.2023.104967.   
Davis, F. D. 1989. “Perceived Usefulness, Perceived Ease of Use, and User Acceptance of Information Technology.” MIS Quarterly 13 (3): 319–40. https://doi.org/10.2307/249008.   
Eteläpelto, A., K. Vähäsantanen, P. Hökkä, and S. Paloniemi. 2013. “What is Agency? Conceptualizing Professional Agency At Work.” Educational Research Review 10: 45–65. https://doi.org/10.1016/j.edurev.2013.05.001.   
Gimpel, H., K. Hall, S. Decker, T. Eymann, L. Lämmermann, A. Mädche, R. Röglinger, et al. 2023. Unlocking the Power of Generative AI Models and Systems Such as GPT-4 and ChatGPT for Higher Education: A Guide for Students and Lecturers (No. 02-2023). Hohenheim Discussion Papers in Business, Economics and Social Sciences. Retrieved July 29, 2023 https://www.econstor.eu/bitstream/10419/270970/1/1840457716.pdf.   
Haleem, A., M. Javaid, and R. P. Singh. 2023. “An Era of ChatGPT as a Significant Futuristic Support Tool: A Study on Features, Abilities, and Challenges.” BenchCouncil Transactions on Benchmarks, Standards and Evaluations 2 (4): 100089. https://doi.org/10.1016/j.tbench.2023.100089.   
Hamilton, M. L., L. Smith, and K. Worthington. 2008. “Fitting the Methodology with the Research: An Exploration of Narrative, Self-study and Auto-Ethnography.” Studying Teacher Education 4 (1): 17–28. https://doi.org/10.1080/ 17425960801976321.   
Hökkä, P., K. Vähäsantanen, and S. Mahlakaarto. 2017. “Teacher Educators’ Collective Professional Agency and Identity – Transforming Marginality to Strength.” Teaching and Teacher Education 63: 36–46. https://doi.org/10.1016/j.tate. 2016.12.001.   
Lipponen, L., and K. Kumpulainen. 2011. “Acting As Accountable Authors: Creating Interactional Spaces for Agency Work in Teacher Education.” Teaching and Teacher Education 27 (5): 812–9. https://doi.org/10.1016/j.tate.2011.01. 001.   
Lund, B. D., T. Wang, N. R. Mannuru, B. Nie, S. Shimray, and Z. Wang. 2023. “ChatGPT and a new academic reality: Artificial intelligence-written research papers and the ethics of the large language models in scholarly publishing.” Journal of the Association for Information Science and Technology 74 (5): 570–81. https://doi.org/10.1002/asi.24750.   
OECD. 2018. Student Agency for 2030. https://www.oecd.org/education/2030-project/teaching-and-learning/learning/ student-agency/Student_Agency_for_2030_concept_note.pdf.   
Paavola, S., and K. Hakkarainen. 2005. “The Knowledge Creation Metaphor - An Emergent Epistemological Approach to Learning.” Science & Education 14 (6): 535–557. https://doi.org/10.1007/s11191-004-5157-0.   
Pavlik, J. V. 2023. “Collaborating with ChatGPT: Considering the Implications of Generative Artificial Intelligence for Journalism and Media Education.” Journalism & Mass Communication Educator 78 (1): 84–93. https://doi.org/10. 1177/10776958221149577.   
Perera, P., and M. Lankathilaka. 2023. “AI in Higher Education: A Literature Review of ChatGPT and Guidelines for Responsible Implementation.” International Journal of Research and Innovation in Social Science VII (6): 306–14. https://doi.org/10.47772/IJRISS.2023.7623.   
Rudolph, J., S. Tan, and S. Tan. 2023. “ChatGPT: Bullshit Spewer or the end of Traditional Assessments in Higher Education?” Journal of Applied Learning and Teaching 6 (1): 342–363.   
Ruohotie-Lyhty, M., and J. Moate. 2016. “Who and How? Preservice Teachers as Active Agents Developing Professional Identities.” Teaching and Teacher Education 55: 318–327. https://doi.org/10.1016/j.tate.2016.01.022.   
Shidiq, M. 2023, May. “The use of Artificial Intelligence-based Chat-GPT and its Challenges for the World of Education; from the Viewpoint of the Development of Creative Writing Skills.” Proceeding of International Conference on Education, Society and Humanity 1 (1): 353–7.   
Stenalt, M. 2020. “Investigating Links Between Students’agency Experiences in Digital Educational Interactions, Participation and Academic Performance.” In ASCILITE’s First Virtual Conference. Proceedings ASCILITE 2020 in Armidale, edited by S. Gregory, S. Warburton, and M. Parkes, 273–281. Armidale. https://doi.org/10.14742/ ascilite2020.0146.   
Wambsganss, T., A. Janson, and J. M. Leimeister. 2022. “Enhancing Argumentative Writing with Automated Feedback and Social Comparison Nudging.” Computers & Education 191: 1–17. https://doi.org/10.1016/j.compedu.2022. 104644.   
Wang, Y., C. Liu, and Y. F. Tu. 2021. “Factors Affecting the Adoption of AI-Based Applications in Higher Education.” Educational Technology & Society 24 (3): 116–29.   
Yu, H. 2023. “Reflection on Whether Chat GPT Should be Banned by Academia from the Perspective of Education and Teaching.” Frontiers in Psychology 14: 1181712. https://doi.org/10.3389/fpsyg.2023.1181712.   
Zawacki-Richter, O., V. I. Marín, M. Bond, and F. Gouverneur. 2019. “Systematic review of research on artificial intelligence applications in higher education–where are the educators?” International Journal of Educational Technology in Higher Education 16 (1): 1–27. https://doi.org/10.1186/s41239-019-0171-0.