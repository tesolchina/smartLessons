# Generative AI in first-year writing: An early analysis of affordances, limitations, and a framework for the future

Robert E. Cummingsa,\*, Stephen M. Monroeb, Marc Watkins b

a University of Misssippi, 106 Hill Hall, P0 Box 1848, University of Misssippi, University, MS, 38677-1848, USA b University of Mississippi, USA

# ARTICLEINFO

# ABSTRACT

Keywords:   
Generative artificial intelligence   
First-year composition   
ChatGPT   
Elicit   
Fermat   
Wordtune   
DEER Praxis

Our First-year Writing program began intentional student engagements with generative AI in the fall of 2022. We developed assignments for brainstorming research questions, writing counterarguments, and editing assistance using the AI tools Elicit, Fermat, and Wordtune. Students felt that the tools were helpful for finding ideas to get started with writing, to find sources once they had started writing, and to get help with counterarguments and alternate word choices. But when given the choice to use the assistants or not, most declined. Generative AI at this stage is unreliable, and many students found the tradeoff in reviewing AI suggestions to be too time consuming. And many students expressed a preference for continuing to develop their own voices through writing. Our experience in engaging AI led to the creation of the DEER praxis, which emphasizes defined engagements with AI tools for specific purposes, and generous use of reflection.

# Background

Even if you are  writing teacher who is not particularly concerned about the influence of technology on writing, 2023 was a year no one will forget. It was the year that everyone in higher education sat up and took notice of generative AI.

For many decades the personal computer has been playing a growing role in writing text via word processors. Before November 2023 and the arrival of ChatGPT, the approach to helping humans writetext with word processors has been framed as \*automated writing assstance' with tools grouped into three main categories spellchecking, grammar checking, and style checking (Dale & Viethen, 2021). Even as late as 2021, computer programs were incrementally improving additional tols for writing asstance. These toos included sentence completion technologies such as Google's Smart Compose (Chen et a. 2019), ften found in word processors, email applications, and mobile texting applications.

With the arrival of ubiquitous generatie atficial intelligence in 2022-23, however, it smed as natural language processing had moved our writing ools from the realm of providing assistance for human writers to becoming writers themselves. Or, to use the terms of artificial intelligence researchers, writing tools appeared to have made exponential progress toward the goal of acting as rational agent (Russell & Norvig, 2022).

The three authors of this esay, like most of the readers of this text, are heavily invested in helping their students engage digital writing tools to reach their best outcomes. We teach composition and rhetoric in a large department responsiblefor writing and speech courses at the University of Misssippi: an R1, SEC, flagship university in the US with an enrollment of some 23,000 students.

Ours is an independent department formed through a separation from an English department, as part of the broader trend and context at the national level (Chapman et al., 1995; Thais & Whithaus, 2016). Also, like many independent departments of writing, the condition of our creation was a continuous self-improvement plan in our application for reaffrmation of accreditation with a regional academic accreditation agency. Our student, faculty, and administrative communitie came together to write a document that serves as a constitution for our department to this day. The teaching and learning of this community is fundamentally paired with the foundations of composition theory, and explicitly connected to the Council of Writing Program Administrators as published in 2000 (Behm & Glau, 2014).

In April 2022 we noticed the presentation of Coauthor at the April 2022 Conference on Human Factors in Computing Systems in New Orleans (Lee et al., 2022). In May of 2022, we began experimenting with generative AI applications built upon GPT-3 and other Large Language Models (LLMs). After a few days of experimentation, we formed an AI Working Group in the Department of Writing and Rhetoric.

Our Working Group began meting each week during the summer of 2022. We explored various tools, remediated our (then) shallow knowledge of AI as field, and debated the coming implications for language instruction (and education more broadly). It was a wonderful and engaging summer. The team decided to pilot the use of generative AI tools in the coming fall (2022) semester.

Moving forward so quickly was, in some ways, an unsettled decision. Our working group worried about potential problems. Pri marily, the technology seemed to change every few days. We could not be sure in June how generative Al tools would perform in September. Additionall, there were no pedagogical precedents for teaching with generative Al. How would students react to the introduction of generative Al? How could we introduce these powerful technologies in a responsible way to developing writers? Might we overwhelm them? Might we disrupt their learning? Our worries were exacerbated when we realized that even LM creators and experienced researchers in the field of AI seemed surprised by the outcomes being generated by LLMs. As Sam Altman of OpenAI admitted in 2023, "Do we understand everything about why the model does one thing and not another thing? Certainly not. Not always. But I would say we are pushing back like in the fog of war (Altman, 2023). If the crators of ChatGPT did not fully understand the technology and its linguistic outputs, should those of us in education pause before introducing the technology to our students? Furthermore, at the time, we had no policies, guidance, or research from our intitutions or professional organizations. Our best pedagogical tarting point was our common practices stemming from the departmental origins, roted in the WPA Outcomes statement of 200. Our Working Group worried, but we pressed ahead, trying our best to design responsible ssignments for the coming fall semester. We knew that we needed develop a clearer theoretical framework for teaching with generative AI and a praxis that extended that awareness.

# Our theoretical frameworks and the DEER praxis

Our team of composition faculty devised an approach to engaging generative Al that was framed by our training in composition scholarship, our experiences in teaching colege writing, our extensive engagement with digital writing technologies, and our shared values as writing teachers.

An emerging theoretical framework for teaching writing with generative AI

We knew our work would be collaborative from the outset. The rapidly emerging generative AI technologies were simply devel. oping too quickly for one faculty member to be able to identify, engage, diagnose, and plan lessons in response. As stated earlier, we started this teaching engagement in fall semester 2022, well before the release of ChatGPT in November 2022. In that roughly threemonth period before OpenAI launched ChatGPT, multipl forms of generative AI products were taking shape, and our faculty worked together to identify, catalogue, and evaluate their suitability for academic writing applications.

Our collaborative ethic has clear roots in composition theory. Our thinking, and our practices, have been shaped by works such as Kenneth Bruffees Collborative Learning the curricula of the department's courses and the assinments within those courses are formed through the discourse communities of faculty teams. When Bruffe (1995) writes that \*knowledge is a social construct, a consensus among the members of a community of knowledgeable peers he describes the not only the epistemology of collaborative learning, but the organization of our Department of Writing and Rhetoric at the University of Misssippi (p. 3)

When thinking about the composition value of collaboration, we also engage more recent scholarship such as Mara Holt's Collaborativ leaning as democratic process A history (Holt, 2018). Holt's arument is that collaborative learning in writing classrooms is shaped by historical contexts. In particular, she addresses the current role of technologie i collaborative knowledge making. Our departmental perspectives includes deep familiarit and experience in teaching collaborative writing over networks via wikis and/or Wikipedia. And the aptitude for wiki technology to promote collaboration in writing pedagogy has certainly been documented (Lundin, 2008). As such, our department practices community responses to writing technologies almost reflexivel, eeking the ways in which we can use new developments in writing technologies to express understanding in community.

Responding to Holt's atention to the role f democracy in collaborative writing, we are working toward a future where our sense of collaboration leans more heavily on student input. The period of work described herein was very early in the development of wide. spread generative Al, starting as early as April 2022. Faculty selected the platorms and but we also explicitly empowered students to make choices as authors. But we envision a future when we work toward empowering students to research, evaluate, and select AI platforms for them and their clssmates. As Bruffe, Holt, and others have noted, cllaborative learning does not mean simply turning students into the wild, or placing them in groups and without creful design. Collaborative leaning requires intentional structure. We practiced these principles when engaging generative artificial intelligence by allowing student writers both the choice in whether to keep the outputs of generative AI, and reflective space to gather perspectives on AI and build metacognition.

Indeed reflection is another value roted in composition theory that works its way through the department as well as our AI as. signments. We did not consider reflection as part f an explicit asssment strategy, such as a part of a portfolio, as Kathleen Yancey researched in her landmark article placing porfolo asssment in the context of larger writig assessment trends (199). Instead, we looked to reflection for aditional values that Yancey and others have also researched, including the ability of reflective practices to provide separation between artifacts and their evaluation, and (hopefully) its abilit to encourage transfer of learning (2019)

When studying the role of reflection in digital writing courses, Sam Hamilton assembled a database of 150 digital writing syllabi from collge level courses during 2010-2017 in an effort to better understand how teachers represented digital writing to students (Hamilton, 2019) In addition to finding that instructors of digital writing were overly reliant on assumptions about students' proficiencies in digital technologies, Hamilton also found that these courses \*underutilized directed reflection when providing students with instruction on the use of digital technologies." Reader, this was not our approach. We found that providing defined reflection space on the use of emerging generative AI writing technologies was fundamental to our students' writing health, and sense of well-being.

Hamilton also notes that the larger project of being digitall literate includes the ability to use and understand present digital technologies, as well as anticipate future digital technologies" (2019). When our faculty discussed the imperatives for engaging generative Al immediately, in the all of 2022 (even as the technologies were wildly iterating on a 72 hour cycle), we often discussed the fact that our students would hopefully wield an advantage in the marketplace of employment if they could identify some sort of orientation to generative Al. Al of us were witnessing the transition of these technologies into workplace productivity software (e., Ms Word, Google Docs), and we knew that two to three years hence our students would likely find even more workplace engagement with generative Al. Thus, we knew that the promise of transfer of learning, as encouraged by reflection, was an intentional part of our strategy of engaging generative Al in the first-year composition classroom. We could certainly envision the scenariof our students employing AI sills in the workplace as \*far transfer," as defined by Perkins and Salomon (1992), but we also knew that our students were developing skill with generative Al that would also affct their work in other college clsses - providing, perhaps, examples of near transfer." lthough we could not necessrily count on students having significant prior experience with generative AI writing technologie, we did structure our assignments so that student perspectives on these technologies and thir prior writing experiences could enable the conditions of transfer, as advised by Shepherd (2018).

Documenting transfer of learning remains challenging and contentious under ideal conditions (Day & Goldstone, 2012). Given that the technology we sought to measure was changing rapidly, and its impacts were poorly understood - even by its developers - we knew we had little hope to measure transfer of learning. It remained limited to discussion.

# DEER praxis

As this our theoretical framework began to be better understood, in parallel we developed a teaching praxis that losely incor. porated the required steps to teaching with an emerging technology in digital writing. Over time, our we defined our teaching ap proaches by the acronym DEER:

D Clearly define the stages of the project, and enumerate each stage's purpose in achieving SLOs;   
E For each stage, evaluate a specific generative AI technology to pair with the learning activity;   
E Encourage students to explore that specific generative AI technology for that stage;   
R Provide students with space for reflection.

Let's look at each stage more closely.

# Define

In order to engage an emerging digital writing technology effectively, we rely on definitions both on the assinment and technology side. Following our local understanding of writing proces, the overall writing proect must be defined in terms of genre. Next each the writing project is broken down in to smaller components, each with a goal that serves the overall assignment.

It is this component or stage definition that allows for a successfl integration with generative Al technology. For example, if the component stage is asking the writer to brainstorm new ideas for an argument paper, then the instructor can look for an Al ool that offers ffordances for brainstorming. f the component tage is asking the writer to summarize research for the purposes of a literature review, then the instructor can look for an Al tool that ffers affordances with summarization. As we explore later, writers will be trained to thoroughly review oututs. But the key to integrating the Al too into the writing roject starts with a clear definition of goals f that component stage. At this phase of their development, generative I tends to get lost and lose its efectiveness if asked to engage with a whole assgnment. We have found that if we narrow the scope of the engagement with a closely defined writing goal,providing more structure for both the writer and the algorithmic outputs, there is a greater chance at finding useful generative Al outputs.

# Evaluate

Based on this clearly understood definition of the writing project component, the writer and/or the writing instructor can evaluate potential AI generative writig platorms. As the reader wil se in the fllowing sections, Instructor Marc Watkins carefully selected three generative AI writing tols - Elicit, Fermat, and Wordtune - for individual stages of his students engagement with generative AI, based on an evaluation of the affordances of these platforms.

For instance, Elicit was chosen to help student writers in brainstorming research questions. Although the underlying model employed by Elicit was common to many platforms (OpenAl's GPT-3), the interface of Elict allowed students to not only explore ideas but also to expand their thinking by generating relevant questions and providing sources that could counter the writer's ideas. These affordances are very different from the question and answer format of other tols such as OpenAI's playground, and are tailored specifically to the invention stage of the writing project.

Who does the evaluation? In these early engagements with generative Al, it was the writing teacher who identified and evaluated potential l plaforms for their fit wit he overall witing proect. In future iterations of the assinment, as gnerative  ools become increasingly commonplace in commercial digital writing technologies it will be crucial to engage students in the identification, evaluation, and selection of generative AI tools for writing assignments.

# Explore

Once the writing stage has been defined, and the appropriate generative AI tool has been evaluated and selected, writers need to explore the tool. This is especially critical if students have not participated in the evaluation process for the tool.

For our work, exploration of the generative Al tool included four specific stages: (1) introduction of the tool; (2) low stakes engagement and orientation with the tol; (3) itting the ool's oututs i to the writr's goals for the project stage; and (4) evaluating the usefulness of the AI output.

The three different platforms engaged herein presented different challenges for each stage. For instance, students noted that Wordtune had a simple interface that presented just in time" suggestions this required littl orientation to the platform, ffered the ability to engage in low-stakes exploration of the tol, and allowed contextual evaluation of Wordtune's suggestions for the writer's project goals. In essence, Wordtune operated much like a technology with which writers already have a familiarity: sentence completion technologies.

# Reflect

A fundamental component of composition practice i reflection (Yancey et a., 2019). By engaging metacognition muscles, writers and teachers alike are able assess experiences and develop insights apart from the flow of drafting.

Reflection in the DEER praxis i essential on several levels for engaging emerging writing technologies. Writers will want to understand the tool from the perspective of its utility in reaching the goals of the writing project. If the writing task was brainstorming, did the too inroduce new ideas? Did i chllenge the writer's thinking by providing counter-arguments? Did the tol help the writer place ideas in the context of conversation with other ideas? Here the goals of the writing project defined in the first stage of the DEER praxis, can help writers and instructors alike in evaluation the application of the technologies to the writing project.

Many writers tended to structure their reflections to engage up to three aspects of the experience: the AI output, the interface, and the net benefit of using the tool. First, writers quickly learned that not all generative Al output could be trusted. All AI suggestions required review before it could be considered for their work. Second: writers were quick to consider whether or not the generative AI interface distracted from their composing proces. Last, during the reflection space most writers considered whether the engagement with the Al tool presented more problems rather than offering helpul advice. In all a recring theme for student reflections was the displacement of thir voice Like all writers, our students work hard toget their thoughts on \*paper," and many see generative AI as a potential silencing.

This framework and praxis helped to focus our experiments and reflections. We now see generative Al as a useful tol in the composition classroom, but only when deloyed ina retrained and scaffolded manner.Ful uman writing actvities wil remainvital to student motivation and learning. Large Language Models are an astonishing technological development, but our focus in compo. sition and rhetoric must remain on the more astonishing and inspiring development of human writers.

# Developing first-year writing assignments to engage Al

Our faculty took a design approach to early experiments with generative Al. Despite uncertainties around generative Al, our team of experienced teachers found stability by focusing on our students and on known truths about human composition and learning. We knew, for example, that developing writers would always need time and space to experiment with their own writing processes. No matter how fast an AI might produce a textual output, for human writers, practice would remain essential, \*and such practice takes time and effrt. (Yancey, 2015b, p. 65). So, we decided to throttle back the power of AI just a bit, to introduce firt-year writers to more focused tools like Fermat, Elicit, and Wordtune, while reserving the nearly unbridled power of ChatGPT for another semester. Silicon Vally might be in a frantic arms race, but good teaching would require slowing down and scaffolding assgnments.

Our approach to the fall 2022 pilots was also guided by other principle of composition pedagogy. We started, for example, with a shared respect for student autonomy as writers. Recognizing that our students would enter a professional world shaped by the affordances of Generative Al, we made the foundational decision to engage these emerging tols right away and very deliberatively (Little, 1991). Students would need to know as much as possile about Generative Al, and thus we needed to shft our composition classes now to create student engagement and deepen faculty experience. Our goal was to experiment responsibly with multiple and erging models of Generative AI, even if this made us a bit uncomfortable as teachers.

Additional fundamental composition values essential to our approach included the primacy of student reflection (Yancey, 1999) and collaboration (Bruffe, 1993). In each engagement with generative Al in the writing cassroom, we asked students to compose short reflective pieces giving voice to their reactions to the deployment of generative Al in their writing projects. These reflections often included notes of concern about the risk of loing authoria oice, as well as pessimism about the utilit of AI tols after writers learned the ned for constant verificatio of every AI utterance. Allof these engagements were based on principles of collaborative learning, as teachers and students engaged AI tools together.

After experimenting with many emerging generative AI applications, the Working Group decided to introduce our student to three during the 2022-2023 academic year: Elicit, Fermat, and Wordtune. We gathered faculty and student feedback, including more than 80,000 words of student rflections. We draw on this data and experience in the sections below to explore the pedagogical affordances and limitations of generative AI in the composition classroom.

# Elicit

Elicit is an Al assistant developed by Ought and designed as the first step toward a general reasoning assistant (Elict 2023). Elicit can help navigate open aes databases and develop focused research questions. At the time of our pilot Elicit utilized GPT-3, OpenAI's language model, to generate focused article recommendations related to the student's topic, research question discovery, and asst them in brainstorming counterarguments. Students input keywords and Elicit returns relevant, credible sources along with summaries and suggestios for intratig sources. Ky ffordances include rapid aces t vette sources, synthesied summaries nd an ease of discovery that enhances early invention and drafting (Fig. 1).

As a part of the first-year writing course, we developed an assignment for Elicit centering on brainstorming research questions (Watkins, 2023). This assignment guides students through utilizing Elicit's AI tool to asst in developing research questions on their topics. Students enter potential ideas into Elict's research question brainstorming feature. The AI generates questions for students to review. Students select promising questions, starring ones they may want to explore further. They then craft a research proposal combining their own words and ideas with the AI-generated questions. The proposal must meet specified requirements including a creative ite backround context aout the toic, an overarching rearch question, and related sub-questions. The reflection prompts students to analyze their experience using AI to formulate research questions.

The assignment exposed students to new perspectives and questions about their topics that they may not have considerec

# Brainstorm research questions

Input Uber and taxi services|

![](img/9d228da251ff198981961ca76e5cef1483dfa00133e920bd6369166860d25975.jpg)  
Fig. 1. Elicit in 2022.

independently. Elict's generative suggestions encouraged students to research with greater objectivity and an open mind, enhancing critical thinking and engagement with thir proposed research tracks. As one student put it, Elicit 'really opened up my mind into thinking about things that I hadn't before and finding out new information on the topic." The generative suggestions not only opened doors for students to explore research topics, but also guided them toward more structured questions. One of the most challenging pedagogical frameworks when teaching first-year students research questions is to avoid deterministic questions, or framing that suggested a biased response during the initial reearch phase. While Elict' brainstorming research question automated that portion of the research proces, it did not completely fflod that kill t the generative output. Students were encouraged to challenge, explore, and push back against suggestions they did not find helpful to their overall research path.

Elicit's suggestions not only aided students in formulating focused research questions, but also helped them anticipate counter. arguments, balancing their overall reearch. Once students completed thir open-ended research questions and allowed the evidence and arguments they encountered to shape their response, they were then able to use the sub questions produced by Elicit to help navigate what opposing opinions they might encounter their overal argument. Part of the ppeal of using Elicit is the design of the tool is not simply to support research, but to also augment the general reasoning ability of the user (Stuhlmiller & Byun, 2022).

While some students were initially confused by Elicit, many found it intuitive after experimenting with i briefly. Developing handson experience alowed students to grasp the value of this novel tool and encouraging them to explore it generative features through a structured assignment helped guide them in their discovery of what generative features they ultimately found helpful. The idea behind starting from a structured assignment and then graduall transferring responsibility to students to use the generative features within the AI tool is part of the AI literacy framework we attempted to impart to students (Watkins, 2023).

Indeed, one student enthusiastically clled Elicit"a great ool to have for allcollege courses going forward." Many expressed shock that such a tool existed and comments like ${ } " \mathrm { I }$ wish I would have known about this website earlier in my writing experience," were common among pilot participants. Elicit's brainstorming research questions task leveraged AI to make early academic research more efficient, targted, and thorough. The tool's capabilities in quickly generating releant materias and perspectives reduced friction for students, helping them construct more informed, objective arguments. Student reflections indicate Elicit meaningfully augmented and enhanced critical processes in their research and writing.

# Fermat

Fermat is an AI asstant that functions on a spatial canvas. We designed assignments using Fermat's various AI-powered ideation templates to help students brainstorm and explore potential counterarguments (Fermat, 2023). Like Elicit, Fermat's Al features used OpenAI's GPT-3 at the time of our pilot. We developed assignments to help students brainstorm and explore counterarguments within

# Brainstorming Exercise Instructions

# Thesis

Develop a thesis statement answering a prompt question.   
Include a short quote from the common read text.   
Generate opposing opinions that contradict your thesis.   
: Include your opinion about what connects your evidence with your thesis.   
: Generate a statement rebutting the opposing opinion

# Quote from the Text & Evidence Connecting to Thesis

For Nezhukumatathil, fireflies were a major part of her childhood, and continue to remind her of it. For her a single firefly can give her positive memories such as, "traveling to a gathering of loved ones dining seaside on a Greek island"(Nezhukumatathil 10). As a result, her observations of these insects act as a catalyst for good memories.

# Counterargument

The author neglects to mention any potential downside to this way of life. However, there are several potential downsides to this way of life. First, this way of life can be very isolating.People who live this way often find themselves cut off from the rest of society.This can lead to feelings of Ioneliness and isolation.Second, this way of life can be very expensive. People who live this way often have to spend a lot of money on things like travel and accommodation. This can make it difficult to save money. Finally. this way of life can be dangerous. People who live this way often put themselves at

Some often forget what is around them due to the business of the modern world, but for Aimee Nezhukumatathil, Yoruk Isik, and Gavin Pretor-Pinney, this is no challenge.For them enjoying seemingly mundane objects is the main event. They have all studied their mundane area of interest and managed to make something meaningful out of it, as well as better connect with their humanity and society.This all stems from observation which is a main tactic they use to fully take in the world around them

# Rebuttal

The potential downsides to this way of life are not as significant as the potential benefits. This way of life can provide people with a sense of freedom and flexibility that they would not otherwise have. It can also allow people to save money by living in a more efficient way. Finally, this way of life can be very rewarding and fulfilling.

the apps interactive canvas to support invention and critical thinking early in the drafting process (Fig. 2).

As a part of the frst-year writing course, we developed an assgnment for Fermat to help students develop counterarguments by leveraging Fermat's Al tool (Watkins, 2023). Students select a prompt and develop a thes satement. They find a quote from the text supporting their thesis. Students use the AI tool to generate opposing opinions contradicting their thesis. They explain how their evidence connect to their thesis, in light of these counterarguments. Students then use the AI tol to produce rebuttals against the counterarguments. They compile an outline with their own writing synthesized with the AI-generated content. The reflection prompts analysis of the value and limitations of using AI for counterargument exploration and critical thinking development.

However, unlike Elicit, student reflections reveal a spectrum of reactions to using Fermat's Al-powered writing assistant. While many students found it helpful for brainstorming and structuring their essays, others faced challenges with Fermat's spatial canvas interface and confusion over its AI capabilities. At its best, Fermat gave students scaffolds to invent thesis statements, consider counterarguments, and outline critical parts of their essy. The step-by-step prompts helped some students break down the writing process ito more manageable chunks. Yet, the tool's complexity and glitchy operation posed obstacles for others. Though the AI features aimed to generate ideas and text, some students preferred developing original thoughts over relying on the algorithmic suggestions. The interface appeared to matter just as much as the underlying technology in how students ultimately used the app. This suggests that pecific use cases for writers (Drake, 2023) need careful and thoughtul design considerations; otherwise, users may disengage from before calling upon AI assistance.

Similar to the Elicit experience, many students aw benefit in using the generative Al features to help them brainstorm potential counterarguments for their writing. The speed of generating outputs that responded directly to student's topics was shocking, often rapidy casing teching to shift fromworkshopping varous portions of the writing proces, t shifting to discssing the implicationsof what justoccurred and asking students to critically reflect on the benefits and limitations of such generative text totheir writing and learning. One key factor that helped slow the process down, was intentionally requring students to produce specific portions of the assignment with their own writing before calling upon generative AI through the app.

However, many students found Fermat's innovative user interface confusing or dificult to use at times. One student said, I personally don't like the [Fermat tool because it makes me angry when I acidentally delete[ed] my boxes and dont know how to get them back." The technical issues of working on a spatial canvas using a mix of generative Al and organic writing were quite overwhelming for some students. Others focused on technical glitches and expressed a general unease working outside of alinear user interface many students are accustomed to through traditional word processing programs. Whil this may appear as a negative for the tool, it actually shows that students carefully read outputs and thoughtfully and critically evaluated them for accuracy and stylistic choices. One of the chef complaints many scholars and designers have raised about ChatGPT's chatbot interface is that i offers users few affordances (Wattenberger, 2023), with littl input for humans outside of arepeated proces of prompting (Appleton, 2022). With Fermat's spatial canas, users constantly had to make decisions, providing direction and context for the generative features to function.

+ Rewrite Casual Formal ++ Shorten ++ Expand

This is a demo of the spices. I'd like you to provide some insight in how Al can help a maturing wriitng grow. $^ +$

![](img/80fd6859db2b08d0fd3007eb651bba48f31128d64d8a79cf3c14f423de5a9708.jpg)  
Fig. 3. Wordtune in 2023.

They likewise had to establish connections between their writig and the generative output by dragging boxes across the screen, some with their own writing and others with generated output. This put an increased cognitive load on many students, causing them to disengage from the assgnment prematurely. Ultimatel, many students preferred developing their own original ideas rather than relying too much on the AI.

# Wordtune

Because of these interface isues, we switched from Fermat to a more conventional interface called Wordtune during the Spring of 2023 (Wordtune, 2023). Wordtune is an AI revision tool developed by AI21 Studios that provides real-time editing suggestions as students write in a web interface similar to Google Docs. Al21 studios developed their own language model clled Jurassic 2to power a variety of Al features within their app they have branded as Spices. Each Spice sends a specific command to the Jurassic language model, allowing students to clupon explanation development, summarization, counterarguments, even statistical facts. Students write naturally within Wordtune, cling upon structured asstance when reaching apain point within their writing proces, which includes rphrasing advice through subtle highlightig. In addition to the Spices features, writing students used Wordtune to enhance sentence variety, correct grammar, and model effctive style choice. Students maintain authorial control to accept or ignore recommendations (Fig. 3).

Students found Wordtune's real-time editing suggestions very helpful for improving the clarity, conciseness and flow of their writing. The Al tool highlights potentially wordy or repetitive phrases and provides alternative ways to rephrase sentences. As one student observed, these features alowed them to "refine their ideas and express themselves more effectively." Another student explained how Wordtune's suggestions helped them shorten lengthy, convoluted sentences into clearer statements. Concrete examples like these show how the rephrasing and editing advice enabled maturing writers to communicate their thoughts in a more organized, understandable way.

In addition to refinement, the Wordtune's Al "spices" features gave students useful prompts to further develop their arguments and ideas. As one reflection explained, the spices provided "suggestions to expand, counterarguments, explanations, and facts/statistics Which helped the student "elaborate on their points and strengthen their esays." The spices sent specific commands to Wordtune's underlying Al, generating targeted recommendations to build on students' paragraphs. Rather than simply rewording, these spices added substantive content to aid students in delving deer into their analysis and reasoning. We encouraged students to use such features as needed and not be overly reliant on AI asstance in their writing process. As we noted in our pilos with both Elicit and Fermat, the app intrface design was major factor in predcting student I use, andWordtune's low barrier to aces the gnerative AI features appeared meaningful to many students using the tool as a writing aide.

Importantly, students maintained authorial control in choosing which suggestions to incorporate or discard. This prevented over. reliance on the Al and allowed students to keep their own voice and ideas. The abilit to accet or reject Wordtune's advice at will was crucial in ensuring students directed how the technology was utilized. This freedom and flexibilit with the tol was essential in enabling students to str their own writing rather than be led solely by the AI's recommendations. Employing an Al-enabled writing processer like Wordtune in this intance alowed for writers to use generative AI features when they hit a pain point in their writing process, augmenting existing skills and competencies instead of simply offloading them.

In the process of using Wordtune, some students found that the experience made them more atentive to aspects like sentence structure, word choice tone, and writing for an academic audience. Several student rflections described how Wordtune improved their editing and proofreading habits. The AI fedback shaped students' approach to writing in a more critical refined manner. However, some noted that overuse of Wordtune in early drafing stages could limit original thinking, and feared ffloading their thinking. Indeed, a fair number of student reflections discuss with candor a general fear of becoming deskilled by generative AI and electing to not use the tool out of this fear.

Yet, most students did not fel Wordtune fundamentally changed their writing process, but rather saw it as a beneficial aid for helping them getting unstuck. The reflections indicate students valued developing their own skills in planning, organizing, and developing ideas even as Wordtune offred helpful assistance. In this manner, the AI features of the tol did not replace human creativity and critical thinking, only supplemented it.

By seeing how the Al would rephrase their writing, students learned about strengths and weaknesses in their individual writing styles. This increased self-awarenes allowed students to improve their areas of elf-knowledge and discovery as writers and critical thinkers. Using the generative AIfatures in writing to learn contexts may be one of the most powerful and impactful use cases for the technology within education. Such instances help maturing writers spend more time exploring their thinking and imagination, and less on attempting to come up with a determinable right answer.

The dominate view among students was that Wordtune proved an effective tool for refining academic writing, but human guidance and effort remained essential to nurture true authoria voice and original perspecties. The reflections suggest the Al enriched the writing process without replacing the core human skills of imagination and analysis at the heart of composition.

# How did students respond to generative AI?

Based on our experience teaching with generative AI to date, we predict that AI adoption willikely not match the speed of deployment. On average, fewer than a quarter of students in Watkinss spring 2023 sections elected to use geerative AI tools once they were made optional outside of the structured assgnments we developed Lack of familiarity with generative Al writing tools causes reluctance among students and this number willikely increase once students become familiar with how these tools work or what they can do. Until then, many students appear hesitant to try them out. As one student reflcted I did not use an AI generators like ChatGPT or WordTune because I trust myself more to writ something than have an AI mis the topic I am writing about. The unknown capabilities of new technology can breed skepticism and prevent adoption unles students have hands-on experience to grasp the value. Direct exposure allows students to move past the initial unfamiliarity.

Concerns about authenticity also foster reluctance. One such insightful student reflected I have also noticed that using the AI decreases my particular style of writing. It is a trade off, which is why it is important to implement the tool, but only in moderation." Students may worr that using AIl tols to generate or refine their writing is not authentic to their own voice and ideas. They may feel reliance on artifical inelligence i like cheating" rather than doing their own original work. Maintaining an authentic uthorial voice is criticll important to student writers, because Al generated writing is exactly that. It is gnerated, and therefore, it is generic."

Fear of over-dependence can make students avoid generative writing tools. They could worry about becoming to reliant on AI to do the writing work for them rather than developing their own skils. Avoiding adoption altogether prevents this perceived risk of I takeover of the writing proces. Students want writing practice, not short-cuts I made a point to myself that I wouldn't go any further with using it, afraid I would get lazy and rely on it too much."

Many students value human feedback more than AI suggestions. They may see more benefit in dialogue about their writing with instructors and ers. The human connection matters greatly in the learning process.Generative tols are perceived as impersonal and disconnected from this nurturing environment. As one student thoughtflly reflecte, I also fel like when i generates it sounds way more mature and professional than my normal writing does. So I personally choose to avoid it because I am capable of writing my own papers and I go to the writing center and other resources to get more opinions and ideas as wellas good feedback."

If AI writing tools have a steep learning curve or glitches, this quickly frustrates students. The technology needs to integrate seamlessly into their workflow. When tools are unintuitive or prone to technical isues, it severely limits adoption. Smooth func. tionality is critical. Some tools do not allow students full contrl to aet or rect l sugestions. f students fel the technology is imposing changes rather than advising, they reject the tool altogether. Maintaining authorial agency is key in their willngness to utilize generative feature. This was expresed by anumber of students: T have tried using I to help write my paper but was not able to use it well.I did not like the paragraphs it created and I did not like the sources it provided. I really struggled figuring out how to navigate it. I ended up not using it to help write my research paper."'

Students also worr reliance on AI could lead to unoriginal writing. If they think tools limit imagination or result i inauthentic text. they resist adopting them. Plagiarism is a major concern surrounding AI content generation: I personall do not use the Al tol, it intimidates me slightly, so I haven't noticed a change in my witing because I dont use it.I am also always worried about not changing it enough from what it suggests that it is going to count as plagiarism and I don't want that."'

Allof these factors contribute o reluctance in adopting new AI writing assistants. Gaining familiaity and control seem to be key in addressing student skepticism and resolving those will take time. More than anything, time is what we need. Understanding student reluctant to adopt generative Al into their writing practice could buy educators the badly needed respite from the fire hose of AI deployment to develop their own proactive approaches to generative AI.

# Conclusion

Our earliestclassoom experiments, conducted in first-year writing classes in the fallof 2022 and spring of 2023, indicate divergences between the panicked presumptions about student adoption/abuse seen in the media during much of 2023 and the actual tentative and responsible experimentations observed in our students. We conclude that collge writers may not always be eager adopters of Al toos.Contrary to some public opinions, many of our students expressed concerns about losing authorial voice and being interrupted by AI during their writing processes. Other students expressed optimism about the usefulness of AI writing tools, particularly during the stages of invention and research.

In looking to the future we realize that the 2022-2023 period is a time of experimentation in the generative Al industry. Multiple teams of developers across the globe competed to release generative AI platforms and attract users with differing feature sets. Their frequent update also meant that the plaforms we chose could also change during our writing assgnments. But i this environment we found that developers were interested in our experience with students and would even reach out to us; our working group even hosted the Fermat developers to a Zoom in early 2023. However, we suspect that this time f relative creativity, diversity of platforms and openness among developers may eventually come to a close. As the market for generative Al writing tols continues to grow it wil likely consolidate in ways simila tothe market for spellcheckers and grammar checker. Many uers experiences willikely be defined by fewer generative Al tool. ols that are embedded with the larest ffice productivit tools are most likel todefine the experiences Of our future writers.

But even if there is consolidation in the generative AI consumer digital writing landscape, we believe that the DEER praxis wil flexibly accommodate new developments. For example, with the release of ChatGPT 4.0 in November 2023, users were given more choices in choosing the underlying database inputs to create a more customized experience (Heath, 2023). The DEER praxis would prove equall useful i the future of customized GP's in writing clasooms. Writing assinments would stil be defined according to narrower stages students and faculty would either evaluate off-the-shelf GPTs (like ChatGPT with Wikipedia) or create their own with a chosen dataet faculty and students would explore the outputs and students would reflect on their use. Hre the exploration phase of the DEER praxis becomes even more important, as writers are not software developers and cannot full evaluate the accuracy and usefulnes of the softwares they are creating on the fl. Thus the DEER praxis is flexible tool that can help writig teachers engage future digital writing tools. Even the praxis cannot provide detive valuations of the safety, acuracy, or usefunessof fuure dgital writing tools, it provides writing teacher and students plan for engaging the new tools.

Composition scholars and teachers value language more than most. We understand the primacy of words to human learning, identity, cognition, metacognition, expression, and more. As Kathleen Yancey said in 2015, \*writing is an activity and a subject of study." Humans ned writing to inquire, analyze, interpret, and, ultimately, make knowledge." (Yancey, 2015a, pp. xvii-xvii. Now, in 2023, there is more activity, and there is much more to study in the digital writing landscape. What wil be the implications of this unexpected technological developments? How will we continue to teach a thoughtul vision of digital literacy to enable and preserve the human voices of writers?

In addressing this project of teaching digital literacy, Sam Hamilton writes:

being digitall literate includes the ability to use and understand present digital technologies, as well as anticipate future digital technologies. If digital literacy is truly an integral component of global citizenship, and if teaching digital literacy is a global citizenship project, then both have to also emphasize the significance not just of knowing how to use already-existing technologies to reproduce already-circulating digital and multimodal genres of communication, but also of knowing how to learn how to use emerging digital technologies to newly produce disruptive and emerging genres of digital and multimodal communication (2019).

We believe that the approach we have developed and outlined herein puts our faculty and students in a strong position to learn how use the digital writing tools of the future and more fully participate in the global community Hamilton envisions.

Funding: This research did not reive any specific grant from funding agencies i the public commercial, or not-for-profit sectors. Declaration of Generative AI and AI-assted technologies in the writing proces: During the preparation of this work the author() used no generative AI tools, and received no AI asstance beyond tool for checking grammar and spelling. The authors take full responsibility for the content of the publication.

# CRediT authorship contribution statement

Robert E. Cummings: Conceptualization, Investigation, Project administration, Supervision, Writing - original draft, Writing - review & editing. Stephen M. Monroe: Conceptualization, Methodology, Writing - review & editing. Marc Watkins: Conceptualization, Investigation, Resources, Writing - original draft, Writing - review & editing, Visualization, Project administration.

Declaration of competing interest

None.

# Data availability

Data will be made available on request.

# References

Altman, S. (2023). Intrview with Lex Fridman. Lex Fridman Pocast #367. 13:25-13:45. Retried from htps://w.yuube.com/watch?=Luz73e6fw. Accessed March 25, 2023.   
Appleton, M. (2022). Reverse outlining with language models. The Garden. htps://maggieappleton.com/reverse-outline.   
Behm, N. N., & Glau, G. R. (2014). The wPA outcomes statement-A decade later. Parlor Press LLC.   
Bruffe, K. (1993. Colaborative learning: higher educatio, nterdependence, and the authority of knowledge. Baltimore: Jons Hopkins UP.   
Chaan ris .  . 199  c   f   314. doi.org/10.1080/07350199509359196 International Conference on Knowledge Discovery & Data Mining (pp. 2287-2295).   
Dale, R., Vithen, J. (2021). The matd witing asisace anape in 2021. Nl ange Egnerng 27, 51-518. tps:/oi.g/10.1017/ S1351324921000164   
Day, . toe, L. 012).h mrt f ke prt tin finn an thrief terf lg. io st, 473, 153-176.   
Drake M.23, ).   d   d.  r t/h/dadl.   
Elicit. (2023). https://elicit.org/. Accessed August 31, 2023.   
Fermat. (2023). https://fermat.app/. Accessed August 31, 2023.   
Hamilton, S. (2019). Reflection (s) in/on digital writing's hybrid pedagogy, 2010-2017. Computers and Composition, 52, 158-174.   
Heth,  2023.  i ing noe cr thr  f . he  /hee./202311/6/234857/cht-t custom-developer-platform Accessed December 15, 2023.   
Holt, M. (2018). Collaborative learning as democratic practice: A history. ncte. org.   
Le,   . tw  e ae n P 2022 CHI conference on human factors in computing systems (pp. 1-19).   
Little, D. (1991). Learner Autonomy, 86(11), 15-22. Dublin.   
Lundin, R. W. (2008). Teaching with wikis: Toward a networked pedagogy. Computers and Composition, 25(4), 432-448.   
Perkins, D. N., & Salomon, G. (1992). Transfer of learning. International Encyclopedia of Education, 2, 6452-6457.   
Russell, S., & Norvig, P. (2022). Artificial intelligence: a modern approach (4th ed, pp. 21-22). New York: Pearson..   
Shepherd, RP. 2018) Dig wtin, midty, and g tfer: Crin otions  ompsition nd in coming. ers and Composition, 48, 103-114.   
Stuhlmiller, A., & Byun, J. (2022, April 8). The plan for elicit. Ought. https://ought.org/updates/2022-04-08-elicit-plan.   
Thaiss C., hs, . 016). Ind Witing Pams tRs: mplties anns in aheeti.  ton and Communication, 68(1), 209-214.   
Wattenberger, A. (2023). Why chatbots are not the future of interfaces. htp://wattenberger.com/thoughts/boo-chatbots.   
Watkins, M. (2023) AI in first year writing courses. TextGenEd. The WAC.   
Wordtune. (2023). https://www.wordtune.com/. Accessed August 31, 2023.   
Wtins     /tis ai-in-first-year-writing-courses/.   
Yancey, K. B. (199). Looking ack as w lo forward: Historicizing writing aesment. Colle Composition and Commncation, 50(3, 483-503.   
ney, 015) i:  i/ic, h s,   co e-r   .) Naming what we know: threshold concepts of writing studies. Utah State UP. xvi-xxxi. know: threshold concepts of writing studies (pp. 64-65). Utah State UP.   
ey, K is  oL Tk,  019) T g r tfr il tin d o 712) 268-295.

er    n   a ips    o th f  c   e,   t t rtig process and product. He currently chairs the AI Task Force at the University of Mississippi.

the     rtt   r t Cener for t t of t e an str e er ath a or for n ndr t. h the oking Group  th  n hric  i io c .  oo      t Southern Universities, was published in 2021.

Mart   a t co-chair th  workggo whn his dmn n e  lio th ther mn n amus, exig tive  ct onching and learning.