# Exploring AI chatbot affordances in the EFL classroom: young learners’ experiences and perspectives

Jaeho Jeon

To cite this article: Jaeho Jeon (2024) Exploring AI chatbot affordances in the EFL classroom: young learners’ experiences and perspectives, Computer Assisted Language Learning, 37:1-2, 1-26, DOI: 10.1080/09588221.2021.2021241

To link to this article: https://doi.org/10.1080/09588221.2021.2021241

# Exploring AI chatbot affordances in the EFL classroom: young learners’ experiences and perspectives

Jaeho Jeon $\textcircled{1}$

Department of English Education, Seoul National University of Education, Seoul, Republic of  Korea

# ABSTRACT

Professionals within the field of language learning have predicted that chatbots would provide new opportunities for the teaching and learning of language. Despite the assumed benefits of utilizing chatbots in language classrooms, such as providing interactional chances or helping to create an anxiety-free atmosphere, little is known about learners’ actual use of chatbots during language classes or how chatbots affect their motivation to learn a language. To address these gaps, this exploratory study aimed to create an inventory of affordances that chatbots provide in the primary English as a foreign language (EFL) classroom and to explore how the affordances affect psychological aspects in language learners, particularly regarding their motivation to learn English through chatbots. Thirty-six Korean primary school learners participated in a 16-week EFL course that utilized customized chatbots. These chatbots were created using Google’s Dialogflow. After the course, individual in-depth interviews were conducted regarding the participants’ experiences and perceptions of the chatbots. Student-chatbot interaction logs produced during the course were also collected to supplement the interview data. Qualitative analysis of the interview transcripts and interaction logs revealed the presence of pedagogical, technological, and social affordances. Depending on the learner, the chatbot affordances were perceived differently; thus, each affordance acted as either an opportunity or a constraint for English language learning. In addition, this study specifically discussed how these chatbot affordances might have affected psychological states in language learners. Future recommendations regarding the use of chatbots in language classrooms were suggested from both pedagogical and technological perspectives.

# KEYWORDS

chatbots; conversational agents; artificial intelligence; affordances; learner motivation; EFL learners; Dialogflow

# Introduction

Language educators and researchers have recommended chatbots as powerful tools for the facilitation of language learning by emphasizing the value of their role as conversation partners (Fryer et  al., 2020). With the development of artificial intelligence (AI) technology, such as natural language processing or machine learning, the relevance of chatbot technology to language learning has become more prevalent. Reflecting on this change, various scholarly attempts to integrate chatbot technology into language learning have been made. Previous research regarding chatbot technology for language learning has revealed that chatbots are effective in increasing language learning motivation (Lee et  al., 2011), facilitating specific language skills such as lexical inferencing (Jeon, 2021), and improving overall L2 proficiency (Bibauw et  al., 2019; Divekar\* et  al., 2021). Furthermore, research has indicated that chatbots act as tools for providing abundant conversation opportunities or practice (Timpe-Laughlin et  al., 2020; Xu et  al., 2021). On the other hand, some concerns have been raised regarding the efficacy of using chatbots in language learning. These include concerns that chatbots are not capable of sustaining goal-oriented conversations necessary for the purpose of language learning (Coniam, 2014); that learners quickly lose interest after the early stages of language learning using chatbots (Fryer et  al., 2017, 2019); or that learners do not conduct themselves in a manner appropriate for conversations with human partners when they communicate with chatbots (Hill et  al., 2015). In addition, Divekar et  al. (2018) indicated that chatbots should possess help features for learners who lack L2 proficiency, such as providing feedback in L1 or vocabulary clarification, to overcome interaction challenges.

Despite the growing popularity of chatbot technology for language learning, it is still unclear how chatbots could be integrated into language classrooms. One reason for this lack of knowledge is that little research has been conducted on how chatbots are used in language classrooms or on how chatbots in such settings affect learners’ motivation to learn languages, although other factors, such as technological immaturity, a lack of infrastructure, or teachers’ reluctance to use technology, can also contribute. Furthermore, as noted in review studies on chatbots (Huang et  al., 2021; Hwang & Chang, 2021), chatbot research in education has mainly used quantitative methods in design or has used relatively short-term experiments composed of a small number of tasks. Before we can determine whether chatbots are beneficial tools for use in the language classroom, it is of particular importance to gain specific knowledge about how chatbots can be incorporated into the language classroom and about their affective influences on language learners, especially through longitudinal and interpretive work that can deepen our contextualized understanding of chatbots.

To address these concerns, the researcher first built educational chatbots capable of sustaining goal-oriented conversations by using Google’s Dialogflow, where teachers can make customized chatbots, and then implemented a set of language activities using the chatbots during a 16-week English as a foreign language (EFL) course for beginner-level primary school students. By qualitatively analyzing student-chatbot interaction records produced during the course and post-course individual interview data, this exploratory study aimed to identify and inventory affordances that chatbots provide within primary EFL classrooms. In addition, this research discussed both the opportunities and constraints of using chatbots in regard to English learning while also revealing how chatbots affect psychological aspects in language learners, particularly regarding motivation to learn English through chatbots. The following question guided this research:

What are enabling and constraining affordances provided by chatbots in the EFL classroom, and how do those affordances affect students’ motivation to learn English?

# Literature review

# Chatbot technology for language learning

Chatbot technology has garnered a great deal of attention from language learning professionals, mainly due to its chat functionality. Suggesting a vision for a conversation practice machine, Atwell (1999) paid attention to the role of chatbots for language learning; this was because of their potential to provide students with abundant opportunities for practicing a new language. Over time, chatbots have progressed alongside the development of technology such as natural language processing and machine learning, thus increasing the relevance of chatbots within the field of language learning (Fryer et  al., 2020).

Initial attempts to use chatbots for language learning were made using rule-based chatbots that were implemented with either restricted pattern or keyword matching. For example, Jia (2003) analyzed 1,256 users’ chatbot interaction logs. The chatbot system employed restricted keywords and pattern-matching mechanisms. The paper concluded that the chatbot system that operated on these limited mechanisms could not work effectively as a teaching assistant program in language learning because it was not equipped with “the ability to process meaning (natural language understanding)” (Bibauw et  al., 2019, p. 853). Recent advances in natural language processing and machine learning technology have made human-chatbot interaction more authentic and suitable for language learning and thus have created new possibilities for language teachers who desire to use chatbots (Kim & Jang, 2020). Reflecting on this development, language scholars in chatbot research have primarily employed two types of chatbots: 1) general-purpose chatbots that can conduct a daily conversation with users, such as Cleverbot (e.g., Fryer et  al., 2017, 2019) and 2) purposeful chatbots that can conduct specific tasks with learners of a particular language proficiency (e.g., Jeon, 2021; Sydorenko et  al., 2019; Timpe-Laughlin et  al., 2020).

Despite these efforts, there may be limitations to using these two types of chatbots in long-term language courses, particularly beginner-level EFL courses. Regarding general-purpose chatbots, first, dialogues with these chatbots tend to be strictly user-initiated and mainly reactive (Bibauw et  al., 2019). Novice EFL students might find it difficult to initiate or actively lead conversations with the chatbots in the target language, given their limited language proficiency (Divekar et  al., 2018, 2021). Next, beginner-level EFL classes inevitably encompass specific learning contexts, learning contents, and particularly structured interactions (DeKeyser, 2010). This means that these classes need to utilize chatbots capable of sustaining goal-oriented conversations within an appropriate educational boundary; it is questionable how well English teachers within their own specific teaching contexts could employ general-purpose chatbots for their educational purposes. In addition, as for existing purposeful chatbots, since these chatbots were created mainly reflecting the context of a specific class, the chatbots are unlikely to cover much of the content of any other long-term language course, although the chatbots provide useful insight into how chatbots could be created and used to attain specific classroom objectives (AlKhayat, 2017; Divekar\* et  al., 2021).

To address these limitations, language teachers can create customized chatbots that are able to sustain goal-oriented conversations with students by using chatbot builders such as Botstify, Chatfuel, or Dialogflow1 . Generally, the chatbots created through these platforms are employed to perform functions such as help-desk, triage, lead generation, or E-commerce assistance for business purposes (Sabharwal & Agrawal, 2020). Scholars in the field of language learning have also noted the potential usefulness of these platforms (e.g., Jeon, 2021; Smutny & Schreiberova, 2020). For example, Lee et  al. (2020) noted that customized chatbots created through these platforms could cater to teachers’ pedagogical needs, although some degree of training would be required. Kessler (2018) also highlighted the relative easiness of chatbot creation through the use of these platforms compared to coding software for professionals. Furthermore, most of the platforms provide an automatic transcript function that can be significantly useful in language classrooms consisting of multiple students because teachers can monitor each interaction through the records and accordingly prepare different instructions for each student (Jeon, 2021). The researcher considered the benefits of the various platforms, and for this study, selected Dialogflow because of its compatibility with devices used in this study. In sum, by using this platform, the researcher was able to create customized chatbots capable of orally interacting with young students and of performing goal-oriented conversations during a one-semester-long EFL course.

# Affordances and learner psychology

The term affordance was first introduced by Gibson (1986) and was later elaborated on by Stoffregen (2003) to describe action possibilities that can emerge from the relation between an agent and environment. Recognizing the value of the term, a body of scholars from various fields have adopted the concept of affordance by modifying it to their own contexts. In the field of language learning, scholars have used the term to describe the language learning possibilities inherent in a learning environment. For example, van Lier (2004) preferred this term to input because it better helped teachers take both the positive and negative potentials of the language learning environment into consideration. Anderson (2015) also emphasized the importance of considering the concept of affordance in language learning and stated that teachers must be prepared for the emergence of affordance to maximize learning opportunities. In this vein, the role of language teachers could be considered one that understands how affordances affect learners and allows for the creation of an environment wherein learners can actualize positive affordances (Plonsky & Ziegler, 2016).

Rapid development in technology has provided new affordances for language learners. Scholars in the field of computer-assisted language learning (CALL) have attempted to examine psychological effects that the affordances of technology have on learners; the examination of psychological states when learners are using technology provides detailed insight into the necessary conditions for effective learning to occur (Dörnyei, 2014). This line of research has also assisted teachers in making the language classroom both technologically and pedagogically more relevant to learners (Freiermuth, 2020). Therefore, for new technology (e.g., AI tools) to be recommended to learners as a means of supporting their learning, it is necessary to explore the affordances of the technology and how the affordances affect the psychological state of the learners.

Previous literature has mainly focused on language learner psychology, especially regarding motivation to learn languages in environments where

L2 interactions occur via the use of technology such as communication apps or collaborative websites (e.g., Freiermuth & Huang, 2012; Zou et  al., 2018). These studies are meaningful because they have identified how incorporating technology affects learner motivation by exploring such factors as anxiety, willingness to communicate, or the need to use a target language. For example, Freiermuth and Huang (2012) revealed that online synchronous chat could be an effective mode for language learning by showing that the technology provided psychological benefits such as alleviating speaking anxiety and making learners more willing to communicate in a target language.

However, chatbot technology creates a unique learning environment in that learners directly interact with AI agents rather than with other human interlocutors, as is the case when using the communication technology mentioned above (Bower, 2019). Freiermuth (2020) stated, “This independence from teachers should not divert our attention away from the students; rather, it should heighten our attention to the ways such [AI] applications are affecting the psychological underpinnings of our students” (p. 18). Recently, Zou et  al. (2020) explored university learners’ perceptions toward AI apps for language learning, specifically English for academic purposes (EAP) regarding speaking. Although it was indicated that the apps lowered speaking anxiety and that learners were satisfied with the apps’ immediate feedback on their overall language performance, they also stated that the technology could not replace language teachers because there were still limitations such as an inability to recognize users’ local pronunciation or to provide tailored feedback.

AI chatbots are different from other AI tools, such as the EAP apps mentioned above, in that chatbots are mainly utilized to provide interactional chances to learners. Within an interactive environment, we can assume that chatbots might generate different psychological effects on language learners. However, only a few studies have explored how chatbots affect psychological states in learners, particularly in relation to their motivation to learn a language (Bibauw et  al., 2019). This line of research has yielded some quantitative data, but the results have been inconsistent. For example, Fryer et  al. (2017, 2019) revealed that learners quickly lost their interest in using chatbots to learn a language after the early stages during a course. In contrast, some reported positive chatbot effects on psychological factors such as motivation, interest, and confidence (e.g., Lee et  al., 2011). This inconsistency may be partly due to the complex and multifaceted nature of learner psychology when learners interact with chatbots. Clearly, research is needed to further explore the complex nature of this inquiry, especially in the form of an approach that can provide a contextualized understanding of the complicated aspects of chatbots’ affective effects.

Although chatbots might offer various affordances as a form of technology themselves, this paper specifically aims to identify and inventory chatbot affordances in terms of language learning in primary EFL classrooms. Furthermore, to address the gap in the literature, and considering that our understanding of AI chatbots is in its initial stages of development, this research seeks to qualitatively explain how the affordances affect psychological aspects in language learners, particularly regarding their motivation to learn English.

# Method

# Participants and classroom context

The settings for this research were two primary classrooms in South Korea. Thirty-six Korean students, all of them being 12 years old at the time of the study, participated in a 16-week EFL course that utilized chatbots. Students in South Korea start to learn English in public schools at the age of nine and take lessons two to three times a week every semester; this means that the participants in the research had four years of EFL learning experience. The results of diagnostic tests administered at the beginning of the semester were used to decide the participants’ English proficiency; all of them belonged to the novice level according to American council on the teaching of foreign languages (ACTFL) guidelines for speaking and listening. In addition, student observation records offered by an English teacher instructing the participants at the time of the research provided further information about their overall spoken English proficiency; the participants were able to perform basic functions in English, such as talking about hobbies or greeting friends; but misunderstandings often arose; they frequently paused as they attempted to recall vocabulary during those types of conversations.

During a 16-week EFL course, lessons were organized on a weekly basis, with three 40-minute-long classes being covered every week. The first two weeks were spent familiarizing students with the chatbots. For the remaining 14 weeks, a different topic was taught each week, following the same weekly lesson structure consisting of three sequential configurations: whole group, small group, and individual. Specifically, the students first participated in a whole class configuration where they were presented with target words and sentences and participated in target dialogue practice through a combination of games, songs, and chants depending on the lesson. In the second class of the week, they participated in information-gap tasks that were adapted by the researcher from the tasks suggested in Ur (1990). The students performed the tasks in a group configuration by communicating with their peers. Next, as the final class of the weekly lessons, another opportunity was given to perform the information-gap tasks with the chatbots replacing their peers; the students spent most of the allotted class time having independent conversations with only their chatbots to complete the tasks. Worksheets were supplied to the students to provide information necessary to complete the tasks. The task topics were related to real-life situations, such as how they could reach or travel to specific buildings and locations (see Supplementary Appendices 1 and 2 for more information regarding weekly topics and a worksheet sample). When the students asked for help regarding technical issues or task performance, the researcher, who also performed the role of a teacher, helped the students perform tasks with the chatbots.

# Chatbots for this study

The researcher created chatbots using Dialogflow to ensure that the chatbots could perform both extended and goal-oriented conversations with the students regarding topics in the context of beginner-level EFL classes. Specifically, the chatbots were designed to provide four different sets of responses: corrective feedback, prompts, fallback intent, and evaluation, all of which were given based on the type of student input. Conditions and examples for each chatbot response are presented in Figure 1. The dialogues coded into the chatbots are presented in Supplementary Appendix 1. To finish one set of interactions, the minimum number of interactional turns (i.e., a pair of student-chatbot utterances) was two; however, depending on the type of student input, the interaction could continue until the students provided the target response to the chatbot question.

The chatbots were then integrated with the Google Assistant interface that provided speech-to-text and text-to-speech technologies. Students accessed the chatbots by using the interface through tablet PCs, which means that it was possible for the students to not only speak and listen but also to read and type during their interactions with the chatbots. This audio-based interaction makes the chatbots more relevant to language learning (van Doremalen et  al., 2016).

# Data collection and analysis

The researcher adopted a qualitative approach in order to identify potential chatbot affordances and to reveal how the affordances might have affected language learner psychology. To this aim, data were collected from two sources: individual in-depth interviews as a primary source and student-chatbot interaction logs to supplement student comments, especially on their interaction experiences with the chatbots.

![](img/48b3eb1886ae1a0034df55a9561ce7f9dcd8fd1b0ed36be4d845dca170983960.jpg)  
Figure 1. A chatbot decision tree diagram example.

Regarding the interview process, students were first asked to write reflections about their English learning experiences with the chatbots immediately following the end of the course. As a prompt, the researcher clarified that they should describe memorable or challenging moments experienced when using the chatbots during the classes. Next, questions for semi-structured interviews were designed, and the interviews were conducted with each student about a week after the last class. The researcher structured interviews around the following questions.

Can you describe how you used the chatbots?   
Did you find using chatbots helpful when studying English? Why? What difficulties did you have when studying with the chatbots? How did you overcome these difficulties?   
Do you want to continue to use chatbots in English class? Why?

Given the exploratory aim of the study, the researcher initially attempted to investigate what was possible through the chatbots in terms of English language learning. Next, based on each student’s reflection log, follow-up questions were carried out focusing on student perceptions of the chatbots, specifically focusing more on the aspects of the chatbots that could facilitate or constrain English language learning. The length of these interviews ranged from 32 to 53 minutes. All interviews were conducted in students’ L1 while being audio-taped. The interviews were then transcribed verbatim.

Next, the transcripts of the interview data were qualitatively analyzed to discover repeated patterns of meaning in relation to the research question, following a thematic analytical approach (Braun & Clarke, 2006). Accordingly, an initial coding scheme was developed by the researcher as follows: first, after the researcher gained a general understanding of the transcripts, all parts related to language learning were extracted for coding; next, each code that shared a similar underlying meaning was then grouped into a common theme; finally, themes were categorized into different affordances, and three affordance categories were identified. Next, a third of the transcripts that were randomly derived from the interview data were given to another language learning professional. This professional was also asked to follow the same coding scheme and to classify each part into the identified affordance categories. Afterward, a discussion between the two coders was carried out in which a new modified coding scheme was developed by refining the initial one (see Supplementary Appendix 3). Last, guided by the refined coding scheme, the two coders independently coded all transcripts. Ninety-four percent intercoder reliability was achieved, and another discussion was carried out to resolve disagreements. Themes that consisted of less than five codes were excluded from the analysis. In the end, 385 parts were divided into three different affordance categories. Representative answers were extracted as a method of documenting and capturing repeated patterns of the meaning behind the students’ words. Student names were coded with numbers (e.g., S1, S2, …) to ensure confidentiality.

Student-chatbot interaction logs were then examined in an effort to supplement the interview data, particularly regarding the students’ interaction experiences with the chatbots. The researcher read all of the interaction transcripts that were saved in the Dialogflow system in a line-by-line fashion to find any supplementary clues to the interview excerpts and to ensure the objectivity and representativeness of the student comments. This analysis process occurred in an iterative manner as the researcher moved between the interaction logs, student interview data, and relevant research reviewed in the Literature review. As a result, some interaction logs were selected when considered representative of the interview themes and presented along with interview excerpts to describe chatbot affordances in an objective manner.

This type of qualitative approach is considered the most appropriate for identifying any revelations in a research topic that a study might provide, as is the case with the exploratory nature of the current study (Braun & Clarke, 2006; Johnson, 1992). Particularly, by basing the current study on students’ actual interaction logs and their reflections after extended exposure to chatbots, the researcher gained a greater understanding of what affordances chatbots provided in the EFL classroom and of psychological aspects in learners, particularly regarding their motivation to learn English through chatbots.

# Results

As a result of data analysis, three categories of affordances were identified: pedagogical, technological, and social. Pedagogical affordances emerged from the direct interactions between the chatbots and the students. These affordances are associated with the primary purpose of employing chatbots in the language classroom, namely, to provide interactional chances to students. Second, technological affordances are related to the use of technology derived from the medium used for chatbot operation or associated with the embedded technological features of the chatbots. Last, social affordances are related to how the chatbots influenced attitudes toward language class. These affordances were generated because the use of chatbots created a socially unique learning configuration that differed from traditional classrooms. An overview of these affordances is presented in Table 1.

# Pedagogical affordances

One major strength of the chatbots perceived by the students was related to the chatbots’ interactional features. Figure 2 is an interaction transcript between S4 and the chatbot that was automatically saved in the Dialogflow system during week 7 (see Supplementary Appendix 2 for the worksheet used for this task). This interaction log is representative of a successful conversation that students could have with the chatbots. These types of successful interaction experiences with the chatbots allowed the students to benefit from the chatbots’ pedagogical affordances in the EFL classroom.

Table 1. O verview of chatbot affordances.   

<html><body><table><tr><td>Affordances</td><td>Themes</td></tr><tr><td rowspan="5">Pedagogical</td><td>Opportunity</td></tr><tr><td>Receiving speaking and listening chances</td></tr><tr><td>Receiving immediate feedback</td></tr><tr><td>Knowing when and how to use target speech.</td></tr><tr><td>Constraint Lacking skills to perform interactions</td></tr><tr><td rowspan="6">Technologicale</td><td>Opportunity</td></tr><tr><td>Using the stop button to think more</td></tr><tr><td>Using search engines to find information</td></tr><tr><td>Using online dictionaries as vocabulary sources.</td></tr><tr><td>Focusing on pronunciation when input is unrecognized.</td></tr><tr><td>Constraint Feeling anxiety about misrecognition</td></tr><tr><td rowspan="6">Social</td><td>Repeating a conversation from the beginning when input is unrecognized</td></tr><tr><td></td></tr><tr><td>Opportunity Being free from anxiety in front of others regarding speech mistakes.</td></tr><tr><td>Controlling one&#x27;s own learning pace independently without peer-pressure.</td></tr><tr><td>Constraint</td></tr><tr><td>Desiring to study with peers</td></tr></table></body></html>

![](img/46cbf1ed830268eab62df15eff5dde064449ad33cb0b86f9d95c2fd3dcc5132d.jpg)  
Figure 2. I nteraction transcript between S4 and the chatbot.

According to 18 students, the chatbots were considered interlocutors with whom the students could interact during the performance of the tasks. This perception of the chatbots facilitated the students’ motivation to utilize the chatbots, which led to active engagement in speaking English. For example, 12 students mentioned that they felt the chatbots were real human-like conversation partners and could practice listening and speaking English with them. S4 stated, "It was great because I could talk as much as I wanted, and the chatbot understood what I said. It is like I was talking to a real person." In addition, the students reported that they enjoyed conversations with the chatbots and were more engaged in class compared to when they studied either with a whole class or a group configuration. Similarly, S2 said, “I did not have as many speaking and listening opportunities like this when I took class without the chatbot.” Furthermore, as six students reported, tasks with the chatbots created a more authentic interactional atmosphere, and they learned when and how they should use new target words and sentences appropriately. S14, for example, found that through interacting with the chatbot, he could not only listen to but also speak target sentences and could understand whether his speech was appropriate or not in a given context thanks to the immediate feedback the chatbot provided. Similar comments were made:

I think it is very practical because I felt like I was talking in a real situation, so I could learn how to use new expressions. (S3)

Whenever I made a mistake, the chatbot gave me feedback right away. It was helpful because I could learn how to use expressions right. (S9)

I think I could use new expressions when I talk to a real foreigner because I already had similar conversations with the chatbot, and now I know it. (S12)

However, while functioning as a conversational partner for some students, there were also constraints caused by the interactional affordance. While many of the students who were able to have a conversation with the chatbots reported on the value of interactional opportunities, eight students whose English skills were not advanced enough to have a spoken conversation with the chatbots mentioned the difficulties they encountered. It was observed that those students did not finish their tasks. Figure 3 is an interaction transcript between S18 and the chatbot, which represents a sample of an unsuccessful interaction.

S18, whose English proficiency was not sufficient to fully interact with the chatbot, tried to speak in his L1. However, as shown in Figure 3, the chatbot system could not recognize his L1 utterances and thus categorized those utterances as unrelated, even though the L1 utterances might have been related to the topic. Comments from the students provide information regarding how these experiences might have affected their motivation to use the chatbots as follows:

I wish the chatbot could speak Korean. I needed help to interact with the chatbot. The chatbot just kept saying I was wrong. I completed the activity with the teacher’s help, but it was discouraging. (S18)

Since I am not good at English, it was very difficult. I need a teacher, not a chatbot, who can help me step by step in Korean. (S10)

It is evident in the interview data that the interactive feature of the chatbots offered plenty of interaction opportunities to students; some students enjoyed these opportunities. However, there was also the sense that the chatbots did not provide the benefit of being able to assist the students as a teacher would during conversation practice (Divekar et  al., 2018). It was observed that this perception toward the chatbots’ inability hampered some students’ motivation to use the tools for language learning (Zou et  al., 2020); this is supported by comments that the students made, such as S10 and S18, whose English skills were not advanced enough to perform interactions with the chatbots in English only.

![](img/60421dcbfc2ddb3136314031ebd284fddf100e5542c71b989ae6f9b2fd6f7137.jpg)  
Figure 3. I nteraction transcript between S18 and the chatbot.

# Technological affordances

The chatbots employed in this study were uploaded to tablet PCs; therefore, the chatbots provided several technological affordances that were not only created by chatbot technology itself but also by the tablet PCs. First, regarding the strengths of the chatbots, 10 students mentioned the technological affordances of the chatbots concerning tablet PC functionalities. For the most part, these affordances were described by using positive words such as convenient, easy, and useful; the affordances helped sustain the students’ willingness to interact with the chatbots using English (Soon et  al., 2020). For example, S11 mentioned that he could stop the chatbot when he needed to think more. S9 said, “When I could not figure out what to say, I stopped the chatbot and prepared what to say. It was convenient because all I had to do was just push the stop button on the screen.” S15 said, “I could easily go back and forth from the chatbot to an online dictionary to find the meanings of words used in tasks.” S16 reported, “I could just stop and go to the internet to search for some information about tasks.”

In addition, several comments were reported regarding speech recognition problems that the students experienced when they attempted to talk to the chatbots. Thirty-three students reported that they experienced this type of speech recognition problem; however, what should be noted is that these recognition issues were perceived differently depending on the student. First, a total of 13 students described the recognition problems as anxious, worrisome, or exhausting. This perception made the students unwilling to speak English to the chatbots. The comments included:

When the chatbot did not recognize my speech, it was very disappointing. I felt anxious if the chatbot could not recognize my pronunciation. (S7) The chatbot often misunderstood what I said. I was quite worried about my speaking. Several times, I just typed instead of speaking. (S6) It did not recognize what I said well. When I failed to make the chatbot understand what I said several times, the chatbot just left the chatroom, and I had to start the conversation all over again. It was exhausting. (S5)

However, in the case of 20 students, these recognition issues were viewed as an opportunity to practice English speaking with more accurate pronunciation. It was frequently observed that those students attempted to pronounce words more clearly and to fix their errors in a repetitive manner when the chatbot did not understand their English utterances. Figure 4 is an interaction transcript between S19 and the chatbot, capturing one of these students’ responses to the chatbot’s misrecognition.

The interview data revealed that, even with the technical limitations, the chatbots enhanced some students’ motivation to learn English through the chatbots. The students attempted to overcome these limitations by repeatedly adjusting their English utterances because they attributed misrecognition to themselves, not to the chatbots. Furthermore, these sorts of obstacles were even viewed as game-like activities where the students should complete missions.

It was hard to make the chatbot recognize the word florist. I found out that I pronounced the word wrong. I tried to pronounce florist differently and finally came to know how to pronounce the word right. (S19)

I concentrated on my pronunciation more while speaking to my chatbot. I repeatedly checked my pronunciation. I studied pronunciation in a more focused way than before with the help of the chatbot. (S2)

It was like a game. My mission was to make the chatbot understand my speech. When it recognized my speech, I felt so satisfied. I wondered if the chatbot also recognized other sentences. (S21)

![](img/f20fc63f64ae427c808508d7c13bc3b30d305caded791d29a77766729da8ae08.jpg)  
Figure 4. I nteraction transcript between S19 and the chatbot.

As indicated in the interview data, students could employ other digital tools such as online dictionaries or search engines while using the chatbots, which helped sustain their willingness to interact with the chatbots using English. Speech recognition problems made some participants feel anxious about their utterances and lowered their motivation to use English with the chatbots (Freiermuth, 2001; Freiermuth & Huang, 2012). In contrast, many students perceived this technological limitation in the chatbots as a learning opportunity in which they could improve their pronunciation accuracy in an engaging way. In other words, many of the students recognized the chatbots as helpful tools from which they could learn more; this perception ultimately led to increased motivation to interact with the chatbots using English.

# Social affordances

Students also described ways in which the learning configuration created by the use of the chatbots influenced their attitude toward English class. Most of the students indicated that they developed a positive attitude toward their English class because of the chatbots. The students mentioned that a learning configuration where they practiced English with only the chatbots was very beneficial because they did not worry about other interlocutors such as friends or teachers. Twenty-six students stated that they felt comfortable talking to the chatbots because they did not feel pressure from having to worry about human partners, specifically, about their speech mistakes; that is, there was no sense of being judged by their peers or teacher. Among the 26 students, eight students, including S2 and S11, elaborated more on their preference for the chatbots by citing the independent learning opportunities that the chatbots created. Comments related to these pressure-free feelings included:

Even if I make countless mistakes, the chatbots do not get annoyed. So, I can try as much as I want with only the chatbot without being worried about my partner. (S2)

I could practice what I wanted at my own pace because the chatbot was the only partner that I had. I am not good at English, so when studying English with friends in a group, I felt pressured because I thought I might slow down the group work. (S11)

As the comments reveal, the learning configuration provided by the use of the chatbots was facilitative to their engagement in speaking English. That is, having the chatbots as the only interlocutor while performing the task helped reduce anxiety related to speaking, which ultimately facilitated the students’ willingness to communicate in English (Freiermuth & Huang, 2012; Freiermuth & Jarrell, 2006). However, it was also observed that 10 students did not enjoy this learning configuration. The students considered the chatbot tasks in the configuration not as attractive as tasks with human partners. This negative perception toward the chatbots lowered their motivation to conduct language tasks with the chatbots; two main reasons were identified regarding this negative perception. First, the students preferred human partners to the chatbots because they enjoyed doing language activities more actively with human partners than practicing alone. These comments included:

When we use the chatbots, this means that we cannot play an English game. I like it when I can play an English activity with friends in the class. When I have a chance to move my body or to compete with friends, I think class becomes more engaging. (S9)

Second, the students also expressed their desire to collaborate with human partners rather than with the chatbots. For example, S1, whose English level was the highest among the participants, indicated that he also did not like using the chatbots because he could not help or collaborate with other friends by using his already established English skills. The comment was:

It was boring because I talked only to the chatbot that was just a machine. I want to study English by talking to my friends. … I finished my tasks with the chatbot, but it was not interesting. English class becomes more fun when I can help my friends. (S1)

The interview data confirmed that a learning configuration that utilized chatbots was perceived differently depending on the student, resulting in different attitudes toward English classes using that configuration. Most of the participants expressed enjoyment about learning with only the chatbots, but for some students, learning with the chatbots was demotivating because they thought the chatbots could not replace human partners (Fryer et  al., 2017, 2019).

# Discussion

It is important to recall that an individual student’s perceived affordances did not occur in a decontextualized manner. Rather, each affordance was perceived and determined by the individual student’s ability to recognize and react to a particular feature within the technology-enhanced learning environment (Chun et  al., 2016; Freiermuth, 2020). Furthermore, the affordances also affected the psychological aspects of the students, which ultimately facilitated or decreased their motivation to learn a language through the chatbots. The psychological aspects identified in this study consisted of students’ own perceptions of their L2 competency or technology control level, awareness of the chatbot’s pedagogical value, perceptions of chatbots as authentic speakers, and anxiety regarding English speaking. These aspects provided insight into how chatbots should be incorporated into the language classroom.

First, student perceptions of their English language competencies affected their motivation to learn English through chatbots. During the 16-week course that consisted of multiple topics, each topic varied in the difficulty level of English words and sentences required. When students perceived that a chatbot task could be resolved with their prior language competency, they became more willing to communicate with the chatbots using English (AlKhayat, 2017). For example, S18, who described her overall experience with the chatbots as discouraging and attributed this to her low English competency, stated that she particularly enjoyed the direction-finding task with the chatbots during the second week. She indicated that this task was within her competency level, as could be observed in her reflection where she mentioned, “It was good to do the direction task with a partner like the chatbot because I could understand the chatbot well during this task and it was intelligent enough to communicate with me” (S18). In this vein, language teachers who desire to employ chatbots in class should first consider students’ prior language competencies when preparing chatbot tasks (Fryer et  al., 2019).

However, not all students reported negative perceptions toward tasks beyond their prior language competency. The interview data indicated that technological affordances compensated for interactional constraints. That is, some students utilized the technological aspects or functionalities of the chatbots to compensate for the skills, knowledge, and attitudes they lacked when interacting with the chatbots, which helped the students sustain their motivation to interact with the chatbots in English (Soon et  al., 2020). These students also autonomously controlled the chatbots, which further enhanced their motivation (Benson, 2011). For example, as shown in the comment made by S9, when the student needed more time to prepare for interacting with the chatbot in English, he used the stop button and refined his English utterance. S6 controlled his speaking anxiety by selecting English typing instead of speaking as the main mode of communication with the chatbot. The interplay between perceived chatbot control level and students’ willingness to learn a language through chatbots may need to be investigated more systematically in future research. Furthermore, language teachers need to consider how technological affordances can compensate for interactional constraints to maximize the educational effectiveness of chatbots.

Active use of the chatbots for language learning was also promoted when the chatbots were perceived as pedagogically valuable (Fryer et  al., 2019). To be more specific, when the chatbots were seen as valuable by the students, the possible technical limitations of the chatbots were perceived less; these positive perceptions toward the chatbots facilitated students’ intrinsic motivation to perform the tasks (Dörnyei, 2002; Freiermuth & Huang, 2012). The chatbots utilized in this study were not free from technical limitations such as speech recognition problems, as was the case with chatbots in previous studies. However, as S19 indicated when he stated, “I could learn from the chatbot,” students who perceived the pedagogical value of chatbots for language learning maintained their willingness to use the chatbots even when faced with technical limitations. That is, the perceptions about the chatbots as learning tools outweighed the possible negative impressions that could result from the chatbots’ technical limitations. Some students even considered recognition difficulties that they encountered as opportunities for pronunciation practice and not as constraints for learning; rather, this difficulty worked as a form of feedback with which the student came to realize how to pronounce a word appropriately.

In addition, when perceived as authentic speakers, the chatbots facilitated students’ willingness to utilize the chatbots for language learning, a finding in line with Timpe-Laughlin et  al. (2020), who revealed that teacher perceptions of chatbots as authentic speakers influenced their willingness to employ the tools in language classes. When students perceived the chatbots as authentic interlocutors with which they could interact, they were more willing to talk to the chatbots and took advantage of the opportunities that the chatbots provided. In contrast, students such as S1, who considered the chatbots as just machines, held a negative attitude toward English classes that utilized the chatbots; the chatbots, when perceived as just machines, made students unwilling to speak English. These students ultimately expressed their desire to study with human interlocutors such as their peers. Hence, methods to make chatbots pedagogically more salient and authentic in terms of language learning may need to be further investigated in future studies.

Finally, the unique configuration of chatbot tasks in which students mainly interacted with the agents rather than human interlocutors provided psychological benefits for language learning. Most of the students revealed positive perceptions toward only interacting with the chatbots because this configuration created a learning atmosphere that helped to reduce social anxiety such as peer pressure. This reduced anxiety level allowed students to speak English more actively (Freiermuth & Huang, 2012; Hill et  al., 2015). For example, as was revealed in the interview data, S2 and S11 directly mentioned that they could comfortably perform conversations in English because they did not have to worry about their peers.

Despite the benefits of using chatbots mentioned above, the interview data also revealed some constraints caused by the chatbots: some students were not prepared to speak English to the chatbots; some needed teacher assistance to perform interactions with the chatbots; some expressed a stronger desire to study with their peers rather than with the chatbots. Language teachers could diversify the forms and types of chatbot activities to address these students’ concerns. For example, multiple chatbots could be utilized simultaneously during an activity (Fryer et  al., 2020). When students have difficulty understanding the target language or need L1 instruction, two chatbots that have different language settings might help students receive comprehensible guidance in the language most appropriate at the moment. Furthermore, multiple chatbots with different language difficulty levels could be created and employed in a gradual way to provide language practice according to students’ language ability. Specifically, chatbots that provide vocabulary practice could be utilized first, and then, students could move on to using chatbots with which they could have a more open-ended conversation using the vocabulary; this will ultimately lead to the students acquiring sufficient experience to then be able to perform the conversation with human partners. In addition, language teachers might be able to design chatbot group activities in which groups of students and a chatbot interact with one another, a multi-faceted approach that incorporates both student-chatbot and student-student interaction (Divekar\* et  al., 2021). Through this approach, students can take advantage of some benefits that chatbots provide, including receiving immediate feedback or focusing on pronunciation, while realizing their desire to study with peers. Students may also perceive the use of chatbots more positively and feel less speaking anxiety (Divekar\* et al., 2021).

Along with the pedagogical solutions mentioned above, there also exist some technical limitations for applying Dialogflow in language classes; these limitations should be examined by either chatbot technology or platform developers. First, multilingual chatbots that can communicate using more than two languages currently only work naturally in the text mode. A chatbot that can communicate both in L1 and L2 using the audio mode might serve as a better teaching tool for beginner-level students such as young EFL students in this study (Divekar et  al., 2018; Jeon, 2021). In addition, the automatic transcription function in Dialogflow needs to provide more linguistic information about student utterances through audio recordings. As presented in Figures 2–4, the written records do not reveal details regarding student pronunciation or speaking fluency. An audio record could provide more accurate information regarding students; thus, teachers might be able to prepare subsequent learning that is more finely focused on an individual’s problem areas (Jeon, 2021). Third, as students advance in language proficiency, it will be difficult for teachers to create chatbots that can provide students with the multitude of potential answers that might occur. The first step in solving this problem would be for developers to provide initial coding models designed for the purpose of language learning; thus, teachers could build on the models to create their chatbots with more complicated interaction capabilities. This effort should be implemented through close collaboration between developers and language education experts. Furthermore, teachers might be able to share their chatbot programs with other teachers, which will eventually contribute to quality enhancements in customized chatbots. Last, other technical issues such as more accurate speech recognition for non-native speech or more authentic speech synthesis functions should be addressed further (Sydorenko et  al., 2019).

# Limitations

There are several noticeable limitations in this study. First, this study examined only a small number of Korean EFL students in the classroom setting; therefore, the findings may not be broadly generalizable to other contexts. Future studies need to examine language learners from a diverse range of proficiency levels, ages, and cultural backgrounds for further theorizing and empirical examination of chatbot affordances and their effects. Second, the type of conversation topic used for the chatbot tasks may have affected the emergence of affordance. Future studies need to consider how affordances emerge differently depending on the topic. In addition, it would be an interesting topic to explore how students’ experiences or opinions evolve over time. Last, the researcher exclusively used a type of chatbot that utilized both audio and text modes in English only. Chatbots with different modalities and language settings might generate different affordances.

# Conclusion

This study aimed to identify and inventory chatbot affordances in primary EFL classrooms while giving implications regarding how chatbot technology could be utilized for young EFL students. Various types of possibilities created by the use of chatbots were confirmed through the analysis of student interview data and student-chatbot interaction logs. The analysis has revealed the presence of pedagogical, technological, and social affordances. In addition, although the chatbot affordances were provided to all students in the classroom, each affordance was perceived differently depending on the student. This study also identified how the chatbot affordances affected various aspects of psychological states in language learners, particularly regarding their motivation to learn English through chatbots. By considering the different types of affordances and their influences on language learners, teachers will be able to facilitate language learning as professionals who effectively take advantage of the privileges provided by technological development.

The current study also provides important implications regarding the future direction of language learning that utilizes chatbots. First, customized chatbots created using a chatbot builder were used for the language course. As shown in this paper, teachers might be able to take advantage of chatbot builders such as Dialogflow as an effective way of incorporating chatbots into their language classes (Jeon, 2021; Lee et  al., 2020). To support this effort, teacher training courses in the CALL field may need to cover both technical and pedagogical elements of chatbot creation and use. Next, these chatbots have the potential to be utilized in a considerably broader range within the field of language learning (Jeon, 2021). Although the chatbots built for this paper were exclusively administered to only 36 students, some teachers would be able to simultaneously apply their own chatbots to much larger numbers of students once they begin to create their own chatbots. Last, students might be able to interact with chatbots ubiquitously (Fryer et  al., 2020). It would be possible for students to interact with chatbots anywhere and at any time if teachers digitally share their chatbot software and have students download the software to their own devices, such as smartphones. Chatbots in this environment may yield different affordances and effects for language learning and teaching.

# Notes

1. Websites related to chatbot builders mentioned in this article -Botsify (developed by Botsify) https://botsify.com/chatbot-for-education -Chatfuel (developed by Chatfuel) https://chatfuel.com -Dialogflow (developed by Google) https://dialogflow.com

# Disclosure statement

No potential conflict of interest was reported by the authors.

# Notes on Contributor

Jaeho Jeon is a doctoral student of English Education at Seoul National University of Education and a primary school English teacher in South Korea. His research interests include dynamic assessment, teacher education, and computer-assisted language learning.

# ORCID

Jaeho Jeon $\textcircled{1}$ http://orcid.org/0000-0002-1161-3676

# References

AlKhayat, A. (2017). Exploring the effectiveness of using chatbots in the EFL classroom. In P. Hubbard & S. Ioannou-Georgiou (Eds.),Teaching English reflectively with technology (pp. 20–36). IATEFL.   
Anderson, J. (2015). Affordance, learning opportunities, and the lesson plan pro forma. ELT Journal, 69(3), 228–238. https://doi.org/10.1093/elt/ccv008   
Atwell, E. (1999). The language machine: The impact of speech and language technologies on English language teaching. British Council.   
Benson, P. (2011). Teaching and researching autonomy in language learning (2nd ed.). Longman. https://doi.org/10.4324/9781315833767   
Bibauw, S., François, T., & Desmet, P. (2019). Discussing with a computer to practice a foreign language: Research synthesis and conceptual framework of dialogue-based CALL. Computer Assisted Language Learning, 32(8), 827–877. https://doi.org/10.108 0/09588221.2018.1535508   
Bower, M. (2019). Technology-mediated learning theory. British Journal of Educational Technology, 50(3), 1035–1048. https://doi.org/10.1111/bjet.12771   
Braun, V., & Clarke, V. (2006). Using thematic analysis in psychology. Qualitative Research in Psychology, 3(2), 77–101. https://doi.org/10.1191/1478088706qp063oa   
Chun, D., Smith, B., & Kern, R. (2016). Technology in language use, language teaching, and language learning. The Modern Language Journal, 100, 64–80. https://doi. org/10.1111/modl.12302   
Coniam, D. (2014). The linguistic accuracy of chatbots: Usability from an ESL perspective. Text & Talk, 34(5), 545–567. https://doi.org/10.1515/text-2014-0018   
DeKeyser, R. (2010). Practice for second language learning: Don’t throw out the baby with the bathwater. International Journal of English Studies, 10(1), 155–165. https:// doi.org/10.6018/ijes/2010/1/114021   
Divekar\*, R. R., Drozdal\*, J., Chabot\*, S., Zhou, Y., Su, H., Chen, Y., Zhu, H., Hendler, J. A., & Braasch, J. (2021). Foreign language acquisition via artificial intelligence and extended reality: Design and evaluation. Computer Assisted Language Learning. Advance online publication. https://doi.org/10.1080/09588221.2021.1879162   
Divekar, R. R., Drozdal, J., Zhou, Y., Song, Z., Allen, D., Rouhani, R., Zhao, R., Zheng, S., Balagyozyan, L., & Su, H. (2018 Interaction challenges in AI equipped environments built to teach foreign languages through dialogue and task-completion [Paper presentation]. DIS 2018 - Proceedings of the 2018 Designing Interactive Systems Conference (pp. 597–610). https://doi.org/10.1145/3196709.3196717   
Dörnyei, Z. (2002). The motivational basis of language learning tasks. In: P. Robinson (Ed.), Individual differences in second language acquisition (pp. 137–158). John Benjamins. https://doi.org/10.1075/lllt.2.10dor   
Dörnyei, Z. (2014). The psychology of the language learner: Individual differences in second language acquisition. Routledge. https://doi.org/10.4324/9781410613349   
Freiermuth, M. R. (2001). Native speakers or non-native speakers: Who has the floor? Online and face-to-face interaction in culturally mixed small groups. Computer Assisted Language Learning, 14(2), 169–199. https://doi.org/10.1076/call.14.2.169.5780   
Freiermuth, M. R. (2020). Introduction and overview: The inescapable confluence of technology, psychology and second language learners and users. In M. R. Freiermuth, & N. Zarrinabadi (Eds.), Technology and the psychology of second language learners and users (pp. 3–32). Palgrave Macmillan. https://doi.org/10.1007/978-3-030-34212-8   
Freiermuth, M. R., & Huang, H. (2012). Bringing Taiwan and Japan closer: A look at an intercultural online synchronous chat task and its effect on motivation. Language Teaching Research, 16(1), 61–88. https://doi.org/10.1177/1362168811423341   
Freiermuth, M., & Jarrell, D. (2006). Willingness to communicate: Can online chat help? International Journal of Applied Linguistics, 16(2), 191–213. https://doi. org/10.1111/j.1473-4192.2006.00113.x   
Fryer, L. K., Ainley, M., Thompson, A., Gibson, A., & Sherlock, Z. (2017). Stimulating and sustaining interest in a language course: An experimental comparison of Chatbot and Human task partners. Computers in Human Behavior, 75, 461–468. https://doi. org/10.1016/j.chb.2017.05.045   
Fryer, L. K., Coniam, D., Carpenter, R., & Lăpușneanu, D. (2020). Bots for language learning now: Current and future directions. Language Learning & Technology, 24(2), 8–22. http://hdl.handle.net/10125/44719   
Fryer, L. K., Nakao, K., & Thompson, A. (2019). Chatbot learning partners: Connecting learning experiences, interest, and competence. Computers in Human Behavior, 93, 279–289. https://doi.org/10.1016/j.chb.2018.12.023   
Gibson, J. J. (1986). The ecological approach to visual perception. Lawrence Earlbaum.   
Hill, J., Randolph Ford, W., & Farreras, I. G. (2015). Real conversations with artificial intelligence: A comparison between human-human online conversations and human-chatbot conversations. Computers in Human Behavior, 49, 245–250. https:// doi.org/10.1016/j.chb.2015.02.026   
Huang, W., Hew, K. F., & Fryer, L. K. (2021). Chatbots for language learning—Are they really useful? A systematic review of chatbot‐supported language learning. Journal of Computer Assisted Learning. Advance online publication. https://doi.org/10.1111/jcal.12610   
Hwang, G. J., & Chang, C. Y. (2021). A review of opportunities and challenges of chatbots in education. Interactive Learning Environments. Advance online publication. https://doi.org/10.1080/10494820.2021.1952615   
Jeon, J. (2021). Chatbot-assisted dynamic assessment (CA-DA) for L2 vocabulary learning and diagnosis. Computer Assisted Language Learning. Advance online publication. https://doi.org/10.1080/09588221.2021.1987272   
Jia, J. (2003). The study of the application of a keywords-based chatbot system on the teaching of foreign languages. 1–11. http://arxiv.org/abs/cs/0310018   
Johnson, D. (1992). Approaches to research in second language learning. Longman.   
Kessler, G. (2018). Technology and the future of language teaching. Foreign Language Annals, 51, 205–218. https://doi.org/10.1111/flan.12318   
Kim, J.-S., & Jang, E.-S. (2020). Artificial intelligence literacy-based teaching conditions and model for improving primary English language learners’ global digital citizenship. Association of Global Studies Education, 12(3), 169–198. https://doi.org/10.19037/agse.12.3.06   
Lee, S., Noh, H., Lee, J., Lee, K., Lee, G. G., Sagong, S., & Kim, M. (2011). On the effectiveness of robot-assisted language learning. ReCALL, 23(1), 25–58. https://doi. org/10.1017/S0958344010000273   
Lee, J. H., Yang, H., Shin, D., & Kim, H. (2020). Chatbots. ELT Journal, 74(3), 338–344. https://doi.org/10.1093/elt/ccaa035   
Plonsky, L., & Ziegler, N. (2016). The CALL-SLA interface: Insights from a second-order synthesis. Language Learning & Technology, 20(2), 17–37. http://llt.msu.edu/issues/ june2016/plonskyziegler.pdf   
Sabharwal, N., & Agrawal, A. (2020). Cognitive virtual assistants using Google Dialogflow. Apress, https://doi.org/10.1007/978-1-4842-5741-8   
Smutny, P., & Schreiberova, P. (2020). Chatbots for learning: A review of educational chatbots for the Facebook Messenger. Computers & Education, 151, 103862. https:// doi.org/10.1016/j.compedu.2020.103862   
Soon, G. Y., Warris, S. N., & Al Marimuthu, R. (2020). Chinese language learners’ intrapersonal and interpersonal perceptions of a pinyin text-to-speech system. In M. R. Freiermuth, & N. Zarrinabadi (Eds.), Technology and the psychology of second language learners and users (pp. 381–401). Palgrave Macmillan. https://doi. org/10.1007/978-3-030-34212-8   
Stoffregen, T. A. (2003). Affordances as properties of the animal-environment system. Ecological Psychology, 15(2), 115–134. https://doi.org/10.4324/9780203726655-2   
Sydorenko, T., Smits, T. F. H., Evanini, K., & Ramanarayanan, V. (2019). Simulated speaking environments for language learning: Insights from three cases. Computer Assisted Language Learning, 32(1–2), 17–48. https://doi.org/10.1080/09588221.2018.1466811   
Timpe-Laughlin, V., Sydorenko, T., & Daurio, P. (2020). Using spoken dialogue technology for L2 speaking practice: What do teachers think? Computer Assisted Language Learning. Advance online publication. https://doi.org/10.1080/09588221.2020.1774904   
Ur, P. (1990). Discussions that work: Task-centered fluency practice. Cambridge University Press.   
van Doremalen, J., Boves, L., Colpaert, J., Cucchiarini, C., & Strik, H. (2016). Evaluating automatic speech recognition-based language learning systems: A case study. Computer Assisted Language Learning, 29(4), 833–851. https://doi.org/10.1080/09588221.2016.1167090   
van Lier, L. (2004). The ecology and semiotics of language learning: A sociocultural perspective. Kluwer Academic Publishers.   
Xu, Y., Wang, D., Collins, P., Lee, H., & Warschauer, M. (2021). Same benefits, different communication patterns: Comparing Children’s reading with a conversational agent vs. a human partner. Computers & Education, 161, 104059. https://doi.org/10. 1016/j.compedu.2020.104059   
Zou, B., Li, H., & Li, J. (2018). Exploring a curriculum app and a social communication app for EFL learning. Computer Assisted Language Learning, 31(7), 694–713. https://doi.org/10.1080/09588221.2018.1438474   
Zou, B., Liviero, S., Hao, M., & Wei, C. (2020). Artificial intelligence technology for EAP speaking skills: Student perceptions of opportunities and challenges. In M. R. Freiermuth, & N. Zarrinabadi (Eds.), Technology and the psychology of second language learners and users (pp. 433–463). Palgrave Macmillan. https://doi.org/10.1007/978-3-030-34212-8