# Examining the direct and indirect impacts of verbatim source use on linguistic complexity in integrated argumentative. writing assessment

Huiying Cai a, Xun Yana,b,

a Department of Linguistics, University of Illinois Urbana-Champaign, USA b Beckman Institute for Advanced Science and Technology, USA

# ARTICLEINFO

# ABSTRACT

Keywords:   
Source use   
Linguistic complexity   
Integrated argumentative writing   
Writing assessment   
Validity

Verbatim source use (vsU) in integrated argumentative writing tasks may enhance linguistic complexity of writing performance. This assistance might present an unequal advantage for testtakers across levels of writing proficiency, engendering validity and fairness concerns. While previous research has mostly examined the relationships between source use characteristics and proficiency levels, the relationship between VSU and linguistic complexity remains underexplored. To further unpack these relationships, this study examined both the direct impact of VSU on linguistic complexity of writing performances and its indirect impact through interaction with writing proficiency. Using natural language processing tools and techniques, we examined 34 linguistic complexity features and three vsU features of 3250 argumentative writing performances on a university-level English Placement Test (EPT). We performed exploratory factor analysis to identify linguistic complexity dimensions and applied mixed-effect models to examine how VsU features and proficiency level impacted these dimensions. Post-hoc analyses suggested weak direct impacts of different VsU features on linguistic complexity, which might reflect different essay writing strategies. However, no meaningful indirect impact was found. The findings help unravel the impact of VsU on argumentative writing and provide empirical evidence for validity arguments for integrated writing assessments.

# 1. Introduction

Integrated writing in academic contexts is acomplex composing process that usually involves the use of sources. In second language (L2) contexts, L2 writers can use source texts not only as content resources but also as language support (Leki & Carson, 1997). In language testing, integrated writing tasks, both summary and argumentative tasks, have been widely employed to assess L2 writing proficiency for academic purposes and are believed to be more authentic than other types of writing tass .g., Plakans, 2009; Plakans & Gebril, 2012; Weigle & Parker, 2012).

Despite the authentic nature of integrated writing tasks, how L2 test-takers use source texts can impact their writing performance Researchers have been concerned about the impact of source use on the linguistic complexity of esays produced by test-takers in integrated writing assessment (e.g., Chan & Yamashita, 2022; Cumming et al., 2005; Gebril & Plakans, 2016). This is because when content and especially language taken from source materials are incorporated into the essay, features of writing performance (e., linguistic complexity) may misrepresent test-takers writing proficiency, leading to validit ssues. Within the argument-based validity framework (Chapelle et al, 2008; Kane, 1992, 2013), validity ssues associated with source use mostly pertain to the evaluation and explanation inferences of test scores.

To date, many studies have examined the asociations between source use-in particular verbatim source use (VsU)-and inte grated writing proficiency (mostly operationalized through esay scores aigned by human raters (e.g., Cumming et al., 2005; Plakans & Gebril, 2012). Their findings suggest a complex relationship between vsU and integrated writing proficiency. Features related to VsU tend to show a negative association, whereas features related to relevance of source and other strategies of source integration (i.e, paraphrasing and summarizing) tend to show a positie ssociation (eg, Plakans & Gebril, 2013). Theseassociations led scholars t ge that soure use hould be trad as part ofthe construct, where diffent es can be use tffeniate igh vs. low proficiency level writers (e.g., Plakans, 2009).

However, how source use impacts linguistic complexity of writing performances remains relatively underexplored. There are two possibilities, ech having  diffent mplication fr writing aent. Onthe one hand, sure use can dety impact (i. hance) linguistic complexity. Along this line of hypothesis, vsU, as a unique case of source use, was found to improve lingustic complexit of essays in all proficiency levels (Cumming et a., 2005; Gebril & Plakans, 2016; Kyle & Crossey, 2016). On the other hand, source use might also interact with writing proficiency to have an indirect impact on linguistc complexity; that is, tet-takers at diffrent pro ficiency levels might be capable of utilizing sourceto ance thir esays linguistc complexity to different degrees. For example, it is possible that higher proficiency writers might be more capable of utlizing their own linguistic skill to integrate source texts to enhance the essays content and inguistic quality, whereas lower proficiency writers might only be able to use source texts verbatim without the abilit to integrate them into their own language or argumentation. If this dferential benefit from source texts is indeed the case, the source texts might proide unequal amounts of language support for test-takers at different proficiency level depending on how they use the sources), thereby afecting the relationship between writing proficiency and linguistic complexit. This differential impact might lead to faines isues during theevaluation of writing peformance and reduce the explanation power of linguistic complexity in proficiency differences. Therefore it i necessary to further explore how source use characteristics impact linguistic complexity and whether they interact with writing proficiency. Although a few studies have focused on the direct impact of VSU on linguistic complexity, to our best knowledge, nostudies have examined the potential indirect impact of Vsu through interaction with writing proficiency. This study examined both direct and indirect impacts of multiple VsU features on a wide range of lexical and syntactic complexity features.

# 2. Literature review

# 2.1. Source use in L2 integrated argumentative writing

Integrated argumentative writing is a complex composing process that involves the use of sources. When sources are used, source material can provide both content and language support. Writers can select relevant information from source texs and synthesize and integrate others ideas to generate cohesive arguments (Spivey, 1997). To help present the arguments effctively, writers can also model on the language used in the source texts. In particular, although undesirable, vsU has been observed as a commonly used writing strategy by L2 test-takers to compensat for insuficient language proficiency, leading to inaccurate ssessment of writing ability (Plakans, 2009; Plakans & Gebril 2012; Weigle & Parker, 2012). Previous research has found that L2 writing performances across scores or proficiency levels tend to demonstrate differences in source use features, such as purpose of source use (Gebril & Plakans, 2009), relevance and type of source (Kyle, 2020; Plakans & Gebril, 2012, 2013), and strategies of source integration (e.g., Weigle & Parker, 2012).

In contrast, few studies have investigated the impact of source use on the inguistic complexity of writing performance. Most existing research compared writing performances on independent vs. integrated writing tasks and found that integrated writing performance tend to exhibit higher syntactic and lexical complexity than independent writing performances (Cumming et a., 2005; Kyle & Crossley, 2016). Employing a different aproach, Gebril and Plakans (2016) found that using words directly from source texts can increase the lexical diversity of argumentative essays produced by L2 writers. I their study, two raters first identified (through impressionistic judgment) the words in source texts that test-takers might potentiall borrow and compiled asource-related vocabulary list. Then, the researchers removed all words on the list from test-taker essays and compared thesays lexical diversty before and fter the word removal. Results showed  ubstantil decrese in lexical diverst at all proficiency leels and a greater decrease at lower-proficiency levels than higher-proficiency levels, and consequently, lexical diversty beame better at ifferntiating proficiency levels. However, removing the source-text words that raters speculated to be borrowed by test-takers might also exclude some words that tes-takers actually know, thereby underrepresenting test-takers' vocabulary knowledge. In fact, few studies provided direct evidence to suggest that the overlapped words between essays and source texts are necessarily words that are beyond test-takers vocabulary knowledge because it is hard to distinguish whether test-takers master the words they borrow (Appel & Wood, 2016) Nevertheles, many researchers speculate that the lack of astrong relationship between linguistic complexity (especially lexical complexity) and proficiency level might be due to source use, and linguisic complexity ofesays without taking into consideration of source use tends to overestimate test-takers' lexico-grammatical knowledge (Chan & Yamashita, 2022; Cumming et al., 2005; Gebril & Plakans, 2009). Thus, f raters do not consciously take into account language use in source texts when scoring writing performances, the linguistic complexity of esay performances might obscure test-takers writing proficiency (Weigle & Parker, 2012). However, how to account for the impact of source use on linguistic complexity in test-taker essays while stil validly and fairly representing

est-takers' linguistic knowledge remains an open question.

# 2.2. Fitting source use under the argument-based validity framework for integrated argumentative writing assessment

Regarding source use, most validity and fairnesssues pertain to the evaluation and explanation inferences inthe argument-based validity framework (Chapellet al., 2008; Kane, 1992, 2013). Atthe lel of evaluation inference, f cran test-takers bnefited more from verbatim use of source texts than other test-takers, it might lead to potential farnes isues during the scoring process therey negatively influencing the scoring validity (Plakans & Gebril, 2012; Weigle & Parker, 2012). At the level of explanation inference, the common approach of validation isto examine a range of construct-relevant linguistic features in writing and investigate the extent to which these features can explain diferences across scoring levels (i.., writing proficiency levels). However, as argued earlier, the presence ofsource use might complicate this validation proces. That is instead of directly examining the relationships betwen proficiency levels and linguistic complexity features, one also needs to closely examine the impact of source use on linguistic complexity while accounting for the relationship between proficiency level and linguistic complexity.

Findings from previous research on VSU can help generate expectations on the relationships among source use, proficiency level. and inguistic complexity. First, the observation that integrated writing performances (with the use of external sources) tend to be linguistically more complex than independent writing performances suggests that source use willikely have a direct impact on linguistic complexity (Cumming t al., 2005; Kyl & Crossey, 2016). However,to be a valid writing proficiency asssment method, this impact should be (considerably) smaller than the impact of writing proficiency. In addition, research on vsU has suggested that test-takers at lower proficiency levels tend touse more word strings directly from sourcetext (Plakans & Gebril, 2013), use more word strings from reading texts but e from listening materials (Kyle, 2020; Plakans & Gebril, 2013), and use longer word srings (Appel Wood, 2016). Thus, it is reasonable to speculate that VsU may provide a larger boost for lower-proficiency test-takers than for higher-proficiency test-takers, thereby reducing the diffrence in linguistic complexity across proficiency levels. In this case, VSU would interact with writing proficiency to have an additional, indirect impact on linguistic complexity. Although Gebril and Plakans's (2016) findis hae suggetd this hyothes fw studis avexmid the indect impact of source use (., the intractionffct) on linguistic complexity. Thus, this line of validation research should be pursued to strengthen the explanation power of linguistic complexity for proficiency differences on integrated writing tasks.

# 2.3. Linguistic complexity features reflecting L2 writing proficiency

Writing researchers tend to measure linguistic complexity features at both lexical and syntactic levels using corpus-linguistic indices and have found meaningful associations between L2 writing proficiency and these features (Crossley, 2020). Lexical complexity is mostly measured in terms of lexical diverst, lexical density, and lexical sophistcation (Crossey, 2020). Lexical diversity describes how many unique words are used in a given text (Wolfe-Quintero et al., 1998. The commonly used lexical diversity indices include type-token ratio (TTR) (Johnson, 1944) and their mathematical transformations (e.g., Guiraud, 1960), Moving Average TTR (MATTR, Covington & McFall, 2010) and Measure of lexical textual diversty (MTLD, McCarthy & Jarvis, 2010). Researchers have benefited from the lexical diversity indces and found that higher-roficiency test-takers tend to produce more diffeent words  u, 2012; Zhang, 2022).

Lexical densit reflects the extent to which information carried by lexical items i concentrated (Read, 2000. The widely used index to measure lexical density is the ratio of the number of content words to the otal number of words (Ure, 1971). Reearchers have found signficant dffernes in lexcal densty acos proficiency levels in academic writing tass and suggetd that lexical dsity is a strong predictor of academic writing proficiency (e.g., Kim, 2014; Gregori-Signes & Clavel-Arroitia, 2015).

Lexical sophistication refers to how sophisticated the words in a text are (Wolfe-Quintero et al., 1998). Higher-proficiency writers are expected to use words lessfrequently use in general or more specifically used within particular contexts and word combinations that are more regularly and appropriately used (Kyle, Crossley & Berger, 2018). Based on this expectation, researchers developed various indice to operationalize lexicl sophistication, incuding word frequency (i., the number of word occurrences in a reference corpus of texts) and word range (i.e., the number of texts in acorpus in which a particular word occurs) (e.g., McNamara et a., 2015; Kyle & Crossley, 2016), polysemy and hypernymy (Guo et al., 2013), $n$ gram frequency (i.e., the number of word co-occurrences in a reference corus of texts)(e., Crossly et al., 2012), and n-gram association strength (.e, the condtional probability that the words consisting of n-grams wil occur together in a reference corpus) (e.g., Granger & Bestgen, 2014). Using these indices, indings have suggested that higher-proficiency writers tend to produce words with a lower frequency (e.g., McNamara et al., 2015), a narrower range (Kyle & Crossey, 2016) lower polysemy score, and/or higher hypernymy score (Guo et l., 2013) and n-grams with a lower frequency (e.g., Crossey et al., 2012) and/or higher asociation strength scores (Granger & Bestgen, 2014; Garner et al., 2020.

Syntactic complexity represents the extent to which syntactic structures are varied and sophisticated (Bulte & Housen, 2014). Traditionall, researchers in writing assessment use holistic indices based on T-unit to measure syntactic complexity (Lu, 2010). However, those features are difficult to interpret because they \*combine multiple structural/yntactic distinctions into a single var iable" (Biber et al., 2020, p. 2). Complexity of different structures may have diferent effct n writing performance. Noun-phrasal structures normally used for information compression can better characterize academic writing, whereas clausal structures nor. mall used for elaboration are more commonly used in speaking (Biber & Gray, 2010). This suggests that the traditional indices are not sensitive enough to capture structural features specifically asociated with acadmic writing proficiency and call for more fine-grained features of syntactic complexit to not only bettr istinguish levels of writing proficiency but also interpret test scores more clearly (Kyle & Crossey, 2018). In reponse to this call,Kyle (2016) provided iegrained complexit indice for a array of tructural types at both clausal and noun-phrasal levels. Using these indices, Kyle and Crossley (2018) have found that noun-phrasal indices, along with one noun-clausal index (i.e, the average number of nominal subjects per clause), were bettr predictors of proficiency level than traditional complexity indices. Their results suggest that writing assessment research may need to include fine-grained complexity indices at both clausal and phrasal levels.

# 2.4. The present study

Motivated by the literature reviewed above, in order to provide source-use-related evidence for the validity argument f integrated argumentative writing tasks, this study examined both the direct impact of VsU on linguistic complexity after accounting for proficiency level and its interaction ffect with writing proficiency on linguistic complexity. The examination involved multiple features of VSU and a wide aray of linguistic complexity features at both lexical and syntactic levels related to writing proficiency. Specifically, the study addressed the following research questions:

1. Is there a significant relationship between writing proficiency and linguistic complexity?   
2. Does VsU directly impact linguistic complexity after accounting for writing proficiency?   
3. Does vsU indirectly impact linguistic complexity by interacting with writing proficiency?

# 3. Methods

# 3.1. Context of the study

This study focused on the writing section of alarge-scale English Placement Test (EPT) at a US university. The purpose of the test is to measure writing proficiency in academic contexts and place students into appropriate English as a second language (ESL) writing courses. The typical EPT test-takers are admitted intenational students with an English proficiency level ranging from B2 to C1 (i., from upper-intermediate to advanced level) on the CEFR scale (Council of Europe, 2001). The writing task requires test-takers to integrate information from a lecture and six short reading texts from 180 to 200 words each) on the same topic and produce a timed argumentative essay. Test-takers are allotted $1 0 0 \mathrm { { m i n } }$ to complete the whole task, which includes $1 0 \mathrm { { m i n } }$ to listen to the lecture and the remaining $9 0 \mathrm { { m i n } }$ to read texts and write the essay. They are allowed to listen to the lecture once but refer back to the reading texts as often as they need. The lecture provides a general background, while the reading texts present detailed information related to the shared topic. The source materials are adapted from published research articles or news stories. Essays are scored by human raters with a4-point rating scale with two critri, arumentation and lexicogrammar. The scale categorizes each essay into four proficiency levels (i., Level 1, 2, 3, and 4, from low to high). It should be noted that the evaluation weighs argumentation more than lexicogrammar to align with the requirements of the ESL courses. The scoring rubric does not explicitly consider source use behaviors. Although the scoring on the EPT does not impose clear penalties for VSU, raters are alerted to the possbility that tes-takers use language directly from sources during rater training, which might mask a lack of lexico-grammatical knowledge.

This study collected EPT essays from 2017 to 2021. Since test-takers with different first language (L1) backgrounds may have different views on VsU and use sources in different ways (e.g, Gebril & Plakans, 2009; Pennycook, 1996), we only included essays produced by tet-takers whose 1 was Chinee o control for potential L1 ffects. We excluded Level1 esays due to the small number of essays at this level $( < 2 ~ \% )$ . There were, in total, 3250 essays covering three proficiency levels (i.e., Level 2, 3, and 4) and 27 different prompt topics (see Appendix). The text length for the essays included in this study ranged from 153 words to 1379 words $( M = 5 7 7 . 9 7 $ $S D = 1 5 6 . 6 0 \mathrm { \Omega }$ . The prompts were carefully controlled to be comparable during content development. Based on the findings from a previous study (Author, 2021), there was no significant difference in linguistic complexity across the prompts and no significant impact of prompts on both scores and linguistic complexity of essays.

# 3.2. Feature extraction

# 3.2.1. Linguistic complexity features

We applied a set of natural language processing (NLP) tools to extract a wide rray of linguistic complexity features of the EPT essas at both lexical and syntactic levels: the Tool for the Automatic Analysis of Lexical Diversity (TAALED 1.4.1) (Kyle et al., 2021) the Tool for the Automatic Analysis of Lexical Sophistication (TAALEs 2.2) (Kyle, Crossley & Berger, 2018), and the Tol for the Automatic Analysis of Syntactic Sophistication and Complexity (TAAssc 1.3.8) (Kyle, 2016). Features rlevant to writing proficiency were selected and later subjectedto exploratory factor analysis (EFA) to reduce data dimension for more statistical power and identify the underlying factor structure of inguistic complexity (i.e, the sub-dimensions of linguistic complexity), taking into account the interplay among these features.

Among the indices provided by the NLP tools, we initially selected 311 indices relevant to writing proficiency based on the literature and judgments from two doctoral students in linguisics specializing in writing assessment. At the lexical level, we distin guished content words vs. unction words for fine-grained information. We selected al indices provided by TLED to extract features of lexical diversity and lexcal density. Note that we also included numbers of content tokens and types and numbers of function tokens and types for the EFA, which are commonly used to operationalize lexical diversity. The EFA solution identifies underlying fctors that can explain common variance shared among features. Although these indices alone might not necessarily be suficient to predict writing proficiency, they may provide additional information regarding lexical diversity for the EFA solution. Regarding lexical sophistication, we selected indice provided by TALES that fallinto the categories of word frequency and word range, polysemy and hypernymy, $n$ gram frequency, and $n$ gram association strength. The selected frequency and range indices are all derived from reference corpora in either general or academic written registers because the EPT was designed to evaluate writing ability in academic contexts. In addition to these lexical sophistication indices, we used indices derived from lis of academic language (Coxhead, 2000) and $n$ gram range (i.e., the number of texts in a corpus in which particular words co-ocur). Although few studies using these indices found significant relationships between writing proficiency and academic language and $n$ gram range, the expert panel suggested that they could be informative for EPT esays linguistic complexity features. We also chose the indice f verb lemma frequency provided by TAAssC as they were considered more relevant to lexical sophistication.

At the syntactic level, we selected both holistic and fine-grained indices of syntactic complexity provided by TAAssc. For holistic indices, TAAssC adopts the T-unit-based indices from the L2 Syntactic Complexity Analyzer (L2SCA, Lu, 2010). We also incorporated the fine-grained indices at both noun-phrasal and clausal levels provided by TAssc. To test the rliability of the too in the current study, we checked TAAssC's accuracy on a random sample of 30 essays (ten per each proficiency level) from the EPT dataset. For holistic indices, since the tool did not provide structure identification results, we manually computed the indices following the operational definitions in Lu (2010). High correlations (ranging from 0.849 to 0.982) were found between reearch-calculated and tool-calculated indices. For fine-grained indices, TAAssc demonstrated a $9 2 . 2 8 \%$ labeling accuracy, determined through percentage agreement with human identification results.

We then performed a correlation analysis between proficiency level and all selected linguistic complexity indices to further filter out indices that had nonsignificant corrlations with proficiency levels in the EPT data. Given that proficiency level is a categorical variable, we conducted Spearman's rho correlations between each index and proficiency level and excluded the indices having absolute correlations with proficiency levels below 0.1, indicating their relationships with proficiency levels were negligible (Cohen, 1988). After this process, we checked Pearsons's correlations amongall retained indices. If two indices had an extremely high correlation $( | r | > 0 . 8 )$ , we removed the one with a lower correlation with proficiency levels in order to avoid multicollinearity for later analysis (Young, 2018). In the end, we selected in total 34 indices of linguistic complexity, including indices regarding vocabulary, noun-phrasal structures, and clause structures and indices based on length of syntactic structures (see Table 1).

Table 1 Selected indices of linguistic complexity.   

<html><body><table><tr><td>Type</td><td>Dimension</td><td>Index</td></tr><tr><td>Vocabulary</td><td> Basic lexical complexity</td><td>Number of content word tokens Number of function word types</td></tr><tr><td></td><td>Lexical diversity</td><td>TTR for function words Root TTR for content words</td></tr><tr><td></td><td>Lexical density</td><td>Ratio of the number of content word tokens to the total number of word tokens Ratio of the number of content word types to the total number of word types</td></tr><tr><td></td><td>Lexical sophistication</td><td>Mean frequency score of content words (BNC-written) Log mean frequency score of function words (COCA-academic written) Log mean frequency score of verb lemmas (COCA-written)</td></tr><tr><td></td><td></td><td>Mean frequency score of verb lemma types (COCA-written) Mean range score of content words (BNC-written) Log mean range score of content words (COCA-academic written)</td></tr><tr><td></td><td></td><td>Mean mutual information score for bigram association strength (cOCA-academic written)</td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td>Mean Delta P association score for bigram association strength (COCA-academic written)</td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td>Mean Delta P unigram-bigram association score for trigram association strength (cOCA-academic</td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td></td><td>written)</td></tr><tr><td></td><td></td><td>Mean Delta P bigram-unigram association score for trigram association strength (cOCA-academic</td></tr><tr><td></td><td></td><td>written)</td></tr><tr><td></td><td></td><td>Normed count of AwL words in text</td></tr><tr><td></td><td></td><td>Normed count of words from AWL Sublist 2 in text</td></tr><tr><td></td><td></td><td>Mean polysemy score for content words</td></tr><tr><td></td><td></td><td>Mean hypernymy score for nouns and verbs (for the average value for all senses and all paths)</td></tr><tr><td>Noun-phrasal structures</td><td>Noun phrase</td><td></td></tr><tr><td></td><td></td><td>Mean number of dependents per nominal.</td></tr><tr><td></td><td>complexity</td><td>Mean number of dependents per agent</td></tr><tr><td></td><td></td><td> Mean number of prepositions per nominal</td></tr><tr><td></td><td></td><td>Mean number of prepositions per nominal subject.</td></tr><tr><td></td><td></td><td>Mean number of prepositions per object of the preposition</td></tr><tr><td></td><td></td><td>SD of the number of dependents per nominal subject (no pronouns)</td></tr><tr><td></td><td></td><td>SD of the number of dependents per agent (no pronouns)</td></tr><tr><td></td><td></td><td>SD of the number of dependents per passive nominal subject</td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td>Clause complexity</td><td>Mean number of passive agents per clause</td></tr><tr><td></td><td></td><td>Mean number of nominal subjects per clause</td></tr><tr><td></td><td></td><td>Mean number of passive auxiliary verbs per clause</td></tr><tr><td>Length of syntactic</td><td></td><td></td></tr><tr><td></td><td>Syntactic complexity</td><td>Mean length of T-unit</td></tr></table></body></html>

Note. TTR $=$ type-token ratio; $\mathsf { B N C } =$ British National Corpus; COCA $=$ Corpus of Contemporary American English; AWL $=$ Coxhead's (2000, 2011) Academic Word List; $\mathbf { S D = }$ standard deviation.

# 3.2.2.VSU features

In this study, we operationalized vsU as a consecutive tring of words that are identical with a string in the source text. However, during this proces, we found two types of trigs: (1) word strings that are rather generic formulaic sequences or lexical bundes (e., the findings suggest that), and (2) word strings that are content or context specific (e.g, replace print textbooks with ebooks). We did not consider the irst type of strings as VsU because these are common phrases and bundles that writers could use acros contexts. In contrast, we considered the second type of strings as Vsu. Moreover, as word strings could vary in length (i.e., number of words), we examined word stings with three, four, five, six, and seven words and found that the proportion of generic phrases and bundles decreased dramatically as the number of words increased, reaching a low level (less than $3 \%$ ) once the strings were five words or longer. In addition, when we closely examined content-specific word strings that were thee or four word long, we found that most of the strings were fixed noun phrases and specialized terms used in the source texts (e.g., minimum legal drinking age). These strings might be dificult to avoid even if the writers were cognizant of plagiarism and cautious of VsU. Thus,to automate the extraction of VSU word strings from the large number of texts examined in this study, we decided to set five words as the threshold length for VSU. This threshold is also supported by Appel and Wood's (2016) findings that writr at lower proficiency levels tend to verbatim use long strings with more than four words from sources more frequently than writers at higher proficiency level. Therefore, we regarded a string with more than four words that overlap with the corresponding sources as an instance of VsU in an attempt to exclude generic phrases commonly used in academic writing.

We wrote a Python script to identify vSU strings and obtain the number and mean length of VSU strings for each essay, normalized by text length (per 1o00 words). These features were obtained for vsU strings from reading texts and listning material, separately. Similar to linguistic complexity indice, we conducted Spearman's rho correlations between each vsU feature and proficiency levels and Pearson's correlations between features. In order to avoid multicolinerity for later analysis we removed the feaure that had an extremely high correlation $( | r | > 0 . 8 )$ with another feature but a lower correlation with proficiency level--the mean length of VSU strings from listning materials. The remaining vsU features included in this study were (1) the number of Vsu strings from reading texts, (2) the mean length of VSU strings from reading texts, and (3) the number of VSU strings from listening materials.

# 3.3. Data analysis

After extracting the 34 features of linguistic complexity at both lexical and syntactic levels, we first performed the EFA on them using the psych package in R (Revell, 2016) to identify the sub-dimensions of inguisic complexity. We chose a maximum likelihood (ML) extraction method and an Oblimin rotation which allows correlations between the factors. One variable, mean length of T-unit was log-transformed to meet the normality assumption. The Kaiser-Meyer Olkin Measure of Sampling Adequacy (KMO) was 0.72, which is considered mediocre fr factor analysis (Kaiser, 1974). We determined the number of factors to retain based on ascre plot of eigenvalues. Variables with a communalit lessthan 0.1 (Comrey & Lee 1992) or did not meet a minimum factor loading threshold of $+ / \mathrm { - } 0 . 3 0$ (Biber & Jones, 2005) were excluded as they contributed littl to the underlying construct. After each exclusion, we re-ran the EFA until all variabes in the model were qualified to retain. By transforming the data based on the final solution, each essay was assigned  factor score for each dimension of linguistic complexit i., dimension score). We then applied linear mixed-effects models (LMMs) to examine the relationships between proficiency level, lingustic complexity dimension scores, and the vsU features. Inthis study, LMMs were itted separately to predict each linguistic complexity dimension (the dependent variable).Although we did not find a significant dffrence in linguistic complexity across prompts, we included potential random efects asociated with prompts. To ensure suficient sample size within each prompt, we excluded the prompts with les than five essays in any proficiency level. The remaining data for the LMMs included 22 prompts and 2837 esays in total. We first examined random intercepts for each dependent variable (i.e., linguistic complexity dimension score) using the intraclas corrlation coeficient (ICc), which indicates variability between groups compared to within groups. All CCs exceeded the cutoff value of 0.05 (Snijders & Bosker, 2011), indicating that there were meaningful variations in every linguistic complexity dimension score led by esays across prompts. Thus, we included prompts as random intercepts in the LMMs.

To examine the relationship between writing proficiency and linguistic complexity dimensions (RQ1), we used proficiency level as an independent variable in the LMMs to predict each dimension score. We first examined the need for a random slope for proficiency level across prompts, but the addition of a random slope either resulted in overftting or did not significantly improve model fit thus, we did not add a random slope of proficiency level into the models. The fitted models met all LMM assumptions. For each of them, we adopted the ye II analyss f variance ov) wth Sattrthwate's method to est te significance f the roficiecy lel effect. Post-hoc analyses using Tukey's honestly significant difference (HSD) were conducted for pairwise comparisons of proficiency levels. As reasoned above, we expected that essays in higher-proficiency levels have higher linguistic complexity dimension scores.

We then examined the direct impact of VsU features on each inguistic complexity dimension score after accounting for proficiency level (RQ2). Starting from the models identified in RQ1, for each model, we adedVSU variables oneat a time into the model as a fixed main effect and retained the variable that made the significant model mprovement in predictig the dimension score as determined by an LRT and led to the smallst Akaike information criterion (AIC).Similar to proficiency level, we also examined whether a random slope was needed every time we added a variable. The results suggested that no random slopes were needed. We kept adding the VSU features until no additional variable significantly improved the model performance. The inal models with the added vsU main ffects met all ssumptions of LMMs. Positive direct impacts of VsU features on linguistic complexity dimension scores were expected. However, we expect these impacts to have smaller effect sizes (i.e., partial $\eta ^ { 2 } )$ than those of proficiency level.

To examine whether the vsU feature(s) inthe model interacted with proficiency level, indirectly impacting linguistic complexity dimension scores (RQ3), we followed similar steps as the above to add interaction terms betweensU features and proficiency lel to the best fitting models identified in RQ2. If the model with an interaction effct outperformed the model without one, we would infer that the vsU feature had an indirect impact on the linguistic complexity dimension through interaction with proficiency level. Due to the lack of previous literature, we do not have a strong expectation regarding the significance of the interaction terms.

# 4. Results

4.1. Dimensions of linguistic complexity and their relationships with proficiency level

The scre plot indicated a four-factor model to represent the variance-covariance of the linguistic complexity features. The four factors together accounted for around $5 0 ~ \%$ of the variance. Table 2 presents the structure of the final solution of EFA (with factor loadings and communalities for each linguistic complexity index),the proportion of variance explained by each factor, and the correlations among the factors. Each variable was ssigned to one factor, where it had the strongest oading (bolded in Table 2). Based on these features, we interpreted the four dimensions in this study as follows:

: Dimension 1: Noun phrasal complexity : Dimension 2: Context specificity : Dimension 3: Lexical diversity : Dimension 4: Lexical sophistication

Among them, Dimension 1 was more relevant to syntactic complexity, and the rest of the thre dimensions were more relevant to lexical complexity.

Accordingly, each essay was assigned four dimension scores. Descriptive statistics (see Table 3) show that esays in higher pro ficiency leels had higher scores in noun phras complexity (D1), context specificity (D2), lexical diversty (D3), and lexic sophistication (D4).

Table 4 shows the results of the LMMs using proficiency level as the fixed effect and random intercepts for prompts. Controlling for the variabilit of intercepts acros prompts, the fixed efects of proficiency level on every linguistic complexity dimension score were significant. Fig. 1 presents thestimated marginal means of each lingustic complexity dimension score across proficiency levels based on the LMMs. All four dimensions had positive relationships with proficiency level.

According to the results of the Typ III ANOVA using Satterthwaite's method, proficiency level had significant main effects on all linguistic complexity dimension scores, namely, noun phrasal complexity $( F ( 2 , 2 8 2 8 . 9 8 5 ) = 1 0 3 . 4 9 5$ $p < . 0 0 1$ $\eta _ { p } ^ { 2 } = 0 . 0 6 8 )$ , context specificity $( F ( 2 , 2 8 1 6 . 5 9 4 ) = 5 8 . 3 8 1$ $p < . 0 0 1$ $\eta _ { p } ^ { 2 } = 0 . 0 4 0 )$ , lexical diversity $( F ( 2 , 2 8 2 4 . 1 5 9 ) = 5 8 . 8 2 3$ $p < . 0 0 1$ $\eta _ { p } ^ { 2 } = 0 . 0 4 0 )$ , and lexical sophistication $( F ( 2 , 2 8 1 9 . 8 0 8 ) = 2 6 . 3 6 2 , p < . 0 0 1$ $\eta _ { p } ^ { 2 } = 0 . 0 1 8 )$ . Although the effect sizes were not strong, the overall effects of proficiency level were meaningful. Proficiency level had the greatesteffect on noun phral complexity, followed by context specificity and lexical diversity, and the smallet effct on lexical sophistcation. The following post hoc comparisons using the Tukey HSD test revealed that for every linguistic complexity dimension, the mean dimension score was sgnificantly different between every pair of proficiency levels $( p < . 0 5 )$ (see Table 5). These results further support the meaningful relationships between proficiency level and linguistic complexity dimensions. As expected, essays in higher proficiency levels presented more complex noun phrasal structures, lexical items more specific to contexts, more diverse content words but les diverse function words, and/or more sophisticated lexical items than essays in lower proficiency levels.

Table 2 Exploratory factor analysis of linguistic complexity features.   

<html><body><table><tr><td>Features</td><td>D1</td><td>D2</td><td>D3</td><td>D4</td><td>h2</td></tr><tr><td>Number of content word tokens</td><td>0.0088</td><td>-0.0430</td><td>0.9891</td><td>0.1897</td><td>0.9950</td></tr><tr><td> Number of function word types</td><td>-0.2013</td><td>0.0729</td><td>0.7514</td><td>-0.2570</td><td>0.6711</td></tr><tr><td>TTR for function words</td><td>-0.2164</td><td>0.1469</td><td>-0.7348</td><td>0.1401</td><td>0.6469</td></tr><tr><td>Root TTR for content words</td><td>0.0731</td><td>0.3692</td><td>0.5625</td><td>-0.0698</td><td>0.4723</td></tr><tr><td>Ratio of the number of content word tokens to the total number of word tokens</td><td>0.0074</td><td>0.0292</td><td>-0.0029</td><td>0.8599</td><td>0.7539</td></tr><tr><td>Mean frequency score of content words (BNC-written)</td><td>-0.0989</td><td>-0.2642</td><td>-0.0041</td><td>-0.6435</td><td>0.6069</td></tr><tr><td>Mean frequency score of verb lemma types (COCA-written)</td><td>0.1464</td><td>-0.1315</td><td>-0.1821</td><td>-0.4164</td><td>0.2214</td></tr><tr><td>Log mean frequency score of function words (COCA-academic written)</td><td>0.5636</td><td>0.1045</td><td>-0.0397</td><td>0.0599</td><td>0.3836</td></tr><tr><td>Mean range score of content words (BNC-written)</td><td>-0.1112</td><td>-0.7837</td><td>0.0172</td><td>-0.2854</td><td>0.8745</td></tr><tr><td>Log mean range score of content words (CoCA-academic written)</td><td>0.0825</td><td>-0.9024</td><td>0.0218</td><td>0.0004</td><td>0.7736</td></tr><tr><td>Mean Delta P association score for bigram association strength (COCA-academic written)</td><td>0.1535</td><td>0.5413</td><td>-0.0011</td><td>-0.2578</td><td>0.3629</td></tr><tr><td>Mean Delta P unigram-bigram association score for trigram association strength (cOCA-academic written)</td><td>0.1531</td><td>0.3559</td><td>-0.0136</td><td>-0.0766</td><td>0.1757</td></tr><tr><td>Mean Delta P bigram-unigram association score for trigram association strength (cOCA-academic written)</td><td>0.0488</td><td>0.5404</td><td>-0.0017</td><td>-0.0833</td><td>0.2977</td></tr><tr><td>Mean polysemy score for content words</td><td>-0.1918</td><td>-0.4257</td><td>0.0566</td><td>-0.0123</td><td>0.2771</td></tr><tr><td>Mean hypernymy score for nouns and verbs (for the average value for all senses and all paths)</td><td>0.2475</td><td>0.4428</td><td>-0.0072</td><td>0.2487</td><td>0.4607</td></tr><tr><td> Mean number of dependents per nominal</td><td>0.7946</td><td>-0.1746</td><td>-0.0053</td><td>0.1338</td><td>0.6154</td></tr><tr><td> Mean number of prepositions per nominal</td><td>0.7332</td><td>0.2089</td><td>-0.0019</td><td>-0.1774</td><td>0.6511</td></tr><tr><td> Mean number of prepositions per nominal subject</td><td>0.4988</td><td>0.1785</td><td>-0.0194</td><td>-0.1866</td><td>0.3251</td></tr><tr><td>Mean number of prepositions per object of the preposition</td><td>0.5510</td><td>0.0952</td><td>0.0444</td><td>-0.1496</td><td>0.3410</td></tr><tr><td> SD of the number of dependents per nominal subject (no pronouns)</td><td>0.4951</td><td>0.0261</td><td>0.0335</td><td>-0.0356</td><td>0.2529</td></tr><tr><td>Log Mean length of T-unit</td><td>0.5327</td><td>-0.1017</td><td>0.0933</td><td>-0.0248</td><td>0.2732</td></tr><tr><td>Mean length of clause % Variance</td><td>0.6595</td><td>0.0467</td><td>0.0411</td><td>0.2207</td><td>0.5670</td></tr><tr><td>Dimension correlations</td><td>11.20</td><td>14.31</td><td>15.85</td><td>8.63</td><td></td></tr><tr><td>D1</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>D2</td><td>-0.0159</td><td></td><td></td><td></td><td></td></tr><tr><td>D3 D4</td><td>0.0838 -0.0552</td><td>0.3281 0.2174</td><td>0.1759</td><td></td><td></td></tr></table></body></html>

Note. Number of prompts $= 2 2$ , total $N = 3 2 5 0$ An oblique rotation was used. $h ^ { 2 } =$ communality; D1, 2, 3, and $4 =$ Dimension 1, 2, 3, 4

Table 3 Descriptive statistics of linguistic complexity dimension scores.   

<html><body><table><tr><td>Score</td><td>Noun phrasal complexity Mean (SD)</td><td>Context specificity</td><td>Lexical diversity</td><td>Lexical sophistication</td></tr><tr><td>2</td><td>-0.277 (0.956)</td><td>-0.167 (0.962)</td><td>-0.150 (0.923)</td><td>-0.107 (0.941)</td></tr><tr><td>3</td><td>0.220 (0.941)</td><td>0.104 (0.897)</td><td>0.078 (0.900)</td><td>0.079 (0.903)</td></tr><tr><td>4</td><td>0.451 (1.048)</td><td>0.432 (1.024)</td><td>0.477 (0.996)</td><td>0.212 (0.889)</td></tr></table></body></html>

Note. Number of prompts $= 2 7$ , total $N = 3 2 5 0$

Table 4 LMMs with fixed effect of proficiency level and random intercept of prompt.   

<html><body><table><tr><td>Effect</td><td colspan="2">Model 1 Noun phrasal complexity</td><td colspan="2">Model 2 Context specificity</td><td colspan="2">Model 3 Lexical diversity</td><td colspan="2"> Model 4 Lexical sophistication</td></tr><tr><td>Fixed effects</td><td>Estimate (SE)</td><td></td><td>Estimate (SE)</td><td></td><td>Estimate (SE)</td><td></td><td>Estimate (SE)</td><td></td></tr><tr><td>(Intercept)</td><td>-0.309 (0.055)***</td><td></td><td>-0.067 (0.136)</td><td></td><td>-0.164 (0.067)*</td><td></td><td>-0.067 (0.090)</td><td></td></tr><tr><td>Level3</td><td>0.431 (0.037)***</td><td>0.045</td><td>0.219 (0.029)***</td><td>0.020</td><td>0.233 (0.035)***</td><td>0.015</td><td>0.188 (0.033)***</td><td>0.011</td></tr><tr><td>Level4</td><td>0.744 (0.065)***</td><td>0.044</td><td>0.487 (0.051)***</td><td>0.031</td><td>0.620 (0.062)***</td><td>0.035</td><td>0.339 (0.058)***</td><td>0.012</td></tr><tr><td>Random effects</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Between-prompt variance</td><td>0.050</td><td></td><td>0.400</td><td></td><td>0.085</td><td></td><td>0.165</td><td></td></tr><tr><td>Within-prompt variance</td><td>0.869</td><td></td><td>0.531</td><td></td><td>0.772</td><td></td><td>0.677</td><td></td></tr><tr><td>ICC</td><td>0.055</td><td></td><td>0.430</td><td></td><td>0.099</td><td></td><td>0.196</td><td></td></tr></table></body></html>

Note. Number of prompts $= 2 2$ , total $N = 2 8 3 7$ . ICC $=$ intraclass correlation coefficient; Level3 $=$ proficiency level of three; Level4 $=$ proficiency level of four. \* \*p <0.01 p <0.001 \*p < 0.05

![](img/ca66dbb96e7e47f1ca719c18756d2c0dc231a120656050b7e6a8994113630ade.jpg)  
ig. 1. Estimated marginal means of linguistic complexity dimension scores across proficiency levels. Note. Number of prompts $= 2 2$ , total $N = 2 8 3 7$ . Error bars indicate $9 5 ~ \%$ confidence interval.

# 4.2. Direct impact of vsU features on linguistic complexity dimension scores

Table 6 preents the results f the s for ech lingustic complexty dimension afer adding the fixed main i.., direct) efects of VSU features that led to the most significant improvement in model performance. After controlling for the variability of intercepts acoss prompts and the fixed effects of proficiency level, linguistic complexity dimension scores wereall significantl affected by at least one VU feature. As expected, nuber ofVSU strings had positive impacts on linguistic complexity dimension scores. Spefiall, essays contaning more VsU strings from reading texts or listening materials had higher context specificity and lexical sophistication scores. In addition, essays contaning mores strings from reading texts also had higher lexical diversity (content words vs. function words).

However, contrary to our expectation, mean length of VSU strings had negative impacts. Specifically, esays containing longer VSU strings from reading texts had lower noun phrasal complexity and lexical diversity (content words vs. function words). However, the effects of vsU features on linguistic complexity dimension scores (measured by partial $\eta ^ { 2 } )$ were much weaker than the effects of proficiency level. The effects of number of VU strings from listening materials and the efect f the su features n lexical diversity were all negligible. Furthermore, compared with the LMMs without ading VSU main effects (see Table 4), the coeficints of proficiency level decreased after adding VsU main effct, suggesting possible redundancies or interactions between vsU features and proficiency level.

# 4.3. vsU features interacting with proficiency level

Table 7 shows the results of LRTs comparing the models with and without interaction between a VSU feature and proficiency level for each linguistic complexity dimension. No interactions led to significant improvement in the model performance at the significance level of.05. This indicated that there was no need for any interaction effects to better predict the linguistic complexity dimension scores, suggesting that no indirect impacts of VsU features through interaction with proficiency level were detected on linguistic complexity dimensions.

# 5. Discussion

# 5.1. Relationship between writing proficiency and linguistic complexity

The significant relationships found between writing proficiency and the dimensions of linguistic complexity largely support val. idity arguments for the integrated argumentative writing task of EPT at the explanation inference level. Test-takers at higher proficiency levels tend to produce more complex noun phrase structures, lexical items more specific to the context, more diverse content words but less diverse function word, and/or more sophisticated lexical items. That said, the generally weak effects of proficiency level on linguistic complexity dimensions might be due to the nature of the test. As we pointed out in the methods section, although the EPT focuses on argumentation and lexicogrammar as its two main constructs in writing, argumentation outweighs lexicogrammar in scoring because argumentation is given more emphasis in ESL writing courses. Thus, it is possble that the scored proficiency level is not as strongly related to lexico-grammatical features such as linguistic complexity.

Table 5 Tukey's Post-hoc test results for pairwise comparisons between proficiency levels.   

<html><body><table><tr><td></td><td>t</td><td>df</td><td>p</td><td></td></tr><tr><td colspan="5">D1: Noun phrasal complexity</td></tr><tr><td>Level2 - Level3</td><td>-11.538</td><td>2836</td><td>&lt;.001</td><td>0.045</td></tr><tr><td>Level2 - Level4</td><td>-11.374</td><td>2827</td><td>&lt;.001</td><td>0.044</td></tr><tr><td>Level3 - Level4</td><td>-4.744</td><td>2828</td><td>&lt;.001</td><td>0.008</td></tr><tr><td colspan="5">D2: Context specificity</td></tr><tr><td>Level2 - Level3</td><td>-7.495</td><td>2819</td><td>&lt;.001</td><td>0.020</td></tr><tr><td>Level2 - Level4</td><td>-9.513</td><td>2818</td><td>&lt;.001</td><td>0.031</td></tr><tr><td>Level3 - Level4</td><td>-5.183</td><td>2818</td><td>&lt;.001</td><td>0.009</td></tr><tr><td colspan="5">D3: Lexical diversity</td></tr><tr><td>Level2 - Level3</td><td>-6.615</td><td>2830</td><td>&lt;.001</td><td>0.015</td></tr><tr><td>Level2 - Level4</td><td>-10.056</td><td>2823</td><td>&lt;.001</td><td>0.035</td></tr><tr><td>Level3 - Level4</td><td>-6.222</td><td>2824</td><td>&lt;.001</td><td>0.014</td></tr><tr><td colspan="5">D4: Lexical sophistication</td></tr><tr><td>Level2 - Level3</td><td>-5.702</td><td>2824</td><td>&lt;.001</td><td>0.011</td></tr><tr><td>Level2 - Level4</td><td>-5.864</td><td>2820</td><td>&lt;.001</td><td>0.012</td></tr><tr><td>Level3 - Level4</td><td>-2.582</td><td>2820</td><td>.027</td><td>0.002</td></tr></table></body></html>

Note. Number of prompts $= 2 2$ , total $N = 2 8 3 7 .$ Mean diff. $=$ Mean difference.

Table 6 LMMs with fixed effects of proficiency level and vsU features and random intercept of prompt.   

<html><body><table><tr><td colspan="2">Effect</td><td colspan="2">Model 1 Noun phrasal complexity</td><td colspan="2">Model 2 Context specificity</td><td colspan="2"> Model 3 Lexical diversity</td><td colspan="2">Model 4 Lexical sophistication</td></tr><tr><td colspan="2">Fixed effects</td><td>Estimate (SE)</td><td></td><td>Estimate (SE)</td><td></td><td>Estimate (SE)</td><td></td><td>Estimate (SE)</td><td></td></tr><tr><td colspan="2">(Intercept)</td><td>-0.148 (0.060)*</td><td></td><td>-0.162 (0.136)</td><td></td><td>-0.178 (0.068)*</td><td></td><td>-0.166 (0.091)</td><td></td></tr><tr><td rowspan="4">Proficiency level</td><td>Level3</td><td>0.427 (0.037)***</td><td>0.069</td><td>0.204 (0.029)***</td><td>0.035</td><td>0.224 (0.035)***</td><td>0.037</td><td>0.173 (0.033)***</td><td>0.015</td></tr><tr><td>Level4</td><td>0.734 (0.064)***</td><td></td><td>0.448 (0.051)***</td><td></td><td>0.597 (0.062)***</td><td></td><td>0.298 (0.057)***</td><td></td></tr><tr><td>No.St</td><td></td><td></td><td>0.027 (0.029)***</td><td>0.029</td><td>0.016 (0.004)***</td><td>0.005</td><td>0.027 (0.003)***</td><td>0.023</td></tr><tr><td>No.St M.Le</td><td>-0.016 (0.002)***</td><td>0.032</td><td>0.036 (0.016)*</td><td>0.002</td><td>-0.004 (0.002)*</td><td>0.002</td><td>0.051 (0.018)**</td><td>0.003</td></tr><tr><td colspan="2">Random effects</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td colspan="2">Between-prompt variance</td><td>0.057</td><td></td><td>0.393</td><td></td><td>0.082</td><td></td><td>0.169</td><td></td></tr><tr><td colspan="2">Within-prompt</td><td>0.840</td><td></td><td>0.514</td><td></td><td>0.768</td><td></td><td>0.659</td><td></td></tr><tr><td colspan="2">variance ICC</td><td>0.063</td><td></td><td>0.433</td><td></td><td>0.096</td><td></td><td>0.205</td><td></td></tr></table></body></html>

Note. Number of prompts $= 2 2$ , total $N = 2 8 3 7$ ICC $=$ intraclass correlation coefficient. Level3 $=$ proficiency level of three; Level4 $=$ proficiency level of four; $\mathbf { N o . S t r . R = }$ number of VsU strings from reading texts; M.Len.R $=$ mean length of VsU strings from reading texts; ${ \bf N } { \bf 0 . } S { \bf t r . } { \bf L } =$ number of VSU strings from listening material.

Table 7 Likelihood ratio test results for interactions between proficiency level and VsU features.   

<html><body><table><tr><td></td><td>?</td><td>df</td><td>p</td></tr><tr><td>D1: Noun phrasal complexity</td><td></td><td></td><td></td></tr><tr><td>Model with Level M.Le</td><td>2.676</td><td>2</td><td>0.262</td></tr><tr><td>D2: Context specificity</td><td></td><td></td><td></td></tr><tr><td>Model with Level No.St</td><td>1.189</td><td>2</td><td>0.552</td></tr><tr><td>Model with Level No.St</td><td>2.531</td><td>2</td><td>0.282</td></tr><tr><td>D3: Lexical diversity</td><td></td><td></td><td></td></tr><tr><td>Model with Level No.St.</td><td>5.935</td><td>2</td><td>0.051</td></tr><tr><td>Model with Level M.Le</td><td>3.768</td><td>2</td><td>0.152</td></tr><tr><td>D4: Lexical sophistication</td><td></td><td></td><td></td></tr><tr><td>Model with Level No.St.</td><td>4.518</td><td>2</td><td>0.105</td></tr><tr><td>Model with Level No.St</td><td>1.738</td><td>2</td><td>0.420</td></tr></table></body></html>

$p < 0 . 0 0 1$ p <0.01 p < 0.05   
Note. Number of prompts $= 2 2$ , total $N = 2 8 3 7 .$ Level3 $=$ proficiency level of three; Level4 $=$ proficiency level of four; No. $\operatorname { s t r } . \mathrm { R } =$ number of VSU strings from reading texts; M.Len.R $=$ mean length of VsU strings from reading texts; $_ { \mathrm { N o . S t r . L } }$ $=$ number of VsU strings from listening materials.

Among the linguistic complexity dimensions, proficiency level had greater efects on noun phrasal complexity at the syntactic level than the other dimensions at the lexical level (especially the lexical sophistication dimension). Ths suggests that lexical complexity dimensions might not reflect proficiency differences as effctively as noun phraal complexity in integrated argumentative writing assesment. This finding aligns with previous literature in that the weaker impact on lexical complexity might be due to the presence of sources (Chan & Yamashita, 2022). Because test-takers have a shared topic and goal to make an argument based on the sources, they are likely to produce essays with similar content. Restricted by the content, the lexical items produced by test-takers might be similar and limited, either retrieved from their own lexicon or borrowed from source texts, leading to a narrower range of lexical sophisti. cation. However, compared with lower-proficiency test-takers, higher-proficiency test-takers tend to write essays closer to the topic with relevant evidence from sources and be more automatic at utilizing a wider range of linguistic resources. Thus, they tend to produce lexical items that are more context-specific and diverse. That might be why proficiency levels had stronger efects on context specificity and diversity than lexical sophistication. Contrary to lexical features, syntactic features do not have as close an association with content as exical features and thus would not be constrained by the content. Therefore, the presence of source use would not lead to much change in the ffect of proficiency level on noun phrasal complexity, which is also regarded as representative of academic written discourse (Biber & Gray, 2010). In summary, the presence of sources in integrated argumentative writing tass might weaken the relationships betwen writing proficiency and linguistic complexity dimensions at the lexical level (compared with the noun phrasal complexity dimension), thereby lowering the explanation power of lexical complexity for proficiency differences.

5.2. Direct impact of vsU on linguistic complexity after accounting for writing proficiency

Based on the final best-performing model predicting each inguistic complexity dimension, this study sugests that VsU features tend to have direct impacts on all dimensions in addition to proficiency level, though weaker in comparison. More importantly, the direct impacts of vsu features dfer in terms of quantity and length of Vu (see Table 8). s the findings suggest, test-takers who use more strings (from reading texts and/or listning materials tend to produce inguisically more complex essays, whereas test-takers who use longer strings from reading texts tend to produce linguisticaly simpler essays. In the section below, we explore plausible explanations for these contrastive relationships with additional post-hoc analyses.

# 5.2.1. Quantity of VsU strings

The first layer of this finding is fairly traightforward to interpret. That is, using a larger quantity of strings directly from source texts is associated with lingustically more complex texts. The positive impact of quantit is as expected and aligns with previous findings: the presence of sources iself might prompt test-takers to produce more complex language to create more academically oriented contexts (Cumming et al., 2005; Kyle & Crossey, 2016). However, as test-takers use the strings from sources for content support (i.e, to develop the argument in the essay), vsU might inevitably also enhance the linguistic complexity of writing performances. This explanation aligns with findings in previous literature (Gebril & Plakans, 2016), pointing to a generally small boosting effect from source use on linguistic complexity.

# 5.2.2. Length of VSU strings

The second layer of the finding requires further unpacking. That is tet-takers who directly use longer trings from source texts tend to have lower inguistic complexity, which was not as expected and contradictory to the previous layer. However, there are two possible explanations for the negative impact of length: (1) the language of the strings used from sources for argumentation was so simple that it resulte ina linguisticlly simple esay; (2) the language riginally produced by test-takers was so simple that een using strings from source texs could not raise their esays' linguisic complexity beyond their proficiency. The assumptions behind the two explanations are rather differet. The first explanation assumes that test-takers would be capable of producing essays linguistically more complex than the source materials. However, given that most of the source materials are modeled from published research articles or news storie, it is unlikely that 2 writers who can write at that leve of complexity would stillneed to take the EPT see the Methods for the range of proficiency levels among the participants).

In comparison, the second explanation assumes a possibleassociation between the length of strings directl from source texts and proficiency level. That i, lower-proficiency test-takers tend to copy longer strings for language support than higher-proficiency testtakers, but their proficiency leels are so low that the enefit from source texts is not sufficient to make  sustantil boost in linguistic complexity. This assumption seems to be supported by previous literature, suggesting the possbilit that lower-proficiency L2 writers tend to rely on the language from sources more to compensate for their insufficient proficiency (e.g., Plakans, 2009). However, this explanation suggests a possible interaction betwen source use and proficiency level, which was not significant in the LMM results. To further explore these explanations, we conducted post-hoc descriptive analyses by simply computing Spearman Rho correlations between mean length of VsU and proficiency level. Although no meaningful correlations were found, there was a weak trend, where Level 4 essays appeared to have on average shorter VsU strings $( M = 9 . 4 6$ $S D = 7 . 2 9 _ { \it \Delta }$ than Level 3 essays $( M = 1 0 . 4 0$ $S D = 9 . 6 5$ and Level 2 essays $( M = 1 0 . 3 7$ $S D = 1 1 . 5 7 ) $ . This suggests that lower-proficiency test-takers had a slightly higher tendency to use longer strings from sources verbatim. Meanwhile, the proportion of VsU strings directly copied from source texts was rather low $M = 3 . 3 9 \ \%$ $S D = 5 . 3 2 \%$ , making it difficult for source use to substantially contribute to essays' linguistic complexity. Based on these post-hoc analyses the second explanation seems more plausible, suggesting that test-takers with lower lexico-grammatical resources rely more on source texts (epecially the reading materials) for language support and copy longer strings a test-taking trategy. However, since there is only so much one can copy from source texts, vsU alone might not be enough to mask a lack of lexico-grammatical knowledge when writing an argumentative essay. In ths case, the length of VSU strings might be more related to using sources as language support rather than content support in integrated argumentative tasks. Therefore, the combination of these results suggests that there is some dgre f intraction btween and proficiency level (i. indirect mpact f source use) on linuistic complexity, but the interaction istoo weak to reach a meaningful impact. Despite this possible explanation, we would like to stress that these analyses regarding VU and proficiency level are purely post-hoc and did not reach statistical significance. Moreover, ater accounting for the impact of proficiency level, the impacts of vsu on lingustic complexity tend to be small and negligible. Thus, our in. terpretations regarding vsU should be taken with a grain of salt. Follow-up studies are needed to test the generalizabilit of the contrastive impacts and further examine the plausibility of our tentative interpretation.

Table 8 Direct impacts of VsU features on linguistic complexity dimensions.   

<html><body><table><tr><td>VSU features</td><td>Source type</td><td>Linguistic complexity dimension</td><td> Impact (+/-)</td></tr><tr><td rowspan="4">Number of strings</td><td rowspan="2">Reading texts</td><td>Context specificity</td><td>+</td></tr><tr><td>Lexical diversity</td><td>+</td></tr><tr><td rowspan="2">Listening materials</td><td>Lexical sophistication</td><td>+</td></tr><tr><td>Context specificity</td><td>+</td></tr><tr><td rowspan="2"></td><td rowspan="2"></td><td>Lexical sophistication</td><td>+</td></tr><tr><td>Noun phrasal complexity</td><td>-</td></tr><tr><td rowspan="2">Length of strings.</td><td rowspan="2"> Reading texts</td><td> Lexical diversity</td><td>-</td></tr><tr><td></td><td></td></tr></table></body></html>

Note. $^ +$ indicates positive impact, - indicates negative impact.

Taken together, the findings indicate the direct impacts of VsU on linguistic complexity of writing performances after accounting for proficiency level, which are smaller than the impacts of proficiency level. These findings provide evidence for validity arguments for the interated arumentative writing task of EPT at the explanation inference level. In addition, the impacts might diffr in terms of quantity and length of VsU. These contrastive impacts might suggest that test-takers use source texts for diffrent functions or as different strategies: (1) using sources as content support for argumentation; (2)using sources as language support to aid for lack of linguistic resource. The potential assciations between the two VSU features and the two functions of VSU might tap into the role of source use in the writing process.

# 5.3. Indirect impact of VsU on linguistic complexity through interaction with writing proficiency

Despite the speculations on the association between vsU and proficiency level, the interaction analyses surprisingly revealed no meaningful interaction effects between vsU and writing proficiency (i.e., indirect impact of source use on linguistic complexity), supporting validity arguments for the integrated argumentative writing task of EPT at the evaluation inference level. The lack of a differentil advantage from  acros proficiency levels suggests that the impact f su on esays linguistc complexity is unlikely to lead to fairness ssues during the scoring proces. At first glance, tis inding sms inconsistent with Gebril and Plakan's (2016) study, which suget differntial benefits for lower-proficiency test-takers in terms of lexical diversity. However, this discrepancy might be because of methodological ifferences; that is, their study removed all possile individual words from source texts that appeared in test-takers esays. As we argued, the removed source-text words might contain words that test-takers already know and thus lead to misrepresentation of the construct of their vocabulary knowledge. That said, there are other possible explanations as well As addressed in Section 5.1, the presence of source use seems to weaken the effcts of proficiency level on the lexical dimensions of complexity (especially for lexical sophistication). This finding, along with the lack of impact from vsU strings, suggests that the weakening impact on the relationship between proficiency level and lexical complexity might result from the use of shorter strings (i. e., primarily individual words and short phrases). In a word, although vsU features do not meaningfully moderate the relationship between writing proficiency and linguistic complexity, the presence of sources might inevitably reduce theeffects of proficiency level on linguistic complexity at the lexical level i integrated argumentative writing assessment. Nonetheless the lack of a differential advantage from VSU seems to suggest that the EPT rater training effectively raised raters' awarenes regarding VSU's potential to obscure test-takers' true writing ability, thereby circumventing fairness issues.

# 6. Implications, Limitations, and Conclusions

The findings of this study have both theoretical and practical implications. Theoreticall, the study has explored both direct and indirect impacts of VSU on lingustic complexity. The direct impacts suggest that source use can indeed enhance the linguistic complexity of writing performances, although test-takers might use source texts for different functions i.e, content vs. language support). These impacts are much weaker than the impact of proficiency. This suggests that even if test-takers can benefit from VSU, the boost is small oghostilow ratr tdifferniate twewting pfomf st-takr t diffe roficiy lels and assign essay scores accordingly his might be because integrated argumentative writing tass are designed to measure test-takers ability to integrate sources for argumentation purposes. Hence, VSU for language support would not provide a differential advantage (i.e, improve essay scores differently) across proficiency level. The lack of interaction effects between vsu and writing proficiency confirms that VSU might not necessarily result in fairness ssues during the scoring process of writing performances. That said, in practice, this would require raters to be consciously aware of VsU's impact on linguistic complexity and take it into account when assigning cores fortest-takers writing ability. The contrastive impacts of VU quantit and length can potentilly inform both human and machine raters in deciding test-takers' proficiency levels. When teaching integrated writing skill, instructors should encourage students to synthesize more pieces of evidence from sources to develop effective arguments and, in the meantime, provide clear guidelines to train students to use proper source use strategies to avoid copying long phrases or sentences. Moreover, the examination of the direct and indirect impacts of Vsu on ingustic complexity has provided empirical evidence for validity arguments for the EPT.

Nonetheles, the study has several limitations and sugestions for future research in integrated argumentative writing assessment First, we identified four dimensions of linguistic complexity through an EFA analysis specifically based on the EPT data. Conducting a confirmatory factor analysis (CFA) on a cross-validation dataset may increase the generalizability of these dimensions. Second, the data used here covered only one L1 background (i.e., Chinese). Future research needs to examine the impacts of vsU on writing performances for test-takers from other L1 backgrounds, which may provide further insights regarding farnessacross 1 groups. Test takers' prior exposure and training in source-based integrated writing should also be considered in the future. Third, as inguistic accuracy is another important indicator of proficiency lel (., Plakans et l., 2019), it s also worth exploring whether and how SU impacts linguistic accuracy of writing performances to provide more evidence for test validation. Fourth, in addition to the formal features of VsU strings (i.e., quantity and length), directly examining functional features of VsU strings may provide a deeper understanding of why and how test-takers verbatim use sources. Extending this line of research might make connections with the analysis of argumentation features in integrated argumentative writing tass. Last but not least, this study used essay scores to operationalize test-takers' writing proficiency. To avoid possblecircular logic in equating the two, future studies could use an independent measure Of writing proficiency.

Limitations notwithstanding, this study has provided empirical evidence for validity arguments of integrated argumentative writing tasks at both evaluation and explanation inference levels by further unpacking the relationships between VsU and lingustic complexity dimensions. The findings have sugested relatively weak, direct impacts of VsU but no meaningful indirect impact by interacting with writing proficiency. Moreover, post-hoc analyses also sugest that the extent to which test-takers use sources verbatim might not necessrily be a sign of lacking linguistic resources or proficiency. A higher quantity of Vsu strings might suggest the use of more content from sources for argument development, though a greater length of VsU might show a lack of lingustic resources. It is important to acknowledge that our tentative interpretations regarding vsU need further research to confirm their plausibility.

# CRediT authorship contribution statement

Huiying Cai: Writing - review & editing, Writing - original draft, Visualization, Validation, Project administration, Methodology, Investigation, Formal analysis, Data curation, Conceptualization. Xun Yan: Writing - review & editing, Writing - original draft, Supervision, Resources, Project administration, Methodology, Investigation, Funding acquisition, Conceptualization.

# Data availability

The authors do not have permission to share data.

Appendix. Distribution of essays by score for each prompt (sorted by prompt alphabetically)   

<html><body><table><tr><td>Prompt</td><td colspan="2">Proficiency level</td><td></td><td>Total</td></tr><tr><td></td><td>4</td><td></td><td>2</td><td></td></tr><tr><td>Cashless economy</td><td>9</td><td>65</td><td>83</td><td>157</td></tr><tr><td>Dress code</td><td>7</td><td>30</td><td>35</td><td>72</td></tr><tr><td>Early language learning</td><td>14</td><td>30</td><td>54</td><td>98</td></tr><tr><td>Ebooks</td><td>6</td><td>68</td><td>69</td><td>143</td></tr><tr><td> Foreign language education</td><td>8</td><td>113</td><td>111</td><td>232</td></tr><tr><td>Greenroofs</td><td>18</td><td>48</td><td>66</td><td>132</td></tr><tr><td>Letter grades</td><td>16</td><td>27</td><td>64</td><td>107</td></tr><tr><td>Marijuana legalization</td><td>17</td><td>76</td><td>34</td><td>127</td></tr><tr><td> Minimum drinking age</td><td>14</td><td>73</td><td>131</td><td>218</td></tr><tr><td> Monitoring online activity</td><td>13</td><td>80</td><td>44</td><td>137</td></tr><tr><td>Museums</td><td>9</td><td>28</td><td>40</td><td>77</td></tr><tr><td>Olympics</td><td>3</td><td>31</td><td>29</td><td>63</td></tr><tr><td> On-campus living</td><td>4</td><td>14</td><td>18</td><td>36</td></tr><tr><td> Online shopping</td><td>5</td><td>25</td><td>29</td><td>59</td></tr><tr><td>Patents</td><td>7</td><td>135</td><td>134</td><td>276</td></tr><tr><td>Penny</td><td>28</td><td>132</td><td>84</td><td>244</td></tr><tr><td>Personal data collection</td><td>16</td><td>48</td><td>64</td><td>128</td></tr><tr><td>Personality tests</td><td>1</td><td>62</td><td>57</td><td>120</td></tr><tr><td> Plastic packaging</td><td>6</td><td>24</td><td>32</td><td>62</td></tr><tr><td>Public utility internet</td><td>5</td><td>15</td><td>22</td><td>42</td></tr><tr><td>Remote learning</td><td>11</td><td>49</td><td>51</td><td>111</td></tr><tr><td> Social media</td><td>7</td><td>31</td><td>39</td><td>77</td></tr><tr><td>Tattoos</td><td>6</td><td>25</td><td>68</td><td>99</td></tr><tr><td>Universal basic income</td><td>4</td><td>10</td><td>22</td><td>36</td></tr><tr><td>Video games</td><td>11</td><td>81</td><td>54</td><td>146</td></tr><tr><td>Vocational schools</td><td>0</td><td>88</td><td>70</td><td>158</td></tr><tr><td>Zoo</td><td>11</td><td>28</td><td>54</td><td>93</td></tr><tr><td>Total</td><td>256</td><td>1436</td><td>1558</td><td>3250</td></tr></table></body></html>

# References

Apel, R d.016.  w nti i  t-a wtig ff  g d -ici  s Quarterly, 13(1), 55-71. https://doi.org/10.1080/15434303.2015.1126718   
Biber, D. a  0.  s at a  , ela, i.  s  e 9(1) 2-20.   
Biber D. a  rt  0    si s tie measurement. Journal of English for Academic Purposes, 46, Article 100869.   
Biber D.  5  sic  c r      . si nd Linguistic Theory, 1(2), 151-182.

https://doi.org/10.1016/j.jslw.2014.09.005 Chan, . msit, . (202). In wting an its r mtas. n ting 54, Aicle 10662.tp/i.org/10.106/. asw.2022.100662 Chapelle, C. A., Enright, M. K., & Jamieson, J. (2008). Building a validity argument for the Test of Eglish as a Foreign Language. Routledge. Cohen, J. (1988). Statistical Power Analysis for the Behavioral Sciences (2nd ed..,). Routledge. Comrey, A L, & Lee H. B. (1992).  Frst Course in Factor Analysis (2nd ed.). Psychology Pres. htps://doi.org/10.4324/9781315827506 Council f Euroe. (2001). Cmmon Euopean Framework of Referece for Languages: Leng eching, sssment. Cambridge Universt Pres. igto    (010 h     sic, , 40. https://doi.org/10.1080/09296171003643098 Coxhead, A. (2000). A new academic word list. TEs0L Quarterl, 34, 213-238. https://doi.org/10.2307/3587951 Coxhead, A. (2011). The academic word list 10 years on: Research and teaching implications. Tesol Quarterly, 45(2), 355-362. Crossley, S. A. (2020) Linguistic features in writing quality and development: An overview. Journal of Writing Research, 11(3), 415-443. Cosley,  ary,   . 012) ti the  ef l  usi  in.  in , 23-263. https://doi.org/10.1177/0265532211419331 05  n and Iner Pt s fr th   h R  0051) -7/./.102/3-80.005.0190. er, e,  l0   wr m   sf ld Linguistics in Language Teaching, 58(1), 51-74. https://doi.org/10.1515/iral-2017-0089 in Second or Foreign Language Assessment. Gel,  la  016.  s   wi a  ,  ad ici  f h or Academic Purposes, 24, 78-88. https://doi.org/10.1016/j.jeap.2016.10.001 Gager,   . 014)h uf o  n.  n-ive wie - t Aled Linguistics, 52, 229-252. https://doi.org/10.1515/iral-2014-0011 Gre 015t t Sciences, 198, 546-556. Guiraud, P. (1960). Problemes et methodes de la statistique linguistique. Reidel. uo,L,    013   i  in  e A comparison study. Assessing Writing, 18(3), 218-238. https://doi.org/10.1016/j.asw.2013.05.002 Johnson, W 194). Studies in langage bevior: I progra f rrch. Psychogical Mongh, 62) 1-15. tps:/oi.rg/10.1037/h0093508 Kaiser, H. F. (1974). Analysis of factorial simplicity. Psychometrika, 39, 31-36. https://doi.org/10.1007/BF02291575. Kane, M. T. (1992). An argument-based approach to validity. Psychological Bulletin, 112(3), 527. Kane  . 013. th o a   .  o n, 501) -7/./1200 Kim, J. Y. (2014). Predicting 2 Writing Proficiency Using Linguisic Complexity Measures: A Corpus-Based Study. English Teaching, 69(4), 27-51. Kyle . 2016rig yctic dment in  witing Fin ed n f yic mplxty and a in f sic phistication (Doctoral Dissertation). Retrieved from (http://scholarworks.gsu.edu/alesl_diss/35).. yle e     n g,  06..106. asw.2020.100467 Kyle K e, 06)h ionhp t xi histictin nd nd d rwtig. J o S ting 34 (4), 12-24. https://doi.org/10.1016/j.jslw.2016.10.003 Kyle, K, & Cosle, . . (2018. Mring syctic complxt n  wig sing fina claal and phral indce. Mod Lge Joal, 102, 333-349. Kyle  oey,   r, . 018.T  for he atc alyis f xi osticai ): vsi. ior , 50, 1030-1046. yle     1.t    0 Lei  ,  (97y f d  in   i 1, 3969. https://doi.org/10.2307/3587974 Lu, X. (2010). Automatic nalysis of syntactic complexity in second language writig. Intemationl Jounal of opus Lingusics, 15(4), 474496. Lu, X. (2012). The relationship of lexical richnessto the quality of ESL larners ral narratives. Modem Language Journal, 96(2), 190-208. carthy,   Jis, . 010)L   :aion st f sphstica c eit s. r eerh Methods, 42(2), 381-392. https://doi.org/10.3758/BRM.42.2.381 35-59. Penycook,  (196). rrowng thrs Wrd: xt, wrship, Memor, nd Plgris 01 Quarrl, 02, 201-230.hp:/do.g/10.2307/3588141 Plakans  (009. Dire syths in intad sond lgag writing amet. ge Tting 26(4), 561-587. hts/o.org/101177 0265532209340192 10.1016/j.asw.2011.09.002 Plas,  i i, 01.  , ,    i.  62 161-179 an 01    n 2 (3), 217-230. Relle  (06. ch: Ps o  ic,  it  (1.mr .t esten University. (http://CRAN.Rproject.org/package-psych). Snijders, T. A., & Bosker, R. J. (2011). Multilevel analysis: An introduction to basic and advanced multilevel modeling. SAGE,. Spivey, N. (1997). The constructivist metaphor: Reading, writing, and making of meaning. Academic Press. Ure, J. (1971). Lexical density and register differentiation. Applications of Linguistics, 23(7), 443-452. ee,  0       183/. org/10.1016/j.jslw.2012.03.004 olf- k  9   f   t  i. Young, D. S. (2018). Handbook of regression methods. CRC Press. Zhang, . 2022.he ionshi t exi e ad  wig qualty A f t.  l of p sics, 3), 371-39.

ssessment, and natural language processing.