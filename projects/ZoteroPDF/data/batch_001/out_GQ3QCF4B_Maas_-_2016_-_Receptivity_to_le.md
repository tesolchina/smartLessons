# Receptivity to learner-driven feedback in EAP

Clare Maas

There is still debate surrounding what constitutes the most effective feedback on EFL learners’ writing, particularly in English for Academic Purposes (EAP) settings. Unanswered questions are found in the literature on topics such as the best formats for feedback, the role of technology, authors’ authority over written texts, and ways of helping learners develop into autonomous writers. This study explores students’ receptivity to an approach to giving feedback on essays which I have developed to address learners’ preferences, include various delivery formats, and help students develop into independent academic writers: learner-driven feedback (LDF). In LDF, the feedback is given to the students by the teacher, but the learners ‘direct’ how and on what they receive feedback comments. The findings from the detailed survey data highlight a high level of student receptivity, and several other compelling reasons for piloting LDF on EAP writing courses, many of which may also justify trialling the approach in other ELT classrooms.

Introduction

Teachers and learners are often frustrated by ‘traditional’ forms of feedback given on L2 learners’ written work, meaning the practice where teachers directly correct language errors in handwritten form, and summarize problem areas beneath the text, often using metalinguistic comments. Indeed, since the 1970s, ELT has seen a problematization of error correction (Ferris 2004), and concerns that ‘traditional feedback’ is less effective at improving L2 writing competence than desired are increasingly visible in the literature.

It is against this backdrop that I devised a new feedback procedure: learner-driven feedback (LDF). LDF combines and adapts previously published ideas, and this study was conducted to explore English for Academic Purposes (EAP) students’ perceptions of the procedure.

Publications exploring the effectiveness of new(er) feedback procedures often include considerations of learner-centredness, personalization, intelligibility of comments, or issues of ‘authority’ over texts. Hyland and Hyland (2006) reviewed research into feedback on L2 writing and identified some central debates, including the best delivery mode(s), the role of technology, and how teachers can help students become autonomous writers. They concluded that the issues highlighted in their review had, at that point, not been satisfactorily resolved. Although a substantial number of studies have been reported subsequently, the debates surrounding potential solutions to these issues remain extensive.

Learner autonomy is often mentioned as a feature of ‘good’ feedback. It is generally understood to mean students being involved in decisions concerning study activities, understanding learning processes, and learning to conduct effective practice activities without direction by a teacher (Benson 2007).

To encourage learner-centred feedback and more learner autonomy, many institutions have embraced peer review, defined as the review of a text by colleagues in the same field, in this case fellow students working on similar assignments. It is important here to highlight the student–student nature of peer review. Bijami, Kashef, and Nejad (2013) evaluate peer review in ELT, and highlight that it promotes independent learning and critical thinking, and is a motivating way for students to receive formative feedback. None the less, they note that the most common drawback is the lack of openness among students to feedback from their peers.

Another direction of work investigates means of heightening students’ openness to teachers’ feedback and encouraging them to engage with feedback received, particularly by encouraging teachers to respond to learners’ individual queries, thus transforming the feedback process into a dialogue. Most work in this area involves adult learners, and/or those in EAP contexts. Bloxham and Campbell (2010), for example, trialled ‘interactive coversheets’, where students pose questions about their essays when submitting drafts. They found most students were encouraged to evaluate their work more carefully, and were grateful to receive personalized feedback. Moreover, the teachers reported being able to provide more focused feedback more quickly. One problem noted was that some students’ limited understanding of expectations affected their ability to ask good questions for feedback; hence the procedure may have mainly benefitted stronger students.

Similarly, Campbell and Schumm-Fauster (2013) required their students to pose feedback questions to determine what tutors focused on when reading essay drafts, for example, as footnotes or in margins. Their action research both stemmed from and supported the idea that ‘to advance in writing proficiency, the learner has to be open to suggestions and constructive criticism, and this is more likely to be the case if the teacher responds to problems identified specifically by the learner’ (Campbell and Schumm-Fauster ibid.: 60). Indeed, students in their survey study were receptive to the procedure, finding the feedback personal and motivating, and effective at meeting their individual needs regarding academic writing. This feedback method constitutes a central part of the LDF concept.

Further approaches have employed technology to supply feedback, which can also increase students’ receptivity. Johanson (1999) provides an introduction to the benefits of recording audio feedback in ESL writing classes, suggesting it saves teachers time, makes comments clearer, and feels more personal to students. These ideas are supported by studies

such as Brearley and Cullen (2012), who found that a three-minute audio recording could include around 500 words of feedback and did not take more time than marking essays by hand. Though their research did not focus on language learners, the students’ positive attitudes towards using audio recordings to provide feedback prompted its inclusion as one option in the LDF studied here. Also investigating technology in feedback, Farshi and Safa (2015) compared grades of EFL students who received handwritten, emailed, or no corrective feedback on written tasks over a 14-week term and found that emailed feedback led to significantly greater improvement on post-test grades than handwritten feedback.

As a further contribution to this work regarding feedback on EFL writing, I devised a procedure which combines and adapts these previously published ideas and allows learners to determine the feedback they receive. This procedure of LDF is based on the acceptance that learners are commonly more receptive to teacher feedback than to peer review and self-editing (Ferris op.cit.; Hyland and Hyland op.cit.), and also provides an impetus to move the feedback process closer to practices suggested to enhance learner autonomy. In LDF, learners ‘drive’ the feedback dialogue by asking for specific feedback, and then redraft based on this feedback. In LDF, the feedback is given by the teacher, but learners decide how and on what they receive feedback: they can choose between various formats (for example handwritten, email, audio recording) and are required to pose questions about their work to which the teacher responds (for example on grammar, vocabulary/register, referencing, organization). Focusing on the development of advanced learners’ academic writing, this study is an initial exploration of students’ receptivity towards LDF in EAP.

Research

The study was based on an academic writing course for two groups, each of 20 advanced EFL learners ( C1 on CEFR) at Trier University (Germany), which was assigned to me for a 14-week semester with two hours of contact time weekly. These students predominantly speak German as their L1 and have some foundation-level academic experience in both English and German. The course takes a process approach to essay composition.

On this course, students submitted three drafts of one 2,000-word discursive essay. The final version was awarded a grade, as summative assessment marks are required by the University. All feedback was LDF. As this was the first time the students had encountered LDF, the process was explained in the first lesson using the handout shown in Appendix 1. The students were also given the Department of English Studies’ grading matrix for essays, and, from discussions in class, gained insight into the aspects of language and writing that would affect their final essay scores.

Within the LDF procedure, students could choose between various modes of feedback: in-text corrections,1 correction symbols,2 handwritten feedback, email, audio recording, or face-to-face consultation. These modes are not mutually exclusive, as, for example, correction symbols can be used to give feedback either in handwritten or electronic form. Students were also free to vary the feedback they requested from draft

to draft. It is important to highlight that the content of the feedback did not vary based on the delivery format. None the less, handwritten feedback tended to be more concise as writing comments by hand is slower and less space-efficient, and audio recorded feedback tended to be more detailed as speaking feedback comments aloud is time-efficient, provided the tutor can set up the recording easily, which was the case here. The average length of the audio recordings in this study was $^ { 2 - 3 }$ minutes. The level of detail in emailed comments tended to be between these two approaches, though the time-efficiency of typing again depended on the tutor. If students requested feedback via email, this was typed into the document and attached to send back. Appendix 2 shows examples of feedback given.

As in Campbell and Schumm-Fauster’s (op.cit.) study, in order to receive feedback, students were required to ask questions about areas they would like to receive feedback on. These could focus on any aspect of writing, for example textual competence, vocabulary, or grammar, and could include both specific and general questions as appropriate. For example, a specific question might ask about differences between vocabulary items (for instance opportunity versus possibility), and a general question might request feedback on the formality of a certain passage. Their questions could be included as footnotes or in margins (most commonly used to ask about specific words/phrases), or at the end of the text (most commonly used to ask about general issues).

For this study, only questions asked by students were answered and other weaknesses of their writing were ignored when giving feedback on drafts. Only where students asked general questions such as ‘Are there any other mistakes?’ was feedback provided on language errors and textual weaknesses other than those mentioned in their feedback requests. Limiting feedback to students’ queries is partly what aims to make LDF so time-efficient, and it was thus important to explore students’ opinions on this aspect of the approach, too. On the final, graded version of their essays, students received feedback on all weaknesses of their work, thus helping to allay potential ethical concerns.

Since the study aimed to explore students’ reactions to this feedback procedure, the main data collection occurred via a written survey at the end of term, focusing on their perceptions of the usability and effectiveness of LDF. I developed the survey questionnaire to collect students’ comments on delivery modes, the perceived effectiveness of LDF for improving their general language accuracy and academic skills related to essays, and any problems they experienced with LDF. The survey questions were judged as valid by colleagues working in linguistics research. The simplicity of the instrument meant students could complete the questionnaire within the last lesson of the course, ensuring that recollections of their experiences were fresh. Since the survey focused on students’ own perceptions of their work with LDF, the problem of inaccurate self-reporting is reduced. One limitation of the survey is the possibility of moderator acceptance bias in students’ responses. By not informing the students about this study’s aims, I hope to have moderated this weakness. Thirty students completed th questionnaire; 14 males and 16 females, all aged between 23 and 27. All responses were anonymous.

Data comparing the same students’ grades on other essay assessments were not collected empirically, but added later whilst preparing this report for publication. There was no control group, though the comparison of students’ performance on the essay written using LDF and scores on similar assessments done (1) one year previously and (2) during the same semester, but where traditional feedback was given, may provide interesting insights to accompany the reports of students’ perceptions.

Table 1 shows responses to Question 1: What delivery forms for feedback have you asked for on this course? Most popular were audio recording (used by $6 { > }$ per cent of students) and email (60 per cent), followed by requests for correction symbols and responses to specific questions, each made by about half of the surveyed students. These figures exceed the numbers of students who requested handwritten comments (13 per cent) and in-text corrections (20 per cent), highlighting students’ willingness to make use of technology-based delivery formats and move away from ‘traditional’ feedback modes. Also, the fact that these numbers total more than $3 0$ (number of students surveyed) would seem to indicate that students tried different delivery modes over the course, again demonstrating an openness to the new approach.

Responses to the open-ended Question 6 (Overall what are the biggest advantages and difficulties of using LDF to help improve your English academic writing?) provide explanations of why students liked receiving audio or emailed feedback, mainly mentioning it being more detailed than usual, which I believe results from the fact that it is quicker for teachers to give feedback in these formats than writing texts by hand, and they can therefore say more, as Brearley and Cullen (op.cit.) also found. Another important point made by students was that audio feedback reportedly enabled them to identify through the teacher’s intonation how positive/ negative comments were, which they may find more difficult when hedging is used in written feedback, in accordance with Johanson’s (op.cit.) view. Having their feedback emailed or recorded also seemed to make students feel it was more personal and time had been invested in helping them individually, similar to views expressed in studies by Benson (op.cit.) and Campbell and Schumm-Fauster (op.cit.).

<html><body><table><tr><td>Form of feedback.</td><td>No. students.</td><td>Percentage (%)</td></tr><tr><td>Audio recordinge</td><td>20</td><td>67</td></tr><tr><td>Handwritten comments</td><td>4</td><td>13</td></tr><tr><td>Email</td><td>18</td><td>60</td></tr><tr><td>Oral/face-to-face feedback</td><td>6</td><td>20</td></tr><tr><td>In-text corrections.</td><td>6</td><td>20</td></tr><tr><td>Marking code/symbols</td><td>16</td><td>53</td></tr><tr><td>Teacher&#x27;s feedback on general aspects of writing</td><td>10</td><td>33</td></tr><tr><td>Teacher&#x27;s feedback to specific questions</td><td>16</td><td>53</td></tr></table></body></html>

No difficulties were mentioned in survey responses regarding the choice of delivery mode for the feedback. The findings indicate a high level of usability of LDF in this respect, and that students responded positively to this innovative feedback procedure.

Figure 1 shows students’ responses to Question 2: Which aspects of general language accuracy do you think LDF has helped you to improve, and to what extent? Three-quarters of students perceived improvements in transitions, 42 per cent significantly, and 33 per cent somewhat. Majorities also perceived improvement in grammar (42 per cent significantly, 40 per cent somewhat) and sentence structure (60 per cent significantly, 33 per cent somewhat). Regarding natural expression, text structure, and vocabulary, the number of students who perceived these features as being improved by LDF (93 per cent, 80 per cent, and $8 7$ per cent, respectively) is considerably higher than those perceiving no improvement.

Interestingly, a high number (67 per cent) perceived no improvement in their ability to set punctuation. This may be because few students asked about punctuation; most students’ questions focused on grammar, mostly tense/aspect, and lexis, specifically collocations or register. It seems concentration on these points led to less focus on what students may often consider ‘minor’ errors, like positioning commas or speech marks. Appendix 3 shows detailed examples of requests for feedback.

The vast majority of students’ responses to open-ended Question 3 (Do you consider LDF more helpful in improving aspects of your general language accuracy than traditional forms of feedback? Why (not)?) were positive. The most common explanation of why students felt LDF was helpful was that it is more specific to their needs than feedback they typically receive, and that LDF motivated them to independently seek solutions to their language problems, again echoing Campbell and Schumm-Fauster’s (op.cit.) findings.

![](img/b0473fd58efb5b7141942a9b34619d4a7ba470090f80ab53024b401c4435181e.jpg)  
figure 1 Responses to Question 2

Figure 2 shows students’ responses to multiple-choice Question 4: Which academic skills do you think LDF has helped you to improve, and to what extent? Skills such as critical thinking, editing/proofreading, and working with feedback were seen as having significantly improved by 53 per cent, 50 per cent, and 60 per cent of students, respectively, and as having somewhat improved by 40 per cent, 37 per cent, and 40 per cent of students, respectively. Improvement was also perceived by students in their ability to argue logically $( 8 7$ per cent) and to engage in academic discourse (80 per cent).

Notably, the skills of researching and using sources were not seen as improving much, if at all. There are also some interesting differences in responses, for example with picking/narrowing a topic, where the number of students reporting significant improvement (37 per cent) is similar to the number who perceived no improvement (33 per cent). This divergence in students’ opinions may possibly be attributed to the previous experience they had in preparing academic work in their native language(s), since the skills of finding sources or choosing topics are less dependent on language competence and Anglo-American academic writing conventions.

Responses to open-ended Question 5 (Do you consider LDF more helpful in improving your academic skills than traditional forms of feedback? Why (not)?) echoed those to Question 3, being mainly positive and in 77 per cent of cases beginning with the simple affirmation, ‘Yes’. The comments again highlighted specificity, personalization, and increased motivation to develop individual skills, mirroring ideas expressed by Johanson (op.cit.) and Campbell and Schumm-Fauster (op.cit.).

Actual improvement

Though not empirically reliable, comparisons of students’ results on this essay and on other essay assessments indicate that their perceptions of improvements appear to be accurate. Since this data were collated later whilst preparing this report for publication, the comparisons were conducted in three categories:

1 essay score on this LDF course versus essay score on a course one year earlier;   
2 essay score on this LDF course versus essay score on a course with traditional feedback in same term; and

![](img/1dd6b9ec4e41186239ac4cdb19b8162c80202632771fece0aeb54e19ba2465c4.jpg)  
figure 2 Responses to Question 4

3 essay score on a course one year earlier versus essay score on a course with traditional feedback in same term as the LDF course.

There are 18 cases which could be compared in Category 1, and 17 cases (with some overlap) in Category 2, which functions like something of a control group. Although the marks are holistic, i.e. not separated into writing and academic skills as in this study, the best scores cannot be achieved if students’ work shows deficits in either area. On a grading system out of 15 points, where $\mathrm { I } 5 / \mathrm { I } 5$ is excellent, $9 / \mathrm { { I 5 } }$ is average, and scores below $4 / \mathrm { I } 5$ indicate a fail, students’ scores compared as follows:

1 essay scores on the LDF course were on average 2.22 points higher than those received one year earlier;   
2 essay scores on the LDF course were on average 1.7 points higher than those received on a course with traditional feedback in the same term; and   
3 essay scores on a course with traditional feedback in same term as the LDF class were on average $_ { 0 . 6 4 }$ points higher than those received one year earlier.

Interestingly, the average improvement of $_ { 0 . 6 4 }$ points found when comparing the 14 cases in Category 3 is clearly smaller than the improvements found between the earlier and the LDF courses, and would thus seem to indicate that the improvements are not merely due to competence growing over time with no intervention, but that LDF may have a role to play. The conjectural improvement suggested by this data fits the trend of findings from similar studies such as Farshi and Safa (op.cit.). Separate studies designed to test this empirically would be necessary to support this supposition.

The findings here go some way to addressing the issues highlighted by Hyland and Hyland’s (op.cit.) review regarding the best way to deliver feedback, the role of technology, and how teachers can help students become autonomous writers.

It seems LDF might be a viable feedback practice, at least with advanced EAP learners as tested here: it involves learners in decisions about the delivery and content of feedback, therefore removing some urgency from practitioners to agree on a single ‘correct’ procedure. Various factors mentioned in students’ survey responses may transpire to be concepts which underpin processes making the practice effective: LDF addresses issues of intelligibility, ‘authority’ over the texts, learner autonomy, and individualization mentioned as problematic above. Indeed, LDF follows Bartram and Walton’s (2002) call for teachers to depart from the established ‘obsession with mistakes’ and shift their focus towards working on what students want to work on, as well as Ferris’ call for raising awareness of feedback practices other than those I describe as ‘traditional’, concluding in her article that students ‘need … the opportunity to engage cognitively in editing as a problem-solving process’ (Ferris op.cit.: 59). This is provided by LDF, highlighting why the procedure may be worthy of further attention.

In this study, the requests for audio or emailed feedback demonstrate a trend towards learners wanting to use technology to receive feedback. This is practical for teachers, who can often provide a higher quantity of more detailed feedback in a shorter time than by writing comments by hand, as Brearley and Cullen (op.cit.) also found. Letting learners choose a delivery format furthermore provides scope for them to request formats that suit their individual strengths, thus enhancing differentiation. Those who are less adept at using technology can choose handwritten or face-to-face feedback. Likewise, those who feel uncomfortable receiving feedback only on issues they identify can pose more general questions to ensure all serious problems are identified.

Furthermore, the students’ desire to integrate technology into the feedback process seems not only to stem from a penchant for digital media, but is explained by specific benefits that they perceive in these delivery modes. For example, hearing feedback was seen to improve intelligibility, and emailed commentaries were perceived as helping learners alleviate individual weaknesses, something they seemed to feel that general comments given in ‘traditional’ feedback do to a lesser extent. Indeed, Farshi and Safa (op.cit.) also conclude that emailed feedback led to greater improvement than handwritten feedback, based on similar reasoning.

From students’ responses to the open-ended survey questions in this study, it seems that working with LDF can help develop learner autonomy. The inclusion of decisions on delivery format in LDF provides even more scope for learner control than the similar concept described by Campbell and Schumm-Fauster (op.cit.). In both approaches, students request particular kinds of help with their writing. This leaves ‘authority’ over the text with the student author, and involves them actively in a feedback dialogue, rather than being reliant on teachers to ‘fix’ their writing. This allows them space to develop the ability to evaluate their work independently, thereby encouraging more learner autonomy (Benson op.cit.).

Some responses to open-ended survey questions did, however, highlight potential problems with LDF, for example students being unsure which aspects of their work to ask about. This suggests that the approach may need adapting for learners who have not yet acquired sufficient competence in English and the metalanguage to discuss language problems. However, this obstacle is not unique to LDF (cf. Benson 2012), and the flexible nature of LDF allows for appropriate differentiation. None the less, almost all comments on problems from students in this study were qualified by phrases like ‘at first’, indicating that this insecurity decreased once students began using the grading matrix to inform their decisions and became used to working with LDF, in accordance with Campbell and Schumm-Fauster’s (op.cit.) and Johanson’s (op.cit.) findings. Another concerning comment highlighted that students may not always be in a position to identify their own weaknesses, echoing Bloxham and Campbell’s (op.cit.) worry (also explored by Benson ibid.). Regarding this drawback, it is important to emphasize that LDF at no point forbids teachers from using their prerogative to indicate areas requiring attention which were not identified by the student. Moreover, common problems in learners’ essays, whether or not these are mentioned in feedback requests, can become the focus of targeted teaching and practice planned for subsequent lessons. It should also be highlighted that peer review and LDF are not mutually exclusive: indeed peer review and student-led discussions of issues raised by teachers’ comments can provide valuable scaffolding to LDF and the (re)drafting process.

Returning to the research question regarding students’ receptivity to LDF in EAP, the results collected here show that learners respond receptively to the LDF approach and view it as beneficial for their written language accuracy and academic skills. However, it seems from the survey results that the specific skills which can be significantly improved by LDF may depend on which skills have already been learnt during the students’ previous academic experience. However, the LDF approach allows for potential developments to concretely include the required differentiation that is only implied by the initial flexible definition. There is large scope for further study on LDF, investigating how students deal with autonomy, what factors affect the feedback they request, and whether they accurately identify their own weaknesses, as well as empirical investigations of actual improvement.

In summary, then, this study suggests LDF is a potentially highly useful tool for improving both essay writing and academic skills. Though it would be hasty to generalize from this study of a comparatively small and homogenous sample of participants, it would appear interesting for EAP teachers to trial LDF, and report their findings which may confirm my positive results. Further studies exploring LDF’s applicability to different genres of writing and in different teaching contexts may also affirm its benefits. Overall, the results highlight compelling reasons for piloting LDF on EAP writing courses, many of which may also be relevant in other EFL contexts.

Final version received July 2016

# Notes

1 To clarify: ‘In-text corrections’ describes the practice where teachers write the correct version of the phrase/sentence on to the student’s work, whereas correction symbols simply highlight the type of error (for example, v.t. $=$ verb tense, $\mathbf { s p } =$ spelling), and leaves the student to correct their own errors.   
2 LDF makes the distinction between the WHAT of feedback and HOW, and correction symbols are seen as HOW, i.e. delivery mode, whereas the WHAT encompasses specific or general questions, etc.

# References

Bartram, M. and R. Walton. 2002. Correction:   
A Positive Approach to Language Mistakes. Boston, MA: Heinle.   
Benson, P. 2007. ‘Autonomy in language teaching and learning’. Language Teaching 40/1: 21–40.   
Benson, P. 2012. ‘Learner-centered teaching’ in A. Burns and J. C. Richards (eds.). The Cambridge Guide to Pedagogy and Practice in Second Language Teaching. Cambridge: Cambridge University   
Press. Bijami, M., S. H. Kashef, and M. S. Nejad. 2013. ‘Peer feedback in learning English writing: advantages and disadvantages’. Journal of Studies in Education 3/4: $9 ^ { \mathrm { I - 7 } }$ .   
Bloxham, S. and L. Campbell. 2010. ‘Generating   
dialogue in assessment feedback: exploring the use of interactive cover sheets’. Assessment and Evaluation in Higher Education $3 5 / 3$ : 291–300.   
Brearley, F. Q. and W. R. Cullen. 2012. ‘Providing   
students with formative audio feedback’. Bioscience Education 20/1: 22–36.   
Campbell, N. and J. Schumm-Fauster. 2013.   
‘Learner-centred feedback on writing: feedback as dialogue’ in M. Reitbauer, N. Campbell, S. Mercer, J. Schumm-Fauster, and R. Vaupetitsch (eds.).   
Feedback Matters. Frankfurt: Peter Lang.   
Farshi, S. S. and S. K. Safa. 2015. ‘The effect of two types of corrective feedback on EFL writers’ skill’. Advances in Language and Literary Studies $6 / \mathrm { { I } ; \mathrm { { I } } \mathrm { { - } } \boldsymbol { 5 } }$ . Ferris, D. R. 2004. ‘The “grammar correction” debate in L2 writing: where are we, and where do we go from here? (and what do we do in the meantime ...?)’. Journal of Second Language Writing 13/1: $4 9 ^ { - 6 2 }$ .   
Hyland, K. and F. Hyland. 2006. ‘Feedback on second language students’ writing’. Language Teaching $3 9 / 2$ : $8 3$ –101.

Johanson, R. 1999. ‘Rethinking the red ink: audiofeedback in the ESL writing classroom’. Texas Papers in Foreign Language Education $4 / \mathrm { I } \colon 3 \mathrm { I } { - } 8$ .

# The author

Clare Maas is a Lecturer in EFL and EAP at Trier University (Germany). She holds postgraduate qualifications from the University of Wales and Trinity College London. Before moving into

tertiary education, she taught English at German grammar schools, and English for Specific   
Purposes at several language academies in the UK and Germany. Her professional interests include EAP materials development and continuing   
professional development for teachers. She has presented and published on the topic of feedback in ELT, and blogs at www.ClaresELTCompendium. wordpress.com.   
Email: cmmaas@uni-trier.de

Appendix 1 Learner-driven feedback

This term we are working with LDF, which requires you to choose:

a areas of your writing you wish your teacher to give feedback on and b the mode of delivery of this feedback.

# a Example areas of writing: Structure

Thesis Statement Paragraph structure Development of ideas Support/evidence Coherence and cohesion

# Vocabulary

Lexical choice Collocations Register

Grammar Tense/aspect Sentence structure Articles/determiners Prepositions

# Mechanics of writing

Punctuation π Spelling π Layout/format

You can ask for feedback:

In footnotes By underlining sentences/words and asking questions in margin By offering alternative versions of words/structures and asking for advice   
π By asking general questions at the end of your text

[Information above adapted from Campbell and Schumm-Fauster 2013]

# b Modes of delivery:

‘Traditional’: handwritten corrections within the text and a summary of feedback at the end.

Correction symbols: errors and areas for improvement highlighted with our standard symbols.

Audio recording: an mp3 of oral feedback.

Email: feedback via email.

Consultation: discuss your work face-to-face.

Here is a transcribed 30-second excerpt from an audio feedback recording which accompanied correction symbols (filled pauses omitted). [Body paragraph is being reviewed]

There’re a couple of points I’ve marked with the symbol for ‘word order’ errors. In those cases, it seems to me that sometimes your sentence structure, so the order of words in a sentence, doesn’t actually emphasise, or sometimes even express, what you’re actually aiming to say. So for example, you’ve got this sentence ‘Despite his insistence there would be more books to come on his website...’. This would mean that the books would come onto the website. And I’m not sure that’s quite what you mean. I think you mean his insistence was published on his website, that there’d be more books that would be published, but they won’t be published on his website, will they? So you might need to play around with that sentence and word order so that it actually emphasises what you mean.

Here is the text of a feedback email. [Introductory paragraph is being reviewed]

First, answers to your general questions: 1) your tone is generally suitably formal, but review some of the vocabulary - you sometimes use words which are a bit too colloquial for an academic essay (e.g. grab hold). 2) this is sadly not how you should reference, no! Check again! “Economist” in brackets is not specific enough!

Now, more specifically on your content and organisation questions:

The focus: I think it’s much better, now the focus really is on identity, and there are no big jumps from economics, etc. Also, you’ve now moved the mention of stereotypes earlier, which I think is good for this essay, since they seem to form a large part of the body. I have the feeling that you’ve really narrowed down the topic for yourself, and for your introduction, so that you’re no longer trying to cover so much ground, but have jumped right into the heart of a very important debate within this whole London vs the Rest topic. Much better!

I also feel that focusing on stereotypes will allow you to better use the data from your survey, as these points are rather less dependent on where someone is from.

Thesis Statement: Actually, I agree with you that the Thesis Statement could do with some editing to make it really strong for your essay. As it stands, I don’t get the feeling that you’re going to look at identity, but rather at historical causes for the general north-south divide, and predictions about future developments. I think you need to include in there the point about exploring people’s perceptions of their status and identity within England, and maybe also identity formation based on stereotypes of the ‘the other’.

Regarding the last point you asked about: I do think the topic has scope for a detailed enough analysis for this level, definitely, but I think you have to substantiate the points, and maybe compare your survey results with academic/secondary sources, to give your essay that academic edge, as well.

I hope this is helpful? Please let me know if there’s anything that’s unclear!

Here is a collection of feedback requests made by students submitting the first draft of their introductory paragraph.

# Requests at the end of the text/in an email

I would like to receive the email feedback version please, with some comments on the effectiveness of my thesis statement, the vocabulary and expression: is sophisticated and formal enough? And sentence structure – is it clear and natural?

I would be grateful if you could provide me with feedback on the style and register of my vocabulary as well as my tenses—especially if I need the Perfect in some places. I would also be thankful to know if you find the introduction coherent and interesting enough and if the opening quote is interest-catching?

I would like to ask you to give me feedback on my introduction via email on the following areas:

tense use (especially I’m not sure if I need the past progressive more in the first part?)   
effectiveness of thesis statement   
correct/effective usage of vocabulary (there are some new words I marked them, I’m not sure if they are right the way I used them).

It would be nice if I would get an audio recording feedback from you and some feedback on the tenses, because I mix up often the simple and the perfect present.

I have these questions: Was there anything in the text that was hard to understand or wasn’t logical? (Because of my language and sentence structure?) Does the introduction have an appropriate tone?

For the feedback, I would appreciate your opinion on 1) my range and 2) effective use of vocabulary, and 3) the naturalness and tone of language (esp. collocations) in the introduction; I think I’m finished with that now except for the language improvement. For the outline also 4) whether the examples and arguments seem well-chosen, relevant, and are well-presented – I took that from your grading matrix! Since so many people said that they found it very helpful, I would like to try out the audio feedback.

# Questions asked within the text (e.g. in margins)

In this sentence [“A.J. as an example to/for other women”], I don’t know the right preposition. We are told ‘example for’ is wrong, but I think here it can be correct. Can you help me in this case?

My own voice is way too obvious, isn’t it? Do I even sound objective at all? How could I improve this aspect? Also, is there a correct use of cohesion markers? Could you use correction code symbols to show me where I need to check it again?

Could you please look at my “interest catcher” at the beginning here (if it is a good one) and if I narrowed down the topic correctly or enough for this essay.

I thought about the phrase ‘over time’ in different places in my sentence, or changing the sentence order, to make the Thesis Statement more emphasised. Which version do you think is better?

For feedback, please look at the narrowing down to the thesis statement here. Is it a smooth flow?

I always use ‘make an argument’ but it sounds like school English. What is a better word than ‘make’?

Comma or no? I get confused by this every time!

I don’t know if it should be ‘had been protesting’ or ‘had protested’?