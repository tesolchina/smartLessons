# Diversity and Standards in Writing for Publication in the Age of AI—Between a Rock and a Hard Place

Maria Kuteeva1, \*, , and Marta Andersson2,

1 Department of English, Stockholm University, Stockholm, Sweden   
2 Department of English, Uppsala University, Uppsala, Sweden

\* E-mail: maria.kuteeva@english.su.se

Abstract: Research communities across disciplines recognize the need to diversify and decolonize knowledge. While artificial intelligence-supported large language models (LLMs) can help with access to knowledge generated in the Global North and demystify publication practices, they are still biased toward dominant norms and knowledge paradigms. LLMs lack agency, metacognition, knowledge of the local context, and understanding of how the human language works. These limitations raise doubts regarding their ability to develop the kind of rhetorical flexibility that is necessary for adapting writing to ever-changing contexts and demands. Thus, LLMs are likely to drive both language use and knowledge construction towards homogeneity and uniformity, reproducing already existing biases and structural inequalities. Since their output is based on shallow statistical associations, what these models are unable to achieve to the same extent as humans is linguistic creativity, particularly across languages, registers, and styles. This is the area where key stakeholders in academic publishing—authors, reviewers, and editors—have the upper hand, as our applied linguistics community strives to increase multilingual practices in knowledge production.

Current debates across different fields of academic inquiry underscore the need to promote inclusivity and decolonize knowledge and the way it is communicated in scholarly publications (e.g. Heidt, 2023; Mughogho et al., 2023). This journal is no exception, as its latest special issue is dedicated to the topic of a decolonial applied linguistics (volume 44(5)). One issue entangled in the ongoing debates is language use in academic publishing, and the dominance of English in particular, which can facilitate participation for some but restrict it for others (e.g. Kuteeva, 2023). Recent discussions in Applied Linguistics go beyond language alone to capture an epistemic bias towards Western modes of thought more broadly (e.g. Figueiredo and Martinez, 2019; Kubota, 2020; Sugiharto, 2022).

In a similar vein, a recent editorial published in Nature Human Behaviour recognizes the limitations of English as the main communication medium and looks forward to employing artificial intelligence (AI)-assisted tools to address systemic biases toward the Global North (Nature Editorial, 2023). While we agree that these tools definitely hold the potential for improving access and participation by unveiling often occluded practices and gate-keeping structures, AI comes with its caveats. The emergence of large language models (LLMs), such as Chat-GPT, has raised existential questions about the nature and future of academic writing in the scientific community, with applied linguistics standing as no exception. In this forum article, we juxtapose and explore the relationship between two trends: decolonization efforts in applied linguistics on the one hand, and AI-supported increased language and knowledge standardization on the other.

As detailed below, due to the nature of its training data, LLMs are susceptible to reproduction of the already dominant norms. Contrary to decolonization’s goals to increase diversity in perspectives and to promote epistemic justice and equal participation, AI-assisted LLMs are likely to drive knowledge communication toward further convergence. Even ChatGPT-3.5 points out this tension, suggesting that we should ‘critically examine the ways in which AI might shape knowledge construction and to ensure that diverse forms of knowledge are valued and promoted’.

Can the centripetal trend toward increased language standardization through AI impact ongoing efforts to promote linguistic and epistemic diversity in applied linguistics? This question is timely and relevant for our research community not only in connection to inequalities in participation and access between the Global South and North. As applied linguistics covers a broad range of research fields, theoretical frameworks, and methodologies—from corpus linguistics to translanguaging research—the impact of AI-assisted tools may vary or be experienced differently by key stakeholders in writing for publication. It is the more locally situated, context-dependent, qualitative lines of inquiry that rely on language in their knowledge-making practices that are more likely to be affected by AI-driven homogenization, starting with the dominance of standard varieties of English.

# English in academic knowledge exchanges

On the one hand, academic publishing in English enables knowledge exchanges, ensures accessibility of research to a wider readership, and yields the potential for international collaborations. At the same time, the ways in which one language shapes knowledge constrain research perspectives and epistemologies (Figueiredo and Martinez, 2019; Kubota, 2020; Sugiharto, 2022), sometimes leading to ‘epistemic monoglossia’ (Kuteeva, 2023), a situation when the field is dominated by theoretical and methodological perspectives associated with the use of that one language. The inhibitory nature of English in international knowledge exchanges is intimately linked to the high-stakes nature of writing for publication, which entails adherence to language norms and writing conventions. While these norms have been deemed necessary to ensure comprehensibility, the language standards in place are intertwined with the dominant academic structures and epistemologies of the Global North. These gate-keeping mechanisms influence the frameworks, methodologies, and audiences targeted by accepted publications.

The dominance of standard English in international publishing is arguably a factor counter to promoting alternative ways of thinking and constructing knowledge across disciplines (e.g., Nakadai et al., 2023). One area where language norms tend to be perpetuated is the peer review process, which often witnesses reviewers’ harsh criticism (Hyland and Jiang, 2020). This is indicative of how the workings of standard language ideologies marginalize and affect scholars from emergent regions (e.g. Silbiger and Stubler, 2019).

Despite calls for departure from ‘native’ standards (e.g. McKinley and Rose, 2018), journal submission guidelines commonly urge authors to use the help of a native speaker and write in impeccable English. As Flowerdew (2019) noted, this is also the case with several major journals in applied linguistics, such as Journal of Second Language Writing and Language Teaching. Outside the field of applied linguistics, with the exception of a handful of journals, including high-impact outlets such as Nature (Nature Editorial, 2023), it is not unusual that submissions get disqualified based on the author’s use of English (Politzer-Ahles et al., 2016). As reported by members of the ‘Reviewer 2 must be stopped’ online community, critical toward perpetuation and reproduction of the established power bias, the language and style adopted by submission authors can be judged based on different conventions of specific varieties of English. In this publishing landscape, calls for the recognition of epistemologies from the Global South and decolonization of academic knowledge (e.g. Heidt, 2023; Mughogho et al., 2023) may appear as a drop in the ocean, so long as the underlying systemic bias continues to persist.

Although global participation and access for researchers based outside of the Global North can be enhanced with the help of AI-driven tools (e.g. Nature Editorial, 2023), there is also a risk that these tools will contribute to further knowledge and cultural homogenization if the source is predominantly in English (Nakadai et al., 2023). As we detail below, LLMs play a crucial part in this centripetal trend of knowledge production.

# LLMs: a drive for diversity or further standardization?

While AI has facilitated writing for decades, initially in the form of spelling and grammar checkers, Google Translate, autocomplete and other tools, it was the emergence of LLMs, such as ChatGPT, that brought the debate to a whole new level. As Chomsky et al. (2023) argue in The New York Times, the current advancements in AI warrant both optimism and apprehension. For instance, the output of ChatGPT paraphraser has been deemed very good in terms of using the accepted standard of grammar and style for scientific writing, as well as maintaining the original meaning of the text. As a result, recent research found that experienced reviewers and journal editors in applied linguistics struggle to detect differences between AI-powered and humanauthored academic writing, even though AI-generated texts can be easily identified by the currently developed tools (Devlin, 2023). At the same time, human-generated texts tend to be evaluated in more positive terms (Casal and Kessler, 2023).

Although the way in which LLMs operate is reminiscent of the seminal ‘examine and report back’ methodology developed by Swales and Feak (2004) to teach academic writing, LLMs very much differ from how humans think and use language. As Chomsky et al. (2023) put it, ‘such programs are stuck in a prehuman or nonhuman phase of cognitive evolution’. They have no agency, no metacognition, and no real understanding of the workings of the human language (Bender et al., 2021). Due to these limitations, they are less likely to develop the kind of rhetorical flexibility that is necessary for adapting writing to ever-changing contexts and demands. As a result, LLMs will be naturally driving both language use and knowledge construction towards homogeneity and uniformity—if only due to their nature of a mere statistical predictor, labelled ‘a stochastic parrot’ by computational linguists (Bender et al., 2021). Another issue concerns inbuilt biases at the data gathering stage of LLMs, such as ChatGPT, which affects content (Payne et al., 2024). Overall, data collected from the Internet overrepresent younger populations based in the so-called WEIRD (Western, educated, industrialized, rich, and democratic) countries.

For example, ChatGPT-2’s training data were harvested from a specific subsample of the Internet, namely outbound links posted in a discussion forum Reddit (Bender et al., 2021). According to Pew Internet Research’s 2016 survey, $67 \%$ of Reddit users in the USA are men, and $6 4 \%$ are aged between 18 and 29 (Bender et al., 2021). This data selection for GPT-2 is then inevitably skewed towards an anglophone (educated) young man. As a result, a model that is predominantly trained on a specific register of English and cultural references (Payne et al., 2024) will struggle to deal with other ways of thinking or generate text in registers or languages that it has not been exposed to. If the training data disproportionately represents certain groups/communities, it can lead to a model that favours those linguistic styles and perspectives. Although some progress has been made in training ChatGPT-3.5 by using Reinforcement Learning with Human Feedback (RLHF)—a method that uses human demonstrations and preference comparisons to guide the model toward desired behaviour—the output is still very skewed toward what is widely established and accepted, both in terms of language and content. We elaborate on this point and provide an example in the section below.

From our vantage point, a major issue is the tension between the forces promoting diversity and decolonization in academic knowledge on the one hand, and the application of AI on the other. While decolonization’s goal is to increase the diversity of perspectives, AI—in the case of LLMs—is convergent towards more of the same standard and reproduction of the already dominant norms oriented towards the current gate-keeping mechanisms. These two trends result in a conundrum: while the research community thrives to foster epistemic justice and increase the variety of perspectives, the AI-powered LLMs are driving knowledge towards convergence and the anglophone centre, thereby perpetuating the status quo. In this context, LLMs are unlikely to remedy inequalities in current knowledge-making practices.

# Linguistic diversity, academic publishing, and LLMs

While multilingual publication and research communication practices seem to be on the rise (e.g. AAAL’s 2023 decision to accept submissions in languages other than English), they do not necessarily address all issues related to participation. Considering the nature of the training data (Bender et al., 2021) and the existing disparities in current knowledge production between researchers based in well-resourced institutions in the Global North and those in teachingintensive or under-funded universities (Besnier, 2019), when facilitated by AI, knowledge flows are more likely to emanate from, rather than to, the anglophone centre, thereby reinforcing the centripetal trend in knowledge exchanges toward the Global North.

So, while there is undoubtedly a great potential for AI-supported tools to facilitate access to (anglophone) knowledge for so-called ‘non-WEIRD’ research communities in the Global South, it does not guarantee increased or equal participation. AI-supported tools can indeed help with translation into standard varieties of major world languages, such as Spanish or Mandarin Chinese, but they are less versed in minority languages. Moreover, a mere translation from English into another (standard) language does not warrant epistemic diversity. The same is true for translations into English, as long as research contributions do not align with expectations of the international research community. As underscored by Niko Besnier (2019), the former editor of American Ethnologist, the quality of non-anglophone journal submissions intended for translation into English was in most cases questionable and they had to be desk-rejected. This further confirms the disparities between researchers based in elite institutions in the Global North and those in the Global South.

Another aspect pertinent to the issue of diversity concerns the limitation of LLMs in replicating human linguistic creativity, particularly across codes, registers, and styles. When a team of psychoneuroimmunology researchers prompted ChatGPT to contribute to a research paper, the resulting text was coherent and accurate on one hand, yet somewhat lackluster and generic on the other (Hill-Yardin et al., 2023). This limitation of LLM-generated text is particularly relevant in the aftermath of theoretical developments in applied linguistics which view language as a fluid construct, not limited to established named languages or varieties (e.g. Canagarajah 2022; Li Wei 2018). In the humanities and social sciences in particular, researchers often work across languages and resort to translingual practices (e.g. Kuteeva, 2023). Moreover, in these disciplines, language often serves an important function of discursively constructing knowledge. According to linguistic anthropologist Nick Enfield (2022), discursive construction of worldviews and interaction is what all human language is really good for, not so much for offering accurate descriptions of reality. For an LLM, any kind of innovative discursive construction is out of the question, as it can only reproduce what is already in place.

For example, when we prompted Chat-GPT 3.5 to write a paragraph for a critical essay about multilingualism in Sweden, and to mix English and Swedish for rhetorical effect and to supporting the argument, it generated a text in which the two languages were mixed in a random fashion, devoid of any deliberate rhetorical significance. Rather than adopting a critical stance, the output outlined the current status quo account of multilingualism which could be applied to any context (e.g. ‘a more intricate reality, where multilingualism grapples with both celebration and assimilation’, ‘we can better appreciate both the challenges and enriching possibilities that multilingualism presents’), lacking any analysis of the extant/potential issues. The text elements in Swedish pertained exclusively to Sweden, its language, and realities, such as Sverige, svenska, den svenska samhällsstrukturen (Sweden, Swedish, the Swedish society structure), and clichés used in official documents or depictions of Sweden, such as integration utan att offra mångfalden (integration without sacrificing diversity) or Sveriges mångspråkliga verklighet (Sweden’s multilingual reality). Thus, instead of introducing a critical perspective, ChatGPT generated a rather descriptive text, reproducing an official discourse about ‘Sweden’s multilingual reality’.

This bland and rosy description results from the model’s lack of contextual information, including situated and physical experience. The inclusion of Swedish expressions was too excessive and would rather cause the reader’s irritation than produce any rhetorical effect. Drawing from our own experiences as researchers situated in the Swedish context, we would have adopted a clearer stance and would have used Swedish more sparingly and strategically. For example, we would deploy Swedish to describe specific contact varieties, such as svengelska (Swenglish) or Rinkebysvenska (a pan-immigrant variety of Swedish spoken in Stockholm area); language policies situated in local contexts, such as parallelspråkighet (parallel language use) or modersmålsundervisning (mother tongue instruction). Thus, even though our ‘locus of enunciation’ (e.g., Figueiredo and Martinez, 2019) is technically speaking in the Global North, it is still far from what the LLM has been trained on. The difference lies in our knowledge of the local language, context, and realities, which goes beyond the source data for the LLM.

The disparity between human and AI-powered use of (trans)linguistic resources to generate content is therefore evident. It appears that rhetoric, argumentation, and critical stance continue to be domains where humans maintain a distinct advantage over LLMs and can resort to stylistic nuance, register variation, and language mixing strategically. Within the context of decolonization of academic writing practices, a pertinent example is the award-winning literacy scholar Canagarajah’s (2022) proposal of strategies for ‘rhetorical resistance’. His own academic writing has combined standard and Sri-Lankan English varieties, as well as his heritage language Tamil, to challenge the status quo and reposition the Global South as a legitimate player on the international publishing scene. As Canagarajah argues, non-standard English and other linguistic resources should not be used excessively but strategically. Despite the idiosyncratic nature of Canagarajah’s efforts, they do make a counter-position to the centripetal standardization trend and underscore the importance of individual voice and positioning in knowledge exchanges, emanating from researcher’s locus of enunciation and reflecting their full communicative repertoire. As English is unlikely to lose its dominant position in academic publishing in the near future, at least it can be diversified from within.

# Conclusion and ways forward

AI-powered tools are here to stay and will increase in significance in research and publication practices. Our task as key stakeholders in academic publishing—authors, reviewers, and editors— is to make sure that these tools are used responsibly so as not to limit participation and perpetuate inequalities. This requires two types of action: diversifying the input and training LLMs, and raising awareness of LLMs’ affordances and limitations in supporting epistemic diversity.

On the micro level of text production, AI currently reinforces reliance on templates and accepted language standards, thereby inhibiting linguistic variation and creativity. To mitigate this effect, key stakeholders in writing for publication can strive for more diversity and encourage individual styles, from which the models may eventually learn. The growing recognition of human involvement in AI and the need to monitor its performance (Chen et al. 2024) underscores the necessity for further linguistic research in natural language generation. Addressing the gap in linguistic studies, particularly concerning LLMs’ ability to ‘discern’ nuances in language across purposes and contexts, could enhance our understanding of their capabilities (Dynel, 2023). This, in turn, could lead to the development of more sophisticated LLMs capable of nuanced and purposeful language production in different contexts.

Further, while LLMs can assist in improving access to, and participation in, knowledge exchanges emanating from the Global North, they seem to be underused by the anglophone research community when it comes to engagement with the research published in languages other than English. This concerns both authors as well as reviewers and journal editors, who— after decades of advising/being advised to review more and more publications in international English-medium outlets—may finally broaden their knowledge horizons with the help of AI-assisted translation.

Last but not least, the conundrum of knowledge decolonization vis- $\grave { \mathbf { a } }$ -vis AI-driven homogenization puts the spotlight on academic journals as ultimate centres of knowledge exchanges, where authors, reviewers, and editors shape the research field. LLMs and other AI-powered tools now make it easier to follow the accepted language norms and achieve the desired clarity and understandability in writing for publication. A new challenge is now to ensure that this centripetal trend does not impede linguistic and epistemic diversity, which is imperative for advancing research and fostering a truly equitable academic landscape.

# Notes on Contributors

Maria Kuteeva is Professor of English linguistics in the Department of English at Stockholm University. Her research has focused on academic discourse analysis and uses of English in multilingual university settings. She has published two books, five special journal issues, and numerous articles in international peer-reviewed journals. She serves on four editorial boards and is co-editor-in-chief of the AELFE journal Ibérica. Address for correspondence: Department of English, Stockholm University, SE-106 91 Stockholm, Sweden <maria.kuteeva@english.su.se>

Marta Andersson is Assistant Professor in the Department of English at Uppsala University. She is a corpus and discourse researcher who is particularly interested in the pragmatics, semantics, and social aspects of computer-mediated communication. Her work has appeared in international peer-reviewed journals.

# References

Bender, E.M., Gebru, T., McMillan-Major, A. & Shmitchell, S. (2021). On the dangers of stochastic parrots: can language models be too big? In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (FAccT ‘21). Association for Computing Machinery, NY, NY, USA, 610–623. doi:10.1145/3442188.3445922   
Besnier, N. 2019. ‘From the editor: What I have learnt in the last four years,’ American Ethnologist 46/4: 381–6.   
Canagarajah, A. S. 2022. ‘Language diversity in academic writing: Toward decolonizing scholarly publishing,’ Journal of Multicultural Discourses 17/2: 107–28.   
Casal, E. J. and M. Kessler. 2023. ‘Can linguists distinguish between ChatGPT/AI and human writing? A study of research ethics and academic publishing,’ Research Methods in Applied Linguistics 2/3: 100068.   
Chen, L., Zaharia, M., & Zou, J. (2024). How is ChatGPT’s behavior changing over time? Harvard Data Science Review. doi:10.1162/99608f92.5317da47   
Chomsky, N., Roberts, I., & Watumull, J. (2023, March 8). Opinion | Noam Chomsky: The False Promise of ChatGPT. The New York Times. https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html   
Devlin, A. (2023). ChatGPT: A scientific proofreader’s thoughts on using AI to read and summarize the literature. Retrieved 29 April 2023, from https://www.scienceeditingexperts.com/blog/ chatgpt-a-scientific-proofreaders-thoughts-on-using-ai-to-read-and-summarize-the-literature  
Dynel, M. 2023. ‘Lessons in linguistics with ChatGPT: Metapragmatics, metacommunication, metadiscourse and metalanguage in human-AI interactions,’ Language & Communication 93: 107–24.   
Enfield, N. (2022). Language vs. Reality: Why Language is Good for Lawyers and Bad for Scientists. Cambridge: MIT Press.   
Figueiredo, E. and J. Martinez. 2019. ‘The locus of enunciation as a way to confront epistemological racism and decolonize scholarly knowledge,’ Applied Linguistics 42/2: 355–9.   
Flowerdew, J. 2019. ‘The linguistic disadvantage of scholars who write in English as an additional language: Myth or reality,’ Language Teaching 52/2: 249–60.   
Heidt, A. and M. Kozlov. 2023. ‘Racial inequalities in journals highlighted in giant study,’ Nature 624: 485–6. doi: 10.1038/d41586-023-01457-4   
Hill-Yardin, E. L., et al. 2023. ‘A Chat(GPT) about the future of scientific publishing,’ Brain Behavior and Immunity 110: 152–4. doi: 10.1016/j.bbi.2023.02.022   
Hyland, K. and F. K. Jiang. 2020. ‘‘This work is antithetical to the spirit of research’: An anatomy of harsh peer reviews,’ Journal of English for Academic Purposes 46/100867. doi: 10.1016/j.jeap.2020.100867   
Kubota, R. 2020. ‘Confronting epistemological racism, decolonizing scholarly knowledge: Race and gender in applied linguistics,’ Applied Linguistics 41/5: 712–32.   
Kuteeva, M. (2023). Tension-filled English at the Multilingual University: A Bakhtinian Perspective. Bristol: Multilingual Matters.   
McKinley, J. and H. Rose. 2018. ‘Conceptualizations of language errors, standards, norms and nativeness in English for research publication purposes: An analysis of journal submission guidelines,’ Journal of Second Language Writing 42: 1–11.   
Mughogho, W., J. Adhiambo, and P. S. Forscher. 2023. ‘African researchers must be full participants in behavioural science research,’ Nature Human Behaviour 7/3: 297–9. doi: 10.1038/s41562-023-01536-6   
Nakadai, R., Y. Nakawake, and S. Shibasaki. 2023. ‘AI language tools risk scientific diversity and innovation,’ Nature Human Behaviour 7: 1804–5. doi: 10.1038/s41562-023-01652-3   
Nature, E. 2023. ‘Scientific publishing has a language problem,’ Nature Human Behaviour 7: 1019–20.   
Payne, A. L., T. Austin, and A. M. Clemons. 2024. ‘Beyond the front yard: The dehumanizing message of accent-altering technology,’ Applied Linguistics doi: 10.1093/applin/amae002   
Politzer-Ahles, S., et al. 2016. ‘Is linguistic injustice a myth? A response to Hyland (2016),’ Journal of Second Language Writing. 34: 3–8. doi: 10.1016/j.jslw.2016.09.003   
Silbiger, N. J. and A. D. Stubler. 2019. ‘Unprofessional peer reviews disproportionately harm underrepresented groups in STEM,’ PeerJ 7: e8247. doi: 10.7717/peerj.8247   
Sugiharto, S. 2022. ‘Enacting the locus of enunciation as a resistant tactic to confront epistemological racism and decolonize scholarly knowledge,’ Applied Linguistics 43/1: 196–202.   
Swales, J. M. & C. Feak (2004). Academic Writing for Graduate Students: Essential Tasks and Skills. 2nd edn. Ann Arbor: University of Michigan Press.   
Wei, Li. 2018. ‘Translanguaging as a practical theory of language,’ Applied Linguistics 39/1: 261–261.