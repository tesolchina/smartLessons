# Assessing oral presentations: An analysis of score-reaching dialogue between EAP practitioners\*,\*\*,\*\*\*,\*\*\*\*

Louise Palmour'

Modern Languages and Linguistics, University of Southampton, UK

# ARTICLEINFO

# ABSTRACT

Keywords:   
Oral presentation   
Genre analysis   
Local EAP assessment   
Decision making processes

Academic oral presentations (AOPs) often feature as part of assessment suites on English for Academic Purposes programmes. This paper documents what teacher assessors do and pay attention to when reaching score decisions on student assesees' oral presentation performances on two EAP modules. The fieldwork conducted at two EAP sites was informed by a blend of constructivist grounded theory and ethnographic inquiry traditions. In this paper, an analysis of rating discussions and interviews demonstrates that a series of filters are applied by EAP practitioners to AOP performances when assigning scores. The processes described demonstrate how the social and learning context on EAP programmes influence assessment decisions. The visual representation of the rating process teamed with the description of processes may prove a useful heuristic with which to better understand and critically appraise decision making in EAP classroom-based oral presentation assessment.

# 1. Introduction

On EAP programmes worldwide, academic oral presentations (AOPs) are used as pedagogical and assessment tools. Oftentimes, in UK Higher Education Instutions, oral presentations form part f n sessment portolio which determines whether students progress onto a disciplinary degree rogramme. I is crucial that EAP agents examine and document the decision-making proceses involved in AOP tasks; tis isespecially important in gatekeeping assessments which have huge social consequences. This article contributes to knowledge bases on EAP AOP asessment, by reporting part of larger study which investigated EAP oral presentation practices a UK universities, through qualitative surveys and fieldwork.

In what follows, a qualitative analysi of score-reaching talk (assessment discussions between teacher asessors is shared in order to shed light on what teacher asessors do when assigning scores to AOP performance. Qualitativedata from observations and audiorecordings of score-reaching discussons coupled with interviews with teacher assessors will be presented. These data sets were analysed using constructivist grounded theory as an analytical framework (Charmaz, 2014). Instead of purely mapping an oral presentation to arating scale, the proceeding analysis of rating conferences and interviews demonstrates that the AP event is put through a range of filters not limited to preordained criteria in rubric.In this article, the personal, interpersonal, social, ranking and criteria filters willbe described. In doing so, it i clearly demonstrated that the influence of social context and interaction in decision-making processes is palpable. This article makes a pivotal contribution to understandings of how score-reaching decisions are enacted in EAP assesment contexts where teacher assessors and student aseees have considerable interaction prior to and aer assesment events. The findings may prove useful for EAP practitioners and cholars internationally who engage in oral presentation asessment in Higher Education settings.

# 2. Literature review

# 2.1. EAP in-house assessment

EAP in-house asessments (those which are designed and implemented in local EAP departments) are common. However, as noted by Schmit and Hamp-Lyons (2015), there has been litle theorisation of in-house EAP assessment practice. Schmitt and Hamp-Lyons encouraged EAP practitioners to conduct and publish studies which address \*the construct of EAP in EAP assessment being under-defined and under-theorized (p.3), especiall in comparison with large-scale standardized assessments. This study responds to Schmitt and Hamp-Lyons' call by investigating in-house EAP oral presentation assessment.

The target onstructsof language assesments continue to be conceptualised as skill test, tapping into Reading, Writig, Speaking, Listening abilites, or a combination of these skills. However, the construct of EAP involves more than language development (De Chazal, 2014; Schmitt & Hamp-Lyons, 2015). Oral presentations are primarily grouped under \*speaking assessment, despite analysis f oral presentations showing that sense-making requires a complexrlationship between speech, gestures and slides (Harrison, 2021). Yet, it i vital to bear in mind hat what i concetualied as the official target construct in AOP assessments dffers depending on the EAP department and EAP practitioners involved. For instance, oral presentations at one EAP site are reportedly being used to assess a relatively narrow construct of discrete linguistic sills such as grammar and pronunciation, whil at another site the academic literacies needed to complete an oral presentation task include high-order capacities around content, presentation sills and language (Palmour, 2020). In high-stakes asessments, which in part determine admission to an English medium degree programme, the construct of EAP is potentially further widened when EAP practitioners work with the notion of "abilit to cope (Fulcher & Davidson, 2007) or \*readiness for academic study' in English medium education. The construct of readines for academic study in English medium education encompasses a complex myriad of physical, cognitive, linguistic, communicative, digital, and socioemotional abilitie. Assessment events are further complicated by the fact that the stated, perceived and operationalied asessment constructs have the potential to converge and diverge depending on the different stakeholders' perspectives (Macqueen, 2022).

In-house assessments are often developed by teams of EAP practitioners in EAP departments within universities (Schmitt & Hamp-Lyons, 2015). These local, classroom-based asessments, as opposed to large-scale tests (such as IELTS) are educational as sessments in that they are linked to a course f ucational study. heseassessments are classoom-based, meaning they aford greater flexibility in monitoring students (Green, 2014). In other word, core characteristic of classoom-based educational asessment is the range of assessment windows availableto teachers who also act as assessors. Assessment opportunities (Rea-Dickins, 2001) can be \*any actions, interactions r artifacts (planed r unplanned, deliberate or unconscious, explicit or embedded) which have the potentil to provide information on the qualitie of a learner's (or group of learners') performance" (Hill & McNamara, 2011, p.397). Even when the assessment is described as a discrete formal assessment activity" (Leung & Mohan, 2004), the informal assesment opportunities have the potentia to shape the asessment decision making. As Moss (2003) argues, in local classroom-based assessments the social context plays a role in influencing scores and is construct relevant. The social context is influential partl because classroom assess ments have a learning purpose as well as a measurement purpose (Bonner, 2013) and due to the availabilit of multipleassessment opportunities between teacher asessors and student asesees. Particular aspects of traditional psychometric theory such as decon. textualisation, and features of standardization may not hold the same degree of relevance in certain assessments (Bonner, 2013), including EAP in-house assessments.

How EAP practitioners respond to the characteristics of local educational assssment and conceptualize the assessment construct in oral presentation tasks is a complex and important research endeavour. This is the case because there are multiple, broad conceptualisations of what EAP, or academic litracy development, entails. Oftentimes, EAP instruction involves preparing students for "seminars and \*oral presentations" and students' performances on seminar discussions or oral presentations form part of an assessed portfolio. Yet, the research base dedicated to investgating how such genres are used as assessment tools i lacking. This is surprising given the established trend of genre analysis in EAP scholarship (Benesch, 2001).

# 2.2. EAP research perspectives on AOP events

My research focuses on a particular ssessment genre: AOPs. AOPs are prevalent across the academy indisseminating research and as formative and summative asessment types (Palmour, 2020; Joughin, 2007). Knowledge of A0P practices on English-medium degree programmes is relatively underdeveloped considering the wealth of practice, both on degree programmes and EAP courses. Research in the field of EAP has sought to demystify AOP events. Levrai and Bolster (2015) surveyed disciplinary lecturersto ascertain their perspectives on A0Ps. Zareva investigated students' understandings of effective PowerPoint designs (Zareva, 2011) and conducted linguistic analyses of oral presentation discourse (e.g. Zareva, 2016). There has also been research on how A0Ps function as effective learning and socialization tools on universty coures (Sundrarajun & Kiely, 2009; Zappa-Hollmann, 2007). In terms of AOP practices on EAP programmes Januin and Stephen (2015) investigated the discourse competence required in fulflling an EAP AOP task. A notable gap in the literature on AOPs related to EAP, however, is a close investigation of how AOPs are operationalised as

assessment tools on EAP programmes.

In EAP, the need to focus on processes as well as products has been advocated (Belcher, 2006). Swales (2019) critiques the \*un. adorned move-step accounts of genres such as conference presentations and elevator pitches. He encourages research which situates textual analysis within ethnographic approaches and consults those with gatekeeping or evaluating roles to gain thicker descriptions of such genres. Swales also argues that \*the scope of a genre can be reconsidered in order to serve the pedagogical purposes of the EAP practitioner" (2019, p.76). For instance, Salter-Dvorak (2016) employed an oral presentation as a pedagogical tol to improve students' argumentation. Despite the fact that the oficial purpose of using an oral presentation was to refine the argumentation in a written pice of work students were found to focus on delivery aspects more than argumentation development. The students regarded the task as a performance assessment rather than a pedagogical intervention on argumentation.

Arguably, the scope of a genre isalso shaped by stakeholders to serve gatekeeping and evaluating purposes as well as pedagogical aims. How individual agents conceptualize and perceive the oral presentation task as a learning and asessment tol has bee found to diffr (Joughin, 2007). Furthermore in asessment contexts the stated constructs may not be realized when operationalised (Macqueen, 2022). For instance, teachers have been found to reach decisions based on qualities not contained in rating scales, such as student behaviour and effort (Llosa, 2008). In the current study, how score decisions are reached on AOPs has been captured by interviewing, observing and recording dialogue between teacher assessors who indeed have a gatekeeping and evaluating role. Accessing these asessment processes and practices develops closer understandings of how AOPs are conceptualised and received on EAP programmes. Genres are social-cultural constructs and actions (Mille, 1984) which describe social conventions, but these constructs and their conventions are realized in variable ways by individuals (Widdowson, 2020, pp. 91-95). Studies which produce qualitative insights through a grounded and ethnographically-oriented methodological approach offr fruitfl insights into what drives individual assessment decisions linked to AOP events.

# 3. Context and methodology

# 3.1. Research context and participants

The research took place on modules which had the explicit aim of developing English for academic study and included AOP as. sessments which in part determined students' transition onto an English medium degree programme at a UK university. The teacher participants responded to acall sent out via the BALAP mailing list and all prticipants provided informed written consent before data collection commenced. Field Site 1 (FS1) was a module on a Pre-Master's programme for students who hoped to transition onto a Master's degree programme). Adam (pseudonyms used throughout) was the main teacher on the module and assessed the AOP tasks. Daniel marked the AOP asessments with Adam and had taught the students on other modules and worked with Adam before on previous EAP modules. Field Site 2 (FS2) was a module on an International Foundation Programme (IFP), for sudents who planned to study on an undergraduate programme. Georgina was the main teacher on the module and asessed the AOPs along with Tracey. Tracey taught the students on other modules on the IFP and conducted tutorials. Field work took place in semester 1 at FS1 and in semester 2 in FS2.

The table below provides key details about the EAP programme, the module and the AOP event (see Table 1).

At both field sites, the asssed AOP events were live, in-person events. The audience consisted of the teacher assessors, students and myself as the researcher. The AOPs were video-recorded and teachers took notes during the performances and referred to the rating scale at points during the assessment event. Rating discussions in FS2 took place on the same day as the students presented; whereas in FS1 the rating conferences were conducted a few days later dueto timetable constraints. In score-reaching talk at oth sites, the teachers referred to ther real-time notes and memories In FS1 teachers consulted clips of the video performances atcertain points in the discussion, namely because the rating discussion took place 3 days after the performances. The teacher assessors in FS1 were attued to the strong possibility that memories of the performances may have been more reliable if they had reached core decisions on the same day as the summative assessment event.

# 3.2. Data collection and analysis

In this article, part of larger project (Palmour, 2020) willbe reported. Data from the two audio-recorded score-reaching rating discussions and interviews with teacher asessors from two field sites will be shared. In the larger project, analysis f leson obser ations, recordings of the asessed AOPs, documents (e.g.syllabus and rating scale) and interviews with students was also conducted. Moreover, the larger project reporte students' perspectives and behaviour as well as teacher asessors views and practices. The analysis presented in this article aims to shed light on what teacher assessors do when asigning scores to AOP performances.Hill and McNamara (2011) and Rea-Dickins (2001) grounded approach to the investigation of assessment activities has informed the meth. odological approach taken in the current study. The current project adopted a blend of constructivist grounded theory and ethno graphic inquiry traditions (Charmaz, 2014; Hammersley & Atkinson, 2019). Constructivist grounded theory and ethnography are compatible in that they both involve inductive research, progressve focussing and underscore the importance of reflexivity (Charmaz & Mitchll, 2001). Ethnographic traditions inspired the level and immediacy of accessand proximity to events gained in the study, namely through observation. Ethnography, unlike grounded theory, prompts the researcher o understand their participants worlds as they live it rather than how participants' talk about it (Charmaz & Mitchell 2001). Constructivist grounded theory suited the inductive investigation of the under-researched phenomena of AOP events across EAP settings. Furthermore, constructivist grounded theory procedures served as an indispensable analytic framework. Line-by-line coding, constant comparison, memo writing and theoretica sampling were conducted in order to construct categories from across the data sets (Charmaz, 2014). Such data collection and analytic procedures, central tenets of constructivist grounded theory, contain correctives which improve the trustworthiness and credibility of the reearch (Charmaz, 2006). In this article, dat from participants is provided to ensure that the link betwen data and findings is transparent In parts of the extracts, however, relevant information has been anonymised. In line with Ethics protocols pseudonyms have been used throughout and long quotations from documentation obtained in the field have not been published to uphold the highest degree of anonymity feasible.

Table 1 Field site information.   

<html><body><table><tr><td>Category</td><td>Field Site 1 (FS1)</td><td>Field Site 2 (FS2)</td></tr><tr><td>Type of programme</td><td>Pre-Master&#x27;s Programme</td><td>International Foundation Programme</td></tr><tr><td>Modules on the programme</td><td>EAP module and content pathway modules</td><td>EAP module and content</td></tr><tr><td>Module under study in the research</td><td>EAP module</td><td>pathway modules EAP module</td></tr><tr><td rowspan="3">Students</td><td>14 students, IELTS 5.5 on entry</td><td>11 students, IELTS 4.5 on entry</td></tr><tr><td>L2 users of English</td><td>L2 users of English</td></tr><tr><td>Mixed</td><td>Mixed</td></tr><tr><td>Target disciplines AOP assessment task</td><td>Group presentation on group project findings</td><td> Individual presentation on topic</td></tr><tr><td></td><td></td><td>of student&#x27;s choice</td></tr><tr><td>Time in the field AOP assessment weighting</td><td>Semester 1 Potentially 10% of final mark. One of two presentations completed by</td><td>Semester 2 Contributed to 25% of final mark</td></tr><tr><td></td><td>students, the best performance was then included in the portfolio.</td><td></td></tr><tr><td>AOP rating scale sections (reworded to</td><td>1. Content 2. Fluency and Intelligibility</td><td>1. Overall Competence in Academic English</td></tr><tr><td>uphold higher degree of anonymity)</td><td>3. Accuracy and Range</td><td>2. Content</td></tr><tr><td></td><td></td><td></td></tr><tr><td></td><td>4. Presentation Skills</td><td>3. Fluency and Coherence</td></tr><tr><td></td><td>5. Group Work</td><td>4. Vocabulary</td></tr><tr><td></td><td></td><td>5. Grammar</td></tr><tr><td></td><td></td><td>6. Pronunciation</td></tr></table></body></html>

Remaining close to the words of participants and filtering theories with data reduces the likelihood of superimposing theory on the data. At the same time, constructivist grounded theory and ethnography both emphasise the co-constructed nature of research between the researcher and participants, therefore underscoring the need for reflexivity. As a researcher, I found there was a constant negotiation of my positioning in the field. Being in the field entaled operating in a\*third space' (McNess e al., 2016) in between insider and outsider. The leve of participation in the activities at the field sites varied. For example, during ratig discssions and assesment events, there was a need to be outwardly "a detached, impartial onlooker' (Van de Ven, 2007, p.269) so as not to influence the

The AOP Performance

![](img/a0b8378c4db077be85b65ab63309ae0ac03fb79b62ea7742837c83d9b87b2f8f.jpg)  
Fig. 1. Visual representation of rating process.

assessment outcomes. My previous work as an EAP practitioner aforded me a level of insider status, whereas being a newcomer to the particular EAP modules under tudy meant there was a degree of outsider status. There was a need to suspend my notions of EAP and AOP assessment constructs from my previous work. It was important to make sure I did not assume practitioners would approach particular concepts (e.g. EAP, oral presentation) in similar ways. My time as an EAP practitioner simultaneously helped me understand if I was achieving rich and grounded perspectives on events. Having rated oral presentations myself,I was aware of some of the possible complexities and perplexities at work. The rating decisions Iobserved and documented provided me with both familiar encounters and fresh insights into EAP practice.

# 4. Findings

From analysing rater conferences and interview data from two EAP sites, a number of categories were constructed which represent the assesment processes teacher asssors engage in when reaching score-decisions. Thevisual reresentation of AOP practices (Fig. 1) outlines main processes teacher assessors enact in score-reaching dialogue on two year-long EAP modules.

At the top of Fig. 1 is a photograph of a student giving an AOP (on a course which was not part f the current study) on the topic of Vygotsky's Zone of Proximal Development theory. This picture represents an AOP performance i it entirety, that i the performance the teacher asessors are offcilly tasked with mapping to a rating scal. Underneath the photograph is the label \*The Zoom" positioned next to a close-up of a slide from the oral presentation. This represents how teacher assessors zoom in to take a closer look at aspects of a presentation (e.g. consider use of language, content). Below \*The Zoom" section are \*The Filters'. The interpretations of the AOP performances are shaped by personal and interpersonal influences, the use of a ranking strategy, the information garnered from social interaction during the EAP programme, and the criteria in the rating scale. The final part of the graphic represents the end product of the assessment process the score which signifies a pass or fal mark. Instances of decision making involve a complex overlapping mix of these processes The following sections show instances of the rating processes at work while highlighting the conditions which shape them. The dynamicity of the processes when operationalised will also be underscored.

# 4.1. The zoom

During the rating conferences, occasionally the assessors evaluate the entire AOP performance:

Excerpt 1:

Daniel: He got what a presentation should be I thought. [FS1, Rating Discussion]

Excerpt 2:

Tracey: I thought it was a really good presentation. [Fs2, Rating Discussion]

Excerpt 3:

Georgina: ...it was like a proper competent presentation. [Fs2, Rating Discussion]

For the most part, however, the teacher assessors zoom in to consider a particular aspect of the AOP peformance, such as language, content, and presentation skills For example, teacher asessors zoom in more closely to discuss aspects, such as linguistic features at particular moments in the AOP performance (e.g. use of grammar, pronunciation).

[FS2, Rating Discussion]

Georgina: ... so the language you know she's great but she makes some mistake

Tracey: Yeah [I've got that].

Georgina: [subject verb] she can't get rid of that. She always says countries is' so I don't know. That's a real problem for her Not that people won't understand her but some singular plural mistakes but nothing major.

In the episode above, the teacher asessors on the IFP in FS2 zoom in from the whole AOP to provide a holistic judgement of the student's language use s "great'. The teachers, Georgina and Tracey, then take closer look to describe instances of language use in this case subject-verb agrement. After this, Georgina and Tracey zoom out gain to evaluate the overall quality of the presentation, deeming these \*mistakes" to be "nothing major'. Similarly, in FS1 on the Pre-Master's, Adam and Daniel use a zooming strategy to gather, and crucially check the relevance and representativenes of, evidence sampled on a student's pronunciation. Adam and Daniel had noted down the pronunciation of the word questionnaire in their notes and now discuss whether this evidence is a distraction or should factor into the score-reaching decision.

[FS1, Rating Discussion]

Adam: Well I've gone 10 or 11. But maybe I don't know 11 top of that band.

Daniel: I think we're distracted by the 'questioneer'

Adam: Ok 11 then. We shouldn't be distracted by one 'questioneer'!

Assessors, Adam and Daniel, zoom out and determine the minimal efect of the student presenter's pronunciation of questionnaire on communicative competence displayed in the AOP performance. Consequently, in FS1 the piece of evidence is considered a distraction and isdiscounted. In FS2, however, Georgina and Tracey indicated tacitly that subject-verb agreement impacts the mark. despite stating i is \*nothing majort. The zoom function i not only useful for narrowing the focus of the discussion but also serves as a means by which to check the validity of evidence being admitted into the decision making.

As well as using the zoom function, the teacher assesors apply a range of filters to the AOP performance. In instances of decision making, ilters are applied to varying degrees. The core filters which shape the decision-making talk are the Personal and Intrpersonal Filter, The Socil ilter, The Ranking Filtr and The riteria Filtr. Prsonal inluences and features of co-constructed dilogic decision making are powerful factors in the score-reaching interaction.

# 4.2. Personal and Interpersonal Filter

The teacher assessors' individual experiences related to teaching, learning, delivering presentations, personal hobbies, among others, inluence their approaches to asessing AOPs. The personal dimensions that affect practice are numerous and diverse, which can been seen when examining one aspect of judging AOPs: orientations towards the presentation delivery tyle. For instance, Adam had delivered presentations in a previous job and valued the aesthetic and interactive quality of an AOP performance. Daniel has an artistic side and valuescreativity but feelshis more concened with the criticality demonstrated in the asssment task. Georgina has had littl experience delivering presentations, but exposure to different AOPs over the years leads her to increasingly question the relevance of presentation styl in an oral presentation with a gatekeeping function. She see home underraduate students using scripts and so questions emphasis on delivery style. Tracey has taught business modules and is particularly looking for a "professional manner' in a presentation delivery, but i also impressed by slide design. Tracey, in fact, overtly indicates the influence of such individual preferences and aesthetic sensibilities during the rating discussion with "you know me":

[FS2, Rating Discussion]

Tracey: TELL you one thing I did like though, I liked her slides. Very clear. I liked the colour coordination. You know me!

This quotation represents clearly how personal preferences enter the decision-making talk. Established relationships and emerging dynamics between teacher asessors also shape how the score-reaching discussion unfolds. The teachers positions as the main teachers, more senior standing within the department or module convenor role can have an impact on their behaviour in rating conferences. The negotiation involved in score-reaching dialogue is openly acknowledged when Tracey likens the score-reaching exchange to an auction.

[FS2, Rating Discussion]

Georgina: So anyway um... can we go with 60? 59? (hesitant tone)

Tracey: [I mean I did] (high pitch tone indicating doubt)

Georgina: [I mean she was] Because I did give it a bit more actually cause I thought the second half got better. I gave it 62.

Georgina: Yeah I'm happy with that.

Tracey: Yeah? Ok. 62 then hehe!

Georgina: Ok!

Tracey: Hehe! Going going gone! (thumps hand on the table imitating gavel at auction)

Widdowson (2020) notes that communication encompases a tension between the social need for participants to relate to each other and the impuls to defend their individual space" (p.12), referring to co-operative and territorial imperaives'. Unlike in the previous exchange when the teacher asessor come to aquick consensus, there were episodes when the conflict between cooperative and territorial imperaties was palpable. In FS2 on the IFP, Georgina gives a lengthy asessment of a student's performance arguing that it is unfortunately a clear fail. Then, Tracey attempts to interrupt Georgina to give her interpretation of the presentation. "OK right' is Tracey's third attempt to offer her thoughts:

[FS2, Rating Discussion]

Tracey: Ok! [Right]

Georgina: [And] that was it!

Tracey: Ok MINE then. Ok! This could have been [a really]

Georgina: [COULD] have been! (high pitch)

Tracey: No listen (firm tone) this could have been a really good PowerPoint presentation. On his referencing on the slides on his reference area

Georgina: Hmm.

Tracey: He had some really good references there.

Georgina: Where?!

Tracey: Wait! What he didn't do. He didn't take any of the stuff he'd learnt in business and bring it in to this presentation.

This is an example of a co-assessor fighting to carve out their individual space. Georgina is not concerned with conflict avoidance here. Georgina and Tracey held similar level EAP job positions and had worked together before and were comfortable challenging each other, but Georgina seemed more at ease with a direct communication style than Tracey. Georgina was the lead teacher on this module and had watched two practice presentations, which may explain her conviction in her interpretation and quicknes to interrupt Tracey. Tellingly, Tracey uses her knowledge of the student from another teaching module as way to ofr nformation Georgina wil take into account, marking out her individual trritory and contribution to the dialogue. Teacher assessors use their wider knowledge of the students (ee discussion in The ocial Filtr ection) as a way to gain kudos and authorit in parts of the rating discussons. Arguably, Tracey should be given the floor more readily, though Georgina's interruptions were coming from a place of concern, frustration and disappointment. Georgina limits interruptions in the other part of iscussions. This episode evidences the potential tense and fraught nature of score-reaching interactions.

Even when there are established collaborative relationships and good-pirited discussions, the lossof face is aconcern. For instance, Adam openly acknowledged the face-threatening nature of the rating conference during the dialogue:

[FS1, Rating Discussion]

Adam: Yes I put 12 for that. Yep. No I was slightly embarassed because you said she wasn't so good and I was oh maybe I've gone a bit high!

Adam notes the human and understandable embarrassment that is associated with putting forth a tentatie mark or interpretation of a performance that could be considered wildl inaccurate by co-assesors. This type of consideration assciated with interpersonal communication, The Interpersonal Filter, is one which is detected but not ofen acknowledged openly. Arguably though, a degree of "impression management (Goffman, 1959) persistently shapes score-reaching behaviour. This i partly because the professonalism of the teacher asesorsis under the spotlight in these encounters with colleagues. In FS1, Daniel holds a more senior EAP role in the department, so this may be one reason why Adam is worried about his performance as an asssor. However, the impact f position does not result in Daniel dominating the discussion. Adam is the module convenor and main teacher so this gives Adam confidence and authorit. Inthe mix influencing the rater conferences are what is at stake in each rating scenario, the asessors' role on the modules and institutional hierarchies.

Interwoven with the personal and interpersonal dimensions of practice, i the social context on the educational programme. How the interactions and information that have been shared on these year-long programmes affct decision making is discussed next.

# 4.3. The Social Filter

The Social Filter refers to the impact f the wider social context on the decision-making proceses namely from interaction on the wider educational course, outside the formal AOP assessment events.

# 4.3.1. Drawing on information outside the AOP

Focussing on individual marks "masks the complex role of the social context in shaping those scores and the interpretations they entail' (Moss, 2003, p.17). In the rating conferences, teachers made reference to sources of evidence both within and outside the AOP performance. This included past performance in class and practice assesments (see excerpts 1 and 2); detail on instruction and feedback students had received (see excerpt 3); anticipated performance based on information teacher assors had gleaned on the target domain from in-sessional work (see excerpt 4); and mitigating factors such as nerves (see excerpt 4).

Excerpt 1

Georgina: Ok for Marina in the practice (presentation) the main ssue was the content. It was descriptive, not analytical. THAT err didn't change in the final presentation. [Fs2 Rating Discussion]

Excerpt 2

Daniel: I thought she was kind of weak on content

Adam: Yes.

Daniel: But that's Anna. [FS1, Rating Discussion]

Excerpt 3

Tracey: He didn't use any businesstrminology in there. I mean he's just taken a whole module of Business with me Fs2, Rating Discussion]

Excerpt 4

Daniel: I dont think I would penalise Fiona. She i very nervous and she trie very hard . in a seminar fter a few months she'l be very impressive. [FS1, Rating Discussion]

When analysing teacher asessor talk, it i often problematic determining what parts of the discussion affect the final score outcome because aspects remain tacit and unsaid. What is discernible, in cases, is the reasoning behind the discussion of such information.It links to how teacher assessors can most confidently manage and reach decisions on who has \*the ability to cope" or "readiness for academic study" in English-medium education.

# 4.3.2. Ascertaining readiness for academic study

At times, tension arises because the teachers acknowledge that the AOP is ofially what should be evaluated in the score-reaching talk, but the teacher assessors wish to ensure the ultimate score decision does not unfairly deprive students of an opportunity to transition onto their prospective degree programmes. The teachers consider the place of what they label insider knowledge".

Excerpt 1:

Adam: My insider knowledge i I know that she did the presentation. But it's unfair because it's not from the presentation. But I think you can say from looking at the presentations, it's bad in terms of teamwork.

Daniel: Yes, and I think that we're being distracted by your insider knowledge and in terms of the actual quality of the pre sentation she wasn't exceptional was she. [Fs1, Rating Discussion]

Excerpt 2:

Daniel: I dont think I would penalise Fiona. She is very nervous and she tries very hard . in a seminar fter a few months she'll be very impressive. [FS1, Rating Discussion]

At times, insider knowledge is discounted (excerpt 1 above); whereas at other points in discussion the insider knowledge holds sway (excerpt 2 above). Particular conditions give rise to teacher asessors considering information beyond the AOP performance. One reason that insider knowledge is drawn upon is that i offers insights into how students function on an educational course. Another rationale put forthis that reaching a sound and fair high-stakes decision based on one real-time AOP performance is challenging.

[FS2, Interview]

Georgina: I mean now I already know who's going to get what more or less. Because there has been a lot of practice work. It would be difficult you know to just hear it once

Georgina presents the case that referring to evidence outside the assessed performance may in fact be a force for good on a course where teacher assessors have interacted with a small group of students in multiple environments over an academic year. In FS2, the students delivered 2 practice presentations to Georgina on the same topic as their final asssment so she was very familiar with the students' progress.

Georgina: So I think I take the whole picture into consideration. I can't just erase t like in [the film] Men in Black! Hehe! . It's quite difficult. I want to be fair to everybody. [Fs2 Interview]

Georgina acknowledges that the assessment opportunities she has gathered over the course of the programme cannot be wiped from her memory with a memory-wiping device, such as the neuralyzer used in the film Men in Black.

In cases, teachers note that the AOP assessment was stronger or weaker than expected: they refer to insider knowledge but choose to remain within the bounds of the AOP assessment event when reaching score decisions. Mitigating factors identified through the use of insider information are at times applied, and discounted in score-reaching decisions in other cases. There are reliability and validty concerns associated with the reference to sources of evidence external to the AOP performance, however. Leung and Teasdale (1997) argue that in summative decisions such information should not be used when it may not be knowable for allstudent asseses.

Caution must be exercised as to what information shapes the final score outcome. What do EAP practitioners know" about their students and what onstitutes \*readiness" on a degree programme? When i \*insider knowledge, or evidence external to an assessed performance, a force for good or harmful when reaching gatekeeping decisions? There is a need to acknowledge that the social context cannot be full disregarded and barrd from the decision making talk. The decisions rest with the practitioners with the knowledge of the social context on the educational course in conjunction with the rating cale. The EAP practitioners deliberate on these important questions on farness and ethics in gatekeeping decision making during parts of the rating process and interviews and acknowledge the constant reflection and action required on these issues.

# 4.4. The Ranking Filter

The teachers in both field sites often compared individual student's performances with each other rather than solely referencing performances against criteria contained in the rating scale.

Excerpt 1

Adam: Ok. Mm-hm. Um well 12 for presentation skills? Or 13 the same as Henry.

Daniel: She wasn't as good as Henry.

Adam: 12 then or 11? [FS1, Rating Discussion]

Teachers at FS1 and FS2 make comparative judgements (Thurstone, 1927) throughout the discussions rather than purely criterion-based ones by referring to the performance of other students. Such practice serves as  way to check the reliability of marks; teacher ssessors do not seem confident with solely using the rating scale as a way to check the consistency of the marks they award to performances.

# 4.5.  The Criteria Filter

The official discourse conveys that an AOP performance is mapped toarating scale to produce a score. This would suggest that all decisions would be ilteed by the criteria. While thre are pisode in the rating talk when th criteria i shaping what is aid attention to, there are other instances when critria not featured in the rating scale are cited. Teacher assessors also supplement and openly criticise the criterion-referenced approach, as discussed in The Social ilter and The Ranking Filter sections. The extent to which the teacher assssors decision-making talk converged with the stated assessment construct as represented in the rating scal, depended on the alignment of the criteria with the perceived ultimate asessment purpose; the criteri fit with the communicative AOP task affordances; and the place the criteria had in teacher assessors strategies adopted to achieve accountability and fairnes.

# 4.5.1. Remaining close to the rating scale

In many part of the discussion, the teacher assssors clearl referenced sections and prose descriptors contained in the ratingscale. For instance, while discssing students performances Adam often signalld a shift in focus by naming a section from the rating scale as seen with his reference to "accuracy" and "presentation skills':

[FS1, Rating Discussion]

Adam: Accuracy. I think is good but when you say when you look at it in close-up it's not as good as it seems

# [...]

Adam: Presentation skills. Though I'd go a bit higher to be honest. I think she's confident and it's probably her trongest area.

The teacher asesors remain cose to the criteriato improve the manageability and reliability of the rating process The criteria is also heavily drawn upon in instances when low or high marks are being greed. In such cases, theciteria is physicall brought coer to the teacher asessors and parts red aloud verbatim. This was articularl noticeable when the techr asesorsdecided to assi aal mark to a student in FS2. Georgina and Tracey had discussed a student's performance in the AOP and other assessments, talking through what opportunities the student had had to showcase their radinessfor academic study. Georgina states that the presentation is a \*clear fal' while Tracey considers if the presentation could be a pass. However, Trace, with reluctance, acknowledges that the presentation is 5 marks below a pass mark of 50:

[FS2, Rating Discussion]

Tracey: I think 45 is actually probably more realistic about it isn't it.

Georgina: Yeah because (looks at notes indicating there are a lot of negative comments)

Tracey: (sigh) I know I've got them too (looks at paper fullof comments) pronunciation is difficult to understand.

(Teachers read parts of the marking criteria verbatim for 7 turns. They do this to locate aplicable criteria for reaching a score decision.)

Georgina: That's it thank you (directed at the marking criteria). 45

Tracey: Yeah I agree with you. (...)

Georgina: It's going to be unfAIR to say to him that you'll be Ok

In order to be sure a fail mark is far, the teacher read out sigficant part of the prose descriptors, determining that the descriptors in the band which constitutes a fail mark correspond with qualities of the student's performance. The teacher asssors' behaviour illusrates that the criteria is used to check decisions and regarded as a tol used to hold teachers accountable (Fulcher, 2012).

# 4.5.2. Moving away from the rating scale

There are criteria which are not cited in discussions and noted as difficult to notice or not applicable to the AOP performance. In FS1, \*complex language' is not described or evaluated in the rater talk. This is explained by Adam in an interview:

[FS2, Interview]

Adam: I think it's quite hard to listen for complex language or complex grammar structures (in AOPs).

In addition, throughout the discussions, there were references to aspects of performance which were not contained in the rating scales. In FS2, the criteria does not include presentation skill, however Georgina and Tracey refer to use of text, slide design, and ability to answer questions. In both sites, teacher assessors make reference to qualities of delivery styleaso not included in rating scales, such as "onfidence", "rgy" ad o trats observedduring th lifespan of the edcational course such s effrt. In one case, a teacher assessor notes that confidence affects the score outcome: \*that's basically a mark of confidence'.

When The Criteria ilter is weakly applied this is because of the dominance of the other filter, most notably The Social ilter. In FS1 and FS2 there were references to socioemotional aspects of learning, which were not covered in the rating scale, because socio emotional abilities were seen as an indicator of students abilit to lean in the target domain. How students fared overall on the year. long modules and Pre-Master's and IFP was considered a holistic indication as to how the students would function on an academic programme.

Excerpt 1

Daniel: Kristina is astudent that is getting stronger week on week, isn't she?In her reading project she prepared. She's trying really hard. [FS1 Rating Discussion]

Excerpt 2

Georgina: So if a student takes feedback on board that should be included in the mark I think. I think that for me that's very important that people show that they've understood what the requirements are. [Fs2, Rating Discussion]

The impetus to learn and ability to follow a course of study and navigate course and assessment requirements were core qualities that the teachers looked for and valued. Adam in FS1 was keen to stres hat responding to fdack did not always entail ollowing the teacher's advice, indicating that there is room to discussapproaches to tasks to afford space for student agency.

In sum, the teacher assessors had a complex and sophisticated relationship with the rating criteria, viewing it as a tool which fostered as well as hampered fairness.

# 5. Discussion and conclusion

The findings demonstrate that the assessment processes, as reflected in teacher asessor talk and interviews, on the two year-long EAP modules are far more complex than mapping a performance to a rating scale. The rating scale is an important artefact in the two field sites and inluence practice, however the rich and prolonged social interaction on these EAP modules ultimately means the social context and identities of the teacher asessors and student sseees aso influence the processes and practices enacted. The criteria cannot account for emergent situational factors and the particularly strong interpretive element involved in making judgements on students that the teachers have taught i small-clas interactions over the course ofasemester in FS1, and academic year in FS2. The most influential factor which leads to the use of The Ranking Filtr and The Social Filte is that the teachers use evidence garnered on how students function in the whole social learning environment on the EAP module and programme as the overall unit of analysis instead of restricting it to the AOP performance.

In local educational assessments which entail an element of predicting future performance, teachers have been found to draw on "external variables", such as efort and behaviour (Bonner, 2013; Lloa, 2008). The resons cited for this pertain to the role of context the dual learning and measurement purposes and the diverse assessment opportunities available over time in classroom based assesment (Bonner, 2013; Moss 003). In the current study, a tension has een demonstrated with teacher asessors acknowledging that evidence from the AOP should factor into the decision making, while also stating that insider information gleaned from the educational course can be aforce for good. Insider information may enhance the possbilit of reaching a justified and justifiable decision on whether a student passes the EAP programme.

As Leung and Teasdale (1997) note \*it is difficult to see how such a dimension [referring to wider circumstances], however powerfully articulated by teachers, could be incorporated into assessment for accountability, since it would render all asessments contingent upon evaluation of other conditions which may in many circumstances remain unknowable" (p.60-1). This is important to monitor closely. Yet, teacher assessors draw atention to instances when referring to information in some ways external to the AOP performance may hold relevance and be justified. The rating discussion is aspace in which teacher assesors check that the asesment construct marries up with the task affordances, teachers guild values and conceptualisation of the asssment purpose(s.At times, evidence from outside the AOP points to mitigating factors and acts as reassurance that the decision made on a discrete AOP task is a fair reflection of a student's ability to function on an Englsh-medium educational course. These findings highlight the ned for EAP practitioners to constantly reflect on what is deemed relevant and valid evidence in asessment processes in classroom based local assessments.

Alexander et al. (2008, p.307) underscore how challenging it is to distinguish assessments which serve formative and summative functions with many EAP assessments in fact consisting of a complex blend. Likewise,in teacher assessor decision-making tallk identifying what information shared is formatie or summative in orientation is highly complex. This is especiall the case on courses when teachers asesstheir own students and comment on how to improve learning and assessment proceses durin rating discussions. In the contexts featured in thi study, it was demonstrated that the formative dimension, the development in learning, is emphasised and valued in the teacher assessrs talk. It would be useful t replicate such ethnographicll-oriented investigations of assessment decision making on EAP programmes which entail various prior relationships between asessment stakeholders, particularly pro grammes on which teacher asessors mark students with which they have not previously interacted. The influence of local factors and individual agents means that research on one EAP programme may not translate to other programmes. However, the sues explored, and analytic categories created, in one EAP context can prove relevant to a number of EAP contexts (Robinson et al., 2001). Further research is encouraged which investigates the applicability and usefulness of the model proposed in this study in other assessment contexts.

In response to Schmitt and Hamp-Lyons (2015), the constructs of EAP across oral presentation asessments and within one oral presentationassessment are conceptualised and operationalised in various ways at diffrent points in time by teacher asesors: 1) as a speaking assessment 2) as an academic literacy and oracy asessment and 3) as an assessment of readiness fr academic study in English medium education. The findings underscore the importance that research is undertaken which investigates how rating scales are implemented in order to understand what is truly loked for and valued in assessment decision making. Investigating potential discord between stakeholders' stated, perceived and operationalised constructs iscrucial to facilitating heightened convergence, which in turn affords increased levels of construct validity and fairness (Macqueen, 2022).

Much dark matter pervades the rating process, but when asessments fulfil a gatekeeping function it isparamount that we endeavour to pinpoint what is referenced in order to improve learning and what afects a score outcome. In the words of Spolsky (1997): \*Once we accept the nee for a gatekeeping function, we are ethically bound to seek the most complete information available" (p. 246).

# Acknowledgements

Thank you to Professor Richard Kiely for his guidance during the doctoral proect and to ll those who took part in the research study.

# References

Alexander, ., Argent, S., & Spencer, J. (2008). AP esentials: A teacher's guide toprinciples and practice. London: Garnet Education.   
Beer .0r       , y  ,, 133-156.   
Benesch, S. (2001).Critical Englishfor academic puposes: Theory, politic, and practice. Mahwah, NJ: Lawrence Erlbaum Associates. (pp. 87-106). Thousand Oaks, CA: Sage Publications.   
Charmaz, K (2006. Constructing gronded thry: A practic gude trough quliative alysis (1st e.).housand Oaks, CA: Sage Publications.   
Charmaz, K. (2014). Constructing grounded theory (2nd ed.). Thousand Oaks, CA: Sage Publications.   
Charaz,  hl, G. (2001). Gndd thry in raphy. I P.nson, Coffy, . nt J Lflnd, L Lfnd (.), H ethnography (pp. 160-174). London: Sage publications.   
De Chazal, E. (2014). English for academic purposes. Oxford: Oxford University Press.   
Fulher,  (2012). S  s. .cher, o .) h  o f  eti  378392.  .   
Fulcher, G., & Davidson, F. (2007). Language testing and asessment: An advanced resource book. Abingdon: Routledge.   
Goffman, E. (1959). The presentation of self in everyday life. London: Penguin.   
Green, A. (2014). Exploring language assessment and testing: Language in action. Abingdon: Routledge.   
Hammersley, M., & Atkinson, P. (2019). Ethnography: Principles in practice ( $4 ^ { \mathrm { t h } }$ ed.). London: Routledge.   
Harrion,  021 skn  l ptio h   in n  s  Pr ia  f s r Academic Purposes, 53. https://doi.org/10.1016/j.jeap.2021.101002   
Hill,  amr. 21) elg amsive ill h rork for - . e estng 293, 395-420. https://doi.org/10.1177/0265532211428317   
Janu, J, then . (2015). pig dre ompeemets i AP  prttions tg ment nd trahic al. Si nd behavioural sciences, 208, 57-166.   
Joughin G. (007). td otins f ral prttions. Std in Highe tion, 32(3), 323-336. hp/i./10.1080/03075070701346873   
Leg  00c ie       tg 21(3), 335-359. https://doi.org/10.1191/0265532204lt287oa   
eung, C. ,  (197).  dng f rg a t  ad  inrs or in mkg    ng Testing, 6, 45-70.   
Levrai, P., & Bolster, A. (2015). Developing a closer understanding of academic oral presentations. Folio, 16(2), 65-72.   
Losa, L (200. Bun ad ptin  alt  for n a am f ishroi  n cher jugmnt. Educational Measurement: Issues and Practice, 27(3), 32-42. https://doi.org/10.1111/j.1745-3992.2008.00126.x   
a2).  .)o   p 233-250). Oxford: Oxford University Press.   
McNes,  Lo e (016r ae the t th rie  th inr . Crossle,  Ar,  .) Rsing inderr rh comtie d ntil cin (p 2138. for  ooks.   
Miller, C. R. (1984). Genre as social action. Quarterly Journal of Speech, 70, 151-167. 3992.2003.tb00140.x for academic purposes courses at UK universities. University of Southampton, Doctoral Thesis.   
Re-Dick. 01).or, ror  t   o    in (4, 2962. //10.177 026553220101800407 English for academic purposes (pp. 347-359). Cambridge: Cambridge University Press.   
Salrk6  h  f s  . /o. 10.1016/j.jeap.2015.12.005, 9-3.   
Schmit, , m-  015Th  P c     Ac  18./o./10.1019 j.jeap.2015.04.003   
Spolsky, B. (1997). The tic ofgatkeing ts: What hae we larnd in a 100 yer Language esting 14(3), 242-247. htp://doi.org/10.1177 026553229701400302   
Sudr., & Kel,  (2009. h o ion s aoxt fr g d .   g g d chg 2) 101117   
Swales, J. (2019). The uues of EAP e stdie: A pronal iewoint. Jdl of Englishfor dmic Puos 3, 75-82. hps:/oi.rg/10.1016/J jeap.2019.01.003   
Thurstone, L. L. (1927). A law of comparative judgement. Psychological Review, 34(4), 273-286.   
Van de Ven, A. (2007). Engaged scholarship: A guide for organizational and social research. New York: Oxford University Press.   
Widdowson, H. (2020). On the Subject of English: The linguistics of language use and leaning. Berlin: Mouton de Gruyter.   
Zapp-. 00 in  ie t l .   3, 585. https://doi.org/10.3138/cmlr.63.4.455   
Zareva, A. (2011). 2 gradate student Poweroint prtationdins: A relity check. Inmatioal Joun f Ivatin nd ng, 9(2), 127-144   
Zareva, A. (2016). Mult-word verbs in student academic preetatios. Joul of Egish for Aademic Pupoe, 23 83-98. htps://do.og/10.1016/j. jeap.2016.07.001