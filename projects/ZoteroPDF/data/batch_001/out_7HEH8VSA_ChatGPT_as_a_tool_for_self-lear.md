# Journal Pre-proof

ChatGPT as a tool for self-learning English among EFL learners: A multi-methods study

Nguyen Hoang Mai Tram, Tin Trung Nguyen, Cong Duc Tran

PII: S0346-251X(24)00310-5   
DOI: https://doi.org/10.1016/j.system.2024.103528   
Reference: SYS 103528

To appear in: System

Received Date: 14 December 2023

Revised Date: 25 October 2024

Accepted Date: 25 October 2024

# ChatGPT as a tool for self-learning English among EFL learners: A multi-methods study

Nguyen Hoang Mai Tram Ho Chi Minh City University of Foreign Languages - Information Technology, Ho Chi Minh City, Vietnam Email: tramnhm@huflit.edu.vn ORCID: https://orcid.org/0000-0003-4796-3325

Tin Trung Nguyen\* Faculty of Business Administration, Ton Duc Thang University, Ho Chi Minh City, Vietnam Email: nguyentrungtin@tdtu.edu.vn ORCID: https://orcid.org/0000-0003-3718-7879

Cong Duc Tran Faculty of Business Administration, Ton Duc Thang University, Ho Chi Minh City, Vietnam Email: trancongduc@tdtu.edu.vn ORCID: https://orcid.org/0000-0003-0765-5571

# ChatGPT as a tool for self-learning English among EFL learners: A

# multi-methods study

# Abstract

This study investigates the factors influencing ChatGPT acceptance in self-directed English language learning and explores its potential to enhance the learning process. A multi-methods approach was employed, comprising a systematic review of 40 empirical articles, a quantitative survey of 344 English as a Foreign Language (EFL) learners, and 19 semi-structured interviews. Results indicated that interactivity, enjoyment, trust, and subjective norms significantly affect continued use through perceived usefulness, while human-likeness, self-efficacy, and technology anxiety influence it through perceived ease of use. EFL learners utilize ChatGPT for both primary and secondary English learning purposes, supporting various language dimensions including reading, writing, vocabulary, and grammar. The study also identified both passive and active language learning engagement facilitated by ChatGPT. This research contributes to the field by proposing an extended Technology Acceptance Model and a conceptual framework for chatbotassisted language learning. For chatbot developers, the findings underscore the need to enhance interactivity, human-likeness, enjoyment, and trust while minimizing technology anxiety to increase sustained use. Educators can utilize these insights to better integrate ChatGPT into their curricula, supporting diverse language skills and engaging learners more effectively. Together, these findings provide concrete guidance for enhancing the design and implementation of AI chatbots in language learning contexts.

Keywords: Adoption; Artificial intelligence; Chatbot; EFL; Self-learning; Systematic review;   
Technology Acceptance Model.

# 1. Introduction

Chatbot is an AI-powered software application that enables interactions with users through text or voice functionality. The use of chatbots in language learning has been extensively studied and documented in recent years (e.g., Huang et al., 2023; Jeon et al., 2023). With the endless support offered by chatbots, EFL learners can have the chance to practice English beyond the classroom, thus increasing their language exposure (Huang et al., 2022). A wealth of studies have shown the potential of chatbots in enhancing language skills and other linguistics aspects, including, but not limited to, listening (Dhivya et al., 2023), speaking (Hwang et al., 2022), writing (Zhang et al., 2023), vocabulary (Polyzi & Moussiades, 2023), and grammar (Kim, 2019). Despite the ability to support language learning, Kuhail et al. (2023) have highlighted the significant limitation of existing chatbots in engaging and maintaining open-ended conversations with learners on various topics.

Chatbots are classified into two types, including goal-oriented and non-goal-oriented chatbots (Jeon et al., 2023). A goal-oriented chatbot is designed to perform specific tasks or achieve predefined outcomes during interactions. In language learning, goal-oriented chatbots are developed to provide learners with opportunities for interaction to improve their overall second language (L2) proficiency. Prior studies have revealed the effectiveness of goal-oriented chatbots, such as Smart Uenglish for speaking English in authentic contexts (Hwang et al., 2022), ELSA for pronunciation and listening skills (Dhivya et al., 2023), Duolingo for using gamification elements to learn English (Shortt et al., 2023), Memrise for collocation learning and retention (Esmaeili & Shahrokhi, 2020). As opposed to goal-oriented chatbots, non-goal-oriented chatbots are not designed for specific task completion or limited to predefined outcomes. Instead, they engage in more natural, open-ended conversations, often across a wide range of topics. However, this type of chatbot can motivate learners, reduce their foreign language phobia, and enhance their English skills, as evidenced by several applications such as Replika (Kim, 2019), Google Assistant (Tai & Chen, 2020), and Alexa (Dizon, 2017).

The November 2022 launch of ChatGPT, an advanced non-goal-oriented chatbot based on large language models (LLM), is forecasted to address the limitations of current chatbot technologies and alter the approach to language learning (Kasneci et al., 2023). This new AI tool gained one million subscribers within five days of release and 100 million after a month (Paul et al., 2023). In contrast to current chatbot systems that rely on predefined answers and basic dialogues (Kuhail et al., 2023), ChatGPT can generate human-like responses and sustain multitopic conversations (Susnjak & McIntosh, 2024). Furthermore, ChatGPT can tailor study plans to each learner's individual needs, interests, and learning pace (Tlili et al., 2023). With its available features, ChatGPT is a potential language companion that may hone learners' language skills and constantly assist them in their language learning journey (Barrot, 2023; Bin-Hady et al., 2023; Liu & Ma, 2024; Yan, 2023). While the potential of non-goal-oriented chatbots in language learning is evident, there remains a scarcity of research in this area, particularly for LLM-based chatbots like ChatGPT, which are rapidly gaining popularity (Jeon et al., 2023). Investigations into the use of non-goal-oriented chatbots among EFL learners will pave the way for research on how technologies not primarily created for education purposes can be efficiently utilized by learners.

ChatGPT, a non-goal-oriented chatbot, has not been given sufficient attention in the EFL context. Some research has explored ChatGPT's functionalities for EFL learners but has mainly discussed the writing dimension (e.g., Barrot, 2023; Yan, 2023). These studies have unveiled the potential merits and pitfalls of ChatGPT for L2 writing. To probe into other facets of learning, Bin-Hady et al. (2023) and Mohamed (2024) examined the effectiveness of ChatGPT in English language learning. Nevertheless, these studies relied on the viewpoints of researchers and teachers without concerning the opinions of EFL learners who are the primary users with firsthand experience using ChatGPT.

A study by Liu and Ma (2024) used the Technology Acceptance Model (TAM), developed by Davis (1989), to explore EFL learners' adoption of ChatGPT. However, the study was merely concerned with the original TAM constructs (i.e., perceived ease of use, perceived usefulness, attitude, behavioral intention), leaving a substantial research gap in how other technological, individual, and social factors contribute to the acceptance of ChatGPT in the EFL context (e.g., Li, 2021; Li et al., 2019; Ni & Cheung, 2023; Zhai & Ma, 2022). Hence, research on ChatGPT adoption should take a broader lens beyond the core factors of the TAM to comprehensively understand the determinants of EFL learners' usage of ChatGPT. Furthermore, learning English is a cumulative process that requires continuous practice to achieve desired goals (Bas & Gezegin, 2015). However, Liu and Ma (2024) focused on initial usage behaviors, overlooking the long-term effect of ChatGPT on EFL learners. To reflect users willingness to learn with ChatGPT as a lasting partner, continuance intention is a more effective measure. Responding to these research gaps, the present study aims to address the two following research questions:

RQ1: What are the determinants of EFL learners' adoption of ChatGPT as a chatbot-assisted language learning?

RQ2: How do they use ChatGPT to assist their English learning process?

To address RQ1, an explanatory sequential multi-methods design was adopted, as it allowed for the integration of quantitative and qualitative findings to provide a logical and comprehensive answer to the research question (Venkatesh et al., 2016). Initially, a quantitative study was developed from a systematic literature review to examine the extended TAM with individual, social, and technological factors and their impacts on the continuance intention. Based on the survey results, the qualitative phase involved conducting semi-structured interviews to clarify the relationships between variables in the proposed research model (Creswell & Clark, 2011). These interview findings enhance the quantitative data by offering specific examples of how EFL learners accept and use ChatGPT in self-learning contexts. For RQ2, qualitative data from these interviews were also analyzed. Since ChatGPT is still emerging in self-learning contexts among EFL learners and represents a significant research area, it is appropriate to explore EFL learners' experiences and perceptions of using ChatGPT through qualitative methods. As Creswell (2014) suggests, a qualitative approach is particularly suitable for investigating new or developing phenomena.

# 2. Theoretical background

# 2.1. Non-goal oriented chatbots

Chatbots are AI-powered software applications that allow interactions with users through text or voice. According to Jeon et al. (2023), chatbots are divided into two types: goal-oriented and nongoal-oriented. Non-goal-oriented chatbots, also known as open-domain chatbots, engage in conversations without a predefined goal (Jeon et al., 2023). These chatbots are designed to maintain conversations rather than achieve a specific objective. In contrast, goal-oriented chatbots focus on completing specific tasks assigned to them (Jeon et al., 2023). In the field of language education, if a chatbot is designed to meet the needs of language learners, it is considered a goaloriented chatbot. For example, Elsa Speak, a language learning app that focuses on pronunciation, speaking, and listening skills, is a goal-oriented chatbot (Dhivya et al., 2023). On the other hand, Google Assistant, a commercial chatbot designed to serve all users without a specific language learning purpose, is considered a non-goal-oriented chatbot. However, Google Assistant has still demonstrated improvements in speaking proficiency, listening comprehension, and the willingness to communicate among EFL learners (Tai & Chen, 2020). Fryer et al. (2020) also pointed out that the benefits of non-goal-oriented chatbots lie in providing learners with experiences in discussing various topics when interacting with these chatbots. However, non-goal-oriented chatbots also present challenges in language learning. Since these chatbots are designed to interact with all users without considering the language proficiency level of learners, this can lead to misunderstandings and ineffective learning experiences (Tai, 2022). Therefore, further development of non-goaloriented chatbots is needed to personalize and better understand the educational needs of users. ChatGPT, a non-goal-oriented chatbot based on LLM, is expected to overcome the limitations of current chatbot technologies and revolutionize the approach to language learning. Since its launch in November 2022, ChatGPT has attracted over 100 million users. The technology has been praised for its ability to generate human-like text in various formats, from short answers to lengthy essays (OpenAI, 2022). Notably, ChatGPT has the capability to self-learn and update its knowledge through interactions with users and real-world data (Mintz & Brodie, 2019). Nongoal-oriented chatbots like ChatGPT have demonstrated significant potential in language education. For instance, ChatGPT can assist EFL teachers with various tasks, including lesson planning, exercise creation, finding teaching materials, and professional development (Kohnke et al., 2023; Mohamed, 2024; Tram & Tran-Thanh, 2024). Moreover, ChatGPT supports learners in various aspects of language learning, from enhancing writing skills and expanding vocabulary to providing learning materials and serving as a conversational partner (Bin-Hady et al., 2023; Karatas et al. 2024; Yang & Li, 2024). Particularly, its ability to personalize learning paths based on users' interests, learning pace, and proficiency helps improve learning outcomes (Huang et al.,

2022). As a result, it holds great promise as a valuable tool for self-directed learning (Liu & Ma, 2024; Liu et al., 2024). Investigations into the use of non-goal-oriented chatbots among EFL learners in self-learning contexts will uncover the motivations behind their use of ChatGPT and reveal the ways in which learners integrate it into their English learning. This contributes to a deeper understanding of how non-goal-oriented chatbots can be effectively utilized in self-directed learning environments and informs strategies to enhance language learning experiences through such technologies.

# 2.2. Systematic review

In response to the paucity of up-to-date systematic reviews examining learner adoption of AIenabled technologies, we conducted a comprehensive literature review focusing on factors influencing the adoption of these technologies in learning contexts. Our methodology adhered to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines (Moher et al., 2009) to ensure a rigorous and transparent process. We initiated our search by exploring four prominent academic online databases: Scopus, Web of Science, EBsCOhost, and IEEE Xplore. To capture potential sources not indexed in these databases, we supplemented our search using Google Scholar. Following relevant reviews (Huang et al., 2022; Mohsen, 2022), we employed a search strategy that combined multiple keywords using Boolean operators. The search string was structured as follows: (education OR learning OR EFL OR ESL) AND (adoption OR acceptance OR use OR continuance) AND (artificial intelligence OR AI OR chatbot). This initial search yielded 4,286 documents after removing duplicates. We then implemented a systematic screening process, wherein titles, abstracts, and full-text documents were examined and coded based on a predefined set of criteria (Figure 1). To ensure the reliability of this process, one researcher independently conducted the initial screening, which was subsequently reviewed by a second researcher. Following this comprehensive screening and selection procedure, we identified 40 eligible studies for inclusion in our literature review.

![](img/4358dadcd2f15ca19050f07698f5ef7434e741019b4a98f1d039bf2e1948663e.jpg)  
Figure 1. Search protocol

The review of included studies revealed a diverse array of theoretical frameworks employed to elucidate the factors influencing individuals' adoption of AI-enabled technologies for learning (Web Appendix: Table A1). Among these, ten distinct theories and conceptual models were identified. Notably, the TAM emerged as the predominant framework, utilized in $50 \%$ of the studies, followed by the Unified Theory of Acceptance and Use of Technology (UTAUT) Model, which was employed in $2 5 \%$ of the research.

The primary aim of this study is to explore the factors influencing the adoption of non-goaloriented chatbots in self-directed English learning. These factors can stem from the technical aspects of AI technologies, individual learning motivations, or broader social norms. Consequently, we require a framework that is parsimonious enough to be theoretically extended by integrating various external factors . Simultaneously, there should be sufficient evidence from the literature demonstrating the framework's adaptability in educational and learning contexts.

The results from the literature review indicated that the TAM emerged as the most parsimonious and versatile model to address the study objectives compared to other potential theories and frameworks used in prior studies (Web Appendix: Table A1). Its widespread use in the field, coupled with its flexibility to incorporate additional constructs, makes it particularly suitable for this research (Pillai et al., 2024). Furthermore, the TAM's proven applicability in educational technology contexts reinforces its appropriateness for our study (Belda-Medina & Calvo-Ferrer, 2022; Hamidi & Chavoshi, 2018). Given these considerations, we adopted the TAM as the core theoretical framework for our research. This choice allows us to build upon a wellestablished model while incorporating specific factors relevant to AI-enabled language learning technologies.

In our analysis of external factors influencing the TAM, we adhered to the methodological approach employed in prior review studies (e.g., Verma et al., 2023) to ensure conceptual clarity and discriminant validity. This process involved consolidating and relabeling similar constructs that were described using different terminology (e.g., human-likeness and anthropomorphism, subjective norms and social influence). Consequently, we identified ten distinct factors emerging from the literature review (Figure 2). Drawing upon the classification scheme proposed by Zhai and Ma (2022), we categorized these factors into three groups: technological, individual, and social factors. This structured approach aims to provide a nuanced understanding of the multifaceted influences on AI-enabled technology adoption in learning contexts, with a specific focus on ChatGPT usage among EFL learners. The subsequent sections of this literature review will provide a comprehensive discussion of the TAM and offer a detailed conceptualization of these identified factors.

# 3. Hypothesis development

# 3.1. Technology Acceptance Model

Derived from the seminal theories of reasoned action (Fishbein, 1979) and planned behavior (Ajzen, 1991), the TAM posits that people have a greater tendency to adopt an information system when they consider it as beneficial (perceived usefulness) and effortless (perceived ease of use) in accomplishing tasks (Davis, 1989). Thanks to its strong theoretical foundation and the potent explanatory power of these two pivotal constructs, TAM serves as a parsimonious model for explaining the adoption of various advanced technologies (Chang et al., 2024; Li et al., 2019; Liu & Ma, 2024; Ni & Cheung, 2023).

In educational technology literature, the TAM has demonstrated versatile applicability. Researchers have applied and extended TAM to explore learners' use of AI-enabled technologies such as teacher-bots in higher education (Pillai et al., 2024), chatbots for language learning (BeldaMedina & Calvo-Ferrer, 2022; Chen et al., 2020), AI-powered tutoring system (Ni & Cheung, 2023), and virtual reality in English learning (Chang et al., 2024). Furthermore, a recent study by Liu and Ma (2024) confirmed the suitability of the TAM for explaining the adoption of ChatGPT by EFL learners. However, this study solely focused on the core constructs of the original TAM (i.e., perceived usefulness and perceived ease of use).

![](img/5bc8ddb463018f29e044c1840f3e0967308003cf2f39ee0f2bab6b6ef7d358c0.jpg)  
Figure 2. The proposed research model

While the original TAM is helpful in understanding people's acceptance and usage of novel technology, it has limitations in evaluating the improvements of specific features within the technology compared to previous versions or other technologies with similar purposes. Hence, a more nuanced and feature-oriented perspective is needed to illuminate how EFL learners use ChatGPT to enhance their language proficiency. Such an approach will facilitate a comprehensive understanding of the distinctive attributes of ChatGPT that can encourage and assist language acquisition, thereby paving the way for further advancements in educational technology. Taking this approach, we proposed the associations among the core constructs of the TAM that influence EFL learners' acceptance of ChatGPT, for self-learning as follows.

H1: Perceived ease of use is positively related to perceived usefulness of ChatGPT.   
H2: Perceived usefulness is positively related to continuance intention of ChatGPT.   
H3: Perceived ease of use is positively related to continuance intention of ChatGPT.

Then, following Zhai and Ma (2022) and our systematic literature review, we considered three categories of external factors that may influence EFL learners' acceptance and continued use of ChatGPT for English self-learning. These categories include technological, individual, and social factors. We integrated these external variables into the TAM as predictors of perceived usefulness and perceived ease of use, which are the key determinants of sustained technology usage. Based on theoretical, logical, and empirical grounds, we formulated hypotheses to analyze the correlations between these variables in the following section. All relationships proposed in these hypotheses are depicted in Figure 2.

# 3.2. Technological factors

# 3.2.1. Perceived intelligence

Perceived intelligence has been extensively investigated in human-robot interaction research (Lee et al., 2023; Pillai et al., 2024). Qiu et al. (2020) demonstrated through experimental research that individuals tend to allocate more time to interactions with robots perceived as possessing higher levels of intelligence. Conversely, when humanoid robots fail to meet expected competence levels, individuals may experience heightened disappointment and anger (Tung & Au, 2018), potentially leading to ineffective interaction or usage termination.

In the context of educational chatbots, Pillai et al. (2024) defined perceived intelligence as the capacity to generate accurate and effective responses through proficient natural language understanding and processing. For automated writing evaluation systems, Zhai and Ma (2022) conceptualized perceived intelligence as the quality of cognitive feedback that facilitates students' writing skill enhancement. Furthermore, perceived intelligence has been identified as a predictor of teacher-bot adoption (Pillai et al., 2024). For individuals utilizing ChatGPT to enhance their English proficiency, the perceived intelligence of this chatbot is contingent upon its ability to comprehend learners' requests and generate concise responses characterized by impeccable collocation, grammar, and structure. This perception of intelligence has the potential to foster cognitive development in learners, motivating them to strengthen their English language skills. Drawing upon these insights, the following hypothesis is formulated.

H4: Perceived intelligence is positively related to perceived usefulness of ChatGPT.

# 3.2.2. Personalization

Personalization has emerged as a prominent theme in educational research. Various terms, such as personalizing, tailoring, customizing, matching, or adapting educational content, have been employed interchangeably to acknowledge and comprehensively address the inherent diversity among learners (Bhutoria, 2022). The foundational tenet of personalized education lies in conducting problem analyses to examine students' individual needs (Cook et al., 2018). From identifying individual learners' problems, tailored solutions can be devised to align with students' unique learning preferences and needs. In this regard, the application of educational technologies has proven instrumental, providing the education sector with tangible and data-driven approaches to achieve personalization.

In the era of personalized learning, AI technology has emerged as a sophisticated learning companion, capable of analyzing users' real-time requests and providing tailored learning experiences based on individual proficiency levels (Bhutoria, 2022). Extant research in AI technology has underscored the critical role of perceived personalization in promoting technology adoption and enhancing user experience (Chan et al., 2022). This emphasis is particularly salient within the educational context (Bhutoria, 2022; Chang et al., 2022; Pillai et al., 2024). In light of this, the present study conceptualizes perceived personalization as EFL learners' assessment of ChatGPT's capacity to provide customized assistance in English learning. Specifically, this refers to ChatGPT's ability to swiftly recognize learners' characteristics--such as language proficiency, specific needs, and personal attributes--through minimal interactions, and subsequently tailor its responses to address these identified needs effectively. Based on the aforementioned discussion, we propose the following hypothesis.

H5: Personalization is positively related to perceived usefulness of ChatGPT.

# 3.2.3. Interactivity

In the context of technology, interactivity manifests as the seamless responsiveness of a technological interface to user inputs, fostering a frictionless and immersive interaction (Hoffman & Novak, 1996). Within the educational domain, interactivity is conceptualized as students' subjective evaluation of their active involvement in communication, discussion, and information exchange during the teaching and learning process (Wang et al., 2023; Zhang et al., 2021). Taken together, this study defines interactivity as the degree to which learners can engage in seamless interactions with ChatGPT and experience a sense of involvement during these exchanges.

The significance of interactivity within the online learning context is underscored by its potential to enhance the overall learning experience for students (Al-Rahmi et al., 2018). Research has demonstrated that interactivity fosters students' intention to participate in AI-assisted teaching environments, resulting in improved communication and enhanced learning outcomes (Rahim et al., 2022). Moreover, empirical evidence indicates that interactivity serves as an antecedent to the acceptance of advanced technologies, including AI and other chatbots (de Cicco et al., 2020). In the specific case of ChatGPT, where the application interacts with EFL learners to address their queries and provide usable output, the role of interactivity assumes paramount importance. The interactive nature of ChatGPT allows for real-time, dynamic exchanges that can potentially enhance the learning experience and facilitate language acquisition. Based on this rationale, the following hypothesis is formulated.

H6: Interactivity is positively related to perceived usefulness of ChatGPT.

# 3.2.4. Human-likeness

Human-likeness refers to attributes that non-human entities resemble a human being (Lee et al. 2023; Lu et al., 2019). According to the uncanny valley theory (Gray & Wegner, 2012), products or objects with anthropomorphic features tend to evoke positive perceptions among individuals. This relationship, however, may not always exhibit a linear pattern (Chuah & Yu, 2021). On the one hand, Mori et al. (2012) revealed that users tend to experience a sense of affinity and attachment towards human-like robots. Similarly, Tussyadiah and Park (2018) demonstrated that the human-like appearance of robots positively influences consumers' intentions to use hotel service robots. In contrast, other studies reported that anthropomorphic machines are often perceived as encroaching upon human identity, resulting in feelings of discomfort among individuals (Lu et al., 2019; Mende et al., 2019). Given these mixed findings, Goudey and Bonnin (2016) proposed that users might be more receptive to robots with some anthropomorphic features rather than a fully human-like appearance.

Since most chatbots are designed to engage in conversations with users via text or voice without physical features that mimic human bodies, human-likeness may have a positive influence on their adoption. Indeed, empirical evidence within the existing literature illustrated a positive association between human-likeness and the adoption of chatbots for hospitality services (Pillai & Sivathanu, 2020), digital assistants in e-commerce (Balakrishnan & Dwivedi, 2024), and teacherbots (Pillai et al., 2024). Based on these studies, hypothesis 7 is formulated as follows.

H7: Human-likeness is positively related to perceived ease of use of ChatGPT.

# 3.3. Individual factors

# 3.3.1. Learning-goal orientation

The concept of goal orientation delineates how individuals pursue and achieve success (Van De Rhee et al., 2007). Individuals with a high learning-goal orientation exhibit intrinsic motivation to acquire new knowledge and enhance their skills. They embrace the notion that abilities are malleable rather than fixed, and can be developed through knowledge acquisition and skill enhancement (Wood & Bandura, 1989). Consequently, these individuals actively seek opportunities that facilitate knowledge gain and skill refinement.

Extant research has explored the association between goal orientation and knowledge acquisition across diverse self-learning contexts (Almaiah et al., 2022; Ni & Cheung, 2023). Learning goals have been linked to various positive outcomes, including higher levels of selfefficacy, more effective learning strategies, increased effort, and improved performance (Mun &

Hwang, 2003). Koestner and Zuckerman (1994) posited that students with high learning-goal orientation employ a broader range of learning strategies, engage in deeper knowledge processing, and demonstrate superior utilization of metacognitive knowledge. Moreover, these individuals exhibit greater adaptability to change, persistence in facing challenging or novel tasks (Kozlowski et al., 2001), and a higher propensity to adopt various supporting technologies (Ni & Cheung, 2023).

In the context of adopting new technology, particularly for self-directed learning, individuals with high levels of learning-goal orientation tend to embrace the challenges presented by advanced technological functions and cultivate self-confidence in their utilization (Ni & Cheung, 2023). This propensity for engagement with novel learning tools suggests a potential relationship between learning-goal orientation and the adoption of innovative educational technologies. Thus, we propose the following hypothesis:

H8: Learning-goal orientation is positively related to perceived usefulness of ChatGPT.

# 3.3.2. Enjoyment

Based on the definition of perceived enjoyment in information systems (Park et al., 2012, Venkatesh et al., 2003), Ni and Cheung (2023) applied this construct to the context of an AIenabled English tutoring system. They defined perceived enjoyment as the pleasure derived from utilizing the technology for language learning. Their study revealed a significant positive relationship between perceived enjoyment and perceived usefulness. Moreover, prior research has demonstrated the substantial impact of perceived enjoyment on the perceived usefulness and acceptance of advanced learning technologies. For instance, Bai et al. (2021) employed the expectancy-value theory to explain that students are more likely to persist in using technology for learning when they find the experience pleasurable and enjoyable. Su and Chiu (2021) found that learners are more inclined to contribute to the usability, adoption, and continued use of an online learning system if they perceive their engagement with the system as enjoyable. Drawing on the existing literature, we hypothesize that when individuals perceive learning English with ChatGPT as a pleasant experience, they will develop a favorable opinion of the technology's usability, which will subsequently lead to prolonged usage.

H9: Enjoyment is positively related to perceived usefulness of ChatGPT.

# 3.3.3. Trust

Trust plays a pivotal role in human-computer interaction (Nikou & Economides, 2017; Pillai et al., 2024). Rousseau et al. (1998) define trust as a psychological state comprising the intention to accept vulnerability based upon positive expectations of the intentions or behavior of another." In the context of technology adoption, trust is conceptualized as users' beliefs regarding a technology's capacity to securely protect their personal data (Al Shamsi et al., 2022). Trust serves multiple functions in technological interactions. It helps mitigate privacy-related risks and uncertainties, fosters positive and meaningful experiences with technology, and facilitates the development of healthy relationships with related systems (Maheshwari, 2023).

The significance of trust in educational technology has been empirically demonstrated. For instance, Chae et al. (2016) revealed a significant influence of perceived trust on learners' intentions to engage in e-learning activities. Similarly, Nikou and Economides (2017) demonstrated that perceived trust leads to positive perceptions of the utility of mobile-based assessment. Transposing this concept into the context of students' interaction with teacher-bots, Pillai et al. (2024) conceptualized perceived trust as students' belief in the communication and feedback offered by teacher-bots and their willingness to share personal data with teacher-bots. Their findings revealed that a student's propensity to disclose personal data to teacher-bots in exchange for outcome information is contingent upon their confidence in the credibility of these bots. Within this context, trust emerges as a key factor in students' decision to accept or reject information and outcomes offered by teacher-bots, consequently fostering heightened perceptions of usefulness and intentions to sustain usage. In light of this, we posit that EFL learners who place their trust in ChatGPT are likely to perceive it as beneficial for learning English.

H10: Trust is positively related to perceived usefulness of ChatGPT.

# 3.3.4. Self-efficacy

Self-efficacy refers to an individual's perception of their capabilities to achieve specific performance levels in various life milestones (Bandura, 2010). In the field of human-computer interaction, this construct has been adapted as "computer self-efficacy,' which pertains to an individual's ability to successfully carry out specific tasks using technology (Tsai et al., 2011). Previous studies have demonstrated a positive correlation between computer self-efficacy and the perceived ease of use of educational technologies (Li, 2021; Li et al., 2019; Zhai & Ma, 2022). For instance, Han and Shin (2016) found that students with higher computer self-efficacy are more likely to increase their use of e-learning devices. Abdullah et al. (2016) showed that individuals with higher levels of computer self-efficacy tend to engage more deeply in e-learning activities. Additionally, Li et al. (2019) revealed a significant influence of computer self-efficacy on the perceived ease experienced by EFL learners when engaging with automated writing evaluation systems. Therefore, it is expected that individuals with higher levels of computer self-efficacy will be more likely to utilize the advanced functions of technology, such as ChatGPT, for self-learning purposes.

H11: Self-efficacy is positively related to perceived ease of use of ChatGPT.

# 3.3.5. Technology anxiety

The term "technology anxiety" refers to the experience of anxiety when using a computer system (Venkatesh et al., 2003). In the context of educational information technology, Zhai and Ma (2022) employed this construct to examine the emotional responses of individuals using advanced technologies for learning purposes. Consistent with previous research (Li et al., 2019; Nikou & Economides, 2017), they found a negative association between computer anxiety and perceived ease of use of technology.

However, the effects of technology anxiety on individuals' attitudes and behaviors toward learning-support technologies, particularly among EFL learners, remain equivocal. The existing literature presents mixed results (Lai, 2010; Li et al., 2019). Some studies indicate that technology anxiety leads to the avoidance of computer use (Celik & Yesilyurt, 2013) and negatively affects the perceived ease of use, attitude, and behavior of EFL learners toward automated writing evaluation systems (Li et al., 2019). Conversely, other research suggests that technology anxiety does not significantly impact the writing complexity, accuracy, and fluency of EFL learners (Amiryousefi, 2016). Similarly, technology anxiety was found to play a limited role in explaining second language writing performance. Given these conflicting findings, this study aims to further explore the impact of technology anxiety on the use of ChatGPT as a supporting technology for English learning.

H12: Technology anxiety is negatively related to perceived ease of use of ChatGPT.

# 3.4. Social factor: subjective norms

The concept of subjective norms was introduced in the UTAUT Model (Venkatesh et al., 2003). According to Venkatesh et al. (2003, p. 451), subjective norms, also referred to as social influence, denote the "degree to which an individual perceives that important others believe he or she should use the new system.' In the context of AI-powered technology, this definition can be adapted to reflect the extent to which individuals perceive that their significant others believe they should use such technology. Prior research has demonstrated a positive association between subjective norms and users' perceived usefulness of new online learning applications (Wang et al., 2022). Moreover, subjective norms, along with performance expectancy and effort expectancy, shaped college students' behavioral intention to use social networking tools for online learning (Alvi, 2021). Similarly, subjective norms were found to positively impact individuals' perceived usefulness in various educational technology contexts, including web-based assessment (Terzis & Economides, 2011), automated writing evaluation systems (Zhai & Ma, 2022), and mobile learning (Wang et al., 2009). Based on these findings, we propose hypothesis 13 as follows.

H13: Subjective norms are positively related to perceived usefulness of ChatGPT.

# 4. Method, analysis, and findings

4.1. Study 1: Survey

# 4.1.1. Measurements and data collection

A survey questionnaire including 46 items was used to collect data for measuring 13 constructs (Web Appendix: Table A2). These items were adapted from the previous studies on information technology systems and supporting technologies for education: four items for perceived intelligence (Pillai et al., 2024; Zhai & Ma, 2022), three items for personalization (Chang et al., 2022; Pillai et al., 2024), five items for interactivity (Lee et al., 2022; Pillai et al., 2024), four items for human-likeness (Pillai et al., 2024), five items for learning-goal orientation (Ni & Cheung, 2023), five items for enjoyment (Ni & Cheung, 2023), four items for trust (Pillai et al., 2024), two items for self-efficacy (Belda-Medina & Calvo-Ferrer, 2022), three items for technology anxiety (Zhai & Ma, 2022), three items for subjective norms (Zhai & Ma, 2022), three items for perceived ease of use (Li, 2021), three items for perceived usefulness (Li, 2021), and two items for continuance intention (Li, 2021). The Vietnamese translation of these items was checked with the participation of twenty students to ensure their readability, logical coherence, and face validity.

Prior to survey distribution, the measurement items and data collection procedure underwent a comprehensive review by the school's ethics committee. The official survey commenced with an informed consent form presented to all participants. This form provided information on response anonymity, the voluntary nature of participation, participants' right to withdraw at any stage of the research, and the consent for data utilization upon survey completion. Invitations to participate in the study were disseminated to five social media groups whose members regularly share educational information. After a one-month data collection period (April 2023), a total of 412 participants had completed the questionnaire. From this initial pool, 78 participants were identified as non-users of ChatGPT for English learning purposes and were subsequently excluded from the analysis. The participant profile is presented in Table 1.

# 4.1.2. Analysis and findings

Given the multi-level relationships among the constructs in the proposed model, we employed SmartPLS for structural model testing, following relevant studies in the education domain (Chang et al., 2022; Wang et al., 2023). The analysis began with an examination of factor loadings, Cronbach's alpha, average variances extracted (AVE) values, and Heterotrait-Monotrait (HTMT) ratios. The results revealed that factor loadings, Cronbach's alpha, and AVE values for all items exceeded the recommended benchmarks of 0.7, 0.7, and 0.5, respectively (Hair et al., 2017a, b) (Web Appendix: Table A2). These findings confirm the construct reliability, internal consistency, and convergent validity of our measures. Additionally, the discriminant validity was established as all HTMT ratios were found to be below the threshold of 0.9 (Hair et al., 2017a, b).

Table 1. Survey participant profile   

<html><body><table><tr><td>Profile</td><td>Measure</td><td>Frequency</td><td>%</td></tr><tr><td>Gender</td><td>Female</td><td>198</td><td>59.30</td></tr><tr><td rowspan="3">Age</td><td>Male</td><td>136</td><td>40.70</td></tr><tr><td>18-29</td><td>270</td><td>80.80</td></tr><tr><td>30-39 aI Pre</td><td>45</td><td>13.50</td></tr><tr><td rowspan="4">Education</td><td>40-49</td><td>19</td><td>5.70</td></tr><tr><td>Secondary school diploma</td><td>4</td><td>1.20</td></tr><tr><td>High school diploma</td><td>258</td><td>77.25</td></tr><tr><td>Bachelor&#x27;s degree</td><td>65</td><td>19.46</td></tr><tr><td rowspan="4">English proficiency</td><td>Postgraduate degree</td><td>7</td><td>2.10</td></tr><tr><td>IELTS &lt;5.0 or equivalent</td><td>72</td><td>21.56</td></tr><tr><td>IETLS 5.0-6.5 or equivalent</td><td>114</td><td>34.13</td></tr><tr><td>IELTS &gt;6.5 or equivalent</td><td>148</td><td>44.31</td></tr></table></body></html>

Subsequently, we assessed the potential presence of common method bias (CMB) using two approaches: the single-factor Harman's test and variance inflation factor (VIF) values. The results of Harman's test revealed that the highest variance explained by a single factor was $3 8 . 2 6 \%$ which falls below the suggested threshold of $50 \%$ (Podsakoff et al., 2003). Additionally, VIF values ranged from 1.06 to 3.354, all of which are below the recommended threshold of 5.0 (Kock & Lynn, 2012). These findings collectively indicated that CMB is not a major concern in this study.

After confirming the validity and reliability of the measurement scales, we tested the hypotheses using the bootstrapping function with 5,000 iterations in SmartPLS. The results are presented in Table 2. Regarding the core TAM, all relationships were found to be significantly positive, which supported H1 $( \mathsf { p } { < } 0 . 0 0 0 )$ , H2 $\scriptstyle \int \displaystyle \mathrm { < } 0 . 0 0 0 )$ ,and H3 $\scriptstyle ( \rho = 0 . 0 2 5$ . Among the technological factors, the effects of perceived intelligence and personalization on perceived usefulness were found to be non-significant $\mathrm { ( \rho { > } 0 . 0 5 ) }$ , leading to the rejection of H4 and H5. However, there were significantly positive associations between interactivity and perceived usefulness (H6, $\scriptstyle \mathsf { p } = 0 . 0 0 4 ,$ , and between human-likeness and perceived ease of use (H7, $\mathsf { \rho } _ { \mathsf { \rho } } = 0 . 0 1 8$ Concerning individual factors, the analysis did not find any significant influences of learning-goal orientation on perceived usefulness (H8, $\mathsf { p } { = } 0 . 3 8 8$ ). However, aligning with our expectation, perceived enjoyment and trust were confirmed to have positive impacts on perceived usefulness (H9, $\scriptstyle \mathsf { p } = 0 . 0 0 2$ ; H10, $\rho { = } 0 . 0 1 4$ ). Moreover, self-efficacy and technology-anxiety also had significant effects on perceived ease of use, which supported H11 $\scriptstyle \int \cdots 0 . 0 0 0 )$ and H12 ( $\scriptstyle \int = 0 . 0 4 5$ , respectively. The social factor of subjective norms also showed a significantly positive influence on perceived usefulness, confirming H13 $\scriptstyle ( \rho = 0 . 0 3 5$ . Lastly, the assessment of control variables showed no significant effects of gender $\scriptstyle ( \rho = 0 . 8 2 4 )$ , age $( \mathsf { p } ^ { = } 0 . 1 0 9$ , education $\scriptstyle \int = 0 . 7 2 0 $ , and English proficiency $( \mathsf { p } ^ { = } 0 . 0 6 4 )$ on continuance intention. To elucidate further understanding of how technological, individual, and social factors affect ChatGPT adoption among EFL learners, we conducted post-hoc serial mediation analyses. The results are presented in Web Appendix: Table A3.

Table 2. Hypothesis testing results   

<html><body><table><tr><td>Effects on endogenous variables</td><td>Path coefficient ()</td><td> p-value</td><td colspan="2">Confidence interval 97.5%</td><td>Decision</td></tr><tr><td>1. Continuance intention (Adj. R2 = 0.554)</td><td></td><td></td><td>2.5%</td><td></td><td></td></tr><tr><td>Perceived usefulness (H2+)</td><td>0.660</td><td>0.000**</td><td>0.015</td><td>0.215</td><td>Supported</td></tr><tr><td>Perceived ease of use (H3+)</td><td>0.115</td><td>0.025*</td><td>0.558</td><td>0.752</td><td>Supported</td></tr><tr><td>2. Perceived usefulness (Adj. R2 = 0.652)</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Perceived ease of use (H1+)</td><td>0.200</td><td>0.000**</td><td>0.088</td><td>0.307</td><td>Supported</td></tr><tr><td>Perceived intelligence (H4+)</td><td>0.060</td><td>0.377</td><td>-0.062</td><td>0.192</td><td>Not</td></tr><tr><td>Personalization (H5+)</td><td>0.142</td><td>0.059</td><td>-0.002</td><td>0.291</td><td>supported Not</td></tr><tr><td>Interactivity (H6+)</td><td>0.172</td><td>0.004*</td><td>0.049</td><td>0.289</td><td>supported Supported</td></tr><tr><td>Learning-goal orientation (H8+)</td><td>0.037</td><td>0.388</td><td>-0.030</td><td>0.138</td><td>Not</td></tr><tr><td>Enjoyment (H9+)</td><td>0.228</td><td>0.002*</td><td>0.066</td><td>0.342</td><td>supported Supported</td></tr><tr><td>Trust (H10+)</td><td>0.145</td><td>0.014*</td><td>0.008</td><td>0.242</td><td>Supported</td></tr><tr><td>Subjective norms (H13+)</td><td>0.109</td><td>0.035*</td><td>0.008</td><td>0.213</td><td>Supported</td></tr><tr><td>3. Perceived ease of use (Adj. R2 = 0.361)</td><td>re</td><td></td><td></td><td></td><td></td></tr><tr><td>Human-likeness (H7+)</td><td>0.234</td><td>0.000**</td><td>0.130</td><td>0.339</td><td>Supported</td></tr><tr><td>Self-efficacy (H11+)</td><td>0.517</td><td>0.000**</td><td>0.415</td><td>0.611</td><td>Supported</td></tr><tr><td>Technology anxiety (H12-)</td><td>-0.103</td><td>0.045*</td><td>-0.203</td><td>-0.020</td><td>Supported</td></tr></table></body></html>

Notes: $^ { * } \mathrm { \rho } ^ { < } 0 . 0 5$ $^ { * * } \mathrm { \rho } ^ { < } 0 . 0 0 1$

# 4.2. Study 2: Semi-structured interviews

# 4.2.1. Sample description

At the end of the survey (Study 1), participants who expressed interest in the subsequent interview provided their personal email addresses. Out of 344 EFL learners surveyed, 34 $( 1 0 \% )$ indicated their willingness to participate in a follow-up interview. To ensure the findings were representative of the population, purposive sampling was employed (Patton, 2008). The selection criteria were: (1) active use of ChatGPT for learning English or performing tasks in English, (2) at least three months of experience using ChatGPT, and (3) diversity in age, English proficiency, gender, education level, and occupation. Based on these criteria, 22 out of the 34 interested participants were selected for the interviews. An invitation email was sent to the selected participants, which provided detailed information about the research objectives, the timing and format of the interviews, their right to refuse participation or decline to answer any questions, and the confidentiality of their information. Of those invited, 19 participants agreed to take part in the interviews. To ensure the confidentiality of participants, their names were anonymized using codes such as L1 / I1 / H1 (representing low, intermediate, and high levels of English proficiency, respectively, along with a number). Further demographic details of the interviewees are summarized in Table 3.

# 4.2.2. Data collection procedures

The semi-structured, one-to-one interviews were conducted online via Google Meet from May to September 2023, adhering to the interview protocol outlined in Table 4. The interviews explored two main areas: (1) technological, social, and individual factors in the proposed research model to validate quantitative findings, and (2) how ChatGPT can assist EFL learners to learn English. The interview guide was initially piloted with two researchers specializing in this field to ensure that the questions were aligned with the research objectives. Subsequently, the questions were tested with two EFL learners to confirm their clarity and comprehensibility. Following the pilot study, 19 semi-structured interviews were conducted. Throughout the interviews, Vietnamese, the participants' native language, was used to avoid misinterpretations or confusion. Researchers had the flexibility to ask follow-up questions to deepen the responses. Participants were also encouraged to share their views on any relevant topics not directly covered by the interview questions. To enhance the validity and reliability of the data, two researchers participated in the interview sessions, thus reducing potential individual biases (Mackey & Gass, 2021). The interviews lasted between 30 to 40 minutes on average and were recorded for verbatim transcription.

Table 3. Interviewee profile   
Table 4. Interview protocol   

<html><body><table><tr><td>Participant</td><td>English level</td><td>Gender</td><td>Age</td><td>Education</td><td>Occupation</td></tr><tr><td>H1</td><td>High</td><td>Female</td><td>29</td><td>Master</td><td>Both</td></tr><tr><td>H2</td><td>High</td><td>Female</td><td>28</td><td> Bachelor</td><td>Working</td></tr><tr><td>H3</td><td>High</td><td>Female</td><td>37</td><td>Doctorate</td><td>Working</td></tr><tr><td>H4</td><td>High</td><td>Female</td><td>27</td><td>Master</td><td>Both</td></tr><tr><td>H5</td><td>High</td><td>Male</td><td>30</td><td>Master</td><td>Both</td></tr><tr><td>H6</td><td>High</td><td>Male</td><td>24</td><td>Master</td><td>Studying</td></tr><tr><td>H7</td><td>High</td><td>Female</td><td>23</td><td> Master</td><td>Studying</td></tr><tr><td>11</td><td>Intermediate</td><td> Male</td><td>38</td><td>Doctorate</td><td>Working</td></tr><tr><td>12</td><td>Intermediate</td><td>Male</td><td>33</td><td>Doctorate</td><td>Working</td></tr><tr><td>13</td><td>Intermediate</td><td>Female</td><td>50</td><td>Doctorate</td><td>Both</td></tr><tr><td>14</td><td>Intermediate</td><td>Male</td><td>24</td><td>Master</td><td>Studying</td></tr><tr><td>15</td><td>Intermediate</td><td>Female</td><td>20</td><td>Bachelor</td><td>Studying</td></tr><tr><td>16</td><td>Intermediate</td><td>Female</td><td>21</td><td>Bachelor</td><td>Studying</td></tr><tr><td>17</td><td>Intermediate</td><td>Female</td><td>20</td><td> Bachelor</td><td>Studying</td></tr><tr><td>L1</td><td>Low</td><td> Male</td><td>22</td><td>Bachelor</td><td>Studying</td></tr><tr><td>L2</td><td>Low</td><td>Female</td><td>17</td><td>High school</td><td>Studying</td></tr><tr><td>L3</td><td>Low</td><td>Female</td><td>21</td><td>Bachelor</td><td>Studying</td></tr><tr><td>L4</td><td>Low</td><td>Female</td><td>21</td><td>Bachelor</td><td>Both</td></tr><tr><td>L5</td><td>Low</td><td> Male</td><td>45</td><td> Bachelor</td><td>Working</td></tr></table></body></html>

# Interview questions

1. What functions do you use in ChatGPT for learning English or completing tasks in English?   
2. Are you satisfied with ChatGPT's responses?   
3. Have you learnt anything about English from ChatGPT's answers?   
4. How do you feel when using ChatGPT for learning or doing tasks?   
5. Have you encountered any difficulties during your usage?   
6. Do you have concerns about privacy when using ChatGPT?   
7. What sources influenced your decision to use ChatGPT?   
8. Do you want to continue using ChatGPT for learning English?

# 4.2.3. Analysis and findings

Thematic analysis was conducted to identify patterns and themes within the dataset, with two independent coders collaborating to ensure accuracy. After transcription, the qualitative data were imported into Nvivo20 for further analysis, following Braun and Clarke's (2021) framework. First, all interview transcripts were thoroughly reviewed to gain a deep understanding of EFL learners' experiences with ChatGPT. During the coding process, significant statements and information relevant to the research questions were highlighted and extracted. These codes were then grouped into initial themes by comparing and examining similar ideas. The next step involved revisiting the dataset to refine and develop these themes, ensuring they accurately addressed the research questions. Finally, clear names and descriptions were assigned to each theme and sub-theme to concisely capture their essence.

To strengthen the rigor of this study, we carefully addressed the credibility, transferability, and dependability of our findings. First, to ensure credibility, which is the accuracy and trustworthiness of the results, member checking was conducted. Five participants were asked to review the identified themes to confirm they accurately reflected their intended meanings. Second, to enhance transferability, or the applicability of the findings to similar contexts, we used crosscase sampling by including EFL learners of varying ages, proficiency levels, and educational backgrounds. Finally, dependability was enhanced through inter-coder agreement. Cohen's Kappa coefficient was used for intercoder reliability assessment (McHugh, 2012). The results achieved an $8 8 \%$ agreement, indicating strong consistency between the two coders.

# 4.2.3.1 Explaining the contribution of factors in the proposed research model

In this part, significant hypotheses (i.e., H6, H7, H9, H10, H11, H12, and H13) were further explained through the results obtained from semi-structured interviews. Based on the qualitative results presented in Table 5, typical codes and selected quotes can elucidate why (1) interactivity, enjoyment, trust, subjective norms have significant effects on perceived usefulness, and (2) human-likeness, self-efficacy, technology anxiety can predict perceived ease of use. The combination of quantitative and qualitative results from two separated samples of EFL learners ensures data triangulation and cross-validation (Venkatesh et al., 2016). The similarity in the findings also establishes a solid foundation for conclusions related to the adoption of ChatGPT for English language learning (Srivastava & Chandra, 2018).

# 4.2.3.2. Explaining the non-contribution of factors in the proposed research model

Perceived intelligence. The quantitative findings do not support the association between perceived intelligence and perceived usefulness. Many participants have noted that ChatGPT shows high linguistic intelligence and maintains high precision in language-related tasks. However, learners across different proficiency levels often perceive some suggested vocabulary as too challenging and unhelpful. They intend not to memorize or use these words and instead prioritize common language elements. Some extracts underscoring this viewpoint are as follows:

Table 5. Corroboration from qualitative results   

<html><body><table><tr><td>Construct</td><td>Codes &quot;multilingual interaction&quot; (L1, L2); &quot;quick,</td><td>Selected quotes</td></tr><tr><td>Interactivitye</td><td>clear, and seamless&quot; (H1, H3); &quot;good two- way interaction&quot; (H1, H2); &quot;hedging, sit on the fence&quot; (I1, H7); &quot;sometimes admit not knowing the answer&quot; (I4, H3); &quot;suggest other sources&quot; (I2, H2); &quot;interrupted in case of too much input&quot; (H4, H7); &quot;decline questions about emotion&quot; (I5, H4); &quot;unable to access academic sources&quot; (16, H5).</td><td>&quot;When I ask ChatGPT about a new word, it gives me definitions and examples in English. Since my English level is low, I ask it to translate into Vietnamese - my first language. That way, I can understand and apply the new word. For other tasks, I also use both English and Vietnamese, and ChatGPT responds quickly and clearly.&quot; (L2) &quot;One time, my foreign friend said something I didn&#x27;t quite understand. I checked that sentence on ChatGPT, and it gave me different meanings. All of them made sense, and ChatGPT concluded that the meaning of the sentence depends on the context the speaker uses. What I like the most is that ChatGPT always maintains a sit on the fence&#x27;</td></tr><tr><td>Human- likeness</td><td>&quot;assistant&quot; (L1); &quot;study buddy&quot; (L2, L3); &quot;friend&quot; (H1, H2); &quot;foreign friend&quot; (L3); &quot;teacher&quot; (L3, L5, H1); &quot;advisor&quot; (L5); &quot;private tutor&quot; (I4); &quot;book author, critic&quot; (H7); &quot;reviewer&#x27; (H6); &quot;content creator&quot; (17); &quot;use the pronoun I&#x27; &quot; (12); &quot;say sorry&quot; (L4, I4, H2, H4); &quot;sure I&#x27;m here to help you&quot;</td><td>attitude in its responses.&quot; (H7) &quot;The way it interacts makes me feel like I&#x27;m chatting with someone, not a machine. For instance, when I say hello, it greets me back; it always responds politely to my requests. If I&#x27;m not happy with its answer, it apologizes and suggests more suitable responses.&quot; (14) &quot;I feel like I&#x27;m learning for free with an English teacher. Sometimes, ChatGPT is also</td></tr><tr><td>Enjoyment</td><td>(H4); &quot;understand and soothe my emotions&quot; (I5, I6); &quot;try to satisfy me&quot; (I1). &quot;excited when getting corrections&quot; (L5); &quot;inspiring to learn English&quot; (L4); &quot;happy to learn new things&quot; (1I6, H1); learning with ChatGPT is fun&quot; (L4, I6, H1, H7); &quot;uncomfortable, prefer real-life experiences&quot;</td><td>like a study buddy sitting next to me, giving instant support when I am in need. The way it communicates is very natural and friendly, just like I&#x27;m talking to a real foreign friend.&quot; (L3) &#x27;I feel happy and excited when acquiring new knowledge from ChatGPT, although I realize that I remember things better with images and videos rather than text. However, ChatGPT has inspired me to learn English and made me realize that there are many ways to learn a language.&quot; (I6)</td></tr><tr><td>Trust</td><td>(L3, L5, I4, H5); &quot;boring, prefer classes with teachers and friends&quot; (L2, H4); &quot;unappealing without images or videos&quot; (L2, I5). &quot;unworried, just ask general questions, not personal ones&quot; (L2, L4, I3, H4); &quot;accept</td><td>&quot;I like going to English classes more than learning with ChatGPT. Classes allow me to interact with people in English, and they keep me motivated because I am not self- disciplined and easily get bored. I also prefer learning from real experiences because it helps me remember things better. But I still love using ChatGPT to learn more after class.&quot; (H4) &quot;When using any apps, personal information can be disclosed. As an ordinary person, my privacy may not be as important as that of famous people. I&#x27;m willing to exchange</td></tr></table></body></html>

<html><body><table><tr><td></td><td>(L5, I4, H3, H7); &quot;trust the AI company&quot; (I1, H5); &quot;so far no information disclosure&quot; (I2).</td><td>&quot;Using ChatGPT, I feel secure as OpenAI is a reputable company with strict privacy. policies. However, I avoid asking personal questions or sharing personal information like my name and birthdate on this platform.&quot; (I1).</td></tr><tr><td rowspan="2">Self-efficacy</td><td rowspan="2">&quot;ask specifically&quot; (L3, L4, I6, H4, H5); &quot;change the way I ask questions&quot; (L4, L5, H2); &quot;keep asking until I understand&quot; (15, H1); &quot;use prompts effectively&quot; (I3, I4, H7); &quot;not rely on a single tool&quot; (H2, I1, 13); &quot;understand what we need before asking&quot; (I5, H7).</td><td>&quot;When I ask ChatGPT to write something, I give it my ideas, specific keywords, word count, and the style I want. This helps ChatGPT create content that suits my needs. If I&#x27;m not satisfied with any part, I tell ChatGPT what I don&#x27;t like, and it makes changes. (H5)</td></tr><tr><td>&quot;I know how to use ChatGPT to learn English better. For example, I can ask it to give me exercises to improve specific grammar points. This saves me time compared to searching on Google or reading books. Also, I can set goals like improving my IELTS score from 5 to 6.5. ChatGPT will suggest a customized study plan to help me get closer to that goal.&quot; (I4)</td></tr><tr><td>Technology anxiety</td><td>&quot;feel comfortable&quot; (L2, L4, L5, I3); &quot;not afraid&quot; (I1, I6, H3); &quot;familiar chat interface, like other tools&quot; (I1, I4, H2); &quot;low-tech but still confident to use&quot; (H1, H4); &quot;adapt to it quickly&quot; (I2, H4).</td><td>&quot;I&#x27;m used to chat interfaces, so I&#x27;m not afraid of using ChatGPT. I think the ChatGPT designers considered that people worldwide are familiar with chatting. For instance, WeChat in China, Line in Japan, Zalo in Vietnam, and older platforms like Yahoo and chat rooms. So, people, including me, feel comfortable using ChatGPT for various tasks.&quot; (11) &quot;I&#x27;m not tech-savvy, but I stillfeel confident to use ChatGPT. Just ask a question, and it.</td></tr><tr><td rowspan="2">Subjective norms</td><td>&quot;Facebook&quot; (I4, H1, H2, H4, H7); &quot;Instagram, Tiktok&quot; (H7); Youtube (L2); &quot;domestic news, official channels&quot; (I1, I5, ur</td><td>will reply. If I can&#x27;t figure something out on my own, I&#x27;m not afraid to ask for help.&quot; (H1) &quot;I am a PhD student, and I got to know about ChatGPT through people of various ages. My supervisor, about fifty, advised me to use this tool wisely for my research work.</td></tr><tr><td>H2); &quot;friends&quot; (I1, 15, H4, H5); &quot;teachers&quot; (L2, L3, L4, I3, I6).</td><td>Other PhD students, between 30 and 40, also shared with me how to use it and write prompts. Even my thirteen-year-old son suggested that I use it to find ideas when. writing.&quot; (13) &quot;I mainly knew ChatGPT through social media, where people discuss how it can.</td></tr></table></body></html>

"ChatGPT often suggests fancy or uncommon words for my assignments. I avoid using the complex phrase 'of utmost significance' suggested by ChatGPT. I choose 'use' or 'employ' instead of 'utilize'. When I share these words with my teacher, he also agrees with my choices. I replace big words with simpler ones to improve my writing." (H1, H4, H7)

"Because ChatGPT doesn't know my English level, it often gives me advanced vocabulary and complex sentences to produce optimal results. However, it's hard to learn and remember these words, so I usually don't use them."(L3, 16)

Personalization. The results from quantitative study show a non-significant path between   
perceived personalization and perceived usefulness. From interview data, elementary and (pre)-   
intermediate learners often encounter gaps in specific grammar points. With the support of   
ChatGPT in correcting and analyzing errors, they can comprehend and acquire new knowledge. In   
contrast, for upper-intermediate and advanced learners, despite receiving satisfactory results, they   
do not gain any extra knowledge from minor mistakes, as explained in the following examples: "I am confident in my grammar. The grammar suggestions that ChatGPT provides are usually things I already know, so there's nothing more for me to learn." (H1, H2, H5) "ChatGPT identifies my mistakes, which I can understand without an explanation. Common mistakes include verb tense issues, third-person singular verb forms, and 'to be' verbs." (I3, 17) Learning-goal orientation. Qualitative data can justify the lack of a significant direct   
relationship between learning-goal orientation and perceived usefulness. Learners desire to explore   
new knowledge, but ChatGPT may not meet their expectations. This could be attributed to

learners' longing for a more interactive learning experience, involving engagement with teachers and peers. Additionally, ChatGPT may be most effective for learners with a read/write learning style, while it may not be appropriate for other learning styles such as visual, auditory, and kinesthetic. The following quotes elaborate on this perspective:

"I prefer learning through experiences because real-life situations leave a deeper impression on me. Learning with ChatGPT is convenient, but the information flows too fast and I often forget it easily and quickly." (L3, H5)   
"I enjoy watching videos on YouTube to improve my English. I only use ChatGPT when needed. When I watch videos and listen at the same time, I can understand the content easier. Although I may not catch every word, I can guess the meaning based on non-verbal communication and the context." (I5, L4)   
"I like attending classes because of the friendly atmosphere, guidance from teachers, and the opportunity to interact with others. Learning through ChatGPT for a long period can make me feel bored and tired because it lacks real human interaction." (L2, H4)

# 4.2.3.3. EFL learners' use of ChatGPT

To investigate how ChatGPT supports the English learning process, this study identified three main themes, eight categories, and sixteen sub-categories as illustrated in Table 6, Table 7, and Table 8. The three main themes include: (1) how users access language through interaction with ChatGPT, (2) aspects of language that users can experience and learn, (3) language learning engagement when using ChatGPT.

The language learning approach can be classified into two categories. First, the \*language learning approach as a secondary purpose" refers to using language to achieve other goals, such as handling work-related tasks or study-related tasks. In this context, users employ ChatGPT in English to complete tasks for work (e.g., reports, emails) or for study (e.g., essays, presentations). Furthermore, ChatGPT can engage in English conversations with users to satisfy their everyday communication needs. Second, the "language learning approach as a primary purpose" involves allocating focused time and effort to language learning and skill development. In this case, language learning becomes the primary and central focus of the learning process, which requires regular practice to attain a higher language proficiency level. Interview data has demonstrated that ChatGPT can support English learning for everyday use (General English), academic contexts (English for Academic Purposes), and a particular field or profession (English for Specific Purposes).

ChatGPT, a non-goal-oriented chatbot in education, still provides learners significant support in various aspects of language learning. In terms of writing, ChatGPT serves as a companion to learners, assisting them from the planning stage, writing, to editing. In particular, ChatGPT provides suggestions for main ideas, outlines, forming and connecting sentences, ensuring the final text's accuracy and quality. Moreover, ChatGPT supports reading comprehension to meet various user needs, such as reading for the main idea (skimming), reading for specific information (scanning), or reading for details (close reading). Regarding grammar, ChatGPT goes beyond error checking and explanations (accuracy) to foster grammatical usage to express ideas (range). Additionally, ChatGPT plays a pivotal role in enhancing learners' vocabulary, both in acquiring new words (learning) and retaining them (recalling). Some learners regard ChatGPT as a platform to explore new vocabulary in various contexts, boost memory retention, and transform passive vocabulary into active use.

The qualitative results also reveal that EFL learners engage in the English learning process with ChatGPT either actively or passively. Active language learning is the intentional engagement with the language in a meaningful way (Bonnell & Eison, 1991), regardless of whether they are approaching language learning as a primary or secondary purpose. For example, even when using ChatGPT to complete work tasks, learners can engage in active learning by analyzing the language in ChatGPT's responses and memorizing key language points for future use. Passive language learning is the process of absorbing language naturally, without conscious effort (Chi, 2009). In these cases, learners may not be paying attention to the language, but their brains are still subconsciously obtaining linguistic information and gradually building up vocabulary and grammar structures. Both active and passive learning can be necessary for effective English learning (Minhas et al., 2012). However, active learning is more efficient, while passive learning may take a significant amount of time, even years, to show learners' improvement.

Table 6. Language learning approaches   

<html><body><table><tr><td rowspan="3">Category Secondary purpose</td><td rowspan="2">Sub-category Work-related tasks</td><td>Codes</td></tr><tr><td>&quot;suggest email structure and content for clients and partners&quot; (H3, I2, L5); &quot;grasp a basic understanding of a specific work-related field&quot; (I5, L5, H7).</td></tr><tr><td>Study-related tasks</td><td>&quot;support the process of writing essays for different educational levels, such as undergraduate (L3, L4, 17), master&#x27;s (H1, H4, H6, I4), and doctoral (I3)&quot;; &quot;summarise information to facilitate the reading of English specialized documents&quot; (H1, H5, I3, I7).</td></tr><tr><td rowspan="4">Primary purposeGeneral English</td><td>Daily conversation</td><td>&quot;when I need someone to talk to, whether in good or bad times&quot; (H7, I5); &quot;understand why I&#x27;m feeling sad for many reasons and offering sound advice&quot; (I5).</td></tr><tr><td></td><td>&quot;search for vocabulary, collocations, idioms, synonyms in different contexts&quot; (H1, H7); &quot; helpful tol for English studies in high school, university, or language courses&quot; (L2, L3, L4).</td></tr><tr><td>English for Academic Purposes</td><td>&quot;score IELTS essays based on predefined criteria and provide model essays for reference&quot; (H5, H7, I6, 17, L5); &quot;expand academic vocabulary to enhance writing in a formal style&quot; (H1, H7, I3, I4).</td></tr><tr><td>English for Specific Purposes</td><td>&quot;learn some marketing terms for better English document comprehension&quot; (I6, L4); &quot;it explains financial terms with examples, which I can&#x27;t find on Google&quot; (H6)</td></tr></table></body></html>

Table 7. Language dimensions   

<html><body><table><tr><td>Category</td><td>Sub-category</td><td>Codes</td></tr><tr><td rowspan="3">Writing</td><td>Planning</td><td>&quot;find ideas for writing&quot; (H4, H7, I5); &quot;ask for an outline and then develop it further on my own&quot; (I5, L5).</td></tr><tr><td>Writing</td><td>&quot;refining sentences in various ways . shortening or extending them&quot; (H4, H5, L4, I1, I4); &quot;*paraphrasing&quot; (H4, H5, H6, H7, I5, L4, I7, I6); linking sentences within the paragraph&quot; (H3, H4, H5).</td></tr><tr><td>Editing</td><td>&quot;check for grammar, spelling, and punctuation&quot; (I1, I2, I3, L1, I7, H4, H6); &quot;check for writing style&quot; (13, I4).</td></tr><tr><td rowspan="3"> Reading</td><td> Skimming</td><td>&quot;ask it to provide a brief summary or underline key points when reading lengthy English documents&quot; (H1, H2, I5, 17, L5).</td></tr><tr><td>Scanning</td><td>&quot;search for information that suits my needs&quot; (L3, L4, I2, H4, H5, H6); &quot;time-saving instead of reading too much on Google&quot; (H2, H3, H4, I3, I4).</td></tr><tr><td>Close reading</td><td>&quot;translate the text into Vietnamese to better understand the whole content&quot; (15, I6, L2, L4); &quot;ask it to rewrite simply, then read the original with the information I&#x27;ve understood, making reading faster and more effective&quot; (H5, H6, H7, 17).</td></tr><tr><td rowspan="2">Grammar</td><td>Accuracy</td><td>&quot;check for grammatical errors after writing&quot; (11, 12, 13, L1, 17, H4, H6); &quot;satisified because errors are analyzed thoroughly, and the accuracy reaches up to 90%&quot; (I2, H6, L3, L5).</td></tr><tr><td>Range</td><td>&quot;use complex sentences as found in academic materials&quot; (H7); &quot;employs many adverbial and adjective clauses&quot; (L5); &quot;learn how to upgrade my sentences since it offers better structures than my current level&quot; (I6, 17).</td></tr><tr><td rowspan="2">Vocabulary</td><td> Learning</td><td>&quot;learn new words in various topics . suggest exercises to practice these words&quot; (L2, L3, I5, I6); learn synonyms, collocations, idioms&quot; (H1, H7).</td></tr><tr><td>Recalling</td><td>&quot;some words I know the meaning but not use them much until ChatGPT suggested .. then I started using them&quot; (I4, 11, L5); I remember certain words since ChatGPT always recommends them&quot; (H4, I5).</td></tr></table></body></html>

716

Table 8. Language learning engagement   

<html><body><table><tr><td>Category</td><td>Codes</td></tr><tr><td>Active</td><td>&quot;take note of errors and new words for periodic review&quot; (H1, L3, L4); &quot;double-check with other sources like Google, dictionaries, or teachers&quot; (11, 12, 13, H4, H6, L2, L5); &quot;compare my writing with its output to see the ifference .. focus on good structures and words ... then reread for memorization and future use&quot; (I1, I4, I6, H3).</td></tr><tr><td>Passive</td><td>&quot;when it corrects me, I may not apply it at first, but over time it becomes ingrained in my memory naturally and without conscious effort&quot; (L5, I6, H2); even without deliberate study, frequent use of a structure leads to natural retention in my mind&quot; (13, H4); &quot;several repetitive words leave a strong impression on me such as &#x27;encompass, delve into, etc.&quot; (14, H4, H7, H6).</td></tr></table></body></html>

# 5. Discussions

In addressing the RQ1 (What are the determinants of EFL learners' adoption of ChatGPT as a chatbot-assisted language learning?), results from a survey of 334 EFL learners revealed that perceived usefulness and perceived ease of use are the key influencing factors for EFL learners' continued use of ChatGPT for self-learning English. This finding aligns with the robustness and consistency of the core TAM in predicting individuals' behavior towards advanced technologies (Belda-Medina & Calvo-Ferrer, 2022; Chang et al., 2024; Liu & Ma, 2024; Pillai et al., 2024). Additionally, the original TAM was extended to incorporate technological, individual, and social factors identified in the literature as relevant to EFL learners' adoption of supporting technologies. The results demonstrated that, among significant drivers (i.e., interactivity, trust, perceived ease of use, and subjective norms), enjoyment had the largest direct influence on perceived usefulness $\scriptstyle ( \beta = 0 . 2 3 )$ and indirect on continuance intention $\mathrm { \beta } \mathrm { = } 0 . 1 4 \mathrm { ) }$ . This finding confirmed our hypothesis (H9) that learning English with ChatGPT is a pleasant experience for EFL learners. The findings also underscored the crucial role of enjoyment as the motivator for EFL learners' efforts to creatively utilize available tools for self-learning English. Moreover, the results from the quantitative study show that self-efficacy had the largest direct association with perceived ease of use ( $( \beta { = } 0 . 5 2 )$ and indirect association with continuance intention $( \beta { = } 0 . 0 7 )$ among other significant factors (i.e., technology anxiety and human-likeness). Self-efficacy has been highlighted as a determinant of individuals' attitudes and behaviors towards new technology (Li, 2021; Li et al., 2019; Zhai & Ma, 2022). The role of self-efficacy, therefore, becomes more substantial in the context of utilizing non-goal-oriented chatbots for self-learning English.

Moreover, the quantitative results revealed that perceived intelligence, personalization of ChatGPT for English learning, and individuals' learning-goal orientation had non-significant influences on perceived usefulness. Control variables such as age, education level, and English proficiency were also found to be non-significantly related to continuance intention, which is consistent with Lee et al. (2017) indicating that personal factors do not explain the use of technology for self-directing learning. To enhance the quantitative results, we integrated qualitative findings through meta-inferences (Cheng et al., 2023). Regarding perceived intelligence, participants praised ChatGPT's linguistic capabilities, but lower proficiency learners found suggested vocabulary challenging, prioritizing common language over "fancy" words. Despite the non-significant impact of personalization in the quantitative study, interviews revealed that elementary and (pre)-intermediate learners benefited from ChatGPT's support in addressing specific grammar gaps. Conversely, upper-intermediate and advanced learners, while satisfied with results, derived no additional knowledge from minor mistakes. Qualitative data elucidates the absence of a significant direct relationship between learning-goal orientation and perceived usefulness. This is possibly because ChatGPT fails to offer interactive learning experiences, such as engaging with teachers and peers. Additionally, ChatGPT seems most effective for read/write learning styles but may not suit visual, auditory, or kinesthetic learners. Taken together, findings from the quantitative and qualitative studies corroborate that EFL learners' proficiency levels play a critical moderating role in the adoption of ChatGPT as a supporting technology for self-learning English (Mohsen, 2022).

The findings for RQ2 (How do EFL learners use ChatGPT to assist in their English learning process?) further highlighted differences in using ChatGPT for learning English among EFL learners with various proficiency levels. Qualitative data collected from 19 in-depth interviews revealed three main findings about: (1) language learning approaches, (2) language dimensions, and (3) language learning engagement. First, EFL learners approach language learning either as their primary or secondary purpose (see Table 6). This is consistent with recent studies that have recognized the role of ChatGPT in supporting work- or study-related tasks for individuals in diverse occupations, such as university students completing assignments (Wollowski, 2023), scientists and researchers speeding up the writing process (Huang & Tan, 2023). However, these studies only focus on how ChatGPT helps with completing necessary tasks and do not address what users learn about the language while using ChatGPT for their work. This is where the qualitative results of this study extend beyond previous research, suggesting that we can learn English anytime, as long as we have ChatGPT to assist with study or work tasks, or even when conversing with it in English. In the EFL setting, prior studies such as Bin-Hady et al. (2023) and Kohnke et al. (2023) have proposed functionalities to recommend ChatGPT for meeting English learning needs as a primary objective. A study by Liu et al. (2024) shared similar findings with our study, showing participants' productive usage of AI in their informal English learning such as reading English novels and practicing TOEFL English with ChatGPT as a conversational partner. This dual-purpose functionality makes ChatGPT a valuable tool not only for intensive language study but also for those seeking to integrate language learning into daily contexts. Second, this study demonstrated that ChatGPT is beneficial across various dimensions of language (see Table 7), supported by prior research that indicates ChatGPT's assistance in reading tasks (Huang & Tan, 2023), writing feedback (Barrot, 2023; Yang & Li, 2024; Yan, 2023), vocabulary development (Bin-Hady et al., 2023; Karatas et al. 2024; Kohnke et al., 2023), and grammar (Su et al., 2023). Further supporting this, Song and Song (2023) discovered that using ChatGPT for AI-assisted instruction can enhance EFL students' writing skills, organization, coherence, grammar, and vocabulary compared to traditional instruction. In addition, Karatas et al. (2024) found that this chatbot does not significantly impact listening and speaking skills, which resonates with our findings on ChatGPT's role in supporting these two skills. The main reason is that ChatGPT operates as a text-based chatbot, primarily enhancing written interactions. However, it lacks the capability to provide voice feedback or simulate real-life conversational dynamics, which hinders learners in practicing their listening and speaking skills.

Third, this study revealed that EFL learners engage in the English learning process with ChatGPT either actively or passively (see Table 8). Many studies have shown that ChatGPT can boost motivation and engagement in language learning due to its rich content and diverse activities, making the learning process more enjoyable (Bin-Hady et al., 2023; Karatas et al., 2024; Mohamed, 2024). However, previous research has not clarified the levels of engagement of learners when interacting with ChatGPT. The qualitative results of this study have filled this gap by categorizing two types of engagement: active and passive. This classification provides a deeper understanding of how learners interact with ChatGPT and helps to better comprehend the impact of different engagement levels on learning outcomes. These two types of engagement align with the ICAP model (Interactive, Constructive, Active, Passive) proposed by Chi and Wylie (2014), where the active mode of engagement leads to higher learning outcomes compared to the passive mode (Chi, 2009). The efectiveness of active learning was also highlighted in a study by Zhuang and Xiao (2018), indicating that active learners are more likely to engage deeply in the thinking and learning process, facilitating a stronger grasp of the learning content. Similarly, Le and Nguyen (2023) found that active learning in the EFL context empowers students to hone language skills, boost memory retention, and foster critical thinking skills. Learners engaging in higher-order thinking to tackle problems tend to attain higher grades than their peers who passively absorb knowledge without truly comprehending, evaluating, and synthesizing information (Dole et al., 2007). Furthermore, several studies (e.g., Huggins & Stamatel, 2015; Oliver, 2018) discouraged the practice of passive learning, highlighting its adverse impact on the development of essential skills required for understanding concepts, and its potential to yield unfavorable results for learners. Nonetheless, in this study, passive learning was found to show learners' improvement, although it did require a substantial time investment. Taking both active and passive learning into consideration, Minhas et al. (2012) noted that both types offer performance benefits when they align with learners' preferences.

# 6. Conclusion and implications

# 6.1. Theoretical implications

Non-goal-oriented chatbots (e.g., Google Assistant, Alexa, Cleverbot) have garnered increasing attention as potent tools for language learning (Dizon, 2020; Fryer et al., 2020; Gonulal, 2021). The rapid proliferation of these chatbots is expected to accelerate, particularly with the advent of LLM-powered chatbots like ChatGPT (Jeon et al., 2023). Despite this burgeoning interest, there remains a significant knowledge gap regarding the motivations behind individuals' adoption of non-goal-oriented chatbots for language learning and the mechanisms through which these interactions enhance language skills. Furthermore, extant research on factors influencing the adoption of AI-enabled technology for English learning remains fragmented, with various studies examining disparate sets of factors (e.g., Chen et al., 2020; Liu & Ma, 2024; Ni & Cheung, 2023). To address these gaps, this research aims to conduct a comprehensive investigation into the factors driving ChatGPT adoption among EFL learners and to elucidate their process of selfdirected English learning with ChatGPT. We employed a multi-methods approach, encompassing a systematic literature review to synthesize influential factors of AI-powered technology adoption in learning and education contexts (Web Appendix: Table A1), followed by a survey study and semi-structured interviews.

This research contributes to theory in three significant ways. First, we extend the TAM to investigate ChatGPT adoption by EFL learners, motivated by its prominence in understanding adopters' behaviors towards advanced technology (Pillai et al., 2024). Our research enriches existing literature (Liu & Ma, 2024; Tai & Chen, 2020) by highlighting that, among other significant factors (i.e., interactivity, human-likeness, trust, technology anxiety, and subjective norms), enjoyment and self-efficacy emerge as key drivers of perceived usefulness and continued usage. Notably, we found that the impact of personalization is contingent upon EFL learners' English proficiency levels, while the effect of learning-goal orientation on ChatGPT use varies across individual learning styles. Based on our systematic review of 40 empirical studies and our findings in this research, we present a comprehensive TAM-based framework of EFL learner adoption of non-goal-oriented chatbots (Figure 3). This framework is generalized across learners' age, gender, education, and English proficiency levels.

Second, expanding on Jeon et al.'s (2023) call for research into the pedagogical potential of non-goal-oriented chatbots, our study positions ChatGPT as a powerful tool for English selflearning. Through active and passive engagement, EFL learners can enhance their writing, reading, grammar, and vocabulary, whether English learning is their primary or secondary goal. This research contributes to the existing literature by introducing a conceptual model of ChatGPTassisted English learning (Figure 4), which captures the diverse ways learners interact with the chatbot. The model not only deepens the understanding of how ChatGPT facilitates language learning but also broadens the conversation around the application of chatbots in educational contexts.

![](img/ad11bb9c1ed627777377e60e77512d1caf48c64640a5d0e99d77d52d64bc6423.jpg)  
Figure 3. The TAM-based framework of EFL learner adoption of non-goal-oriented chatbots

Third, by employing a multi-methods approach (Venkatesh et al., 2016), we derive comprehensive and insightful conclusions (Cheng et al., 2023). The qualitative analysis of interview data complements and extends our quantitative findings, ensuring a nuanced and holistic response to our research questions. This methodological triangulation enhances the richness and robustness of our results, contributing to a more profound understanding of EFL learners' adoption and utilization of ChatGPT for self-directed English learning.

![](img/490982e5c154addab728401fee69b33781d25a97abe6c41a6bb887dc12a20ec2.jpg)  
Figure 4. Summary of qualitative results of ChatGPT-assisted English learning

# 6.2. Practical implications

The findings from this study offer valuable insights into (1) various factors that influence EFL learners' adoption of ChatGPT as a language learning tool and (2) how ChatGPT can assist the

English learning process. These insights can guide AI developers and educators in optimizing ChatGPT and similar AI-driven tools to enhance their effectiveness in language education.

To enhance technological factors, developers should prioritize increasing ChatGPT's interactivity by integrating real-time feedback and refining its human-like interaction. Improvements in tone, contextual understanding, and conversational flow can significantly enrich the user experience. Implementing adaptive difficulty setings will also allow ChatGPT to tailor vocabulary and language complexity to the learner's proficiency, ensuring that the content remains accurate yet challenging enough to promote learning. Regarding individual factors, developers are encouraged to create user-friendly interfaces and supportive resources that boost self-efficacy while alleviating technology anxiety. Educators play a crucial role in this process by introducing the tool in a way that addresses learner concerns. To further boost enjoyment, incorporating gamified elements like quizzes and rewards will make the learning experience more motivating. Additionally, establishing robust data privacy measures will foster trust and confidence among users, which is essential for widespread adoption. Besides that, social factors significantly affect learners' perceptions of ChatGPT. When educators actively endorse and integrate this tool into their teaching, they can positively influence students' views on its usefulness. To further enhance adoption, developers and institutions should engage in outreach efforts, such as webinars, workshops, and social media campaigns featuring educational influencers, to effectively highlight ChatGPT's benefits and encourage its use.

The qualitative study provides actionable guidance for both teachers and learners on effectively using ChatGPT in language learning. Self-learners should view ChatGPT as a versatile resource that supports multiple dimensions of language learning. They can practice writing by composing essays or responses to prompts, with ChatGPT offering feedback and suggestions for improvement. In reading, learners can engage with text by asking ChatGPT to summarize, analyze. or discuss content, thereby deepening their comprehension and critical thinking skills. Furthermore, vocabulary acquisition can be facilitated through interactive exercises where learners ask for definitions, synonyms, and contextual usage of new words. To maximize the benefits of ChatGPT, teachers should design lessons that not only introduce this AI tool but also provide learners with the skills necessary to critically evaluate AI-generated content. For example, teachers might assign tasks where students compare AI-generated essays with their own work or assess the quality of ChatGPT's explanations. Such activities not only enhance language skills but also empower learners to take an active role in their education. Moreover, the study's findings highlight the importance of both passive and active engagement with ChatGPT. Teachers can incorporate this understanding into their lesson plans by encouraging students to engage with the tool in varied ways--both passively, through activities like reading and comprehension exercises, and actively, through discussions and collaborative projects. This multifaceted approach not only fosters a sense of agency and motivation but also enriches the overall language learning experience.

# 6.3. Limitations and future research

This research has some notable limitations. First, EFL learners in both quantitative and qualitative studies allshare Vietnamese as their first language. Cultural factors specific to different countries may influence how EFL learners perceive, adopt, and use ChatGPT. Hence, caution is advised when applying the results to other cultural contexts. Second, although the survey sample included participants from diverse backgrounds in terms of age, gender, education, and occupation (students vs. non-students), the majority belongs to the 18-29 age group and is highly educated (possessing a high school diploma or above). While the results from interviews with a more representative sample confirmed the survey findings, additional applications of the model to test the learning behaviors of younger and older age groups would enhance its generalizability. Third, as this research focused on ChatGPT v3.5, changes in functions introduced in an updated version of ChatGPT or in other non-goal-oriented chatbots, such as Bing AI and Gemini, may impact the results. Fourth, the data relied on participants' self-reported adoption and use of ChatGPT, potentially introducing self-report bias. Lastly, while this study highlights the potential of ChatGPT to enhance language learning through self-directed study, it does not assess its effectiveness in improving English proficiency. To address this gap, future research should prioritize longitudinal experimental designs to systematically evaluate the impact of ChatGPT and other AI tools on specific language skills, including listening, speaking, reading, and writing. Such studies could determine whether AI integration leads to sustainable improvements in these areas. Additionally, since this research primarily focuses on individual self-learning, it would be beneficial for researchers to explore how AI tools can facilitate collaborative learning environments. This investigation could foster peer interaction and significantly enhance the overall learning experience.

# References

Abdullah, F., Ward, R., & Ahmed, E. (2016). Investigating the influence of the most commonly used external variables of TAM on students' Perceived Ease of Use (PEOU) and Perceived Usefulness  (PU) of e-portfolios.Computers in Human Behavior, 63, 75-90. https://doi.org/10.1016/j.chb.2016.05.014   
Ajzen, I. (1991). The theory of planned behavior. Organizational Behavior and Human Decision Processes, 50(2), 179-211. https://doi.org/10.1016/0749-5978(91)90020-T   
Almaiah, M. A., Alfaisal, R., Salloum, S. A., Al-Otaibi, S., Shishakly, R., Lutfi, A., .. & AlMaroof, R. S. (2022). Integrating teachers' TPACK levels and students' learning motivation, technology innovativeness, and optimism in an IoT acceptance model. Electronics, 11(19), 3197. https://doi.org/10.3390/electronics11193197   
Al Shamsi, J. H., Al-Emran, M., & Shaalan, K. (2022). Understanding key drivers affecting students' use of artificial intelligence-based voice assistants. Education and Information Technologies, 27(6), 8071-8091. https://doi.org/10.1007/s10639-022-10947-3   
Al-Rahmi, W. M., Alias, N., Othman, M. S., Alzahrani, A. I., Alfarraj, O., Saged, A. A., & Rahman, N. S. A. (2018). Use of elearning by university students in Malaysian higher educational institutions: A case in universiti teknologi Malaysia. IEEE Access, 6, 14268- 14276. https://doi.org/10.1109/ACCESS.2018.2802325   
Alvi, I. (2021). College students' reception of social networking tools for learning in India: An extended UTAUT model. Smart Learning Environments, 8(1), 1-18. https://doi.org/10.1186/s40561-021-00164-9   
Amiryousefi, M. (2016). The differential effects of two types of task repetition on the complexity, accuracy, and fluency in computer-mediated L2 written production: A focus on computer anxiety. Computer Assisted Language Learning, 29(5), 1052-1068. https://doi.org/10.1080/09588221.2016.1170040   
Bai, B., Wang, J., & Chai, C. S. (2021). Understanding Hong Kong primary school English teachers' continuance intention to teach with ICT. Computer Assisted Language Learning, 34(4), 528-551. https://doi.org/10.1080/09588221.2019.1627459   
Balakrishnan, J., & Dwivedi, Y. K. (2024). Conversational commerce: entering the next stage of AI-powered digital assistants.Annals of OperationsResearch, 333(2), 653-687. https://doi.org/10.1007/s10479-021-04049-5   
Bandura, A. (2010). Self-Efficacy. The Corsini Encyclopedia of Psychology. John Wiley & Sons, Inc., Hoboken, NJ, USA https://doi.org/10.1002/9780470479216.corpsy0836   
Barrot, J. S. (2023). Using automated written corrective feedback in the writing classrooms: Effects on L2 writing accuracy. Computer Assisted Language Learning, 36(4), 584 607. https:/doi.org/10.1080/09588221.2021.1936071   
Bas, M., & Gezegin, B. B. (2015). Language learning as losing weight: Analysing students' metaphorical perceptions of English learning process. Procedia-Social and Behavioral Sciences, 199, 317-324. https://doi.org/10.1016/j.sbspro.2015.07.554   
Belda-Medina, J., & Calvo-Ferrer, J. R. (2022). Using chatbots as AI conversational partners in language learning. Applied Sciences, 12(17), 8427. https:/doi.org/10.3390/app12178427   
Bhutoria, A. (2022). Personalized education and artificial intelligence in the United States, China, and India: A systematic review using a human-in-the-loop model. Computers and Education: Artificial Intelligence, 3, 100068. https:/doi.org/10.1016/j.caeai.2022.100068   
Bin-Hady, W. R. A., Al-Kadi, A., Hazaea, A., & Ali, J. K. M. (2023). Exploring the dimensions of ChatGPT in English language learning: A global perspective. Library Hi Tech. In-press. https:/doi.org/10.1108/LHT-05-2023-0200   
Bonnell, C.C., & Eison, J.A. (1991). Active learning: Creating excitement in the classroom. Washington, DC: George Washington University Press.   
Braun, V., & Clarke, V. (2021). Thematic Analysis: A Practical Guide. London: Sage   
Celik, V., & Yesilyurt, E. (2013). Attitudes to technology, perceived computer self-efficacy and computer anxiety as predictors of computer supported education. Computers & Education, 60(1), 148-158. https://doi.org/10.1016/j.compedu.2012.06.008   
Chae, S. W., Lee, K. C., & Seo, Y. W. (2016). Exploring the effect of avatar trust on learners' perceived participation intentions in an e-learning environment. International Journal of Human-Computer Interaction, 32(5), 373-393. https://doi.org/10.1080/10447318.2016.1150643   
Chan, L., Hogaboam, L., & Cao, R. (2022). Artificial intelligence in education. In Applied Artificial Intelligence in Business: Concepts and Cases (pp. 265-278). Cham: Springer International Publishing. https:/doi.org/10.1007/978-3-031-05740-3

7 Chang, H., Park, J., & Suh, J. (2024). Virtual reality as a pedagogical tool: An experimental study   
8 of English learner in lower elementary grades. Education and Information Technologies,   
9 29(4), 4809- 4842. https://doi.org/10.1007/s10639-023-11988-y   
0 Chang, Y., Lee, S., Wong, S. F., & Jeong, S. P. (2022). AI-powered learning application use and   
1 gratification: an integrative model. Information Technology & People, 35(7), 2115-2139.   
2 https://doi.org/10.1108/ITP-09-2020-0632   
3 Chen, H. L., Vicki Widarso, G., & Sutrisno, H. (2020). A chatbot for learning Chinese: Learning   
4 achievement  and  technology acceptance.Journal .of . Educational  Computing   
5 Research, 58(6), 1161-1189. https://doi.org/10.1177/0735633120929622   
6 Cheng, X., Su, X., Yang, B., Zarifis, A., & Mou, J. (2023). Understanding users' negative emotions   
7 and continuous usage intention in short video platforms. Electronic Commerce Research and   
8 Applications, 58, 101244. https:/doi.org/10.1016/j.elerap.2023.101244   
9 Chi, M. T. H. (2009). Active-constructive-interactive: A conceptual framework for differentiating   
0 learning activities. Topics in Cognitive Science, 1, 73-105. http://doi:10.1111/j.1756-   
1 8765.2008.01005.x   
2 Chi, M. T., & Wylie, R. (2014). The ICAP framework: Linking cognitive engagement to active   
3 learning outcomes. Educational Psychologist, 49, 219-243.   
4 https://doi.org/10.1080/00461520.2014.965823   
5 Chuah, S. H. W., & Yu, J. (2021). The future of service: The power of emotion in human-robot   
6 interaction.Journal of Retailing  andConsumerServices, 61, 102551.   
7 https://doi.org/10.1016/j.jretconser.2021.102551   
8 Cook, C. R., Kilgus, S. P., & Burns, M. K. (2018). Advancing the science and practice of precision   
9 education to enhance student outcomes.Journal of School Psychology,66, 4-10.   
0 https://doi.org/10.1016/j.jsp.2017.11.004   
1 Creswell J. W., (2014). Research Design: Qualitative, Quantitative and Mixed Method   
2 Approaches. 4th edition. Newcastle upon Tyne, UK: Sage.   
3 Creswell, J. W., & Clark, V. L. P. (2011). Designing and conducting mixed methods research.   
4 (2nd ed.). Sage publications.   
5 Davis, F. (1989). Perceived usefulness, perceived ease of use, and user acceptance of information   
6 technology. MIS Quarterly, 13(2), 319-340. https:/doi.org/10.2307/249008   
7 de Cicco, R., Silva, S. C., & Alparone, F. R. (2020). Millennials' attitude toward chatbots: an   
8 experimental study in a social relationship perspective. International Journal of Retail &   
9 Distribution Management, 48(11), 1213-1233. https:/doi.org/10.1108/IJRDM-12-2019-   
0 0406   
1 Dhivya, D. S., Hariharasudan, A., Ragmoun, W., & Alfalih, A. A. (2023). ELSA as an education   
2 4.0 tool for learning Business English communication. Sustainability, 15(4), 3809.   
3 https://doi.org/10.3390/su15043809   
4 Dizon, G. (2017). Using intelligent personal assistants for second language learning: A case study   
5 of alexa. TEsOL Journal, 8(4), 811-830. https:/doi.org/10.1002/tesj.353   
6 Dizon, G. (2020). Evaluating intelligent personal assistants for L2 listening and speaking   
7 development. Language, Learning and Technology, 24(1), 16-26.   
8 https://doi.org/10125/44705   
9 Dole, J. A., Hacker, D. J., & Nokes, J. D. (2007). Teaching high school students to use Heuristic   
0 while reading Historical texts. Journal of Educational Psychology, 99(3), 492-504.   
1 https://doi.org/10.1037/0022-0663.99.3.492

Esmaeili, Z., & Shahrokhi, M. (2020). The Impact of Memrise Application on Iranian EFL Learners' Collocation Learning and Retention. International Journal of Language Education, 4(2), 221-233. https://doi.org/10.26858/ijole.v4i2.10672   
Fishbein, M. (1979). A theory of reasoned action: Some applications and implications. Nebraska Symposium on Motivation, 27, 65-116.   
Fryer, L., Coniam, D., Carpenter, R., & Lapusneanu, D. (2020). Bots for language learning now: Current and future directions. Language, Learning and Technology, 24(2), 8-22. http://hdl.handle.net/10125/44719   
Gonulal, T. (2021). Investigating EFL learners' humorous interactions with an intelligent personal assistant. Interactive Learning Environments, 31(7), 4521-4534. https://doi.org/10.1080/10494820.2021.1974489   
Goudey, A., & Bonnin, G. (2016). Must smart objects look human? Study of the impact of anthropomorphism on the acceptance of companion robots. Recherche et Applications en Marketing, 31(2), 2-20. https://doi.org/10.1177/2051570716643961   
Gray, K., & Wegner, D. M. (2012). Feeling robots and human zombies: Mind perception and the uncanny valley. Cognition, 125(1), 125-130. https://doi.org/10.1016/j.cognition.2012.06.007   
Hair, J. F., Jr., Hult, G. T. M., Ringle, C. M., & Sarstedt, M. (2017a). A primer on partial least squares structural equation modeling (PLS-SEM). Sage publications.   
Hair, J. F., Hult, G. T. M., Ringle, C. M., Sarstedt, M., & Thiele, K. O. (2017b). Mirror, mirror on the wall: A comparative evaluation of composite-based structural equation modeling methods. Journal of the Academy of Marketing Science, 45(5), 616-632. https://doi.org/10.1007/s11747-017-0517-x   
Hamidi, H., & Chavoshi, A. (2018). Analysis of the essential factors for the adoption of mobile learning in higher education: A\~ case study of students of the University of Technology. Telematics $\mathcal { S } ^ { \setminus }$ and Informatics, 35(4), 1053-1070. https:/doi.org/10.1016/j.tele.2017.09.016   
Han, I., & Shin, W. S. (2016). The use of a mobile learning management system and academic achievementofonline  students. Computers &Education, 102, 79-89. https://doi.org/10.1016/j.compedu.2016.07.003   
Hoffman, D. L., & Novak, T. P. (1996), Marketing in hypermedia computer-mediated environments:  conceptual foundations, Journal of Marketing,  60(3), 50-68. https://doi.org/10.2307/1251841   
Huang, J., & Tan, M. (2023). The role of ChatGPT in scientific communication: Writing better scientific review articles. American Journal of Cancer Research, 13(4), 1148-1154. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10164801   
Huang, W., Hew, K. F., & Fryer, L. K. (2022). Chatbots for language learning-Are they really useful? A systematic review of chatbot-supported language learning. Journal of Computer Assisted Learning, 38, 237-257. https://doi.org/10.1111/jcal.12610   
Huang, X., Zou, D., Cheng, G., Chen, X., & Xie, H. (2023). Trends, research issues and applications of artificial intelligence in language education. Educational Technology & Society, 26(1), 112-131. https://doi.org/10.30191/ETS.202301_26(1).0009   
Huggins, C., & Stamatel, J. (2015). An Exploratory Study Comparing the Effectiveness of Lecturing  versus Team-based Learning. Teaching  Sociology, 43(3),  227-235. https://doi.org/10.1177/0092055X15581929

1097 Hwang, W. Y., Guo, B. C., Hoang, A., Chang, C. C., & Wu, N. T. (2022). Facilitating authentic   
1098 contextual EFL speaking and conversation with smart mechanisms and investigating its   
1099 influence on learning achievements. Computer Assisted Language Learning. In-press.   
1100 https://doi.org/10.1080/09588221.2022.2095406   
1101 Jeon, J., Lee, S., & Choe, H. (2023). Beyond ChatGPT: A conceptual framework and systematic   
1102 review of speech-recognition chatbots for language learning. Computers & Education, 206,   
1103 10498. https:/doi.org/10.1016/j.compedu.2023.104898   
1104 Karatas, F., Abedi, F. Y., Ozek Gunyel, F., Karadeniz, D., & Kuzgun, Y. (2024). Incorporating   
1105 AI in foreign language education: An investigation into ChatGPT's effect on foreign   
1106 language learners. Education and Information Technologies, In-press.   
1107 https://doi.org/10.1007/s10639-024-12574-6   
1108 Kasneci, E., Sessler, K., Kuchemann, S., Bannert, M., Dementieva, D., Fischer, F., Gasser, U.,   
1109 Groh, G., Gunnemann, S., Hullermeier, E., Krusche, S., Kutyniok, G., Michaeli, T., Nerdel,   
1110 C., Jurgen, P., Poquet, O., Sailer, M., Schmidt, A., Seidel, T. ..., & Kasneci, G. (2023).   
1111 ChatGPT for good? On opportunities and challenges of large language models for education.   
1112 Learning and Individual Differences, 103, 102274.   
1113 https://doi.org/10.1016/j.lindif.2023.102274   
1114 Kim, N. Y. (2019). A study on the use of artificial intelligence chatbots for improving English   
1115 grammar skills. Journal ofDigital Convergence, 17(8), 37-46.   
1116 https://doi.org/10.14400/JDC.2019.17.8.037   
1117 Kock, N., & Lynn, G. (2012). Lateral collinearity and misleading results in variance - Based   
1118 SEM: An illustration and recommendations. Journal of the Association for Information   
1119 Systems, 13(7), 546-580. https://doi.org/10.17705/1jais.00302   
1120 Koestner, R., & Zuckerman, M. (1994). Causality orientation, failure, and achievement. Journal   
1121 of Personality, 62, 321-345. https://doi/10.1111/j.1467-6494.1994.tb00300.x   
1122 Kohnke, L., Moorhouse, B. L., & Zou, D. (2023). ChatGPT for language teaching and   
1123 learning. RELC Journal, 54(2), 537-550. https://doi.org/10.1177/00336882231162868   
1124 Kozlowski, S. W., Gully, S. M., Brwon, K. G., Salas, E., Smith, E. M., & Nason, E. R. (2001).   
1125 Effects of training goals and goal orientation traits on multidimensional training outcomes   
1126 and performance adaptability. Organizational Behavior and Human Decision Processes,   
1127 85(1), 1-31. https://doi.org/10.1006/obhd.2000.2930   
1128 Kuhail, M. A., Alturki, N., Alramlawi, S., & Alhejori, K. (2023). Interacting with educational   
1129 chatbots: A systematic review. Education and Information Technologies. 28, 973-1018.   
1130 https://doi.org/10.1007/s10639-022-11177-3.   
1131 Lai, Y. H. (2010). Which do students prefer to evaluate their essays: Peers or computer   
1132 program. British Journal of Educational Technology, 41(3), 432-454.   
1133 https://doi.org/10.1111/j.1467-8535.2009.00959.x   
1134 Le, H. M., & Nguyen, T. T. D. (2023). Investigating EFL teachers'perceptions of implementing   
1135 active learning techniques in teaching speaking. European Journal of Foreign Language   
1136 Teaching, 7(2). http://dx.doi.org/10.46827/ejfl.v7i2.4795   
1137 Lee, C., Yeung, A. S., & Ip, T. (2017). University English language learners' readiness to use   
1138 computer technology  for  self-directed learning.System, 67, 99-110.   
1139 https://doi.org/10.1016/j.system.2017.05.001   
1140 Lee, J. C., Tang, Y., & Jiang, S. (2023). Understanding continuance intention of artificial   
1141 intelligence (AI)-enabled mobile banking applications: an extension of AI characteristics to   
1142 an expectation confirmation model. Humanities and Social Sciences   
1143 Communications, 10(1), 1-12. http://dx.doi.org/10.1057/s41599-023-01845-1   
1144 Lee, K. C., Chang, I. H., Wu, T. J., & Chen, R. S. (2022). The moderating role of perceived   
1145 interactivity in the relationship between online customer experience and behavioral   
1146 intentions to use parenting apps for Taiwanese preschool parents. SAGE Open, 12(1),   
1147 21582440221082136. https://doi.org/10.1177/21582440221082136   
1148 Li, R. (2021). Modeling the continuance intention to use automated writing evaluation among   
1149 Chinese EFL learners. SAGE Open, 11(4), 1-13.   
1150 https://doi.org/10.1177/21582440211060782   
1151 Li, R., Meng, Z., Tian, M., Zhang, Z., Ni, C., & Xiao, W. (2019). Examining EFL learners'   
1152 individual antecedents on the adoption of automated writing evaluation in China. Computer   
1153 Assisted Language Learning, 32(7), 784 804.   
1154 https://doi.org/10.1080/09588221.2018.1540433   
1155 Liu, G. L., Darvin, R., & Ma, C. (2024). Exploring AI-mediated informal digital learning of   
1156 English (AI-IDLE): a mixed-method investigation of Chinese EFL learners' AI adoption and   
1157 experiences. Computer Assisted Language Learning, In-press.   
1158 https://doi.org/10.1080/09588221.2024.2310288   
1159 Liu, G., & Ma, C. (2024). Measuring EFL learners' use of ChatGPT in informal digital learning   
1160 of English based on the technology acceptance model. Innovation in Language Learning and   
1161 Teaching, 18(2), 125-138. https://doi.org/10.1080/17501229.2023.2240316   
1162 Lu, L., Cai, R., & Gursoy, D. (2019). Developing and validating a service robot integration   
1163 willingness scale. International Journal of Hospitality Management, 80, 36-51.   
1164 https://doi.org/10.1016/j.ijhm.2019.01.005   
1165 Mackey, A., & Gass, S. M. (2021). Second language research: Methodology and design. New   
1166 York: Routledge. https://doi.org/10.4324/9781003188414   
1167 Maheshwari, G. (2023). Factors influencing students' intention to adopt and use ChatGPT in higher   
1168 education: A study in the Vietnamese context. Education and Information Technologies,   
1169 29, 12167-1219. https://doi.org/10.1007/s10639-023-12333-z   
1170 McHugh, M. L. (2012). Interrater reliability: The kappa statistic. Biochemia Medica, 22, 276-282.   
1171 https://hrcak.srce.hr/89395   
1172 Mende, M., Scott, M. L., van Doorn, J., Grewal, D., & Shanks, I. (2019). Service robots rising:   
1173 How humanoid robots influence service experiences and elicit compensatory consumer   
1174 responses. Journal of Marketing Research, 56(4), 535-556.   
1175 https://doi.org/10.1177/0022243718822827   
1176 Minhas, P. S., Ghosh, A., & Swanzy, L. (2012). The effects of passive and active learning on   
1177 student preference and performance in an undergraduate basic science course. Anatomical   
1178 Sciences Education, 5(4), 200-207. https:/doi.org/10.1002/ase.127410.1002/ase.1274   
1179 Mintz, Y., & Brodie, R. (2019). Introduction to artificial intelligence in medicine. Minimally   
1180 Invasive Therapy & Allied Technologies, 28(2), 73-81.   
1181 https://doi.org/10.1080/13645706.2019.1575882   
1182 Mohamed, A. M. (2024). Exploring the potential of an AI-based Chatbot (ChatGPT) in enhancing   
1183 English as a Foreign Language (EFL) teaching: Perceptions of EFL Faculty Members.   
1184 Education and Information Technologies, 29(3), 3195-3217.   
1185 https://doi.org/10.1007/s10639-023-11917-z   
186 Moher, D., Liberati, A., Tetzlaf, J., & Altman, D. G. (2009). Preferred reporting items for   
L187 systematic reviews and meta-analyses: The PRISMA statement. Annals of Internal   
188 Medicine, 151(4), 264-269. https://doi.org/10.7326/0003-819-151-4-200908180-00135   
1189 Mohsen, M. A. (2022). Computer-mediated corrective feedback to improve L2 writing skills: A   
L190 meta-analysis.Journal  of  Educational  Computing Research, 60(5),1253-1276.   
191 https://doi.org/10.1177/07356331211064066   
1192 Mori, M., MacDorman, K., & Kageki, N. (2012). The uncanny valley [from the field]. IEEE   
1193 Robotics and Automation Magazine, 19(2), 98-100.   
1194 https://doi.org/10.1109/MRA.2012.2192811   
l195 Mun, Y. Y., & Hwang, Y. (2003). Predicting the use of web-based information systems: self  
L196 efficacy, enjoyment, learning goal orientation, and the technology acceptance   
1197 model. International Journal of  Human-Computer Studies, 59(4),  431-449.   
L198 https://doi.org/10.1016/S1071-5819(03)00114-9   
1199 Ni, A., & Cheung, A. (2023). Understanding secondary students' continuance intention to adopt   
1200 AI-powered intelligent tutoring system for English learning. Education and Information   
1201 Technologies, 28(3), 3191-3216. https://doi.org/10.1007/s10639-02211305-z   
1202 Nikou, S. A., & Economides, A. A. (2017). Mobile-based assessment: Investigating the factors   
1203 that influence behavioral intention to use.Computers & Education, 109, 56-73.   
1204 https://doi.org/10.1016/j.compedu.2017.02.005   
1205 Oliver, R. (2008). Engaging First Year Students Using a Web-Supported Inquiry-Based Learning   
1206 Setting. Higher Education, 55(3), 285-301. https://doi.org/10.1007/s10734-007-9055-7   
1207 OpenAI. (2022). Introducing ChatGPT. OpenAI. https://openai.com/blog/   
1208 Park, Y., Son, H., & Kim, C. (2012). Investigating the determinants of construction professionals'   
1209 acceptance of web-based training: An extension of the technology acceptance   
1210 model. Automation in Construction, 22, 377-386.   
1211 https://doi.org/10.1016/j.autcon.2011.09.016   
1212 Patton, M.Q. (2008). Qualitative research and evaluation methods. Newbury Park, CA: Sage.   
1213 Paul, J., Ueno, A., & Dennis, C. (2023). ChatGPT and consumers: Benefits, pitfalls and future   
1214 research agenda. International Journal of Consumer Studies, 47(4), 1213-1225.   
l215 https://doi.org/10.1111/ijcs.12928   
1216 Pillai, R., & Sivathanu, B. (2020). Adoption of AI-based chatbots for hospitality and   
1217 tourism. International Journal of Contemporary Hospitality Management, 32(10), 3199   
1218 3226. https://doi.org/10.1108/IJCHM-04-2020-0259   
1219 Pillai, R., Sivathanu, B., Metri, B., & Kaushik, N. (2024). Students' adoption of AI-based teacher  
1220 bots (T-bots) for learning in higher education. Information Technology & People, 37(1),   
1221 328-355 https://doi.org/10.1108/ITP-02-2021-0152   
1222 Podsakoff, P. M., MacKenzie, S. B., Lee, J. Y., & Podsakoff, N. P. (2003). Common method biases   
1223 in behavioral research: a critical review of the literature and recommended remedies. Journal   
1224 of Applied Psychology, 88(5), 879-903. https://doi.org/10.1037/0021-9010.88.5.879   
1225 Polyzi, P., & Moussiades, L. (2023). An artificial vocabulary learning assistant. Education and   
1226 Information Technologies. 28(12), 16431-16455. https://doi.org/10.1007/s10639-023-   
1227 11810-9   
1228 Qiu, H., Li, M., Shu, B., & Bai, B. (2020). Enhancing hospitality experience with service robots:   
1229 The mediating role of rapport building. Journal of Hospitality Marketing & Management,   
1230 29(3), 247-268. https://doi.org/10.1080/19368623.2019.1645073

Rahim, N. I. M., A. Iahad, N., Yusof, A. F., & A. Al-Sharafi, M. (2022). AI-based chatbots adoption model for higher-education institutions: a hybrid PLS-SEM-neural network modelling approach. Sustainability, 14(19), 12726. https://doi.org/10.3390/su141912726   
Rousseau, D. M., Sitkin, S. B., Burt, R. S., & Camerer, C. (1998). Not so different after all: A cross-discipline view of trust. Academy of Management Review, 23(3), 393-404. https://doi.org/10.5465/amr.1998.926617   
Shortt, M., Tilak, S., Kuznetcova, I., Martens, B., & Akinkuolie, B. (2023). Gamification in mobile-assisted language learning: A systematic review of Duolingo literature from public release of 2012 to early 2020. Computer Assisted Language Learning, 36(3), 517-554. https://doi.org/10.1080/09588221.2021.1933540   
Song, C., & Song, Y. (2023). Enhancing academic writing skills and motivation: assessing the efficacy of ChatGPT in AI-assisted language learning for EFL students. Frontiers in Psychology, 14, 1260843. https://doi.org/10.3389/fpsyg.2023.1260843   
Srivastava, S. C., & Chandra, S. (2018). Social presence in virtual world collaboration: An uncertainty reduction perspective using a mixed methods approach. MIS Quarterly, 42(3), 779-804. http:/doi:10.25300/MISQ/2018/11914   
Su, C. Y., & Chiu, C. H. (2021). Perceived enjoyment and attractiveness influence Taiwanese elementary school students' intention to use interactive video learning. International Journal of Human-Computer Interaction, 37(6), 574-583. https://doi.org/10.1080/10447318.2020.1841423   
Su, Y., Lin, Y., & Lai, C. (2023). Collaborating with ChatGPT in argumentative writing classrooms. Assessing Writing, 57, 100752. https://doi.org/10.1016/j.asw.2023.100752   
Susnjak, T., & McIntosh, T. R. (2024). ChatGPT: The end of online exam integrity?. Education Sciences, 14(6), 656. https://doi.org/10.3390/educsci14060656   
Tai, T. Y. (2022). Effects of intelligent personal assistants on EFL learners' oral proficiency outside the classroom. Computer Assisted Language Learning, 37(5-6), 1281-1310. https://doi.org/10.1080/09588221.2022.2075013   
Tai, T. Y., & Chen, H. J. H. (2020). The impact of google assistant on adolescent EFL learners' willingness to communicate. Interactive Learning Environments, 31(3), 1485-1502. https://doi.org/10.1080/10494820.2020.1841801   
Terzis, V., & Economides, A. A. (2011). The acceptance and use of computer based assessment. Computers & Education, 56(4), 1032-1044. https://doi.org/10.1016/j.compedu.2010.11.017   
Tlili, A., Shehata, B., Adarkwah, M. A., Bozkurt, A., Hickey, D. T., Huang, R., & Agyemang, B. (2023). What if the devil is my guardian angel: ChatGPT as a case study of using chatbots in education. Smart Learning Environments, 10(1), 15. https://doi.org/10.1186/s40561-023- 00237-x   
Tram, N. H. M., & Tran-Thanh, V. (2024). The Role of Supportive Environments in Shaping EFL Teachers' Adoption of ChatGPT. In P. H. Bui & E. Namaziandost (Eds.), Innovations in Technologies for Language Teaching and Learning. Springer. https://doi.org/10.1007/978- 3-031-63447-5_4   
Tsai, C. C., Chuang, S. C., Liang, J. C., & Tsai, M. J. (2011). Self-efficacy in Internet-based learning environments: A literature review.Journal of Educational Technology & Society, 14(4), 222-240. https://www.jstor.org/stable/10.2307/jeductechsoci.14.4.222   
Tung, V. W. S., & Au, N. (2018). Exploring customer experiences with robotics in hospitality. International Journal of Contemporary Hospitality Management, 30(7), 2680 2697. https:/doi.org/10.1108/IJCHM-06-2017-0322   
Tussyadiah, I. P., & Park, S. (2018). Consumer evaluation of hotel service robots. In Information and Communication Technologies in Tourism 2018: Proceedings of the International Conference in Jonkoping, Sweden, January 24-26, 2018(pp. 308-320). Springer International Publishing. http:/dx.doi.org/10.1007/978-3-319-72923-7 24   
Van Der Rhee, B., Verma, R., Plaschka, G. R., & Kickul, J. R. (2007). Technology readiness, learning goals, and eLearning: Searching for synergy. Decision Sciences Journal of Innovative Education, 5(1), 127-149. https://doi.org/10.1111/j.1540-4609.2007.00130.x   
Venkatesh, V., Brown, S. A., & Sullivan, Y. W. (2016). Guidelines for conducting mixed-methods research: An extension and illustration. Journal of Association for Information Systems, 17(7), 435- 495. https://doi.org/10. 17705/1jais.00433   
Venkatesh, V., Morris, M. G., Davis, G. B., & Davis, F. D. (2003). User acceptance of information technology: Toward a  unified view. MIS Quarterly, 27(3),425-478. https://doi.org/10.2307/30036540   
Verma, D., Dewani, P. P., Behl, A., Pereira, V., Dwivedi, Y., & Del Giudice, M. (2023). A metaanalysis of antecedents and consequences of eWOM credibility: Investigation of moderating role of culture and platform type.Journal of Business Research, 154, 113292. https://doi.org/10.1016/j.jbusres.2022.08.056   
Wang, S., Wang, H., Jiang, Y., Li, P., & Yang, W. (2023). Understanding students' participation of intelligent teaching: an empirical study considering artificial intelligence usefulness, interactive reward, satisfaction, university support and enjoyment. Interactive Learning Environments, 31(9), 5633-5649. https://doi.org/10.1080/10494820.2021.2012813   
Wang, Y. S., Wu, M. C., & Wang, H. Y. (2009). Investigating the determinants and age and gender differences in the acceptance of mobile learning. British Journal of Educational Technology, 40(1), 92-118. https://doi.org/10.1111/j.1467-8535.2007.00809.x   
Wang, Y., Yu, L., & Yu, Z. (2022). An extended CCtalk technology acceptance model in EFL education. Education and Information Technologies, 27(5), 6621-6640. https://doi.org/10.1007/s10639-022-10909-9   
Wollowski, M. (2023). Using ChatGPT to produce code for a typical college-level assignment. AI Magazine, 44(1), 129-130. https://doi.org/10.1002/aaai.12086   
Wood, R., Bandura, A. (1989). Impact of conceptions of ability on self-regulatory mechanisms and complex decision making. Journal of Personality and Social Psychology, 56, 407-415. https://doi.org/10.1037/0022-3514.56.3.407   
Yan, D. (2023). Impact of ChatGPT on learners in a L2 writing practicum: An exploratory investigation.  Education and Information Technologies, 28(11), 13943-13967. https://doi.org/10.1007/s10639-023-11742-4   
Yang, L., & Li, R. (2024). ChatGPT for L2 learning: Current status and implications. System, 124, 103351. https:/doi.org/10.1016/j.system.2024.103351   
Zhai, N., & Ma, X. (2022). Automated writing evaluation (AWE) feedback: A systematic investigation of college students' acceptance. Computer Assisted Language Learning, 35(9), 2817-2842. https://doi.org/10.1080/09588221.2021.1897019   
Zhang, R., Zou, D., & Cheng, G. (2023). Chatbot-based learning of logical fallacies in EFL writing: perceived effectiveness in improving target knowledge and learner motivation.

1320 Interactive Learning Environments, In-press.   
1321 https://doi.org/10.1080/10494820.2023.2220374   
1322 Zhang, Y., Qin, G., Cheng, L., Marimuthu, K., & Kumar, B. S. (2021). Interactive smart   
1323 Educational System using AI for students in the higher education platform. Journal of   
1324 Multiple-Valued Logic & Soft Computing, 36(1-3), 83-98.   
1325 Zhuang, W., & Xiao, Q. (2018). Facilitate active learning: The role of perceived benefits of using   
1326 technology. Journal of Education for Business, 93(3), 88-96.   
1327 https://doi.org/10.1080/08832323.2018.1425281