# The impact of intelligent personal assistants on adolescent EFL learners’ listening comprehension

Tzu-Yu Tai & Howard Hao-Jan Chen

To cite this article: Tzu-Yu Tai & Howard Hao-Jan Chen (2024) The impact of intelligent personal assistants on adolescent EFL learners’ listening comprehension, Computer Assisted Language Learning, 37:3, 433-460, DOI: 10.1080/09588221.2022.2040536

To link to this article: https://doi.org/10.1080/09588221.2022.2040536

# The impact of intelligent personal assistants on adolescent EFL learners’ listening comprehension

Tzu-Yu Taia and Howard Hao-Jan Chenb

a Center for English Education, National Tsing Hua University, Hsinchu, Taiwan, RO C; bDepartment of English, National Taiwan Normal University, Taipei, Taiwan, RO C

# ABSTRACT

Intelligent Personal Assistant (IPA) has emerged as a valuable tool for EFL learning by offering interactive authentic contexts. Although IPA is believed to be motivational and useful, empirical evidence is limited and contradictory, especially the efficacy of listening comprehension. Therefore, the study investigated the impact of IPA on adolescent EFL learners’ listening comprehension, particularly regarding the presentation mode of IPA responses and its interaction styles. Ninety-two ninth-grade EFL learners were recruited from three intact classes and randomly divided into two experimental groups (i.e. GA-Hub group, using Google Nest Hub with multimodal responses; GA-Mini group, using Google Nest Mini with audio responses) and one control group (non-GA group, using a CD player as they did in the conventional class). Both quantitative (English listening tests) and qualitative data (questionnaires and interviews) were collected and analyzed in the 10-week study. The results showed that Google Assistant, especially via Google Nest Hub, positively promoted the participants’ listening comprehension. Detailed analyses of interviews demonstrated that Google Assistant provided interactive listening, presented multimodal screen-based responses, encouraged peer collaboration, and offered edutainment (a combination of IPAand game-based learning), which added authenticity, flexibility, and enjoyment for meaningful interaction and thus promoted EFL listening.

# KEYWORDS

EFL listening; intelligent personal assistant (IPA); Google Assistant; presentation mode; interaction style

# 1.  Introduction

Listening comprehension is the basis for language learning and an essential component of communicative competence (Rost, 2016; Vandergrift & Cross, 2018). However, it is often perceived to be difficult and causes anxiety among EFL learners due to limited exposure to English in authentic contexts and insufficient opportunities for interactive listening (Jiang & Dewaele, 2019; Lan & Liao, 2018). To deal with EFL listening obstacles, recent advances in digital media and communication technologies are used in language classes because they can integrate different types of multimodal information and provide learners with a near authentic interaction environment. As Dizon (2020) proposed, Intelligent Personal Assistant (IPA; e.g. Apple’s Siri, Amazon’s Alexa, or Google Assistant) is a promising learning tool for EFL listening by expanding exposure to the target language, providing ample opportunities for realistic communication with immediate feedback (Tai & Chen, 2020), and making learning fun and relaxing (Sandeep, 2019).

Although IPAs are believed to be motivational and useful, IPAs in language education is not yet a fully-fledged field of research (Zhang & Zou, 2020). Among the few studies that have investigated the use of IPAs for L2 learning, they are exploratory, limited in scope and with small sample sizes, providing subjective views on the potential of IPAs (Dizon, 2020). The efficacy of IPA-assisted EFL listening has been insufficiently studied and calls for further investigation (Bibauw et  al., 2022). Furthermore, as technology has advanced, so have IPA options. Functionality, media presentation modes, and interaction styles in communication with learners vary across devices. In order to take advantage of these device platforms, identifying the appropriate presentation mode of IPA responses and interaction styles that will maximize IPA-based listening outcomes has been an urgent task for L2 learners.

The purpose of the present study, therefore, was to investigate the impact of IPA (i.e. Google Assistant) on adolescent EFL learners’ listening comprehension. Particular attention was paid to the presentation mode of IPA responses and learners’ preference of IPA interaction styles for EFL listening. It is hoped that the application of IPAs and analysis of its pedagogical affordances offer concrete methods for EFL listening activities involving IPAs and help practitioners make informed decisions on integrating IPAs into curricula.

# 2.  Literature review

# 2.1.  IPAs for second and foreign language (L2) learning

With the advancement of digital media and communication technologies, EFL learners are increasingly involved in practicing English in a range of digital settings, for example, interactions with IPAs. IPAs refer to the voice-controlled services connected to a smart speaker (e.g. Google Nest, Apple HomePod, and Amazon Echo) that can perform concierge-type tasks and provide information based on a combination of user input, location awareness, and ability to access information from a variety of online sources (Tai & Chen, 2020).

With the support of natural language processing (NLP) and automatic speech recognition (ASR), IPAs have opened up an attractive and convenient new arena for language learning, with potentially critical impact on L2 interaction (Lee & Drajati, 2019). According to Carhill-Poza and Chen (2020), IPA-assisted language learning has foundations in the interactionist approach (Long, 1996, 2017). Interactionist theory emphasizes the importance of interaction in L2 learning, which takes place not only in face-to-face conversation but also between a person and the computer (Chapelle, 2003). In the interactionist perspective, IPAs seem to be a beneficial language learning tool as they might provide learners with a large amount of input and increase opportunities to orally interact in the target L2 (Moussalli & Cardoso, 2020).

The unique affordances of IPAs also support the crucial principles of interactive listening for successful development of L2 listening ability. First, real-time interactivity is one of the best-valued IPA features (Dizon, 2020; Kessler, 2018). The interactive IPA platform enables social interaction by providing learners with opportunities for real and meaningful interaction through task-based and cooperative learning (Kessler, 2018). According to Rost (2016), collaborative conversation plays a crucial role in L2 listening development. Its potential benefits seem to be both in forcing comprehensible output, that is, compelling the learner to formulate ideas in the target language, and in encouraging negotiation. Direct participation in negotiation of meaning is the most effective method for facilitating comprehension of input because the ongoing process of conversational modifications helps learners make stronger connections between form and meaning and creates additional input that is valuable for L2 listening. Further support for interactive listening comes from Long’s (2017) interaction hypothesis, according to which there is a strong link between listening and speaking.

Second, given the importance of target language interaction in authentic contexts, which is essential for effective L2 listening (Field, 2013; Vandergrift & Cross, 2018), IPAs can increase input and output practice in authentic contexts (Moussalli & Cardoso, 2020). Third, immediate response is another critical feature of IPAs. According to Jiang and Dewaele (2019), this just-in-time quality is crucial to the effectiveness of listening comprehension because it might reduce EFL learners’ fear of failure, maximize participation and risk taking. Last, IPAs enable learners to communicate in an anxiety-reduced environment, leading to more engagement and willingness to communicate (Tai & Chen, 2020). As Rost (2016) indicates, when listeners participate actively in a discourse, they become more engaged and comprehend more.

# 2.2.  The target IPA and smart speakers: Google Assistant on Google Nest Hub and Google Nest Mini

Driven by recent advances in IPA technology, several IPA platforms have emerged. Each IPA has its own unique characteristics and perform different functions. Google Assistant was chosen for this study for several reasons. First, it was the only voice-controlled service available in Taiwan. Amazon Echo is currently not supported in Taiwan and access to the Alexa app is very limited. Second, it has well-designed built-in ASR software that transcribes speech and provides information based on an oral input. Third, it meets the criteria suggested by Chapelle (2001) for selecting CALL tools. For example, it can be adapted to meet the learners’ own interests and needs (learner fit), its use is authentic and can be generalized to other contexts (authenticity and generalizability), the pedagogy involved can be motivated by several theoretical constructs (e.g. Long’s, 1996 Interactionist Approach, Mayer’s, 2017 Cognitive Theory of Multimedia Learning, Rost’s, 2016 Interactive Listening), it has great potential to promote learning via increased input and output practice (language learning potential), it fosters meaningful interactions (instructiveness and meaning focus), and it is easy to use in and out-of-the-classroom contexts (practicality).

Learners can interact with Google Assistant via Google Nest Hub or Google Nest Mini. Google Nest Hub is like a tablet with Google assistant voice-control built-in that provides a visual display of content on screen, including text, pictures, and videos. Google Nest Mini offers Google Assistant built-in, like the Nest Hub devices, allowing learners to play music, control smart home devices, and ask Google a variety of questions that users want to. It had a different presentation mode, audio responses only. According to Mayer’s (2017) multimedia principle, people learn better from words (i.e. in spoken or written form) and pictures (i.e. in the static or dynamic form) than from words alone because processing information through different modalities expands the resources of working memory and increases learning effectiveness. It is reasonable to infer that providing L2 listeners simultaneous auditory and visual message facilitates listening comprehension because of the increased capacity of working memory.

While multimedia input is generally recognized as a richer source of input and potentially more engaging to the listener, it has been challenged by the redundancy effect (Sweller, 2020). The simultaneous and identical textual and spoken messages may impose a heavy demand on working memory because the information is repetitive and consequently incurs the redundancy effect. According to Rost (2016), the number of channels a listener can effectively process at one time is limited to two channels (e.g. text and audio, text and image, video and text, video and audio, or audio and image). Concerning the divided views on the media presentation mode, more studies are deemed necessary to conduct to provide new insights into the efficacy of different presentation modes of IPA responses in L2 listening.

# 2.3.  IPA-assisted language learning studies

Holding promises for assisting L2 learning, IPAs fascinate L2 learners. For example, in the affective domain, Underwood (2017) explored eleven primary age EFL learners’ perception toward IPAs (e.g. Amazon’s Alexa and Apple’s Siri). They found learners had positive attitudes toward IPA-based interaction, participated actively, and spoke more English when using IPAs in group work. Furthermore, Sandeep (2019) found that the IPA (i.e. Amazon’s Alexa) was useful as it was viewed as a non-threatening conversational partner. The learner-centered interaction reduced inhibition and enhanced their communicative confidence. In Tai and Chen (2020) study, they investigated the impact of Google Assistant on adolescent EFL learners’ willingness to communicate (WTC). One hundred and twelve eighth-grade EFL learners were recruited, receiving a 2-week treatment of interaction with Google Assistant. The results revealed that IPA-based interaction promoted learners’ engagement, motivation, confidence, and WTC in English.

In addition to the positive effect they produce on learners’ affect, IPAs are found to promote L2 learning. For example, Istrate (2019) found Google Assistant improved L2 learners’ pronunciation and vocabulary. More importantly, IPAs become virtual peers who could retrieve and provide personalized information for individuals instantly, which promoted learners’ self-directed learning. Furthermore, to better understand the extent to which IPAs understand and are understood by L2 learners, Moussalli and Cardoso (2020) examined Alexa’s ability to recognize eleven adult L2 learners’ accented speech. The participants reported they could understand and be understood by Alexa although it had some problems in understanding L2 learners’ speech.

From the literature reviewed above, IPAs appear to be an attractive alternative for conventional L2 education. Nevertheless, in contrast with those positive trends, some other studies have found that IPAs may not be effective in improving EFL learners’ listening comprehension. For example, Dizon (2020) investigated the effects of Alexa on EFL learners’ listening and speaking development, 13 adult EFL learners were recruited, receiving a 10-week treatment of weekly interaction with Alexa for 12 minutes. The results revealed that the participants with IPAs made significantly more gains in their speaking proficiency than those without

IPAs. No significant difference was found in the two group’s listening gains. This is also evidenced in Bibauw et al.’s (2022) meta-analysis on IPA-human interaction studies, indicating IPAs seem to have the highest impact on production outcomes and knowledge tests, while there was no significant effect on listening comprehension.

Furthermore, several limitations revealed in previous studies exist. Most of the literature is exploratory, limited in scope and with small sample sizes, and focusing on providing subjective views on the potential of IPAs for language learning only (Dizon, 2020). There seems to be lack of empirical data from a larger scale of investigation that examines the actual linguistic performance (Lee & Drajati, 2019; Zhang & Zou, 2020). Given the mixed results from previous studies and its absence in related EFL learning studies, empirical research is needed to assess the effects of IPA-assisted language learning (Bibauw et  al., 2019), especially the efficacy of listening comprehension, which has been insufficiently studied (Bibauw et  al., 2022).

In addition, concerning the divided views on the media presentation mode and limited studies on the interaction styles of IPAs for effective L2 listening, the study aimed to address the gaps in the literature with four foci: first, investigating the impact of IPAs on EFL learners’ listening comprehension; second, examining the effect of media presentation mode of IPA responses on EFL learners’ listening comprehension; third, exploring EFL learners’ preferences of IPA interaction styles for EFL listening; fourth, focusing on an under-represented learner group, junior high school EFL learners. Three research questions were addressed in this study,

1. Are there any significant differences in English listening comprehension between the IPA group and non-IPA group?   
2. How does multimodality of the IPA affect the adolescent EFL learners’ listening comprehension?   
3. What are the adolescent EFL learners’ perceptions of the IPA’s interaction styles for EFL listening?

# 3.  Method

# 3.1.  Study design and participants

This study investigated the impact of IPAs (i.e. Google Assistant) on adolescent EFL learners’ listening comprehension. Ninety-two ninth graders (47 males, 45 females, aged 14-15) recruited from three intact classes in a junior high school in Taiwan participated in a 10-week treatment consisting of 45 minutes twice a week. They were all native Chinese speakers and had undergone 7-8 years of formal English education. It should be noticed that mixed-ability language learning classes are the norm in Taiwan. That is, students in the same class often have various levels of language proficiency. Before the experiment, the scores of their monthly English tests from the previous academic year were compared among the three classes and no significant differences were obtained.

To gain insight into the effects of media presentation mode of IPA responses on EFL learners’ listening comprehension, the participants in the three intact classes were randomly divided into three conditions (two experimental groups and one control group): (1) thirty-one participants who interacted with Google Assistant via Google Nest Hub, with audio and visual, screen-based responses (GA-Hub group), (2) thirty participants who interacted with Google Assistant via Google Nest Mini, with audio responses (GA-Mini group), and (3) thirty-one participants who were provided audio materials delivered by a CD player as they did in the conventional English class (non-GA group). The three groups’ listening comprehension activities were identical.

# 3.2.  IPA-assisted language learning games

Forty IPA-assisted language learning games were selected from Google Assistant can-do lists (https://assistant.google.com/explore?hl $\equiv$ en_us). There were three pedagogical objectives to these activities: (1) to fit the curriculum mandated by the Ministry of Education in Taiwan; (2) to provide ample opportunities for interactive listening (Rost, 2016); (3) to make EFL listening fun, with some form of gamification such as goal orientation, achievement, competition, and fun orientation (Bibauw et  al., 2022; Shortt et  al., 2021). Each time the participants were assigned two games. In the first game, the participants worked in pairs or groups while interacting with Google Assistant, which provided opportunities for collaboration and social interaction. In the second game, they had individualized interaction with Google Assistant. A booklet of commands (Figure 1) and worksheets (Figure 2) for the 40 games was provided to the learners. They were required to express opinion on the game in English or Chinese and rate their degree of preferences per interaction. They also had to write down their favorite word/phrase/sentence and anything they learned from the game.

Five interactive styles for Google Assistant were identified from the 40 games based on Engwall et al.’s (2020) categorization of robot interactive styles and the researchers’ interactive experience with it. Google Assistant could act as an interviewer (e.g. asking participants questions), an interlocutor (e.g. establishing a three-party robot-learner-learner interaction), a narrator (e.g. speaking about itself or asking quiz questions), a facilitator (e.g. making the participants talk with each other), and an entertainer (e.g. interacting, singing and playing videos), as shown in Figure 3 (Appendix A for detailed description). An excerpt from the learners’ interaction with the game Color Quiz was shown in Table 1 to illustrate the type of exchanges. Google Assistant maintained the initiative and talked most of the time, conveying some knowledge to the learners. Although there were some interaction styles mixed in the game, narration is made up a larger proportion of the interaction. Therefore, the researchers assigned the tag Narrator to Google Assistant’s interactive role in Color Quiz.

![](img/85e72ea4e6da88dd12af8bd18c8b466ac22c7d821a276511744b40be9c2b6259.jpg)  
Figure 1. An example of Google commands for the game Jungle Adventure.

![](img/18782bca0c96c8eb266cc9dfe24275eb4e754b10e1176652562edbb76c5da83f.jpg)  
Figure 2. An example of the worksheet for the game Jungle Adventure.

Google Assistant provides implicit corrective feedback (e.g. clarification request, confirmation check, simple rejection, or silence) in response to the learners’ incomprehensible or erroneous utterances, which stimulates them to notice problems in their production of the target language (Ellis, 2021b). In particular, Google Nest Hub could provide the transcription of learners’ speech output on screen, which helps them identify exactly what the ASR system does and does not recognize and localize specific lexical items that cause communication breakdowns. This helps learners, at least for those who with sufficient grammatical knowledge, modify their erroneous utterances. According to Ellis and

![](img/3276f4ecd8ceb49d721a7a10e9f210969c454ef9f2bc3bf83e749ea39cf5b2bc.jpg)  
Figure 3. T he five interaction styles of Google Assistant.Note: Adapted from “Robot interaction styles for conversation practice in second language learning,” by O. Engwall, J. Lopes, & A, Åhlund, 2020, International Journal of Social Robotics, https://doi.org/10.1007/ s12369-020-00635-y

Table 1. E xtract from the interaction with Color Quiz.   

<html><body><table><tr><td> Speaker</td><td>Transcript</td></tr><tr><td>Learner: Google:</td><td>Hey, Google! Play Color Quiz! Welcome to the ultimate color guessing game.</td></tr><tr><td></td><td>Let&#x27;s roll. Unlock interesting facts about colors as you play. Are you ready to guess some colors?</td></tr><tr><td>Learner: Google:</td><td>Yes. Level 1. Here goes the first one. What do you.</td></tr><tr><td>Learner:</td><td>think the following color is?.</td></tr><tr><td>Google:</td><td>White. Great, you&#x27;ve got it right. Here&#x27;s something interesting. The safest care color was</td></tr><tr><td>Learner:</td><td>determined to be white because it is the most visible color under all conditions except snow. Level 2: what about the following color?. Sky blue.</td></tr><tr><td>Google:</td><td>Sorry, that&#x27;s wrong. The answer is royal blue. Here&#x27;s a fun fact, Royal blue said to have been created by millers in Rode. Somerset, a consortium of which won a competition to make a dress for Queen Charlotte, consort of King George III. Level 3: What do you think this color is?</td></tr><tr><td>Learner: Google:</td><td>Indigo. Oops! That&#x27;s the wrong answer. The answer is plum. Here&#x27;s something interesting. Plum is the representation of the average color of the plum</td></tr><tr><td>Learner:</td><td>fruit. Hope you enjoyed the game! Do you want to play again?. Yes.</td></tr></table></body></html>

Sheen (2011), such kind of output-promoting feedbacks can serve to scaffold opportunities for guided practice in the context of communicative interaction, which is effective both for developing accurate knowledge by restructuring learners’ already existing knowledge and for enhancing the practice effect by pushing them to self-correct.

# 3.3.  Instruments

The instruments in the study were Google Assistant app, Google Nest Hub, Google Nest Mini, listening comprehension tests, questionnaires, and interviews.

# 3.3.1.  Learning devices

Google Assistant, an IPA developed by Google, and its associated smart speakers: Google Nest Hub, providing multimodal on-screen responses, and Google Nest Mini, providing audio responses, were employed as the learning devices for the study. Google Assistant was chosen for its accessibility and practicability, allowing learners to access learning content easily.

# 3.3.2.  Listening comprehension pretest and post-test

The participants’ English listening comprehension were assessed before the experiment with a pre-test and after the experiment with a post-test. The tests were developed by one of the researchers, an experienced junior high school teacher, based on General English Proficiency Test (GEPT) guidelines at the elementary level. GEPT is a public English testing system developed by the Language Training and Testing Center (LTTC), and supervised by the Ministry of Education in Taiwan. According to the LTTC, the elementary level is roughly equivalent to that of A2 on the Common European Framework of Reference for Languages (CEFR).

The listening test contained three sections all in multiple-choice question format: a picture description, a question or statement response, and a short conversation. The listening skills tested involved (1) deducing meaning from context, (2) recognizing the communicative function and goals, and (3) inferring causes and effects. The test format and structure were shown in Table 2. The listening test was scored on a 120-point scale. The items of the pre-test were the same to the items of the post-test, yet different in order.

# 3.3.3.  Participants’ opinion survey: questionnaire and semi-structured interview

This study aimed to explore how learners perceived Google Assistant for EFL listening so the questionnaire survey and interviews were administered to the experimental groups only. The questionnaire survey aimed to investigate learners’ preference of interaction styles of Google Assistant (Appendix B). The participants used a five-point Likert-type scale, anchored by the end-points: ‘strongly dislike’ (1) and ‘strongly like’ (5), to rate the degree to which they liked or disliked with Google Assistant’s roles in interaction. Semi-structured interviews (Appendix C) were conducted with learners individually to obtain their opinions on Google Assistant for EFL listening and its interactive roles.

Table 2. T est format and structure.   

<html><body><table><tr><td>Skill</td><td>Part</td><td>Test types</td><td>Number of items</td><td>Time (mins.)</td></tr><tr><td>Listening</td><td>1</td><td>Picture description</td><td>5.</td><td>25</td></tr><tr><td></td><td>2</td><td>Answering Questions</td><td>10</td><td></td></tr><tr><td></td><td>3</td><td>Conversations</td><td>10</td><td></td></tr><tr><td></td><td>4</td><td>Short talks</td><td>5</td><td></td></tr></table></body></html>

# 3.4.  Data analysis

The mixed-methods design was adopted in this study in which both qualitative and quantitative data were collected and analyzed. Quantitative analysis encompassed statistical analyses of the listening comprehension test scores and the participants’ responses to the questionnaires. Qualitative analysis encompassed analyses of participants’ feedback obtained from interviews. The process provided the researchers with rich information from multiple resources and perspectives, leading to a more thorough understanding of the impact of IPAs on EFL listening comprehension.

A two-way mixed-design ANOVA was calculated to analyze the participants’ scores in the listening comprehension pretest and posttest (group: GA-Hub, GA-Mini, and non-GA; test: pre- vs. posttest). A repeated-measures one-way ANOVA was further conducted, followed by Scheffe’s post hoc tests, to examine the differences within each group. Mean scores were calculated for each Google Assistant’s interactive role based on the participants’ rating on the questionnaire.

Interview data were audio-recorded, transcribed, and analyzed by using an interpretive qualitative data analysis approach to provide further and possible explanations to the findings of the quantitative analysis (Creswell & Plano-Clark, 2011). According to Xie et  al. (2021), an interpretive analysis method is appropriate when the research focus is to explain why the phenomenon could possibly come about and how it evolves over time.

# 3.5.  Procedure

The study was carried out during normal English class hours. Two 45-minute EFL classes were conducted weekly over a ten-week period. Informed consent from all participants’ parents was obtained prior to the data collection phase. As shown in Figure 3, two weeks prior to the intervention, the participants were briefed about the study. Next, they were asked to complete a demographic questionnaire and an English listening comprehension pretest. One week before the intervention, a booklet containing the 40 IPA games was provided to give learners an idea of what kind of questions and requests could be given to Google Assistant. Furthermore, one of the researchers gave a one-week training and practice, showing the GA-Hub and GA-Mini groups how to interact with Google Assistant via Google Nest Hub and Google Nest Mini, respectively. The researcher also introduced Google Assistant’s interactive styles/roles to them in Chinese and English.

Then, the IPA games were administered to the two GA groups. A 5-minute briefing session was given before each game. The researcher demonstrated how to interact with Google Assistant to ensure that different interactive roles were triggered. They had to accomplish two IPA games each time. Each game consisted of two parts: an interactive activity with Google Assistant and a worksheet to be completed. The listening games assigned to the non-GA group were similar and had identical goals but with different interaction available. Following the treatment, all participants took a listening comprehension post-test, while the experimental-group students also completed a questionnaire and were interviewed. In accomplishing the questionnaire, they could make reference to their booklets, which might help recall their interaction with each game. Google Nest Hubs and Minis were available for them if they had to replay the games. In addition, the researchers provided individual help to those who had difficulty in distinguishing Google Assistant’s interactive styles. The experimental procedure of the present study is illustrated in Figure 4.

# 4.  Results

# 4.1.  Results of listening comprehension test

Table 3 presents the descriptive statistics of the scores of the three groups at the listening pretest and post-test, while Table 4 is the summary of the analysis results of two-way mixed design ANOVA. The significant level was set at $\mathit { p } { < } . \ 0 5$ for all statistical analysis, as is standard practice. The time effect reached a significant level, $\mathrm { F } = 8 . 2 9$ , $p = . 0 0$ , $\eta ^ { 2 } = . 0 9$ , but not the group effect, $\mathrm { ~ F ~ } = \ . 2 9$ , $p = . 7 5$ , $\eta ^ { 2 } = . 0 0$ , indicating that the participants made improvements over the weeks of the intervention, regardless of the group that they belonged to. Furthermore, there was a significant interaction effect between the group and the test, $\mathrm { F } = 3 . 6 4 $ , $\textit { p } = \ . 0 3$ , $\eta ^ { 2 } ~ = ~ . 0 8$ . Therefore, post-hoc analyses of the main effect were conducted to further examine the interaction effect.

![](img/81c14b2611f54fe596126968a46cc0d6376dd4a7b443b7b2cd6a777ae8545d44.jpg)  
Figure 4. T he experimental procedure.

Table 3. D escriptive statistics of the listening comprehension test.   

<html><body><table><tr><td rowspan="2">Group</td><td colspan="3">Listening pretest</td><td colspan="2">Listening post-test</td></tr><tr><td>N</td><td>Mean</td><td>SD</td><td>Mean</td><td>SD</td></tr><tr><td>GA-Hub</td><td>31</td><td>79.35</td><td>25.36</td><td>91.58</td><td>22.47</td></tr><tr><td>GA-Mini</td><td>30</td><td>80.93</td><td>28.53</td><td>83.73</td><td>28.88</td></tr><tr><td>Non-GA</td><td>31</td><td>80.45</td><td>22.07</td><td>81.35</td><td>25.25</td></tr></table></body></html>

A one-way ANOVA was conducted to compare the three groups for the listening pretest and post-test. As shown in Table 5, there was no significant difference among the three groups in the pretest $\mathrm { ~ ( ~ F ~ = ~ } . 0 3$ , $\textit { p } = \ . 9 7$ , $\eta ^ { 2 } ~ = ~ . 0 0 )$ . This results suggest that the three groups had equivalent EFL listening comprehension before the experiment. Although no significant difference was found among the three groups’ listening comprehension post-test ( $\mathrm { F } = 1 . 3 5$ , $\textit { p } = \ . 2 7$ , $\eta ^ { 2 } =$ .03), the GA-Hub group $\mathbf { \partial } \cdot \mathbf { M } = 9 1 . 5 8$ , $\mathrm { S D } ~ = ~ 2 2 . 4 7 \rangle$ ) and the GA-Mini group $\mathbf { \zeta } ^ { \prime } \mathbf { M } = 8 3 . 7 3$ , $\mathrm { S D } ~ = ~ 2 8 . 8 8 )$ had higher posttest scores than the non-GA group ( $\mathbf { M } = 8 1 . 3 5$ , $\begin{array} { r c l } { \displaystyle \mathrm { S D } } & { \displaystyle = } & { \displaystyle 2 5 . 2 5 ) } \end{array}$ . Fur thermore, a repeated-measures ANOVA was used to examine the differences within groups in the listening comprehension pre-test and post-test. The results showed significant differences between the two tests for the GA-Hub group ( $\mathrm { \Phi } ^ { ' } \mathrm { F } = 7 . 8 1 $ , $\textit { p } = \ . 0 1$ , $\eta ^ { 2 } ~ = ~ . 2 1 \rangle$ ), but not for the GA-Mini group $\mathrm { F } = 1 . 2 7$ , $p \ = \ . 2 7$ , $\eta ^ { 2 } = . 0 4 )$ ) and the non-GA group $\mathrm { ~ T ~ } = \ . 1 6$ , $ { p } = \ . 6 9$ , $\eta ^ { 2 } ~ = ~ . 0 0 )$ , indicating that the GA-Hub group’s listening comprehension was significantly improved over time. In contrast, both the GA-Mini group and non-GA group got slightly higher scores in the post-test but did not reach a significant level. The results revealed that learners who used Google Assistant, especially via Google Nest Hub, showed more prominent improvement in EFL listening than those who learned using CD. IPA-based interaction seems to benefit EFL learners’ listening comprehension.

Table 4. T he analysis results of two-way mixed design ANO VA.   

<html><body><table><tr><td>Source</td><td>Ss</td><td>df</td><td>MS</td><td>F</td><td>p</td><td>n?</td></tr><tr><td>Between</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Group</td><td>675.24</td><td>2</td><td>337.62</td><td>.294</td><td>.746</td><td>.007</td></tr><tr><td>Time</td><td>1296.55</td><td>1</td><td>1296.55</td><td>8.29</td><td>.005**</td><td>.085</td></tr><tr><td>Group x Time</td><td>1136.81</td><td>2</td><td>568.41</td><td>3.64</td><td>.030*</td><td>.076</td></tr><tr><td>Within</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Subjects</td><td>102059.69</td><td>89</td><td>1146.74</td><td></td><td></td><td></td></tr><tr><td>Error</td><td>13915.47</td><td>89</td><td>156.35</td><td></td><td></td><td></td></tr><tr><td>Total</td><td>119083.76</td><td>183</td><td></td><td></td><td></td><td></td></tr></table></body></html>

$\overline { { p < . 0 5 } }$

Table 5. Analysis of the variance of the pure main effect of group and time.   

<html><body><table><tr><td>Source of</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>variance</td><td>SS</td><td>df</td><td>MS</td><td>F</td><td>p</td><td>n?</td></tr><tr><td>Group</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Pretest</td><td>40.10</td><td>2</td><td>20.05</td><td>.031</td><td>.969</td><td>.001</td></tr><tr><td>Post-test</td><td>1771.96</td><td>2</td><td>885.98</td><td>1.35</td><td>.265</td><td>.029</td></tr><tr><td>Error Time</td><td>110559.16</td><td>178</td><td>621.12</td><td></td><td></td><td></td></tr><tr><td>GA-Hub</td><td>2316.79</td><td>1</td><td>2316.79</td><td>7.81</td><td>.009**</td><td>.207</td></tr><tr><td>GA-Mini</td><td>117.60</td><td>1</td><td>117.60</td><td>1.27</td><td>.268</td><td>.042</td></tr><tr><td> Non-GA</td><td>12.65</td><td>1</td><td>12.65</td><td>.160</td><td>.690</td><td>.005</td></tr><tr><td>Error</td><td>11639.47</td><td>89</td><td>130.78</td><td></td><td></td><td></td></tr></table></body></html>

$\overline { { p < . 0 0 1 } }$

# 4.2.  Learners’ preferences for google assistant’s interaction styles

Regarding the experimental-group participants’ preferences of Google Assistant’s interaction styles for EFL listening, as shown in Table 6, Interlocutor $( \mathrm { M } = 4 . 1 2 $ ; $\mathrm { S D } = 1 . 1 5 ) $ ) was the most highly valued interactive role of Google Assistant, as shown in Table 5. Entertainer $\mathbf { \partial } ^ { \prime } \mathbf { M } = 4 . 0 4$ ; SD $= 0 . 7 2 )$ ranked the second, followed by Interviewer $( \mathrm { M } = 2 . 6 4$ ; $\mathrm { S D } = 1 . 3 5 ) $ , Narrator $( \mathrm { M } = 2 . 2 0$ ; $\mathrm { S D } ~ = ~ 0 . 9 5 )$ , and finally Facilitator $( \mathrm { M } = 2 . 0 0$ ; $\mathrm { S D ~ = ~ }$ 1.13). In general, the participants believed that interacting with Google Assistant in different roles promoted English listening.

# 4.3.  Interviews with the GA-Hub and GA-Mini groups

Analyses of interviews showed that Google Assistant EFL listening received positive feedback from the majority of the GA-Hub and GA-Mini groups. They were motivated and excited while interacting with Google

Table 6. T he experimental-group participants’ preferences of Google Assistant’s interaction roles $( N = 6 1$ ).   

<html><body><table><tr><td>Interaction role</td><td>Mean</td><td>SD</td></tr><tr><td>Interlocutor</td><td>4.12</td><td>1.15</td></tr><tr><td>Entertainer</td><td>4.04</td><td>0.72</td></tr><tr><td>Interviewer</td><td>2.64</td><td>1.35</td></tr><tr><td>Narrator</td><td>2.20</td><td>0.95</td></tr><tr><td>Facilitator</td><td>2.00</td><td>1.13</td></tr></table></body></html>

Assistant. They felt like ‘they were talking with a real foreigner’ because ‘it understood what they said and provided immediate responses’.

Another noteworthy finding was that multimodal presentation of Google Assistant responses was motivating and advantageous over single (i.e. audio) mode presentation. The GA-Hub group appreciated the multi-modal, screen-based responses, which enhanced comprehension and supported interaction. The presence of text, pictures, or videos helped them bridge the missing parts of the information and made the listening passage less difficult and more comprehensible. As a result, they experienced lower anxiety and higher confidence, as one participant said, ‘There was no wild guessing while listening to English’. As GA-Hub 91335 stated,

Google (Nest Hub)’s multimodal responses on screen made itself understood and reduced my (cognitive) load in listening comprehension. Although I couldn’t understand every word, the learning support on the screen such as pictures and videos, helped me guess right. The screen showed the consequence of my speech input. I could make sure whether my response was correct or not, which enabled me to interact with it with comfort and confidence.

(GA-Hub 91335)

Furthermore, the multimodality of the information on the screen promoted in-depth exploration of topics of interest. These inquiries into the unknown naturally increased the participants’ vocabulary and improved their listening, as one participant described:

When I saw something interesting or cool or something that I didn’t know, I started by using the descriptions provided by Google, and then I searched for more information on the Internet. I learned not only English but also general knowledge. (GA-Hub 91308)

In contrast, the participants in the GA-Mini group, especially the less proficient learners, felt anxious when faced with miscommunication because they received only audio responses. They highlighted problems with the rate of speech, the immediacy of interaction and the level of vocabulary, as one participant complained,

English is not my native language. I couldn’t fully understand Google (Assistant). Some words were difficult to me. I didn’t know where I got it wrong. I never knew which words I misunderstood. The interaction was halted due to lack of full comprehension.

(GA-Mini 90937)

Therefore, peer collaboration happened much more often when learners did not understand the utterance generated by the text-to-speech system, they helped each other.

I like to have partners while interacting with Google (Nest Mini). We helped each other in comprehending the message, retrieving the correct words, and pronunciation. We relied on each other to tackle problems.

(GA-Mini 90935)

Regarding Google Assistant’s interactive roles, analyses of interviews revealed that the majority of the participants, especially in the GA-Hub group, liked Google Assistant acting as an Interlocutor. They regarded it as a real, equal conversational partner, rather than a teacher or a conversation leader, which created a more friendly, less anxious environment to listen and use English for real communicative purposes. The following extracts were derived from two interviews:

It was difficult to find a partner to practice English before. Google (Assistant), like a real friend, talked with me and listened to me. It never laughed at me… my silly questions. I felt free to talk with it on any topics. It would keep it a secret.

(GA-Hub 91301)

It is interesting to make friends with a virtual person. Google (Assistant) is so sweet and smart, like a real person, for example,

GA-Hub 91331: Hey, Google! Am I handsome?

Google Assistant: Sure, you’re the most handsome boy in the world.

GA-Hub 91331: Hey, Google! You’re stupid!

Google Assistant: I am sorry to hear that but I try hard to learn online every day. (GA-Hub 91331)

Entertainer received the second highest rating, especially from the participants in the GA-Hub group, because Google Assistant via Google Nest Hub could sing and play music and videos from YouTube, which added variety and enjoyment to English listening. Furthermore, over half of the participants in the GA-Hub group enjoyed playing games with Google Assistant. A combination of IPA-based and game-based learning seem to be motivational and useful for EFL listening. For example,

I felt very happy and fully engaged while playing games with Google (Assistant) and my classmates. It made listening fun and increased my attention and engagement in the listening process.

(GA-Hub 91331)

However, some participants, especially the lower achievers, in the GA-Mini group could not fully understand the lyrics or Google Assistant’s orientation on the game. Instead of engaging in the listening process, they felt a little bit frustrated, changing the songs or games frequently.

Interviewer was ranked the third. Nearly half of the participants liked Google Assistant asked short, learner-centered questions, as one GA-Hub participant expressed, ‘It seemed that someone really cares about me!’ They were more willing to divulge personal information and presented their personal viewpoints. Furthermore, some participants in the GA-Mini group mentioned about clearly structured turn-taking and expected content frame in interacting with Interviewer, which created a less anxious listening environment, compared to interacting with the teacher in the conventional classroom.

The majority of the participants agreed that Narrator might improve their listening comprehension but they didn’t like it because ‘it talked most of the time’. Some learners with higher proficiency disliked the passive role, as GA-Mini 90908 complained,

Google (Assistant) talks too much. It narrates about itself, asks me for my views, but then responds with its views or shifts the topic, rather than asks follow-up questions. How about me? I want to talk, too! My opinions? It doesn’t care! (GA-Mini 90908)

Furthermore, Narrator’s long utterances were problematic and difficult to understand for the GA-Mini group. It was perceived as an egocentric interlocutor that held the initiative the most, continued with its own narrative, and ignored learners’ input. In contrast, several participants in the GA-Hub group appreciated Narrator’s effort in providing a variety of knowledge in science, history, culture, etc.

Facilitator was identified as the setting where the participants had the most initiative; however, it received the least support from the participants and was rated the lowest for EFL listening. The participants in the GA-Mini group rated the setting more negatively because they were not proficient enough to take more initiative in the dialogue (Table 7).

# 5.  Discussion

The first research question investigated the impact of Google Assistant on adolescent EFL learners’ listening comprehension. The statistical results showed that there was no significant difference in the listening post-test among the three groups. However, a significant difference was found between the listening pretest and post-test for the GA-Hub group. The GA-Hub group’s listening comprehension improved significantly over time. Given the similar English listening comprehension for the three groups before the intervention, this disparity may be attributed to the impact of interacting with Google Assistant, especially via Google Nest Hub.

Table 7. G A-Hub and GA-Mini groups’ perception of Google Assistant’s interactive roles.   

<html><body><table><tr><td>Interactive role</td><td>Opinions</td><td>GA-Hub (N=31)</td><td>GA-Mini (N= 30)</td></tr><tr><td rowspan="5">Interlocutor</td><td>An equal, friendly conversation partner</td><td>26</td><td>19</td></tr><tr><td>Reduced anxiety</td><td>24</td><td>15</td></tr><tr><td>Listen for real communication purpose</td><td>26</td><td>19</td></tr><tr><td>Peer collaboration</td><td>19</td><td>23</td></tr><tr><td>Scaffolding on communication skills</td><td>17</td><td>14</td></tr><tr><td rowspan="3">Entertainer</td><td>Irrelevant responses</td><td>10</td><td>17</td></tr><tr><td>Edutainment: engaging music and video Flexibility and variety in listening: Games</td><td>28</td><td>19</td></tr><tr><td></td><td>28</td><td>13</td></tr><tr><td rowspan="4">Interviewer</td><td>Improve EFL listening and vocabulary</td><td>20 23</td><td>13 21</td></tr><tr><td>Short, learner-centered question. Structured interaction.</td><td>18</td><td>16</td></tr><tr><td>Develop thinking ability.</td><td>14</td><td></td></tr><tr><td>Difficult English vocabulary</td><td>10</td><td>10 16</td></tr><tr><td rowspan="5">Narrator</td><td>Incoherent questions.</td><td>11</td><td>15</td></tr><tr><td>Enhance EFL listening</td><td>25</td><td>23</td></tr><tr><td>Listen to learn and listen to think</td><td>20</td><td>12</td></tr><tr><td>Peer collaboration</td><td>19</td><td></td></tr><tr><td>Dominate the interaction</td><td>14</td><td>23 19</td></tr><tr><td rowspan="4">Facilitator</td><td>Rate of speech: too fast.</td><td>8</td><td>17</td></tr><tr><td>Peer collaboration.</td><td></td><td></td></tr><tr><td></td><td>13</td><td>16</td></tr><tr><td>A variety of learning topics and tasks Learner&#x27;s inadequate English proficiency</td><td>9 11</td><td>7 16</td></tr></table></body></html>

Interactive listening provides a potential explanation for the GA-Hub and GA-Mini groups’ better listening comprehension. In line with prior research (Tai & Chen, 2020), Google Assistant provided an ideal environment for target language interaction in authentic context. According to Long’s (2017) interaction hypothesis, there is a strong link between listening and speaking. Collaborative conversation is now well established as a vital means of language development and as a benchmark of listening performance. Its potential benefits seem to be both in forcing comprehensible output, that is, compelling the learner to formulate ideas in the target language, and in encouraging negotiation. According to Rost (2016), direct participation in negotiation of meaning is the most effective method for facilitating comprehension of input because the ongoing process of interactional modifications helps learners make stronger connections between form and meaning and creates additional input that is valuable for L2 listening. By contrast, the non-GA group, interacting with the CD, listened but had no possibilities to respond.

Furthermore, listeners were granted the opportunity to interact with Google Assistant in different roles, allowing them to experience the dynamics of interaction as they interacted with native speakers, which result in significant listening gains. . For example, learners could listen for meaningful communication (interlocutor), pleasure (entertainer), gaining knowledge (narrator), and eliciting specific information (interviewer).

The findings provide evidence for some researchers’ (e.g. Field, 2013; Rost, 2016; Vandergrift & Cross, 2018) claim that for effective L2 listening, L2 listeners should be introduced to greater variety in the types of input; the type of listening be closely related to what would be expected in a target real-world context.

Proving immediate responses is another critical feature of Google Assistant. As Vandergrift (2004) indicates, learning occurs when learners get feedback at critical periods of development, which encourages learners to self-correct and enable them to listen to learn. This just-in-time quality is crucial to the effectiveness of listening comprehension because it might reduce EFL learners’ fear of failure, maximize participation and risk taking (Jiang & Dewaele, 2019).

In addition, the GA-Hub and GA-Mini groups’ preference of peer collaboration also contributed to their listening comprehension, which was in accordance with Su and Zou (2020) study that there is a positive correlation between technology-enhanced collaborative learning and students’ development of language knowledge and affective status. According to Ellis (2015), scaffolding is not dependent on the presence of an expert. It can arise in interactions between learners. In peer-peer interaction, learners can act concurrently as experts and novices and support learning through, for example, questioning, proposing possible solutions, disagreeing, and repeating. The collaborative dialogue in which peers engage as they work together on listening help learners correct their errors and enhance comprehension.

Last, similar to prior research (Sandeep, 2019; Tai & Chen, 2020; Wu et  al., 2020), Google Assistant seemed to constitute a more friendly and stress free atmosphere than a conventional classroom. The participants showed fewer inhibitions and displayed less social anxiety, which enabled them to listen in a anxiety-reduced environment and thus enhanced comprehension.

The second research question examined the GA-Hub and GA-Mini groups’ interacting experience with Google Assistant, particularly regarding the effects of presentation mode of responses on EFL listening. The statistical results revealed that the GA-Hub group improved significantly over time, while the GA-Mini group did not. Qualitative analyses revealed several factors contributing to the differences. First, the multimodal presentation of responses (e.g. audio, textual, pictorial, and visual aids), is advantageous over single mode presentation for promoting EFL listening comprehension. The multimodal responses supported the GA-Hub group’s interaction and alleviated difficulties in interpreting information, which is in accordance with Mayer’s (2017) multimedia principle that people learn better from words and pictures than from words alone because processing information through different modalities expands the resources of working memory and increases learning effectiveness. Furthermore, according to Lan and Liao (2018), simultaneous auditory and visual message provides L2 listeners with a direct link between word forms and the underlying meaning and activate their prior knowledge to make appropriate inferences.

Second, the GA-Hub group benefited from the display of query results through on-screen responses. The finding corroborated with Wu et  al. (2020) study that the on-screen responses helped learners bridge the missing parts of the information and made the listening passage more comprehensible. In particular, Google Nest Hub can provide the transcription of learner’s speech output on screen, which might help learners identify exactly what the ASR system does and does not recognize and localize specific lexical items that caused miscommunication. This helps learners, at least for those who with sufficient grammatical knowledge, modify their erroneous utterances. This modification move is claimed to contribute to L2 listening on the basis of Swain’s (2005) output hypothesis and the benefits of comprehensible output that is ‘not only conveyed, but that is conveyed precisely, coherently, and appropriately’ in the context of communicative interaction.

In addition, having visual responses on the Google Nest Hub also reduced burden of having to interpret and retain information for L2 listeners, which was an issue when responses were solely delivered using speech (i.e. when using Google Nest Mini). It was common for the participants in the GA-Mini group to doubt whether they had pronounced words correctly. When they faced communication breakdown, they felt anxious because they had no idea where they got it wrong. In addition to direct repetition, abandonment was a common strategy, which led to limited practicing of speaking and reduced input opportunity. According to Long (2017) and Rost (2016), direct participation in conversation is the most effective method for facilitating listening comprehension because the ongoing process of conversational modifications helps learners make stronger connections between form and meaning and creates additional input that is valuable for L2 listening. Therefore, the GA-Mini group’s reduced speaking and listening opportunity might provide a plausible explanation why their listening comprehension was not improved significantly over time.

Regarding Mayer’s (2017) redundancy principle that the written text on screen is likely to increase cognitive load, the findings, however, revealed that in addition to narration and graphics, the on-screen text provided by Google Nest Hub was imperative for the GA-Hub group’s successful interaction with IPAs. One possible explanation is that some multimedia instruction principles have boundary condition (Mayer, 2017). For example, the redundancy principle can be effective in helping learners handle the task when learners are not native speakers of the language. The on-screen text enhanced comprehension, word recognition, and motivation because text might help L2 learners develop associations with the aural and written forms of words (Lan & Liao, 2018). Furthermore, the written text helped learners identify exactly what the ASR system did and did not recognize and localize specific lexical items that caused miscommunication. Learners have the opportunity to notice gaps and correct errors. According to Chapelle (2003), these processes (e.g. repetitions and modification) mirror those that are hypothesized by interactionist theory to be valuable in conversation and help with comprehension. In addition, the permanence of supplementary visual responses may give L2 learners extra time to process and better comprehend the information. The findings helped to pinpoint the boundary condition under which the redundancy principle can be effective in IPA-assisted EFL listening.

Finally, the multimodality of the information on the screen promoted the GA-Hub group’s in-depth exploration of topics of interest. These inquiries into the unknown naturally increased the GA-Hub participants’ vocabulary, creating additional input, which is valuable for L2 listening and language learning purposes (Ellis, 2021a).

Based on the above finding, it underlines the value of multimodal presentation of Google Assistant responses for promoting EFL listening comprehension. However, it should be noticed that not all participants made favorable comments on the value of Google Assistant for listening comprehension. Some participants in the GA-Hub group echoed problems caused by distractions and cognitive overloading mentioned in previous research. As Rost (2016) indicated, the number of channels a listener can effectively process at one time is limited. These participants were unable to manipulate so much functionality simultaneously and found it difficult to concentrate on the listening activities. In other words, the intertwining multimodal input and output accompanied by real-time interactions had increased the cognitive load and interrupted information processing (Sweller, 2020). Therefore, when designing IPA-based listening activities in the EFL context, the teacher had better consider the presentation mode of responses based on learners’ proficiency (Engwall et  al., 2020).

The third research question concerned with the participants’ preference of Google Assistant’ interaction styles for EFL listening. Interlocutor and Entertainer were the most highly valued interaction roles of Google Assistant. By contrast, Narrator, which held the initiative the most, and Facilitator, which gave learners the most initiative, received the least support. The findings revealed that the higher degree of interaction with Google Assistant was, the more engaged, active, and confident they became, which corroborated with prior research (Vandergrift & Cross, 2018) revealing the benefits of interactive listening for promoting L2 listeners’ motivation and comprehension. Furthermore, multimedia such as music and videos added enjoyment and variety to listening practice. In addition, as Shortt et  al. (2021) indicated, the aim of gamification is to affect behaviors and attitudes relevant to learn and, in turn, to affect learning outcomes. The interview data revealed that a combination of IPA-based learning and gamification engaged learners with goal-oriented listening tasks and evoked interactions in the form of collaboration and competition, which was motivating and beneficial for listening comprehension. The findings also support Rost’s (2016) active listening hypothesis that goal-oriented learners tend to experience an absorption that psychologist call ‘flow’, which contributes to a higher level of comprehension.

By contrast, while Google Assistant acting as a Facilitator, some participants, especially those with lower English proficiency, asked for reduced production due to limited English proficiency, which was in line with Wu et  al. (2020) study revealing L2 learners’ difficulty in taking more initiate in the dialogue. On the other hand, Narrator received less support from the more advanced learners. They would like to take more initiative to propose topics and ask questions, instead of being passive receivers of information. The results indicate that EFL learners at different levels might want Google Assistant to interact differently. As Engwall et  al. (2020) suggest, learners’ proficiency and preference need to be anticipated in order to improve their satisfaction with IPA-assisted EFL listening.

Taken together, the findings showed that interactive listening, multimodal presentation mode of IPA responses, peer collaboration, and gamified IPA-based learning added authenticity, flexibility, and enjoyment for real and meaningful interaction and thus promoted EFL listening.

# 6.  Conclusion

The purpose of this study was to investigate the impact of the IPA (i.e. Google Assistant), especially regarding its presentation mode of responses and interaction style on adolescent EFL learners’ listening comprehension. The results suggested that the participants who used Google Assistant, especially via Google Nest Hub, showed more prominent improvement in EFL listening comprehension than those who learned using only the support of traditional means in the conventional classroom. The GA-Hub group’s listening comprehension was significantly improved over time but not for the GA-Mini and non-GA groups.

Detailed analyses of the experimental-group participants’ interviews demonstrated that in order for IPAs to be maximally effective for EFL listening, four features should be present: (1) interactive listening where learners took a more active role as a participant, joining the conversation equally; (2) multimodal presentation mode of IPA responses, supporting interaction and alleviating listening difficulties and anxiety; (3) peer collaboration in understanding and being understood by IPAs; and (4) an integration of gamification into IPA-based learning was enjoyable, fun, motivating and fascinating to the learners (Shortt et  al., 2021). Furthermore, interacting with different roles played by Google Assistant added variety to listening practice and maintaining learners’ interest for English listening. Interlocutor and Entertainer were the most highly valued interaction roles. By contrast, Narrator, which held the initiative the most, and Facilitator, which gave learners the most initiative, received the least support. The results indicate that the participants favored interactive listening where they could take the role as a participant, joining the conversation equally.

From a pedagogical perspective, the study not only supports the value of IPA-assisted EFL listening, but also provides a deeper understanding of the impact of presentation mode of IPA responses and EFL learners’ preferred IPA interactive styles. Such findings are expected to help the practitioners to identify the appropriate mode of content presentation and interaction styles of IPAs and make informed decisions when adopting IPAs for EFL listening.

Nevertheless, this study is limited by its small-scale sample of participants. To provide more substantial evidence, it is recommended that future studies be undertaken with larger, more diverse samples. Furthermore, differences in language proficiency may influence preferences for Google Assistant’s interaction styles. This is not explored in the present study and such an investigation would be relevant in future work. Questions regarding the comparative effects of IPA interactive styles on EFL learning need further empirical studies. In addition, the order of Google Assistant’s interactive roles in the questionnaire should have been scrambled to avoid a repeated pairwise ranking. Last but not least, this study specifically targeted at English listening. Future research hopefully can investigate leaners’ development and performance in other language skills to provide more comprehensive results on the role of IPAs in facilitating EFL learners’ language learning, helping practitioners make informed decisions on integrating IPAs into curricula.

# Disclosure statement

No potential conflict of interest was reported by the authors.

# Notes on Contributors

Tzu Yu Tai is an Assistant Professor in the Center for English Education, National Tsing Hua University. She also teaches English in Taipei Municipal Hong Dao Junior High School. Her research interests include CALL and TESOL.

Prof. Howard Hao-Jan Chen is distinguished professor of Applied Linguistics in the Department of English at National Taiwan Normal University. Prof. Chen’s research interests include computer-assisted language learning, corpus linguistics, second language acquisition, and second vocabulary acquisition.

# ORCID

Howard Hao-Jan Chen $\textcircled{1}$ http://orcid.org/0000-0002-8943-5689

# References

Bibauw, S., François, T., & Desmet, P. (2019). Discussing with a computer to practice a foreign language: Research synthesis and conceptual framework of dialogue-based CALL. Computer Assisted Language Learning, 32(8), 827–877. https://doi.org/10.108 0/09588221.2018.1535508   
Bibauw, S., François, T., Van Den Noortgate, W. V., & Desmet, P. (2022). Dialogue systems for language learning: A meta-analysis. Language Learning & Technology, 26(1), 1–25. Retrieved from https://serge.bibauw.be/publication/bibauw-et-al-202 2-dialogue-systems-language-learning-meta-analysis/   
Carhill-Poza, A., & Chen, J. (2020). Adolescent English learners’ language development in technology-enhanced classrooms. Language Learning & Technology, 24(3), 52–69. http://hdl.handle.net/10125/44738   
Chapelle, C. A. (2001). Computer applications in second language acquisition: Foundations for teaching, testing, and research. Cambridge University Press.   
Chapelle, C. A. (2003). The potential of technology for language learning. In C. Chapelle (Eds.), English language learning and technology (pp. 35–67). John Benjamins Publishing Company. https://doi.org/10.1075/lllt.7   
Creswell, J. W., & Plano-Clark, V. L. (2011). Designing and conducting mixed methods research. Sage Publications, Inc.   
Dizon, G. (2020). Evaluating intelligent personal assistants for L2 listening and speaking development. Language Learning & Technology, 24(1), 16–26. http://hdl.handle. net/10125/44705   
Ellis, R. (2015). Understanding second language acquisition (2nd ed.). Oxford University Press.   
Ellis, R. (2021a). A short history of SLA: Where have we come from and where are we going? Language Teaching, 54(2), 190–205. https://doi.org/10.1017/ S0261444820000038   
Ellis, R. (2021b). Explicit and implicit oral corrective feedback. In H. Nassaji & E. Kartchava (Eds.), The Cambridge handbook of corrective feedback in second language learning and teaching. (pp. 341–364). Cambridge University Press.   
Ellis, R., & Sheen, Y. (2011). Corrective feedback in language teaching. In Hinkel, E. (Ed.), Handbook of research in second language teaching and learning. (pp. 593–610). Routledge.   
Engwall, O., Lopes, J., & Åhlund, A. (2020). Robot interaction styles for conversation practice in second language learning. International Journal of Social Robotics, 13, 251–276. https://doi.org/10.1007/s12369-020-00635-y   
Field, J. (2013). Cognitive validity. In A. Geranpayeh & L. Taylor (Eds.), Examining listening. (pp. 77–151). Cambridge University Press.   
Istrate, A. M. (2019). The impact of the virtual assistant on language classes. eLearning & Software for Education, 1(1), 296–301. https://doi.org/10.12753/2066-026X-19-040   
Jiang, Y., & Dewaele, J. M. (2019). How unique is the foreign language classroom enjoyment and anxiety of Chinese EFL learners? System, 82, 13–25. https://doi. org/10.1016/j.system.2019.02.017   
Kessler, G. (2018). Technology and the future of language teaching. Foreign Language Annals, 51(1), 205–218. https://doi.org/10.1111/flan.12318   
Lan, Y. J., & Liao, C. Y. (2018). The effects of 3D immersion on CSL students’ listening comprehension. Innovation in Language Learning and Teaching, 12(1), 35–46. https://doi.org/10.1080/17501229.2018.1418242   
Lee, J. S., & Drajati, N. A. (2019). Willingness to communicate in digital and non-digital EFL contexts: Scale development and psychometric testing. Computer Assisted Language Learning, 33(7), 688–707. https://doi.org/10.1080/09588221.2019.1588330   
Long, M. H. (1996). The role of the linguistic environment in second language acquisition. In W. C. Ritchie & T. K. Bhatia (Eds.), Handbook of research on language acquisition. (pp. 413–468). Academic Press.   
Long, M. H. (2017). Instructed second language acquisition (ISLA): Geopolitics, methodological issues, and some major research questions. Instructed Second Language Acquisition, 1, 7–44. https://doi.org/10.1558/isla.33314   
Mayer, R. E. (2017). Using multimedia for e-learning. Journal of Computer Assisted Learning, 33, 403–423. https://doi.org/10.1111/jcal.12197   
Moussalli, S., & Cardoso, W. (2020). Intelligent personal assistants: Can they understand and be understood by accented L2 learners? Computer Assisted Language Learning, 33(8), 865–890. https://doi.org/10.1080/09588221.2019.1595664   
Rost, M. (2016). Teaching and Researching Listening (3rd ed.). Routledge.   
Sandeep, S. S. (2019). Learning English language through Amazon Alexa for Indian students. Journal of the Gujarat Research Society, 21(10), 619–622.   
Shortt, M., Tilak, S., Kuznetcova, I., Martens, B., & Akinkuolie, B. (2021). Gamification in mobile-assisted language learning: A systematic review of Duolingo literature from public release of 2012 to early 2020. Computer Assisted Language Learning. Advance online publication. https://doi.org/10.1080/09588221.2021.1933540   
Swain, M. (2005). The output hypothesis: theory and research. In E. Hinkel (Ed.), Handbook of research in second language teaching and learning. (pp. 471–483). Lawrence Erlbaum Associates.   
Su, F., & Zou, D. (2020). Technology-enhanced collaborative language learning: Theoretical foundations, technologies, and implications. Computer Assisted Language Learning. Advance online publication. https://doi.org/10.1080/09588221.2020.1831545   
Sweller, J. (2020). Cognitive load theory and educational technology. Educational Technology Research and Development, 68, 1–16. https://doi.org/10.1007/ s11423-019-09701-3   
Tai, T. Y., & Chen, H. J. (2020). The impact of Google Assistant on adolescent EFL learners’ willingness to communicate. Interactive Learning Environments. Advance online publication. https://doi.org/10.1080/10494820.2020.1841801   
Underwood, J. (2017, August 23–26). Exploring AI language assistants with primary EFL students. In K. Borthwick, L. Bradley, & S. Thouësny (Eds.), CALL in a climate of change: Adapting to turbulent global conditions (pp. 317–321). Research-publishing. net. https://doi.org/10.14705/rpnet.2017.eurocall2017.733   
Vandergrift, L. (2004). Listening to learn or learning to listen? Annual Review of Applied Linguistics, 24, 3–25. https://doi.org/10.1017/S0267190504000017   
Vandergrift, L., & Cross, J. (2018). Metacognitive Listening Strategies. In The TESOL Encyclopedia of English language teaching (pp. 1–6). John Wiley & Sons, Inc.   
Wu, Y., Rough, D., Bleakley, A., Edwards, J., Cooney, O., Doyle, P. R., Clark, L., & Cowan, B. R. (2020, October). See what I’m saying? Comparing intelligent personal assistant use for native and non-native language speakers. In  MobileHCI ‘20: 22nd International Conference on Human-Computer Interaction with Mobile Devices and Services  (pp. 1–9). ACM. https://doi.org/10.1145/3379503.3403563   
Xie, Y., Chen, Y., & Ryder, L. H. (2021). Effects of using mobile-based virtual reality on Chinese L2 students’ oral proficiency. Computer Assisted Language Learning, 34(3), 225–245. https://doi.org/10.1080/09588221.2019.1604551   
Zhang, R., & Zou, D. (2020). Types, purposes, and effectiveness of state-of-the-art technologies for second and foreign language learning. Computer Assisted Language Learning. Advance online publication. https://doi.org/10.1080/09588221.2020.1744666

# Appendix A

# Typology of Google Assistant (GA)-mediated interaction with examples

<html><body><table><tr><td>Role</td><td>Interaction</td><td></td><td>Dialogue excerpt</td></tr><tr><td>Interviewer</td><td>GA has the initiative,</td><td>GA:</td><td>Nice to meet you.</td></tr><tr><td></td><td>sequentially ask questions,</td><td>S:</td><td>Nice to meet you, too.</td></tr><tr><td></td><td>and drives the conversation,</td><td>GA:</td><td>Where are you from?</td></tr><tr><td></td><td>focusing on learners,</td><td>S:</td><td>I am from Taiwan.</td></tr><tr><td></td><td>without providing much</td><td>GA:</td><td>Is this your first year in London?</td></tr><tr><td></td><td>information about itself or</td><td>S:</td><td>No, I have been living in London</td></tr><tr><td></td><td>its own opinions.</td><td>GA:</td><td>for two years. What are you studying?</td></tr><tr><td></td><td></td><td>S:</td><td>English literature.</td></tr><tr><td> Narrator</td><td></td><td>GA:</td><td>Sounds cool.</td></tr><tr><td></td><td>1. GA aims to convey its</td><td>S:</td><td>What is COVID-19?</td></tr><tr><td></td><td>opinions or some knowledge</td><td>GA:</td><td>Coronavirus disease is an</td></tr><tr><td></td><td>to learners. It maintains the</td><td></td><td>infectious disease caused by</td></tr><tr><td></td><td>initiative and talks most of</td><td></td><td>the SARS-CoV-2 virus. Most</td></tr><tr><td></td><td>the time.</td><td></td><td>people experience mild to</td></tr><tr><td></td><td>2. The content includes a</td><td></td><td>moderate symptoms and</td></tr><tr><td></td><td>semi-monologue.</td><td></td><td>recover without special</td></tr><tr><td></td><td>3. Learners can practice asking</td><td></td><td>treatment. However, some will</td></tr><tr><td></td><td>for information in real-life</td><td></td><td>become seriously ill and require medical attention.</td></tr><tr><td></td><td>scenarios.</td><td></td><td>(Hub: illustrate with COVID-19</td></tr><tr><td> Facilitator</td><td>1. GA aims to get the two</td><td>GA:</td><td>pictures) Who is your favorite Science</td></tr><tr><td></td><td>learners to talk with each</td><td></td><td>Fiction author?</td></tr><tr><td></td><td>other and to interfere as</td><td>S1:</td><td>Book or film?</td></tr><tr><td></td><td>little as possible. For</td><td>GA: S1:</td><td>Books.</td></tr><tr><td></td><td>example, GA, acting as a quizmaster, stimulates</td><td>S2:</td><td>J. K. Rowling.</td></tr><tr><td></td><td>learners to discuss and come</td><td></td><td>Author famous for writing the Harry Potter series of books.</td></tr><tr><td></td><td>up with the answers</td><td>S1:</td><td>Yeah, I like her books.</td></tr><tr><td></td><td>together.</td><td>S2:</td><td>Have you told her how you feel?</td></tr><tr><td></td><td>2. GA asks general, open</td><td>S1:</td><td>No. I don&#x27;t write to her.</td></tr><tr><td></td><td>questions, addressed at both</td><td>GA:</td><td>Why not? No need to be shy.</td></tr><tr><td></td><td>learners simultaneously, and</td><td>S2:</td><td>Could you help us send the</td></tr><tr><td></td><td>encourage learners to</td><td></td><td>messages to her?</td></tr><tr><td></td><td>choose topics to discuss.</td><td>GA:</td><td>Okay!</td></tr><tr><td>Interlocutor</td><td>1. GA aims to establish a</td><td>S:</td><td>You are not talkative.</td></tr><tr><td></td><td>three-party interaction.</td><td>GA:</td><td>Are you kidding? I do nothing but</td></tr><tr><td></td><td>2. GA is more personal,</td><td></td><td>talk.</td></tr><tr><td></td><td>providing information about</td><td>S:</td><td>(Haha!)</td></tr><tr><td></td><td>itself.</td><td>GA:</td><td>I made you laugh! Human</td></tr><tr><td></td><td>3. The initiative is more shared.</td><td></td><td>emotions are difficult for me</td></tr><tr><td></td><td>4. Learners can have a casual</td><td></td><td>to understand! My master will</td></tr><tr><td></td><td>conversations with GA; users</td><td></td><td>be pleased I made you laugh.</td></tr><tr><td></td><td>are free say or ask anything</td><td></td><td></td></tr><tr><td>Entertainer</td><td></td><td>S:</td><td>Hey, Google. Let&#x27;s play a game.</td></tr><tr><td></td><td>1. GA plays games with</td><td>GA:</td><td>I have a few options for that.</td></tr><tr><td></td><td>learners.</td><td></td><td>Which one would you like to</td></tr><tr><td></td><td>2. GA itself can sing songs to</td><td></td><td></td></tr><tr><td></td><td>amuse learners, interacting</td><td></td><td>try? (Hub: Showed the games</td></tr><tr><td></td><td>in a funny way.</td><td></td><td>on screen)</td></tr><tr><td></td><td></td><td>S:</td><td></td></tr><tr><td></td><td>3. GA can play music and</td><td></td><td>My Smart Pet!</td></tr><tr><td></td><td> videos from YouTube.</td><td>GA</td><td>Let&#x27;s start!</td></tr></table></body></html>

# Appendix B

# Questionnaire: Rating of Google Assistant’s interaction styles

Place a number in the column that indicates the extent to which you like with each interactive role of Google Assistant based on your interacting experience with it: 1 (least like) to 5 (strongly like)

<html><body><table><tr><td>Role</td><td>Degree of likeness 1-&gt;5</td></tr><tr><td>Interlocutor</td><td></td></tr><tr><td> Narrator</td><td></td></tr><tr><td>Interviewer</td><td></td></tr><tr><td>Facilitator</td><td></td></tr><tr><td>Entertainer</td><td></td></tr></table></body></html>

# Appendix C

# Semi-structured interview questions

1. How do you feel about Google Assistant via Google Home Hub/Google Home Mini for EFL listening?   
2. Which interactive style of Google Assistant do you like most and find most beneficial for your English listening? Why?   
3. What are the challenges you have encountered while interacting with Google Assistant?