# Exploring the dynamics of student engagement with receiving peer feedback in L2 writing

Yuge Zhanga, Ying Gaob,\*

School of Foreign Languages, Northeast Normal University, Changchun, China ' MOE Language Training Center and School of Foreign Languages, Northeast Normal University, Changchun, China

# ARTICLEINFO

# ABSTRACT

Keywords:   
Student engagement   
Peer feedback   
Dynamic change   
L2 writing

Although research on student engagement with peer feedback in second and foreign language (L2) writing has attracted some attention in recent years, there has been little emphasis on the dynamic changes in and factors influencing student engagement. Drawing on multiple data sources, we explored how six undergraduate students affectively, cognitively, and behaviorally engaged with receiving peer feedback across three writing cycles in an online TOEFL writing course. The findings revealed that L2 students' engagement with peer feedback was complex, dynamic, and nonlinear. Affectively, the students experienced fluctuating emotions across tasks, which directly contributed to changes in their behaviors, as positive emotions promoted feedback implementation, while negative emotions hampered it. Cognitively, the students showed dynamic difficulties in understanding peer feedback across tasks, which triggered negative emotions and inappropriate revisions, and noticing/understanding feedback did not guarantee the use of cognitive strategies. Behaviorally, the students manifested different trends of implementing peer feedback and deployed a variety of observable revision strategies across the three writing cycles. Overall, the dynamics of student engagement with receiving peer feedback were found to be influenced by a number of individual and contextual factors, indicating the malleability of L2 students' engagement with peer feedback.

# 1. Introduction

The value f pr feedback/review in L2 writing has been widely recognized (Gao et al, 2019; Min, 2006; Nelson & Schunn, 2009) However, its efectiveness ultimately depends on the way in which students engage with it (Jin et al., 2022; Mulder et al., 2014; To, 2021), and it could be unproductive without engagement (Price et al., 2011; Tsao, 2021). In contrast to the wealth of research on student engagement with reeiving teacher feedback (Han & Hyland, 2015; Hyland, 2003; Zheng & Yu, 2018; Zheng et al., 2020), student engagement with receiving peer feedback remains inadequately explored. Among the limited number of studies, some have focused on a single dimension of engagement, such as student behavioral engagement in the context of peer feedback uptake through revision operations and strategies (Diab, 2011; Min, 2006; Yu & Lee, 2016), while those investigating multiple dimensions have mostly been conducted within a single round of writing tass (Fan & Xu, 2020; Yu et al., 2019). Language learning engagement is malleable and dynamic in nature (Fredricks et al., 2004; Zhang & Hyland, 2018), and a longitudinal observation acros writing and reviewing tasks could reveal more changes and complexitie regarding student engagement in peer review. However, "research investigating developmental trajectories of engagement remains rare' (Hiver e al., 2021: 4). Furthermore, given that the relationships among the multiple dimensions of engagement are reciprocal rather than static (Kim & Kim, 2020), there is a need to further explore the dynamism of student engagement with peer feedback from a multi-dimensional perspective on various timescales.

Drawing on multiple data sources, including pr comments, draft, semi-structured interviews, and stimulated recall, this study examines how si undraduat stdnts afectively, contively, and bhaviorally engged wth recevig peerfedack acoss three writing and reviewing cycles in an online L2 writing context. By tracing the developmental trajectories of students engagement with peer feedback across a term, we attempt to uncover the nature of students' dynamic and emergent engagement and the factors influencing them. Hopefully, the study could further our knowledge of the dynamics of learner engagement in per feedback and provide pedagogical implications for future peer feedback practices in L2 writing.

# 2. Literature review

# 2.1. Conceptualizing student engagement with peer feedback

Student engagement isthe extent to which students commit to their learning (Cheng & Liu, 2022; Zhang & Hyland, 2018). Although new constructs of engagement, such as academic (Apleton et al., 2006) and agentic (Reeve & Tseng, 2011; Wang & Lee, 2021) engagement, have ben proposed, student engagement has generally encompassed three dimensions: affct/emotion, cognition, and behavior (Fredricks et al., 2004; Kahu, 2013; Tian & Zhou, 2020). This three-dimensional framework has been widely adopted to explore student engagement with feedback in L2 writing (Ells, 2010; Koltovskaia, 2020; Yu et l., 2019 Zhang & Hyland, 2018; Zheng & Yu, 2018).

Affectie engagement refers to students affecive reactions in the classroom, such as interest, boredom, anxiety, sadness, and happiness (Fredricks et al., 2004). In fedback actvitie, affective engagement is commonly framed as students' emotional responses and attitudinal reactions t fedback (Ellis 2010; Han & Hyland, 2015), including interest (willingnes to reive fedback), value (evaluation of the worth of feedback), and affect (emotions toward feedack) (Fan & Xu, 2020). It has been argued that such def. nitional inclusiveness can lead to definitional overlap, including i relation to motivation (Fredrics et al., 2004), and value, as the causal factor haping engagement, should be investigated separately (Zhang et al. 2023). To avoid conceptual confusion and focus on the trajectries of students' affectie reactions to receiving peer feedback, the current study examined affective engagement with respect to emotional valence, including positive (e, enjoyment, relaxation, and gratitude) and ngative (e, anger, frustration, and hopelessness) (Pekrun & Linnenbrink-Garcia, 2012) states.

Cognitive engagement is the extent of students cognitive response to feedback (Elli, 2010). To explore students' engagement with teacher written corrctive feedback, Han and Hyland (2015) categorized cognitive engagement into three sub-constructs: depth of processing feedback (noticing and understanding feedback), cognitive operations (e.g., reasoning) regarding the mental effort that students spend on processing feedback and generating revisions, and metacognitive operations (e.g., planning for cognition), which regulate the mental effrt that students exert while processing feedback. The present study adopted Han and Hyland's (2015) taxonomy with two minor adaptations. First, students' processing of feedback was categorized into noticing and understanding, as obvious distinctions emerged in our data. Although students generally noticed feedback, they ofen failed to or spent es efort un. derstanding it. Second, cognitive and metacognitive operations were combined into one sub-construct for two reasons: (1) the overlap between cognitive and metacognitive operations makes it conceptually and practicallydifficult to separate them (e.g., \*valuating) can be both); and (2) the limited amount of metacognitive investment (when i occurs) is found mostly consistent with that of cognitive investment. Therefore, i is rational and operational to merge the two so as to better present the dynamics of degre (high, mid, and low) and tendency (growing and declining) of student cognitive engagement.

Behavioral engagement involves both the revision operations (feedback uptake) and revision strategies that students deploy to proces feedback and improve writing (Han & Hyland, 2015), such as consulting the Internet (Koltovskaia, 2020). In line with Yu et al (2019) and Fan and Xu (2020), who focused on student engagement with receiving per feedback, the current study investigated behavioral engagement by examining students' revision operations in response to peer feedback and the observable strategies they deployed.

From the above analysis, a multi-dimensional analytical framework for engagement with receiving peer fedback i shown below.

Affective engagement refers to students' emotional reactions to receiving per feedback and is examined through the valence of emotions, including positive and negative states.   
Cognitive engagement refers to students' cognitive investment in processing peer feedback, manifested in the depth of processing peer feedback at the levels of noticing and understanding and the adoption of cognitive and/or metacognitive operations to process peer feedback and generate revisions.   
Behavioral engagement concerns students revision operations in response to per feedback and the observable strategies they deploy to process peer feedback and revise their writing.

# 2.2. Studies on student engagement with peer feedback

Theoretically, students who engage with peer feedback can be scaffolded across their zones of proximal development (ZPD) through sociocultural interactions (Frawley & Lantolf, 1985; Saeed et al., 2018; Tian & Zhou, 2020). Feedback uptake and L2 writing can be enhanced through such sococultural interactions, as the joint construction of meaning allows students to develop L2 learning by transferring from other- t self-regulation (Lantolf & Pavlenko, 1995; Villamil & de Guerro, 2006). When students are isengaged from the feedback process, their learning opportunities are limited (Price et al., 2011).

Previous studies on student engagement with peer fedback have focused on the behavioral dimension of engagement, mostly in terms of revision operations and strategies (Diab, 2011; Min, 2006; Patchan et al., 2016; Yu & Le, 2016). These studies found thal student engagement with feedback was crucial to effective feedback uptake and L2 learning (To, 2021; Winstone et al., 2017); however, a comprehensive picture of student engagement with peer feedback is needed to explain the complexities underlying students' revision operations.

Although limited in number, studies adopting a multi-dimensional perspective to explore student engagement with receiving peer feedback have pointed to various complextie. u et al. (2019) studied theaffective, conitive, and behavioral engagment of master's students with per feedback in academic writing and found that the relationships among the sub-constructs of each dimension as wel as among the thre dimensions were interconnected in complex ways. For instance students valued peer feedback but held different personal judgements of it, and thir afectie engagement either promoted or hampered their behavioral and cognitive engagement. Despite positive attitudes toward per feedback, their cognitive investment was insuficient, and they only responded to a small proportion of feedback regarding thesis revision, thereby demonstrating superficial cognitive and behavioral engagement. However, Fan and Xu (2020) found that universty EFL students manifested both positive and negative emotions and extensive cognitive and behavioral engagement. In particular students deployed a variety of cognitive and metacognitive operations and responded to $9 5 \%$ of form-focused feedback. Although the above studies were conducted in similar L2 learning contexts, some of their findings were contradictory, and further research is needed to better understand the benefits of engaging with receiving peer feedback.

Additionally, an important characteristic of student engagement is its dynamism (Aubrey, 2022; Reschly & Christenson, 2012), given that it is a proces rather than a product (Price et al., 2011) and that the relationships among the multiple dimensions are reciprocal rather than static (Kim & Kim, 2020). Furthermore, research on engagement dynamics has advocated for larger timescale studies (e.g, between tasks) (Aubrey, 2022; Aubrey et al., 2020; Tian & Zhou, 2020), while studies on student engagement with receiving peer fedback have mainly been conducted over shorter timescales (e., with one task). Therefore, there is an urgent need for inquiry into the dynamic changes in L2 students' engagement with receiving peer feedback in the long run.

Further, student engagement is a complex processin which both individual and contextual factors come into play (Price et al. 2011; Zhang, 2017). For example, the factors influencing student engagement with teacher fedback or automated written evaluations include language aptitude, goals, and feedback sources (Elis, 2010; Han & Hyland, 2015; Zhang & Hyland, 2018). Moreover, some individual (eg., peronal beliefs) and contextual (e. ral intraction) factors have been found to account for the callenge rgarding student engagement with peer feedback (Fan & Xu, 2020). However, there is a knowledge gap around how specifi factors actually function for individual students and across contexts.

Therefore, the present study investigated the complex and dynamic nature of students' afective, cognitive, and behavioral engagement with pee feedback on a roader timecal across thee tasks in a semester) in an online 2 writig context and explored the underlying reasons for student (dis)engagement. Specifically, this study intended to answer the fllowing research questions:

(a) How did L2 students' engagement with peer feedback change across tasks? (b) What factors influenced student engagement with peer feedback?

# 3. Methodology

# 3.1. Research context and participants

The study took place at a research-oriented university in northeast China during the CoviD-19 period. An online TOEFL (Test of English as a Foreign Language) writing course was organized by the first author, who has 10 years TOEFL training experience. This 18- week course was composed of lectures on TOEFL writing, peer review training, and three writing practice cycles using peer review. According to the course plan, the instruction specialized in TOEFL independent writing (an argumentative essay with no upper word limit), covering aspects of content and language skills in accordance with the official rubrics of TOEFL writing. The students were trained in how to provide feedback, implement peer comments into their revision, and provide back-evaluations (fedback on

Table 1 Students' profiles.   

<html><body><table><tr><td>Code</td><td>Age</td><td>Major</td><td>TOEFL scores (Language proficiency)</td><td colspan="6">Writing scores</td></tr><tr><td></td><td></td><td></td><td></td><td colspan="2">T1 (Task 1)</td><td colspan="2">T2 (Task 2)</td><td colspan="2">T3 (Task 3)</td></tr><tr><td></td><td></td><td></td><td></td><td>D1</td><td>D2</td><td>D1</td><td>D2</td><td>D1</td><td>D2</td></tr><tr><td>A</td><td>20</td><td>English</td><td>101 (high)</td><td>80</td><td>83</td><td>83</td><td>87</td><td>85</td><td>89</td></tr><tr><td>B</td><td>22</td><td>Education</td><td>97 (high)</td><td>78</td><td>80</td><td>79</td><td>81</td><td>70</td><td>74</td></tr><tr><td>c</td><td>21</td><td>English</td><td>86 (mid)</td><td>73</td><td>75</td><td>73</td><td>74</td><td>77</td><td>80</td></tr><tr><td>D</td><td>20</td><td>Finance</td><td>79 (mid)</td><td>70</td><td>74</td><td>74</td><td>80</td><td>87</td><td>91</td></tr><tr><td>E</td><td>22</td><td> Management</td><td>64 (low)</td><td>68</td><td>72</td><td>64</td><td>66</td><td>63</td><td>64</td></tr><tr><td>F</td><td>21</td><td> Management</td><td>42 (low)</td><td>46</td><td>52</td><td>40</td><td>41</td><td>38</td><td>39</td></tr></table></body></html>

Note: Pairing in T1: A-C, B-E, D-F; T2: A-F, B-D, C-E; T3: A-B, C-D, E-F.

1BiJ X   
18 butter Here doing things they don't want to do is an unpleasant experience, so the phrase decide tois not very good. because it seems like you have made great determination to not do it, isnt that strange? My suggestion is using the phrase have to", which means you are compelled to do it. butter # It has grammar mistake, and my suggestion is: which is named by these people as responsibility. butter # I think here the pause of sentence is not very good. That is, your sentence is too long, which can prevent readers from understanding your content flly or clearly. A

![](img/d3edd923963b72c36135534d01602d9a503b8c1c573e4d8767daa8ea5e670a07.jpg)  
Fig. 1. A screenshot of peer feedback alongside a student's draft.

comments rceived). Three rounds of writig and review practie each lasting 4 weeks) were arranged as after-las assignments, each involving writing a first draft (D1) on a given topic, reviewing a peer's writing and providing comments in English, giving backevaluations on peer feedack, revising D1 in accordance with peer feedback, and submitting a revised draft (D2) to the teacher in Microsoft Word format. The assignments were chosen from authentic TOEFL writing tests (see Appendix A). Tencent Meeting, a synchronous videoconferencing a, was used for lectures and peer review training; WeChat, an instant messaging app, was used by the teacher and students to communicate after clas. Students' drafts and comments were collected and distributed through email.

Six female undergraduate students who were highly motivated to pass the TOEFL signed up for the course. They were coded in terms of their language proficiency acording to previous TOEFL test scores (see Table 1). They all expressed their willingness to participate in this study and completed all the tasks.

All online lectures, training, and review tasks proceeded anonymously, and the students only knew that all their classmates were female. In each review task, they were purposely asigned to three pairs and conducted one-to-one peer review. We ensured that they worked with peers of varying proficiency levels across the three tasks. Fig. 1 demonstrates a peer feedback interface.

# 3.2. Data collection

The data were collcted throughout the duration of the tasks (i.e., over 18 weeks) and included three original drafts with peer feedack, back-evaluations on the pe fedack, thre revise drafts, two sem-structurd interviews, and three stimulated recalls for each student. Textual and qualitative data from the stimulated recall were collected immediately after the corresponding writing and review practice. The teacher, together with a trained PhD candidate experienced in teaching TOEFL writing, graded the students first and revised drafts in the three tasks. Inter-rater reliability between the two raters was 0.94.

The semi-structured interviews were conducted in weeks 1 and 18 with each of the six students and focused on their background information and engagement with per feedback from multiple dimensions (see Appendix B for the interview guide). On average, the two interviews and thre stimulated recall for each student lasted about two hours through Tencent Meeting and were conducted in Chinese (the native language of the students) for ease of communication.

In total, the research data consisted of 36 draft, 18 peer feedback documents, 18 back-evaluation documents, three hours of in terviews, and nine hours of stimulated recall. The first researcher transcribed all the recordings and translated the transcripts into English. The second researcher checked the accuracy against the original materials.

# 3.3. Data analysis

Student engagement was measured qualitatively and quantitatively across three fedback activities. In particular, the qualitative data, which included semi-structured interviews, stimulated recall, and back-evaluations, were nalyzd along three first-level codes and six second-level codes based on the analytical framework in 2.1 (see Table 2).

Referring to previous research (Zhang et al., 2023), a dominant approximate level high (H), medium (M), or low (L)-was adopted to code allthe qualitative data on student engagement. Given the likelihood of some variaility across the data collected from the stimulated recall, interviews, and back-evaluations, we identified and reported the most common character across time and sources as the indicator of each engagement dimension.

Affective and cognitie engagement were measured through qualitative coding. Specificll, the students emotional reactions toward peer feedback were coded as H (predominantly positive emotions), L (predominantly negative emotions), and M (mixed valence emotions) based on the stimulated recall and interview data.

Furthermore, by inquiring into the students cognitive investment in each instance of feedback in the stimulated recalls, we were able to classfy their cognitie engagement with each sub-dimension into thre levels high (H), medium (M), and low (L), signifying that one has noticed, understood, and used cognitive and/or metacognitive strategies on all fedback (H), more than half of the feedback (M), and fewer than half f the fedback (L). The overall level was calculated by averaging the total percentage of the three sub-dimensions. Furthermore, although not included in the calculation, back-evaluations served as a reference to further explore explanations relating to student engagement, for example, designing stimulated recall questions to probe mismatches between responses such as "I agree with you' in the back-evaluation and no actual implementation of the corresponding comment i the revision.

Table 2 Qualitative data codes and examples.   

<html><body><table><tr><td>First-level codes</td><td>Second-level codes</td><td>Examples from the present study</td></tr><tr><td>Affective</td><td>Positive emotions</td><td>I really enjoyed the process of receiving feedback. (A in Task 1)</td></tr><tr><td>engagement</td><td>Negative emotions</td><td>The reviewer&#x27;s comments made me a little embarrassed. (F in Task 1)</td></tr><tr><td>Cognitive engagement</td><td>Depth of processing peer feedback at the level of noticing</td><td>I just overlooked this comment. (E in Task 1)</td></tr><tr><td></td><td>Depth of processing peer feedback at the level of understanding</td><td>I cannot understand the comment as the grammar is so confusing. (D in Task1)</td></tr><tr><td></td><td>Using cognitive and/or metacognitive strategies</td><td>The reviewer advised me to change &quot;do&quot; into &quot;doing&quot;, but I think it was incorrect. (B in Task 2)</td></tr><tr><td>Behavioral engagement</td><td>Using observable revision strategies</td><td>I searched online and changed &quot;imparted&quot; into &quot;taught&#x27;. (B in Task 1)</td></tr></table></body></html>

Behavioral engagement was measured both quantitatively and qualitatively. A major indicator of student behavior was peer feedback uptake. We first conducted textual analysis based on a coding scheme adapted from Wu and Schunn (2020) to clean the data of comments. ll the comments were separated into independent idea units, each of which raised and/or slved one problem on one dimension of the students' writing. A total of 339 idea units were produced, which were further coded into 303 implementable comments that could trigger revision and 36 non-implementable comments (e.g., summaries or praise). The non-implementable comments were excluded from further analysis, as they could not trigger revision, while the implementable ones were further coded into high-level feedback (comments on content, idea development, coherence, and organization) and low-level feedback (comments on vocabulary, grammar, selling, and mechanics). The comparison function of Microsoft Word was then used to compare the students' original and revised drafts to determine their revision operations in response to the peer fedback. The revisions were further classified into high and low levels in line with the scope of peer feedback.

The qualitative coding of behavioral engagement concerned students' adoption of revision strategies. Regarding the students selfreports in the stimulated recals and interviews, frequent use of revision strategies was coded as H, occasional use M, and almost or completely no use L.

To identify the individual and contextual factors influencing student engagement with per feedack, we further conducted within case analysis on the stimulated recall and interview data and adopted cros-case analysis to compare the findings from allsix students (Yin, 2011).

# 4. Findings

# 4.1. Student engagement with peer feedback

# 4.1.1. Student affective engagement with peer feedback

In exploring the students' affectie engagement with peer feedback that is, their emotional reactions to reeiving per feedback we found that they had manifested a variety of positive and negative emotions, which fluctuated within and across the three writing cycles (see Table 3). Generall, the students emotional states tended to be negative in 1-with three at level L, one at level M, and two at level H--becoming more negative in T2 but significantly more positive in T3, with four at level H and two at level L.

In particular, the high-proficiency students manifested mixed emotions in T1 before turning fully negative in T2 and positive in T3. For instance, B was frustrated and disappointed about the confusing feedback from T1 and became increasingly negative in T2 when she again received \*unclear comments." However, even though B was not satisied with all the comments received in T3, she grew positive. Compared to reviewers from previous tass, B seemed to be more tolerant of the third reviewer and began focusing on the positive side. Ase clamed, There i some deficiency in her comment..but a lest she was careful in atitude. and her comments were easy to understand."

The mid-proficiency students grew increasingly positive across the three tasks. For example, D felt\*stressed out and \*frustrated" about the \*confusing comments in T1 and T2, which lowered her expectations regarding peer fedback. Therefore, when she received high-quality comments in T3, she grew very ecited.enjoyed it so much! It was as good as teacher fedback," said D in the stimulated recall. Meanwhile, neative emotions transformed into positive ones within singletass. Despite frustration, also expressed gratitude toward the first two reviewers in the interview: "I know that my essays are very long, and they had already done their best.. til appreciate their help."

Unfortunately, the two low-proficiency students changed from experiencing mixed emotions to becoming fully negative over time. Specificly,  enjoyd the first task wherethe reviewer providd indirect crtical fdback and praise. Epecting ut faiing to receive comments of a similar nature in T2, she developed various negative emotions. 'She did not tell me exactly what to do, like the last reviewer.. [he wa] toodirect... was quite annoyd," said  i the real. Faig to eeive expected fedack agan in 3, E became hopeless and began questioning whether she could make good use of peer feedback.

# 4.1.2. Student cognitive engagement with peer feedback

Student cognitive engagement with peer feedback was investigated from three sub-dimensions, each manifesting different fluc. tuation levels across the three tasks (ee Table 4). Similar to student emotions, overall cognitive engagement manifested a swing pattern, which began with four students at level M and two at levelH in T1, one t level M dropping to level L in T2, and two at level M advancing to level H in T3. In particular, the high- and mid-proficiency students demonstrated an increasing trend, while the low-level students evinced the opposite.

Table 3 Fluctuations in students' emotions regarding peer feedback.   

<html><body><table><tr><td></td><td>T1</td><td>T2</td><td>T3</td></tr><tr><td>A</td><td>H (enjoyment; pleasant surprise; gratitude)</td><td>L (frustration; disappointment)</td><td>H (enjoyment; empathy)</td></tr><tr><td>B</td><td>L (frustration; disappointment)</td><td>L (frustration; disappointment; anger).</td><td>H (contentment; relief)</td></tr><tr><td>c</td><td>L (embarrassment; shame)</td><td>H (enjoyment; gratitude)</td><td>H (enjoyment; empathy)</td></tr><tr><td>D</td><td>M (stress; frustration; gratitude)</td><td>M (frustration; gratitude)</td><td>H (enjoyment; excitement)</td></tr><tr><td>E</td><td>H (enjoyment; relief, gratitude)</td><td>L (frustration; anger; embarrassment)</td><td>L (frustration; disappointment; hopelessness)</td></tr><tr><td>F</td><td>L (embarrassment; frustration; anger)</td><td>L (frustration; shame)</td><td>L (frustration; disappointment)</td></tr></table></body></html>

Processing peer feedback at the level of noticing. Five students maintained a high level of noticing peer feedback across the three tasks. Only one comment in T1 was overlooked by E. I know I should write back-evaluation on each piece of comment received...I just missed it..." said E in the stimulated recall.

Processing peer feedback at the level of understanding. In contrast to the high level of noticing fedback, the level of understanding feedack fluctuated significantly acrossthe three writing cycles. Upon receiving a vague comment in T1, B expressed her confusion in the stimulated recall: "She wrote a long paragraph, but Ididn't see much difference with my writig... What did she mean?" D encountered similar ssues in T1: Her comments were poor in grammar..I's so hard to understand," said D in the stimulated recall. However, two rounds of practices seemed to increase the qualit of the comments alongside the students' level of understanding. All high- and mid-proficiency students fully understood the peer feedback in T3.

Two low-proficiency leaners were found to have dificulty understanding peer feedback, especiall F, who maintained a low level of understanding throughout. For instance, she received a comment in 2 (\*This run-on sentence is to long. Please cut it into several short sentences.) but did not understand it and complained in the stimulated recall, I was speechless. Why is a long sentence problematic?".

Deploying cognitive and/or metacognitive operations. Noteworthil, four high- and mid-proficiency students utilized exten. sive cognitive and metacognitive strategies to process their feedback and make revisions across the three writing cycles (see Table 4), such as evaluating the appropriatenes and accuracy of the peer feedback, reflecting on the writing, and monitoring revision quality. For instance, A was advised to change search and discovery to searching and discovering" in T2. She did not accept it and relie in the back-evaluation, I think both are fine." I had doubts about this, and I checked online. I'm sure there is nothing wrong with this phrase, so I didn't revise it, said A in the stimulate recall Meanwhile, a mid-level understanding i T1 and T2 did not hinder D's use of cognitie and metacognitive strategies regarding pr feedback. Although she implemented few comments in the first two tasks, she was found to carefully evaluate each comment and justifiably reject reviewer suggestions.

In contrast, the level at which E and F adopted cognitive and metacognitie operations decreased over time and tended to be casual, incomplete, and inaccurate. In T3, continuous disappointment about feedback seemed to diminish E's patience, which led her to decline the use of cognitive strategies. Nevertheles, she acepted most comments and revised based on \*language intuition." For example, the reviewer incorrectly advised E to add is" ater it in the sentence I find it hard to breathe when I do sports," and she accepted it because \*it sounds better." Noteworthily, D's deliberate rejection of peer fedback contrasted sharply with E's careles acceptance of it, suggesting a mismatch in their cognitive and behavioral engagement.

# 4.1.3. Student behavioral engagement with peer feedback

The students' behavioral engagement with peer feedback was manifested in their feedback implementation and adoption of observable revision strategie. Textual analysis on the students' drafts indicated that they made revisions on both high- and low-level issues, with their feedback implementation rate fluctuating significantly across the three writing cycles (see Table 5).

Overall, the students implemented $5 8 \%$ of the feedback, increasing from T1 $( \mathrm { M } = 5 1 \%$ $\mathrm { S D } = 0 . 3 1 $ ) to T2 $( \mathrm { M } = 4 6 \%$ $\mathrm { S D } = 0 . 1 7 )$ and T3 $\mathbf { M } = 8 0 \%$ $\mathrm { S D } = 0 . 1 8 )$ , with the lowest implementation rate increasing from $1 4 \%$ to $1 0 0 \%$ . The SD values reveal that the large variation in the implementation rate among the students in T1 grew increasingly smaller in T2 and T3.

Specificall, the students manifested varying patterns in feedback uptake, including upward swing patterns by A, B, D, and E, an increasing pattern by C, and a downward swing pattern by F (see Fig. 2).

Regarding the content of the feedback uptake, the students conducted more low-level $( 6 1 \% )$ than high-level $( 4 1 \% )$ revisions. Nevertheles, their implementation rate for the high-level fdback increased sharply across the three tasks, which was alo confirmed in the interview data. For example, D referred to herelf as stubbon and was reluctant to acet content-related feedack in1 because "there are a thousand Hamlets in a thousand people's eyes." However, she implemented most of the high-level feedack in T3 and admitted that peers could provide useful comments on writing content despite their language proficiency, since they had an objective stance."

Noteworthly, the students' implementation of high-level comments was especiall interconnected with their cognitive and met acognitive feedback-processing strategies. By carefully evaluating and reflecting on high-level comments, A and D accepted the feedback that they fully agred with and managed to revise high-level issues, such as thesis statements, topic sentence, and conclusions, which significantly improved the quality of their writing (see Table 1). In contrast, E, who showed great confidence in her writing content, did not eficiently ealuate the feback or reflec on her writing: \*I was so weak in anguage us..ut I know how to

Table 4 Students' cognitive engagement in each sub-dimension.   

<html><body><table><tr><td></td><td colspan="3">Depth of processing feedback (Noticing)</td><td colspan="3">Depth of processing feedback (Understanding)</td><td colspan="3">Using cognitive and/or metacognitive strategies</td><td colspan="3">Overall</td></tr><tr><td></td><td>T1</td><td>T2</td><td>T3</td><td>T1</td><td>T2</td><td>T3</td><td>T1</td><td>T2</td><td>T3</td><td>T1</td><td>T2</td><td>T3</td></tr><tr><td>A</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td></tr><tr><td>B</td><td>H</td><td>H</td><td>H</td><td>m</td><td></td><td>H</td><td>H</td><td>H</td><td>H</td><td>M</td><td>m</td><td>H</td></tr><tr><td>c</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td></tr><tr><td>D</td><td>H</td><td>H</td><td>H</td><td>m</td><td>M</td><td>H</td><td>H</td><td>H</td><td>H</td><td>m</td><td>m</td><td>H</td></tr><tr><td>E</td><td>M</td><td>H</td><td>H</td><td></td><td>L</td><td>M</td><td>M</td><td>M</td><td>L</td><td>m</td><td></td><td>M</td></tr><tr><td>F</td><td>H</td><td>H</td><td>H</td><td>L</td><td>L</td><td>L</td><td>m</td><td>L</td><td>L</td><td>M</td><td>L</td><td>L</td></tr></table></body></html>

Table 5 Student feedback implementation (uptake/feedback count) in three tasks.   

<html><body><table><tr><td>Type</td><td colspan="3">High-level revision</td><td colspan="3">Low-level revision</td><td colspan="3">Total revision</td></tr><tr><td>Round</td><td>T1</td><td>T2</td><td>T3</td><td>T1</td><td>T2</td><td>T3</td><td>T1</td><td>T2</td><td>T3</td></tr><tr><td>A</td><td>1/1</td><td>1/4</td><td>1/1</td><td>6/6</td><td>5/9</td><td>4/4</td><td>7/7</td><td>6/13</td><td>5/5</td></tr><tr><td>B</td><td>0/1</td><td>0/1</td><td>0/0</td><td> 6/10</td><td>8/19</td><td>13/16</td><td>6/11</td><td>8/20</td><td>13/16</td></tr><tr><td>c</td><td>0/3</td><td>3/3</td><td>3/3</td><td>3/19</td><td>1/2</td><td>3/3</td><td>3/22</td><td>4/5</td><td>6/6</td></tr><tr><td>D</td><td>0/2</td><td>2/10</td><td>5/8</td><td>15/37</td><td>2/2</td><td>26/30</td><td>15/39</td><td>4/12</td><td>31/38</td></tr><tr><td>E</td><td>0/0</td><td>0/3</td><td>1/1</td><td>17/21</td><td>9/18</td><td>6/8</td><td>17/21</td><td>9/21</td><td>7/9</td></tr><tr><td>F</td><td>1/3</td><td>1/1</td><td>0/1</td><td>24/39</td><td>4/7</td><td>4/7</td><td>25/42</td><td>5/8</td><td>4/8</td></tr><tr><td>Overall</td><td>2/10</td><td>7/22</td><td>10/14</td><td>71/132</td><td>29/57</td><td>56/68</td><td>73/142</td><td>36/79</td><td>66/82</td></tr><tr><td></td><td>19/46</td><td></td><td></td><td>156/257</td><td></td><td></td><td>175/303</td><td></td><td></td></tr></table></body></html>

# Feedback implementation rate

![](img/664b558e23ccf8cf4b8790a3f626d6f9c2d8454613b868c30f1bd786625a0fde.jpg)  
Fig. 2. Students' feedback implementation rate across three tasks.

organize my writig content Itis not that dfficult as long as you have argumentative ideas," said  in the interview. Consequently he failed to revise the serious problems in her writing, despite receiving detailed peer feedback on them in T2.

In terms of observable revision strategies (see Table 6), the students al manifested a high level in T1, such as re-reading draft. frequently checking for grammatical mistakes, and turning to the Internet or friends for asstance. While the high- and mid proficiency students maintained this high level in the following two tasks, the low-proficiency students used revision strategies increasingly les frequenly: I dont havetime to use rision stratgis].I reied the lastessay onthe plane" sad in the intervie.

Meanwhile, we found that the effectiveness and depth, rather than the mere action, of trategy use mattered more in terms of student behavioral engagement. For example, E and F used online dictionaries to simply look up word meanings, while A and D delved further into their usage, manifesting the distinction between superficial and deep engagement.

Notably, the students were found to conduct extensive self-editing ${ \bf ( n = 1 9 8 ) }$ alongside feedback uptake. Though we did not involve them in the dataset, since we focused on student engagement with receiving feedack rather than gneral revision behaviors, they also demonstrated high engagement with peer feedback activity. As D, who made the most self-initiated revisions $\mathbf { \Phi } ( \mathbf { n } = 1 2 1 $ ), said in the interview, "'Disagrement with per feedback facilitated more reflection on my writing...When you totally agree with someone, you don't think critically."

Table 6 Students' adoption of observable revision strategies.   

<html><body><table><tr><td></td><td>T1</td><td>T2</td><td>T3</td></tr><tr><td>A</td><td>H</td><td>H</td><td>H</td></tr><tr><td>B</td><td>H</td><td>H</td><td>H</td></tr><tr><td>c</td><td>H</td><td>H</td><td>H</td></tr><tr><td>D</td><td>H</td><td>H</td><td>H</td></tr><tr><td>E</td><td>H</td><td>M</td><td>L</td></tr><tr><td>F</td><td>H</td><td>L</td><td>L</td></tr></table></body></html>

# 1.1.4. Summary of the changing patterns of student engagement

The students' engagement with receiving peer feedback pointed to varying patterns of change acros different engagement dimensions (see Table 7 for a summary). The changing patterns were measured quantitatively and qualitatively and are shown separately.

# 4.2. Factors influencing student engagement with peer feedback

Engagement is by nature mallable (Fredricks et al., 2004) and can be impacted by both individual and contextual factors (Ellis 2010). As shown in Table 8, the content analysis of the semi-structured interviews, stimulated recalls, and back-evaluations revealed two individual and three contextual factors influencing student engagement with peer feedback and its dynamic changes.

Two individual factors L2 proficiency and learner beliefs-tended to inluencestudent engagement with peer fedback. Language proficiency was significant influencing factor, as the students had more difficulty understanding peer fedback and might not have been capable of appropriately evaluating it. Behaviorall, the low-proficiency students likely encountered difficulty implementing comments, as they might not have known how to revise or improve their writing, even though they understood the peer comments and agreed with the criticisms or suggestions. Further, failig to understand feedback led to negative feelings and blind acceptance or neglect of comments among low-proficiency students due to their lack of confidence in their language proficiency: \*With respect to comments on grammar, I had no judgment but to accept them directly," said E in the interview.

The learners' beliefs about the effctiveness of peer feedback, English writing, and their writing abilitie also influenced their engagement. The high- and mid-proficiency students tended to positively evaluate the effctivenessof eer feedback. Acording to A, "Peer feedback cannot beaccurate all the time, but I felt inclined to trust peers and implement their comments in the peer review setting onverel, we found that the ow-proficiency studnts wer more likely to doubt th effctivenessfper fdback and failed to take advantage of it Challenged by the reviewer on the content in T2, E did not reflect on her writing or employ revision strategies, instead, she questioned the validity of the peer feedback and rejected some valuable comments: I found that our way of thinking was different, so I starte to question the comments provided by her," said E in the recall. The level of F's engagement with peer feedback was found to decline across tasks. While she had great dificulty understanding peer feedback, she aso seemed to doubt it effectiveness and hardly believed in the reviewers.

The students beliefs about English writing and their writing abilities contributed to their engagement with per feedack in various ways. For example, E engaged more with low-lel than high-level feedback acrossthe three tasks, partly because of her overemphasis on the precise use of language n writing and overonfidence in her own writing aility regarding high-level issues. In contrast, C and D engaged extensively with high-level feedback, as they weighed content development as much as linguistic accuracy. Further, D believed that there was great room for improvement in her writing. Therefore, despite her dissaisfaction with pee feedack in T1 and T2, she implemented the comments she had agreed with and actively reflcted on her writing, together accounting for the significant improvement in the writing quality (see Table 1).

Besides individual factors, three contextual factors (feedback accuracy, feedback feature, and (dis)satisfaction with prior perfor mance) contributed to the dynamic changes in student engagement. According to the course design, the students had been purposely assigned to different cross-ask parigs, which explained why they received feedback of varying quality and comprising different features. Inaccurate comments (in language or content) were found to hinder student behavioral engagement and lead to negative emotions about peer review, arguably accounting for the low implementation rate (as in D) and negative felings (as in B) in the frst two tasks. Meanwhile, fdback features, which are the structral components ofpeer feedback, such as whether it explicitly describes a problem, contains solutions, or gives praise (Wu & Schunn, 2020), significantly influenced student engagement. All sixstudents appreciated detiled comments. According to D it was not as easy to accept peer fedback in the same way as teacher feedack, unles it contained some convincing explanations or solutions. Furthermore, it emed easier for the students to acet peer edack when it consisted of both critical comments and prais. All i students expressed anticipation for praise:  ook forward to receiving praiseon my writing. They couldnt help me with the revision, but they made me happy and more wiling to accet the critical comments," said C in the interview. One of the reasons for E's emotional changes in T2 may have been that ll the comments except one were critical in nature, potentially leading to her experiences of embarrassment, frustration, and anger.

Additionally, the students' (dis)satisfaction regarding prior performance was found to influence their engagement with peer feedback acros tasks Satisfaction with one's own performance in the prior task positively contributed to continuous engagement with peer feedback. A and D maintained high engagement with pee feedback, since they had gained a sense of achievement from prior tasks and were ooking forward to helping others inthe same way. Conversel, E's confidence in herself declined due to her dissatisfaction with her performance in prior tasks, partly leading to her negative emotions and superficial cognitive and behavioral engagement with pr fedback: As I reviewed more eays, I felt that howI behave in preious taks was not idel. To be honest, started to doubt whether I could make good use of peer feedback," said E in the interview.

Table 7 Changing patterns of student engagement.   

<html><body><table><tr><td></td><td>Affective</td><td>Cognitive</td><td colspan="2"> Behavioral</td></tr><tr><td></td><td></td><td></td><td>Feedback uptake</td><td>Strategy use</td></tr><tr><td>A</td><td>Declining &amp; growing</td><td>Constantly high</td><td>Declining &amp; growing</td><td>Constantly high</td></tr><tr><td>B</td><td>Growing</td><td>Growing</td><td>Declining &amp; growing</td><td>Constantly high</td></tr><tr><td>c</td><td>Growing</td><td>Constantly high</td><td>Growing</td><td>Constantly high</td></tr><tr><td>D</td><td>Growing</td><td>Growing</td><td>Declining &amp; growing</td><td>Constantly high</td></tr><tr><td>E</td><td>Declining</td><td>Constantly medium</td><td>Declining &amp; growing</td><td>Declining</td></tr><tr><td>F</td><td>Constantly low</td><td>Declining</td><td>Growing &amp; declining</td><td>Declining</td></tr></table></body></html>

Table 8 Factors influencing student engagement.   

<html><body><table><tr><td>Categories</td><td> Sub-categories</td><td>Examples</td></tr><tr><td>Individual</td><td>Language proficiency</td><td>I am really weak at grammar.</td></tr><tr><td>factors</td><td>Beliefs about the effectiveness of peer feedback, English writing and their own writing</td><td>I started to doubt the reliability of peer feedback. /The content is more important than the language for argumentative writings. /I was not good at using short examples in my writing.</td></tr><tr><td>Contextual</td><td>Feedback accuracy</td><td>The comments were poor in language and so hard to understand.</td></tr><tr><td>factors</td><td>Feedback feature</td><td>I felt empathetic with the reviewer and was willing to accept the comments because she offered some sincere praise.</td></tr><tr><td></td><td>(Dis)satisfaction with prior task</td><td>I gained a strong sense of achievement from the previous task, so I look forward to the following one.</td></tr></table></body></html>

# 5. Discussion

This longitudinal multiple case study explored the complexities and dynamics of L2 undergraduate students' affctive, cognitive, and behavioral engagement with receiving per feedback in English writing. Student engagement with peerfeedback was found to be interconnected within and across three dimensions (Fan & Xu, 2020; Yu et l., 2019), and it changed dynamically throughout multiple writing task cycles.

Affectively, the students manifested abundant emotions throughout the peer edback activity, including positive ., enjoyment, excitement, empathy) and negative (e.g., embarrassment, frustration, anger) experience. Consistent with previous research (Han & Hyland, 2015), al students experienced mood swings toward feedback across the thre witing cycles, indicating fluid and fluctuating emotions over time (Xu & Zhang, 2023). It is worth noting that even though the students were all willing to participate in the peer feedback activity, native mtions did fture (Jin et al., 2022). Fortunately, deite ther trggle with ngative feelings, they were able to regulate them in positive ways (Han & Hyland, 2015).

Cognitively, the students had no difficult noticing per fback in the three task. Nevertheles, the level f undertanding of peer feedback fluctuated within and across the tass for most students, indicating that L2 students could encounter challenges in under. standing fedback due to individual learner traits or contextual factors (Koltovskaia, 2020; Zheng & Yu, 2018). Moreover, alure in understanding peer feedback could lead to negative emotions and inappropriate feedback implementation.

Cognitive strategy use is a challenging part of student engagement (Zhang, 2021). In line with previous studies (Fan & Xu, 2020; Han & Hyland, 2015), the student participants were found to utilize a variety of cognitive and metacognitive strategies in processing eedback and revising essays, primarily analyzing, evaluating, reflecting, monitoring, and retrieving previous knowledge (Zhang, 2021; Zhang & Hyland, 2018). The frequency and effctivenessof strtegy use remained stable across the tasks but vried signficantly among the students and seemed largely subject to individual differences, such as in language proficiency (Han & Hyland, 2015). The low-proficiency students deployed limited strategies and relied on intuition to evaluate feedback (Cheng & Liu, 2022), resulting in either surface-level processing or rejection of apropriat feedback (Koltovskaia, 2020). Furthermore, there were inconsistencies among the sub-constructs of cognitive engagement, for example, while the students noticed peer fdback, their understanding and use of cognitive or metacognitive strategies on the feedback remained limited and superficial. Noteworthily, although the students cognitive engagement was mostly stableacross the tasks, in contrast t the level of stabilit regarding noticing and the use of cognitive strategies, their level of understanding varied. This inconsistency suggests that the students could choose to notice or use cognitive strategies but might not have understood the feedback, as understanding requires more skill in terms of language proficiency and critical thinking and is reliant on the accuracy or complexity of the feedback received.

Further, processing high-level issues is cognitively more complex than in the case of low-level isues (Wu & Schunn, 2023) Encouragingly, $5 0 \%$ of the students were found to employ extensive cognitive strategies in processing high-level feedback, including analyzing its accuracy and reflecting on their own writing, arguably accounting for their continuing writing improvement.

Behaviorall, the number of revisions conducted by the students fluctuated across the three tasks, echoing previous finding that students' response to feedack is dynamic in nature (Tian & Zhou, 2020). In line with Zhang (2017), we found that engaging behaviorally withfedback does not meanhe more, the betert (p. 325). Students can revise their writing superficially, with limited cognitive investment and blind trust in peers, indicating that the thee dimensions of engagement jointly determine how students processfeedack (Yang & Zhang, 2023). Encouragingly, the student participants were found to go beyond low-level issues and make high-level revisions (Zhang et al., 2017). Although such revisions were relatively small in number, they could significantly improve writing quality if conducted properly.

Moreover, the students adopted various strategies in the revision proces across the tasks, including re-reading their drafts checking for grammatical mistakes, and seeking asstance from friends or online sources (Han & Hyland, 2015; Zhang & Hyland, 2018). However, some of them also used revision stategies ineffctively (Zheng & Yu, 2018), potentially impeding their under. standing of peer feedback and text revision.

Furthermore, peer feedback can trigger critical thinking and foster learner autonomy for L2 learners (Vuogan & Li, 2022). With strong instrumental motivation to pass the TOEFL, the students were found to conduct extensive self-editing, proving that they could be active learners in peer review activities (Wu & Schunn, 2023) and revise beyond teacher and peer feedback (Li & Zhang, 2021; Yu et al., 2019).

Interconnectedness and inconsistencies were revealed among the three engagement dimensions, which indicated the complexity, dynamism, and nonlinear nature of student engagement with pee feedback (Xu & Zhang, 2023). For instance, while positive emotions could promote feedack implementation (Jin et al., 2022), they did not guarantee the students' cognitive investment in feedback processing. Furthermore, although the students were aware of the learning potential of feedback, some individual and contextual factors jointly constrained or influenced their engagement (Han & Hyland, 2015; To, 2021; Zhang & Hyland, 2018).

Affective engagement and its dynamic changes were largely influenced by the students' language proficiency and (dis)satisfaction with prior eformance as wel as by feedack accuracy and features. Students who perceived themseles as les proficient in linguistic competence tended to become disengaged (Zheng, Yu, & Tong, 2022), generating negative emotions toward peer fedback due to their lack of confidence (Gao et al., 2023; Xu & Zhang, 2023). As the accuracy and features of the feedback were quite uneven, inaccurate comments generally generated negative felings, whil praise normall induced positie emotions (Fan & Xu, 2020). Satisfaction with prior tasks also boosted the morale and encouraged the students to continue to engage with peer fedback, echoing previous findings that students' evaluation of and reflection on their performance could influence their engagement across learning tasks (Aubrey e l. 2020).

Student cognitive engagement tended to be influenced by a number of individual (language proficiency and learner beliefs) and contextual (feedback acuracy and feedback features) factors. The low-proficiency students appeared ineffectie at processing feedback (Zheng & Yu, 2018). Beliefs about the efectiveness of feedback inluenced student engagement (Han & Hyland, 2015; Zheng et al., 2020), as blind doubt regarding the authorit and efectiveness f peer feedback may have led students to reject valuable comments, while students who trusted in peers tended to make greater cognitive investments (Gao et al., 2023). Additionall, the students beliefs about the weight of language over content development and their own writing ability likely influenced their conitive investment in emphasizing local over global ssues (Chen & Zhang, 2019). Furthermore, fedback acuracy and feedback features could have influenced the students' cognitive engagement, as incorrect or indirect feedback likely created obstacles to feedback processing.

Likewise, student behavioral engagement was influenced by both individual and contextual factors. The low-proficiency students were less likely to produce successul revision outcomes (Koltovskaia, 2020), as they tended to focus on low-level isues and deploy surface-level revision strategies (Cheng & Liu, 2022), which explains why their behavioral engagement did not result in writing improvement. Students who had positive belies about feedback efectivenesstended to implement peer fedback wisely and take advantage of opportunities to improve their writing. However, beliefs about the weight of language over content development potentially resulted in students implementing more comments on local isues. Encouragingly, most students in the prent study paid attentionto both high- and low-lel ssues in writing and implemented increasing amounts f high-level comments across tasks, which improved writing quality in the long run. Furthermore, feedback accuracy and feedback features likely accounted for the changes in the students revision behavior over time. In particular, detailed comments and praise were well received by ll the students, promoting feedback uptake.

# 6. Conclusion

Drawing on multiple data sources from six L2 students across threetask cycles, this study examined and revealed the complex dynamic, and nonlinear nature of student engagement with peer feedback. Interconnectedness and inconsistencies were revealed within and across the sub-constructs of affctive, cognitive, and behavioral engagement. In particular, the study demonstrated that student engagement with peer feedback changed longitudinall and was influenced by individual and contextual factors.

Pedagogically, this study implies that enhancing student engagement with peerfeedack i likely to improve learning outcomes (Yu et a. 2019. With extensive engagement, students could revise their writig in acordance with peer edack and reflet on their own writing. Multiple rounds of peer feedback activity are strongly recommended, as they can strengthen the effects of the feedback and provide insight for long-term learning. Meanwhile, students should be encouraged to work on high-level isues, as they play a key role in improving writing quality.

The limitations of this study are mainly twofold. First, due to the one-to-one feedack mode, the amount f fedback across tasks and for each student were rather uneven. Future studies could consider using scientifically controlled multiple per review so as to obtain insights from a more evenly distributed feedback dataset. Second, this study only focused on student engagement with peer feedback from the perspective of receivers. Future research could examine the learning processof fedback givers and the interconnectedness betwen receiving and providing peer feedback, which may contribute to a more comprehensive picture of student engagement with peer review activities.

# CRediT authorship contribution statement

Yuge Zhang: Writing  original draft, Visualization, Validation, Software, Resources, Investigation, Formal analysis, Data curation. Ying Gao: Writing - review & editing, Validation, Supervision, Methodology, Funding acquisition, Conceptualization.

# Declaration of Competing Interest

None.

# Data availability

The data that has been used is confidential.

# Acknowledgements

This study was supported by the National Social Science Fund of China [18Byy114], and Social Science Planning Fund of Jilin Provincial Education Department [JJKH20221148SK].

# Appendix A. Topics for writing tasks

Task 1. Do you agree or disagree with the following statement? Parents are the best teachers. Use specific reasons and examples to support your answer. Task 2. It has been said, "Not everything that is learned is contained in books." Compare and contrast knowledge gained from experience with knowledge gained from books. In your opinion, which source is more important? Why?

Task 3. Do you agree or disagree with the following statement? People should sometimes do things that they do not enjoy doing. Use specific reasons and examples to support your answer.

# Appendix B. Guide for semi-structured interview

1. What difficulties do you have in preparing TOEFL writing?   
2. Why did you volunteer to participate in this online TOEFL writing course?   
3. Have you experienced peer feedback activity before?   
4. How did you feel when you receive peer feedback? Had you experienced any emotional change across tasks?   
5. Did you have difficulty in processing peer comments? If yes, what difficulties did you have in each task?   
6. How did you use peer feedback to improve your writing in each task?   
7. What type of peer feedback do you think can help you improve your writing? Why?   
8. Have you used any revision strategy (e.g., searching online) to revise your writing? If yes, what trategies did you use, and how?

# References

Appon, J. J, hriston,  L, i . chly, L 006n tive ad l m ti f th stt gagemnt instrument. Journal of School Psychology, 44(5), 427-445.   
Aubrey, . 202).y m  ond g uter-e ollatie wig s ntin md m in econd Language Learning and Teaching, 12, 59-86.   
Aubrey, ., King, J, Amkiled, H A A. (2020). Lngage lner egagment uring saking sks: A longtdinal study. RELC Jounal, 53), 519-53.   
Chen, J. & Zhang, L J. (2019. Asesig stnt-writers selfeficcy belefs aout text reision in L writig. Assin Writng, 40, 27-41.   
Cheg       0 ti 102880.   
Diab 11  tf t   k a qaf  wnn 6, 74292.   
Ellis, . (2010). A framework for investigating oral and writte corrective fedback. Studies n Second Language Acquisition, 32, 335-349.   
Fan, Y., & Xu, J. (2020). Exploring student engagement with pee feedack on L2 writing. Jounal of Second Languge Writing, 50,1-13.   
Frawley, W., & Lantolf, J. (1985). Second language discourse: A vygotskyan perspective. Applied Linguistics, 6, 19-44.   
Frecks, d  Pi 0 c   t, ft i    71) 59-109.   
Gao    . Educational Evaluation, 77, Article 101252 (Article).   
Gao,   019        p    i r Evaluation in Higher Education, 44, 294 308.   
Han  d015   t 30, 31-44.   
Hver,  ie  , J   2021).   a tc f 0  f r mt a tion. Language Teaching Research, 00(0), 1-30.   
Hyland, F. (2003). Focusing on form: Student engagement with teacher feedback. System, 31, 217-230.   
Ji     ti Learning Environments, 0(0), 1-17. https://doi.org/10.1080/10494820.2022.2081209   
Kahu, E. R. (2013). Framing student engagement in higher education. Studies in Higher Education, 38(5), 758-773.   
Kim, M. K, & Kim, S. M (2020). Dynamic lener engagment in a wikianced writing course. Jounal f omputig in Higer Edcation 32(3),1-25.   
olkai 20   w ti ing 4 (3)), Article 100450 (Article).   
Lantolf, J. ., & Pavlenko, A. (1995. Sciocultural thory and second language acquisition. Annual Review of pplied Lingusics, 15, 108-124.   
Li,   1) t        f  , i.e n Psychology, 11, Article 612088 (Article).   
Min HT. 206). fts f td e  n  stus iion ty d wtin qt.  of   n 2), 118-141.   
Mlder, R, Bik, , Nao,  & e, .2014). H d st er ri ie tio, et d   se t. Assessment & Evaluation in Higher Education, 39(6), 657-677.   
Patchan, M  D.  rt R J.2016).  f fack H er fk  at d t a ad alit of revisions. Journal of Educational Psychology, 108(8), 1098-1120.   
Pekr  ni012 a t s  .) o h on Student Engagement (pp. 259-282). Springer Science + Business Media.   
Price, M., Hande, K., & Millr, J. (2011). Feedback: Focusing attention on engagement. Studie in Higher Education, 36(8), 879-896.   
Ree, .,  g  (01.   t o   g i.i , 6(4, 257-26.   
e   2).  j t  , A. L. Reschly, & C. Wylie (Eds.), Handbook of Research on Student Engagement (pp. 3-19). New York, NY: Springer.   
Saed . 018   in Technology Education Research, 17, 39-61.   
Tn L 0         1tie 102247 (Article).   
To, J. (2021). ig e fack  st m wh fack. gr ion   Dmet, 44, 116.   
Tao .J.1  ieer, 30() 575-584.   
Villa tk  ti f F. Hyland (Eds.) Feedback in Second Language Writing: Contexts and Issues (pp. 23-42). New York: Cambridge University Press   
gan .ti f    .1002 tesq.3178   
Wang ,  . (2021) 2e gc e in an  asn wtin sosi ing 50. te 0057.   
instone . s  Pakr,   .2017  r ac  wh f   do recipience processes. Educational Psychologist, 52(1), 17-37.   
u   0 . 5 1012 (Article).   
u, Y.   . (20 aie, atie, n ttie  th er k id mdf l rm r fky Educational Psychology, 73, Article 102160 (Article).   
u, J. 3 ti 107(Supplement 2023), 161-178. https://doi.org/10.1111/modl.12823   
Yng    J 22.  tt  h fak  f h wie. f gs fr dc Purposes, 63, Article 101226 (Article).   
Yin, R. K. (2011). Qualitative Research from Start to Finish. New York/London: The Guilford Press.   
Yu, S., & Le, I. (2016). Exploring Chinese students' strategy use in a cooperative peer feedback writing group. System, 58, 1-11.   
Yu, ., hng, ,  ,   g 09 g t  th r f n mer' t et Evaluation in Higher Education, 44(1), 50-65.   
Zhang, Z. V. (2017). Student engagement with computer-generated feedback: A case study. ELT Journal, 71(3), 317-328.   
Zhang, 021). Pm  t wh fack s frm tie y d cr fack    gher Education, 47(4), 540-555.   
Zhang, Z. V., & Hyland, K (2018). Student engagement with teacher and automated feedback on L2 writing. Assesing Writing 36, 90-102.   
a   t   r. Instrumental Science, 45(4), 679-707.   
a  3   i for Academic Purposes, 64, Article 101255 (Article).   
heg   e.g Writing, 37, 13-24.   
he   e  i in Higher Education, 28(2), 301-321.   
heg   th t-i Language Teaching Research, 0(0). https://doi.org/10.1177/13621688221115808

Ms. Yuge  is a Ph ddate a hof F g, tt vrst  h r h  de r  in writing, learner engagement and self-regulated learning.