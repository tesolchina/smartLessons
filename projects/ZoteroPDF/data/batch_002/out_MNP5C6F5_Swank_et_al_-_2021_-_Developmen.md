# Development of the teaching competencies scale

Jacqueline M. Swank, Alisa Houseknecht & Ren Liu

To cite this article: Jacqueline M. Swank, Alisa Houseknecht & Ren Liu (2020): Development of the teaching competencies scale, Assessment & Evaluation in Higher Education, DOI: 10.1080/02602938.2020.1778634

To link to this article: https://doi.org/10.1080/02602938.2020.1778634

# Development of the teaching competencies scale

Jacqueline M. Swanka , Alisa Houseknechta and Ren Liub

a School of Human Development and Organizational Studies in Education, University of Florida, Gainesville, Florida, USA; b School of Social Sciences, Humanities, and Arts, University of California Merced, Merced, California, USA

# ABSTRACT

Teaching is one of the primary roles of counselor educators; and, therefore, it is crucial to have psychometrically sound assessments to evaluate teaching competencies. This study focused on the development of the Teaching Competencies Scale (TCS). We conducted an exploratory factor analysis with 288 individuals and identified four factors with 48 items. Common model fit indices showed good fit for the four-factor model. The factors that emerged were: Factor 1: Instruction and Evaluation with 18 items; Factor 2: Knowledge, Ethics and Preparation with 15 items; Factor 3: Dispositions with nine items; and Factor 4: Behaviors and Technology Use with six items. Professionals can use the TCS for training, evaluation, and research.

# KEYWORDS

Counselor education; instrument development; teaching competencies; pedagogy

Teaching is a significant element of a counselor educator’s professional identity and an educator’s teaching abilities may affect the growth and development of counseling students. The Council for Accreditation of Counseling and Related Educational Programs (CACREP 2015) Standards and the American Counseling Association (ACA 2014) Code of Ethics address the importance of teaching competency for counselor educators, and the need to effectively prepare counselor education doctoral students for teaching. Competencies are defined as a cluster of related knowledge, skills and attitudes that are a major part of a job, affect performance on the job, can be measured against established standards, and can be improved with training and development (Parry 1996). Teaching competencies are defined as the personal characteristics, knowledge, skills and attitudes needed for effective performance in various teaching contexts (Tigelaar et al. 2004).

Scholars have identified teaching competencies in the areas of knowledge, skills, behaviors, and dispositions that doctoral students and counselor educators need to develop and possess to be effective teachers (Swank and Houseknecht 2019). However, counselor educators need a method to evaluate doctoral students’ teaching competency, as well as a tool to facilitate discussions about strengths and areas for growth (Swank and Houseknecht 2019). By evaluating teaching competencies, faculty and doctoral students can collaboratively influence training and development of teaching competence. Thus, the purpose of this study is to examine the psychometric properties of an instrument designed to measure teaching competencies of counselor educators and counselor education doctoral students. The instrument is intended for use as a self-evaluation measure for both counselor educators and doctoral students. It is designed for use as an evaluation tool for instructors, supervisors, and peers evaluating the teaching competencies of others.

# Assessments of teaching effectiveness

Assessments of teaching quality and effectiveness can be beneficial for improving teaching quality, evaluating faculty performance, and training future faculty (Spooren, Brockx, and Mortelmans 2013). However, conducting accurate and useful assessments of teaching effectiveness may be difficult given wide variation in instructor preparation, considerable teacher variation in instructional methods, and differing philosophies about teaching (Association for Counselor Education and Supervision, Teaching Initiative Taskforce, $2 0 1 6 ;$ Baltrinic, Jencius, and McGlothlin 2016; Waalkes et al. 2018). Scholars recommend using a multidimensional approach to assess teaching effectiveness, including student evaluations of teaching (SETs), instructor reflection, evidence of student learning, and peer observations of teaching (Benton and Ryalls 2016).

SETs are one of the most common and well-known ways of assessing teaching effectiveness; however, there is controversy regarding their use for evaluating teaching. Common concerns regarding SETs include: (a) differences in students and teachers’ perceptions of effective teaching, (b) poorly designed SETs that lack psychometric support, (c) depersonalization of the student-teacher relationship through a standardized form, (d) misinterpretation and inappropriate use of results, and (e) lack of awareness of research on SETs that may influence beliefs and use (Spooren, Brockx, and Mortelmans 2013).

Additionally, although researchers found evaluations encompassing both ratings and openended questions may provide valuable formative feedback for faculty (Benton and Cashin 2012), meaningful interpretations about a teacher’s effectiveness require evaluations from multiple courses over time (Benton and Ryalls 2016). Self-reflection and consultation regarding student evaluations is necessary in order to improve teaching (Ryan 2015). Scholars found faculty who engaged in reflection about their teaching improved their SET scores over time (Winchester and Winchester 2014). Professional or academic reflection, as opposed to personal reflection, involves a critical examination of professional learning and growth and should lead to action (Ryan 2015). The process of learning through reflection includes: (a) recognizing issues or critical incidents; (b) reflecting on one’s responses, capabilities, motivations and desires in relation to the issue; (c) understanding contributing social or contextual factors; (d) thinking creatively and critically about the issue; (e) making informed decisions; and (f) taking appropriate action (Ryan 2015).

Faculty peer evaluations offer another method to obtain feedback about the quality and effectiveness of teaching. Peer observations provide faculty with constructive feedback regarding teaching in the context of a trusting and collegial relationship. Faculty, who have their teaching observed by peers, report becoming aware of their strengths and identifying opportunities to improve teaching (DiVall et al. 2012). Junior faculty report benefiting from peer relationships and learning from both being observed and observing others (Carroll and O’Laughlin, 2014). Effective peer observations require faculty to understand the purpose and process of peer observations. This includes adequate preparation of peer observers, pre- and post-observation consultation, and integration of evidence of direct student learning (Chamberlain, Artrey, and Rowe 2011).

# Measures of teaching related constructs

Measures assessing teaching competencies in higher education are limited, with no instruments specifically focused on teaching in counselor education. The Evaluation of Teaching Competencies Scale (ETCS; Catano and Harvey 2011) is a 159-item instrument that measures teaching effectiveness based on nine competencies identified by students as important to good teaching: (a) communication, (b) availability, (c) creativity, (d) individual consideration, (e) social awareness, (f) feedback, (g) professionalism, (h) conscientiousness, and (i) problem solving. On the ETCS, respondents rate critical incidents using behavioral anchors (low, moderate, high) to indicate level of teaching effectiveness. The Teacher Effectiveness Scale in Higher Education (TESHE; Calaguas 2012) is a 67-item instrument with a four-point scale. It has four subscales: (a) teacher related behavior, (b) subject matter expertise, (c) relational expertise, and (d) personality. The Multicultural Teaching Competencies Inventory (MTCI; Prieto 2012) is designed to assess cultural competency (knowledge, skills, awareness) of higher education faculty and their ability to work with a culturally diverse student body in the classroom. The MTCI is a 15-item self-report instrument that measures respondents’ level of multicultural competence using a five-point Likert scale.

While these instruments assess teaching-related constructs in higher education (i.e., teaching effectiveness, multicultural teaching competencies), Swank and Houseknecht (2019) identified teaching competencies specific to counselor education that are not reflected in these existing instruments (i.e., gatekeeping). Therefore, a need exists for the development of an instrument measuring teaching competencies of counselor educators.

The development of the Teaching Competencies Scale (TCS) was based on the lack of instruments for examining and assessing teaching competencies among counselor education faculty and doctoral students. The counselor education literature is also limited in examining teaching competencies. Recently, Swank and Houseknecht (2019) conducted a Delphi study with counselor educators who had expertise in teaching to identify counselor education teaching competencies within four domains (knowledge, skills, behaviors, and dispositions). The researchers defined teaching experts as (a) having a doctoral degree in counselor education, (b) employed as a counselor educator, and (c) authored a publication on teaching, had a service position or membership in a group focused on teaching, and/or received an award for teaching excellence. The study resulted in 152 competencies within the four domains and multiple subdomains.

While there was some overlap between the Delphi study and existing literature, the experts also identified teaching competencies unique to counselor education that are not present in existing measures of teaching competency (e.g., gatekeeping). The experts identified components of teaching competency (e.g., knowledge of adult learning and teaching theories) that appear to be missing from existing instruments that measure teaching competency and effectiveness. Researchers report the lack of traditional teaching theories in the literature on pedagogy within counselor education and the need for this integration (Barrio Minton, Wachter Morris, and Yaites 2014). Thus, the authors developed the TCS using the teaching competencies identified through the Delphi study and other literature on teaching competencies to provide a comprehensive assessment for evaluating counselor educators and doctoral students’ teaching competencies and providing guidance for training doctoral students to become counselor educators.

This study was guided by the following research questions: (a) Research Question 1: What is the factor structure of the TCS with a sample of counselor educators and counselor education doctoral students? (b) Research Question 2: What is the reliability/internal consistency of the TCS with a sample of counselor educators and counselor education doctoral students (total TCS score and TCS subscale scores)?

# Method

# Initial item development of the teaching competencies scale

We developed the TCS using the eight step process identified by DeVellis (2017): (a) determine what to measure, (b) create items, (c) develop measurement format, (d) item review by experts, (e) consider adding validation items, (f) administer items to a sample, (g) evaluate items, and (h) revise length of instrument. The list of teaching competencies developed by Swank and Houseknecht (2019) provided a strong source for the development of items for the TCS, along with other literature about teaching competencies and effectiveness (e.g. Pietrzak, Duncan, and Korcuska 2008; Buller 2016; Hill 2014; ACES 2016; Schneider and Preckel 2017). We developed the format based on DeVellis’ recommendations for scale development, and the layout (e.g., visual presentation, organization of demographic questions) based on Dillman, Smyth, and Christian (2014) guidelines for survey development. Due to limited instruments measuring teaching competencies, we also used existing instruments that measured other types of competency (e.g., Research Competencies Scales [RCS]; Swank and Lambie 2016) as a model for formatting and development of response options.

After developing the draft of the TCS, we had four experts review the instrument for content, format, and layout. The experts were counselor educators from different universities with a variety of teaching experiences in different counseling specialty areas (e.g., clinical mental health, school counseling, doctoral training). Additionally, two reviewers had conducted research in pedagogy, and two had experience in instrument development. We integrated the feedback from the experts (e.g., revised wording of items and response options, added and deleted items to ensure the construct was not under or over-represented) to finalize the instrument for administration to the developmental sample.

# Participants

The target population for this study was counselor educators who had experience of teaching, and counselor education doctoral students who were engaging in teaching experiences to develop their skills as teachers. A total of 288 individuals completed the instrument. The sample included 194 $( 6 7 \% )$ females, 88 $( 3 1 \% )$ males, 3 $( 1 \% )$ that identified as Other (one genderqueer, one trans-male, and one who did not provide additional information for other), and 3 $( 1 \% )$ that did not respond to the item about gender. Regarding race/ethnicity, 227 $( 7 9 \% )$ reported White/ Caucasian, 25 $( 9 \% )$ Black/Non-Hispanic, 9 $( 3 \% )$ Asian/Pacific Islander, 9 $( 3 \% )$ Hispanic, 8 $( 3 \% )$ Mixed Racial, 8 $( 3 \% )$ Other (three White/Caucasian Hispanic, one European-American, one Native American, and 3 provided no additional information), and 2 $( 1 \% )$ did not respond. The sample included 32 $( 1 1 \% )$ participants aged 21-29, 80 $( 2 8 \% )$ 30-39, 74 $( 2 6 \% )$ 40-49, 55 $1 9 \% )$ 50-59, 32 $( 1 1 \% )$ 60-69, 13 $( 5 \% )$ 70 and older, and 2 $( 1 \% )$ did not respond. There were 59 $( 2 1 \% )$ participants that reported their highest degree as MS/MA, 210 $( 7 3 \% )$ as PhD/EdD, 17 $( 6 \% )$ as Other, and 2 $( 1 \% )$ did not respond.

Regarding specialty area, 171 $( 5 9 \% )$ reported mental health; 56 $( 1 9 \% )$ school counseling; 28 $( 1 0 \% )$ marriage, couple, and family counseling; 31 $( 1 1 \% )$ Other; and 2 $( 1 \% )$ did not respond. There were 71 $( 2 5 \% )$ participants that reported being doctoral students, 209 $( 7 3 \% )$ faculty, 6 $( 2 \% )$ Other, and 2 $( 1 \% )$ did not respond. Of the participants reporting they were faculty, 68 $( 3 3 \% )$ reported rank as assistant, 65 $( 3 1 \% )$ associate, 58 $( 2 8 \% )$ professor, 17 $( 8 \% )$ Other, and 1 $( 1 \% )$ did not respond. Of the participants reporting they were doctoral students, 10 $( 1 4 \% )$ reported it was their first year, 23 $( 3 2 \% )$ second year, 18 $( 2 5 \% )$ third year, 8 $( 1 1 \% )$ fourth year, 8 $( 1 1 \% )$ fifth year, and 4 $( 6 \% )$ Other. Table 1 provides additional information about demographic characteristics of the sample related to teaching.

Regarding their current institution, participants reported Carnegie university classification as 75 $( 2 6 \% )$ R1, 61 $( 2 1 \% )$ R2, 44 $( 1 5 \% )$ R3, 36 $( 1 3 \% )$ M1, 28 $( 1 0 \% )$ M2, 26 $( 9 \% )$ M3, 8 $( 3 \% )$ Other, and 10 $( 4 \% )$ did not respond. The Association for Counselor Education and Supervision (ACES) region was reported as 128 $( 4 4 \% )$ Southern region, 62 $( 2 2 \% )$ North Central region, 50 $( 1 7 \% )$ North Atlantic region, 20 $( 7 \% )$ Western region, 13 $( 5 \% )$ Rocky Mountain region, and 15 $( 5 \% )$ did not respond. The representation of participants within ACES regions is consistent with the percentage (within $4 \%$ for any region) of CACREP-accredited program by region (CACREP 2017). Additionally, 270 $( 9 4 \% )$ reported their program was CACREP-accredited, 14 $( 5 \% )$ reported not being CACREP-accredited, and 4 $( 1 \% )$ did not respond. It is important to note that some of the total percentages reported are slightly less or more than $100 \%$ due to rounding considerations.

<html><body><table><tr><td>Faculty</td><td>cimg LAp. First yr 5 (3%)</td><td>02 (0770) 1-5 yrs 49 (23%)</td><td>5.1-10 yrs 45 (22%)</td><td>10.1-15 yrs 39 (19%)</td><td>15.1-20 yrs</td><td>20.1 + yrs 38 (18%)</td><td>No Response 3 (1%)</td></tr><tr><td>Teaching Exp. Faculty</td><td>None 5 (2%)</td><td>1 class 30 (14%)</td><td>2 classes 64 (31%)</td><td>3 classes 59 (28%)</td><td>30 (14%) 4 classes 35 (17%)</td><td>Other 16 (8%)</td><td></td></tr><tr><td>Teaching Now Teaching</td><td>Very Confident</td><td>Confident 113 (39%)</td><td>Moderately 34 (12%)</td><td>Limited 4 (1%)</td><td>No Response 3 (1%)</td><td></td><td></td></tr><tr><td>Confidence Teaching interest*</td><td>134 (47%) Very Interested</td><td>Interested 57 (20%)</td><td>Somewhat 25 (9%)</td><td>Limited 1 (.3%)</td><td>No Response 3 (1%)</td><td></td><td></td></tr><tr><td>Teaching</td><td>202 (70%) Strong 64 (22%)</td><td>Good 77 (27%)</td><td>Adequate 83 (29%)</td><td>Limited/Weak 60 (21%)</td><td>No Response 4 (1%)</td><td></td><td></td></tr><tr><td>preparation Overall competence*</td><td>Very Competent 103 (36%)</td><td>Competent 147 (51%)</td><td>Moderately 30 (10%)</td><td>Limited/ None 4 (1%)</td><td>No Response 4 (1%)</td><td></td><td></td></tr></table></body></html>

# Procedure

Following approval from the institutional review board at our institution, we used several strategies to recruit participants for the study. Specifically, we sent a recruitment email to faculty at CACREP-accredited counselor education programs and posted an announcement on CESNET (a listserv primarily comprised of counselor educators and doctoral students). To recruit additional doctoral students, we emailed faculty at institutions with doctoral programs and asked them to send the announcement to their doctoral students. We also emailed doctoral students listed on the ACES directory. We used recommendations from Dillman, Smyth, and Christian (2014) during the data collection process regarding sending out follow up requests for participation. The recruitment email included a Qualtrics (online survey portal) link to complete the TCS and demographic questions. The survey also contained information about informed consent, and completion of the survey constituted consent for participation.

# Instruments

We used two instruments for data collection: (a) demographic questionnaire, and (b) TCS. The demographic questionnaire encompassed items about participants’ general demographic characteristics and individual information about teaching. We also requested information about institutional characteristics.

Teaching Competencies Scale (TCS). We used the self-assessment TCS for this study. Following the instrument development process, the TCS encompassed a total of 67 items within four domains: (a) knowledge, (b) skills, (c) behaviors and (d) dispositions. The skills domain was divided within three areas: (a) preparation skills, (b) instructional skills, and (c) evaluation and gatekeeping skills. The TCS includes a 5-point response scale that ranges from none/not competent to strong/very competent. Scoring results in a total score and subscale scores for each domain/area. Sample items include “knowing ethical standards related to teaching in counselor education”, “developing a course syllabus”, “facilitating class discussions”, “counseling students out of the program”, “being professional”, and “believing that all students are capable of learning”.

# Data analysis

We obtained item responses from 288 individuals. Considering both the variables-to-factors ratio and the communality, our sample size exceeded the minimum requirement (Mundfrom, Shaw, and Ke 2005). There were $0 . 3 \%$ of the data points missing and the missingness was randomly scattered across different individuals on different items. To estimate the missing values and obtain a complete dataset, we used a non-parametric iterative imputation method called random forest. Random forest is a state-of-the-art iterative imputation method that outperforms traditional imputation methods (e.g., Stekhoven and Buhlmann € 2012; Tang and Ishwaran 2017). Then, we used factor analysis to answer the two research questions.

# Results

To answer Research Question 1, we ran an exploratory factor analysis (EFA) using principal components extraction with a varimax rotation. Prior to running the EFA, we examined the data for (a) sampling adequacy using the Kaiser-Meyer-Olkin (KMO) measure of sampling adequacy, and (b) sphericity using Bartlett’s test of sphericity. The KMO measure of sampling adequacy was strong (.946) and Bartlett’s test of sphericity yielded statistical significance $( x ^ { 2 } = 1 3 4 4 3 . 4 4 4$ $d f = 2 2 1 1$ , $p < . 0 0 1 .$ ). Therefore, we were able to proceed with the analysis. Then, using parallel analysis, we determined we should retain four factors. Common model fit indices showed good fit for the four-factor model: the root mean square error of approximation $( \mathsf { R M S E A } ) = 0 . 0 4$ , the comparative fit index $\mathtt { ( C F l ) } = 0 . 9 4$ , the Tucker-Lewis index $\mathrm { ( T L I ) } = 0 . 9 3$ , and the standardized root mean residual $( \mathsf { S R M R } ) = 0 . 0 5$ .

In running the EFA, we used the following criteria to determine items to retain: (a) a measure of sampling adequacy (MSA) of .5 or above for each item, and (b) factor loading of .45 or above for each item. The lowest MSA value for any item was .835; and therefore, no items were removed due to the MSA value. We removed eight items that had factor loadings below .45. Sample items removed due to factor loading below .45 included "separate self from students’ comments in feedback" (.32), and "consult with colleagues" (.36). We also removed 11 items that loaded above .45 on multiple factors (cross loadings) after reviewing each one and determining the content of the items related to multiple factors. Sample items removed due to cross loading included "integrating content across counseling specialties", and "constructing test items". We retained a total of 48 items across the four factors: Factor 1: Instruction and Evaluation with 18 items; Factor 2: Knowledge, Ethics, and Preparation with 15 items; Factor 3: Dispositions with nine items; and Factor 4: Behaviors and Technology Use with 6 items. Table 2 indicates the standardized factor loadings. The rotation of the four factors accounted for $5 2 . 9 5 \%$ of the total variance (Factor $1 = 3 8 . 1 6 \%$ , Factor $2 = 6 . 3 6 \%$ , Factor $3 = 4 . 6 1 \%$ Factor $4 = 3 . 8 1 \% )$ ). The correlation between factor 1 and two was .55, between factor 1 and three was .25, between factor one and factor four was .61, between factor two and three was .12, between factor two and four was .23, and between factor three and four was .09.

To answer Research Question 2, we computed Cronbach’s alpha as a measure of reliability/ internal consistency for the entire TCS (.963) and each subscale. The alpha value for each subscale was: Factor $1 = . 9 4 9 _ { i }$ , Factor $2 \ : = \ : . 9 2 8 ,$ Factor $3 = . 8 3 9$ , and Factor $4 = . 7 9 8$ . Thus, scores on the TCS and its subscales have acceptable to strong reliability.

# Discussion

This study contributes to the counselor education literature by focusing on the development of an instrument to measure teaching competency among counselor educators and counselor education doctoral students. We found a four-factor structure in the dataset. The first subscale, Instruction and Evaluation, encompassed 18 items focused on skills counselor educators use for course instruction and evaluation. The second subscale, Knowledge, Ethics and Preparation, encompassed 15 items focused on knowledge about theories, accreditation and best practices, ethical and research considerations, and preparation for course instruction. The third subscale, Dispositions, included nine items focused on personal characteristics of counselor educators. The fourth and final theme, Behaviors and Technology Use, included six items focused on professional and ethical behavior and the use of technology.

Researchers support the identification of the four subscales (Parry 1996; Tigelaar et al. 2004; Swank, Lambie, and Witta 2012; Swank and Houseknecht 2019). Specifically, Parry (1996) defined competencies generally, without focusing on an identified career area, as including knowledge, skills, and attitudes. Additionally, in focusing on counseling competencies, Swank, Lambie, and Witta (2012) identified four areas: (a) knowledge, (b) skills, (c) professional behaviors, and (d) dispositions. Regarding teaching competencies specifically, Tigelaar et al. (2004) included four competency areas (personal characteristics, knowledge, skills, and attitudes) needed for effective teaching. Furthermore, in focusing on counselor education teaching competencies, Swank and Houseknecht (2019) reported competencies within four domains (knowledge, skills, professional behaviors, and dispositions), and various categories within each domain (e.g., skills categories encompassing course preparation, instruction, evaluation and gatekeeping) used in developing the TCS.

Table 2. Factor loadings for exploratory factor analysis of the teaching competencies scale.   

<html><body><table><tr><td rowspan="2">Item</td><td colspan="4">Factor</td></tr><tr><td>1</td><td>2</td><td>3</td><td>4</td></tr><tr><td>Asking questions effectively.</td><td>.752</td><td>.207</td><td>.212</td><td>.153</td></tr><tr><td>Facilitating difficult conversations with students</td><td>.709</td><td>.336</td><td>.186</td><td>-.038</td></tr><tr><td>Using class time effectively (i.e., pacing of class)</td><td>.672</td><td>.169</td><td>.084</td><td>.233</td></tr><tr><td>Promoting intellectual curiosity through critical thinking</td><td>.661</td><td>.276</td><td>.269</td><td>.147</td></tr><tr><td>Encouraging students to take responsibility for their learning</td><td>.658</td><td>.254</td><td>.274</td><td>.136</td></tr><tr><td>Balancing structure and flexibility in the classroom</td><td>.655</td><td>.374</td><td>.159</td><td>.073</td></tr><tr><td>Balancing supporting and challenging students</td><td>.648</td><td>.337</td><td>.221</td><td>.213</td></tr><tr><td>Explaining course concepts in a clear and relatable manner</td><td>.647</td><td>.254</td><td>.155</td><td>.243</td></tr><tr><td>Providing students with summative feedback</td><td>.638</td><td>.321</td><td>.140</td><td>.244</td></tr><tr><td>Employing classroom management skills</td><td>.635</td><td>.215</td><td>.250</td><td>.254</td></tr><tr><td>Providing students with formative feedback</td><td>.629</td><td>.269</td><td>.125</td><td>.255</td></tr><tr><td>Facilitating class discussions</td><td>.627</td><td>.197</td><td>.239</td><td>.229</td></tr><tr><td>Creating a classroom to explore diverse perspectives</td><td>.597</td><td>.173</td><td>.269</td><td>.144</td></tr><tr><td>Responding to students&#x27; questions in the classroom</td><td>.571</td><td>.312</td><td>.138</td><td>.294</td></tr><tr><td>Using strategies to create a welcoming classroom</td><td>.540</td><td>.200</td><td>.239</td><td>.143</td></tr><tr><td>Evaluating one&#x27;s own effectiveness as a teacher</td><td>.506</td><td>.417</td><td>.199</td><td>.141</td></tr><tr><td>Implementing class policies and expectations</td><td>.489</td><td>.277</td><td>.148</td><td>.445</td></tr><tr><td>Delivering course lectures</td><td>.479</td><td>.304</td><td>.069</td><td>.347</td></tr><tr><td>Developing curriculum that connects outcomes, readings, etc.</td><td>.300</td><td>.740</td><td>.008</td><td>.332</td></tr><tr><td>Selecting a course textbook and/or readings</td><td>.235</td><td>.735</td><td>.083</td><td>.239</td></tr><tr><td>Knowing CACREP standards related to content area</td><td>.032</td><td>.715</td><td>.177</td><td>.110</td></tr><tr><td>Developing student remediation plans</td><td>.437</td><td>.670</td><td>.168</td><td>.021</td></tr><tr><td>Counseling students out of the program</td><td>.430</td><td>.666</td><td>.083</td><td>.085</td></tr><tr><td>Developing a course syllabus</td><td>.273</td><td>.662</td><td>.002</td><td>.343</td></tr><tr><td>Designing course assignments that measure students&#x27; learning</td><td>.382</td><td>.654</td><td>.031</td><td>.282</td></tr><tr><td>Developing objectives that align with Bloom&#x27;s Taxonomy.</td><td>.270</td><td>.633</td><td>.053</td><td>.149</td></tr><tr><td>Understanding best practices in graduate level teaching</td><td>.250</td><td>.607</td><td>.229</td><td>.077</td></tr><tr><td>Knowing ethical standards related to teaching</td><td>.184</td><td>.569</td><td>.304</td><td>.209</td></tr><tr><td>Integrating research outcomes, practices, and new knowledge</td><td>.335</td><td>.547</td><td>.123</td><td>.210</td></tr><tr><td>Understanding the teacher&#x27;s role in gatekeeping</td><td>.091</td><td>.544</td><td>.364</td><td>.165</td></tr><tr><td>Advocating for needed curriculum changes</td><td>.366</td><td>.536</td><td>.192</td><td>.212</td></tr><tr><td>Possessing course content knowledge informed by research</td><td>.320</td><td>.513</td><td>.110</td><td>.155</td></tr><tr><td>Knowing models or theories relevant to adult learning</td><td>.190</td><td>.504</td><td>.172</td><td>.120</td></tr><tr><td>Possessing empathy</td><td>.225</td><td>.081</td><td>.734</td><td>.006</td></tr><tr><td>Having a passion for counseling.</td><td>.012</td><td>.210</td><td>.689</td><td>.005</td></tr><tr><td>Being authentic - ability to bring one&#x27;s humanity into the room</td><td>.311</td><td>.077</td><td>.664</td><td>.050</td></tr><tr><td>Believing that all students are capable of learning</td><td>.115</td><td>.075</td><td>.606</td><td>.164</td></tr><tr><td>Having a passion for teaching and learninge.</td><td>.100</td><td>.277</td><td>.601</td><td>.129</td></tr><tr><td>Having humility.</td><td>.167</td><td>.025</td><td>.594</td><td>.182</td></tr><tr><td>Possessing a sense of humor</td><td>.208</td><td>.035</td><td>.573</td><td>.070</td></tr><tr><td>Being emotionally stable.</td><td>.268</td><td>.036</td><td>.540</td><td>.345</td></tr><tr><td>Having awareness of influence of own biases</td><td>.297</td><td>.182</td><td>.468</td><td>.093</td></tr><tr><td>Using technology (i.e., digital media) for class instruction</td><td>.152</td><td>.063</td><td>.058</td><td>.666</td></tr><tr><td>Using the electronic teaching platform</td><td>.056</td><td>.189</td><td>.089</td><td>.663</td></tr><tr><td>Maintaining appropriate boundaries with students</td><td>.358</td><td>.184</td><td>.235</td><td>.595</td></tr><tr><td>Being professionale</td><td>.271</td><td>.195</td><td>.164</td><td>.585</td></tr><tr><td>Using self-disclosure appropriately</td><td>.358</td><td>.176</td><td>.253</td><td>.572</td></tr><tr><td>Being accessible and responsive to students outside of class</td><td>.375</td><td>.162</td><td>.181</td><td>.519</td></tr></table></body></html>

Note: Boldface values indicate items with a factor loading of .450 or above, representing the items in each factor. Wording of some items is shortened in this table. Factor 1: Instruction and Evaluation; Factor 2: Knowledge, Ethics, and Preparation; Factor 3: Professional Dispositions; Factor 4: Professional Behaviors and Technology Use. For permission to use the TCS and to obtain a copy of it, please contact the first author, Jacqueline Swank, at jswank@coe.ufl.edu

The TCS domains and items may help educators identity key teaching content to address within the curriculum (i.e., knowledge of teaching theories within a foundational teaching course, practice of teaching skills within a teaching internship course). Reviewing the TCS may also help doctoral students develop awareness about the necessary knowledge, skills, professional behaviors, and dispositions of effective counselor educators, similarly to reviewing the teaching competencies (Swank and Houseknecht 2019).

The participants’ demographic data also contributes to the counselor education literature on teaching. Specifically, in the current study, only $1 6 \%$ of the 288 participants reported no teaching coursework, compared to $5 4 \%$ of the 262 participants in Hall and Hulse (2010) study. This increase in coursework may relate to a growing emphasis on teaching preparation within counselor education doctoral programs, as indicated within the 2016 CACREP Standards. Counselor educators may use the TCS to assess doctoral students’ competencies during content knowledge courses, as well as teaching internship experiences. The use of the TCS may help instructors communicate expectations for developing teaching competencies, and may help with grading within teacher preparation coursework and experiences, and well as remediation processes when necessary (Swank and Houseknecht 2019), similar to other competency scales (Swank and Lambie 2012; Swank, Lambie, and Witta 2012).

Nearly half (141 participants; $4 9 \%$ ) of the participants reported strong or good teaching preparation, with an additional 83 $( 2 9 \% )$ participants reporting adequate teaching preparation. This appears to contradict previous studies focused on doctoral students’ level of preparation and confidence in teaching; however, recent studies have focused on qualitative explorations and involved recent doctoral graduates (i.e., Waalkes et al. 2018), while the current study is a quantitative investigation and involves doctoral students and counselor educators at various points in their career. Nevertheless, researchers have emphasized the importance of teacher preparation, which supports the development of an instrument (i.e., TCS) to assist in the preparation of counselor educators as teachers.

In addition to the instructor’s evaluation of students’ performance, instructors and supervisors may have students engage in self-evaluation by completing the TCS, and then reflect on their strengths and areas for growth. Self-evaluation demonstrates taking responsibility for one’s own growth and development (Swank 2014). Counselor educators may also use the TCS to evaluate their own teaching competencies, as well as obtain feedback from colleagues. This may provide valuable insight about strengths and areas for growth within teaching, as counselor educators often receive limited teaching feedback, except for course evaluations completed by students (Swank and Houseknecht 2019). Finally, counselor educators may use the TCS during discussions with administrators outside of counselor education to help articulate areas of teaching competency within counselor education, such as an emphasis on gatekeeping. Thus, academicians can use the TCS in a variety of ways to support the development of teaching competencies.

# Limitations and recommendations for future research

There are limitations to consider within this study. Regarding the sample, the nonresponse rate is unknown. There was also only a small representation of diverse groups in the sample, with the majority of participants being White. Additionally, although the researchers developed the items based on previous research, this is the first examination of the instrument.

Future research may focus on addressing the limitations in this study, including further examination with a more racially and ethnically diverse sample, and a larger sample of doctoral students. Further examination of the psychometric properties of the TCS may also involve comparing the TCS with other methods of evaluating teaching effectiveness (i.e., course evaluations). Additionally, scholars may compare doctoral students’ TCS self-evaluations to instructor or supervisor evaluations of the doctoral students’ teaching competencies. Research may also focus on examining the perceived development of teaching competencies across a doctoral program or academic career through a longitudinal study. Furthermore, researchers may investigate the psychometric properties and use of the TCS within preparation programs for other helping professions (i.e., psychology, social work).

# Conclusion

This study focused on the development of the TCS to assess teaching competencies within counselor education. Teaching is a foundational area within counselor education and it is crucial to foster the development of effective teachers. Through the use of the ${ \mathsf { T C S } } ,$ both counselor educators and counselor education doctoral students can work to promote quality teaching to help prepare effective counselors and counselor educators.

# Disclosure statement

No potential conflict of interest was reported by the authors.

# References

American Counseling Association (ACA). 2014. ACA code of ethics. Author.   
Association for Counselor Education and Supervision, Teaching Initiative Taskforce (ACES). 2016. Best Practices in Teaching in Counselor Education. https://www.acesonline.net/sites/default/files/ACES%20Teaching%20Initiative% 20Taskforce%20Final%20Report%20Oct%2023%202016%20.pdf   
Baltrinic, E. R., M. Jencius, and J. McGlothlin. 2016. “Coteaching in Counselor Education: Preparing Doctoral Students for Future Teaching.” Counselor Education and Supervision 55 (1): 31–45. doi:10.1002/ceas.12031.   
Barrio Minton, C. A., C. Wachter Morris, and L. D. Yaites. 2014. “Pedagogy in Counselor Education: A 10-Year Content Analysis of Journals.” Counselor Education and Supervision 53 (3): 162–177. doi:10.1002/j.1556-6978.2014. 00055.x.   
Benton, S. L., and W. E. Cashin. (2012). Student Ratings of Teaching: A Summary of Research and Literature. IDEA Paper #50. https://www.ideaedu.org/Portals/0/Uploads/Documents/IDEA%20Papers/IDEA%20Papers/PaperIDEA_ 50.pdf.   
Benton, S. L., and K. R. Ryalls. (2016). Challenging Misconceptions About Student Ratings of Instruction. IDEA Paper #58. https://www.ideaedu.org/Portals/0/Uploads/Documents/IDEA%20Papers/IDEA%20Papers/PaperIDEA_58.pdf.   
Buller, A. 2016. “Exploring the Experiences of Award Winning Teaches in Counselor Education: A Qualitative Inquiry.” The Online Journal of Counseling and Education 5: 14–28.   
Calaguas, G. M. 2012. “Teacher Effectiveness Scale in Higher Education: Development and Psychometric Properties.” International Journal of Research Studies in Education 2 (2): 3–20. doi:10.5861/ijrse.2012.108.   
Carroll, C., and D. O’Loughlin. 2014. “Peer Observation of Teaching: Enhancing Academic Engagement for New Participants.” Innovations in Education and Teaching International 51 (4): 446–456. doi:10.1080/14703297.2013. 778067.   
Catano, V. M., and S. Harvey. 2011. “Student Perception of Teaching Effectiveness: Development and Validation of the Evaluation of Teaching Competencies Scale (ETCS).” Assessment & Evaluation in Higher Education 36 (6): 701–717. doi:10.1080/02602938.2010.484879.   
Chamberlain, J. M., M. D. Artrey, and D. Rowe. 2011. “Peer Observation of Teaching: A Decoupled Process.” Active Learning in Higher Education 12 (3): 189–201. doi:10.1177/1469787411415083.   
Council for Accreditation of Counseling and Related Educational Programs (CACREP). 2015. 2016 Standards. http:// www.cacrep.org/wp-content/uploads/2012/10/2016-CACREP-Standards.pdf   
Council for Accreditation of Counseling and Related Educational Programs (CACREP). 2018. CACREP vital statistics 2017: Results from a national survey of accredited programs. Author.   
DeVellis, R. F. 2017. Scale Development: Theory and Applications (4th ed.). Thousand Oaks, CA: Sage.   
Dillman, D. A., J. D. Smyth, and L. M. Christian. 2014. Internet, Mail, Phone, and Mixed-Mode Surveys: The Tailored Design Method (4th ed.). New York, NY: Wiley.   
DiVall, M., Barr, J. Gonyeau, M. Matthews, S. J. Amburgh, J. Van Qualters, D. and Trujillo, J. 2012. “Follow-up Assessment of a Faculty Peer Observation and Evaluation Program.” American Journal of Pharmaceutical Education 76 (4): 61. doi:10.5688/ajpe76461.   
Hall, S. F., and D. Hulse. 2010. “Perceptions of Doctoral Level Teaching Preparation in Counselor Education.” Journal of Counselor Preparation and Supervision 1 (2). doi:10.7729/12.0108.   
Hill, L. H. 2014. “Graduate Students’ Perspectives on Effective Teaching.” Adult Learning 25 (2): 57–65. doi:10.1177/ 1045159514522433.   
Mundfrom, D. J., D. G. Shaw, and T. L. Ke. 2005. “Minimum Sample Size Recommendations for Conducting Factor Analyses.” International Journal of Testing 5 (2): 159–168. doi:10.1207/s15327574ijt0502_4.   
Parry, S. B. 1996. “The Quest for Competencies.” Training 33: 48–54.   
Pietrzak, D., K. Duncan, and J. S. Korcuska. 2008. “Counseling Students’ Decision Making regarding Teaching Effectiveness: A Conjoint Analysis.” Counselor Education and Supervision 48 (2): 114–132. doi:10.1002/j.1556-6978. 2008.tb00067.x.   
Prieto, L. R. 2012. “Initial Factor Analysis and Cross-Validation of the Multicultural Teaching Competencies Inventory.” Journal of Diversity in Higher Education 5 (1): 50–62. doi:10.1037/a0026199.   
Ryan, M. 2015. “Framing Student Evaluations of University Learning and Teaching: Discursive Strategies and Textual Outcomes.” Assessment & Evaluation in Higher Education 40 (8): 1142–1158. doi:10.1080/02602938.2014.974503.   
Schneider, M., and F. Preckel. 2017. “Variables Associated with Achievement in Higher Education: A Systematic Review of Meta-Analyses.” Psychological Bulletin 143 (6): 565–600. doi:10.1037/bul0000098.   
Spooren, P., B. Brockx, and D. Mortelmans. 2013. “On the Validity of Student Evaluation of Teaching: The State of the Art.” Review of Educational Research 83 (4): 598–642. doi:10.3102/0034654313496870.   
Stekhoven, D. J., and P. Buhlmann. 2012. € “MissForest-non-parametric Missing Value Imputation for Mixed-type Data.” Bioinformatics (Oxford, England) 28 (1): 112–118. doi:10.1093/bioinformatics/btr597.   
Swank, J. M. 2014. “Assessing Counseling Competencies: A Comparison of Supervisors’ Ratings and Student Supervisees’ Self-Ratings.” Counseling Outcome Research and Evaluation 5 (1): 17–27. http://doi.org/dw56. doi:10. 1177/2150137814529147.   
Swank, J. M., and A. Houseknecht. 2019. “Teaching Competencies in Counselor Education: A Delphi Study.” Counselor Education and Supervision 58 (3): 162–176. http://doi.org/dw57. doi:10.1002/ceas.12148.   
Swank, J. M., and G. W. Lambie. 2012. “The Assessment of CACREP Core Curricular Areas and Student Learning Outcomes Using the Counseling Competencies Scale.” Counseling Outcome Research and Evaluation 3 (2): 116–127. http://doi.org/dw58. doi:10.1177/2150137812452560.   
Swank, J. M., and G. W. Lambie. 2016. “Development of the Research Competencies Scale.” Measurement and Evaluation in Counseling and Development 49 (2): 91–108. http://doi.org/dn92. doi:10.1177/0748175615625749.   
Swank, J. M., G. W. Lambie, and E. L. Witta. 2012. “An Exploratory Investigation of the Counseling Competencies Scale: A Measure of Counseling Skills, Dispositions, and Behaviors.” Counselor Education and Supervision 51 (3): 189–206. http://doi.org/dw59. doi:10.1002/j.1556-6978.2012.00014.x.   
Tang, F., and H. Ishwaran. 2017. “Random Forest Missing Data Algorithms.” Statistical Analysis and Data Mining: The ASA Data Science Journal 10 (6): 363–377. doi:10.1002/sam.11348.   
Tigelaar, D., D. Dolmans, I. Wolfhagen, and C. Van der Vleuten. 2004. “The Development and Validation of a Framework for Teaching Competencies in Higher Education.” Higher Education 48 (2): 253–268. https://doi.org/ 10.1023/B. :HIGH.0000034318.74275.e4 doi:10.1023/B:HIGH.0000034318.74275.e4.   
Waalkes, P. L., J. M. Benshoff, J. Stickl, P. J. Swindle, and L. K. Umstead. 2018. “Structure, Impact, and Deficiencies of Beginning Counselor Educators’ Doctoral Teaching Preparation.” Counselor Education and Supervision 57 (1): 66–80. https://doi.org/10.1002/ceas.1209. doi:10.1002/ceas.12094.   
Winchester, T. M., and M. K. Winchester. 2014. “A Longitudinal Investigation of the Impact of Faculty Reflective Practices on Students’ Evaluations of Teaching.” British Journal of Educational Technology 45 (1): 112–124. doi:10. 1111/bjet.12019.