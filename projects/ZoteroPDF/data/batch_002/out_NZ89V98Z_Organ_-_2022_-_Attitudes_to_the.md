# Attitudes to the use of Google Translate for L2 production: analysis of chatroom discussions among UK secondary school students

Alison Organ

To cite this article: Alison Organ (2022): Attitudes to the use of Google Translate for L2 production: analysis of chatroom discussions among UK secondary school students, The Language Learning Journal, DOI: 10.1080/09571736.2021.2023896

To link to this article: https://doi.org/10.1080/09571736.2021.2023896

# Attitudes to the use of Google Translate for L2 production: analysis of chatroom discussions among UK secondary school students

Alison Organ $\textcircled{1}$

School of Education, Language and Psychology, York St John University, York, UK

# ABSTRACT

This paper presents the findings of a research project on UK school students’ attitudes to the use of Free Online Machine Translation for L2 production and more specifically in preparing for assessment. Data were collected from a publicly available online forum to analyse students’ spontaneous discussion of the use of Free Online Machine Translation, predominantly Google Translate. The majority of relevant comments were posted by secondary school students in the UK, regarding the use of Google Translate for GCSE examinations. The findings reveal that use of Google Translate for assignments was accepted practice among secondary school students in the UK over the last decade. However, they show mixed attitudes to this usage, and the nature of the discussion changed over the decade as a result of the evolution of Google Translate and changes to UK examination requirements. This study is original in its use of netnography, the study of online communities, to analyse students’ comments to each other about their use of Google Translate in preparing for modern foreign languages (MFL) coursework. These findings, therefore, serve to inform the debate on how schools and universities should respond to student Google Translate usage for language learning and assignments.

# KEYWORDS

Google Translate; Free Online Machine Translation; language assignments; secondary assessment; GCSE

![](img/9dbdfda5f96837dc0b362dfb072782baa4220872d54602b4309acc546befee11.jpg)

# Introduction and rationale

Since the creation of Free Online Machine Translation (FOMT) tools such as Google Translate, language teachers have struggled to combat their students’ use of them. In order to better understand how and why their students are using these tools, language educators all over the world have carried out extensive research over the last decade, mainly in the form of surveys and case studies. These have addressed themes such as student and staff attitudes to the use of machine translation, the efficiency and accuracy of the tools, and the extent to which this use constitutes plagiarism and can be detected. However, they all share a common issue: students are generally asked to reveal their use of this controversial tool to the researcher, who may be from their own establishment, and complete honesty can therefore not be guaranteed.

This unique case study explores UK student attitudes to the use of Google Translate as voiced spontaneously to each other (rather than to a researcher) in comments submitted to The Student Room (https://www.thestudentroom.co.uk/), a publicly available online forum, between 2010 and 2020. The Student Room is a UK-based community forum for students to ask each other questions about topics such as subjects they are studying, school and university courses, accommodation, finance and personal matters. The time period was determined by the results: as will be explained further in the methodology, a search in 2020 for ‘Google Translate’ in the Student Room produced ‘hits’ dating back to 2009. Google Translate is generally acknowledged to be the most widely used of the FOMT tools available (Aiken and Balan 2011; Allué 2017; Clifford et al. 2013). As will be seen, the vast majority of enquiries were posted by secondary school students, with very few from university students; the focus of this study is therefore on the attitudes of school-age students in the UK to the use of Google Translate for public examinations.

# Literature review

# Previous research

Although numerous researchers have already explored student attitudes to the use of machine translation in language learning, these studies have largely been case-study or survey-based and have also been carried out in higher education settings. Case studies including those by Garcia and Pena (2011), Groves and Mundt (2015), and Kol, Schcolnik and Spector-Cohen (2018) have explored how FOMT can be used by university students of English to improve their writing. Among others, Bower (2010), Korošec (2011), Kumar (2012), Clifford et al. (2013a, 2013b), Sukkhwan (2014), Groves and Mundt (2015), Jolley and Maimone (2015), Farzi (2016), Alhaisoni and Alhaysony (2017) and Maulidiyah (2018) have carried out surveys of FOMT usage by university students studying European languages (including English) at institutions outside the UK, while Somers et al. (2006) and Niño (2009) carried out research involving students of modern foreign languages (MFL) in the UK. This is the first study of school-aged UK students’ own FOMT usage (as opposed to tasks given to them), as evidenced by the fact that the majority of the posts relevant to this study concerned GCSEs, with a smaller number from A level students. In the UK, GCSEs are largely taken at the end of year 11 (when students are approximately 16 years of age), and A levels at the end of year 13, (18 years of age).

While the findings from the above-mentioned surveys differ slightly in terms of the numbers of students declaring their use of FOMT to translate words, sentences or paragraphs, all report that students find the tools useful and that some admit to using them for assignments. This is striking in the light of the period covered by these reports and the issues with machine translation reliability before the advent of Google’s Neural Machine Translation system (GNMT) in 2016, which we will explore later.

Farzi (2016) devotes more attention than the previous studies to the extent to which students post-edit the results of their machine translation usage, citing Niño (2009) and O’Neill (2012) who had both concluded that texts written by students using post-edited machine translation output were superior to those not using machine translation tools. Farzi postulates: ‘Exploring ways to improve the quality of students [sic] interactions with the tools is probably a more productive pedagogical strategy than disregarding or disallowing a tool that may actually have pedagogical value for L2 students’ (Farzi 2016: 172).

Bower’s (2010) study, of 258 students of English in Japan in 2009, is particularly relevant to this research in its focus on the students’ arguments for and against the use of machine translation. $6 9 \%$ of students questioned in his survey claimed not to have used machine translation at all for writing, citing reasons such as unawareness of the tools, the fact that it was not a good learning technique, they could write better without it, their teacher had told them not to, or they considered it cheating. It will be seen that these opinions are echoed in many of the responses in our study. It must also be noted that this is a relatively early study in terms of Google Translate’s reliability, and that Japanese does not lend itself so easily to machine translation (Aikawa 2015). Of total respondents, $2 2 \%$ said that they considered use of machine translation for assignments to be cheating, and $5 2 \%$ thought that the teacher would be able to spot its usage in their work. As the researcher says, this contrasts with his own experience: given the number of students claiming to use it $( 3 1 \% )$ , he estimates that he identifies between $8 \%$ and $1 6 \%$ of usage. He cites Ruthven-Stuart (2008) who ‘has shown that English language teachers in Japan have difficulty discriminating written production from low-level English learners which has used OMT [online machine translation] from written work which has not used OMT’ (Bower 2010: 3).

This conclusion is borne out by Somers et al. (2006) and Groves and Mundt (2015) who both focus on students’ use of machine translation for assignments. Echoing Ruthven-Stuart (2008), Somers et al express their shock that ‘the standard of translation achieved by FOMT might be worthy of a C grade – a moderate pass – at ‘A’ level’ (Somers et al. 2006: 2). Groves and Mundt consider machine translation outputs from an IELTS (International English Language Testing System) perspective, reporting that errors are tolerated even at level 6.0, and posing the question: ‘After all, why would a potential student go to the effort and expense of learning a foreign language if she is able to produce an acceptable L2 text from her own L1 writing, instantly and with no financial cost?’ (Groves and Mundt 2015: 113).

There are two further studies which involve school-age pupils, one in Sweden and one in the UK. The study by Josefsson (2011) involved upper secondary school pupils in Sweden who were asked to undertake a post-editing task by using Google Translate to translate a text, then discussing the output. They were then given a questionnaire asking them about their own use of Google Translate, which, like the previously-cited studies, showed that the students used it extensively. Josefsson concludes that the students showed a ‘critical awareness’ of the translation tool and ‘increased awareness of their own learning processes’ (Josefsson 2011: 23) and calls for further research into how activities using Google Translate could be integrated into the classroom.

The research by Somers et al. (2006) is the only study to my knowledge which takes A level students in the UK as its subjects, albeit as a minor part of their study: they carried out experiments with 20 university students of Italian and Spanish and five A level students of German. However, their study differs from my own in several ways: their focus was on plagiarism detection (whether the use of FOMT by students could be detected in assignments) and involved an experiment, rather than an analysis of student usage or attitudes. They asked their participants to translate a text or to post-edit the FOMT translation of it and analysed the two outputs for patterns. Their results were inconclusive, finding that while ‘the mistakes made by MT systems are sufficiently different from those made by language learners to permit some sort of automatic detection’, this detection necessitated the use of computational stylometry and would only ‘signal to the teacher that the work might be plagiarized’ (Somers et al. 2006: 7, original emphasis).

Several of these previous researchers (Correa 2014; Farzi 2016; Groves and Mundt 2015; Jolley and Maimone 2015) conclude that it will henceforward either be impossible or unnecessary to prevent students from using Google Translate either for their own development or in assignments. They argue that the language instructor’s task should be to bring the tool into the classroom and train students how to use it more effectively, rather than using it covertly and possibly without discernment.

These themes of prevalence of usage, types of usage (for formative work or assignments), arguments for and against usage, the need for post-editing, and the debate around cheating and plagiarism, find echoes in the comments gathered in this study, with the difference that in this case they were posted spontaneously by students rather than elicited in surveys.

# Language learner attitudes and motivation

There has been substantial investigation over the last few decades into the impact of attitudes and motivation on language learners and their success or lack of it. In successive publications, Gardner (1972 with Lambert, 1985a, 1991, 2005) coined and refined the concepts of integrative and instrumental motivation in second language learning. Integrative motivation involves the extent to which the learner wishes to identify with another language community, their attitude towards the learning situation, and their goal-directed behaviour (the amount of effort they are willing to expend to learn the language), while instrumental motivation relates to practical motives for learning the language, such as gaining a qualification.

This is echoed by Ames’ (1992) goal orientation theory which distinguishes between ‘mastery’ and ‘performance’ goals. While ‘mastery’ involves the ‘intrinsic value of learning’ (p. 262) and trying to improve their level of competence, a performance goal involves a focus on ability and self-worth. In this context, ability is evidenced by ‘doing better than others, by surpassing normative-based standards, or by achieving success with little effort (Ames 1984; Covington 1984)’ (Ames 1992: 262, my emphasis). The relevance to student use of Google Translate for assignments hardly needs highlighting.

Gardner (2005) further identifies language anxiety as a factor affecting language learning. This is particularly relevant to this study, as many of the students posting to the Student Room appear to be doing so as a result of a chronic lack of confidence in their ability. While acknowledging that anxiety can have motivational properties which may facilitate achievement, he posits that it also has ‘debilitating components that interfere with learning and production’ and is, therefore ‘generally negatively related to achievement as well as to self-confidence with the language’ (Gardner 2005: 8).

Horwitz et al. (1986) focus specifically on language anxiety, which can be caused by an expectation of error-free performance:

Certain beliefs about language learning also contribute to the student’s tension and frustration in the classroom. We note that a number of students believe nothing should be said in the foreign language until it can be said correctly and that it is not okay to guess an unknown foreign language word. Beliefs such as these must produce anxiety since students are expected to communicate in the second tongue before fluency is attained and even excellent language students make mistakes or forget words and need to guess more than occasionally. (Horwitz et al. 1986: 127)

Like Gardner, Dörnyei has spent much of his academic career exploring the nature and impact of motivation within second language acquisition, with a focus on self-determination theory, attribution theory, and goal theories. He cites Bernard Weiner (1992), the main proponent of attribution theory, who argues that the reasons to which we attribute past successes and failures shape our ‘motivational disposition’:

If, for example, we ascribe past failure on a particular task to low ability on our part, the chances are that we will not try the activity ever again, whereas if we believe that the problem lay in the insufficient effort or unsuitable learning strategies that we employed, we are more likely to give it another try. (Dörnyei 2003: 8–9).

This is relevant to our study as it would appear from some of the posts to the Student Room that posters are ascribing their past failure to their own low ability, and are reaching for external solutions rather than attempting to employ better learning strategies.

Dörnyei (2003) further cites Williams, Burden, and Lanvers’ (2002) study of British schoolchildren’s strategy use, which concludes that ‘most participants appeared to have great difficulty in discussing different aspects of their metacognitive strategy use and conveyed a lack of sense of control over their learning. … Very little evidence was found of planning behavior’ (Williams, Burden, and Lanvers 2002: 519; cited in Dörnyei 2003: 17).

This aspect of language learning attitudes and motivation, therefore, finds echoes in mindset theory, developed by Dweck et al. (1995), which differentiates between a fixed mindset (‘I failed the test because I am dumb’) and a growth mindset (‘I failed the test because of my effort or strategy’) (Dweck et al. 1995: 1). Mercer and Ryan (2010) apply this theory to L2 learning, suggesting that foreign language learning is ‘a domain in which the fixed mindset may be particularly prevalent, given the widespread belief in the importance of natural talent or aptitude in successful language learning’ (Mercer and Ryan 2010: 444).

They conclude that ‘the data suggest that, even in cases where a strong growth mindset exists, learners may feel frustrated and helpless without the tools and metacognitive knowledge of strategies to put their effort to focused use’ (Mercer and Ryan 2010: 443).

Lou and Noels (2019) further apply mindset theory to L2 motivation, devising the Language Mindsets Inventory (LMI) to gauge language learners’ attitude to language learning:

In addition to beliefs about general verbal intelligence in the native language (e.g. ‘people either have the talent in language-based abilities or not; they can’t change it’), beliefs about second language aptitude (e.g. ‘the ability to learn a foreign language is innate; it is immutable’) and beliefs about age and language learning ability (e.g. ‘people’s ability to learn languages is fixed by a certain young age; adults lose the capability to acquire languages’) are also important aspects of language mindsets. (Lou and Noels 2019: 2, original emphasis)

As mentioned above, these beliefs and mindsets are clearly represented in the data which forms the basis of the current research.

Ferrari (2013) also traces the history of research into attitudes and motivation in L2 learning, before formulating her own model. Although her research focusses on adult learners, her exploration of language learner motivation is enlightening. Her Fiume model (2013: 228) graphically represents the impact of various motivational factors over time during the language learning process, showing that initial personal motivation (either intrinsic or extrinsic) may be positively or negatively affected by external factors such as group dynamics and the relationship with the teacher as well as challenges and barriers to learning.

She cites Ushioda (2008) who calls for more qualitative research in L2 motivation, claiming that ‘the most promising line of inquiry lies in enabling language learners’ own voices and stories to take centre stage’ (Ushioda 2008: 29). While Ferrari emphasises the fact that her research focusses on language learners’ own words while the researcher remains in the background, the current study goes even further, in that the students quoted here voiced their opinions unelicited, without any input from the researcher.

# Evolution of Google Translate

When analysing the data below, it is important to acknowledge the evolution of Google Translate over the course of the decade in question. Google Translate was launched in 2006, using a statistical (Phrase-Based) Machine translation system (Le and Schuster 2016). This was replaced in 2016 by Google’s Neural Machine Translation system which offered a step-change in the accuracy and scope of the translations provided. Google Translate is now used by more than 500 million monthly users, searching for 140 billion words per day (Lewis-Kraus 2016). In an analysis of test translations in 2016, Google themselves claimed that neural machine translation was fast approaching human translation, particularly in European languages (Le and Schuster 2016). In 2016, there were 2.5 billion sentence pairs in the Google Translate programme’s training material for English and French (Bates Ramirez 2016) and in 2020 the system was training on 25 billion sentence pairs from over 100 languages (Wiggers 2020).

As the name suggests, Google’s Neural Machine Translation system is designed to function in a similar way to the human brain, making connections and learning new information. This process does not generate sentences directly into the target language as the previous phrasebased systems did. Neural machine translation performs an analysis in two stages, encoding and decoding, by a process called deep learning (Shofner 2016). Importantly, as a step forward from the previous systems which proceeded word by word or phrase by phrase, the encoding of each new word takes into account what has happened earlier in the sentence (Le and Schuster 2016).

The implications for language teaching are clear. While machine translation was easily identified in its early stages through its inability to recognise context, it has now reached a point where it could arguably claim to provide its users with language of a higher quality than had been estimated by the researchers quoted above, who judged that it could produce results equivalent to the work of an average student.

# Changes in assessment methods

The other important relevant change over the last decade is the way in which students are assessed in public examinations in the UK. Before 2018, students were partially assessed by means of ‘controlled assessments’ or coursework, tasks which they could potentially prepare in advance and deliver by rote, although this had not been the intention when this assessment method was introduced. The amendment brought in for the examinations in summer 2018 (and therefore taught in classrooms from 2016) removed this element in favour of external ‘linear’ examinations carried out at the end of the course (Long 2015). While it might have been predicted that this would significantly affect the number of queries regarding student use of Google Translate in preparing for public examinations, it will be seen in the findings below that the number fell only slightly, although there was a slight change in the nature of the enquiries and responses to the Student Room forum.

The initial impetus for the research was a concern that use of FOMT (overwhelmingly Google Translate) for L2 production was becoming more and more prevalent among language learners, and that instructors and examination bodies were ignorant of the extent of this use for assignments (particularly public examinations). Following the investigation into previous research cited above, highlighting themes of attitude and motivation, prevalence and nature of use of Google Translate, arguments for and against usage, and the debate around cheating and plagiarism, the following research objectives were formulated:

. To investigate student attitudes to the use of Google Translate for L2 production as articulated spontaneously in an online chat room;   
. To determine to what extent students admit to using Google Translate for L2 production and more specifically for assignments.

# Methodology

The methodological framework adopted for this study is ‘netnography’, a term coined by Kozinets (2002), who defined it as ‘ethnography adapted to the study of online communities’ (2002: 1). According to Kozinets, it has distinct advantages:

As a method, “netnography” is faster, simpler, and less expensive than traditional ethnography, and more naturalistic and unobtrusive than focus groups or interviews. (2002: 1)

Netnography shares the methodological stages and procedures adopted in traditional ethnography: entrée (formulation of the research questions and identification of an appropriate online community for study), data collection, analysis and interpretation (Kozinets 2002). Kozinets raises the issue of ethical concerns in the light of the online and publicly accessible nature of the data:

Ethical concerns over ‘netnography’ turn on two nontrivial, contestable and interrelated concerns: (1) are online forums to be considered a private or a public site?, and, (2) what constitutes ‘informed consent’ in cyberspace? A clear consensus on these issues, and therefore on ethically appropriate procedures for ‘netnography,’ has not emerged. (2002, 8)

While he acknowledges that some scholars consider it to be unnecessary to gain informed consent for the use of data posted in a public area (Sudweeks and Rafaeli 1995 cited in Kozinets 2002: 8), he himself and a number of other researchers are more cautious. They feel that ‘“netnographers” would be wise to consider the chief ethical concerns apparent in “netnography”: privacy, confidentiality, appropriation of others’ personal stories, and informed consent’ (Sharf 1999, cited in Kozinets 2002: 9).

The data in this study were gathered by taking a purely observational stance, (in Kozinets’ terms, ‘lurking’), as opposed to participating in the forum and revealing the fact that the research was being carried out. Costello et al. (2017) also debate the ethics of ‘lurking’, citing Alavi et al. (2010) who believe that a purely observational stance ensures that ‘the analysis is conducted in the natural context of the community and thus is free from the bias which may arise through the involvement of the researcher or experimental research setting’ (Alavi et al. 2010: 88; cited in Costello et al. 2017: 6). In the case of this study, consent from posters to the forum was not sought: the Student Room forum shows only their username and no other information which could lead to their identification. Although some comments reveal potentially controversial material such as an admission to having used Google Translate in assignments, their identity is hidden so there could be no repercussions. To address Sharf’s concerns regarding ‘privacy, confidentiality, appropriation of others’ personal stories, and informed consent’ cited above, it was felt that contributors were sharing their personal stories and opinions freely on a publicly available forum and must therefore be aware that this was neither private nor confidential. Ethical approval was of course obtained for the project and the collection of this data.

There is some debate in the literature regarding what actually constitutes netnography. Costello et al. (2017) discuss its origins, stemming from studies of consumer behaviour and opinion as voiced spontaneously by members of online communities to each other, rather than to researchers in surveys, interviews or focus groups. Costello et al. (2017) suggest that

the analysis of archived online textual data by off-line researchers who have never actively participated in the communities for which, and through which that data was created, is perhaps more appropriately categorized as archival research than as netnography or ethnography. (2017: 7)

They argue for a more active, participatory approach, leading to a co-creation of knowledge with the online community studied.

Nevertheless, they concede that in his more recent work, Kozinets emphasises that, in a netnographic study, a ‘significant’ amount of data collection ‘originates in and manifests through the data shared freely on the internet’ (Kozinets 2015: 79; cited in Costello et al. 2017: 2). They also quote Kozinets as claiming that netnography has a ‘voyeuristic quality’ because it can be used to ‘reveal discourse about hidden and stigmatic behaviours that may be more difficult to study in person’ (Kozinets 2015: 88; cited in Costello et al. 2017: 3).

This resonates with the current study, as it is likely that language students might be reluctant to speak openly about their use of Google Translate in assignments or in preparing for exams. For this reason, despite Costello et al’s (2017) reservations about a non-participatory or passive approach, it is felt that the research described here can still be identified as netnography as opposed to, for example, qualitative content analysis, because of its nature as the ‘unobtrusive and noninfluencing monitoring of the communication and interaction of community members to gain practical insights into their usage behaviour’ (Pollok et al. 2014: 2; cited in Costello et al. 2017: 3).

The aim of the study was to carry out a qualitative analysis of contributions to The Student Room which referred to the use of Google Translate in the context of language learning and, more specifically, in preparing for public examinations.

A search in late 2020 of the Student Room forum for the term ‘Google translate’ returned 2149 results. Of these, 88 posts and 175 responses from 2010 to 2020 were identified as providing information relevant to this study. The posts selected as relevant were chosen because they addressed issues regarding the use of Google Translate for language learning and particularly for public examinations in the UK such as GCSE or A Level as explained above. Many of the other posts included elements such as offers of translation unassociated with public examinations, general discussions about the future of translation and language learning, questions about relationships with speakers of other languages, and issues with international students, all of which were judged to be outside the remit of this study.

The analytical framework used to investigate the students’ attitudes is thematic analysis, as defined by Braun and Clarke (2006). The data corpus comprises the total posts and responses produced by the search for ‘Google Translate’ in the Student Room forum, and the data set is the subset of posts and responses deemed relevant to this study by the researcher, namely those which referred to the use of Google Translate for L2 production and more specifically for assignments. An inductive semantic interpretative approach was used to analyse the data. This allows the researcher to identify prevalent themes from the data in the absence of previous theory, at a semantic or explicit level, followed by an attempt to ‘theorize the significance of the patterns and their broader meanings and implications’ (Braun and Clarke 2006: 84).

When the data were analysed, several themes were identified, which could further be broken down into subthemes. The overarching themes were the original poster’s motivation for posting, and responses which view the use of Google Translate favourably or unfavourably. The original posts show different motivations for posting: asking others to write, translate or correct work for them to submit as their own (often giving further information as to why they feel unable to do it themselves); asking whether teachers can spot its usage or whether it would be considered cheating; asking for exam or revision tips; asking for advice about courses, such as whether to take a language at GCSE or A level; and miscellaneous questions which do not fit into any of those categories. Many of these posts do not mention Google Translate specifically themselves, but elicit responses which do.

Regarding posts which offer an unfavourable view of the use of Google Translate for language production, a further sub-categorisation can be made. Some reasons pertain to the shortcomings of the tool itself, leading to comments that it is inaccurate, so teachers will be able to spot its use or students should not trust it. Others offer a judgment on the poster themselves, suggesting that they are lazy or cheating and that using Google Translate is a poor language learning technique.

The favourable comments are rather more complex in nature: some are almost boastful, asserting that they used Google Translate successfully for assignments and achieved excellent grades; some suggest that the use is common practice among students and portray the tool as a useful ally; others offer caveats suggesting that it can be used judiciously for short phrases; and a further sub-category offer linguistic advice such as post-editing the output, using the speech function to practise pronunciation, or using other online tools which provide more linguistic information.

# Findings

# Overview

Of the 88 posts studied, 60 $( 6 8 \% )$ relate to GCSE, 11 $( 1 3 \% )$ to A Level or International Baccalaureate, and 17 $( 1 9 \% )$ either do not mention a public exam or are concerned with other situations such as self-study or extra-curricular courses. Interestingly, none are posted by students identifying as studying languages at degree level.

The number of relevant posts per year increases then decreases during the time period represented, with very few posts per year from 2010 to 2013, rising to a peak in 2017 then falling off towards 2020 (Figure 1). This rise and fall in number through the decade is perhaps understandable as students became more familiar not only with Google Translate itself but also with social media and web forums, and also correlates with the move away from coursework.

![](img/3b71427d462c77eafe3e4f93f72acf982e9af28a22bc1273047ccecfe5905007.jpg)  
Type of enquiry per year.

An analysis of the type of enquiry posted over time shows that requests for peers to help them with their work were the most common type of post while controlled assessment was current, rising steadily over the period 2010-2017, whereas after the change, students posted more enquiries about tips for revision or exam success. There are still some requests for help with specific topics or tasks after 2018, but these are more often associated with the oral exam.

# Motivation for posting

As will be seen in the example below, several original posters (OP) explain that they do not feel their language ability is sufficient to cope with the demands of the coursework or exams, and that they need to ask for help from peers or resort to using Google Translate. This echoes the research into L2 learner motivation cited above, which highlights a lack of confidence leading to language anxiety.

However, it is clear that their teachers’ warnings may have had some effect, as many of these posts also express a lack of trust in Google Translate, or trepidation at the idea that they may be caught out. One post from 2015 specifically asks whether using Google Translate is breaking exam board rules, and whether ‘moderators at the exam board [would] pick up on it’.

It may shock teachers to learn that $4 1 \%$ of posts involve the poster asking fellow contributors to write, translate or correct a piece of work for an assignment; it is also interesting to read the variety of positive and negative responses to these requests, which we consider in more detail later. Another $4 1 \%$ of original posts ask for tips to revise for or succeed at a particular exam, $1 1 \%$ ask for advice regarding A level or university courses, $3 \%$ ask whether other contributors think that use of machine translation is cheating or that teachers will be able to spot it, and another $3 \%$ comment on its usefulness.

The following thread shows an excellent cross-section of the opinions expressed in this case study. The original post in 2016 asked for help with coursework:

I am doing some coursework on French (A writing piece which equates to only $1 5 \%$ of my GCSE) - and I needed a bit of help, so I was wandering [sic] if any French people / people who are good at French to possibly help me?

These responses (all from 2016) show a typical range of attitudes to Google Translate, which we shall go on to explore in more detail:

google translate is your friend. Don’t paste entire paragraphs into it, do small phrases or sentences, and use some of your knowledge to make sure it is correct.

try reverso– it’s better than google translate.

google translate is really not your best friend. Try memrise for topic specific vocab and use linguee.fr, it gives you words in context.

I don’t not use Google Translate as for quick translations, it’s usually very reliable. However, use sites such as word reference to check the accuracy of any long sentences or paragraphs.

Please don’t just ‘type it into google translate’ as some people on this thread have suggested - what’s the point of that, after all? What in earth are you learning by doing that?

When all posts and responses are analysed, $3 2 \%$ show a negative view of the use of Google Translate, and $2 2 \%$ a positive view. The remaining $4 6 \%$ are either framed as questions or show a mixed opinion or no particular opinion.

# Unfavourable views of Google Translate

The unfavourable comments show a variety of attitudes, some regarding Google Translate itself, and others targeting its users (Figure 2).

![](img/ee3ddc438112a98a630f5be101b25c1d16c1064de9e89a945668285e930d6577.jpg)  
Unfavourable comments $\%$ of total posts and comments).

Twenty one per cent (of the total comments) warn against using Google Translate because of the inaccuracy of the results or because it is untrustworthy, while $1 3 \%$ are sure that teachers will spot it. Contributors show a strong awareness of the failings of Google Translate, such as literal translation, translating words in the wrong context, incorrect tenses, and inconsistent grammar or syntax.

This leads many responders to argue that teachers will definitely be able to spot its usage. After one of the earliest posts in 2010, saying that the OP had used Google Translate because they ‘couldn’t be bothered’ with their French essay, but that their teacher had said they would be able to spot it, there are numerous responses confirming the teacher’s claim. Respondents explain that the teacher will notice at best a difference in writing style or a sudden use of more sophisticated vocabulary, or at worst, errors in grammar or syntax and words used in the wrong context.

It must be remembered that these comments were posted in 2010, when the tool was still relatively unreliable. However, more recently, responders were still advising against its use because Google Translate ‘messes up’ and it is harder to memorise material that one has not written oneself.

This introduces a more optimistic feature of the study, in that in several cases $2 4 \%$ of total comments), students take the time to help each other by giving advice rather than just agreeing or refusing to help them with a specific piece of work. This sometimes takes the form of recommending other tools, such as WordReference, Reverso, Linguee, SpanishDict, and Quizlet. Posts such as the example below from 2010 show an understanding of the linguistic advantages of using these tools as opposed to Google Translate:

Use the wordreference.com forums instead of google translate! The dictionary is far more extensive and you can choose words closer to the meaning you’re after, as too many words have more than one meaning to make online translators accurate! The people on there are also really helpful and if you need a full sentence translated or a tense explained or you can’t find the right word you’ll usually get several native speakers helping you out within minutes.

Other students help the OP by suggesting that they could use Google Translate but would need to post-edit it. Suggestions include reading it through ‘to check word order, tenses etc. to make sure it was all correct’, or even asking ‘a nerdy friend to fine-tune it’. Several respondents comment, however, that if you are going to post-edit the Google Translate output, you may as well do it yourself in the first place; one student discovered that it was ‘much quicker doing the whole thing myself with a dictionary than translating it all and proofreading’.

Some students, on the other hand, are willing to go to extreme lengths outside of the classroom to achieve success. One in particular, from 2015, explained a system they had used successfully four times: they used all the resources the teacher had given them as well as online tools to write a first draft, used a French spell check to ‘check for spelling, accents and grammar’, then posted it on forums ‘for people to mark’, then gave it to their teacher ‘for the final check’, before memorising it to write out on the day of the assignment. One might feel that despite the unorthodox methods, the thoroughness and perseverance of the student merit the 20/20 they claim the work received.

Although the motivation is often to successfully pass off the Google Translate (or peer) output as their own, these comments still show that the students have an element of linguistic awareness. Their advice also chimes with much of the previously-mentioned research into students’ use of FOMT which recommends bringing Google Translate out of the closet and instructing students in how to use it more effectively (Correa 2014; Farzi 2016; Groves and Mundt 2015; Jolley and Maimone 2015; Josefsson 2011). The evidence of students using linguistic strategies to improve their work also shows that those who respond to the OPs have a greater sense of control and heightened awareness of metacognitive strategies, echoing the research explored above (Dörnyei 2003; Lou and Noels 2019; Mercer and Ryan 2010).

Several of the respondents $7 \%$ of total comments) also raise another common issue regarding the length or complexity of texts translated, advising peers that while Google Translate can be used successfully for words or phrases, it is less accurate when used for sentences, paragraphs, or longer passages:

The odd phrase or two could be fine, but for a whole essay then I would think it would be obvious. At best they’ll just think you’re bad at French, at worst they’ll know you cheated. (2010)

This last comment brings us to the issue of some respondents’ criticism of the $\mathsf { O P } ^ { \prime } \mathsf { S }$ intention to use Google Translate. $1 3 \%$ of the total comments reproach users of Google Translate, $5 \%$ commenting that it is lazy, $5 \%$ cheating, and $3 \%$ a poor learning technique. As one critic points out:

If you care so little about learning a language, why even go to the effort of running it through a translator? You’re learning nothing by doing that, whereas by writing it yourself, you can learn from your mistakes. (2010)

# Favourable views of Google Translate

As mentioned above, however, $2 2 \%$ of total comments express satisfaction with Google Translate (Figure 3).

![](img/8f739f6de139c15ceace2ec39390ca453a5b71e4128061c5a28d22ed56d288bf.jpg)  
Favourable comments $\%$ of total posts and comments).

Twenty three per cent make it clear that they have used Google Translate for production in the target language, $9 \%$ specifying that this was for assignments, often with great success: several claim that they used it throughout their GCSE or A level course and achieved $\mathsf { A } ^ { \ast } \mathsf { s } ,$ the top grade available. One comment gives an interesting insight into a student’s view of the difference between GCSE and A level (the assessment at the time was divided into AS for the first year and A2 for the second year of study):

I got an $\mathsf { A } ^ { \ast }$ at GCSE and continued with French. I’m doing A2 now and I absolutely love it. See the thing is, the jump between GCSE and AS is difficult because you go from using google translate and memorising your coursework to actually having to learn the grammar rules and applying them in spontaneous situations. (2017)

What is striking about this comment is the implication that using Google Translate to produce the coursework and then memorising it was almost expected among students, with no suggestion that it could be construed as cheating. In fact, $3 \%$ of respondents suggest that use of Google Translate is common practice among their peers, one reassuring the OP that ‘I’m sure most students studying languages have used translators extensively at some point’. Worryingly for language teachers, $6 \%$ of comments claim that their teachers did not identify their usage of Google Translate, even back in 2010 when it was less reliable.

Several comments echo the observation by Somers et al. (2006) cited above, that Google Translate can achieve a similar result to a student of intermediate ability:

… I don’t see how they know the difference between Google badly translating it and you badly translating it, though. (2010)

Like someone said already, I think this says everything about the level expected from GCSE students. It really makes me wonder how anyone manages to fail, when google translate can get a C. (2010)

On a more optimistic note, as with the negative views, there are elements of the study which show language learning behaviour which may cheer language teachers. In addition to the alternatives to Google Translate already mentioned, a number of more recent respondents single out the speech function as being particularly useful. This also reflects the shift in the focus of the comments from written to spoken issues after 2018, when the written coursework element had been discontinued:

For improving your accent, copy your responses on to google translate and then play them, and try to copy what the voice says. (2017)

I also use good old google translate on my phone so I can listen to the pronunciation of words and things and also with some “extra help” for any particularly difficult homeworks. (2018)

For speaking, speak French as much as you can! Do little mini mocks by yourself. Get the google translate lady to read the question to you and respond straight from your head. (2019)

# Discussion and conclusion

From this study, it can be seen that students are looking both to each other and to online tools in their language learning. In answer to my research questions, we can see from the data that secondary school students between 2010 and 2020 admit to each other, if not to their teachers, that they are using Google Translate both for homework and for a range of assignments, for written coursework in the earlier years and preparation for the oral exam in the latter part of the decade. This betrays in many cases a lack of confidence in their own ability and an unwillingness to approach their teachers about it. It also echoes the research cited above regarding a fixed mindset and ‘performance goals’, by which students attempt to ‘achieve success with little effort’ (Ames 1992: 262).

On a more optimistic note, responses to the original posts exhibit a readiness to exploit internet resources and share good practice, showing evidence of a growth mindset. While the number of students willing both to ask for and provide assistance in producing target language for assignments is alarming, as is the number who claim to have used Google Translate extensively without repercussions, it is clear that others condemn this behaviour, some of them offering constructive alternatives such as tools or techniques.

It is accepted that this study has certain limitations, notably that some of the data refers to a version of Google Translate which has now been vastly improved, and that many of the posts refer to coursework assignments, which are no longer a feature of public exams in the UK (Long 2015). To address the first point, if students were willing to risk using Google Translate when it was acknowledged to be unreliable, they are arguably even more likely to be tempted to use it now that it is less detectable. Secondly, despite the fact that public exams no longer include a coursework component, the data shows that even post 2018, when the new specifications were implemented, contributors are still seeking help for essays or oral presentations which they intend to memorise. Furthermore, changes to public examinations in the future may bring about a return to ‘non-exam assessment’ (CLiE 2021: 5).

As mentioned above, previous researchers have argued that language instructors should accept that FOMT tools are here to stay, and train their students to use them effectively for formative activities:

If students can see that communicating in another language is not simply a matter of plugging words into a formula that can be calculated by a machine, they will begin to understand language and communication as complex and multilayered. (Williams 2006: 572)

This is echoed by Correa (2014) who also concurs with some of the student comments above, in reflecting that if they need to post-edit the output, they may as well do it themselves in the first place:

By asking learners to review and modify the text (be it the original or the translation), we emphasize the view that writing is a process and not just an end product (as the students planning to use the online translation might think). (Correa 2014: 16)

The problem with both of these comments is their age: since 2014, and definitely since 2006, Google Translate has evolved to the extent that it is able to produce highly accurate language, particularly in European languages and at the level expected at GCSE. Understandably, teachers are reluctant to embrace the tool in their teaching, as it would reveal to students just how useful it can be. At the same time, it is clear from MFL teaching networks (such as #mfltwitterati on Twitter and Secondary MFL Matters on Facebook) that teachers are increasingly frustrated by their students’ use of Google Translate in completing homework, particularly since the advent of remote teaching during the COVID 19 pandemic. There are no easy answers here; however, the move away from controlled assessment would seem to be helpful in the circumstances, and even if students use Google Translate to prepare for their oral exam, this demands some degree of mastery of the language acquired. It is beyond the scope of this study to offer solutions, but while the findings reveal a worrying lack of confidence among secondary school students in their ability to operate at the language level required, the responses showing a high level of linguistic awareness are also grounds for optimism.

This is the first netnographic study of student attitudes towards the use of Google Translate for L2 production and assignments, revealing student attitudes posted spontaneously to each other rather than elicited by a researcher. These findings confirm that use of Google Translate was accepted practice among school-age students in the last decade, and should help to inform the debate regarding language departments’ response to this behaviour. The findings also call for further research into higher education students’ current use of FOMT for take-home assignments, and an increased debate as to how to re-evaluate assessment at that level: my contention is that attitudes and practices exhibited here by students taking language GCSEs or A levels may be assumed to continue to exist among those who progress to higher education, and this has been borne out by further personal research (as yet unpublished). Coursework or ‘continuous assessment’ may no longer be an issue at GCSE or A level, but is widespread in higher education. This research throws into question the extent to which educators can trust the work submitted by students as their own. The debate at higher education level has already begun, but it throws up more questions than it answers in terms of what constitutes plagiarism and how assessment policies should be adapted in the light of increasing evidence of student FOMT usage.

# Disclosure statement

No potential conflict of interest was reported by the author(s).

# ORCID

Alison Organ $\textcircled{1}$ http://orcid.org/0000-0001-6028-5341

# References

Aikawa, T. 2015. Challenges for English into Japanese machine translation (MT): can we embrace machine translation for language teaching? Presented at University of Michigan, February 2016. https://jat.org/blog/challenges_for_ english_into_japanese_machine_translation_mt.   
Aiken, M., and S Balan. 2011. An analysis of Google Translate accuracy. Translation Journal 16, no.2. http://www. bokorlang.com/journal/56google.htm.   
Alavi, S., V. Ahuja, and Y Medury. 2010. Building participation, reciprocity and trust: netnography of an online community of APPLE using regression analysis for prediction. Apeejay Business Review 11: 82–96.   
Alhaisoni, E., and M. Alhaysony. 2017. An investigation of Saudi EFL university students’ attitudes towards the use of Google Translate. International Journal of English Language Education 5, no. 1: 72–82. [Internet] http://www. macrothink.org/journal/index.php/ijele/article/view/10696/8598.   
Allué, B.R. 2017. The reliability and limitations of google translate: a bilingual, bidirectional and genre-based evaluation. Revista de Traducción y Comunicación Intercultural, February 2017: 67. [Internet]. http://entreculturasuma. comimagine.es/wp-content/uploads/2017/05/articulo05.BlancaRoigAllu%C3%A9.Entreculturas9.pdf.   
Ames, C. 1984. Competitive, cooperative, and individualistic goal structures: a cognitive-motivational analysis. Research on Motivation in Education 1: 177–207.   
Ames, C. 1992. Classrooms: goals, structures, and student motivation. Journal of Educational Psychology 84, no. 3: 261– 271. [Internet] https://psycnet.apa.org/doiLanding?doi $= 1 0 . 1 0 3 7 \% 2 5 0 0 2 2 { \cdot } 0 6 6 3 . 8 4 . 3 . 2 6 1$ .   
Bates Ramirez, V. 2016. A computer can now translate languages as well as a human. Singularity Hub, 4 October [Internet] https://singularityhub.com/2016/10/04/a-computer-can-now-translate-languages-as-well-as-a-human/.   
Bower, J. 2010. Japanese university students’ use of online machine translators for English writing tasks. [Internet]. https://kuis.repo.nii.ac.jp/?action $=$ repository_action_common_download&item_id $=$ 496&item_no $=$ 1&attribute_ $\mathsf { i d } = 1 8 \& \mathsf { f i l e \_ n o } = 1$ .   
Braun, V., and V Clarke. 2006. Using thematic analysis in psychology. Qualitative Research in Psychology 3, no. 2: 77–101. doi:10.1191/1478088706qp063oa.   
CLiE. 2021. Response to the DfE consultation on the GCSE by the Committee for Linguistics in Education (CLiE). [Internet] http://lagb.org.uk/forum/10519460.   
Clifford, J., L. Merschel, and J. Munné. 2013a. Surveying the landscape: what is the role of machine translation in language learning?. $@$ tic. revista d’innovació educativa, 10, January-June 2013: 108–121, (10). January-June, 2013, pp. 108-121 [Internet] http://www.redalyc.org/pdf/3495/349532398012.pdf.   
Clifford, et al. . 2013b. The Elephant in the room: machine translation in language learning at Duke University. [Internet]. https://learninginnovation.duke.edu/blog/2013/04/the-elephant-in-the-room-machine-translation-in-the-languageclassroom/.   
Correa, M. 2014. Leaving the “peer” out of peer-editing: online translators as a pedagogical tool in the Spanish as a second language classroom. Latin American Journal of Content and Language Integrated Learning 7, no. 2: 1–20. doi:10.5294/laclil.2014.7.1.1. eISSN 2322-9721. [Internet]. http://laclil.unisabana.edu.co/index.php/LACLIL/article/ view/3568/3411.   
Costello, L., M.L. McDermott, and R Wallace. 2017. Netnography: range of practices, misperceptions, and missed opportunities. International Journal of Qualitative Methods 16, no. 1, [Internet]. http://journals.sagepub.com/doi/full/10. 1177/1609406917700647.   
Covington, M.V. 1984. The motive for self-worth. In Research on Motivation in Education: Student Motivation, eds. C. Ames and R.E. Ames, Vol. 1, 77-113. San Diego.   
Dörnyei, Z. 2003. Attitudes, orientations, and motivations in language learning: advances in theory, research, and applications. Language Learning 53, no. S1: 3–32. [Internet] https://d1wqtxts1xzle7.cloudfront.net/56969942/D-rnyei2003-Language_Learning_1-with-cover-page-v2.pdf.   
Dweck, C. S., C. Chiu, and Y Hong. 1995. Implicit theories and their role in judgements and reactions: a word from two perspectives. Psychological Inquiry 6: 267–285. [Internet] https://www.tandfonline.com/doi/abs/10.1207/ s15327965pli0604_1.   
Farzi, R. 2016. Taming translation technology for L2 writing: documenting the use of free online translation tools by ESL students in a writing course. Doctoral diss., University of Ottawa. [Internet]. https://ruor.uottawa.ca/handle/10393/ 34585.   
Ferrari, L. 2013. The motivation of adult foreign language learners on an Italian beginners’ course: an exploratory, longitudinal study. Doctoral diss., University of York. [Internet] https://etheses.whiterose.ac.uk/4073/.   
Garcia, I., and M.I Pena. 2011. Machine translation-assisted language learning: writing for beginners. Computer Assisted Language Learning 24, no. 5: 471–487. [Internet]. https://www.tandfonline.com/doi/full/10.1080/09588221.2011. 582687.   
Gardner, R.C., and W.E Lambert. 1972. Attitudes and Motivation in Second-Language Learning. Rowley, MA: Newbury House Publishers. [Internet] https://eric.ed.gov/?id $=$ ED081270.   
Gardner, R. C. 1985a. Social Psychology and Second Language Learning: The Role of Attitudes and Motivation. London: Edward Arnold.   
Gardner, R. C. 2005. Integrative motivation and second language acquisition. Canadian Association of Applied Linguistics/Canadian Linguistics Association Joint Plenary Talk, May 30, 2005; London, Ontario. [Internet] http:// publish.uwo.ca/\~gardner/docs/caaltalk5final.pdf.   
Gardner, R.C. and P.D. MacIntyre, P.D. 1991. An instrumental motivation in language study: who says it isn’t effective? Studies in Second Language Acquisition 13, no. 1: 57–72. [Internet]. https://www.cambridge.org/core/journals/studiesin-second-language-acquisition/article/abs/an-instrumental-motivation-in-language-study/14DE6D1A5C5D60A2D9 252000ADE64352.   
Groves, M., and K Mundt. 2015. Friend or foe? Google Translate in language for academic purposes. English for Specific Purposes 37: 112–121. [Internet]. https://www.sciencedirect.com/science/article/pii/S088949061400060X.   
Horwitz, E.K., M.B. Horwitz, and J Cope. 1986. Foreign language classroom anxiety. The Modern Language Journal 70, no. 2: 125–132. [Internet] doi:10.2307/327317.   
Jolley, J., and L. Maimone. 2015. Free online machine translation: use and perceptions by Spanish students and instructors. In Learn Languages, Explore Cultures, Transform Lives: Selected Papers from the 2015 Central States Conference on the Teaching of Foreign Languages, ed. A.J. Moeller, 181–200. https://digitalcommons.unl.edu/cgi/viewcontent.cgi? article $=$ 1298&context $=$ teachlearnfacpub#page $= 2 0 2$   
Josefsson, E. 2011. Contemporary approaches to translation in the classroom: a study of students’ attitudes and strategies. [Internet] http://www.diva-portal.org/smash/record.jsf?pid $=$ diva2%3A519125&dswid $= 7 0 9 0$ .   
Kol, S., M. Schcolnik, and E. Spector-Cohen. 2018. Google Translate in academic writing courses? The EuroCALL Review 26, no. 2: 50–57. [Internet] https://polipapers.upv.es/index.php/eurocall/article/view/10140.   
Korošec, M.K. 2011. Applicability and challenges of using machine translation in translator training. ELOPE: English Language Overseas Perspectives and Enquiries 8, no. 2: 7–18. [Internet] https://revije.ff.uni-lj.si/elope/article/view/3226.   
Kozinets, R. 2002. The field behind the screen: using netnography for marketing research in online communities. Journal of Marketing Research 39, no. 1: 61–72. doi:10.1509/jmkr.39.1.61.18935. [Internet] http://www.nyu.edu/pages/classes/ bkg/methods/netnography.pdf.   
Kozinets, R. 2015. Netnography: Redefined. London, England: Sage.   
Kumar, A. 2012. Machine translation in Arabic-speaking ELT classrooms: applications and implications. International Journal of Social Science and Humanity 2, no. 6: 442–445. . [Internet] http://www.ijssh.org/papers/142-A00015.pdf.   
Le, Q., and M. Schuster. 2016. A neural network for machine translation, at production scale. [Internet]. https://ai. googleblog.com/2016/09/a-neural-network-for-machine.html.   
Lewis-Kraus, G. 2016. The great AI awakening. The New York Times Magazine, 14, p.12. [Internet] https://www.nytimes. com/2016/12/14/magazine/the-great-ai-awakening.html.   
Long, R. 2015. GCSE, AS and A level reform: briefing paper #06962. London, House of Commons Library. [Internet]. https://commonslibrary.parliament.uk/research-briefings/sn06962/.   
Lou, N.M., and K.A Noels. 2019. Promoting growth in foreign and second language education: a research agenda for mindsets in language learning and teaching. System 86. [Internet] doi:10.1016/j.system.2019.102126.   
Maulidiyah, F. 2018. To use or not to use Google Translate in English language learning. Jurnal Linguistik Terapan, 1–7. [Internet]. http://jlt-polinema.org/ $? p = 9 9 6$ .   
Mercer, S., and S Ryan. 2010. A mindset for EFL: learners’ beliefs about the role of natural talent. ELT Journal 64, no. 4: 436–444. [Internet] doi:10.1093/elt/ccp083.   
Niño, A. 2009. Machine translation in foreign language learning: language learners’ and tutors’ perceptions of its advantages and disadvantages. ReCALL 21, no. 2: 241–258. [Internet] doi:10.1017/S0958344009000172.   
O’Neill, E.M. 2012. The effect of online translators on L2 writing in French. Doctoral diss., University of Illinois, UrbanaChampaign. [Internet]. https://www.proquest.com/openview/bea7e311fd45ee30b4833fa235d91d16/1?pq-origsite $=$ gscholar&cbl=18750.   
Pollok, P., D. Lüttgens, and F. T Piller. 2014. . Leading edge users and latent consumer needs in electromobility: findings from a nethnographic study of user innovation in high-tech online communities. RWTH-TIM Working Paper, February 2014.   
Ruthven-Stuart, P. 2008. Machine translation websites: communication tools but an impediment to communicative competence? Presented at WorldCALL 2008, Fukuoka, Japan.   
Sharf, B.F. 1999. Beyond netiquette: the ethics of doing naturalistic discourse research on the internet. In Doing Internet Research: Critical Issues and Methods for Examining the Net, ed. S. Jones, 243–256. Thousand Oaks, CA: Sage.   
Shofner, K. 2016. Neural machine translation and the future. United Language Group. [Internet] https://www. unitedlanguagegroup.com/blog/neural-machine-translation-and-the-future.   
Somers, H., F. Gaspari, and A Niño. 2006. Detecting inappropriate use of free online machine translation by language students – a special case of plagiarism detection. Proceedings of the Eleventh Annual Conference of the European Association for Machine Translation, Oslo, Norway, 41-48. [Internet] https://www.aclweb.org/anthology/2006.eamt1.6.pdf.   
Sudweeks, F. and S. Rafaeli. 1995. How do you get a hundred strangers to agree? Computer-mediated communication and collaboration. In Computer Networking and Scholarship in the 21st Century University, eds. T.M. Harrison and T.D. Stephen, 115–136. New York: SUNY Press.   
Sukkhwan, A. 2014. Students’ attitudes and behaviors towards the use of google translate. Masters diss., Prince of Songkla University. [Internet] http://kb.psu.ac.th/psukb/bitstream/2010/9459/1/387714.pdf.   
Ushioda, E. 2008. Motivation and good language learners. In Lessons from Good Language Learners, ed. G Griffiths, 19– 34. Cambridge: CUP. [Internet] http://www.lenguasvivas.org/campus/files/0_28/motivation_and_lgelearners.pdf.   
Weiner, B. 1992. Human Motivation: Metaphors, Theories and Research. Newbury Park, CA: Sage.   
Wiggers, K. 2020. How Google is using emerging AI techniques to improve language translation quality. VentureBeat: The Machine. [Internet] https://venturebeat.com/2020/06/03/how-googleis-using-emerging-ai-techniques-toimprove-language-translation-quality/.   
Williams, L. 2006. Web-based machine translation as a tool for promoting electronic literacy and language awareness. Foreign Language Annals 39, no. 4: 565–578. [Internet] https://onlinelibrary.wiley.com/doi/full/10.1111/j.1944-9720. 2006.tb02276.x.   
Williams, M., R. L. Burden, and U Lanvers. 2002. ‘French is the language of love and stuff’: student perceptions of issues related to motivation in learning a foreign language. British Educational Research Journal 28: 503–528. [Internet] doi:10.1080/0141192022000005805.