# Reviews

# Genre-based Automated Writing Evaluation for L2 Research Writing: From Design to Evaluation and Enhancement. Palgrave Macmillan (2014). xvii $\mathbf { + 2 8 3 }$ pp., UK, GBP 29.95, 978-1-137-3336-0

As a teacher of writing, I appreciate resources that not only respect the complexity of writing, but which are accessible to my learners for interactive self-study. We may be used to pedagogical toolsdparticularly those digitaldwhich have had inflated claims. Cotos’s thorough and careful documentation of her conception, implementation, and classroom-based testing of her Research Writing Tool (RWT) “from design to evaluation to enhancement” is anything but inflated: She earns our trust through the deep documentation of the tool’s first iteration as the Intelligent Academic Discourse Evaluator, IADE, and calls on us to recognize how that tool was “effective when implemented as a supplemental formative tool”, importantly employed by teachers and learners within a research writing course (p. 210). Carol A. Chapelle rightfully frames the book in its forward as a “classic example of applied linguistics research” because “it defines a language-related problem, devises a solution drawing on relevant theory, research, and practice, and tests the solution in a manner that informs future action” (xv). I would also argue that it is a gift to CALL specialists modeling and inviting new augmented approaches to writing instruction.

Toward that gifted invitation, the book is divided into two parts: Part one (chapters 1–4) focuses on designing genre-based academic writing evaluation for L2 research writing, and part two (chapters 5–7), explicates implementation, evaluation and principled practical realization.

Chapter 1 reviews learning and teaching challenges of research writing. Both readers new to genre-based pedagogies and current practitioners will appreciate Cotos’s travel through cognitive and socio-disciplinary dimensions of research writing to definitions of “research writing competence” among L2 writers. Genre-based pedagogy is presented as an innovative answer, which connects linguistic and rhetorical approaches through the use of discipline specific corpora. The common challenge to such pedagogy in contexts where one research writing course is charged to serve scholars from multiple disciplines is the amount of individual and discipline-specific feedback truly possible across revisions through one instructor.

Before Automated Writing Evaluation (AWE) is offered as a way to further what an instructor and peer-learning could provide in genre-based pedagogy, in Chapter 2 Cotos traces its history as the “scoring and evaluation of written prose” (p.40). Educators as “consumers” greatly benefit from her review of the affordances and constraints of almost fifty commercialized and non-commercialized technologies spanning from 1966 to 2013. Criticisms and inflated claims of AWE are scrutinized. Given this smart analysis, the question becomes how to better conceptualize the writing needs of teachers and learners.

In Chapter 3 Cotos presents her conceptual model. She argues for the symbiotic relationship she has discovered, through practice at Iowa State University, between the theories of Systemic Functional Linguistics, Second Language Acquisition and Skill Acquisition Theory. Because these theories are not always thought of as complementary to each other, Cotos augments for the reader an operational framework integrating the three perspectives of Formative Assessment, Intelligent ComputerAssisted Learning, and Evidence-Centered Design that indeed allows for their actualization and integration.

With peaked curiosity, readers in Chapter 4, first see what the flesh of the Intelligent Academic Discourse Evaluator (IADE) looks like. Screen shots show us what a writer using IADE sees as they draft research introductions. We see how IADE colorlabels their introduction to point out the location of different Swalesian rhetorical moves, and how results of their attempts are logged in relation to distribution in their discipline. Writers are given both quantitative and formative feedback that feeds their evaluation and revision. To scaffold noticing of negative and positive evidence, writers can visit help options such as definitions of the moves, discipline specific statistics, and an annotated corpus of research articles. In looking at these articles, we revisit the large range of graduate majors motivating the project itself, 34, and learn of the 105 participants helping to investigate IADE’s effect. Scholars interested in the technical aspects of how text annotations were pulled from the corpus of 1000 published research article Introductions (50 disciplines, each discipline represented by 20 texts) are given a detailed roadmap here that would help them understand construction decisions, as well as do replication, if desired.

While Chapter 4 helps scholars consider construction and the prototype, Chapter 5 leads us through the implementation context and the methodological approach for investigating effectiveness. Chapelle’s (2001) evaluative criteria of Language Learning Potential, Meaning Focus, Learner Fit, and Impact Qualities are the framework for testing. We see rigorous mixed and triangulated methods set to collect data on users’ experiences from classwork on research articles. This data includes pretests, concurrent-revision elicitation data via think-aloud protocols, screen recordings, and observations, database data via automated evaluation, student drafts, and frequencies, and finally, post-revision interviews, post-tests, and surveys with open-ended and likert-scale questions. It is an impressive array, leaving no stone unturned.

With such careful rigor leading to its production and implementation, Chapter 5’s reporting of how the prototype was a success is no surprise. Yet a lack of surprise will likely not lessen the joy ESPj readers will experience from witnessing the many ‘ah-ha’ moments captured by users and the revelation of sequential and causative relationships between elements of their revision cycles. Here is a taste of the learning process experiences through some sample questions and answers:

How did you know that there were imperfections in your introduction? (Noticing of negative evidence) Because I saw the distribution of my moves in color and in percentages.

Why do you think you better understood how to build each move more effectively? (Enhanced understanding) Because I saw what and where my problems were and tried to clarify them. (Noticing of negative evidence)

Why did you make changes to particular parts of your introduction? (Output modification) Because I could see my problems and because I could better understand the purpose, function, and realization of each move (Noticing of negative evidence $^ +$ Enhanced understanding)

Why did you pay attention to your moves after resubmission (Focus on form) Because I wanted to see how good they were. (Output modification) (p.146).

As one would expect of a researcher of feedback, Cotos used feedback from participants to make improvements and expand IADE. For example, because users found the automated feedback verifying, but wanted even more elaboration and direction for remediation, Cotos furthered feedback and help option capabilities. Rather than the sole Analysis section of IADE, in RWT, there are three modules: Analysis, Demonstration, and Instruction. In the Analysis module users are no longer limited to drafts of a single research Introduction; they can now also analyze additional Introductions, other sections of a research paper, or their full research papers. The Demonstration module offers students a function-based concordancer that can be queried for examples of specific steps within moves of each research article section. Annotated corpora are expanded from 20 to 30 articles and the original publication can be called up for any of the articles, whenever the learner sees fit. Learner control of their own path is reinforced in the new Instruction module, which includes videos of an instructor who presents short lectures explicating and demonstrating the realization of individual moves with examples. The new “Language focus guidelines” highlight some lexico-grammatical patterns characteristic of a given article section. Better visualizations and options for personalization were also added such as comparative pie-charts and bar graphs, smileys, Facebook-like thumbs, and the ability to save intra-personal comments on one’s own writing.

Cotos’s conclusion to her book, “glimpse into the future” is actually a coda reiterating the strength of design-based research which is constantly generative and improving. She is already thinking of ways to add,

intricacies of both individual cognitive and social dimensions (for example peer feedback, teacher feedback, disciplinary expert feedback, peer blogs, integration of student-compiled corpora, individual planning options and idea logs, study tutorials) by creating a remote collaboration environment supported by communities of practice (p.249).

Though I know of no other tool of its kind, Cotos pioneers not only the tool, but a model for design-based research by teachers. This impassioned bookdjustified by the work of theoretical, operational and empirical rationalesdinvites and demonstrates the “long-awaited” path for scholarsdat all levelsdto “inform a socio-cognitive-model of the revision process supported by interactive intelligent learning technologies” (p.249). It is an essential read for educators who see the art of teaching as a science which innovates from the messy realities of the classroom. The complex needs (and assets) of multilingual writers and their teachers are deeply respected throughout the text.