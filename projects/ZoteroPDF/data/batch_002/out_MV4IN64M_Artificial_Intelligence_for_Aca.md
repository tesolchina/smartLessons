# Artificial Intelligence for Academic Purposes (AIAP): Integrating AI literacy into an EAP module

Thu Ngan Ngo a,b,\*, David Hastie b

a University Centre for Academic English, University of Manchester, Samuel Alexander Building, Manchester M13 9PL, UK b International College Dundee, University of Dundee, 2 Airlie Place, Dundee, DD1 4HQ, UK

# a r t i c l e i n f o

# a b s t r a c t

Article history:

Keywords:   
AI literacy   
English for Academic Purposes (EAP)   
Higher education   
AI integration in education   
International students

With the rise of generative AI (GenAI) tools such as ChatGPT and their growing relevance in academic contexts, the need for AI literacy has become imperative, particularly for international students in EAP programs. The study addresses the gap in practical guidance for incorporating AI literacy by developing and implementing a 10-week AI-integrated EAP module at a pathway college in Scotland based on a novel framework termed AI for Academic Purposes (AIAP). Utilising a mixed-methods approach, the research investigates the impact of this module on international students’ attitudes, confidence, and purposes of using AI tools. Results of this study indicate significant improvements in students’ ability to critically evaluate GenAI output, confidence in using a greater variety of AI tools, understanding of ethical AI use, and an expansion in the purposes for which students use AI tools. The integration of AI literacy with traditional EAP skills was found to meet students’ academic needs effectively. This study provides a replicable model for integrating AI literacy into EAP courses, offering a holistic educational approach that aligns technological proficiency with ethical awareness.

$^ { © }$ 2024 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).

# 1. Introduction

Generative AI (GenAI) is a type of artificial intelligence that can create new content such as texts, images and videos. Users can input text or ‘prompts’ to GenAI tools such as ChatGPT or Microsoft Co-pilot and quickly receive an entire essay. The release of ChatGPT 3.5 in late 2022 initiated panic in higher education (HE), with several universities including Oxford and Cambridge banning ChatGPT in early 2023 and decreeing its usage to constitute academic misconduct (Chan, 2023a; Lim et al., 2023). Since this initial burst of reactionism, however, an acceptance that the use of GenAI is an inescapable reality has predominated (Alharbi, 2023; Mills et al., 2023). The release of AI assistants such as Google Duet which is embedded directly into Google Docs is a further critical development, in that we all have access to GenAI from within the spaces where we write (Liu & Bridgeman, 2023). This, along with the fact that AI literacy is regarded as a key graduate attribute due to the integration of AI into the workplace, underscores the idea that the higher education (HE) sector must continue adapting to the new era of GenAI (O’Dea & O’Dea, 2023; Southworth et al., 2023; Chiu, 2024). Research into students’ perspectives has shown that they want universities to take the lead in this regard (Chan, 2023a; Jisc, 2024). However, there is a notable absence of concrete and practical institutional guidance and within the nascent research for practitioners on how to proceed (Barrett & Pack, 2023; Walter, 2024).

This is also an issue in English for Academic Purposes (EAP), a field where there is a clear rationale for the integration of AI literacy. EAP courses teach core academic and study skills deemed relevant to international students of all subjects and disciplines (Hyland, 2006), aiming to support these students in achieving success in English-speaking academic environments. These skills include paraphrasing, summarising, referencing and critical thinking and, by equipping students with these, EAP modules help mitigate some forms of academic dishonesty such as plagiarism (Perkins et al., 2020).

There is a significant overlap between the skills typically taught in EAP courses and the capabilities and use cases of GenAI as both involve, for instance, summarising and paraphrasing. Just as with EAP, GenAI can provide additional language support for international students whose first languages are not English (Du & Alm, 2024; Farrelly & Baker, 2023). As EAP classes typically involve teaching how to avoid academic misconduct, they can offer space to address concerns regarding AI-related misuse or ‘AI-giarism’ (Chan, 2023b) by defining and modelling parameters of appropriate use (Chami, 2023; Lim et al., 2023) and facilitating the development of this sensibility within students themselves (Chan, 2023b). Additionally, the generally smaller class sizes, closer student-teacher relationships, and focus on communication and discussion typically found in EAP contexts represent the optimal classroom environment for fostering AI literacy.

For these reasons above, it can be argued that AI literacy should be integrated into EAP modules. Previous research on EAP students’ perceptions of GenAI supports this integration (Liu et al., 2024; Du & Alm, 2024; Kohnke, 2024), yet no detailed framework for doing so has been provided. To address this gap, this article develops a framework for teaching AI literacy within an EAP context – which we refer to as AI for Academic Purposes, or, AIAP. This framework was conceived in response to issues we, as EAP practitioners, were encountering on the ground, such as an increase in AI-related academic misconduct, a lack of understanding from students of how to interact with or prompt these tools effectively (Walter, 2024) and a tendency to blindly trust information output from GenAI (Ding et al., 2023). Based on this framework, we have designed a concrete AIintegrated EAP module with a carefully structured, week-by-week curriculum which not only embeds AI literacy but also aligns it with the development of critical academic skills. This can offer a practical and replicable model for EAP educators, thereby advancing the discourse on AI literacy in academia.

The research questions are as follows:

RQ1. What is the impact of an AI-integrated EAP module on a) students’ attitudes and perceptions of GenAI, b) students’ confidence in using AI tools for academic purposes, c) the purposes for which they use these tools and d) students’ confidence in ethically and appropriately using AI tools?

RQ2. How does this module meet the needs of students?

This article begins with a literature review looking at the conceptualisation of AI literacy, as well as key findings and trends regarding students’ attitudes towards GenAI, confidence in utilising it academically, and the range of academic purposes it is being used for. Subsequently, the article illustrates the AIAP framework and how an AI-integrated EAP module was designed based on it. After that, the methodology of this research will be given before the results are analysed and discussed.

# 2. Literature review

# 2.1. AI literacy

Scholarship and commentary are now clear on the importance of AI literacy owing to it quickly becoming a key graduate attribute (World Economic Forum, 2023), as well as the wide range of educational benefits and affordances AI can offer to students generally, and international students in particular (Du & Alm, 2024; Farrelly & Baker, 2023). For Long and Magerko (2020), AI literacy is a set of competencies that enables an individual to critically evaluate, communicate, and collaborate with AI tools. This has proved a usefully broad definition despite the rapid advances made in the capability of GenAI tools and large language models (LLMs), and the exponentially growing range of different tools and applications now available. As an important adjunct, scholars have also pointed out the importance of addressing broader societal and ethical considerations of AI (Chiu, 2024; Hornberger et al., 2023).

Approaches to fostering these sets of competencies tend to revolve around a few key ideas: student-centered learning or flipped classroom approaches (Kong et al., 2022), open and transparent communication practices, and ‘hands-on’ experience using relevant AI tools (Chan, 2023a; Pretorius, 2023). The duration and frequency of AI literacy programs or interventions are inconclusive, with some scholars and institutions advocating an integrated approach ‘across the curriculum’ (Southworth et al., 2023) and others maintaining that even a single AI literacy workshop can significantly improve student confidence and understanding of these tools (Sullivan et al., 2024).

Regarding the specific content of these modules or workshops, Walter (2024, p.22) argues that AI literacy courses ought to include ‘essential AI concepts, ethical considerations, and practical applications’ at a minimum. These prerequisites aside, it is also important to note that different AI user groups have different AI literacy requirements, and that it is therefore important to tailor the pedagogical approach and components of AI literacy to the context (Pinski & Benlian, 2024). An exploration of the pedagogy and components of AI literacy for general academic purposes (AIAP) is therefore an important undertaking.

# 2.2. Students’ attitudes and perceptions of GenAI

As with other tools and technologies, students’ attitudes and perceptions towards GenAI can substantially impact their willingness to utilise it (Chan & Hu, 2023). Several studies have found that university students have broadly positive attitudes and perceptions towards GenAI predicated on knowledge of the many educational affordances GenAI can offer (Chan & Zhou, 2023; Firat, 2023), and this base positivity appears to be common across different cultures and backgrounds (Yusuf et al., 2024). Despite the apparent generalisability of these sentiments, cross-disciplinary research cautions that attitudes and perceptions towards AI are not uniform across subjects, with humanities and arts students less positive than peers in STEM and related disciplines (Irfan et al., 2023; Kelly et al., 2023).

Student attitudes towards the accuracy and reliability of GenAI appear nuanced and considered – they are found to be sceptical about the extent to which GenAI can be utilised for grading and feedback because of its tendency to make mistakes or exhibit biases (Chan & Hu, 2023; Jisc, 2024). They are also becoming increasingly aware of the broader ethical issues surrounding this technology. Students specifically highlight a lack of institutional AI literacy support and guidelines (Jisc, 2024). This may be particularly relevant within EAP contexts; research from Australia cautions that international students may have less familiarity, awareness, and experience of GenAI than their domestic peers, highlighting the urgency of integrating AI literacy within EAP curricula to ensure a base equality of opportunity (Kelly et al., 2023).

# 2.3. Students’ confidence in using AI tools

Although little specific literature about student confidence in utilising AI for educational purposes exists, confidence itself reliably predicts achievement across different knowledge domains and subjects (Kleitman & Stankov, 2007; Stankov et al., 2012). Increasing student confidence in utilising GenAI is thus an important consideration regarding student equity (Chiu, 2024; Ng et al., 2021). Kong et al.’s (2021; 2022) research shows that AI literacy courses can empower students to work with AI.

Confidence in utilising GenAI ethically and appropriately warrants further consideration. Plagiarism detection software is unreliable at best and potentially biased against students whose first language is not English (Liang et al., 2023), and with the ever-advancing sophistication of LLMs, it is becoming increasingly difficult to differentiate between human and GenAI output (Waltzer et al., 2023). Studies have suggested that more experience in hands-on use of GenAI leads to an increase in confidence in its ethical and appropriate utilisation (Kelly et al., 2023), and that fostering ethical awareness can positively impact student use of GenAI (Zhu et al., 2024). Other studies, however, point to considerable variance in students’ understanding of inappropriate or unethical use of GenAI (Chan, 2023b), again highlighting the need both for clear institutional guidance and policy, as well as explicit pedagogical focus on this area (Chiu, 2024; Kong et al., 2024; Walter, 2024).

# 2.4. Students’ purposes of using AI

Generative AI has a wide range of applications within HE, and as noted, facilitates foundational academic research and writing practices, such as brainstorming and gathering sources and ideas (Chan & Zhou, 2023; Chiu, 2024; Jisc, 2024). It can also act as an additional tutor for students (Ifelebuegu et al., 2023; Ou et al., 2024) by providing personalised feedback (Chan & Zhou, 2023; Farrelly & Baker, 2023; Jisc, 2024), proofreading and editing (Farrelly & Baker, 2023), and fostering critical thinking (Allen & Kendeou, 2024; Walter, 2024). This range of academic applications is largely borne out by recent research on student purposes of GenAI utilisation. Personalised and immediate learning support, and ideation, brainstorming, and writing support are highlighted by students as particularly beneficial uses (Chan & Hu, 2023; Jisc, 2024). In addition, students are utilising AI in a pastoral as well as academic sense, with personal, motivational, and emotional support uses related to loneliness or mental health emerging as novel themes of usage (Jisc, 2024).

# 3. Module design and AI literacy integration

# 3.1. Context

Our 10-week AI-integrated English for Academic Purposes 2 (EAP2) module is taught in the second term of the International Stage One (also known as International Foundation Year 1) at a pathway college in Scotland. The college provides international students who do not fulfil the admission requirements of a Scottish university with alternative paths to obtaining university degrees. To progress to university, all international students in the International Stage One are required to take three EAP modules (EAP1, EAP2 and EAP3), each of which lasts 10 weeks (five hours per week divided into two classes), to develop English language and academic skills, alongside modules related to their pathway subjects.

EAP2 follows up on EAP1 in which students are taught foundational academic skills such as critical reading, discussion, paragraph writing and avoiding plagiarism by paraphrasing and referencing, alongside academic vocabulary and style. EAP2 focuses on extended writing with pre-determined assessments and intended learning outcomes.

In 2023, we revamped EAP2 by integrating AI literacy into the teaching of academic skills and language based on what we term the AIAP framework which includes five components 1) Vocabulary, jargon, concepts, 2) Inner workings, 3) Prompt engineering, 4) Specific suggested tools $\mathcal { E }$ applications and 5) Ethics & appropriacy. How these components are integrated into the module will be explained in the following sections. This new version of EAP2 has been implemented since the beginning of 2024 and the module in this research was taught between January and March 2024.

# 3.2. Course structure

The original curriculum followed the process-based approach (Hyland, 2003) with content on pre-writing, writing and post-writing stages. We decided to keep this approach as this is aligned with the pre-determined assessments which include a draft, a final piece of extended writing, followed by a presentation of this piece’s content. Scholars have also suggested the process-based approach to assessments to mitigate AI-related misconduct (Yeo, 2023).

The first three weeks of the course focused on the pre-writing tasks such as analysing task instructions, searching for and evaluating sources and preparing an outline. Lessons in weeks 4–7 shifted the focus to skills, language and genre awareness needed for writing extended academic texts with content on paragraph writing, reporting language, academic style, cohesion and introduction and conclusion writing. The first lesson in Week 8 was about revision and proofreading while the rest of the course was lessons on presentation skills. AI literacy was integrated into all stages of the writing process, giving instruction on how to use AI effectively in each stage for writing support.

Course outline and sample materials are provided in Appendices A and B.

# 3.3. AIAP integration

# 3.3.1. Vocabulary, jargon, concepts

The foundation of any literacy is predicated on lexical, theoretical, and conceptual understanding (Egli et al., 1995) and AI literacy is no different. The few, limited efforts to promote AI literacy for ‘citizens’ often begin in the same manner by fostering knowledge of core concepts and terminologies such as machine learning and large language models (LLMs) (Kong et al., 2021, 2022). In our module, these vocabulary items (e.g. machine learning, GenAI, LLMs) were taught in the first lesson to enable students to confidently engage in AI-related texts and discussions throughout the course.

# 3.3.2. Inner workings

Understanding how GenAI tools function as well as their capabilities and limitations can help students use these tools responsibly and effectively (Chiu, 2024; Southworth et al., 2023). In our module, the inner workings of GenAI were explained in the first lesson by a video from Wharton School (2023) Practical AI for Instructors and Students. This video was chosen because it caters for those in academic contexts and it provides a foundational understanding of GenAI’s inner workings with a simple explanation of how LLMs are trained and function, along with their key capabilities and limitations. This understanding can enable students to engage more deeply with later tasks in the course such as prompt engineering, critical evaluation of AI outputs, and understanding the ethical implications of AI use in academic contexts. We decided against exploring the complex inner workings of AI such as the detailed mechanics of machine learning algorithms or the architecture of large language models as these can distract from the focus of the course which is developing students’ academic language and skills.

# 3.3.3. Prompt engineering

Prompt engineering is a fundamental skill for eliciting useful responses from GenAI (Ding et al., 2023; Walter, 2024). Proficiency in prompt engineering is intrinsically linked to developing criticality as crafting effective prompts requires critical and creative thinking (Walter, 2024). This skill can also result in a greater understanding of the capabilities and limitations of LLMs (Hillier, 2023) and enhances student self-efficacy by giving them the tools to leverage these technologies for their academic pursuits (Giray, 2023). Due to the importance of prompt engineering, one full lesson and a half of another on the module were dedicated to this. Also, this content was included in the first two weeks of our module for students to be able to leverage GenAI tools for more complex tasks later in the course such as using AI for writing revision. The framework of prompt engineering taught in this module is adapted from the Birss’s (2023) CREATE framework (see more details in Appendix B) because the mnemonic is easy to remember and also includes the requirements of an effective prompt such as specificity, detail, relevance and iteration (Mollick, 2023).

# 3.3.4. Specific suggested tools $\mathcal { E }$ applications

Given the enormous proliferation of AI tools now available, it is unsurprising that students are looking for institutional recommendations and guidance as to which tools are most useful and trusted (Chan, 2023a). At the same time, Yusuf et al.’s (2024) large-scale multi-cultural research found that ChatGPT is the most widely utilised tool among both university lecturers and students. Taking these, plus the module’s focus on extended writing, into consideration, we decided to introduce ChatGPT, along with Elicit, Consensus and Perplexity in our module. Elicit and Consensus, both AI-powered search engines, were introduced in the Week 3 lesson on the pre-writing process, along with Perplexity, a GenAI tool that can gather information from the internet and unlike ChatGPT, can incorporate source links directly into its answers. These three tools can support students in searching for relevant academic sources.

Both ChatGPT and Perplexity are LLMs that have a wider range of applications. Some applications which are the most useful for students were introduced throughout the course, including ideation, language support, exam revision aid (Weeks 2 & 3), reference list correction (Week 4) and personalised feedback on writing (Week 8) (see Appendix B).

Following Lim et al.’s (2023) caution against making AI tools ‘central’ to the curriculum, with the focus instead on discussing and evaluating the pros and cons of different tools, when introducing these tools, our teachers encouraged students to compare how Elicit and Consensus work and compare the output of ChatGPT and Perplexity. In addition, several GenAI output evaluation activities were included in the module to promote students’ criticality and raise awareness of AI-generated content’s problems, as suggested by Ding et al. (2023), Farrelly and Baker (2023) and Walter (2024). For example, in a lesson in Week 4, students were tasked with evaluating and comparing four paraphrases by Quillbot, an AI-powered paraphrasing tool (Appendix B). Subsequently, they had a discussion on problems with this kind of tool and how to use (or not use) it. As Chami (2023) states, practitioners’ modelling and students’ evaluation of AI tools can contribute to developing student familiarity and knowledge of a wider range of useful tools.

# 3.3.5. Ethics $\mathcal { E }$ appropriacy

Research has found that students struggle with the distinction between using AI as an aid for academic writing and using it in ways that constitute academic misconduct (Chan, 2023b). Thus, there should be a focus on explicit teaching of appropriate use of AI (Chan, 2023a; Chan & Hu, 2023). Meanwhile, whereas universities might have their own GenAI policies, students might not read or understand these documents (Chiu, 2024) or, in other cases, find them lacking and ambiguous (Jisc, 2024). As the line between appropriate or acceptable use of GenAI and overreliance is necessarily something of a grey area, pedagogical approaches to developing this sensibility are thus best based on discussion, openness and trust. Rowland (2023) recommends providing sample scenarios of AI use for students to analyse and discuss and we have found this approach works extremely well. This discussion activity (Appendix B) was included in Weeks 3 and 4 of the module when students had gained a fundamental grasp of generative AI’s strengths and weaknesses but had not yet begun writing. This timing was intentional, aiming to establish a clear understanding of proper AI utilisation and discourage academic dishonesty before the writing process started. After these discussions, students were asked to make their own lists of appropriate and inappropriate AI use before comparing these lists with the university’s GenAI policy. This aimed at creating an educational setting where AI was used thoughtfully and ethically, in accordance with the university’s established policies.

To further promote transparency and academic integrity, also in Week 3, our teachers modelled how to fill in a declaration of AI use, which could teach students to take responsibility for their work and their use of AI tools. The process of declaring AI use could also encourage students to reflect on how they engaged with AI. This reflection practice was consolidated in Week 6 when students worked in groups to write an essay using only GenAI tools and then engaged in a structured reflection task (Appendix B). This can encourage students to critically assess their interactions with AI and further develop an understanding of ethical and appropriate AI use.

# 4. Methodology

The research employed an explanatory sequential mixed-methods design (Creswell & Clark, 2017). It began with a premodule survey to gauge students’ baseline knowledge and attitudes towards AI. Students then took the EAP2 module in which AI literacy was explicitly taught and integrated with the teaching of academic language and skills. After the module, a post-module survey was conducted to identify changes in students’ attitudes and confidence. Semi-structured interviews were then conducted with a selected group of students to explore these changes in more depth. The combination of quantitative survey data and qualitative interview data provided a comprehensive understanding of the module’s impact on students.

# 4.1. Participants

39 international students from 22 nationalities and various pathways were enrolled in the module and they completed both pre- and post-module surveys. Eight students volunteered for the interviews. Table 1 provides background information on these eight students whose names have been pseudonymised.

Table 1 Interviewees’ profiles.   

<html><body><table><tr><td>Pseudonym</td><td>Age</td><td>Nationality</td><td>Pathway</td></tr><tr><td> Jordan</td><td>19</td><td>American</td><td>Life Sciences</td></tr><tr><td>Ngoc</td><td>18</td><td>Vietnamese</td><td>Art &amp; Design</td></tr><tr><td>Christine</td><td>19</td><td>Kenyan</td><td>Nursing</td></tr><tr><td>Jiwon</td><td>19</td><td>South Korean</td><td>Nursing</td></tr><tr><td>Emily</td><td>20</td><td>Indonesian</td><td>Life Sciences</td></tr><tr><td> Megan</td><td>18</td><td>Nigerian</td><td>Nursing</td></tr><tr><td>Patience</td><td>20</td><td>Nigerian</td><td>Nursing</td></tr><tr><td>Daryna</td><td>18</td><td> Ukrainian</td><td>Social Sciences</td></tr></table></body></html>

# 4.2. Pre- and post-module surveys

The pre-module survey consisted of four sections. The first employed a 5-point Likert scale to survey students’ overall confidence in using AI and confidence in using specific AI tools, including ChatGPT, Elicit, Consensus and Perplexity, which would be introduced and modelled, and Quillbot, whose output would be evaluated in the module. The second section examined students’ purposes of using AI. Respondents were asked to choose from a list of purposes. Optional write-ins were given in these two sections. The third section investigated students’ perceptions, focusing on their perception of GenAI’s usefulness, accuracy, reliability and unbiasedness, while the fourth explored students’ confidence in ethical and appropriate AI use, both using a 5-point Likert scale.

In the post-module survey, the same questions were used to identify changes among students. Three open-ended questions were added at the end to gather student feedback on the module.

# 4.3. Interviews

Semi-structured interviews were conducted in English with eight participants after the module. Each interview lasted approximately $2 0 ~ \mathrm { { m i n } }$ . Interviewees were asked about whether there had been any changes in their perceptions of AI, their abilities to use AI and their views on using AI appropriately throughout the academic term. They were asked to elaborate on their answers and explain their survey responses. Subsequently, interviews were transcribed and pseudonymised.

# 4.4. Data analysis

Regarding quantitative data, to identify the impact of the module, we compared the pre- and post-module responses to questions about students’ confidence and perception of GenAI. Due to the non-normal distribution of the data (Shapiro–Wilk results were all lower than 0.05), we employed the Wilcoxon signed-rank test, a non-parametric alternative that does not assume normality. The effect size was calculated if the test showed statistically significant differences and was interpreted as follows: small effect: $\Gamma = 0 . 1 0$ to 0.29; medium effect: $\Gamma = 0 . 3 0$ to 0.49; large effect: $\Gamma = 0 . 5 0$ to 1.0 (Pallant, 2010). For data on students’ purposes of using AI, since we used a checkbox question, the McNemar test was used to compare paired nominal data.

Qualitative data from interviews and open-ended survey question responses were analysed thematically. It has been recommended that multiple forms of qualitative data should be collected for thematic analysis instead of relying solely on a single source (Creswell & Poth, 2018). Following the steps of Braun and Clarke’s (2006) thematic analysis, we (1) read and reread the data from open-ended survey question responses and interview transcripts to become intimately familiar with their content; (2) generated initial codes based on words and phrases that were often mentioned in both sources of data; (3) grouped codes into potential themes that were relevant to the research questions; (4) reviewed the themes using Braun and Clarke’s questions (2012, p. 65); (5) defined the themes and established the relationships between them.

# 5. Results

# 5.1. Quantitative results

# 5.1.1. Perceptions of GenAI

Table 2 shows that before the module, students were mostly ambivalent about the accuracy, reliability and objectivity of GenAI (all Ms were approximately 3) but they were positive about its usefulness $\mathbf { M } = 3 . 8 2$ ). After the module, there was a decrease in students’ perception of GenAI’s as unbiased (median decreased from 3.00 to 2.00), with the Wilcoxon signed-rank test confirming that this change was statistically significant $\textstyle \langle Z = - 2 . 1 3 8$ , $\mathbf { p } = 0 . 0 3 3$ ) with a medium effect size $\mathbf { \check { r } } = 0 . 3 4 2 $ . For accuracy $Z = - 1 . 5 5 1$ , $\mathsf { p } = 0 . 1 2 1$ ), reliability $( Z = - 1 . 7 3 8$ , $\mathbf { p } = 0 . 0 8 2 \mathrm { \rangle }$ , and usefulness $\langle Z = - 1 . 5 1 0$ , $\mathsf { p } = 0 . 1 3 1$ ), there were no statistically significant changes. This shows that the module significantly impacted students’ perceptions of GenAI’s unbiasedness, suggesting they viewed GenAI as more biased post-module. Perceptions of GenAI’s accuracy, reliability, and usefulness, however, showed non-significant changes.

Table 2 Descriptive statistics for students’ perceptions of GenAI.   

<html><body><table><tr><td></td><td colspan="6">Mean (pre-module) Mean (post-module) Median (pre-module) Median (post-module) SD (pre-module) SD (post-module)</td></tr><tr><td>Accuracy of GenAI</td><td>3.03</td><td>2.74</td><td>3.00</td><td>3.00</td><td>0.707</td><td>0.818</td></tr><tr><td>Reliability of GenAI</td><td>2.97</td><td>2.67</td><td>3.00</td><td>3.00</td><td>0.843</td><td>0.701</td></tr><tr><td>Unbiasedness of GenAI 2.77</td><td></td><td>2.33</td><td>3.00</td><td>2.00</td><td>0.777</td><td>1.034</td></tr><tr><td>Usefulness of GenAI</td><td>3.82</td><td>4.08</td><td>4.00</td><td>4.00</td><td>0.721</td><td>0.807</td></tr></table></body></html>

Table 3 Descriptive statistics for students’ confidence in using AI tools.   

<html><body><table><tr><td>Students&#x27; confidence in using AI tools</td><td>Mean (pre- module)</td><td>Mean (post- module)</td><td>Median (pre- module)</td><td>Median (post- module)</td><td>SD (pre- module)</td><td>SD (post- module)</td></tr><tr><td>Overall confidence</td><td>3.05</td><td>3.92</td><td>3.00</td><td>4.00</td><td>1.075</td><td>0.739</td></tr><tr><td>ChatGPT</td><td>2.97</td><td>3.92</td><td>3.00</td><td>4.00</td><td>0.873</td><td>0.807</td></tr><tr><td>Quillbot</td><td>1.95</td><td>2.87</td><td>2.00</td><td>3.00</td><td>1.099</td><td>1.105</td></tr><tr><td>Consensus</td><td>1.15</td><td>2.85</td><td>1.00</td><td>3.00</td><td>1.099</td><td>1.226</td></tr><tr><td>Elicit</td><td>1.10</td><td>3.41</td><td>1.00</td><td>3.00</td><td>0.502</td><td>1.208</td></tr><tr><td> Perplexity</td><td>1.10</td><td>3.13</td><td>1.00</td><td>3.00</td><td>0.307</td><td>1.151</td></tr></table></body></html>

# 5.1.2. Confidence in using AI tools for academic purposes

Table 3 shows that before the module, students were moderately confident in using AI in general $\mathbf { M } = 3 . 0 5$ . Besides ChatGPT, students were not at all confident with the other tools discussed in the module $( \mathbf { M } < 2 )$ . After the module, the overall confidence, as well as confidence in using various AI tools introduced in the module, increased, with medians increasing to 3.00 or 4.00. Results from the Wilcoxon signed-rank test showed that these increases were statistically significant. The Zvalues, p-values and effect sizes were as follows: overall confidence $( Z = - 3 . 8 8 8$ , $\mathbf { p } < 0 . 0 0 1$ , $\Gamma = - 0 . 6 2 3$ ), ChatGPT $\mathbf { \zeta } Z = - 3 . 9 5 7 ,$ , $\mathsf { p } < 0 . 0 0 1$ , $\Gamma = - 0 . 6 3 4 )$ , Quillbot $( Z = - 3 . 3 1 8$ , $\mathsf { p } < 0 . 0 0 1$ , $\boldsymbol { \mathrm { r } } = - 0 . 5 3 1$ ), Consensus $\langle Z = - 4 . 9 0 9$ , $\mathsf { p } < 0 . 0 0 1$ , $\mathbf { r } = - 0 . 7 8 6 )$ , Elicit $Z = - 5 . 2 2 6$ , $\mathsf { p } < 0 . 0 0 1$ , $\mathbf { r } = - 0 . 8 3 7 ,$ ), and Perplexity $Z = - 5 . 1 3 7 ,$ , $\mathsf { p } < 0 . 0 0 1$ , $\mathbf { r } = - 0 . 8 2 3 ,$ . These large effect sizes $( \Gamma > 0 . 5 )$ indicate substantial improvements in students’ confidence levels, with the largest gains seen for Elicit and Perplexity. This indicates the module’s effectiveness in enhancing students’ confidence in utilising these tools.

# 5.1.3. Purposes of using GenAI

The McNemar test revealed that the module significantly increased the range of purposes for which students utilised GenAI. Specifically, there were significant increases in the use of AI for brainstorming ideas $\mathbf { \Phi } ( \mathbf { p } < 0 . 0 0 1 $ , writing essays $\begin{array} { r } { ( { \bf p } = { \bf 0 } . 0 2 1 \mathrm { \Omega } , } \end{array}$ ), searching for sources $\mathbf { \tilde { p } } < 0 . 0 0 1 $ ), checking grammar and spelling mistakes $\mathbf { \tilde { p } } = 0 . 0 0 3 )$ , and revising for exams $\mathbf { \bar { p } } = 0 . 0 4 9 ^ { \cdot }$ ). However, there were no statistically significant changes in the use of AI tools for other listed purposes whose pvalues were above the 0.05 threshold.

In addition, Figure 1 shows that before the module, students used AI tools primarily for proofreading $( 4 8 . 8 ~ \% )$ , brainstorming ideas $( 3 6 . 6 ~ \% )$ , looking for information about a topic $( 3 6 . 6 ~ \% )$ , paraphrasing $( 3 6 . 6 ~ \% )$ and searching for sources $( 1 9 . 5 ~ \% )$ . Figure 2 shows that after the module the most common uses were brainstorming and proofreading (each $8 7 . 2 \%$ , followed by searching for sources $( 6 4 . 1 ~ \% )$ , looking for information about a topic $( 5 9 \% )$ and paraphrasing or summarising $( 5 6 . 4 \% )$ .

# 5.1.4. Confidence in ethically and appropriately using AI tools

Table 4 shows that the module increased students’ confidence in using AI ethically and appropriately, as well as their confidence in their ability to distinguish between appropriate and inappropriate AI use. Results from the Wilcoxon signedrank test showed that these increases were statistically significant. For confidence in using AI ethically and appropriately $( Z = - 3 . 2 7 1$ , $\mathbf { p } = 0 . 0 0 1$ ), the effect size was large $\mathbf { \check { r } } = - 0 . 5 2 4 )$ , with the mean increasing from 3.38 $\mathrm { S D } = 1 . 1 3 8 $ ) pre-module to 4.15 $\mathrm { S D } = 0 . 7 7 9 ,$ post-module. For confidence in distinguishing between appropriate and inappropriate AI use $( Z = - 2 . 6 7 7 ,$ , $\mathbf { p } { = } 0 . 0 0 7 \mathrm { ; }$ , the effect size was medium $\mathbf { \tilde { r } } = - 0 . 4 2 9 )$ , with the mean confidence increasing from 3.67 $\mathrm { S D } = 1 . 0 0 9 ,$ pre-module to 4.21 $\mathrm { S D } = 0 . 8 6 4 \mathrm { , }$ post-module. These results indicate that the module effectively enhanced students’ confidence in both of these areas, with particularly strong gains in confidence in ethical AI usage.

# 5.2. Qualitative results

# 5.2.1. Perceptions and attitudes

We found that after the module, students became more critical of AI. For example, Jiwon said: “Before I came to university [.] I almost just totally believed AI because I thought it’s accurate and correct; now I feel I can control AI to get the correct information”.

Interestingly, several students were scared of using AI for fear of academic misconduct prior to taking the module, saying that they were “terrified of AI” (Emily) and “thought using AI was a crime” (Megan). Jiwon explained: “I was afraid to use it because [.] if I asked to AI something about information and then use that information in my writing, [.] university will notice me and I will be fail”. Moreover, students were actively discouraged from using AI, with Jordan saying: “in my high school, they were like: “your universities aren’t going to let you use AI in any way””.

Students stated that the fear of using AI was replaced by understanding and acceptance after the module. For instance, Ngoc said: “before I was able to [.] interact with AI [.] there is quite a stigma with using AI and research because you can come across as not having integrity and plagiarism [.] after that I don’t have the stigma anymore. I understand that this can be used in a positive way in a legal way and it’s not always that if you use AI you are not being a good person, you’re plagiarising and you don’t have integrity”.

![](img/6ef5deed8024a0b0c922e81431d930b0b5960b028978971f63ac5ee1a2ba5c4e.jpg)  
Figure 1. Students’ pre-module purposes of using GenAI.

![](img/ffe6fb499c4c52456d2cc9bc3661da16006098d64943aec613ce1d293a8b492a.jpg)  
Figure 2. Students’ post-module purposes of using GenAI.

Table 4 Descriptive statistics for students’ confidence in ethically and appropriately using AI tools.   

<html><body><table><tr><td></td><td>Mean (pre- module)</td><td>Mean (post- module)</td><td>Median (pre- module)</td><td>Median (post- module)</td><td>SD (pre- module)</td><td>SD (post- module)</td></tr><tr><td>Confidence in using AI ethically and appropriately</td><td>3.38</td><td>4.15</td><td>4.00</td><td>4.00</td><td>1.138</td><td>0.779</td></tr><tr><td>Confidence in distinguishing between appropriate and inappropriate AI use</td><td>3.67</td><td>4.21</td><td>4.00</td><td>4.00</td><td>1.009</td><td>0.864</td></tr></table></body></html>

# 5.2.2. Confidence in using AI tools for academic purposes

Several students mentioned that they gained confidence in using AI after the module. For example, Daryna said “as a new person in AI, I can say that it is a huge progress from nothing like 0 till now.”. Students also appreciated the teaching of various AI tools in the module. Patience, for example, stated: “Compared to last term, I didn’t know about Elicit [.] Consensus [.] the way I can use ChatGPT to correct grammatical errors and give outlines [.] So I’m very, very happy”.

Additionally, students reported appreciation for prompt engineering instructions, with six open-ended responses saying that this was the most useful aspect of the module. Christine elaborated on this saying: “CREATE (prompting framework) is really easy to use”. Students’ confidence in prompt engineering is demonstrated in Emily’s comment: “Rather than giving short sentences to ChatGPT to help answer my questions or help me, I’ve now know how to make a prompt more useful”.

# 5.2.3. Purposes of using AI

Students mentioned that in the module they learned several new use cases of AI such as “ask it to give you math problems and correct you if you’re wrong; having a conversation with it in a different language and asking you to correct you if you were wrong” (Jordan) and “summarise the key points of a long article” (Christine). Several said that they use AI for language support. For example, Daryna said: “as English is not my first language and I have a lot of mistakes, I just (ask AI) “Can you check it please? Can you advise me how to write this more formal?”. Interestingly, several students mentioned using AI for independent learning. Christine, for example, used it to revise for her psychology exam by asking it to “create some review questions with the correct answers” while Emily said she “pop it (her work) into AI for feedback”.

# 5.2.4. Confidence in ethically and appropriately using AI tools

Students reported an improvement in confidence in using AI ethically and appropriately. Patience, for example, said: “I’m more aware of the misuse of AI and what not to do and what to do”. Jordan attributed this change to the pedagogical approach of how “(teachers) showed us some appropriate uses and inappropriate uses of AI (through sample scenarios). So now it’s more easy to tell”. This teaching was also considered the most important aspect of the module by several students (open-ended responses e.g. how to use AI tools appropriately and can still help us with our studies; the ethical ways of using AI in university).

It is important to note that although the module only covered AI use for general academic purposes, some students developed their personal subject-specific framework of ethics and appropriacy. Ngoc, an art student, said that she avoided using AI image generators because “I do not want it to affect like my ability to perform art [.] I try to keep technology as a tool to enhance my art, not using it to create art.”

# 5.2.5. AI-integrated EAP module and students’ needs

There was a consensus among students that the module could support them in achieving their academic goals. On the one hand, they highlighted the significance of AI literacy instructions. For example, some responses to the question about the most important aspect of the module are “the appropriate use of AI tools that can aid with research and grammatical skills” and “how to use correctly the AI for courseworks and presentation”. On the other hand, students recognised the importance of foundational academic skills and language. Patience, for instance, said: “there’s a topic about how to compose yourself during a presentation, how your presentation should be. That has really helped a lot.” Jiwon even associated her improvement in academic performance with the combination of AI literacy and academic skills instructions, saying that “20 to $30 \%$ (of my improvement) is (due to) AI, to be honest, because without AI I spend too much time to find sources, and then about $80 \%$ is because of the teachers – if I don’t know the structure of essay – even if I have correct sources I cannot make the essay”.

# 6. Discussion

RQ1a addresses the impact of our AI-integrated EAP module on students’ perceptions of GenAI. The results reveal that students became notably more critical of GenAI’s unbiasedness after the module. This critical evaluation of GenAI might have developed from several classroom activities where students practised evaluating GenAI outputs. This finding provides empirical evidence for Ding et al.’s (2023), Farrelly and Baker’s (2023) and Walter’s (2024) suggestion that the integration of AI literacy into education should include activities which require students to analyse and assess GenAI output to foster critical thinking skills. Without this explicit instruction, students tend to blindly trust GenAI output (Ding et al., 2023).

However, the results also demonstrate stable perceptions of GenAI’s accuracy and reliability among students. This could imply that students have become more competent at identifying and correcting inaccuracies and biases themselves. Jiwon’s statement about controlling GenAI to acquire the correct information supports this idea, showing that students became more empowered and skilled in using AI, which does not necessarily translate to a changed perception in the survey metrics.

One unanticipated finding is that while students generally perceived GenAI as a useful tool, they were afraid of using it before the module due to concerns over unethical use. This fear might be a consequence of the universities’ initial ban and lack of guidance on GenAI use (Barrett & Pack, 2023; Chan, 2023a; Lim et al., 2023). The lack of a sector-wide cohesive approach to the use of GenAI might have additionally confused students. This is illustrated by Jordan’s comment that their high school teachers told students they would not be allowed to use AI at university. The solution to these problems, we argue, is fostering a positive learning environment where AI use is embraced under clear guidelines. This is evidenced by Ngoc’s shift from scepticism to understanding after our module.

RQ1b concerns the impact of our module on students’ confidence in using AI tools for academic purposes. Our study has found that students gained significant overall confidence, which is consistent with previous studies on the influence of nonspecialised AI literacy courses (Kong et al., 2021, 2022). Regarding specific tools, before the module, ChatGPT was the most utilised while others were mostly new to students. This is similar to Yusuf et al.’s (2024) survey results which point to ChatGPT’s popularity in university settings. After ChatGPT, Consensus, Elicit, and Perplexity were introduced and modelled, students gained significant confidence in using these tools. Students’ confidence in Quillbot - whose output was evaluated in the module (see Appendix B for example materials) - increased significantly as well. The fact that students expanded their range of AI tools utilised highlights the importance of explicit teaching of AI literacy. With thousands of AI tools freely available online, students need guidance on tools which are most relevant to their needs (Chan, 2023a).

An additional finding regarding RQ1b is students’ confidence in prompt engineering which was considered as the result of explicit instructions and activities regarding this component. This underscores the impact of teaching prompt engineering, providing empirical support for calls for this type of instruction in the literature (Ding et al., 2023; Walter, 2024). Without this knowledge, students might receive generalised responses from AI (Walter, 2024) which are likely to be unhelpful.

RQ1c focuses on the impact of our module on the purposes for which students use AI tools. The results indicate that before the module, students mostly used AI tools for proofreading, brainstorming ideas, looking for information about a topic and paraphrasing. The results also show that the module had a significant impact on expanding the purposes for which students use AI tools, particularly for brainstorming, writing essays, searching for sources, proofreading and revising for exams. These changes suggest that the module successfully broadened students’ awareness and practical application of AI tools for academic purposes. The purpose of using AI for ‘writing essays’ should not be immediately interpreted as academic misconduct. Instead, it can reflect the use of AI as a tool to improve the quality of essay writing through suggestions and corrections, which aligns with the qualitative data.

Another important finding is that after the module, students started to utilise AI tools to support personalised learning needs, particularly for non-native English speakers to seek language support. Students like Daryna, who used AI to check and improve her English writing, exemplify how the module facilitated the use of AI as a tool for international students to overcome language barriers. Personalised and immediate learning support is also the main reason why students use AI in Chan and Hu’s (2023) study. Our finding suggests that AI literacy instructions can encourage students to leverage AI tools autonomously and effectively. This further underscores the importance of integrating AI literacy into education, as suggested by several scholars such as Southworth et al. (2023) and Yeo (2023).

RQ1d examines the module’s impact on students’ confidence in using GenAI ethically and appropriately. The results demonstrate strong gains in confidence in ethical AI usage and students attributed this improvement to explicit instructions on what constitutes appropriate and inappropriate AI use. This indicates that students need and appreciate these instructions to make informed decisions on how to use GenAI themselves. This finding confirms the validity of the calls for training on ethical and appropriate use of AI in the literature (Chan, 2023a; Chan & Hu, 2023), with teachers showing students how to use AI ethically and appropriately (Barrett & Pack, 2023; Yeo, 2023). In addition, the influence of teaching AI literacy on students’ ethical considerations and decision-making processes can be seen in Ngoc’s conscious decision to avoid AI image generators to preserve her artistic abilities. This personal ethical framework shows a critical reflection on the importance of guarding against the loss of human agency while the value of AI as a collaborative tool is still acknowledged.

RQ2 investigates how the module meets students’ needs. Students’ narratives highlight the importance of the module in not only introducing ethical use of AI tools to support their academic work but also addressing their needs for academic skills and language. Jiwon’s comment on how both AI literacy and foundational academic skills contributed to her academic improvement shows the synergy between these two components in meeting students’ academic needs. All these findings imply that the integration of AI literacy into an EAP module can create a holistic educational approach that can address students’ academic needs, enhance their performances and prepare them for an AI-enabled world.

# 7. Conclusion

This study has explored the integration of AI literacy into an English for Academic Purposes (EAP) module through the development and implementation of the AI for Academic Purposes (AIAP) framework. The results indicate that embedding AI literacy within an EAP curriculum significantly enhances students’ confidence in using AI tools, broadens the range of academic applications for which these tools are utilised, and deepens their understanding of ethical considerations surrounding AI use. Importantly, students also developed a more critical perspective on the biases and limitations of generative AI, which is crucial in fostering a responsible and informed approach to technology in academic settings.

Our AI-integrated EAP curricular design based on the AIAP framework offers a practical and replicable model for educators aiming to integrate AI literacy into their courses, aligning the development of foundational academic skills with the competencies required to navigate an AI-driven world. This research is a stepping stone towards developing best practices for incorporating foundation AI literacy in educational settings, ensuring students are not only technologically proficient but also ethically informed.

Several limitations to this study need to be acknowledged. First, the sample size is small due to the low number of students at our institution. Second, the study focuses on undergraduate students in an International Foundation Year at a pathway college in Scotland, meaning the findings might only be partly generalisable to other educational contexts or student populations. Third, the use of pre- and post-module surveys involves self-reported data, which can be subject to biases. Students might overestimate their understanding or capabilities in using AI tools. They might also try to please their instructors by providing positive feedback. Without triangulation with student writing, the actual depth of AI integration and its effectiveness in enhancing academic performance or ethical understanding might be difficult to quantify with precision. Fourth, with three different instructors teaching the module, there could be variations in the delivery, emphasis, and pedagogical approaches used, which can influence the results of the research. Finally, as AI technology evolves rapidly, students’ attitudes and competencies will change quickly. The next cohort of students taking this module might have a different attitude, along with better baseline knowledge and understanding of appropriacy. This means that the research findings might become outdated quickly.

Future research should consider including more participants with a more diverse range of subjects, educational levels, institutions, and geographical locations. Besides self-reported surveys and interviews, incorporating more objective measures of students’ AI proficiency and understanding of ethics and appropriacy, such as independent evaluations of students’ written work, could provide a more accurate picture of the effectiveness of the AI literacy integration.

# Funding

This research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.

# Declaration of competing interest

We have nothing to declare.

# CRediT authorship contribution statement

Thu Ngan Ngo: Writing – review & editing, Writing – original draft, Visualization, Methodology, Investigation, Formal analysis, Data curation, Conceptualization. David Hastie: Writing – review & editing, Writing – original draft, Investigation, Formal analysis, Data curation, Conceptualization.

# Declaration of Generative AI and AI-assisted technologies in the writing process

During the preparation of this work the authors used ChatGPT, Grammarly, Elicit, and Consensus in order to receive feedback on drafts, to find relevant literature, and to review the final manuscript for missing references. After using this tool/ service, the authors reviewed and edited the content as needed and take full responsibility for the content of the published article.

# Declaration of competing interest

We have nothing to declare.

# Acknowledgement

The authors wish to acknowledge the encouragement and support from colleagues and students at International College Dundee, and the considered feedback from those who had to suffer through earlier drafts of this manuscript, in particular Guilherme Moreira Fians, Xuan Minh Ngo and Tuan Bui.

# Appendix A. Course outline

<html><body><table><tr><td>Week</td><td>Lesson aims Activities</td><td>Assessments</td><td>AIAP components 1 - Vocabulary, jargon, concepts 2 - Inner workings 3 - Prompt engineering 4 - Specific suggested tools &amp; applications 5 - Ethics &amp; appropriacy</td></tr><tr><td>1</td><td>1.1 Introduction to EAP2 and AI - To understand the module&#x27;s overall con- tent and assessment plan - To be introduced to basic concepts related</td><td>- Read and discuss the module guide - Discuss existing knowledge of AI - Watch videos about ML and LLMs (inner workings,</td><td>1, 2, 5</td></tr><tr><td>1.2 Prompt engineering - To revise Al vocabulary</td><td> to AI and relevant vocabulary</td><td>capabilities and limitations) and take notes - Compose the definitions of key AI vocabulary - Do an AI vocabulary quiz - Learn how different prompt structures lead to</td><td>3</td></tr></table></body></html>

(continued )   

<html><body><table><tr><td>Week</td><td>Lesson aims</td><td>Activities</td><td>Assessments AIAP</td><td>components 1 - Vocabulary, jargon, concepts 2 - Inner workings 3 - Prompt engineering 4 - Specific suggested tools &amp;</td></tr></table></body></html>

- To learn about a prompt engineering framework   
- To practise prompting   
2.1 Reports   
- To identify features of a report   
2.2 Evaluating sources   
- To learn about how sources can be evaluated for reliability   
- To practise evaluating a source   
- To continue practising prompting

# 3.1. Pre-writing process

- To become familiar with the writing process   
- To learn how to use AI in the pre-writing process   
3.2 Using AI appropriately   
- To critically evaluate an AI-generated outline   
- To determine appropriate and inappropriate uses of AI in educational contexts   
- To develop guidelines for responsible AI use   
4.1 Paragraph structure & Using AI   
appropriately (2)   
- To explore the structure of an academic paragraph   
- To practise writing an academic paragraph   
- To become aware of ethical problems of AI   
- To evaluate AI output   
- To consolidate understanding of appropriate use of AI in academic settings   
4.2 Revision on avoiding plagiarism   
- To revise how to avoid plagiarism   
- To examine how to use AI tools in referencing and paraphrasing   
5.1 Reporting language   
- To recognise and effectively use the language for reporting information from sources   
5.2 Academic style   
- To revise features of academic style   
6.1 Cohesion   
- To understand the importance of cohesion in writing   
- To practise improving cohesion in writing   
6.2 AI scramble   
- To continue practising prompt engineering   
- To critically analyse and evaluate the strengths and weaknesses of extended AI outputs   
7.1 Report introduction and recommendation   
section   
- To understand the purpose and structure of a report introduction and a recommendation section   
- To practise writing these sections   
- Use Birss’s (2023) CREATE framework to prompt for given scenarios   
- Read a report and identify its typical features   
- Discuss the content of the report   
- Be introduced to how to evaluate sources 3, 4   
- Evaluate three given sources   
- Use Birss’s (2023) CREATE framework to prompt for given scenarios   
- Analyse report assessment question and take notes of 4 what to search for to answer the question   
- Use Elicit, Consensus and Perplexity to search for sources   
- Start preparing a report outline based on ideas from sources   
- Evaluate an AI-generated outline for an outline on the 4, 5 same topic   
- Analyse and discuss scenarios where AI tools are used in completing academic tasks to decide which ones are appropriate   
- Make a list of Dos and Don’ts regarding using AI at university   
- Be instructed on how fill in AI declaration form   
- Read an example academic paragraph and analyse its 2, 4, 5 structure   
- Write an academic paragraph   
- Read and discuss an article about ethical problems of AI   
- Evaluate paragraphs from AI over-reliant student work   
- Analyse and discuss scenarios where AI tools are used in completing academic tasks to decide which ones are appropriate   
- Revise how to reference sources 3, 4, 5   
- Use Generative AI to correct errors in a reference list   
- Evaluate Quillbot’s paraphrases   
- Discuss how to use AI paraphrasing tools ethically   
- Analyse the reporting language in an academic paragraph   
- Use reporting language in paragraph writing   
- Match features of academic styles with examples Report draft   
- Change informal language to formal language   
- Compare a cohesive paragraph with an incohesive one to identify features of the cohesive one   
- Analyse and improve the cohesion of a paragraph   
- Use Generative AI tool(s) to write an essay on a given 3, 5 topic   
- Critically evaluate AI-generated essay   
- Reflect on the process of using AI in the writing process   
- Identify key elements typically included in an effective introduction and recommendation section   
- Write a report introduction and a recommendation section

(continued )   

<html><body><table><tr><td>Week</td><td>Lesson aims</td><td>Activities</td><td>Assessments</td><td>AIAP components 1 - Vocabulary, jargon, concepts 2 - Inner workings 3 - Prompt engineering 4 - Specific suggested tools &amp; applications 5 - Ethics &amp;</td></tr></table></body></html>

# 7.2. Tutorials

- Discuss feedback on the report draft and ask clarifying questions - Work with the tutor to identify specific areas for improvement and practical steps for revision.

- To understand and clarify tutor feedback on the report draft   
- To identify strategies for improving writing in the final report   
8.1 Revision and proofreading   
- To learn how to use AI tools for revision and proofreading

Final report 3, 4

8.2 Presentation skills (1)

- Analyse tutor’s feedback on report draft for key areas for improvement   
- Analyse writing marking criteria for key points   
- Use the above to create prompt(s) for getting feedback from AI   
- Discuss previous experience with making presentations   
- Watch a presentation recording and identify its strengths and weaknesses   
- Discuss and make a list of most useful tips for designing visual aids   
- Design visual aids   
- To discuss previous experience with making presentations   
- To evaluate a presentation   
- To revise how to design effective visual aids   
- To practise designing visual aids   
9.1 Presentation skills (2)   
- To become aware of presentation structure and signpost language   
- To learn how to deal with questions effectively   
- To practise making a presentation   
- Watch a presentation recording and analyse its structure   
- Identify signpost language in the presentation recording   
- Make a list of signpost language organised by functions   
- Discuss strategies to deal with questions after a presentation   
- Make a 2-min presentation and receive peer and tutor feedback   
- Analyse presentation marking criteria   
- Make a complete presentation and receive peer and tutor feedback

9.2 Presentation skills (3) - To practise making a presentation

# Appendix B. Example materials

Week 1 – 1.2. Prompt engineering

# Prompt engineering

In Al, a prompt is any form of text, question, information, or coding that communicates to Al what response you're looking for. Knowing how to prompt can help us to communicate effectively with Generative Al e.g. ChatGPT. Thisleads to better quality, more helpful and relevant responses.

# Read the following prompts and responses

Prompt 1:Tell me about Al.

Response 1: Artificial intelligence (Al) is a branch of computer science that deals with the creation and development of machines that can perform tasks requiring human-like intelligence. This includes learning, reasoning, problem -solving, and understanding natural language."

Prompt 2:"Provide a concise summary of artificial intelligence, its subfields, and current applications."

Response 2:Artificial intelligence (Al) is the study of creating intelligent agents capable of performing tasks autonomously. Key subfields include machine learning, natural language processing, and robotics. Current applications range from virtual assistants and recommendation systems to autonomous vehicles and medical diagnosis."

What is the difference? How does the input change the output?

# CREATE Framework (Birss, 2023)

:C - Character (what role do you want it to play?)   
:R- Request (tell it specifically what you want it to do- give context and useful info)   
:E - Examples (GPT is great at learning from examples)   
. A - Adjustments (where you make changes to improve output) :T- Type of output (bullet point, table,500 word summary etc) :E- Extras (eg. 'ask me questions before you answer', 'explain your thinking').

# What do these prompts look like in practice? (CREATE)

You are a friendly,experienced academic English tutor.Please give me feedback on my draft essay focusing on argument, structure, coherence, cohesion, grammar, lexis.Please list any errors, problems or issues you find in the form of a table, and give an indication of what type of error it is.Help me to try and re-phrase or correct these errors before giving me your corrections.Based on the types of errors I am making,please suggest some strategies, readings, or materials for my improvement.Ask clarifying questions before answering.

The essay is as follows: ..

# Identify the following elements

C -Character (what role do you want it to play?) R-Request (tell it specifically what you want it to do-give context and useful info)   
E-Examples (GPT is great at learning from   
examples)   
A- Adjustments (where you make changes to improve output)   
- Type of output (bullet point, table, 500 word summary etc)   
-Extras (eg.ignore everything before this prompt,'ask me questions before you answer', 'explain your thinking).

# Your turn

Work in pairs/groups of 3.   
Open one of these Generative Al tools:ChatGPT,Gemini, Claude, Bing, CoPilot, Poe(whatever you like).Note thatsome tools require registration.   
: Use the CREATE framework and the earlier example to create some sample prompts for the scenarios in the following slide,   
Put your prompts into your chosen Gen Al tool.   
Discuss together and make sure you iterate appropriately.   
Be ready to make a short presentation to the class about your prompts and outputs-we will compare across groups.

# Your turn

1. You want to revise materials on an aspect of your subject that you are not clear about (aim to output an explanation and a test as a minimum). 2. You want to learn a language of your choice as a beginner.

# Week 3 – 3.2 Using AI appropriately

# Read the scenarios below decide if they are appropriate use of AI or not

1. Jayden is working on his dissertation and needs to review related literature (previous research) on his topic. He asks ChatGPT to summarise the major works and findings in his research area. He then adds that summary to his dissertation and submits it.   
2. Lana, a language student, is preparing for her final oral exam in Portuguese. To enhance her vocabulary, she requests ChatGPT to simulate a conversation with her in Portuguese, allowing the AI to correct her when she makes an error.   
3. Susan is struggling with the recommendation section of her report. She provides ChatGPT with her analysis, asking it to write a fitting recommendation section. She then adds this recommendation to her report and submits it.   
4. Arjun needs to write an essay about climate change but he is not sure which aspect of climate change to focus on. He asks Perplexity to give him some possible essay questions about climate change. He chooses one of the questions from the list Perplexity generates and writes his own essay.   
5. Jane is preparing a presentation about the impact of globalisation. She asks Perplexity to explain the impact of globalisation on the global economy and uses Perplexity’s ideas in her presentation. She cites and references Perplexity.   
6. Otis is preparing for his Maths exam. He puts a maths exercise that his teacher gave him in the class into ChatGPT and asks it to generate similar exercises. He does these exercises and then asks ChatGPT to give him feedback.   
7. Maria, an international student in the UK, occasionally struggles with English grammar in her essays. She inputs problematic sentences into ChatGPT for corrections. For example, from "She had less books than him," ChatGPT suggests "She had fewer books than him," and explains the difference. Using ChatGPT, Maria quickly refines her essay and submits it.   
8. Yoko is an international student in Australia. Her tutor notices that she is struggling with academic reading and gives her some exercises as homework to practise reading skills. These exercises require Yoko to read some texts and answer comprehension questions. Yoko does not read the texts but puts them into Perplexity and asks it to answer the questions for her.

Week 4 – 4.2 Revision on avoiding plagiarism

Task 1: Below is an original text and 4 paraphrased versions by QuillBot, and AI tool which specialises in paraphrasing. Highlight/note the similarities and differences between the 4 paraphrased versions.

# Discuss:

1) Are these paraphrases effective?   
2) What would happen when several students used QuillBot for paraphrasing and then submitted the paraphrases as part of their assessments?   
3) How should we use paraphrasing tools e.g. QuillBot or ChatGPT?

# Original text:

The Future of Jobs Survey also probes the expected impact of technology adoption on employment. [.] Big data analytics, climate change and environmental management technologies, and encryption and cybersecurity are expected to be the biggest drivers of job growth. [.] Generative AI has received particular attention recently, with claims that $1 9 \ \%$ of the workforce could have over $5 0 \%$ of their tasks automated by AI and job losses making headlines, while others expect the technology to enhance jobs.

Source: World Economic Forum (2023). The Future of Jobs Report (2023). Available at: https://www3.weforum.org/docs/WEF Future_of_Jobs_2023.pdf (Accessed: 29 September 2023).

# Quillbot:

1. The expected effect of technology adoption on employment is another topic covered in the Future of Jobs Survey. [.] The biggest job growth drivers are anticipated to be big data analytics, climate change and environmental management technologies, encryption, and cybersecurity. [.] Recent media attention has focused on generative AI, with some predicting job losses and claims that $1 9 \ \%$ of the workforce could have over $5 0 \ \%$ of their tasks automated by the technology.   
2. The projected effects of technology adoption on employment are also investigated by the Future of Jobs Survey. [.] The technologies that are anticipated to create the greatest increase in employment include big data analytics, climate change and environmental management technology, encryption, and cybersecurity. [.] With projections that $1 9 \%$ of the workforce might have over $5 0 \%$ of their tasks automated by AI and job losses making headlines, generative AI has recently attracted a lot of attention. However, other people anticipate the technology to improve jobs.   
3. The Future of Jobs Survey looks into the anticipated effects of technology adoption on employment. [.] The largest jobgrowth drivers are anticipated to be technology related to big data analytics, environmental management and climate change, encryption, and cybersecurity. [.] Recent headlines about job losses and projections that $1 9 \%$ of the workforce may have over $5 0 \%$ of their labour automated by AI have drawn attention to the field of generative AI, however some experts believe the technology may actually improve employment opportunities.   
4. The projected effects of technology adoption on employment are also examined by the Future of Jobs Survey. [.] The largest job-growth drivers are anticipated to be big data analytics, climate change and environmental management technology, encryption, and cybersecurity. [.] With projections that $1 9 \%$ of the workforce might have over $5 0 \%$ of their tasks automated by AI and job losses making headlines, generative AI has recently attracted a lot of attention. However, some anticipate the technology to improve jobs.

# Week 6 – 6.2 AI scramble

After your group have finished writing an essay on a given topic by only using GenAI, reflect on this process and discuss the following questions in your group.

1. Which combination of GenAI tools did you decide to use to write the essay, and how did you use/combine them?   
2. How did your knowledge of prompt engineering impact the quality of the final essay?   
3. How do you feel this essay would compare to one solely written by you?   
4. In what ways was this exercise useful? What new things did you learn from doing this?   
5. What problems did you encounter? Did you encounter any issues with accuracy or reliability in the AI-generated content?   
6. What do you think will happen in the future if we use AI regularly at university? Do you believe that using AI for writing impacted your ability to express original ideas or creativity? Why/why not?

# Week 8 – 8.1 Revision and proofreading

# Feedback from Al

Having Al act as a learning aid in this way is both appropriate and ethical as well as beneficial to your learning - this is what it really excels at!   
As always, we need to create prompt to get Al to generate anything.   
We engineer this prompt in the same general way we engineer others to get the best quality output - remember CREATE?   
The details are particularly important here -- what do we want feedback on? What is determining your mark?   
Look at the extended writing rubric in 8.1 - what are the key points to get a good mark?

# Key points (writing)

Clear focus on question   
Clear understanding and use of sources. Citations and references are accurate   
Balance of information from sources and own ideas / analysis   
Main ideas are well developed   
Clear, effective, and appropriate structure   
Clear and logical paragraphing and use of topic sentences   
Work is logically cohesive and uses cohesive devices accurately   
Meaning is clear and fluent   
Uses subject specific vocabulary accurately   
Academic register / style is consistent   
: Able to accurately use complex grammatical forms

# Putting it all together

: Create a prompt to get feedback from Al.   
: Based on your knowledge of prompt engineering, your understanding of the rubric, and finally, any comments your tutor, include as much detail as possible in your prompt to get useful feedback from ChatGPT (or any other Generative Al tool of your choice)   
Be prepared to discuss your prompt as well as your thoughts (both positive and negative) about the output / feedback this has resulted   
in with the class.

# A sample prompt

Act as an academic English instructor. Give feedback on my report draft, focusing particularly on how well I've addressed the question, my understanding and use of sources, the accuracy of my Harvard citations and references, the balance between information from sources and my own analysis, evaluation, and ideas, how well-developed these ideas are, whether the structure and paragraphing is clear, effective and appropriate, the overall coherence and cohesion of the work and appropriacy of cohesive devices, the clarity, fluency, and academic style of the prose, accurate use of'subject-specific vocabulary, and accuracy and use of complex grammatical! forms.

Rather than giving me the answers, please guide me to doing so myself by identifying an error, asking me about it and guiding me towards improving it, waiting for my response, giving me feedback on my new effort and then moving on to the next one.

If there are any particular error types in style, grammar or lexis that occur frequently within my draft, classify these at the end and give me advice as to how to improve in these areas.

Here is the report question. ... Here is my draft report : <..?

# References

Alharbi, W. (2023). AI in the Foreign Language Classroom: A Pedagogical Overview of Automated Writing Assistance Tools, 2023 (pp. 1–15). Education Research International.   
Allen, L. K., & Kendeou, P. (2024). ED-AI Lit: an interdisciplinary framework for AI literacy in education. Policy Insights from the Behavioral and Brain Sciences, 11(1), 3–10.   
Barrett, A., & Pack, A. (2023). Not quite eye to AI: student and teacher perspectives on the use of generative artificial intelligence in the writing process. International Journal of Educational Technology in Higher Education, 20(1), 59. https://doi.org/10.1186/s41239-023-00427-0   
Birss, D. (2023). How to write an effective prompt for AI. LinkedIn Learning [Video] https://www.linkedin.com/learning.   
Braun, V., & Clarke, V. (2006). Using thematic analysis in psychology. Qualitative Research in Psychology, 3(2), 77–101.   
Braun, V., & Clarke, V. (2012). Thematic Analysis. American Psychological Association.   
Chami, G. (2023). Artificial intelligence and academic integrity: striking a balance. Higher Education. https://www.timeshighereducation.com/campus/ artificial-intelligence-and-academic-integrity-striking-balance.   
Chan, C. K. Y. (2023a). A comprehensive AI policy education framework for university teaching and learning. International Journal of Educational Technology in Higher Education, 20(1), 38. https://doi.org/10.48550/arXiv.2305.00280   
Chan, C. K. Y. (2023b). Is AI changing the rules of academic misconduct? An in-depth look at students’ perceptions of’AI-giarism’. arXiv preprint arXiv:2306. 03358. https://doi.org/10.48550/arXiv.2306.03358   
Chan, C. K. Y., & Hu, W. (2023). Students’ voices on generative AI: perceptions, benefits, and challenges in higher education. International Journal of Educational Technology in Higher Education, 20(1), 43. https://doi.org/10.1186/s41239-023-00411-8   
Chan, C. K. Y., & Zhou, W. (2023). Deconstructing student perceptions of generative AI (GenAI) through an expectancy value theory (EVT)-based instrument. arXiv preprint arXiv:2305.01186. https://doi.org/10.48550/arXiv.2305.00290   
Chiu, T. K. (2024). Future research recommendations for transforming higher education with generative AI. Computers and Education: Artificial Intelligence, 6, Article 100197. https://doi.org/10.1016/j.caeai.2023.100197   
Creswell, J. W., & Clark, V. L. P. (2017). Designing and Conducting Mixed Methods Research. Sage publications.   
Creswell, J. W., & Poth, C. N. (2018). Qualitative Inquiry and Research Design: Choosing Among Five Approaches. Sage publications (4th edition).   
Ding, L., Li, T., Jiang, S., & Gapud, A. (2023). Students’ perceptions of using ChatGPT in a physics class as a virtual tutor. International Journal of Educational Technology in Higher Education, 20(1), 63. https://doi.org/10.1186/s41239-023-00434-1   
Du, J., & Alm, A. (2024). The impact of ChatGPT on English for academic purposes (EAP) students’ language learning experience: a self-determination theory perspective. Education Sciences, 14(7), 726. https://doi.org/10.3390/educsci14070726   
Egli, U., Pause, P., Schwarze, C., Stechow, A., & Wienold, G. (1995). Lexical knowledge in the organization of language. Language, 72, 670. https://doi.org/10. 1075/CILT.114   
Farrelly, T., & Baker, N. (2023). Generative artificial intelligence: implications and considerations for higher education practice. Education Sciences, 13(11), 1109. https://doi.org/10.3390/educsci13111109   
Firat, M. (2023). What ChatGPT means for universities: perceptions of scholars and students. Journal of Applied Learning and Teaching, 6(1), 57–63. https:// doi.org/10.37074/jalt.2023.6.1.22   
Giray, L. (2023). Prompt engineering with ChatGPT: a guide for academic writers. Annals of Biomedical Engineering, 51(12), 2629–2633. https://doi.org/10. 37074/jalt.2023.6.1.22   
Hillier, M. (2023). A proposed AI literacy framework. TECHE. https://teche.mq.edu.au/2023/03/a-proposed-ai-literacy-framework/.   
Hornberger, M., Bewersdorff, A., & Nerdel, C. (2023). What do university students know about Artificial Intelligence? Development and validation of an AI literacy test. Computers and Education: Artificial Intelligence, 5, Article 100165. https://doi.org/10.1016/j.caeai.2023.100165   
Hyland, K. (2003). Second Language Writing. Cambridge University Rress.   
Hyland, K. (2006). English for Academic Purposes: an Advanced Resource Book. London: Routledge.   
Ifelebuegu, A. O., Kulume, P., & Cherukut, P. (2023). Chatbots and AI in Education (AIEd) tools: the good, the bad, and the ugly. Journal of Applied Learning and Teaching, 6(2). https://doi.org/10.37074/jalt.2023.6.2.29   
Irfan, M., Murray, L., & Ali, S. (2023). Insights into student perceptions: investigating artificial intelligence (AI) tool usability in Irish higher education at the University of Limerick. Global Digital & Print Media Review. https://doi.org/10.31703/gdpmr.2023(vi-ii).05   
Jisc. (2024). Student perceptions of generative AI. https://www.jisc.ac.uk/reports/student-perceptions-of-generative-ai.   
Kelly, A., Sullivan, M., & Strampel, K. (2023). Generative artificial intelligence: university student awareness, experience, and confidence in use across disciplines. Journal of University Teaching and Learning Practice, 20(6), 12. https://doi.org/10.53761/1.20.6.12   
Kleitman, S., & Stankov, L. (2007). Self-confidence and metacognitive processes. Learning and Individual Differences, 17(2), 161–173. https://doi.org/10.1016/j. lindif.2007.03.004   
Kohnke, L. (2024). Exploring EAP students’ perceptions of GenAI and traditional grammar-checking tools for language learning. Computers and Education: Artificial Intelligence, 7, Article 100279. https://doi.org/10.1016/j.caeai.2024.100279   
Kong, S. C., Cheung, M. Y. W., & Tsang, O. (2024). Developing an artificial intelligence literacy framework: evaluation of a literacy course for senior secondary students using a project-based learning approach. Computers and Education: Artificial Intelligence, 6, Article 100214. https://doi.org/10.1016/j.caeai.2024. 100214   
Kong, S. C., Cheung, W. M. Y., & Zhang, G. (2021). Evaluation of an artificial intelligence literacy course for university students with diverse study backgrounds. Computers and Education: Artificial Intelligence, 2, Article 100026. https://doi.org/10.1016/j.caeai.2021.100026   
Kong, S. C., Zhang, G., & Cheung, M. Y. (2022). Pedagogical delivery and feedback for an artificial intelligence literacy programme for university students with diverse academic backgrounds: flipped classroom learning approach with project-based learning. Bulletin of the Technical Committee on Learning Technology, 22(1), 8–14. https://doi.org/10.30191/ETS.202301_26(1).0002   
Liang, W., Yuksekgonul, M., Mao, Y., Wu, E., & Zou, J. (2023). GPT detectors are biased against non-native English writers. Patterns, 4(7). https://doi.org/10. 1016/j.patter.2023.100779   
Lim, W. M., Gunasekara, A., Pallant, J. L., Pallant, J. I., & Pechenkina, E. (2023). Generative AI and the future of education: ragnarök or reformation? A paradoxical perspective from management educators. International Journal of Management in Education, 21(2), Article 100790. https://doi.org/10.1016/j. ijme.2023.100790   
Liu, D., & Bridgeman, A. (2023). ChatGPT Is Old News: How Do We Assess in the Age of AI Writing Co-pilots? The University of Sydney. https://educationalinnovation.sydney.edu.au/teaching@sydney/chatgpt-is-old-news-how-do-we-assess-in-the-age-of-ai-writing-co-pilots/.   
Liu, Y., Park, J., & McMinn, S. (2024). Using generative artificial intelligence/ChatGPT for academic communication: students’ perspectives. International Journal of Applied Linguistics, 1–25. https://doi.org/10.1111/ijal.12574, 2024.   
Long, D., & Magerko, B. (2020). What is AI literacy? Competencies and design considerations. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (pp. 1–16).   
Mills, A., Bali, M., & Eaton, L. (2023). How do we respond to generative AI in education? Open educational practices give us a framework for an ongoing process. Journal of Applied Learning and Teaching, 6(1), 16–30. https://doi.org/10.37074/jalt.2023.6.1.34   
Mollick, E. (2023). A guide to prompting AI (for what it is worth). In One Useful Thing. https://www.oneusefulthing.org/p/a-guide-to-prompting-ai-for-what.   
Ng, D. T. K., Leung, J. K. L., Chu, S. K. W., & Qiao, M. S. (2021). Conceptualizing AI literacy: An exploratory review. Computers and Education: Artificial Intelligence, 2, Article 100041. https://doi.org/10.1016/j.caeai.2021.100041   
O’Dea, X. C., & O’Dea, M. (2023). Is artificial intelligence really the next big thing in learning and teaching in higher education? A conceptual paper. Journal of University Teaching and Learning Practice, 20(5). https://doi.org/10.53761/1.20.5.05   
Ou, A. W., Stöhr, C., & Malmström, H. (2024). Academic communication with AI-powered language tools in higher education: From a post-humanist perspective. System, 121, Article 103225. https://doi.org/10.1016/j.system.2024.103225   
Pallant, J. (2010). SPSS Survival Manual: A Step by Step Guide to Data Analysis Using SPSS (4th ed.). McGraw-Hill.   
Perkins, M., Gezgin, U. B., & Roe, J. (2020). Reducing plagiarism through academic misconduct education. International Journal for Educational Integrity, 16, 1– 15. https://doi.org/10.1007/s40979-020-00052-8   
Pinski, M., & Benlian, A. (2024). AI literacy for users–A comprehensive review and future research directions of learning methods, components, and effects. Computers in Human Behavior: Artificial Humans, 1, Article 100062. https://doi.org/10.1016/j.chbah.2024.100062   
Pretorius, L. (2023). Fostering AI literacy: A teaching practice reflection. Journal of Academic Language and Learning, 17(1), T1–T8. https://www.journal.aall. org.au/index.php/jall/article/view/891.   
Rowland, D. R. (2023). Two frameworks to guide discussions around levels of acceptable use of generative AI in student academic research and writing. Journal of Academic Language and Learning, 17(1), T31–T69.   
Stankov, L., Lee, J., Luo, W., & Hogan, D. J. (2012). Confidence: A better predictor of academic achievement than self-efficacy, self-concept and anxiety? Learning and Individual Differences, 22(6), 747–758. https://doi.org/10.1016/j.lindif.2012.05.013   
Southworth, J., Migliaccio, K., Glover, J., Reed, D., McCarty, C., Brendemuhl, J., & Thomas, A. (2023). Developing a model for AI Across the curriculum: Transforming the higher education landscape via innovation in AI literacy. Computers and Education: Artificial Intelligence, 4, Article 100127. https://doi. org/10.1016/j.caeai.2023.100127   
Sullivan, M., McAuley, M., Degiorgio, D., & McLaughlan, P. (2024). Improving students’ generative AI literacy: A single workshop can improve confidence and understanding. Journal of Applied Learning and Teaching, 7(2).   
Walter, Y. (2024). Embracing the future of Artificial Intelligence in the classroom: the relevance of AI literacy, prompt engineering, and critical thinking in modern education. International Journal of Educational Technology in Higher Education, 21(1), 15. https://doi.org/10.1186/s41239-024-00448-3   
Waltzer, T., Cox, R. L., & Heyman, G. D. (2023). Testing the ability of teachers and students to differentiate between essays generated by ChatGPT and high school students. Human Behavior and Emerging Technologies, 2023(1), Article 1923981. https://doi.org/10.1155/2023/1923981   
Wharton School. (2023). Practical AI for Instructors And Students Part 1: Introduction to AI for Teachers and Students [Video]. YouTube. https://www.youtube. com/watch?v¼t9gmyvf7JYo.   
World Economic Forum. (2023). Future of jobs report 2023. Available at: https://www3.weforum.org/docs/WEF_Future_of_Jobs_2023.pdf.   
Yeo, M. A. (2023). Academic integrity in the age of artificial intelligence (AI) authoring apps. TESOL Journal, 14(3), e716. https://doi.org/10.1002/tesj.716   
Yusuf, A., Pervin, N., & Román-González, M. (2024). Generative AI and the future of higher education: a threat to academic integrity or reformation? Evidence from multicultural perspectives. International Journal of Educational Technology in Higher Education, 21(1), 21. https://doi.org/10.1186/s41239- 024-00453-6   
Zhu, W., Huang, L., Zhou, X., Li, X., Shi, G., Ying, J., & Wang, C. (2024). Could AI ethical anxiety, perceived ethical risks and ethical awareness about AI influence university students’ use of generative AI products? An ethical perspective. International Journal of Human-Computer Interaction, 1–23. https:// doi.org/10.1080/10447318.2024.2323277   
Thu Ngan Ngo (aka Cassie) is an EAP tutor based in the UK. She holds an MA in TESOL and Applied Linguistics, along with a CELTA and a DELTA. She has

taught EAP, ESP and EFL in the UK, Brazil, China and Vietnam. Her research interests include integration of technology into teaching and learning and of AI literacy into EAP.

David Hastie is an EAP tutor living in Dundee, Scotland. He holds an MA in English Literature and an MSc in TESOL, both from the University of Aberdeen. He was worked in pre and in-sessional EAP programs at universities in the UK and China, and has a particular interest in materials design and AI literacy.