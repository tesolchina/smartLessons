# Game changers: A generative AI prompt protocol to enhance human-AI knowledge co-construction

Jeandri Robertson a,b,\* , Caitlin Ferreira c , Elsamari Botha d , Kim Oosthuizen e

a Lulea˚ University of Technology, Sweden   
b University of Cape Town, South Africa   
c Graduate School of Business, University of Cape Town, Cape Town, South Africa   
d UC Business School, University of Canterbury, Christchurch, New Zealand   
e University of Stellenbosch Business School, Cape Town, South Africa

# KEYWORDS

Large language models;   
Generative AI;   
ChatGPT;   
Prompt engineering;   
Constructivism

Abstract The democratization of powerful artificial intelligence (AI) tools, including ChatGPT, has sparked the interest of business practitioners given their ability to fundamentally change the way we work. While AI tools are positioned to augment human capabilities, their effective implementation requires the skill to understand where, when and how to best utilize them efficiently. Furthermore, meaningful engagement with the content produced by generative AI (GenAI) necessitates the intricacy of appropriate prompt engineering to optimize the learning process. As the field of GenAI continues to advance, the art of developing impactful prompts has become a necessary skill for harnessing its full potential. This research develops an AI prompting protocol through a constructivist theory lens. Based on the principles of constructivism, where individuals assimilate new knowledge by bridging it with their existing understanding, this research suggests an active engagement process in the human-AI co-construction of knowledge through GenAI. The goal is to empower business managers and their teams to construct effective AI prompts and validate responses, thereby enhancing user interaction, optimizing workflows, and maximizing the potential outcomes of AI chatbots.

$\circledcirc$ 2024 Kelley School of Business, Indiana University. Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/ licenses/by/4.0/).

# 1. Generative AI and prompt engineering

Artificial intelligence (AI) is a field that encompasses the capabilities of machines to perform cognitive functions, such as learning and problemsolving, that are typically attributed to human minds (Raisch & Krakowski, 2021). AI includes technologies such as machine learning, deep learning, and computer vision. One specific subset of AI is generative AI (hereafter, GenAI), which refers to advanced systems that can generate novel output based on user prompts (De Cremer et al., 2023). This generated content can include text, digital images, video, audio, or code. To generate this content, Large Language Models (LLMs) are trained using deep learning techniques on large volumes of unlabeled data, such as images and words (Kietzmann & Park, 2024; Krakowski et al., 2023). As foundation models, these LLMs use reinforcement learning and natural language processing to predict the next likely word, based on the prompts provided (Sundberg & Holmstro¨m, 2023). GenAI can be used in applications such as chatbots, intelligent digital assistants, demand planning applications, and predictive analytics tools (Desouza et al., 2020; Przegalinska et al., 2019). While GenAI can mimic human language and predict the words to follow in a sentence or paragraph, they lack contextual understanding and serve the primary purpose of generating textbased outputs optimized for dialogue.

Within the workplace, GenAI is often used to augment human creativity, simplify certain tasks, and provide valuable outputs that can be used for various purposes within an organization, ranging from enhanced productivity to enabling new forms of creative expression (De Cremer et al., 2023; Ramaul et al., 2024). There is a wide range of GenAI tools available, covering text creation via LLMs for content summarization and automation (e.g., Grammarly, JasperAI, ChatGPT), audio-totext conversion (e.g., Whisper, Murf, Listnr, Otter), video generation or editing technologies (e.g., Syntheys, Synthesia), and AI tools for code creation, such as Codex and GitHub (Sundberg & Holmstro¨m, 2023).

For business managers to effectively utilize GenAI in their operations, mastering prompt engineering is essential (Peres et al., 2023). Prompt engineering involves constructing the right questions to guide AI to generate relevant and meaningful content that can be refined by humans for practical application (De Cremer et al., 2023). Although powerful GenAI tools like ChatGPT have become more accessible, many users still lack knowledge of the best practices for effectively interacting with these tools (Dwivedi et al., 2023). This knowledge gap limits their ability to fully harness the capabilities of GenAI in the business environment (Noy & Zhang, 2023). To bridge this gap and empower business managers and their teams to utilize these tools effectively, this study draws on the principles of constructivism. Constructivism focuses on integrating new knowledge with what is already known, offering a foundation for jointly building knowledge through productive interactions between humans and AI (Frey, 2018).

Research suggests that GenAI can act as a more knowledgeable other (MKO), offering users the necessary support to extend their skills and manage intricate tasks with expert guidance (Dwivedi et al., 2023; Stojanov, 2023). MKOs can take on multiple forms, encompassing not only human mentors but also informational resources, like books and videos, as well as technological agents such as GenAI (Stojanov, 2023). By examining human-AI interactions through the lens of constructivist principles and honing prompt engineering skills, business managers are better equipped to leverage GenAI effectively, benefiting their teams and organizations.

This study aims to equip business managers and their teams with actionable guidance on how to effectively use GenAI tools like ChatGPT and similar chatbots. The goal is to provide these managers with a framework which can be used as a starting point for developing an efficient GenAI prompting protocol, thereby facilitating the coconstruction of knowledge through productive human-AI collaboration. We examine how users can engage with GenAI tools to collaboratively construct knowledge, drawing on the principles of constructivist learning theory. The study illustrates how adept AI prompting can optimize the results and quality of human-AI exchanges using GenAI tools, holding the potential to enhance operational efficiency, customer engagement, and overall business performance (Ferraro et al., 2024; Peres et al., 2023; Short & Short, 2023).

We offer a practical protocol for constructing impactful prompts and showcase use cases that highlight the ability of GenAI tools to drive business efficiencies as well as a framework to evaluate the output. This framework not only improves the quality of GenAI chatbot output, but also decreases the risk of perpetuating bias in the output. As GenAI tools become more prevalent across different industries, understanding how to prompt and engage with these tools for collaborative knowledge co-construction grows in importance (Eriksson et al., 2020). However, prior to the AI prompting process, strategic considerations should be taken into account to ensure the alignment and effectiveness of the prompts with the desired business objectives. These are discussed next.

# 2. Strategic considerations prior to the AI prompting process

When using a GenAI tool such as ChatGPT, it is essential for users to interact with the system in a specific manner to elicit the desired responses. All GenAI technologies operate on input from users, who must input a sequence of words that the model uses to generate an output, whether that be text or images (Jarrahi et al., 2023). The popularity of ChatGPT, in particular, is partly due to its user-friendly interface available for prompting the model and its ability to answer questions in a human-like conversational way (Dwivedi et al., 2023). When given a prompt, ChatGPT matches the questions to the model’s knowledge and generates text (Sundberg & Holmstro¨m, 2023). However, using ChatGPT and LLMs correctly requires creating a well-defined prompt. The process of prompting and using GenAI systems requires careful consideration to ensure the provided information is correct, free of bias and not providing inaccurate information. As business managers seek to determine the appropriate GenAI tool and approach for the prompting process, several important factors warrant attention.

First, given that GenAI models can sometimes produce content that mirrors their training data closely, there is a risk they might generate inaccurate informationdknown as “hallucinations”d where the model creates details or data not based in reality (Metze et al., 2023). This can be a common issue with GenAI models, as they are designed to create new content and can occasionally produce plausible sounding but incorrect information (McIntosh et al., 2023). It is important that business managers are aware of this limitation and take precautions to ensure the accuracy of the information generated by the AI model. Validating the model’s responses against known facts, realtime data, historical trends, and expert opinions can help mitigate this issue and enhance the overall accuracy of the generated content.

Second, business managers should clearly define the specific text-to-text requirements of their business in order to select the most suitable and efficient model based on its unique capabilities (Raisch & Krakowski, 2021; Ray, 2023). This would entail spending time understanding how the models work and testing the outputs of the prompts, and if available, finding information about the data and how the models are trained. This knowledge provides deeper insight into each model’s strengths and potential limitations (Jarrahi et al., 2023).

Third, it is important to consider the specific purpose for which the model has been trained (De Bruyn et al., 2020). For example, Cohere, an opensource enterprise AI model, is trained on diverse and inclusive data sets, making it suitable for creating marketing content. Different training methods may also impact the model’s behavior (Cabrera et al., 2023), for example, the use of different training methods by models like BERT, which employs masked language modelling and next-sentence prediction, versus LaMDA, which pretrains on public dialogue and then fine-tunes, can result in nuanced responses.

When selecting GenAI models, it is thus crucial to understand the business context in which they will operate. Therefore, the choice of model should be guided by specific use case requirements, considering the model’s features, capabilities, the complexity of data parameters, and the training method employed. To practically demonstrate the prompt construction process and outline the key steps, the next section will employ the constructivist dimensions of context, structure, and evaluation to detail an AI prompt protocol for knowledge co-construction.

# 3. Improving human-AI knowledge coconstruction

# 3.1. Application of constructivist principles to prompt engineering using GenAI

Constructivism, as an epistemology, provides a theory of learning and meaning making. It explains the nature of knowledge, including “the mechanisms through which humans acquire and internalize” knowledge (U¨ltanir, 2012, p. 195). Piaget’s (1955) theory of constructivism suggests that learners build knowledge through experiences. Bruner (1961) and Vygotsky (1978) extend this to social contexts, where learning happens through interaction. According to Stojanov (2023), when users interact with GenAI, they engage in a form of social constructivism with the AI acting as an MKO. This interaction can help users progress into their zone of proximal development, where they can perform more advanced tasks under expert guidance before they can do so independently (Dwivedi et al., 2023). Several key principles central to the constructivist learning process can be applied to shape and understand AI prompting. Table 1 provides an explanation of how these principles relate to the shaping of prompt engineering.

By applying the constructivist principles shown in Table 1 to AI prompting, users can construct prompts that align with the active, contextualized, collaborative, and reflective nature of knowledge creation. These principles guide the construction of prompts that encourage meaningful engagement, connecting new information with prior knowledge and fostering problem-solving tasks (Kim & Adlof, 2023). When users interact with GenAI tools such as ChatGPT through an iterative process of prompting, they create a dialogic environment where the AI, acting as an MKO, scaffolds the learning and knowledge-building experience (Wang & Yin, 2021). This interactive process, aided by the AI’s prompt responses, becomes a zone where the user can engage with complex problems and develop solutions with the AI’s support before being able to do so alone (Kim & Adlof, 2023). Integrating these principles of collaborative knowledge co-construction into prompt engineering, can improve the results of human-AI interactions and increase the effectiveness of GenAI prompting (Cooper, 2023). The subsequent section will present an overview of how these constructivist principles are applied within prompt engineering, guiding the development of an AI prompting protocol.

# 3.2. Knowledge co-construction: A step-bystep AI prompting protocol

The backbone of prompt engineering entails thoroughly thinking through the process of how to construct the problem, opportunity or question that you are posting to the GenAI tool. A wellconstructed prompt will guide the AI to provide the most accurate and relevant information based on the inquiry, ensuring that the model’s responses are correct and free from hallucination (McIntosh et al., 2023). Owing to the capability of GenAI tools to imitate human behavior, they should be considered partners in the collaborative process of knowledge co-construction (Suh et al., 2021).

In personal constructivism, the knowledgebuilding experience is seen as an iterative process, where new understanding is derived from existing knowledge (Piaget, 1955). Similarly, when given a prompt or input text, ChatGPT, as a GenAI tool, generates continuous text by predicting the next word to be used, also rendering the process iterative (Dwivedi et al., 2023). Drawing from social constructivism, Vygotsky (1978) emphasizes the critical role of active engagement in jointly creating knowledge. In the context of AI prompting, this aligns with a process of iterative refinement, enhancing the dialogue between the human user and the AI, with the aim of formulating a cohesive response to a problem or query (Short & Short, 2023).

Thus, leveraging both these constructivist perspectives, AI prompting encompasses an iterative loop consisting of three overarching dimensions and six steps, that foster the human-AI collaborative dialogue and facilitate knowledge coconstruction. Three dimensions of constructivism are of particular relevance when considering the design of AI prompts. First, constructivism fundamentally relies on a context-centric interpretation of knowledge construction (Piaget, 1955). Similarly, in AI prompting, considering context is crucial (Paschen et al., 2019). By accounting for the user’s prior knowledge, the specific topic or problem, the intended audience, and the appropriate tone, prompters can create relevant and engaging prompts that facilitate meaningful learning experiences by connecting users’ existing knowledge with new information from the AI model (Cooper, 2023; Jarrahi et al., 2023).

Second, constructivist learning places emphasis on the crucial structural elements required for building cognitive or mental models that facilitate the organization of knowledge (Vygotsky, 1978). Similarly, well-designed prompts in AI prompting, with a clear structure, support the collaborative construction of knowledge between users and AI models. A defined prompt structure guides user interaction, facilitating cognitive processes involved in knowledge construction (Hashem et al., 2024) and fostering human-AI symbiosis. This symbiotic relationship enhances the interaction between humans and AI systems, augmenting the intelligence of both parties progressively over time (Jarrahi, 2018).

Third, evaluation of contextual and structural elements is essential to ensure optimal knowledge organization and construction (Kim & Adlof, 2023). In AI prompting, evaluation also plays a crucial role, similar to constructivist learning, enabling critical reflection to understand and refine mental models for optimal knowledge construction (Dwivedi et al., 2023). It also helps with avoiding the spread of misinformation and bias, by verifying the provided information (Berente et al., 2021). Additionally, prompters need to assess the effectiveness of prompts and generated responses in addressing questions or problems, fostering engagement, and providing meaningful insights to users. Continuous evaluation of prompts and user interactions allows prompters to enhance the design quality and effectiveness of their prompts, which promotes ongoing learning and improvement (Zamfirescu-Pereira et al., 2023). Figure 1 visually presents this constructivist approach to AI prompting, providing examples to illustrate its application in a business context. These three dimensions and their six associated steps are discussed in greater depth in the following sections.

Table 1.  The intersection of constructivism and Al prompt engineering in GenAl   

<html><body><table><tr><td>Constructivist</td><td>Principle defined</td><td>Principle applied to Al prompt engineering.</td></tr><tr><td>principle 1. Learning is an active process</td><td>Learners actively construct their understanding and knowledge of the world by engaging with and questioning information, rather than passively absorbing or replicating it (Cooper, 2023).</td><td>Prompts should be designed to facilitate active engagement. Instead of simple question-answer or command-driven prompts, prompts should be open-ended, provoke thought, demand exploration, or stimulate conversation, causing the user to deeply engage with the responses generated by the Al.</td></tr><tr><td>2. Prior knowledge influences learning</td><td>Learning does not occur in a vacuum. As such, while. the learner actively constructs knowledge, they link new information to what is already known. (Crosthwaite &amp; Baisa, 2023; Vygotsky, 1978). A learner&#x27;s prior knowledge and experiences serve as the foundation for new learning. These prior experiences influence how new information is interpreted and assimilated into existing cognitive</td><td>In the context of Al prompt engineering, the user&#x27;s prior knowledge. greatly influences the model&#x27;s output. Furthermore, Al systems can leverage past interactions and develop context-aware prompting systems to cater to the user&#x27;s inferred knowledge.</td></tr><tr><td>3. Learning is contextualized</td><td>structures (Ausubel, 2012). The context in which learning occurs plays a. significant role in constructivist theory. Knowledge is interconnected with the situation in which it is acquired, emphasizing the importance of embedding learning in realistic and relevant settings (Peters et al., 2013).</td><td>When designing prompts for Al systems, leveraging user context,. location, or previous interactions can foster more meaningful and productive interactions. Tailoring prompts to the user&#x27;s individual context enhances the relevance and effectiveness of the Al system.</td></tr><tr><td>4. Learning is collaborative</td><td>Constructivist learning highlights the benefits of collaboration and social interactions. Learners consolidate their understanding and construct new knowledge more effectively when working together and sharing ideas (Vygotsky, 1978).</td><td>In Al prompt engineering, the user and Al model work collaboratively to construct a conversation. Users provide prompts, and Al models generate responses based on the user&#x27;s input, creating an ongoing discourse. This collaboration enhances the learning process and facilitates knowledge co-construction.</td></tr><tr><td>5. Reflection enhances learning</td><td>A critical component of constructivist learning is the process of reflection. Learners should have the opportunity to reflect on their experiences, current understanding and contemplate how they can apply their new knowledge in the future (Piaget, 1955).</td><td>In the context of human-Al interaction, prompts serve to promote. reflection and understanding for both the user and the Al system. Users engage in critical evaluation, assessing whether the Al&#x27;s responses meet their needs and prompting them to think deeply. and apply insights gained from the interaction to new scenarios.</td></tr><tr><td>6. Learning involves problem- solving</td><td>Constructivism promotes active engagement in problem-solving tasks, in which learners confront challenges and actively participate in the learning process (Vygotsky, 1978).</td><td>Constructivist learning actively engages learners in problem-solving tasks. Similarly, prompt engineering could frame prompts as problems or challenges for users to solve. The Al system guides users through problem-solving stages, facilitating active learning and making the interaction process more engaging.</td></tr></table></body></html>

# 3.2.1. Context

When crafting an AI prompt, it is vital for business managers and their teams to clearly define and map out the context surrounding the inquiry. The context should include prior knowledge of the problem or scenario, delineate who the AI model responses should involve or be targeted at, and be clear with the appropriate tone or complexity relative to the specific problem or question (Cabrera et al., 2023). Context-centric information improves the output of human-AI interactions and assists the GenAI tool in generating actionable responses (Liu et al., 2023)dthat is, the broader and deeper the context provided, the more effective AI can be at producing meaningful and useful output.

From a context perspective, the first step in the AI prompting protocol includes the identification of the problem, where the user determines the initial prompt or question to pose to the AI (Liu et al., 2023). This can range from a simple query to a more complex request or instruction. Informing this initial stage is the second step, which involves the user’s prior knowledge and aids in a more comprehensive formulation of the prompt (Jarrahi et al., 2023). For example, if a manager is using ChatGPT as an AI chatbot to respond to a customer complaint, it would be important to include the underlying problem faced by the customer, identify the factors that contributed to their dissatisfaction, and insights into potential solutions. Any relevant information that would enable the chatbot to provide a more comprehensive, meaningful and relevant response to the customer’s complaint once prompted, would be of value.

# 3.2.2. Structure

The structure of the prompt involves the format and layout of the prompt, detailing how it should be organized and presented. Figure 2 provides an example of a structured prompt, which aims to assess product availability based on a customer’s inquiry. Different prompt structures have been proposed, including zero-shot prompting, prompting with examples (one-, few-, and multi-shot), chain-of-thought prompting and role prompting (Bulat & Tzimiropoulos, 2023). Users need to understand the different approaches and when which structure is most appropriate.

The structured prompt explicitly defines the expectations, thereby directing the AI to generate responses that align with the desired outcomes. Important factors to consider include clarity, ensuring the questions are clear and easy to understand; conciseness, presenting the information in a succinct manner; simplicity, using plain language and avoiding technical jargon; and directness, making sure the prompts address the specific customer queries.

![](img/beb912594a518f7755d480c65bcd90f2b3337f611e66d5edd1df604edfd4e687.jpg)  
Figure 1. A prompt protocol for co-constructed AI knowledge

![](img/53607b4af0fc12e54669cf58948b574827323e6c25bae8ddc2ed534c75d47c17.jpg)

The third and fourth steps of the prompting protocol also occur within the structural dimension. Step three entails creating the prompt. Once the prompt has been created, the AI model processes the prompt by leveraging its learned patterns and information from its training data to generate a relevant response. The process of prompt curation and optimization occurs next in step four, involving the selection and assembly of prompts with a goal-oriented approach to ensure they are constructed correctly and aligned with the desired outcome. Optimization is the process of tweaking these curated prompts for efficiency, ensuring they are clear and concise, removing ambiguity, and enhancing their ability to generate informative and relevant AI responses. The AI model aims to provide coherent and accurate responses by leveraging the given prompt and its training, while the user curates and optimizes these responses by assessing their alignment with their own prior knowledge and the context of the original question. This may involve clarifying the question, modifying the phrasing or context, or specifying the desired response type. This iterative curation process allows both the AI model and the user to collaborate and improve the quality of the generated responses. Important to note here is that the machine learning structure of chatbots such as ChatGPT, cannot access real-time or company-specific data from the Internet or proprietary databases, and as such, one has to structure the AI prompt efficiently to get the most accurate AI analysis.

# 3.2.3. Evaluation

Evaluation is the process used to assess the quality of the AI’s responses through validation and refinement (step five), and lastly by applying the prompt in context (step six). Validation involves testing the output generated against the original objectives to see if it is accurate, without bias, and fit for the intended use. Refinement denotes a process of fine-tuning the prompt, incrementally improving the response by either elaborating on complex points or streamlining the information for clarity and precision.

When evaluating the GenAI response, users not only need to evaluate the appropriateness of the GenAI output to the best of their abilities, but they also need to evaluate the potential bias in their application of the output. Potential bias, both on the part of the AI and the user, needs to be considered. Bias in AI is typically defined as a divergence from standard statistical patterns, which could be due to a biased dataset or biased assumptions in the model (Kaplan & Haenlein, 2020). These can result in, for example, the perpetuation of gender stereotypes (Marinucci et al., 2023). While it might be tempting to attribute most bias in human-AI interaction to the AI component, the relationship is actually more nuanced. In fact, there are instances where AI has demonstrated less bias than humans, underscoring the complexity of this interaction (Black & van Esch, 2020). The detection of biases within AI can be challenging, as these biases tend to become formalized and ingrained based on the data that it has been trained on, thereby making it difficult to detect (Kaplan & Haenlein, 2019). To help in identifying these possible areas of bias, Table 2 provides a five-step validation process that can serve as a practical self-check guide to minimize potential bias in human-AI co-constructed knowledge.

It is crucial to acknowledge that humans may also introduce bias when evaluating AI-generated content, especially when the content is conconstructed with GenAI. Three key biases are identified: First, automation bias, or the tendency to over-trust AI systems such that users assume AI output is always correct or superior, is a threat to proper validation of GenAI output (Alon-Barkat & Busuioc, 2023). While AI assists human decisionmaking, the use of Explainable AI is crucial to mitigate automation bias among users, a foundational step toward establishing secure hybrid intelligence systems (Rai, 2020). In order to curb the impacts of automation bias, business managers and their teams should familiarize themselves with the data, algorithms, and capabilities underpinning the AI’s recommendations. To assess the reliability of the AI output, users can prompt the GenAI chatbot to explain its rationale. This explanation can help in deciding whether the provided advice can be trusted.

Table 2. Five-step validation process for co-constructed AI knowledge   

<html><body><table><tr><td></td><td>Question 1</td><td>Question 2</td><td>Question 3</td><td>Question 4</td><td>Question 5</td></tr><tr><td>Validation question</td><td>Do I have a basic understanding of the data used to train the GenAl model?</td><td>Is the output comparable to verified statistical patterns?</td><td>Can I verify the reasoning or process used to get to the output?</td><td>Does this confirm what I thought before? If yes, is there an alternative perspective/ view that can</td><td>Have my prompt and subsequent interactions potentially influenced the GenAl&#x27;s response?</td></tr><tr><td>Bias addressed</td><td>Bias in the training data</td><td>Perpetuation of data biases</td><td>Automation bias</td><td>be considered? Confirmation bias</td><td>Feedback loop bias</td></tr></table></body></html>

Second, confirmation bias might lead users to overvalue AI-generated results that align with their preconceptions while undervaluing those that do not. Confirmation bias is a tendency to favor information that confirms preexisting beliefs or values, while ignoring or discounting evidence that challenges or contradicts them (Nickerson, 1998). This bias can manifest in various ways, including in how people gather information, interpret it, and use it. It essentially encompasses the various ways our preconceptions or beliefs can unconsciously influence our decision-making and analysis.

Finally, feedback loop bias could also potentially negatively impact the validity of GenAI output. Feedback loop bias, prevalent in recommendation systems, occurs when the system’s suggestions, influenced by user interactions, reinforce preexisting biases (Canhoto & Clear, 2020). Likewise, during GenAI-human exchanges, the act of curating and optimizing the GenAI output might steer the AI to adapt its replies toward user preferences. Thus, users should be cognizant of instances where their interactions may have unduly constrained the GenAI’s response. While users need not affirmatively answer each question, awareness of these potential biases could assist in curbing the propagation of misinformation and disinformation. Additionally, it could enhance the quality of coconstructed human-GenAI knowledge.

In conclusion, the application step also forms a cyclical loop back to the context dimension, as the user has to analyze and assess the prompt’s components to identify potential improvements to enhance the efficacy of the response and to assess its alignment with the context of the domain of knowledge within which it has been coconstructed. AI tools like ChatGPT and GPT-4 do not have access to real-time or specific business data. The output generated is based on the preexisting knowledge that the AI tool was trained on, and the details provided by the user in the prompt. As such, output validation and contextual evaluation are important steps to ensure that the AI’s response is not inaccurate or incorrect. This may involve taking the AI output, analyzing it in the context of the particular business situation, and considering how it fits into the existing strategy or knowledge of the business manager, their team, and their business.

If the AI tool’s response does not align with the current business situation or does not satisfy the user’s needs, it may be necessary to go back to step four, curate the prompt, validate again and refine. This iterative cycle fosters ongoing enhancement of the AI’s responses for the developers (Marinucci et al., 2023), and promotes human learning (Stojanov, 2023) by encouraging users to reflect on the particular context, apply their existing knowledge, and evaluate the potential effect of the AI’s output within the given scenario. Such engagement creates human-AI symbiosis to support meaningful knowledgebuilding interactions with users (Jarrahi, 2018).

# 4. Assessing the business value of mastering the art of effective prompting with GenAI

The business value of developing an AI prompting protocol that promotes symbiotic human-AI knowledge co-construction, is that it enables organizations to harness the collective intelligence of humans and AI, leading to increased innovation, improved decision-making, and enhanced productivity within the business domain (Jarrahi et al., 2023; Krakowski et al., 2023). Addressing previous calls to better understand human-AI symbiosis in an organizational context (Hashem et al., 2024; Jarrahi, 2018), we provide a protocol with distinct constructivist dimensions and a step-by-step framework to facilitate a process-based perspective on how to achieve more effective collaborative efforts between humans and AI. Approaching this process from a constructivist viewpoint, we extend the existing theory to the context of human-AI knowledge co-construction. We propose AI can be viewed as a MKO (Stojanov, 2023). In this role, AI assists users in enhancing their knowledge and skills, enabling them to undertake more complex tasks under expert guidance until they can execute these tasks independently. By investigating this dynamic, the study builds on the previous work by Przegalinska et al. (2019) and Raisch and Krakowski (2021), in enhancing business managers’ understanding of how GenAI chatbots can effectively support and facilitate the coconstruction of knowledge within their teams.

The iterative nature of AI prompt engineering also closely aligns with the well-established principles of personal and social constructivism (Bruner, 1961; Piaget, 1955; Vygotksy, 1978), emphasizing the importance of building on one’s existing knowledge through a sequence of ongoing steps (Kim & Adlof, 2023). These knowledgebuilding steps are reflected in the prompting protocol through curating, refining, validating, and evaluating one’s knowledge base when revising AI prompts. By recognizing this synergy, the developed protocol acknowledges the value of iterative processes in knowledge construction, which allows for the continuous improvement and development of knowledge in the context of human-AI collaboration. The shift toward utilizing GenAI for knowledge processing within organizations is increasingly becoming a vital strategy for securing a competitive advantage (Krakowski et al., 2023). Business managers are pivotal in facilitating this transformation by assuming a leadership role in the formulation of best practice guidelines for the implementation of an AI prompting protocol. Through such a proactive approach, organizations can set themselves up for future successes by advancing their workforce skills and adapting to the forthcoming technological advancements (Budhwar et al., 2023). Through the implementation of an AI prompting protocol which facilitates contextually relevant, structured, focused communication with AI systems, businesses can enhance their utilization of insights and content generated by AI (Desouza et al., 2020). This transformation effectively supports the wider goal of leveraging AI to boost both internal team productivity and external operational efficiency.

Through the development of an organizational AI prompting protocol, business managers not only can improve their team’s proficiency in using GenAI, but also enhance the AI literacy within their organization (Kaplan & Haenlein, 2020), as well as validate the GenAI output. By implementing such a protocol, organizations can improve their organizational knowledge and familiarity with AI systems, enabling their employees to leverage AI tools more effectively (Jarrahi, 2018; Jarrahi et al., 2023). This increased familiarity and expertise empower business managers and their teams to make informed decisions and maximize the value derived from AI technologies within their operations. The AI prompting protocol also emphasizes the crucial role of human input in the AI prompting process, underscoring the significance of leveraging uniquely human abilities and expertise to evaluate and effectively apply the generated output (Short & Short, 2023). By adopting effective AI prompting practices, organizations can augment human capabilities while fostering human-AI collaboration. This collaborative approach enhances overall productivity and efficiency within organizations, leveraging the strengths of both humans and AI to drive success (Campbell et al., 2020; Kanbach et al., 2023).

It is important to also note the limitations of AI prompting and determine when the use of GenAI may not be suitable. GenAI models, including ChatGPT, may generate biased or inaccurate outputs and should not be solely relied upon for critical decision-making, legal document development, or compliance with legislation (Arrieta et al., 2020; Kaplan & Haenlein, 2020; Oosthuizen et al., 2021). We provide a process with which to mitigate and decrease potential human and AI biases in the co-constructed output.

The quality of GenAI’s output is also symbiotically tied to the quality of input instructions, which means that detailed and well-crafted prompts will, in turn, yield more accurate and valuable responses. As such, there are a number of circumstances in which GenAI should not be used as a sole source of information: First, when making critical business decisions that require multiple inputs and consideration for different stakeholder groups, such a complex decision should not be left solely to the discretion of GenAI as it cannot provide a substitute for human judgement (Dwivedi et al., 2023). Second, in a setting that requires adherence to specific legislation and attention to detail, such as the development of legal documentsdwhile GenAI content could be incorporateddensuring alignment with relevant legislation and accuracy should remain at the discretion of the individual (Budhwar et al., 2023). Third, as argued above, all AI is biased by the data it trains on and users of GenAI need to be aware of the potential for bias to be present in the output (Marinucci et al., 2023). The implication thereof is the unintentional perpetuation of bias that is ingrained in the data that GenAI is reliant on. Fourth, managers should engage and train teams around the data privacy and protection legislation that governs their data management policies. It is critical that users do not share confidential or sensitive information with publicly available, open-access GenAI platforms. Finally, managers should encourage their teams to verify information produced by GenAI that is presented as factual information and not to assume its verification. The potential for AI hallucinations (McIntosh et al., 2023; Metze et al., 2023) can result in the reproduction of factually incorrect information. This emphasizes the importance of having a welldefined protocol for GenAI use within the organization, coupled with human verification of information, to optimize the process of knowledge coconstruction between humans and AI.

# 5. Limitations and areas for future research

While the inclusion of constructivism theory in GenAI tools and the emergence of models like ChatGPT have significantly enhanced knowledge acquisition processes, there are still certain limitations that need to be addressed, which in turn open several avenues for future research. Though AI tools can generate comprehensive and creative content, they currently lack the capability to contextualize information, largely providing output based purely on the given prompt. Enhancing the AIs’ ability to ‘understand’ and reflect context could constitute an exciting area for further study.

The ethical, legal, and practical challenges exposed by AI technologies are another area that warrants more research attention. Future research could consider developing clear guidelines for understanding the principles of responsible AI including research examining how AI can reduce or eliminate bias, false information, and plagiarism in their output. In addition, validation of AI responses is another noteworthy limitation. Techniques to improve the accuracy and reliability of AIgenerated content, and methods to help users verify this content, could be an interesting aspect to explore in future research. Finally, with AI transforming business models and operations, it would be beneficial to study how AI could be effectively incorporated into various business practices without compromising ethical norms and the human touch required in many business interactions.

# References

Alon-Barkat, S., & Busuioc, M. (2023). HumaneAI interactions in public sector decision making: “Automation bias” and “selective adherence” to algorithmic advice. Journal of Public Administration Research and Theory, 33(1), 153e169.   
Arrieta, A. B., Dı´az-Rodrı´guez, N., Del Ser, J., Bennetot, A., Tabik, S., Barbado, A., Garcia, S., Gil-Lopez, S., Molina, D., Benjamins, R., Chatila, R., & Herrera, F. (2020). Explainable artificial intelligence (XAI): Concepts, taxonomies, opportunities, and challenges toward responsible AI. Information Fusion, 58, 82e115.   
Ausubel, D. P. (2012). The acquisition and retention of knowledge: A cognitive view. Berlin, Germany: Springer Science & Business Media.   
Berente, N., Gu, B., Recker, J., & Santhanam, R. (2021). Managing artificial intelligence. MIS Quarterly, 45(3), 1433e1450.   
Black, J. S., & van Esch, P. (2020). AI-enabled recruiting: What is it and how should a manager use it? Business Horizons, 63(2), 215e226.   
Bruner, J. S. (1961). The act of discovery. Harvard Educational Review, 31(1), 21e32.   
Budhwar, P., Chowdhury, S., Wood, G., Aguinis, H., Bamber, G. J., Beltran, J. R., Boselie, P., Cooke, F. L., Decker, S., DeNisi, A., Dey, P. K., Guest, D., Knoblich, A. J., Malik, A., Paauwe, J., Papagiannidis, S., Patel, C., Pereira, V., Ren, S., Rogelberg, S., Saunders, M. N. K., Tung, R. L., & Varma, A. (2023). Human resource management in the age of generative artificial intelligence: Perspectives and research directions on ChatGPT. Human Resource Management Journal, 33(3), 606e659.   
Bulat, A., & Tzimiropoulos, G. (2023). Language-aware soft prompting: Text-to-text optimization for few-and zero-shot adaptation of V&L models. International Journal of Computer Vision, 132, 1108e1125.   
Cabrera, A´. A., Tulio Ribeiro, M., Lee, B., Deline, R., Perer, A., & Drucker, S. M. (2023). What did my AI learn? How data scientists make sense of model behavior. ACM Transactions on Computer-Human Interaction, 30(1), 1e27.   
Campbell, C., Sands, S., Ferraro, C., Tsao, H. Y. J., & Mavrommatis, A. (2020). From data to action: How marketers can leverage AI. Business Horizons, 63(2), 227e243.   
Canhoto, A. I., & Clear, F. (2020). Artificial intelligence and machine learning as business tools: A framework for diagnosing value destruction potential. Business Horizons, 63(2), 183e193.   
Cooper, G. (2023). Examining science education in ChatGPT: An exploratory study of generative artificial intelligence. Journal of Science Education and Technology, 32(3), 444e452.   
Crosthwaite, P., & Baisa, V. (2023). Generative AI and the end of corpus-assisted data-driven learning? Not so fast. Applied Corpus Linguistics, 3(3), 100066.   
De Bruyn, A., Viswanathan, V., Beh, Y. S., Brock, J. K.-U., & von Wangenheim, F. (2020). Artificial intelligence and marketing: Pitfalls and opportunities. Journal of Interactive Marketing, 51(1), 91e105.   
De Cremer, D., Bianzino, N. M., & Falk, B. (2023, April 13). How generative AI could disrupt creative work. Harvard Business Review. Available at https://hbr.org/2023/04/howgenerative-ai-could-disrupt-creative-work   
Desouza, K. C., Dawson, G. S., & Chenok, D. (2020). Designing, developing, and deploying artificial intelligence systems: Lessons from and for the public sector. Business Horizons, 63(2), 205e213.   
Dwivedi, Y. K., Kshetri, N., Hughes, L., Slade, E. L., Jeyaraj, A., Kar, A. K., Baabdullah, A. M., Koohang, A., Raghavan, V., Ahuja, M., Albanna, H., Albashrawi, M. A., Al-Busaidi, A. S., Balakrishnan, J., Barlette, Y., Basu, S., Bose, I., Brooks, L., Buhalis, D., & Wright, R. (2023). Opinion paper: “So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges, and implications of generative conversational AI for research, practice, and policy. International Journal of Information Management, 71(August), 102642.   
Eriksson, T., Bigi, A., & Bonera, M. (2020). Think with me, or think for me? On the future role of artificial intelligence in marketing strategy formulation. The TQM Journal, 32(4), 795e814.   
Ferraro, C., Demsar, V., Sands, S., Restrepo, M., & Campbell, C. (2024). The paradoxes of generative AI enabled customer service: A guide for managers. Business Horizons, 67(5), 549e559.   
Frey, B. B. (2018). The Sage encyclopedia of educational research, measurement, and evaluation. Thousand Oaks, CA: Sage.   
Hashem, R., Ali, N., El Zein, F., Fidalgo, P., & Khurma, O. A. (2024). AI to the rescue: Exploring the potential of ChatGPT as a teacher ally for workload relief and burnout prevention. Research and Practice in Technology Enhanced Learning, 19, 23.   
Jarrahi, M. H. (2018). Artificial intelligence and the future of work: Human-AI symbiosis in organizational decision making. Business Horizons, 61(4), 577e586.   
Jarrahi, M. H., Askay, D., Eshraghi, A., & Smith, P. (2023). Artificial intelligence and knowledge management: A partnership between human and AI. Business Horizons, 66(1), 87e99.   
Kanbach, D., Heiduk, L., Blueher, G., Schreiter, M., & Lahmann, A. (2023). The GenAI is out of the bottle: Generative artificial intelligence from a business model innovation perspective. Review of Managerial Science, 18, 1198e1220. Available at https://doi.org/10.1007/s11846-023-00696-z   
Kaplan, A., & Haenlein, M. (2019). Siri, siri, in my hand: Who’s the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence. Business Horizons, 62(1), 15e25.   
Kaplan, A., & Haenlein, M. (2020). Rulers of the world, unite! The challenges and opportunities of artificial intelligence. Business Horizons, 63(1), 37e50.   
Kietzmann, J., & Park, A. (2024). Written by ChatGPT: Large language models, conversational chatbots, and their place in society and business. Business Horizons, 67(5), 453e459.   
Kim, M., & Adlof, L. (2023). Adapting to the future: ChatGPT as a means for supporting constructivist learning environments. TechTrends, 68, 37e46.   
Krakowski, S., Luger, J., & Raisch, S. (2023). Artificial intelligence and the changing sources of competitive advantage. Strategic Management Journal, 44(6), 1425e1452.   
Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., & Neubig, G. (2023). Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. ACM Computing Surveys, 55(9), 195.   
Marinucci, L., Mazzuca, C., & Gangemi, A. (2023). Exposing implicit biases and stereotypes in human and artificial intelligence: State of the art and challenges with a focus on gender. AI and Society, 38, 747e761.   
McIntosh, T. R., Liu, T., Susnjak, T., Watters, P., Ng, A., & Halgamuge, M. N. (2023). A culturally sensitive test to evaluate nuanced GPT hallucination. IEEE Transactions on Artificial Intelligence, 1, 1e13.   
Metze, K., Morandin-Reis, R. C., Lorand-Metze, I., & Florindo, J. B. (2023). Bibliographic research with ChatGPT may be misleading: The problem of hallucination. Journal of Pediatric Surgery, 59(1), 158. Available at https://doi.org/ 10.1016/j.pedsurg.2023.08.018   
Nickerson, R. S. (1998). Confirmation bias: A ubiquitous phenomenon in many guises. Review of General Psychology, 2(2), 175e220.   
Noy, S., & Zhang, W. (2023). Experimental evidence on the productivity effects of generative artificial intelligence. Science, 381(6654), 187e192. (2021). Artificial intelligence in retail: The AI-enabled value chain. Australasian Marketing Journal, 29(3), 264e273.   
Paschen, U., Pitt, C., & Kietzmann, J. (2019). Artificial intelligence: Building blocks and an innovation typology. Business Horizons, 63(2), 147e155.   
Peres, R., Schreier, M., Schweidel, D., & Sorescu, A. (2023). On ChatGPT and beyond: How generative artificial intelligence may affect research, teaching, and practice. International Journal of Research in Marketing, 40(2), 269e275.   
Peters, L. D., Pressey, A. D., Vanharanta, M., & Johnston, W. J. (2013). Constructivism and critical realism as alternative approaches to the study of business networks: Convergences and divergences in theory and in research practice. Industrial Marketing Management, 42(3), 336e346.   
Piaget, J. (1955). The construction of reality in the child. Journal of Consulting Psychology, 19(1), 77.   
Przegalinska, A., Ciechanowski, L., Stroz, A., Gloor, P., & Mazurek, G. (2019). In bot we trust: A new methodology of chatbot performance measures. Business Horizons, 62(6), 785e797.   
Rai, A. (2020). Explainable AI: From black box to glass box. Journal of the Academy of Marketing Science, 48, 137e141.   
Raisch, S., & Krakowski, S. (2021). Artificial intelligence and management: The automationeaugmentation paradox. Academy of Management Review, 46(1), 192e210.   
Ramaul, L., Ritala, P., & Ruokonen, M. (2024). Generative and conversational AI affordances: How the new breed of chatbots are revolutionizing the creative and knowledge industries. Business Horizons, 67(5), 615e627.   
Ray, P. P. (2023). ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics, limitations, and future scope. Internet of Things and CyberPhysical Systems, 3, 121e154.   
Short, C. E., & Short, J. C. (2023). The artificially intelligent entrepreneur: ChatGPT, prompt engineering, and entrepreneurial rhetoric creation. Journal of Business Venturing Insights, 19, e00388.   
Stojanov, A. (2023). Learning with ChatGPT 3.5 as a more knowledgeable other: An autoethnographic study. International Journal of Educational Technology in Higher Education, 20, 35.   
Suh, M., Youngblom, E., Terry, M., & Cai, C. J. (2021, May). AI as social glue: Uncovering the roles of deep generative AI during social music composition. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. Available at https://doi.org/10.1145/3411764.3445219   
Sundberg, L., & Holmstro¨m, J. (2023). Democratizing artificial intelligence: How no-code AI can leverage machine learning operations. Business Horizons, 67(5), 777e788.   
U¨ltanir, E. (2012). An epistemological glance at the constructivist approach: Constructivist learning in Dewey, Piaget, and Montessori. International Journal of Instruction, 5(2), 195e212.   
Vygotsky, L. (1978). Mind in society. Cambridge, MA: Harvard University Press.   
Wang, X., & Yin, M. (2021). Are explanations helpful? A comparative study of the effects of explanations in AIassisted decision-making. In $2 6 ^ { t h }$ International Conference on Intelligent User Interfaces. Available at https://doi.org/ 10.1145/3397481.3450650   
Zamfirescu-Pereira, J. D., Wong, R. Y., Hartmann, B., & Yang, Q. (2023, April). Why Johnny can’t prompt: How nonAI experts try (and fail) to design LLM prompts. In Proceedings of the $2 0 2 3 \ C H I$ Conference on Human Factors in Computing Systems. Available at https://doi.org/10.1145/ 3544548.3581388