# A comparative study of voice in Chinese English-major undergraduates’ timed and untimed argument writing

Xiangmin Zeng a,\* , Jie Liu b , Neil Evan Jon Anthony Bowen c

a School of Foreign Languages, Southwest Jiaotong University, Chengdu, China b Department of Curriculum, Pedagogy and Assessment, Institute of Education, University College London, UK c Department of English & Linguistics, Faculty of Liberal Arts, Thammasat University, Bangkok, Thailand

# A R T I C L E I N F O

# A B S T R A C T

Keywords:   
EFL voice construction   
Voice dimensions   
Voice categories   
Argument writing   
Assessing voice in student writing

As a somewhat elusive and occlusive concept, voice can be a challenging and formidable hurdle for second language (L2) writers. One area that exemplifies this struggle is timed argument writing, where authors must position claims, ideas, and individual perspectives to an existing knowledge base and scholarly community under the confines of time. To enrich our un derstandings of voice construction in L2 English writers’ timed writing, we explored how 41 Chinese English-major undergraduates deployed authorial voice in two prompt-based argument writing tasks (timed versus untimed). We also sampled their self-reported knowledge, use, and understanding of voice through a survey-based instrument. To compare the quantity and quality of voice construction between the two samples, we measured 10 voice categories, three voice dimensions, and overall voice strength. Results showed that only two categories displayed sta tistically significant differences in terms of frequencies, but all three voice dimensions and overall voice strength scored significantly higher in untimed writing samples. Based on the results of our text analysis and survey, we further highlight the complexities of voice in L2 writing, provide evidence in support of existing voice rubrics, and make practical suggestions for teaching and assessing voice in writing.

# 1. Introduction

In academic writing, authorial voice assumes a key role in the creation and reception of a measured perspective toward knowledge and a scholarly community. It can act as a linchpin that binds together arguments, ideas, and individual perspectives, and directly affects academic success, scholarly engagement, and effective communication within diverse educational settings (Hyland, 2008). However, cultivating a distinct and authentic voice goes beyond mastery of linguistic units, as voice can be realized through lexical and grammatical choices that are perhaps best learnt through osmosis and immersion in a discourse community (Bowen & Thomas, 2020). Consequently, for L2 writers, the quest for an authentic and authoritative voice is both a compelling journey and a formidable hurdle, reflecting not only pedagogical challenges, but also issues surrounding inclusivity (Ivaniˇc, 1998). Indeed, the importance of and challenges surrounding voice in L2 writing are evidenced by the large number of studies exploring its acquisition and use (Ahmed & Zhang, 2023).

One major strand of interest has been the investigation of voice in arguments written by L2 English students (Yoon, 2017; Zhao,

2013, 2017, 2019), a genre that is extensively found in L2 writing exams (Hirvela, 2017) and higher education settings (Hirvela & Belcher, 2021). However, in researching L2 argument writing, “there has been less focus on the effect of writing time on individual components” (Lee et al., 2021, p. 253), wherein most studies have focused on comparing scores assigned to non-voice elements, such as coherence and cohesion, lexical variation, and overall scores (e.g., Khuder & Harwood, 2015; Knoch & Elder, 2010; Wu & Erlam, 2016). Indeed, to the best of our knowledge, there is only one study on the influence of time on voice construction in L2 writers’ argument essays (Yoon & Abdi Tabari, 2023). Consequently, while studies show correlations between effective voice construction and the quality of timed argument writing (Zhao & Llosa, 2008; Zhao, 2017), we know little about how these same writers would deploy voice in untimed writing, where extended source use, more time for planning and revising, access to model texts, etc., might affect their choices.

Being able to identify what voice features L2 writers can and cannot attend to in timed (controlled) and untimed (uncontrolled) writing is important for several reasons. First, by comparing the choices students make in timed versus untimed writing, we can gain insights into the internalized knowledge and skills they are able to apply in high pressure situations (Weigle, 2007). This, in turn, can help educators to focus their teaching strategies on under-utilized or misused voice components. For instance, if voice elements are missing from untimed and timed writing tasks, educators can infer that a student requires extended instruction on these areas to expand his/her expressionist potential. Contrastingly, if voice elements are underused, overused, or used inappropriately in timed writing, educators can advise students on how best to employ their voice repertoire in high-stakes situations like timed tests (socioconstructivist potential). Ultimately, such concerns have important implications for developing a pedagogy of negotiation rather than prescription (Canagarajah, 2015), and establishing the contextual and cognitive validity of timed tests (Weir, 2005).

Accordingly, we compared the construction of voice in 41 upper-intermediate Chinese English-major undergraduates’ argumen tative essays under two conditions: timed writing without access to external resources and, untimed writing with access to external resources and feedback. These conditions were selected to mirror the different contexts students might encounter in real academic settings (see Section 3.3.1 for a detailed rationale). Furthermore, to better situate our exploration through an interpretive hermeneutics lens, we designed a survey to elicit the students’ self-reported beliefs and knowledge surrounding their applications and un derstandings of voice. This helped us to anchor our discussions from the participants’ viewpoints, as well as those of the current literature and our experiences in teaching/assessing L2 writing. Ultimately, through this mixed-method approach, we hope to high light the complexities of integrating voice in L2 writing, provide further evidence in support of existing scoring rubrics on voice, and make practical suggestions for teaching and assessing voice in argument writing. To accomplish these goals, the study addresses the following research questions:

1. How does the realization of voice alter, if at all, when Chinese EFL undergraduates write timed and untimed argumentative essays? 2. What do Chinese EFL students report about their knowledge, use, and understanding of voice in English argument writing, and how might these beliefs be affected by different writing conditions?

# 2. Voice and academic writing

# 2.1. Voice as an elusive construct

In academic writing, voice is a somewhat elusive construct, as evidenced by the various terms used to refer to it, such as personal stamp (Elbow, 1994), idiolect (Coulthard, 2008), authorial voice (Hutchings, 2014), and signature/key (Hood, 2010). In its broadest sense, it refers to the style and tone of an author when presenting ideas and arguments, and it is closely related to the stance a writer takes. A key scholar on academic voice, Ken Hyland (2012), “understand[s] stance to refer to a writer’s rhetorically expressed attitude to the propositions in a text and voice as his or her attitude to a given community.” (p. 134, italics in original) Thus, Hyland seemingly makes a clear distinction between creating a stance on a topic (more writer-oriented) and positioning one’s voice to a context (more reader-oriented). Matsuda (2001) has a similar view on voice when he states that it is “the amalgamative effect of the use of discursive and non-discursive features that language users choose, deliberately or otherwise, from socially available yet ever-changing reper toires; it is the overall impression.” (p. 40) Consequently, as these two quotes highlight, voice is often seen as a gestalt entity that reflects the positioning of a text, its author, and its reader to a discourse community, whereas stance is linked to the status and value of

![](img/a183e92913fd2b5887d6f31602edb9095a1eb635de4a7e6b140c3efa70fd0611.jpg)  
Fig. 1. Voice and communicative stance in academic writing. (Bowen, 2016, p. 43).

information.

Bowen, (2016) further explicates this relationship by suggesting that voice is the amalgamation of interactions: reader-writer interaction (dialogism), interaction with other voices (heteroglossia), and interaction with other texts (intertextuality), as shown in Fig. 1.

Such a view highlights the complexities of studying stance and voice from a trinocular perspective. Ostensibly, they are discursive devices that can be used to indicate membership within a discourse community (Thompson, 2012), create a unique style and tone by the author (Ivaniˇc, 1998; Zhao, 2019), and convey an overall sense of engagement with the reader and the topic (Matsuda & Tardy, 2007). Nevertheless, such a view also highlights why it is difficult to operationalize or delineate voice in an objective way (see also Cameron, 2012).

In this paper, we explore voice primarily from the perspective of Zhao (2013), focusing on discourse that construes the writer’s positioning and evaluation of a topic, as well as their alignment to the reader. While this view of voice does not fully cover the nuanced conceptualization of voice outlined above, we believe it is the best for an exploration of our first research question, as outlined in the following two sections.

# 2.2. Voice as a quantitative and qualitative measurement

As noted by Matsuda and Jeffery (2012), measuring voice in a systematic way can be challenging because “what is measured is limited by what can be measured and by how ‘good writing’ is conceived in the first place” (p. 162). Thus, it is perhaps unsurprising that most studies on written voice have focused on features that are seemingly easier to operationalize in research—typically, met adiscourse markers realized via grammatical features such as modals, adjectives, and adverbs (Biber, 2006; Hood, 2010; Hyland, 2005; Lancaster, 2014). Nevertheless, studies typically codify voice according to bottom-up (a posteriori) or top-down (a priori) categorizations.

In a bottom-up approach, a corpus of texts is segmented into units of analysis and then parsed for markers connected to voice. The resultant words/phrases (metadiscourse) are then grouped according to shared features into categories or dimensions. Typical cate gories include epistemic/deontic stance, hedges, boosters, attitude markers, and engagement (Ahmed & Zhang, 2023). In terms of stance markers, for example, Gray and Biber (2012) illustrate how they can be categorized according to two axes, as per Fig. 2. In this figure, the bottom axis represents their units of analysis, and the other represents movement between attitudinal value (affect) and epistemic stance (evidentiality).

As for top-down categorizations, existing labels are applied to elements that contribute to voice. For instance, Yeh’s (1998) rubric for argumentative essays used a six-point voice scale that included credibility appeals and affective appeals. However, specific guidelines on how to assess such appeals were missing, and there were no means for objective numerical measures such as frequency counts. Helms-Park and Stapleton (2003) put forward a somewhat more robust rubric: the Voice Intensity Rating Scale. It classified linguistic features of voice into four components: (1) assertiveness, represented by hedges and intensifiers; (2) self-identification, represented by first person pronouns; (3) reiteration of central point; and (4) authorial presence and autonomy of thought. However, this rubric ignored the interactive characteristics of voice, whereby a reader can participate in the construction of a text’s voice, and thus perhaps focused too much on projecting the confidence of the writer. Subsequently, to cover better the interactional nature of voice, Hyland (2008) proposed a model that incorporated both stance and engagement: Writer-oriented stance included four features (hedges, boosters, attitude markers, and self-mention); reader-oriented engagement included five features (reader mention, personal asides, knowledge reference, directives, and questions).

Drawing on Helms-Park and Stapleton (2003) and Hyland (2008), Zhao (2013) designed a three-dimensional rubric using seven voice categories. Dimension 1 reflects voice from an ideational perspective. It measures presence and clarity of ideas in terms of two categories: C1-central point articulation and C2-directives. Dimension 2 construes affective aspects of voice: C3-hedges, C4-boosters, and C5-attitude markers. Dimension 3 relates to writer and reader presence: C6-authorial self-mention and C7-reader reference. Each dimension is measured quantitatively (how often an element of each category occurs) and qualitatively (how appropriately these categories are used as judged by the reader). Overall voice strength is based on the combined scores given to the three dimensions. Since Zhao’s (2013) rubric has been validly tested and used in several studies (Yoon, 2017; Zabihi & Bayan, 2020; Zhao, 2017, 2019), we use it to compare voice construction in timed and untimed argumentative writing, as outlined in the Method section.

# 2.3. Voice and L2 argument writing

An increasing number of studies have focused on voice construction in texts written by English as a foreign language (EFL) writers, ranging from dissertations (Ivaniˇc & Camps, 2001) to course assignments (Helms-Park & Stapleton, 2003) to language proficiency tests (Yoon, 2017; Zhao & Llosa, 2008; Zhao, 2013, 2017, 2019). This growing body of literature continues to highlight how appropriately voice is shaped according to the genre of the text, the conventions of the disciplinary field, and the context of the text’s reception (Ahmed & Zhang, 2023).

![](img/aae6ee5634e0ec4da0f04d9c1ffa1836b37262f0d1b6b2084f82136f47e144cf.jpg)  
Fig. 2. Axis by which stance is typically analyzed. (Gray & Biber, 2012, p. 19).

Of relevance to the current study is voice construction in L2 argument writing (Yoon, 2017; Zabihi et al., 2019; Zhao, 2013, 2017, 2019). Such studies frequently claim that evidentiality has a more frequent role than affect in portraying an appropriate stance, and thus this voice element seemingly correlates with text quality (Gray & Biber, 2012, p. 19). Specifically, in most disciplines a valued stance on an argument is one that projects a cautious, limited, yet assertive position (Aull & Lancaster, 2014; Uccelli et al., 2013). Indeed, this is evidenced in research that distinguishes between the value of deontic projections, which help invoke feelings such as disapproval, necessity, and obligation, and epistemic projections, which help convey degrees of certainty or belief.

However, there have also been mixed findings on how voice contributes to argumentative writing quality. For instance, studies have shown how the expression and reception of voice varies depending on the context (Helmes-Park & Stapleton, 2003), culture (Fløttum, 2012), audience (Gea-Valor, 2010), passage of time (Hyland & Jiang, 2016), and influence of the writer’s first language (Zhao & Wu, 2024). Thus, there is no consensus on how best to teach voice so that it resonates to the same degree across different demographic groups. Moreover, the assessment of L2 writing quality as it pertains to voice is often premised on differing views on arguments and argument structures (see Hirvela, 2017). When cycling through different rhetorical moves (e.g., introductions, sum maries, etc.), the concept of an “appropriate voice” also changes, reflecting that voice often occurs in waves or phases as a writer works towards section-specific goals (Kawase, 2015).

Nevertheless, there is a broad consensus that identifiable discourse markers of voice exist, and these make varying contributions to the overall appropriateness and strength of voice in L2 argument writing (Yoon, 2017; Zhao, 2013). Moreover, it is somewhat widely accepted that the qualitative use of these voice markers (how appropriately they are used) correlates more highly with positive judgements of overall voice than the quantitative use of such voice markers (how often they are used) (Yoon & Abdi Tabari, 2023; Zhao, 2013). However, the interplay between qualitative and quantitative aspects of voice is still somewhat under explored in timed versus untimed writing conditions.

# 3. Method

# 3.1. Participants and sample

Participants were third-year Chinese undergraduates $( n = 4 1 $ ) from two intact advanced English classes. All participants were enrolled on an English Major BA program at a large university in China. At the time of the study, none of the students had received any instruction in English-speaking countries, but they had all completed full-time courses $^ { \cdot 3 2 \mathrm { h } }$ per course) on academic, argument, expository, and narrative writing. All students had also passed the Test for English Majors Grade 4 (TEM4)1 at the end of their second year, which is roughly equivalent to a CEFR level of $^ { \mathrm { B 1 + } }$ to B2 (Liu, 2012). Their instructor was a Chinese national who specialized in British and American literature and had passed the TEM8 (CEFR of approximately $^ { \mathrm { B 2 + } }$ to C1). Consequently, this study builds on existing research on voice in L2 writing, particularly in the context of Chinese EFL students. For a comprehensive overview of English education practices and the teaching of argumentative writing in China, readers are referred to the works of Liu and Braine (2005), Pei et al. (2017) and Qin and Karabacak (2010).

In total we collected 41 timed argument essays (average word cou ${ \bf n } { \bf t } = 3 4 0 . 9 8$ , $S D = 4 3 . 2 8 \mathrm { \Omega }$ ) and 41 untimed argument essays $( M =$ 658.29 words, $S D = 9 6 . 5 3 $ ), which is a typical sample size for studies looking at voice in L2 writing (Ahmed & Zhang, 2023). We also collected 41 sets of responses to a questionnaire (outlined below).

Five Chinese MA students majoring in applied linguistics worked as raters to code/assess the writing samples. All of them had been studying applied linguistics for 2 years at same the university as the undergraduate participants, and all had passed the TEM8. The first author of this paper, a professor of English applied linguistics, functioned as a trainer and a mediator.

# 3.2. Data collection

With the assistance of the participants’ instructor, we collected writing samples from two of their main assignments: untimed and timed argument writing. The “untimed” writing (UW) task had a deadline of two weeks and was assigned at the end of study week 4.2 Students were advised to take the full two weeks to write their essay and to revise/proofread as much as possible. Students wrote their essays on MS Word and at times and locations of their own choosing. In study week 7, students were given the timed writing (TW) task during normal class time. Students had $3 0 \mathrm { m i n }$ to compose their essays on MS Word. Both tasks were a part of their normal course activities, and both were awarded scores that went toward their overall grade, increasing the ecological validity of the data (essays were graded independently of the study by the students’ instructor).

Following the completion of the TW task, we administered an in-class questionnaire using a printed form. We made it clear to students that their participation in the questionnaire was voluntary and non-participation would not affect their grades. They did not have to provide any identifying information and they were free to ask questions at any time. However, they were not free to discuss their responses with other students while doing the questionnaire. The questionnaire took approximately $2 0 \mathrm { { m i n } }$ to complete. This duration was necessary because the survey included working definitions for each of the ten categories of voice, ensuring that par ticipants fully understood the terms used in the questions.

The writing samples were labelled as UW1 and TW1 for participant 1, UW2 and TW2 for participant 2, and so on. Similarly, questionnaire responses were labelled QR1, QR2, QR3, etc. All data was transferred to an Excel workbook for analysis.

# 3.3. Instruments

# 3.3.1. Writing tasks

The two writing tasks asked students to produce an argument in response to a prompt. The “untimed with access to external re sources” (UW) task had a deadline of two weeks. Students were encouraged to use various resources, seek feedback, and revise their essays. The “timed without access to external resources” (TW) task was conducted during normal class time, giving students $3 0 \mathrm { m i n }$ to complete their essays without any external help.

To enhance the validity of the comparative corpora, both prompts began with the same question: “Do you agree or disagree with the following statement?”. The two writing statements that followed the question (one for each task) focused on the same theme: how adaptability can increase the chances of success. The first prompt (UW) was taken from the coursebook used by the students: “The traits that got you to where you are won’t necessarily take you to the next level”. (Mei et al., 2015, p. 10) The second prompt (TW) is one that is widely available online through websites such as testbig.com and ielts69.com: “To succeed in school or at work, the ability to adapt or adjust to a changing condition or circumstance is more important than having excellent knowledge of a job or a field of study.”

Moreover, while the two tasks had different word limits $( \mathrm { U } \mathrm { W } = 3 0 0$ words; $\mathrm { T W } = 6 0 0$ words), the UW task allowed students to use external sources and potentially seek outside help, reflecting authentic academic writing practices where such resources are commonly available. This design choice was made to simulate real-life scenarios, where students would engage with external materials and receive feedback, thereby demonstrating their full potential in constructing voice. Conversely, the TW task was conducted in a controlled setting, mirroring high-stakes exam conditions where students must rely solely on their independent skills within a limited timeframe. This controlled environment sought to reflect students’ abilities to construct voice under pressure, giving insights into their internalized knowledge and skills.

# 3.3.2. Scoring rubric for voice

To measure the quantity, quality, and overall “strength” of voice in our sample, we used three scoring rubrics. First, we employed Zhao’s (2013) voice rubric and Hyland’s (2005) descriptions/examples to help the raters identify linguistic realizations of voice markers. Although Zhao’s (2013) final rubric excluded three of the linguistic-level elements from Hyland’s (2008) model (C8-personal aside, C9-reference to shared knowledge, and C10-rhetorical and audience directed questions), we hypothesized that these may occur in untimed writing. Thus, our rubric contained ten categories. Second, drawing on Zhao’s (2013) criterion for qualitative assessment, we included a rubric for three dimensions of voice: D1-presence and clarity of ideas in the content, D2-manner of idea presentation, and D3-writer and reader presence, as shown in Fig. 3. Third, we asked each rater to use these dimensions to give their holistic and impressionistic feeling on the overall strength of voice in each writing sample. Both the dimensional and overall strength measures were scored on a scale of 1–5.

![](img/2d90a1cbde133f0604776a28914617a3fe44ca87681b00b6b87dcabbb90b0fcf.jpg)  
Fig. 3. Dimensions of voice in writing. (adapted from Zhao, 2013, p. 213).

# 3.3.3. Questionnaire

To enrich our interpretations of the students’ understandings and uses of voice, we designed a 16-item questionnaire. At the start of the questionnaire, we presented an example and a definition for each of the ten categories of voice. Questions 1–10 then asked the students to what extent (extraordinary–ordinary–little) they pay attention to each of these categories in general writing tasks (declarative knowledge). Question 11–14 asked students about their perceived level of acquisition for each voice category, which categories they used most frequently in UW and TW, what amount of instruction (if any) they had received on the ten voicing cate gories, and their understandings of voice, respectively. Questions 15 and 16 asked them about when and why they employed elements of voice.

The questionnaire’s design was based on Negretti’s (2012) three-aspect categorization of metacognitive knowledge of cognition and our combined knowledge and experience of voice in English writing. The questionnaire was piloted on a class of third-year English majors from the same university as the study’s participants.

# 3.4. Data coding and analysis

Before the raters began coding/assessing their respective samples, they were trained in how to use the rubrics by the first author and given guidelines on how to identify explicit features of voice. An instant messenger group was also set up so that the raters and the first author could discuss any categorization issues and come to a consensus. When a consensus was not reached, the first author would make the final judgment.

Rater 1 assessed all 82 written texts. Raters 2–5 acted as inter-raters for UW1 to UW21 (Rater 2), UW22 to UW41 (Rater 3), TW1 to TW21 (Rater 4), and TW22 to TW41 (Rater 5). The correlation coefficients between Rater 1 and each of the other 4 raters were all higher than $r = 0 . 8 2 3$ , $p = . 0 1$ , for each of the voice categories. Given this level of correlation, we felt confident using R1’s dataset for the analysis of voice categories. For the scoring of dimensions and overall strength, we took the average between R1’s score and the inter-rater’s scores. However, if the discrepancy between Rater 1 and the inter-rater was more than 2 points (e.g., R1 scored a dimension as 5 but R2 scored it as 2), the first author would reassess that essay and assign a score.

The results from the voice rubrics were put into SPSS 23.0. To test for any significant differences between the overall frequencies of each voice category in UW and TW corpora, and the scores given for each of the three dimensions, we ran paired samples t-tests.

For the Likert-scale questionnaire responses, we obtained descriptive data in the form of frequency counts and percentage ratios. For the open-ended questions, we used inductive content analysis to code for recurrent themes and then counted the number of in stances in each theme. For instance, in response to Question 16, which asked, “To improve the quality of writing … what aspects would you consider differently under timed and untimed writing conditions?” If a student stated, “we have time to find more supporting evidence in untimed writing”, and another student wrote “in untimed writing I can reason with more examples”, we would group both comments under the category of “more supporting evidence”.

# 4. Results

# 4.1. Comparison of voice categories in untimed and timed writing

In total we identified 3254 markers (tokens) of voice in the UW corpora and 1456 in the TW corpora. Using the ten voice categories outlined above, we coded each marker for their functional purpose (e.g., “may” would be coded as C3-hedges). We then calculated the overall means for each category using standardized frequency counts (per 100 words) and ran paired samples t-tests on these means. Table 1 shows the results of these calculations.

Table 1 shows that, in both UW and TW samples, C7-reader reference, C5-attitude markers and C4-boosters were the most frequently employed categories, whereas C8-personal asides, C9-reference to shared knowledge, and C10-rhetorical or audience directed questions were the lowest. This result supports Zhao’s (2013) decision to remove the three latter categories from her revised rubric.

Table 1 also shows that the only significant differences between the two samples occurred for C1-central point articulation and C10- rhetorical or audience directed questions. Specifically, there was a significant increase in the standardized count of C1 features in the TW sample $( p < . 0 5 )$ , but a significant decrease in C10 features $( p < . 0 5 )$ .

Table 1 Comparison of standardized means between untimed and timed writing samples.   

<html><body><table><tr><td rowspan="2">Voice category</td><td colspan="2">UW (n = 41)</td><td colspan="2">TW (n = 41)</td><td rowspan="2">t</td></tr><tr><td>m</td><td>SD</td><td>M</td><td>SD</td></tr><tr><td>C1-central point articulation</td><td>0.84</td><td>0.15</td><td>1.17*</td><td>0.20</td><td>8.68</td></tr><tr><td>C2-directives</td><td>0.29</td><td>0.30</td><td>0.34</td><td>0.24</td><td>1.08</td></tr><tr><td>C3-hedges</td><td>0.79</td><td>0.71</td><td>0.97</td><td>0.95</td><td>1.50</td></tr><tr><td>C4-boosters</td><td>2.10</td><td>0.75</td><td>1.84</td><td>0.84</td><td> 1.79</td></tr><tr><td>C5-attitude markers</td><td>2.18</td><td>0.71</td><td>2.48</td><td>0.75</td><td>1.73</td></tr><tr><td>C6-authorial self-mention</td><td>0.55</td><td>1.02</td><td>0.59</td><td>0.94</td><td>0.19</td></tr><tr><td>C7-reader reference</td><td>3.93</td><td>2.43</td><td>3.20</td><td>2.25</td><td> 1.64</td></tr><tr><td>C8-personal asides</td><td>0.01</td><td>0.04</td><td>0.04</td><td>0.10</td><td>1.78</td></tr><tr><td>C9-reference to shared knowledge.</td><td>0.12</td><td>0.14</td><td>0.11</td><td>0.16</td><td> 0.31</td></tr><tr><td>C10-rhetorical or audience directed questions</td><td>0.17</td><td>0.19</td><td>0.09*</td><td>0.15</td><td> 2.37</td></tr></table></body></html>

$p < . 0 5$ .

Perhaps the most interesting finding was the relatively low occurrence of C3-hedges in both corpora, which is inconsistent with most research on the use of hedges in argument writing (Lee & Deakin, 2016; Yoon & Abdi Tabari, 2023; Zhao, 2019). Considering that the varied use of voice categories tends to correlate more with holistic voice strength than individual frequencies (Yoon, 2017), Table 2 presents the original (or non-standardized) frequencies for the various hedges used in the two corpora.

As shown in Table 2, there were more similarities than differences between the two corpora when it came to the range of hedges used. This suggests that the sampled writers did not see the need to go beyond their existing repertoires, even when given more time and access to external sources in the UW task. Nevertheless, their focus on predominantly modal verbs and adverbs of frequency accords with existing research on novice writers (Hyland, 1996; Kobayashi & Rinnert, 2023).

# 4.2. Comparison of dimensions and strength of voice between UW and TW

As well as calculating the frequencies of individual voice categories, raters also scored the essays on a scale of 1–5 for the three voice dimensions and overall voice strength. Table 3 shows the overall means and standard deviations for these scores for each corpus alongside the results of paired samples t-tests comparing the means.

As shown in Table 3, the mean scores for all three voice dimensions and overall voice strength were significantly lower in the TW than UW corpus, $p < . 0 1$ . Such findings are consistent with our hypothesis that more time would be advantageous to EFL writers when realizing appropriate patterns and strength of voice. In terms of overall voice strength, our score of 3.84 is somewhat comparable to Yoon’s (2017) finding of 3.68, but much higher than that reported by Zhao $( M = 3 . 0 4$ ; 2019) and Zabihi et al. $( M = 1 . 8 2$ ; 2019).

# 4.3. Participants’ perceptions of their voicing practices

Following the completion of the TW task, participants completed a 16-item questionnaire. Questions 1–10 measured the extent (extraordinary/ordinary/little) to which they pay attention to the ten voice categories when writing. Two voice categories stood out as “extraordinarily important” in the minds of our participants, as shown in Fig. 4: C5-attitude markers ( $6 0 . 9 8 \%$ of participants) and C1- central point articulation $( 5 3 . 6 6 \% )$ .

Fig. 4 also shows that these participants pay the least amount of attention to C8, C9 and C10, which once again supports Zhao’s decision to remove these items from her final rubric. The remaining five categories were rated as mostly “ordinarily important”.

Question 11 elicited the participants’ self-reported acquisition level of each voice category. Question 12 obtained their beliefs on how frequently they used each category in UW and TW. Table 4 presents the results from these two questions.

As shown in Table 4, many participants believed that they had good acquisition of C1-central point articulation $( 7 3 . 1 7 \% )$ ) and C5- attitude markers $( 6 3 . 4 1 \% )$ , while just under $5 0 ~ \%$ reported good acquisition of C6-authorial self-mention and C7-reader reference. Somewhat surprisingly, given their relatively high frequency of occurrence in both corpora, just $4 1 . 4 6 \%$ of participants reported good acquisition of C4-boosters. Table 4 also shows that the highest reported frequencies of usage in TW were C5-attitude markers $( 6 0 . 9 8 ~ \% )$ , C7-reader reference $( 4 8 . 7 8 \% )$ , and C4-boosters $( 3 9 . 0 2 \% )$ ; whereas in UW, the highest percentages were C5-attitude markers $( 6 3 . 4 1 \% )$ , C1-central point articulation $( 4 8 . 7 8 \% )$ , and C7-reader reference $( 4 1 . 4 6 \% )$ ). Interestingly, except for C1, the participants’ self-reported use of C4, C5, and C7 seems to correlate with their actual frequency of use shown in Table 1, which suggests that these EFL writers consciously attend to these categories more than the others, regardless of time constraints.

The next two questions asked how much prior instruction participants had received regarding voice (question 13) and how much explicit knowledge they had of voice (question 14). Somewhat surprisingly, given their self-reported usage of voice categories and prior completion of several writing courses, $7 0 . 7 3 \%$ of participants reported receiving no instruction on voice, and $7 0 . 7 3 \%$ admitted they had never heard of the concept of voice (Question 14).

Table 2 Frequency counts of hedges found in timed and untimed writing samplesa .   

<html><body><table><tr><td rowspan="2">Hedges</td><td colspan="2">TW</td><td colspan="2">uW</td></tr><tr><td>Item</td><td>Frequency</td><td>Item</td><td>Frequency</td></tr><tr><td rowspan="4">Modal verbs</td><td>may.</td><td>30</td><td>may (might)</td><td>55</td></tr><tr><td>would</td><td>19</td><td>would</td><td>26</td></tr><tr><td>could</td><td>11</td><td>could</td><td>20</td></tr><tr><td>should</td><td>3</td><td>should</td><td>4</td></tr><tr><td rowspan="4">Lexical verbs</td><td>seem</td><td>6</td><td>seem</td><td>7</td></tr><tr><td>believe</td><td>4</td><td> suppose</td><td>5</td></tr><tr><td>indicate</td><td>2</td><td>believe</td><td>4</td></tr><tr><td></td><td></td><td>tend to</td><td>2</td></tr><tr><td rowspan="4">Determiners Adverbs</td><td>some</td><td>42</td><td>some</td><td>32</td></tr><tr><td>often usually</td><td>4</td><td>often</td><td>11</td></tr><tr><td> probably</td><td>3 2</td><td>maybe sometimes</td><td>9</td></tr><tr><td> maybe</td><td>2</td><td>almost</td><td>5 4</td></tr><tr><td rowspan="2">Adjectives</td><td></td><td></td><td> seemingly</td><td>2</td></tr><tr><td> possible</td><td>2</td><td>likely possible</td><td>9 4</td></tr></table></body></html>

a Items with only one occurrence were excluded.

Table 3 Overall mean scores for voice dimensions and voice strength.   

<html><body><table><tr><td></td><td colspan="2">UW (n = 41)</td><td colspan="2">TW (n = 41)</td><td>+</td></tr><tr><td>Dimensionse</td><td>M</td><td>SD</td><td>M</td><td>SD</td><td></td></tr><tr><td>D1-presence and clarity of ideas</td><td>4.02</td><td>0.77</td><td>2.99***</td><td>0.53</td><td> 8.534</td></tr><tr><td>D2-manner of idea presentation</td><td>4.01</td><td>0.53</td><td>2.72***</td><td>0.57</td><td> 12.014</td></tr><tr><td>D3-writer and reader presence</td><td>3.76</td><td>0.86</td><td>2.78***</td><td>0.68</td><td>- 6.172 \</td></tr><tr><td>Overall voice strength</td><td>3.84</td><td>0.57</td><td>2.87***</td><td>0.60</td><td>- 7.678</td></tr></table></body></html>

$p < . 0 1$ .

![](img/51e3cc36989c45363a3997b86d410bb4153b3c0ed5b7c746bd42fe92e550ed64.jpg)  
Fig. 4. Participants’ attention toward the 10 voice categories.

Table 4 Participants’ reported acquisition and usage of voice.   

<html><body><table><tr><td>Voice category</td><td>Good acquisition (% of participants)</td><td>Frequent use in Uw (% of participants)</td><td>Frequent use in TW (% of participants)</td></tr><tr><td>C1-central point articulation</td><td>73.17 %</td><td>48.78 %</td><td>34.15 %</td></tr><tr><td>C2-directives</td><td>19.51 %</td><td>29.27 %</td><td>14.63 %</td></tr><tr><td>C3-hedges</td><td>31.71 %</td><td>34.15 %</td><td>29.27 %</td></tr><tr><td>C4-boosters</td><td>41.46 %</td><td>36.59 %</td><td>39.02 %</td></tr><tr><td>C5-attitude markers</td><td>63.41 %</td><td>63.41 %</td><td>60.98 %</td></tr><tr><td>C6-authorial self-mention</td><td>46.34 %</td><td>34.15 %</td><td>34.15 %</td></tr><tr><td>C7-reader reference</td><td>46.34 %</td><td>41.46 %</td><td>48.78 %</td></tr><tr><td>C8-personal asides</td><td></td><td></td><td></td></tr><tr><td>C9-reference to shared knowledge</td><td>-</td><td></td><td></td></tr><tr><td>C10-rhetorical or audience directed questions</td><td>12.20 %</td><td>:</td><td></td></tr></table></body></html>

The answers to the previous two question are even more perplexing when we consider their responses to Question 15, which was an open-ended item. Specifically, 27 participants $( 6 5 . 8 5 \% )$ ) reported that the genre of writing (i.e., argumentation) affected their choice of voice categories, yet these choices were not uniform across the participants. For instance, most participants $( n = 2 5$ ) were aware of the necessity of C1-central point articulation and made comments such as “clear central point articulation should be the first priority for argumentative writing” (QR-28), and “no matter what topic an argumentative writing has, the writer should put as much emphasis on central point articulation as possible” (QR-34). However, when it came to the other categories, there was no such consensus. For C6- authorial self-mention, for example, one participant remarked, “argumentative writing should not use self-mention often so as to make the argumentation look more objective” (QR-11). Another stated “self-mention should be used frequently because it is a tool of expressing personal opinions” (QR-35).

As for the questionnaire’s last item, most of the participants reported that in TW tasks they were more likely to consider complexity, accuracy, and fluency (CAF) of language, whereas in UW tasks, they were more likely to focus on supporting evidence and to propose more unique claims.

# 5. Discussion

# 5.1. Quantitative and qualitative aspects of voice

Our first research question explored the difference, if any, between the realization of voice in arguments written under untimed and timed writing conditions. Results showed that time had little to no effect on the standardized frequencies of eight of the individual voice categories (Table 1), which contrasts with the findings of Yoon and Abdi Tabari (2023), who found significant differences in C3-hedges, C4-boosters, C6-authorial self-mention, and C7-reader reference between UW and TW. The only significant differences in quantitative terms were found for C1-central point articulation and C10-rhetorical or audience-directed questions, where C1 was employed more in the TW condition, $p < . 0 5$ , and C10 was employed more in the UW condition, $p < 0 . 5$ . Given the very low frequencies of C10 in both samples and our small participant pool, the emergence of a significant difference here may be the result of random distributional patterns. Nevertheless, the higher use of rhetorical questions in UW aligns with the exploratory and reflective approach students can adopt when not constrained by time (Ho & Li, 2018). Regarding C1, however, we hypothesize that the significant difference $( + 0 . 3 3 )$ between the standardized frequencies in UW and TW samples, $p < . 0 5$ , was an epiphenomenon of the task demands and the way we analyzed the data. Namely, in argument writing, C1 is explicitly realized through the thesis statement, topic sentences, and concluding sentences (Bowen, 2023). In other words, a text with fewer paragraphs (e.g., TW condition) would have fewer topic sentences than a text with more paragraphs (e.g., UW condition). Consequently, our decision to standardize the frequencies for all ten categories, which was premised on voice being realized at the sentence level, may have given us a false negative (Type-II error). Indeed, if we use the absolute frequencies for C1, our result is reversed: We find a significant increase between TW $\mathbf { \mathcal { M } } = 3 . 9 8$ , $S D = . 6 9$ ) and UW $( M = 5 . 4 4$ , $S D = . 6 7 $ ) of $1 . 4 6 , t = 9 . 8 5 , p < . 0 5$ .

This significant effect of time on C1-central point articulation in UW implies that students can articulate more main points and structure arguments more effectively when given additional time and resources. While this finding is perhaps not that surprising, it nevertheless points to a need for increased instruction in this area when students move to timed writing tasks. For instance, it would be beneficial to teach students techniques for quickly organizing their thoughts and developing a clear thesis statement accompanied by relevant topic sentences. Moreover, incorporating timed writing exercises can help students develop the skills needed to articulate their central point effectively even when under pressure. This can include quick outlining techniques and prioritizing key arguments.

Although individual voice categories were, for the most part, relatively stable across the writing conditions, the same could not be said for our holistic (and more subjective) measures of voice. Specifically, all three dimensions of voice and overall strength of voice scored significantly higher in the UW condition (Table 2) than the TW condition, $p < . 0 1$ . Disentangling the differences between these scores involves examining the more objective (quantitative) and subjective (qualitative) aspects of voice used by the assessors/raters. In the case of Zhao’s (2013) rubric, this means looking at the frequencies of the categories contained within a dimension and the assessors’/raters’ subjective/gestalt impression of how appropriately these categories are deployed within a dimension.

Dimension 1 is an ideational one. Quantitatively, it measures how many times a central point is articulated (C1) and how many times directives are used (C2). We have already seen how and why C1 may be quantitatively different in UW and TW conditions, and C2’s frequency of occurrence was low in both conditions. Therefore, how does C1 differ qualitatively? Qualitatively, reader engagement with this dimension comes “through full development of the central idea (point of view) with adequate use of effective examples and details” (Zhao, 2013, p. 226). Indeed, this ties into some participants’ remarks (question 16) that in UW, they focus more on supporting evidence and unique claims than language-related issues. Such a finding accords with most research on EFL/ESL writers, where students at a similar level to ours tend to focus on form over content in time-restricted settings (Barkaoui, 2016; Bowen & Thomas, 2020; Khuder & Harwood, 2015).

Dimension 2 of Zhao’s (2013) rubric is an affective one. It measures the manner of idea presentation in terms of the author’s stance and feelings, which is reflected through choices in C3-hedges, C4-boosters, and C5-attitude markers. This dimension showed the largest increase in overall average score between TW and UW $( + 1 . 2 9 )$ . However, as per D1, quantitatively, there was little difference in the standardized frequencies of each category between samples, which suggests that the increased scores were based primarily on qualitative differences in the deployment of these three categories. Interestingly, this dimension is arguably the most important one in relation to the tasks’ demands, which called for an argument centered on a value claim—a value claim is a qualitative judgment about the worthiness or value of some concept, idea, person, thing, or fundamental belief. In making a value claim argument, hedges, boosters, and attitude markers play a crucial role in establishing a middle ground, where both sides of an argument can be heard. Hedges, for instance, can reduce imposition on the reader by softening the writer’s claim. Boosters, on the other hand, can strengthen the writer’s position, and attitude markers reveal the writer’s feelings about something.

In our corpus, the increased presence of hedges and decreased presence of boosters (per 100 words) seem to reflect the students being overly cautious. However, the increased use of attitude markers pushes back at this and seems to reflect the students being more confident about their own feelings toward the topic. Consequently, the relative distribution of these categories in the TW task may have undermined the credibility of their arguments, as the students were not taking a sufficiently clear stance on the issue they were debating, yet they were displaying strong feelings toward it. We believe these patterns are reflective of the differences in task con straints, as follows.

Regarding C3-hedges, when given more time and access to resources, students may use fewer hedges because they feel more secure in their arguments and the supporting evidence they provide. Indeed, when asked what they do differently in UW, most students replied that they look for more supporting evidence. In TW, on the other hand, students often face significant cognitive pressure to organize their thoughts and express them quickly (Lee et al., 2021). This can lead to a higher use of hedges as a strategy to manage uncertainty and avoid making strong commitments to content that they might not have time to fully develop or justify (Meyer, 1997).

Concerning C4-boosters, in UW, authors might consider their audience more deeply, crafting their arguments to be more engaging and thoughtful, hence they use fewer boosters which can sometimes seem aggressive or overly assertive. In contrast, in TW, authors may prioritize getting the point across quickly, leading to increased use of boosters. Indeed, the students’ answers to our open-ended questionnaire items seemed to reflect this, as they seemed overly concerned with C1-central point articulation in TW.

Regarding C5-attitude markers, in UW, students have the luxury of time to integrate more nuanced expressions of their feelings and evaluations with respect to a reader’s potentially contrastive viewpoint. This reflective process is more difficult to achieve in TW, where the focus is often on the rapid construction of a text. Again, this hypothesis is supported by the students’ open-ended responses, as most students seemed overly focused on CAF in TW.

Dimension 3 of Zhao’s (2013) rubric reflects the extent to which the author intrudes upon the discourse (C6-authorial self-mention) and directly engages with the reader (C7-reader reference). After comparing the TW and UW texts of participants who demonstrated sharp differences in Dimension 3, we found two typical phenomena. A positive aspect involved the use of C6-authorial self-mention which seemed to be more appropriate and contextually relevant in UW tasks. For example, UW-40 introduced an experience of studying philosophy, perceivably to impress the reader with her argument that improving one’s learning method takes one to a higher academic level. A negative aspect was the misuse or overuse of C7-reader reference in TW texts, leading to less effective engagement with the reader, as exemplified in an extract from TW-39’s essay: “You must know your position in the group, which can let you know how to respect others and communicate with others. By doing so, you can also make new friends. Only in healthy relationships can you continuously develop yourselves” (reader reference underlined by us). Clearly, the excessive use of such directives (e.g., “You must …”) can come across as aggressive or patronizing, weakening the overall effectiveness of the writer’s voice.

Overall, the fact that all three voice dimensions and overall voice strength scored significantly higher in untimed writing was somewhat predictable given the additional time and resources available to students. This outcome aligns with previous research, confirming the intuitive understanding that extended time and resources allow for more thorough development of voice. However, beyond this predictability, our study provides deeper insights into how specific aspects of voice construction are influenced by writing conditions. For instance, the significant improvement in central point articulation (C1) and the nuanced changes in the use of hedges, boosters, and attitude markers (D2) reveal the complexities of voice deployment under varying time constraints. These findings have practical implications for teaching strategies, suggesting a need to balance timed and untimed writing tasks and to develop techniques for transferring skills between these contexts. Theoretically, these findings contribute to our understanding of the critical role that time and resources play in voice construction, challenging educators and researchers to consider how different writing conditions impact the deployment of voice and the implications for assessment practices.

# 5.2. Students’ perspectives on the use of voice in argument writing

Our second research question explored the participants’ self-reported knowledge and beliefs about voice in English writing. Our purpose here was to gain further insight into factors that may have affected the students’ choices when deploying voice in both writing conditions.

As shown in Table 4, over $4 0 \%$ of participants reported good acquisition of five voice categories (C1, C4, C5, C6, C7) and frequent use of C5 and C7 in both writing conditions. C4 and C5 were the third and second most frequently realized categories in both writing samples, respectively. These categories, as already discussed, relate to the affective dimension of voice (D2) and were primarily realized through modals that reduced the certainty of the main verb, or determiners that reduced the specificity of the head noun (e.g., “some”). In other words, these are relatively simple boosters and attitude markers that take the form of single words. Similarly, C7- reader reference, which was the most frequently realized category in both writing samples, is a relatively easy aspect of voice to deploy in writing, as it takes the form of you, your, and yours. A similar conclusion can be drawn concerning C6-authorial self-mention, which is generally achieved using first-person pronouns.

C1-central point articulation, on the other hand, as argued earlier, is not an aspect of voice that can be easily realized through a single word choice, but instead occurs at the clausal level through clearly written thesis, topic, and concluding sentences. Thus, we hy pothesize that the participants’ reported awareness of (or familiarity with) this category—the highest level of participants $( 7 3 . 1 7 \% )$ reported “good acquisition” of C1—might be the result of their previous instruction on five-paragraph essay writing, where an EFL instructor would typically place a heavy emphasis on these elements (Bowen, 2023). Interestingly, in their review study, Plakans & Ohta, (2021) argue that many integrated writing rubrics used for formative assessments lack an authorial voice component, which would surely feed into reduced washback (Matsuda & Jeffery, 2012), giving one possible explanation why these students’ teachers did not explicitly focus on voice construction.

Regarding the students’ understandings of voice, although all writers deployed voice to varying degrees of success and stated good acquisition of many individual voice categories, the concept of voice as a gestalt entity seemed to escape them. For example, in response to Question 14, participants either stated unfamiliarity with the concept $( 7 0 . 7 3 \% )$ or confused it with thinking-aloud—a research method used to gather data that they had previously learnt—as one participant stated, “voice is thinking aloud, that is, while a writer writes or types down words in the course of writing, s/he says out what s/he is thinking in the brain” (QR-28). Such responses as to what constitutes voice are perhaps unsurprising given that most participants $( 7 0 . 7 3 \% )$ ) reported receiving no instruction on it (Question 13). Moreover, the assigned textbook used in the participants’ previous argument writing course (Xu et al., 2006) has no detailed introduction to voice in writing. Consequently, even though the participants reported acquiring voice categories to varying extents, there appeared to be no systematic acquisition of these voice categories, and thus their use of them was perhaps mostly unintentional or implicit.

Moreover, their responses to Question 15, which elicited their perspectives on how and where to use voice, also showed varied understandings. For instance, some participants referred to the use of C6-authorial self-mention as something that should be used, “to make the argumentation look more objective” (QR-11), because “the first priority of argumentation is to highlight author’s claims” (QR-38). Other participants thought that authorial self-mention was “a tool of expressing personal opinions” (QR-35) and should be frequently used because “the author needs to express his or her personal arguments and to restate them over and over again” (QR-7). In the study, such disparities were further reflected in the frequencies of those participants $( n = 1 2$ ) who never used first-person pronouns and those who used as many as 5.49 (TW-17) and 5.09 (UW-27) in timed and untimed writing.

To elicit further information about the writer’s conditional knowledge of voice, Question 16 stated the following: “To improve the quality of writing English argumentative essays, what aspects would you consider differently under timed or untimed writing conditions?”. In response to this item, most participants’ comments would fall under D1-presence and clarity of ideas. For instance, one participant stated, “one difference is that in untimed writing I may look for and find resources through various kinds of tools to get enough evidence, like the use of quotes and epigrams” (QR-34). Another participant remarked, “in timed writing I tend to use words and sentences to express my tone and attitude instead of citing examples for argumentation, but in untimed writing more attention is paid to the use of examples” (QR-31). Overall, these two typical responses support our earlier assertion; namely, when given more time, the sampled participants shifted from a focus on form to a focus on content—content that qualitatively affected D1 in terms of improving the quality of examples, evidence, and details that supported their claims.

Overall, the combined findings from our text analysis and survey responses have several important pedagogical implications that are tied to task demands in argument writing. First, most English argument writing textbooks arguably focus on the Toulmin Method, which prioritizes the presentation of evidence (grounds) linked to claims through sound and logical reasoning (warrants). Indeed, the popularity of such an approach seems to be reflected in the students’ understandings of what constitutes a good argument. Namely, the presentation of objective (fact) claims supported by evidence. However, the sampled tasks required them to write value claim arguments, which are inherently more subjective as there is often little available evidence in the form of measurable, objective criter ia—evidence which usually comes from experiences, opinions, societal norms, or cultural beliefs that are tied to a person’s/group’s sense of identity, self-worth, and belonging. Consequently, we hypothesize that the patterning of voice in an argument would vary depending on the type of argument being made.

In other words, voice is not just about individual elements like tone, style, or stance, but about how these elements come together to form a cohesive and authoritative presence in relation to task demands. In our case, this meant creating an authorial voice that sought compromise, empathy, and a mutually beneficial answer/solution to a pressing issue. Yet, when it came to timed writing, the sampled students struggled to achieve such a voice. Therefore, we recommend that instruction should move beyond isolated exercises on tone or stance to activities that help students see how these elements interact to create a coherent voice that reflects task demands, “and to equip them with strategies to write in the most appropriate manner to fit the context and the contextual conditions.” (Khuder & Harwood, 2019, p. 623) For example, teachers can provide explicit instruction on what constitutes a strong authorial voice when it comes to fact, value, and policy claims, and then model these through examples (see Canagarajah, 2015; Hyland, 1996; Yoon, 2021; Yoon & Abdi Tabari, 2023).

# 6. Conclusion

By exploring the quantity, quality, and overall “strength” of ten voice categories and three voice dimensions in timed and untimed argumentative essays written by EFL students, we have made several contributions to the field of teaching/researching writing.

Empirically, our findings are consistent with Zhao’s (2013) work, which highlights the complexities of voice construction in L2 writing. Our results also show that students’ voice dimensions—such as clarity of ideas, manner of presentation, and writer-reader presence—improve with more time and external source use (see also Kobayashi & Rinnert, 2023), which reaffirms the significant role that time plays in the development of a strong authorial voice. Second, we provide support for Zhao’s (2013) decision to include only seven voice categories when assessing EFL writers. Specifically, our results showed that C8 to C10 were very infrequently deployed by the sampled EFL writers, even when given more time to complete a task. Third, while time appeared to have little to no effect upon the standardized frequencies of most voice categories, we did find a significant effect of time on C1-central point articulation. This implies that the sampled students can articulate more main points and structure arguments more effectively when given additional time and resources. While this in itself is perhaps not surprising, we also found that time had a significant effect on the scores for ideational (D1), affective (D2), author-reader presence (D3), and overall strength, each of which was much higher in the UW sample than the TW sample. We argued that these increases came not from an increased presence of voice (quantitative measure), but from how well individual voice categories/elements were used.

The pedagogical implications of these findings and others are numerous. First, although our participants had completed semester long courses on essay writing, it was clear that none had received instruction on what constituted voice or how to appropriately realize it in writing. Thus, it was perhaps not surprising that the concept of voice as a gestalt entity seemed to escape them. Consequently, in addition to explicit instruction on the multifaceted nature of voice and the important role it plays in positioning the author to the topic and the reader, teachers of argument writing in contexts like ours may wish to explore how different types of arguments might require different patterns of authorial voice. Pedagogically, this could mean raising students’ awareness of how voice categories and di mensions can be tailored to suit the type of argument: For instance, in teaching fact claim arguments, teachers may want to draw attention to the importance of objective evidence and precise language to establish credibility (i.e., a focus on C1-central point artic ulation and the use of statistical data, authoritative sources, and objective language). Contrastingly, when teaching value claim ar guments, voice as a gestalt entity may lean more toward the inclusion of a balanced use of hedges, boosters, and attitude markers to convey personal stance and emotional engagement (i.e., increased engagement with the categories that make up D2 might be bene ficial, where students can practice balancing assertiveness with empathy). In teaching policy claim arguments, teachers may want to highlight how voice as a gestalt identity would perhaps congregate around C2-directives and C7-reader reference to motivate a call to action.

More generally, though, our findings point to the need for writing teachers to incorporate both TW and UW exercises in their curriculums, where they can focus on teaching students how to transfer effective planning and revision strategies to TW (Na & Yoon, 2016). Moreover, leveraging technology, such as chatbots that provide instant feedback on argument writing (Guo et al., 2022), can also help students refine their authorial voice in real-time, bridging the gap between untimed and timed writing conditions. Our study also highlights the importance of more rigorous assessments of voice in student writing. Specifically, more attention should be paid to assessing the identifiable components of voice in L2 writing, especially when it comes to setting clear scoring rubrics for specific genres, disciplines, and perhaps even sections of a text. Fundamentally, educators and assessors should consider the conditions under which writing tasks are completed when evaluating students’ work. For instance, most scoring rubrics are based on Anglocentric conceptualizations of voice, thus as Zhao and Wu (2024) argue, there is perhaps a need for “instrument revision and redevelopment to capture voice in bi- or multilingual writing practices and to inform voice and writing instruction in our current multilingual world.” (p. 14) Moreover, understanding that untimed tasks allow for richer voice development can inform more balanced assessment practices that recognize the constraints of timed tasks (Weigle, 2007).

Aside from a relatively small sample size, our study has several limitations. First, the study is cross-sectional, thus it captures data at a single point in time. A longitudinal approach would provide deeper insights into how students’ voice construction and perceptions evolve over time with continued practice and instruction. Second, we did not have access to participants’ writing practices during the tasks. Consequently, we did not explore how different aspects of writing, such as planning, drafting, and revising, could have influ enced the results. Third, in the UW condition, students had access to external resources such as technological tools and model texts. Future studies may wish to measure the extent to which aspects of writing and the use of resources can impact voice construction via tools such as Inputlog (see Bowen, 2019). Fourth, our survey relied on self-reported data, which may be subject to biases such as social desirability or inaccurate self-assessment. Future studies could incorporate other data collection methods, such as interviews or think-aloud protocols, to provide more insights.

# CRediT authorship contribution statement

Jie Liu: Writing – review & editing, Conceptualization. Xiangmin Zeng: Writing – review & editing, Writing – original draft, Supervision, Project administration, Methodology, Funding acquisition, Data curation, Conceptualization. Neil Bowen: Writing – review & editing, Methodology, Conceptualization.

# Consent to participate

This work has gained the participants’ consent.

# Consent for publication

This work has gained the consent for publication.

# Ethics approval

This work has gained appropriate approvals.

# Funding

The work was supported by the 10th Research Projects of China Foreign Language Education Fund under Grant no. ZGWYJYJJ10A127.

# Conflicts of interest/Competing interests

None.

# Acknowledgement

We would like to thank the raters, especially Ms. Xiaoxiao Xue, in the research for their work of assessing the participants’ writing samples.

# Data availability

Data will be made available on request.

# References

Ahmed, A., & Zhang, X. (2023). Students’ voice in L2 English writing: A systematic review of literature. Ampersand, 100114. https://doi.org/10.1016/j. amper.2023.100114   
Aull, L. L., & Lancaster, Z. (2014). Linguistic markers of stance in early and advanced academic writing: A corpus-based comparison. Written Communication, 31(2), 151–183. https://doi.org/10.1177/0741088314527055   
Bowen, N. E. J. A. (2016). Modelling choice in digital writing: Functional revisions and ‘texture’ [Unpublished doctoral dissertation]. Cardiff University.   
Bowen, N. E. J. A. (2019). Unfolding choices in digital writing: A functional perspective on the language of academic revisions. Journal of Writing Research, 10(3), 465–498. https://doi.org/10.17239/jowr-2019.10.03.03   
Bowen, N. E. J. A. (2023). Essential knowledge and skills for essay writing: A practical guide for ESL and EFL undergraduates. Equinox.   
Barkaoui, K. (2016). What and when second-language learners revise when responding to timed writing tasks on the computer: The roles of task type, second language proficiency, and keyboarding skills. The Modern Language Journal, 100(1), 320–340. https://doi.org/10.1111/modl.12316   
Biber, D. (2006). University language: A corpus-based study of spoken and written registers. John Benjamins. https://doi.org/10.1075/scl.23   
Bowen, N. E. J. A., & Thomas, N. (2020). Manipulating texture and cohesion in academic writing: A keystroke logging study. Journal of Second Language Writing, 50 (100773), 1–15. https://doi.org/10.1016/j.jslw.2020.10077   
Cameron, D. (2012). Epilogue. In In. K. Hyland, & C. S. Guinda (Eds.), Stance and voice in written academic genres (pp. 249–256). Palgrave Macmillan. https://doi.org/ 10.1057/9781137030825_16.   
Canagarajah, A. S. (2015). “Blessed in my own way:” Pedagogical affordances for dialogical voice construction in multilingual student writing. Journal of Second Language Writing, 27, 122–139. https://doi.org/10.1016/j.jslw.2014.09.001   
Coulthard, M. (2008). By their words shall ye know them: on linguistic identity. In In. C. Caldas-Coulthard, & R. Iedema (Eds.), Identity trouble: Critical discourse and contested identities (pp. 143–155). Palgrave Macmillan. https://doi.org/10.1057/9780230593329_8.   
Elbow, P. (1994). Introduction. In P. Elbow (Ed.), Landmark essays on voice in writing (pp. xi–xvii). Lawrence Erlbaum.   
Fløttum, K. (2012). Variation of stance and voice across cultures. In K. Hyland, & C. S. Guinda (Eds.), Stance and voice in written academic genres (pp. 218–231). Palgrave Macmillan.   
Gea-Valor, M.-L. (2010). The emergence of the author’s voice in book reviewing: A contrastive study of academic vs. non-academic discourse. In R. Lor´es-Sanz, P. Mur-Duenas, ˜ & E. Lafuente-Millan ´ (Eds.), Constructing interpersonality: Multiple perspectives on written academic genres (pp. 117–136). Cambridge Scholars Publishing.   
Gray, B., & Biber, D. (2012). Current conceptions of stance. In In. K. Hyland, & C. S. Guinda (Eds.), Stance and voice in written academic genres (pp. 15–33). Palgrave Macmillan. https://doi.org/10.1057/9781137030825_2.   
Guo, K., Wang, J., & Chu, S. K. W. (2022). Using chatbots to scaffold EFL students’ argumentative writing. Assessing Writing, 54, Article 100666. https://doi.org/ 10.1016/j.asw.2022.100666   
Helms-Park, R., & Stapleton, P. (2003). Questioning the importance of individualized voice in undergraduate L2 argumentative writing: An empirical study with pedagogical implications. Journal of Second Language Writing, 12(3), 245–265. https://doi.org/10.1016/j.jslw.2003.08.001   
Hirvela, A. (2017). Argumentation & second language writing: Are we missing the boat? Journal of Second Language Writing, 36, 69–74. https://doi.org/10.1016/j. jslw.2017.05.002   
Hirvela, A., & Belcher, D. (Eds.). (2021). Argumentative writing in a second language: Perspectives on research and pedagogy. University of Michigan Press. https://doi.org/ 10.3998/mpub.11548313.   
Ho, V., & Li, C. (2018). The use of metadiscourse and persuasion: An analysis of first year university students’ timed argumentative essays. Journal of English for Academic Purposes, 33, 53–68. https://doi.org/10.1016/j.jeap.2018.02.001   
Hood, S. (2010). Appraising research: Evaluation in academic writing. Palgrave Macmillan. https://doi.org/10.1057/9780230274662   
Hutchings, C. (2014). Referencing and identity, voice and agency: Adult learners’ transformations within literacy practices. Higher Education Research Development, 33 (2), 312–324. https://doi.org/10.1080/07294360.2013.832159   
Hyland, K. (1996). Nurturing hedges in the ESP curriculum. System, 24(4), 477–490. https://doi.org/10.1016/S0346-251X(96)00043-7   
Hyland, K. (2005). Metadiscourse: Exploring interaction in writing. Continuum.   
Hyland, K. (2008). Disciplinary voice: Interactions in research writing. English Text Construction, 1(1), 5–22. https://doi.org/10.1075/etc.1.1.03hyl   
Hyland, K. (2012). Undergraduate understandings: Stance and voice in final year reports. In In. K. Hyland, & C. S. Guinda (Eds.), Stance and voice in written academic genres (pp. 134–150). Palgrave Macmillan. https://doi.org/10.1057/9781137030825_9.   
Hyland, K., & Jiang, F. (2016). Change of attitude? A diachronic study of stance. Written Communication, 33(3), 251–274. https://doi.org/10.1177/ 0741088316650399   
Ivaniˇc, R. (1998). Writing and identity: The discoursal construction of identity in academic writing. John Benjamins. https://doi.org/10.1075/swll.5   
Ivaniˇc, R., & Camps, D. (2001). I am how I sound: Voice as self-representation in L2 writing. Journal of Second Language Writing, 10(1), 3–33. https://doi.org/10.1016/ S1060-3743(01)00034-0   
Jin, Y., & Fan, J. (2011). Test for English majors (TEM) in China. Language Testing, 28(4), 589–596. https://doi.org/10.1177/0265532211414852   
Kawase, T. (2015). Metadiscourse in the introductions of PhD theses and research articles. Journal of English for Academic Purposes, 24, 114–124. https://doi.org/ 10.1016/j.jeap.2015.08.006   
Khuder, B., & Harwood, N. (2015). L2 writing in test and non-test situations: Process and product. Journal of Writing Research, 6(3), 233–278. https://doi.org/ 10.17239/jowr-2015.06.03.2   
Khuder, B., & Harwood, N. (2019). L2 writing task representation in test-like and non-test-like situations. Written Communication, 36(4), 578–632. https://doi.org/ 10.1177/0741088319862779   
Knoch, U., & Elder, C. (2010). Validity and fairness implications of varying time conditions on a diagnostic test of academic English writing proficiency. System, 38(1), 63–74. https://doi.org/10.1016/j.system.2009.12.006   
Kobayashi, H., & Rinnert, C. (2023). Developing multilingual writing: Agency, audience, identity. Springer. https://doi.org/10.1007/978-3-031-12045-9   
Lancaster, Z. (2014). Exploring valued patterns of stance in upper-level student writing in the disciplines. Written Communication, 31(1), 27–57. https://doi.org/ 10.1177/0741088313515170   
Lee, J. J., & Deakin, L. (2016). Interactions in L1 and L2 undergraduate student writing: Interactional metadiscourse in successful and less-successful argumentative essays. Journal of Second Language Writing, 33, 21–34. https://doi.org/10.1016/j.jslw.2016.06.004   
Lee, S., Lim, G. S., & Basse, R. (2021). The effect of additional time on the quality of argumentation in l2 writing assessment: A mixed-methods study. Language Assessment Quarterly, 18(3), 253–272. https://doi.org/10.1080/15434303.2021.1872080   
Liu, J. G. (2012). Aligning TEM-4 with the CEFR (Unpublished master’s thesis). China: Henan Normal University.   
Liu, M., & Braine, G. (2005). Cohesive features in argumentative writing produced by Chinese undergraduates. System, 33(4), 623–636. https://doi.org/10.1016/j. system.2005.02.002   
Matsuda, P. (2001). Voice in Japanese written discourse: Implications for second language writing. Journal of Second Language Writing, 10(2), 35–53. https://doi.org/ 10.1016/S1060-3743(00)00036-9   
Matsuda, P. K., & Jeffery, J. V. (2012). Voice in student essays. In In. K. Hyland, & C. S. Guinda (Eds.), Stance and voice in written academic genres (pp. 151–165). Palgrave Macmillan. https://doi.org/10.1057/9781137030825_10.   
Matsuda, P. K., & Tardy, C. M. (2007). Voice in academic writing: The rhetorical construction of author identity in blind manuscript review. English for Specific Purposes, 26(2), 235–249. https://doi.org/10.1016/j.esp.2006.10.001   
Mei, R., Wang, L., & Liang, H. (2015). Contemporary college English (Intensive reading 6). Foreign Language Teaching and Research Press.   
Meyer, P. G. (1997). Hedging strategies in written academic discourse: Strengthening the argument by weakening the claim. In R. Markkanen, & H. Schroder ¨ (Eds.), Hedging and discourse: Approaches to the analysis of a pragmatic phenomenon in academic texts (pp. 21–41). De Gruyter. https://doi.org/10.1515/ 9783110807332.21.   
Na, S., & Yoon, H. (2016). Effects of in-class and out-of-class writing assignments on L2 writing strategy use and writing quality. The Asia-Pacific Education Researcher, 25, 195–205. https://doi.org/10.1007/s40299-015-0250-5   
Negretti, R. (2012). Metacognition in student academic writing: A longitudinal study of metacognitive awareness and its relation to task perception, self-regulation, and evaluation of performance. Written Communication, 29(2), 142–179. https://doi.org/10.1177/0741088312438529   
Pei, Z., Zheng, C., Zhang, M., & Liu, F. (2017). Critical thinking and argumentative writing: Inspecting the association among EFL learners in China. English Language Teaching, 10(10), 31–42. https://doi.org/10.5539/elt.v10n10p31   
Plakans, L., & Ohta, R. (2021). Source-based argumentative writing assessment. In A. Hirvela, & D. Belcher (Eds.), Argumentative writing in a second language: Perspectives on research and pedagogy (pp. 64–81). The University of Michigan Press.   
Qin, J., & Karabacak, E. (2010). The analysis of Toulmin elements in Chinese EFL university argumentative writing. System, 38(3), 444–456. https://doi.org/10.1016/ j.system.2010.06.012   
Thompson, P. (2012). Achieving a voice of authority in PhD theses. In In. K. Hyland, & C. S. Guinda (Eds.), Stance and voice in written academic genres (pp. 119–133). Palgrave Macmillan. https://doi.org/10.1057/9781137030825_8.   
Uccelli, P., Dobbs, C. L., & Scott, J. (2013). Mastering academic language organization and stance in the persuasive writing of high school students. Written Communication, 30(1), 36–62. https://doi.org/10.1177/0741088312469013   
Weigle, S. C. (2007). Teaching writing teachers about assessment. Journal of Second Language Writing, 16(3), 194–209. https://doi.org/10.1016/j.jslw.2007.07.004   
Weir, C. J. (2005). Language testing and validation: An evidence-based approach. Palgrave Macmillan. https://doi.org/10.1057/9780230514577   
Wu, J., & Erlam, R. (2016). The effect of timing on the quantity and quality of test-takers’ writing. New Zealand Studies in Applied Linguistics, 22(2), 21–34.   
Xu, K., Guo, S., & Cheng, J. (2006). Contemporary college English (Intermediate writing II). Foreign Language Teaching and Research Press.   
Yeh, S. S. (1998). Validation of a scheme for assessing argumentative writing of middle school students. Assessing Writing, 5(1), 123–150. https://doi.org/10.1016/ S1075-2935(99)80009-9   
Yoon, H. (2017). Textual voice elements and voice strength in EFL argumentative writing. Assessing Writing, 32(4), 72–84. https://doi.org/10.1016/j.asw.2017.02.002   
Yoon, H., & Abdi Tabari, M. (2023). Authorial voice in source-based and opinion-based argumentative writing: Patterns of voice across task types and proficiency levels. Journal of English for Academic Purposes, 62, 1–10. https://doi.org/10.1016/j.jeap.2023.101228   
Yoon, H. (2021). Interactions in EFL argumentative writing: Effects of topic, L1 background, and L2 proficiency on interactional metadiscourse. Reading and Writing, 34, 705–725. https://doi.org/10.1007/s11145-020-10085-7   
Zabihi, R., & Bayan, M. (2020). Are two voices better than one? Comparing aspects of text quality and authorial voice in paired and independent L2 writing. Written Communication, 37(4), 512–535. https://doi.org/10.1177/0741088320939542   
Zabihi, R., Mehrani-Rad, M., & Khodi, A. (2019). Assessment of authorial voice strength in L2 argumentative written task performances: Contribution of voice components to text quality. Journal of Writing Research, 11(2), 331–352. https://doi.org/10.17239/jowr-2019.11.02.04   
Zhao, C. G. (2013). Measuring authorial voice strength in L2 argumentative writing: The development and validation of an analytic rubric. Language Testing, 30(2), 201–230. https://doi.org/10.1177/0265532212456965   
Zhao, C. G. (2017). Voice in timed L2 argumentative essay writing. Assessing Writing, 31(1), 73–83. https://doi.org/10.1016/j.asw.2016.08.004   
Zhao, C. G. (2019). Writer background and voice construction in L2 writing. Journal of English for Academic Purposes, 37, 117–126. https://doi.org/10.1016/j. jeap.2018.11.004   
Zhao, C. G., & Llosa, L. (2008). Voice in high-stakes L1 academic writing assessment: Implications for L2 writing instruction. Assessing Writing, 13(3), 153–170. https://doi.org/10.1016/j.asw.2008.10.003   
Zhao, C. G., & Wu, J. (2024). Voice and voicing strategies across native and second language writing: Extending the interactional metadiscourse framework. Applied Linguistics, amae021, 1–16. https://doi.org/10.1093/applin/amae021

Xiangmin Zeng is a Professor of English language and literature at the Department of English, School of Foreign Languages, Southwest Jiaotong University, China. His academic interest includes second language writing research and English for Academic Purposes. He has published several research articles on such issues in Chinese journals.

Jie Liu is a Lecturer in education at the Department of Curriculum, Pedagogy, Assessment, Institute of Education, University College London, UK. She holds a PhD in education. Her academic research includes multilingual education and second language teaching research.