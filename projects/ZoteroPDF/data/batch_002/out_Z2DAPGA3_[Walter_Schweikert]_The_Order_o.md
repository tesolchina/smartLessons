# The Order of Prepositional Phrases in the Structure of the Clause

# The Order of Prepositional Phrases in the Structure of the Clause

# Linguistik Aktuell/Linguistics Today

Linguistik Aktuell/Linguistics Today (LA) provides a platform for original monograph studies into synchronic and diachronic linguistics. Studies in LA confront empirical and theoretical problems as these are currently discussed in syntax, semantics, morphology, phonology, and systematic pragmatics with the aim to establish robust empirical generalizations within a universalistic perspective.

# Series Editors

Werner Abraham University of Vienna

Elly van Gelderen Arizona State University

# Advisory Editorial Board

Cedric Boeckx   
Harvard University   
Guglielmo Cinque   
University of Venice   
Günther Grewendorf   
J.W. Goethe-University, Frankfurt   
Liliane Haegeman   
University of Lille, France   
Hubert Haider   
University of Salzburg   
Christer Platzack   
University of Lund   
Ian Roberts   
Cambridge University   
Ken Safir   
Rutgers University, New Brunswick NJ   
Lisa deMena Travis   
McGill University   
Sten Vikner   
University of Aarhus   
C. Jan-Wouter Zwart   
University of Groningen

# Volume 83

The Order of Prepositional Phrases in the Structure of the Clause by Walter Schweikert

# The Order of Prepositional Phrases in the Structure of the Clause

Walter Schweikert University Ca ’Foscari, Venice

The paper used in this publication meets the minimum requirements TM of American National Standard for Information Sciences – Permanence of Paper for Printed Library Materials, ansi z39.48-1984.

# Library of Congress Cataloging-in-Publication Data

Walter Schweikert The Order of Prepositional Phrases in the Structure of the Clause / Walter Schweikert. p. cm. (Linguistik Aktuell/Linguistics Today, issn 0166–0829 ; v. 83) Includes bibliographical references and indexes. 1. Grammar, Comparative and general--Prepositional phrases. 2. Grammar, Comparative and general--Syntax. 3. Grammar, Comparative and general--Word order. 4. Grammar, Comparative and general--Clauses. I. Title. II. Linguistik aktuell ; Bd. 83.

P285.S338 2005   
415--dc22   
isbn 90 272 2807 8 (Hb; alk. paper)

2005048266

$^ { © }$ 2005 – John Benjamins B.V.   
No part of this book may be reproduced in any form, by print, photoprint, microfilm, or any other means, without written permission from the publisher.

John Benjamins Publishing Co. $\ast$ P.O. Box $3 6 2 2 4 \cdot 1 0 2 0 ~ \mathrm { M F }$ e Amsterdam $\cdot$ The Netherlands John Benjamins North America $\cdot$ P.O. Box 27519 $\ast$ Philadelphia pa 19118-0519 $\cdot$ usa

# TABLE OF CONTENTS

# Acknowledgements ix

# List of Abbreviations xi

CHAPTER 1   
Introduction 1

CHAPTER 2   
Arguments and modifiers 5 2.1 Sentence constituents 6 2.2 Representation in X-Bar structure 16 2.3 The Split Infl hypothesis 19 2.4 The level of logical form and covert movement 23 2.5 The minimalist program 25 2.6 Antisymmetry 27 2.7 Argument structure and VP shell 32 2.7 Semantic interpretation of X-bar structure 35 2.8 Parallels between morphology and syntax 38 2.10 The Cinque hierarchy 39 2.11 Recent minimalist developments 44   
3.1 Introduction 47   
3.2 General remarks on German sentence structure 53   
3.3 Potential tests for finding the base generation of phrases 54 3.3.1 Infinitival complex 54 3.3.2 VP-topicalisation 56 3.3.3 Binding theory 58 3.3.4 Quantifier pronoun binding 62 3.3.5 Semantic interpretation 63 3.3.6 Weak cross over 64 3.3.7 Wh - pronouns used as indefinites 64 3.3.8 Licensing of negative polarity items 66 3.3.9 Quantifier scope (QS) 66 3.3.10 Focus neutral order 73 3.3.11 Informational focus (IF) 77 3.3.12 Role disambiguation 80 3.3.13 Pair – List reading (PLR) 82 3.3.14 Reference to events 83

3.4 Word order in the German Mittelfeld 86

3.4.1 The description in Heidolph et al. (1981: 707 ff.) 86 3.4.2 The data according to R. Hinterhölzl 88 3.4.3 Frey und Pittner‘s Mittelfeld order 89 3.4.4 Recent works by W. Frey 93 3.5 My data 95 3.5.1 General methodology 95 3.5.2 The main thematic roles 96 3.5.3 One example of the data 101 3.5.4 Results 104 3.5.5 Relative distances 108 3.5.6 The larger sample 115 3.5.7 Argumental PPs 123 3.5.8 English 129 3.5.9 Reference to events 131 3.5.10 Conclusion 132

CHAPTER 4   
Restrictions on structure and movement 133 4.1 Introduction 133 4.2 Trees and subtrees 135 4.3 Basic projections 137 4.4 Basic relations 140 4.5 Extended projections 143 4.6 Sequences of modifiers of the same category 155 4.7 Derivations 156 4.8 Movement 158 4.9 The parameters 168   
CHAPTER 5   
Affixes in syntax 171 5.1 Introduction 171 5.2 Prefixes and suffixes 173 5.3 Derivation of the inverted order of suffixes 177 5.4 Derivation of the direct order of prefixes 180 5.5 Separable prefixes 190 5.6 Derivation of the inverted order of prefixes 200 5.7 Fused morphemes 220 5. 8 Arguments 225 5.9 Open questions 236 5.10 Conclusion 237   
CHAPTER 6   
Syntactic analysis of the surface word order of PPs 239 6.1 The basic patterns 239 6.1.1 The direct order 239 6.1.2 The inverted order 240 6.1.3 Mixed order 241 6.1.4 Patterns of other constituents 243 6.1.5 Conclusion 247 6.2 A symmetric analysis 247 6.3 Directionally licensing and the proposal of Haider 252 6.4 Collective versus indivual checking in the work of Koster 253 6.5 The pied piping analysis of Cinque 255 6.6 The verb second problem 270   
6.7 Overt verb movement driven only by morphology 271 6.8 Cyclic approaches 273 6.8.1 A Derivations that result in direct order 274 6.8.2 B Derivations that result in inverted order 276 6.8.3 Derivation of the inverted structure 278 6.8.4 Derivation of the direct order 284 6.8.5 Modifications in order to include morphology 298 6.8.6 Modifications in order to include arguments 299 6.8.7 Recursive extended projections and event Structure 30

CHAPTER 7   
Conclusion 323

# References 325

# Name index 329

Language index 331

Subject index 333

# ACKNOWLEDGEMENTS

This work could never have been completed without the help of many people, whom I would like to thank here.   
First of all I am grateful to my supervisor Guglielmo Cinque, whose advice guided me through this work. In many discussions he helped me to clarify my ideas and opened new doors to aspects I had not seen before. Whenever I got lost in the vast area of syntax he helped me find the way back to the path. I will always be indebted to him for his encouragement and support in all stages of this thesis.   
I sincerely thank Paola Benincà for her support in my work as well her suggestions and encouragement.   
I also want to thank Hubert Haider for giving me the opportunity to spend three months in Salzburg and for the many profound discussions we had about the nature of syntax. His support in establishing valid syntactic test for the order of PPs in German cannot be overestimated.   
It was also in Salzburg where I met Werner Abraham who showed how much passion can be found in linguistics and who later on contributed in bringing this book into the actual shape.   
I am thankful to Laura Brugè, Anna Cardinaletti, Alessandre Giorgi, Giuliana Giusti, Nicola Munaro and Cecilia Poletto for the opportunity to discuss my ideas with them and the thousand and one proposals they contributed to this work.   
I am very grateful to Enoch Aboh, Sjef Barbiers, Josef Bayer, Hans Den Besten, James Higginbotham, Richard Kayne, Jan Koster and Jan-Wouter Zwart for enlightening discussion.   
Peter Cole and Gillian Ramchand not only helped me with supportive comments, they also provided me with useful English data.   
Linguistic and moral support came from all the graduate students in Venice and Padua, of whom I especially want to mention: Paolo Chinellato, Francesco Costantini, Federico Damonte, Federico Ghegin, Soon Haeng Kang, Debora Musola, Laura Sgariotto and Luigi Zennaro as well as Elisa Franchi, María Martínez-Atienza and Sara Vecchiato.   
Special thanks go to Walter Bisang and Thomas Müller-Bardey, who opened my eyes to the beauty of linguistics.

Last, but not least, I want to thank Lisa Martinengo, who also provided me with English data, and helped in correcting many errors of this work. With out her editing and moral support, this work would not be the same.

# ABBREVIATIONS

ACC accusative case   
AffP affix phrase   
AGR general agreement affix   
AgrP agreement phrase   
ArgOP (direct) object-agreement phrase   
ASP aspect marker   
CAUS causative   
CP complementizer phrase   
DAT dative case   
DET determiner   
DP determiner phrase   
DPO directional prepositional object   
DUR durative   
ECP empty category principle   
EPP extended projection principle   
F feminine   
FUT future tense   
GB Government and Binding   
HMC head movement constraint   
IF informational focus   
IMP imperfective aspect   
IP inflection phrase   
KP case phrase   
LCA linear correspondence axiom   
LF logical form   
LPO locative prepositional objects   
M masculine   
MLI modified lexical items   
MPL main projection line   
NegP negation phrase   
NOM nominative case   
NPST non-past tense   
$\mathrm { O B J _ { d i r } }$ direct Object   
$\mathrm { O B J _ { i n d } }$ indirect Object   
PART participle marker   
PASS passive   
PF phonological form   
PL plural agreement   
PLR pair list reading   
PP prepositional phrase   
PrefP prefix phrase   
PROG progressive marker   
PRS present tense   
PSI principle of semantic interpretation   
PST past tense   
QS quantifier scope   
RECIP reciprocal   
REFL reflexive   
RPO reason prepositional object   
SG singular agreement   
TP tense phrase   
VP verbal phrase

# CHAPTER 1

# INTRODUCTION

Ich schreibe diesen Satz im Jahre 2004 in Italien in Venedig. (German) I am writing this sentence in Italy in Venice in the year 2004. (English) Sto scrivendo questa frase in Italia a Venezia nel 2004. (Italian)

All three sentences above have the same meaning, though we find remarkable differences with respect to the order of the involved prepositional expressions. They all contain two locative PPs and one temporal. One of the locative expressions, ‘in Venice’, specifiers the location described by the other, ‘in Italy’. Their order with respect to each other is preserved in all three languages. Both appear to the right of the temporal PP in German, but to the left of it in English and Italian.

All three sentences can be uttered out of the blue, which indicates that they have neutral informational structure. Changing the order between temporal and locative expressions results in a marked structure with non-neutral focus structure and associated intonation Changing the order between the two locative phrases results in a different interpretation. Starting from the traditional point of view that all three prepositional modifiers are adjuncts these observations seem to be in odds. Adjunction is a free operation and should not give preference to a certain order. This leads us to the following questions:

Why do we have an order preference for prepositional modifiers in each   
language?   
Is this order attributed to semantic reasons?   
Why do we find reverse order between temporal and locative expressions   
in English and Italian with respect to the order in German?   
Why do we have the same order for the two locative expressions in all three   
languages?   
Why does English form a group with Italian and not with German?

English, though genetically more related to German, has an important parameter in common with Italian: Both are VO languages, German is an OV languages. This leads to the final question:

Can the differences between PP ordering be related to the OV – VO order?

I try to give an answer to these questions with this work. Most of my work is concerned with modifying PPs as opposed to selected elements.

I start with a short overview presenting important historical contributions to the syntactic theory of modifiers. Chapter 2 presents the traditional view of modifiers as syntactic adjuncts to VP and IP in GB and minimalist frameworks. It furthermore presents the innovations to syntactic theory that result from Kayne's antisymmetric restrictions on syntactic structure. This framework excludes the possibility of having several adjuncts to one and the same maximal projection. As a consequence of this restriction and based on data from many languages Cinque presented in 2000 a theory which stipulates a cascade of functional projections above the VP. Adverbs, auxiliaries and affixes are grouped into distinct classes each of which is related to one of these functional projections. It is this theory, I take as starting point for my analysis of prepositional phrases.

In Chapter 3 I list several syntactic tests that can help to establish the base order between constituents. Three of them I used extensively with all possible combinations of 14 different PP types in German. The complete data can be found in the appendix. The evaluations of the tests give in all three cases a consistent, transitive hierarchy of thematical roles, which is nearly identical for all tests. Additional PP types and a fourth test are introduced and evaluated in a less extensive way. The resulting hierarchy correspond in relevant parts to Cinque's hierarchy of functional projections. The other elements have no correspondent adverb or affix in this hierarchy.

In Chapter 4, I propose a variant of an antisymmetric syntax whose basic elements are not simple words, which can be inserted into heads, but complete maximal projections. This proposal excludes head movement, leading to very general and abstract considerations about possible restrictions on movement. The rest of the Chapter speculates about the nature of parameters, based on recent works of Kayne.

Excluding head movement requires new ideas about verb movement up the syntactic tree. Chapter 5 proposes a theory of VP movement in order to attach the verb to its inflectional affixes. It is an attempt to integrate major parts of morphology into syntax. Central for the discussion is the Axiom of Word Boundary, which states that there is no word boundary between overt elements in the specifier and the head of the same maximal projection. Certain examples with agglutinating and fused morphemes are discussed in detail.

Chapter6, finally, tries to derive the different surface orders in OV and VO languages. Several analyses are presented and compared. A derivation with cyclic movements of the VP around each PP, followed by movement of prepositional material is suggested, which is compatible with the morphological analysis presented in Chapter 5. The notion of extended projection is generalised to modifiers which attributes to each modifier a rich syntactic structure with a low argumental part, a higher modifying layer and high projections related to pragmatic functions such as focus and topic.

The work presented here can only open the door into a large field of future research which has to answe many other questions concerning the inner structure of modifiers and their relation with argumental elements such as subject and object. If the integrations of other elements like adverbs and modals succeed we can arrive at a general theory of the syntax of modifiers.

# CHAPTER 2

# ARGUMENTS AND MODIFIERS

Early syntactic views on sentence structure concentrated on the main predicate (the verb) and its (obligatory) arguments. Constituency and recursion were early observations of structuralist analysis. The distinction between internal (objects) and external arguments (subjects) was another milestone in syntactic theory. Attempts were made to generalize the observed structure of the sentence also to the internal composition of each constituent (mainly the arguments). The next step was to represent the structure of a sentence and its constituents in a uniform way with the mathematical tool of tree structure that resulted in the well-known X-Bar theory. Predicates were viewed as heads of the constituent, internal arguments as complements. The status of the external argument was a bit more problematic, since it seemed to be seated outside the constituent projected by the predicate.

Subsequent work focussed on more peripheral material of the sentence. Functional elements like determiners and complementizers were sometimes indispensable and were analysed as sitting in a specifier position just like certain auxiliaries. Modifiers like adverbs or prepositional phrases seemed to be totally optional and they were added to syntactic theory in the form of adjuncts.

In this chapter, I want to give a short overview of this era, before presenting more recent approaches that challenged the old model. In the 90s there appeared two major new theories, which tried to solve the problems that came up with a more detailed look at sentence structure. Chomsky's minimalist program presented a dynamic model of construction of sentences where complete words in the form of sets of features are inserted into the structure. Some of these features are uninterpretable, which gives motivation for movement. Kayne on the other side started with the observation of certain typological asymmetries. In order to give an explanation for this data he developed a theory, which set linear order of words in relation to syntactic hierarchy. The result is a restriction to X-Bar structure. Cinque presented a new view on modifier syntax, which is based on Kayne's antisymmetric approach.

# 2.1 Sentence constituents

Syntax as the science of the composition of sentences seeks to describe and explain the order of the constituents in a sentence and their relationships to each other. In order to achieve this goal linguists search for a theory that is powerful enough to account for any permissible sentence in any language, but at the same time restrictive enough to exclude all ungrammatical sentences – or at the level of languages – to exclude properties of languages that are not found among the described human languages.

Like any other scientific project (e.g. physics) it was natural to start with the examination of the properties of the most simple objects, in our case with the shortest sentences, which contain only indispensable elements, which means sentences that contain the main predicate and its arguments. The number of these arguments seems to differ depending on the verb, from zero to three:

(2-1) It rains. (0) (2-2) John sleeps. (1) (2-3) John kisses Mary. (2) (2-4) John gave Mary a book. (3)

But these simple examples show, that nouns and verbs cannot be in all cases the only obligatory elements. In sentence (2-1), an expletive has to be added to fulfil the requirements of an overt subject in English, and in sentence (2-4), the determiner ‘a’ was added to the common noun ‘book’. Leaving these elements out would result in ungrammatical structures:

(2-5) \* rains.   
(2-6) \* John gave Mary book.

Looking at more complex sentences, a large number of new elements appeared in the inventory of linguistic descriptive tools, which could not be omitted from certain sentences without rendering the sentence ungrammatical; for instance, complementizers, auxiliaries, infinitive markers, supporting ‘do’ in questions etc. Closer inspection revealed that the inner composition of the words can have inflectional elements such as agreement and tense suffixes which are obligatory in all sentences:

(Italian)

(2-7) Gianni ha det-to \*(che) tu hai telefona-to. Gianni has say-PART (that) you have.2SG call-PART “Gianni said that you called.”

(2-8) John \*(has) gone home. (2-9) John wants \*(to) sleep. (2-10) \*(Did) John go to work? (2-11) John sleep\*(s).

But clearly these elements could not be viewed in any respects as arguments of the verb. They seemed to serve more a functional purpose and soon the distinction between lexical elements such as verbs, nouns, adjectives, adverbs, prepositions on the one side and functional elements like determiners, complementizers, auxiliaries, etc. was introduced.

For a long time certain classes of elements, such as adverbs, adjectives and circumstantial prepositional phrases, didn't attract much attention in the linguist world. They seemed to share a number of properties:

1. They were optional. In a sentence like:

John kissed a (beautiful) girl (passionately) (in the garden).

everything seems dispensable except for the subject, the verb and the object. Even adjectives can be omitted without rendering the sentence ungrammatical or changing the semantics radically:

(2-13) John kissed a beautiful girl.   
(2-14) \* John kissed.   
(2-15) \* John kissed girl.   
(2-16) \* kissed a girl.   
(2-17) John kissed a girl.

2. They seemed to be unordered. Both of the following sentences were considered equivalent and having the same interpretation:

(2-18) John worked for Mr. Miller in New York.   
(2-19) John worked in New York for Mr. Miller.

The adding of these elements to a nuclear clause seemed to be unlimited.

# 3. They didn't seem to give an essential contribution to the meaning of the nuclear event:

The following sentences describe the same event. The difference is only the positioning on spatial or temporal scales:

(2-20) John kissed Mary on Friday.   
(2-21) John kissed Mary on Tuesday.   
(2-22) John kissed Mary in the garden.

These elements seemed to modify somehow the event described by the main predicate and its arguments, but not to change it radically.

The distinction between arguments and modifier was essential for dependency grammar. Tesnière defined the valency of the verb as the number of obligatory elements it selected. But soon it became clear, that it was not always straightforward to define the valency of a verb. Certain verbs like ‘eat’ which seem to select clearly two arguments, a subject and an object, could be used in certain environments with deletion of the object:

(2-23) Johns eats an apple.   
(2-24) ?? John eats.   
(2-25) What is John doing? He is eating.

Another problem with Tesnière's theory was his restriction to the elements counting as arguments. He accepts three types: subjects, accusative objects, indirect objects in dative or genitive case. Prepositional expressions were excluded. Certainly this was problematic. Take the following pair of sentences:

(2-26) John eats an apple.   
(2-27) John sits on a chair.

Apart from the preposition there seems not to be much reason to distinguish between the argumental status of ‘an apple’ and ‘on a chair’. Their omission renders both sentences ungrammatical:

$$
\begin{array} { r c l } { { ( 2 { - } 2 8 ) } } & { { \ast } } & { { \mathrm { J o h n \ e a t s . } } } \\ { { ( 2 { - } 2 9 ) } } & { { \ast } } & { { \mathrm { J o h n \ s i t s . } } } \end{array}
$$

Their contribution to the semantics of the sentence is comparable: Both select out of a number of possible objects a certain type. Dative shift provides another example of semantic equivalence of an indirect dative object and its prepositional counterpart:

(2-30) John gives Mary a book.   
(2-31) John gives a book to Mary.

Another problem arose with certain kinds of accusative objects. A verb like ‘run’ which clearly is intransitive can get an accusative object in sentences like:

(2-32) John ran a mile.

A possible escape hatch could be the assumption that there were two different entries for ‘run’ in the lexicon, one being intransitive and the other transitive. The problem with this solution is the productivity of the construction. ‘A mile’ can be added to any motion verb, even if it freshly enters the language

-33) John skated a mile.

Another problem came up with passive constructions. The agentive part, which was the indispensable subject of the active counterpart, became optional.

It became necessary to invent tests to distinguish between arguments and modifiers. Jacobs (1994) presents 7 tests such as obligatoriness, argument status, semantic contribution which all seem to have fuzzy borders. He presents several examples to show that all the tests were independent of each other. I will not go into detail since the definitions themselves are fuzzy (e.g. “Beteiligtheit . $. . . B E T ( X , Y )$ in S gdw. x in S eine Entität bezeichnet, die an dem Vorgang oder Zustand, der von Y ausgehend in S dargestellt wird, beteiligt ist. ”).

More of interest are some tests described in Helbig (1992).

Obligatoriness: Helbig is less restrictive and allows for sentences like

(German)

Peter isst (einen Apfel). “Peter eats (an apple).”

Peter steigt (in die Straßenbahn) ein. Peter enters (into the tram) in “Peter enters the tram.”

as opposed to (2-36) \* Peter besucht. Peter visits

Modalisation: if the modal ‘können’ (can) can be used with the verb but without the constituent in question it is a modifier:

(2-37) Kann er essen? Can he eat “Is he able to eat”

(2-38) \* Kann er besuchen? Can he visit?

‘Und zwar’ –modification: If a part of the sentence can be paraphrased by a ‘und zwar’ (namely)-construction, it is a modifier:

(2-39) Peter isst, und zwar einen Apfel. Peter eats and precisely an apple “Peter eats, namely an apple.”

Another test is found in the literature that at first sight seems to be equivalent; the ‘did so’-test:

(German)

(2-40) Peter aß einen Apfel im Restaurant. “Peter ate an apple in the restaurant.”   
(2-41) Peter aß einen Apfel. Er tat es im Restaurant. “Peter ate an apple. He did so in the restaurant.”

But sometimes we get a clash with the ‘und zwar’-modification:

(2-42) Peter stieg ein, und zwar in die Straßenbahn. “Peter enters, namely the tram.”   
(2-43) \* Peter steigt ein, und er tat dies in die Straßenbahn. Peter enters and he did so in(to) the tram

(German)

These few examples show that the line between arguments and modifiers is not easily drawn.

On the other side the verb (or better: the nuclear event) imposes restrictions on the types of modifiers it permits.

Well known from perfectivity tests is the restriction on ‘for-‘ and ‘in-’ expressions indicating duration: Only imperfective states of affairs permit the modification with a durative modifier:

(2-44) John was running for an hour.   
(2-45) \* The bomb exploded for an hour.

On the other side only perfective events allow modification by ‘in-‘ PPs:

(2-46) John painted the picture in an hour.   
(2-47) \* John is running in an hour. (in the sense of having finished running an hour later)

Matter-modifications are very restricted. You can talk about a subject or read about it, but you cannot swim about it:

(2-48) John talked about politics.   
(2-49) \* John swam about politics.   
(2-50) \* Bill gave Mary ten dollars about politics.

Benefactives seem to be less restrictive but not totally free either:

(2-51) John gave Mary ten dollars for Bill.   
(2-52) John was running for his school.   
(2-53) \* John was sleeping for his girl friend.

Temporals and Locatives have an even higher degree of freedom:

(2-54) John was sleeping in the park on Sunday.   
(2-55) The bomb exploded in the park on Sunday.   
(2-56) John swam in the river on Friday.

However, Chierchia (1995) and Kratzer (1995) have shown, that they don't go together with individual level predicates:

(2-57) \* Maria was blond in the car.   
(2-58) \* John was tall on Sunday.

(But see Maienborn 2003 for a pragmatic explanation of this effect).

In Fillmore (1968) we find an interesting approach to the distinction between obligatory and optional participants. According to him every sentence represents an event, which prototypically involves several participants. The verb, as main predicate, selects a certain perspective of the event that renders one or two (or three) participants obligatory and the rest optional.

He gives the example of a commercial event, which involves a buyer, a seller, the goods and the exchange value (the money). A number of verbs describe the same event from different perspectives. In the particular event, Harry is the seller, the goods are roses, the price is five dollar and the buyer is the speaker.

If we choose the verb ‘sell’ we view the process from the perspective of the seller, which becomes the subject and the roses are the object:

(2-59) Harry sold a dozen roses. (2-60) Harry sold a dozen roses to me for five dollars. The verb ‘buy’ takes the view of the buyer, the roses remain the object:

(2-61) I bought a dozen roses.

If we were to keep the buyer the subject but choose the money as object we have to take the verb ‘pay’:

(2-63) I paid five dollars.   
(2-64) I paid five dollars to Harry for a dozen roses.

But note, that here again we can add temporal and locative modifiers freely, which according to Fillmore are not prototypical participants of this event.

A more recent contribution to the discussion we find in Dowty (2003). For him the distinction between arguments and modifiers (in his terminology ‘complements’ and ‘adjuncts’) is clear-cut in semantic structure, but not always easy to determine. He starts his analysis with the following definitions:

An adjunct is ‘optional’, while a complement is ‘obligatory’:   
A constituent Y in a phrase [XY] (or [YX]) is an ADJUNCT if and only if (i) phrase X by itself (without Y) is also a well-formed constituent, and (ii) X (without Y) is of the SAME category as phrase[XY]. (X is in this case the HEAD of the phrase [XY].)   
Then a constituent Y in [XY] is a COMPLEMENT if and only if (i) X by itself (without Y) is not wellformed, or else (ii) if it is grammatical, then X standing alone (does) not have the same category as in [XY] (and does not have exactly the same meaning as it has in [XY])q.

An adjunct 'modifies' the meaning of its head, while a complement 'completes' its head's meaning.

If Y is an adjunct, the meaning of [XY] has the same kind opf meaning (same logical type) as that of $X _ { i }$ , and Y merely restricts [XY] to a proper subset of the meaning/denotation of X alone.

WhereY is a complement in [XY], (i) the meaning of $X$ by itself, without Y, is incomplete or incoherent. Else, (ii) X must be understood elliptical – the hearer must imagine/infer some context-dependent or anaphoric meaning of the general kind of Y to “fill in” the semantic slot that X requires semantically. …

Also, the same adjunct combined with different heads affects their meaning in the “same” way semantically (e.g. walk slowly vs. write slowly). But the same complement can have more radically different effects with different heads (e.g. manage to leave vs. refuse to leave).

(Dowty 2003: 1 f.)

Dowty represents complements (arguments) and adjuncts (modifiers) in categorial grammar with different structures from which it automatically follows, a) that complements are closer to the verb, b) that they are obligatory, c) that adjuncts are optional and d) that adjunction is in principle unlimited.

After having clarified these notions he concentrates on expressions such as adjectives, adverbs and PPs, which commonly are used as clear modifiers, but in certain constructions, bear clearly properties of arguments. He uses the term Subcategorized Adjunct and proposes that they should be analysed as complements.

As an example he discusses sentences with dative prepositional expression such as:

(2-65) Mary explained the memo to John.   
(2-66) Mary rented the apartment to John.   
(2-67) John offered a glass of tomato juice to Mary.

In all three cases, the ‘to-PP’ cannot be omitted without rendering the sentence ungrammatical. The semantic contribution of this PP-argument is furthermore highly dependent on the selecting verb. In sentence (2-65) it is information, which is given to John, in (2-66) ownership of the apartment and in (2-67) only the mere option of having the glass of tomato juice.

Dowty contrasts this behaviour with directional PPs, introduced by the same preposition:

(2-68) Mary kicked the ball to the fence.   
(2-69) John pushed the desk to the wall.   
(2-70) Sue slid the paperweight to the edge of the table.

In all three cases, the contribution of the PPs has the same semantic effect: adding the goal of the action to the description of the scenery.

Dowty refers to several predecessors, among them especially Anderson (1971), who claim that all actual instances of prepositional expressions are abstracted from original locative uses. Whereas many of the prepositions retain their original locative meaning others are reduced to grammatical markers.

Dowty proposes that all language-learners who encounter an expression headed by a locative preposition (such as ‘to’ and ‘from’) analyse it in a first step as a locative modifier. Only at a later step they will reanalyse the same expression as an argumental complement. This is what he calls the Dual Analysis.

So far, it seems, that certain types of adjuncts behave in a syntactically different way, depending on the semantic predicate.

If we restrict ourselves for the moment to prepositional expressions, we can distinguish five types with respect to their boundedness by the verb:

1. It is the totally obligatory, indispensable argument of the verb. Under no circumstances can the Object PP be omitted.

(2-71) Der Besen lehnt an der Wand. “The broom leans against the wall.”   
(2-72) \* Der Besen lehnt. “The broom leans.”   
(2-73) \* Der Besen liegt nicht, er lehnt. “The broom does not lay, it leans.”

2. The PP seems to have argument status and omitting it is odd in most cases though in contrastive environments it becomes possible.

(German)   
(2-74) Das Bild hängt an der Wand. “The picture hangs at the wall.”   
(2-75) ?? Das Bild hängt. “The picture hangs.”   
(2-76) Das Bild liegt nicht, es hängt. “The picture doesn't lie, it hangs.”

3. The PP is a prototypical participant in the sense of Fillmore, but the specific verb chooses a perspective that excludes them from the set of obligatory arguments.

(2-77) Harry sells three roses for five dollars.   
(2-78) Harry sells three roses.

4. The PP is not obligatory and does not belong to the set of prototypical participants, but can be added to the sentences.

(2-79) Harry sold the roses on Sunday.   
(2-80) Harry sold the roses.

5. The PP is incompatible with the main predication (note that it is not always the verb that determines compatibility, but very often a bigger constituent).

(2-81) \* Harry sleeps for Mr. Miller.   
(2-82) \* Harry is eating in five minutes.   
(2-83) Harry eats an apple in five minutes.

But does this imply a continuum of binding force between a verb and certain thematic roles? In German, at least, there is a straight-forward syntactic test which is able to distinguish between two types of participants, which we would like to identify with arguments and modifiers: Only the latter can be found in the ‘Nachfeld’(the position after the finite verb in subordinate clauses).

The German sentence is normally described as having a verb bracket, which consists of two positions for the verb, one in second position (the normal position of the inflected verb in main clauses) and at the end (the usual position of the verb in dependent clauses). In main clauses, in front of the inflected verb, we find topicalised material or elements in focus. This position is traditionally called ‘Vorfeld’.

(German)

(2-84) Hans traf Maria. “Hans met Maria.”

Am Sonntag traf Hans Maria. On Sunday met Hans Maria “Hans met Maria on Sunday.”

Weißt du, dass Hans Maria traf? Know you that Hans Maria met “Do you know that Hans met Maria?”

Describing the right verb bracket as the very last position is not quite correct. You can find certain elements to the right of this position if they are destressed. This position is called Nachfeld. Arguments are clearly forbidden in this position:

(German)

(2-87) Weißt du, dass Hans Maria am Mittwoch traf? (2-88) Weißt du, dass Hans Maria traf am Mittwoch? (2-89) \* Weißt du, dass Hans am Mittwoch traf Maria?

This restriction also holds for argumental PPs:

(2-90) Weißt du, dass Hans auf dem Stuhl sitzt? Know you that Hans on the chair sits “Do you know that Hans sits on the chair?”

This seems to indicate that syntactically there is a distinction between arguments and modifiers. Fillmore’s example shows that it is not semantics that determines the difference. In order to account for possibility of omitting the object in some cases we have to look for something else.

# 2.2 Representation in X-Bar structure

One of the great successes of early structuralist linguistics was the discovery of constituency in human language. Later, Chomsky could show that recursion was an important property of sentences. The same structure of predicate, arguments, modifiers and functional elements that we find in the sentence itself, could be found in certain arguments and modifiers. Noun phrases especially showed the same structural composition, the head noun behaving as a predicate, genitive noun phrases as arguments and adjectives as modifiers. Adjective and adverbial phrases as well as prepositional phrases seem to be structured internally in an analogous way.

The mathematical tool of tree structure was soon accepted as an appropriate mode of description. The idea was to represent arguments, modifiers and certain functional elements in a uniform way in their relation to heads. For various reasons (purely syntactic ones as well as arguments of learnability) most theories restrict trees structure to binary branching. This resulted in the 70s in the famous X-Bar structure with the following elements:

Heads: Indispensable elements which determine the category of the whole projection. Single words as terminal elements of the tree sit always in head position. Predicates are viewed as heads of a projection.   
Complements: Position of the internal argument of a predicate. More general: material selected by the head. In this general view the inflection head selects a VP as its complement.   
Specifier: a very diffuse category, not easily definable. Position of the subject of the sentence. Landing position of moved phrases. In earlier times base position for functional elements like complementizers and determiners.

An example would be:

![](img/53770a2ca5783b4bde3e7818d2ce9cc11435943406a69d628be63a92688627f6.jpg)

where the theory does not define the linear order between sister nodes. The following trees are thus totally admissible examples:

![](img/7e1172a6b0a8b2ec183ad4e3e20664a2c0377ae3cd8e04f320b18ccb16498a5d.jpg)

The order of the complement with respect to the head – the so called head parameter – was for a long time considered to be responsible for the difference between languages with verb – object order like English (VO-languages) and languages with the order object – verb like German (OV-languages).

Modifiers were represented through adjunctions, which are viewed as a doubling of nodes. Adjunctions can be done freely without any limits in number and without respecting a specific order. Some variants of the theory considered modifiers to be added freely to the right and the left.

Early theories considered adjunction to the intermediate position $X '$ as also possible. This was excluded in later theories. Nowadays only adjunctions to the head and to the maximal projection are considered:

Head adjunction:

![](img/650759853f1b966d04eb70dbc2ecbb36f222e274606cb703c3f222f39fc955e6.jpg)

XP-adjunction:

![](img/f97ae30061c97efd45243b0663759f17e2eb6ff96d08ad2961be59de63154cc3.jpg)

with a slight asymmetry between them: Most syntactic theories consider the XP-adjunction position (as well as the specifier position) a position for basic insertion, as well as a landing position for moved XPs, whereas there is no theory (to my knowledge) which permits basic insertion of heads in adjunct position.

Some theories don't make a distinction between XP-adjuncts and specifiers (in particular the antisymmetric theory of R. Kayne from 1994 as we will see later).

Whereas the order of several projections that sit in complement position is determined by selection, there exists no equivalent mechanism to give any ordering to adjuncts among each other. Any order should be possible.

Further developments of the theory of syntax arrived at a more extended structure of the sentence. The existence of several functional elements, which couldn't be located in specifiers of the same projection led to a layered structure with two functional projections above the VP:

IP, as an abbreviation of ‘inflectional phrase’, is headed by functional elements like auxiliaries, inflectional affixes or the English infinitive marker ‘to’. In its specifier we find the external argument of the verb, the subject of the phrase. This certainly is a departure from the idea of presenting arguments in a uniform way or at least all in a local relationship to its predicate.

Above the IP in the outermost layer of the sentence we find the CP (‘complementizer phrase’) headed either by an overt complementizer or a covert question marker. Its specifier can host elements that were moved out of their original position to mark constituents under question (wh-elements) or in focus.

The overall X-Bar structure of a sentence can thus be represented as:

![](img/1fc24c2fceb971f777a91109f67ba6275f70acbd107294ee6dd7ac235c1ed05c.jpg)

# 2.3 The Split Infl hypothesis

In 1989 this model was refined in a remarkable essay by Pollock (1989) developing certain observations by Emonds (1978). It started with a comparison of the order of finite and non finite verbs in English and French with respect to certain adverbs and negation.

In English we never find finite verbs (apart from ‘be’, ‘have’ and ‘do’ or certain modals) in front of the negation ‘not’,

(2-92) \* John likes not Mary.

nor in front of certain adverbs such as ‘often’:

(2-93) \* John kisses often Mary.

as opposed to their French equivalents:

(2-94) Jean (n') aime pas Marie. Jean NE love not Marie “Jean does not love Marie.”

(2-95) Jean embrasse souvent Marie. Jean kisses often Marie “Jean often kisses Marie.”

If we take the position of adverbs to be stable during a derivation, and if we assume a universal base structure for all languages, we can explain this striking difference as a difference in verb movement. In both languages the negation and the adverb are generated above the verb. In French but not in English, the verb moves up across negation and the adverb, to a higher position.

In infinitival sentences we do not find a difference in the order of the (infinite) verb and negation:

(2-96) Not to get arrested under such circumstances is a miracle.   
(2-97) \* To get not arrested under such circumstances is a miracle. (French)   
(2-98) Ne pas regarder le télévision consolide l'esprit critique. NE not watch the television strengthen the spirit critical “Not to watch television strengthen one's independence.” (French)   
(2-99) \* Ne regarder pas le télévision consolide l'esprit critique. NE watch not the television strengthen the spirit critical

In both languages it seems impossible for the infinitival verb to climb over the negation. So at first sight the difference in verb movement between the two languages seems to be neutralized in the case of infinitives. But with respect to certain adverbs Pollock discovers something totally unexpected:

(2-100) To hardly speak Italian after years of hard work means you have no gift for languages.   
(2-101) \* To speak hardly Italian after years of hard work means you have no gift for languages. (French)   
(2-102) A peine parler l'italien après cinq ans d'étude dénote un manque de don pour les langues. (French)   
(2-103) Parler à peine l'italien après cinq ans d'étude dénote un manque de don pour les langues.

While English infinitives are not allowed to climb over these adverbs, their French equivalents are. Note that the climbing in the French case is optional.

If the French infinitival verb can climb above certain adverbs, but not above the negation, then there must be an intermediate landing position. That is Pollock's surprising conclusion. Instead of having a single IP (InflP) he expands it to a distinct TP (tense phrase) and AgrP (agreement phrase) with an optional NegP (negation phrase) in-between:

![](img/e5d5853bef3a5c30cc23573c4bdb28124e21948d514a031e2e06c41390d92951.jpg)

In T we find the tense suffix, in Neg the negation and in Agr the agreement suffixes. Finite tense is an operator which triggers movement in the French case. The finite verb moves first to Agr, takes it suffix (incorporates it) and both climb up over Neg to T:

![](img/05a72e0d55332b9eadab1543a643ff5e65a8cd69443fc11edb9866aeda1ff9cc.jpg)

![](img/6ca74b26be59c9e1e1a13f2ffdcc4a1e41a30e618858c7e359b3635806055a61.jpg)

In this way morphology is integrated via ‘affix hopping’ into syntax.

In English, the movement of the verb to Agr is blocked due to its very impoverished morphology. The HMC (head movement constraint) prohibits heads to make long distance movements without stopping at each intervening head. Therefore the verb cannot move directly to the T head. (Neg doesn't count in Pollock analysis as an intervening head).

The important question is how the English verb gets its tense morphology. Pollock's answer is: Affix lowering. The T head moves downward to the verb to provide it with its morphology.

In the infinitival case, the verbs don't have tense features, so they don't have to move to T. English infinitives remain in base position just like finite verbs. French infinitives move to the Agreement node.

Pollock's idea of splitting the single IP into two (or, with NegP, three) different projections was a great success, though in successive works the order of the two involved projections was inverted: AgrP is today usually assumed to be higher than TP. (Belletti 1990)

The idea of affix hopping also found a warm welcome in the linguistic community. But the lowering of affixes to the verb was an obstacle. Since it is commonly assumed that traces must be C-commanded, the lowering of an element was technically excluded. Thus the question of how the verb could possibly get its affixes in English gave rise to a paradigm revolution in generative grammar. But before we give a very brief introduction to this Minimalist program we need to introduce the level of LF.

# 2.4 The level of logical form and covert movement

First hints of how to solve this conflict showed up in the eighties with the invention of LF and covert movement. One of its origins lies in the comparison of constituent question formation in different languages.

In English we have the so-called wh-movement, which marks a question: The questioned constituent contains a wh word like ‘who’, ‘what’ or ‘when’ and starts the sentence. Most analyses assume that this constituent has been moved from its base generated position. If it is the object that is questioned for example, the wh-word is base generated in object position and then moved to the specifier of the CP. This movement is called wh-movement to distinguish it from other kinds of argument movements where arguments are moved into argument positions (spec IP):

(2-104) Who(m) did you see?

can be analysed as:

[CP Whoi [C' [... did you see ti]]]

where t denotes the (invisible) trace left by the moved element. But it is an interesting fact that in the case of two questioned elements only one moves to the front in English. If for example the subject and the object are questioned we get:

(2-105) Who saw whom?

instead of

$$
( 2 { - } 1 0 6 ) ^ { \ast } ~ \mathrm { { W h o } ~ w h o m ~ s a w ? }
$$

or

(2-107) \* Who whom did see?

But in Polish both elements move to the front:

(2-108) Kto co robi? Who what does “Who does what?”

(Haegeman 1994: 504)

In Chinese however we find the opposite pattern. No wh-element moves (wh in situ):

(2-109) Zhangsan xiangzin shei mai-le shu Zhangsan believe who buy-ASP book “Who does Zhansan believe bought books?” (Haegeman 1994: 499)

At this time it was commonly assumed, that at the end of the derivation all operators have to move to the left to a position from where they can C-command the elements in their scope (e.g. the whole sentence). How could we then possibly explain the elements in situ, e.g. in the base position? The answer gave rise to the T-model of the late Government and Binding framework: at the beginning of the derivation all elements are inserted in the so called D-structure which represents the predicate argument structure of the main verb. Subsequent movements result in S-structure which represents more or less the order of the words that we find in the spoken sentence, the surface order. From here the derivation splits into a branch leading to the logical form (LF) and one which leads to the phonological form (PF). On the branch to PF only post syntactic phonological (and maybe morphological) rules apply. At the end we have the phonetic representation of the string.

LF represents the logical and semantic relations of the elements of the sentence. Here all operators have to be in scope-taking positions, e.g. all the elements in their scope must be C-commanded by them. The branch to LF consists of only syntactic rules, but since they apply after S-structure they have no visible effect; the movements are covert.

![](img/1b260b8038604b99cb02764b4a7e8f13da2fc4662ac7d37d3176c0999850480f.jpg)

Now we can explain the differences of wh-movement between languages in terms of overt, (before S-structure) versus covert movement: all languages have the same structure at LF. All wh-elements are at the beginning of the sentence. In Polish all wh-elements move in the branch between D-structure and S-structure. In English this is only allowed (and obligatory) for one element, the others moving covertly. In Chinese all wh-elements move covertly.

This analysis could be useful to explain the problems that linguistic theory had with verb movement and affix lowering.

We could simply say, that all verbs move up to the highest head that bears affixes, but that in certain languages this movement (or part of the movement) is procrastinated until the covert branch to LF. French verbs move overtly, while English verbs do so covertly. This could be a nice solution, but unfortunately it brought up another riddle. If English verbs move to their affixes after S-structure, why do we see the affixes on the verb at the level of PF? The branch to LF should have no influence to its sister branch.

# 2.5 The minimalist program

In the early nineties Chomsky presented a radical new view of syntax, which could overcome the problems of verb raising and morphology. Instead of moving the verb to a position where it gets assigned an affix (or its affixes), or moving the affix to the verb, he assumes that all verbs, more generally all words, are inserted into the syntactic structure in their fully inflected form. Furthermore he abandons the idea of a complex D-structure at the beginning of the derivation in favour of a fully dynamical construction.

At the beginning of the derivation we only have the numeration, i.e. a collection of all words used in the sentence in their fully inflected form. These elements are put together to form constituents. Already built up constituents can be used to merge with other constituents. The sentence is thus built from the bottom (the verb) stepwise up to the top (the sentence). At each level of this derivation the highest node looks for another constituent with which to form two sister nodes of a new mother node. This other constituent can be either a constituent, which is already subpart of the searching node and is moved up to the new position (Move), or it is an already built constituent independent of the searching tree (Merge).

Move:

![](img/073d7c5cda2f43a8f68c9c0dd211394f267b3ed3fffb112948d7d327731574dc.jpg)

Merge:

![](img/f164e912069be70c7d5d162ca468d2c091c465bfe3cc24a36ba4dcaa8fb8f759.jpg)

Certainly this model no longer contains D-structure. But Chomsky also gets rid of S-structure. The derivation continues as above until LF. At a certain point of the derivation (and this point is highly language dependent) a second branch leads the sting (constructed up to then) to PF:

![](img/b5dc70dab6d36a950ef411abb226d01a315183ceebf2ac90c1176afcf26c81f0.jpg)  
Numeration

One of the most fascinating elements of the Minimalist Program is the fact that every movement is motivated. Each word we find in the numeration has a set of syntactic, phonetic and semantic features. At LF only semantic features can be interpreted and at PF only phonetic features. All other features have to be stripped off during the derivation. Spell Out itself strips off all phonetic features and passes them over to PF. Semantic features that remain are fully interpretable at LF and are no problem to the cognitive system. But syntactic features have to be cancelled before LF. The way to do this is via paring two constituents bearing the same feature in a local neighbourhood. This can be either a specifier head configuration or a head head adjunction. Uninterpretable features will be cancelled.

Chomsky assumes that functional heads bear uninterpretable features which therefore attract lexical elements with matching features into a local neighbourhood.

In this way verbs start the numeration with all their affixes, each of which is paired with a feature. Above the VP we find the usual functional projections that bear features like aspect, tense, mode, which are non interpretable. So they attract the verb via head-head adjunction and cancel their own features, while the features of the verb remain being interpretable themselves.

At any step of this movement we can find the language specific Spell Out point, which strips away the phonetic features of the sentence and sends them to PF. Since the verb had all its morphology from the very beginning we have no problem with missing affixes.

Economy principles, that restrict the number of derivations, the size of the structure and above all, the distance of movement were implemented into the theory.

The Minimalist Program is a work in progress and subject to many subsequent modifications. The ideas of verb movement and head movement in general, though initially promising, have become more dubious in later formulations of the theory. But before coming back to more recent minimalist analysis I will present the contribution of R. Kayne to syntactic theory.

# 2.6 Antisymmetry

Richard Kayne explores in Kayne (1994) the outcome of a restricted theory of syntactic structure, which had great influence on following syntactic theories. He establishes a relationship between the hierarchical syntactic structure of a sentence and the linear order of the words in it. Starting from observed asymmetries in natural languages he proposes a restriction on X-Bar structure which, informally spoken, correlates (asymmetric) C-command to linear ordering (of terminals). Since his theory is of great importance for the following I will try to present it here in a formal way:

Basic for his proposal is the term 'asymmetrical C-command', which I will quote here:

# X asymmetrically $C$ -commands Y iff X C-commands Y and Y does not C-command $X$ (Kayne 1994: 4).

On first approach he adopts Chomsky's definition of C-command as

X C-commands $Y$ iff $X$ does not dominate Y and every node that dominates $X$ dominates Y.

Furthermore he introduces a function 'd' that maps each nonterminal node $\mathrm { X }$ to the set of terminal nodes $\operatorname { d } ( \mathrm { X } )$ that are dominated by X. This function can be extended to Cartesian products of two non terminals in a natural way, so that $\mathrm { d } ( \mathrm { X } , \mathrm { Y } ) = \mathrm { d } ( \mathrm { X } ) \mathrm { ~ x ~ d } ( \mathrm { Y } )$ for two non terminal nodes X,Y.

His main axiom is now that the image of all pairs $\mathrm { ( X _ { i } , Y _ { j } ) }$ , where $\mathrm { X } _ { \mathrm { i } }$ asymmetrically C-commands $\mathrm { Y _ { j } }$ , is a total linear ordering of the set of terminal nodes. (Also called ‘The Linear Correspondence Axiom’, LCA).

In other words:

a) If a nonterminal $\mathrm { X }$ asymmetrically C-commands another nonterminal node Y, than all terminals dominated by $\mathrm { X }$ precede the ones dominated by $\mathrm { Y }$ (in the PF string!).   
b) To every two terminal nodes (words) p and q (q following p) there will be at least two nonterminal nodes X, dominating q, and Y, dominating p, with X asymmetrically C-commanding Y (and no pair where Y asymmetrically C-commands X).

Among the Consequences for X-Bar theory, that follow immediately are:

a) Phrases cannot have more than one head.   
b) Phrases must be headed.   
C Phrases are binary branching.

(In the case of head adjunction the head node of the projection can dominate two other head nodes, one which has the same features as the mother and the adjoined one. However there is still only one head of the projection, even if it is complex).

A problem arises for the specifier position: Let's take a projection XP with a specifier YP, a head X and a complement ZP, the two latter both dominated by a node $\mathbf { X } ^ { \prime }$ . Since $\mathbf { X } ^ { \prime }$ asymmetrically C-commands all terminal nodes of the specifier YP and YP asymmetrically C-commands the head X (and all terminals under ZP), according to Kayne's definition we don't get a linear order between the material under YP and the material under $X$ . A theory like this would restrict us to phrases consisting only of heads and complements. A sentence structure would look like this:

![](img/56906d9a6499d788c1f9901a24e2ef50ed17e2a07cdb8ab7a8fb518a29299494.jpg)

This would give a mere sequence of words without any structuring, a highly undesirable result. In order to include specifiers Kayne introduces Chomsky's distinction between categories and segments and changes his definition of Ccommand:

X C-commands Y iff X and Y are categories and X excludes Y and every category that dominates X dominates Y.

(Kayne 1994: 16)

From this perspective all the nodes dominating a head $( \mathrm { X } )$ and projected by it $( \mathrm { X } , \mathrm { X } ^ { \prime \prime } )$ are considered segments of the same category. This gives the desired result, that specifiers can be included in the theory. But the definition remains restrictive enough to exclude more than one specifier. Adjunctions to maximal projections are excluded.

The only adjunction that is included into the theory is head to head adjunction. We thus get the following restrictions to X-Bar theory:

Projections have one and only one head.   
They have at most one complement and this is a right sister of the head. They have at most one specifier and this is a left sister to the node dominating the head.

![](img/17edaee78ecdac8e4a7786f6811cbd74b0d67656a4399384c616be5d563d7314.jpg)

Hilda Koopman mainly adopts Kayne's definition of antisymmetric syntax apart from his distinction between categories and segments. She solves the specifier problem in another way: She proposes that there can be no overt material in the head and the specifier of the same projection. With this she states her modified LCA:

Segments participate in $C$ -command.   
Modified LCA: the linear order of overt terminal elements corresponds   
to asymmetric $C$ -command. (Koopman 2000: 338)

This approach seems to me to have two technical problems. First it doesn't permit movement to a specifier of a specifier and second, more problematic, we don't get asymmetric C-command of a specifier over a complement.

Take the following configuration:

![](img/1558a12d5b460a043d10202246164ace2d554c1bb3efb556bbc7588808cfd20e.jpg)

ZP asymmetrically C-commands YP. This means y has to follow z. But $X$ also asymmetrically C-commands Z. Therefore z has to follow y. We arrive at a contradiction.

Note, that this contradiction is independent whether the head of XP is filled or not.

But the proposal, not allowing overt material in the specifier and the head at the same time is interesting by itself. I will return to it when discussing the ways to implement morphology in syntax.

What is important here is the empirical reason Koopman gives for this assumption. In fact it is a generalisation of the Doubly Filled Comp Filter, a rule that doesn't permit overt elements in the spec of the CP together with overt material in its head. In Haegeman (1994: 423) we find the following definition:

When an overt wh-phrase occupies the Spec of some CP, the head of that CP must not dominate an overt complementizer.

It seems that similar restrictions hold for many operators assumed to be in the CP. The alleged exceptions can, according to Koopman, be explained by taking recourse to a Split CP model (e.g. Rizzi 1997). She showed clearly that instead of having the two elements in consideration as spec and head of the same projection it seems more plausible to assume them sitting in different projections. One example from many that she gives in Dutch shall suffice here:

(Dutch)

(2-110) Ik vraag me af wie of dat er morgen komt. I ask me AF who if that there tomorrow comes “I wonder who will come tomorrow.”

(Koopman 2000: 342)

The three elements in question ‘wie’, ‘of’ and ‘dat’ can of course not be in one and the same projection. According to Koopman's analysis we have to deal with three projections in the split CP. ‘wie’ sits in the spec of a WH-projection, ‘of’ in the head of a Q projection and ‘dat’ is the head of a CP.

In Sportiche (1996) we find a generalization of the Doubly Filled Comp Filter for clitic projections which he calls voice projections:

...Suppose that just as the Clitic Criterion suggests a generalization of the WH-criterion to a more general principle of licensing ... the doubly filled COMP filter generalizes in such a way that it covers Clitic projections or Voices as well. The general idea might be that functional heads such as certain Cs or certain Clitics cannot be simultaneously filled as their specifier if they encode a property overtly realized on the specifier...

(Sportiche 1996: 32)

While the minimalist program tends via economy principles, to minimize projections, the antisymmetric framework ends up postulating more structure. But this apparent disadvantage is balanced by the much simpler and more uniform description of phrase and sentence structure.

In the meantime new observations in the fields of argument structure and modifier status gave new impetus to syntactic theory.

# 2.7 Argument structure and VP shell

The first problems arose in the field of arguments. Ever since the restriction to totally binary structure of syntactic trees was accepted, it was unclear how to deal with ditransitive structures. There was only one complement position available for two internal arguments.

Larson gave an interesting answer to this problem in Larson (1988) with his VP shell hypothesis. Instead of having only one single projection associated with the verb, he assumed that there were two; one (the lower) headed by the full verb and the other by a so called light verb, which could be overt like the Italian ‘fare’ in causative constructions like:

(2-111) ti lo faccio vedere. you.DAT it.ACC CAUS see “I show it to you.”

or covert as in the English equivalent. This structure gives enough room to host all internal arguments of the verb. The direct object sits in the complement position of the full verb and the indirect object in its specifier position.

Together with the VP-internal subject hypothesis we have all arguments of the verb base generated in a very local relation to its predicate:

![](img/3fd91d415a3863d8be1e715a84b5b834c0d2ccb679d0ab5b168d2614fab9d71f.jpg)

The subject is supposed to undergo A-movement to the position of spec IP.

The model has the advantage in analysing all arguments of the verb as base generated in a local relationship to its predicate. But if we try to correlate X-bar theoretic relations as specifier and complement with semantic relations like predicate, internal and external arguments, we meet – in my opinion - some unexpected difficulties:

While the direct object sits in a complement position, the indirect is to be found in a specifier position, just like the subject. This groups together the subject and the indirect object as opposed to the direct object. Unfortunately there are no syntactic properties supporting this grouping. So we have for example in English both types of objects (in the pronominal system) the same case realisations (him/him versus he etc.). In some languages only subjects can be relativised. On the other hand, subject and indirect object don't seem to have any property in common as opposed to the direct object.

If X-Bar structure would have some correlate in semantics, we would expect either all arguments to be in analogous positions or both objects in similar positions but the subject in a different one.

Heads are excluded from argument positions, since these are always full XPs. Since adjunctions are potentially free, they don't provide a good position for arguments either. So the only positions seem to be complements and specifiers.

Putting all (three) arguments into complement positions seems to be difficult. They cannot sit directly along the main projection line, since this is already occupied by the verb and its higher functional projections (VP, IP,CP). The only possible positions would be complements of XPs sitting in certain specifier positions. A possible solution would be:

![](img/a081bc8c0fd423e09c0003d0a15f890c9f980aeccedc6639e00732739b07e809.jpg)

Independently of the exact realisation, this seems highly implausible, since we know that arguments have to be allowed to move out of their base position. Most modern syntactic theories try to avoid movements out of spec positions for independent reasons. The only admissible position out of which movement is sometimes allowed is the highest internal specifier. But even if we allow for internal movements to this position before extraction, we could extract only one argument and move it to a higher position in the tree. That this can't be enough in general can be shown by the example (2-108) in Polish where two arguments were wh-fronted:

(2-108) Kto co robi ? Who what does “Who does what?”

(Haegeman 1994: 504)

This one example should suffice to show that the above structure does not seem to be the correct one.

It remains to posit all arguments in spec positions. The simplest way to achieve this would be to add a single projection to Larson's VP shell, removing the direct object from complement position and putting it in the spec position of the newly inserted phrase:

This partial syntactic tree presents a model totally symmetric in all arguments with only a rising degree of connectedness with the verb from direct object to subject in accordance with cross-linguistic syntactic observations.

If we look on the other side for a possible model, which posits both objects in analogous positions, but the subject in another one, we have a priori two possibilities:

a) The objects sit both in complement positions, the subject in a specifier b) The subject occupies a complement position; the objects are in specifiers.

Solution a) can be excluded for the same reasons as shown above by rejecting all three arguments in complement positions.

If we concentrate on the second solution the only possible model corresponds to reversed Larsonian shells: the subject is the complement of the verb and both objects are in specs:

![](img/870f6d334a9dfc8802e8b7ee6b3c7d69c84a6eff2d6c1e0b16819e35e8dd2b02.jpg)

But this gives us the undesirable constituent V-Subject.

To me, the total symmetric structure with all arguments sitting in specifier positions seems to be the only solution if we want to maintain the assumption, that all arguments are base generated in local relation to the verb (in a kind of ‘VP shell’) and if we want to have X-Bar relations correlated to semantics.

A predicate with more than one argument (e.g. with n arguments) would then be represented by a shell of $\mathrm { n } { + } 1$ projections, where the lowest one hosts in its head the predicate and the higher ones the arguments in spec positions.

# 2.7 Semantic interpretation of X-bar structure

The idea of interpreting X-Bar directly in semantic terms is not entirely new. Barbiers presents in his dissertation an interesting proposal concerning a relation between syntax and semantics. With reference to economy principles of the minimalist program he writes:

There is one property of current generative syntactic theory that makes it particularly uneconomical, namely the fact that X-Bar structure itself does not contribute to the semantic interpretation.

(Barbiers 1995: 2)

To establish a possible link between syntactic and semantic relations he considers two options:

a) a direct link between a syntactic relation R that holds between two nodes X and Y and a semantic relation S holding between X and Y b) a separate node R which expresses this semantic relation

Barbiers considers the second option to be more economical and chooses it. He takes relations of the type relation R relates element X to element $\mathrm { Y }$ to be the principal ones. Since three constituents are involved, namely the relation and the two elements, he calls them ternary. Relations between lexical items and their modifiers, e.g. nouns and adjectives or VP and adjunct PPs are in his framework ternary relations reduced to binary relations via movement. Formally he expresses these ideas in the

Principle of Semantic Interpretation (PSI)   
I. A node Z establishes a S(emantic)-Relation between a node $X$ and a node $Y$ iff $X$ immediately $C$ -commands $Z$ and $Z$ immediately $C$ - commands Y.   
II. A node Z is a Qualifier of a node $X$ iff Z establishes a S(emantic)- Relation between X and Y, and X and Y are coindexed.

(Barbiers 1995: 7)

He illustrates his proposal with the example of the relation of ‘John’ being ‘after’ ‘Mary’, which could be expressed by the following PP:

![](img/d421d399625de7273a27a1bcab9bc363c68e7a41df7ea60152ef9dec56d74a5a.jpg)

So it is the intervening head ‘after’ which determines the relation between the two DPs. But since ‘after’ is an asymmetrical relation there is missing, according to Barbiers, a second relation which could be paraphrased as ‘... and John is after’. To see how this could be implemented, let's first have a look at a typical ‘qualification’ relation like ‘the old man’ where ‘old’ is the qualifier of ‘the man’. Since there is only one DP involved it has to occupy both positions that are related by the qualifier:

![](img/afadbc97f877ded396361c25d561319103278515f125d6b6704582b2c6783c87.jpg)

This means for our ‘John after Mary’ example that the missing relation ‘...and John is after’ has also to be expressed via movement:

![](img/8d3b2032e288079556db750b9c4253fd39366cf49c250e34877b76587897d957.jpg)

Note that the Agr node has the same index as the moved DP via spec head agreement.

Though the idea behind this proposal to relate X-Bar structure to semantic relations seems to me to be a milestone, it is surprising that Barbiers rejects the first option of relating directly the relation between two syntactic nodes to semantic relations. The introduction of the intervening node with lexical content, constrains the model to express only relations defined by lexical items. In my opinion, it would be more minimalist to express directly X-Bar relations with semantic terms as for example Spec-Head relations relate to argumentpredicate relations.

But if we restrict ourselves to antisymmetric structure, there are not many syntactic relations available: specifier-head, head-complement and specifiercomplement. If we are looking for syntactic equivalents for predicate-argument relations we encounter the problem of predicates with more than one argument.

A ditransitive predicate as ‘give’ is commonly assumed to have three arguments: the donator, the gift and the goal. Since we have only one specifier for every head we cannot simply put all three arguments in the specifier of the head node above the verb. There are two possible options:

One possibility is to view a sentence like ‘John gives a book to Anne’ as compounded of three predications. The innermost consists of the predicate ‘give’ which has only one argument slot for the gift. Here we can put the verb in the head and the argument in its specifier. Then these two build up the complex predicate ‘to give a book’ which in turn has again only one argument, the goal. ‘to give a book’ is a maximal projection which sits in the complement of an empty head and the goal ‘Anne’ in its specifier. Together they build the maximal projection ‘to give a book to Anne’ which can be viewed as the one slot predicate with the donator ‘John’ being its single argument. Again the predicate is in the complement of an empty head and the argument in the specifier. This would give us as generalisation both syntactic relations ‘specifierhead’ and ‘specifier-complement’ as realisations of a ‘argument-predicate’ relation.

The other option is to enlighten the condition of taking only strictly local syntactic relations inside one maximal projection. We could view the verb ‘give’ as having three arguments. It sits in the head of the lowest projection. All arguments (respecting an order dictated by syntax and/or lexical entry of ‘give’) sit in specifiers of projections above. But this would imply a kind of superstructure composed of more than one projection. Its lowest projection bears the predicate in its head. The number of projections is given by the number of arguments. Predicate-argument relations are realised as relations between specifiers and the lowest head. I will return to this idea in the chapter about prepositional phrases and movement. There I will present an analogous structure for PPs above the VO, which I developed for independent reasons.

# 2.8 Parallels between morphology and syntax

In 1985 in the famous article referred to as ‘The Mirror Principle’ Baker (1985) described striking parallels between syntactic derivations and orders of certain morphemes of the main verb. What these morphemes have in common is that they are all involved in changing the valency of the verb. Passive morphemes render a transitive verb intransitive; the original object becomes the subject. The former subject gets oblique case and is optional. Modifying DPs, usually expressed as PPs become ordinary objects via applicatives and causatives add a new argument as principal subject.

There is another property of these morphemes that distinguishes them from ordinary derivative and inflective morphemes like mode, tense and aspect: they do not have a rigid ordering among each other, as an example from Quechua exemplifies:

(Quechua)

(2-112) Maqa-nak-ya-chi-n beat-RECIP-DUR-CAUS-3SG $\mathrm { \cdot H e _ { j } }$ is causing them to beat each other ”   
(2-113) Maqa-chi-naku-rka-n beat-CAUS-RECIP-PL-3SG “Theyi let someonej beat each otherin”

(Baker 1985: 374 f.)

In(2-112) the reciprocal marker is closer to the root than the causative marker. Therefore Baker assumes that the reciprocal is attached prior to the causative. This corresponds to the order of syntactic derivations which first identify Subject and Object of the verb ‘beat’ before adding a causer to the event.

In (2-113) the reciprocal is attached to the verb after the causative. The interpretation makes clear that the corresponding syntactic derivation first adds a causer and then identifies causer and object.

This idea has consequences for the theory of the organisation of the grammar. Morphology and Syntax cannot be viewed as entirely independent. Somehow it has to be explained why and how syntactic derivations reflect morphological ones. If we take verbs as entering the numeration totally inflected with all affixes, we have to stipulate somehow that the internal order of the morphemes is transparent for the syntactic process.

# 2.10 The Cinque hierarchy

A milestone in the field of modifier syntax is the contribution of G. Cinque in Cinque (1999). He assembles a large amount of data from a great number of languages which helps to view the syntax of certain types of modifiers in a totally different light.

He starts with the observation that adverbs can be grouped in different types which respect among themselves, a rigid order. Thus only one of the following word orders is possible:

(Italian)

(2-114) Ha solitamente sempre ragione lui. Has usually always right he “He is usually always right.”   
(2-115) \* Ha sempre solitamente ragione lui. “He is always usually right.” (Italian)   
(2-116) Gianni ha sempre completamente perso la testa per lei. “Gianni has always completely lost his mind for her.” (Italian)   
(2-117) \* Gianni ha completamente sempre perso la testa per lei. “Gianni has completely always lost his mind for her.” (Cinque 1999: 6 f.)

In English the second order is also at least very odd, as the translations show. In French we find the same pattern:

(French)

(2-118) C'est lui qui a généralement toujours raison. “It's him who is usually always right.”   
(2-119) \* C'est lui qui a toujours généralement raison. “It's him who is always usually right.”

Expanding the corpus to many other adverb types and comparing this with data from totally different languages such as Norwegian, Chinese and Hebrew, he arrives at the conclusion that these types of adverbs are rigidly ordered in all sentence types in all languages.

In a similar way he discovered a universal hierarchy of agglutinating affixes. In all languages with agglutinative suffixes we find epistemic morphemes to the right of tense morphemes and the latter to the right of aspect morphemes. For prefixes we get two patterns: either the opposite order of the suffix order (by far the pattern found most) or the same order (rarely found, e.g. in Navajo).

But the most surprising discovery was his observation that between groups of adverbs and each type of affixes a semantic one to one relation could be established which gives us the exact mirror order of the adverbs for the suffixes.

Combining the two orders (one filling gaps of the other) he derives the universal hierarchy of modifier types:

Moodspeech act   
Moodevaluative   
Moodevidential   
Modepistemic   
T (Past)   
T (Future)   
Moodirrealis   
Modnecessity   
Modpossibility   
Modvolition   
Modobligation   
Modability, permission   
Aspecthabitual   
Aspectrepetitive I   
Aspectfrequentative I   
Aspectcelarative I   
T (Anterior)   
Aspectterminative   
Aspectcontinuative   
Aspectperfect   
Aspectretrospective   
Aspectproximative   
Aspectdurative   
Aspectgeneric/progressive   
Aspectprospective   
AspectSgCompletetive I   
AspectPlCompletive   
Voice   
Aspectcelarative II   
AspectSgCompletetive II   
Aspectrepetitive II   
Aspectfrequentative II   
frankly   
fortunately   
allegedly   
probably   
once   
then   
perhaps   
necessarily   
possibly   
willingly   
inevitably   
cleverly   
usually   
again   
often   
quickly   
already   
no longer   
still   
always   
just   
soon   
briefly   
characteristically   
almost   
completely   
tutto   
well   
fast, early   
completely   
again   
often

(Cinque 1999: 106)

This discovery opens up the discussion on modifier structure and the old adjunction model could not serve any more.

As described above, adjunction is a free process, unordered and unlimited. But Cinque's data revealed a rigid order, which could not be explained via adjunction.

Furthermore adjunction is incompatible with Kayne's antisymmetric model of syntax. So three questions arise:

How to account for the rigid order of adverbs? How to account for the rigid order of affixes? How to account for the relation between the two orders?

Cinque's answer to these questions is ingenious and simple: he extends Pollock's Split Infl Hypothesis region to a hierarchy of functional projection between the CP layer and the VP shell. Each functional projection corresponds to one of the above modifier types. Affixes are seated in the heads of the prevailing projection, adverbs in their specifiers.

Note that adverbs cannot simply be heads, but must be part of their own projection, since they can be modified by other adverbs and degree expressions without changing the ordering relations:

(German)

(2-120) Hans hat oft schnell aufgegeben. Hans has often quickly given_up (2-121) ?? Hans hat schnell oft aufgegeben.

(German)

(2-122) Hans hat sehr oft wirklich schnell aufgegeben. Hans has very often really quickly given_up.

(2-123) ?? Hans hat wirklich schnell sehr oft aufgegeben.

(The sentences marked with ‘??’ become possible with a very marked intonation and correlated topic- focus structure with the celerative AdvP in some kind of topic position and the frequentive AdvP in some kind of focus position). Being a full XP the head position is not available for the AdvPs. Cinque supports the Adv in Spec hypothesis with data from verb movements in Italian.

If we think back to former analysis of $\mathrm { I P }$ or in the Pollock framework, we remember that not only affixes were hosted in the functional heads but also certain auxiliaries. If we are going to expand the split Infl region to the Cinque hierarchy we should expect a corresponding hierarchy of auxiliaries as well. And indeed Cinque shows, that e.g. in English and Spanish we can find this corresponding order:

(2-124) These books have been being read all year (Spanish)   
(2-125) Esos libros han estado siendo leídos todo el año (Cinque 1999: 57)

where the three auxiliaries reveal the order Tense $>$ Aspectperfect $>$ Aspectprogressive $>$ Voice in accordance with the Cinque Hierarchy.

In recent work Cinque (2000) he expands the analysis to include certain verbs in Italian that take infinitival complements and permit clitic climbing like ‘volere’ (to want), ‘finire’ (to end) and ‘venire’ (to come), co called restructuring verbs. He claims that these verbs are base generated in functional heads just like auxiliaries such as ‘be’ and ‘have’. By doing so he manages to explain their otherwise exceptional behaviour.

An interesting aspect is the way Kaynian antisymmetry and linear order of adverbs follow from each other. We have seen that adjunction, which would give us free order, is excluded from syntax by the antisymmetric model. On the other side the overall data shows that the languages of the world have an inherent antisymmetry with respect to adverb order: In a symmetric world (with respect to the head parameter), we would expect both languages with adverb order of the Cinque type (mode before tense before aspect), and languages of the reversed type (aspect before tense before mode).

In fact, there seem to be a small sample of VO languages like Malagasy, Tzotzil and Zapotec which show reversed order. In Pearson (2000: 330 f.) we find the following examples:

(French)

(2-126) Jean lave toujours bien ses vêtements. Jean washes always well his clothes “John always washes his clothes well.” (Malagasy)   
(2-127) Manasa tsara ny lambany foana i Ketaka. wash well DET clothes.3 always DET Ketaka “Ketaka always washes his clothes well.”

Pearson distinguishes two types of VO languages: one that behaves like French, having the direct order of adverbs and the other (probably much smaller group) with inverse order. OV languages seem to exhibit always the direct order. This is certainly not a symmetric pattern. Given that many languages with direct order have partial verb climbing and the described examples are all verb initial, we might arrive at the conclusion that adverbs exhibit the pattern:

Adverbs before the verb appear always in direct order, adverbs behind the verb either in direct or in inverted order

But before having a closer look at the sample of languages with inverted order this generalisation should be handled with care. It is tempting to accept it since it would be in perfect analogy with patterns we find with Noun-Adjective and Verb-PP orders. If it turns out to be correct, a symmetric analysis will have difficulty explaining why we never find languages with reverse order before the verb. It is in this way that the typological distribution of adverb order confirms the antisymmetric hypothesis.

# 2.11 Recent minimalist developments

Recently Chomsky made some major changes to the Minimalist Program in Chomsky (1998), Chomsky (1999) and Chomsky (2001). Though he is mainly concerned with the core system of main predicate, arguments and agreement, he gives some remarks on modifier syntax (Chomsky 2001).

Movement in this variant of minimalism is still triggered by the deletion of uninterpretable features. Elements with these features that cannot be interpreted at the level of LF are called probes. They search in their C-command area for elements with matching features which are called goals. If they find them they establish a so-called Agree – Relation.

In most cases the probe has an additional OCC feature (which replaces the former EPP feature), which provides an extra specifier position (and here we find a major difference with Kayne's system that allows for only one specifier) that has to be filled. This can happen via (external) Merge with an already constructed external constituent like an expletive (e.g. English ‘it’ or ‘there’) or via Move (internal Merge), where the agreeing element is attracted to this position. What is important for our purpose is the possibility that the agreeing element in certain cases does not have to move to the probe. ‘Agree’ in this framework is not an inherent part of ‘Move’.

But Chomsky does not extend noun verb agreement system to other realms of verbal inflection. (One could think of the functional heads that correspond to the Cinque hierarchy, as bearing uninterpretable features which trigger verb movement).

Moreover he speculates that V-raising itself is not part of narrow syntax:

The account so far leaves open the possibility that $V$ -raising is comparable to TH/EX and DISL: not part of the narrow-syntactic computation but rather an operation of the phonological component.

(Chomsky 1999: 30)

If this is true for Verb-raising then we could easily generalize this to eliminate head movement completely.

In Chomsky (2001) he addresses the problems of modifier syntax. While clinging on to the idea of adjunction which he considers to be an obstacle to syntactic theory at least up to now

There has never, to my knowledge, been a really satisfactory theory of adjunction,...

(Chomsky 2001: 15),

he tries to overcome these obstacles and open up a window to integrate adjuncts into his framework. But in order to permit this he introduces a new mechanism, called ‘late merge’, which means that the adjunct can be merged to the element it modifies, after the latter has been moved, and this even in a non cyclic way.

Since in this version of minimalism there is clearly no mechanism available to explain the rigid order of adverbs and their correspondence to the order of affixes, I will remain in the following in the (antisymmetric) framework of Cinque. First I want to go deeper into morphology and show how one could explain the difference between prefixes and suffixes in a purely syntactic approach in Chapter 2 before extending the idea of a hierarchy of modifiers to the realm of prepositions. In Chapter $3 \mathrm { ~ I ~ }$ try to show that we can indeed establish an ordering between prepositional expressions with the example of German. In Chapter 4 I try to explain how to derive the different surface orders in German, English and Dutch.

CHAPTER 3

# THE ORDER OF PPS IN GERMAN – EMPIRICAL OBSERVATIONS

# 3.1 Introduction

German syntax with its relatively free word order has always challenged generative grammarians. It could neither be characterised as being clearly as superficially SVO nor SOV, because in main clauses the (finite) verb appears in second position and in dependent clauses at the end. The first property was responsible for the name “verb second language” the last for claiming German to be basically a SOV language. In main clauses the verb moves to the head of the CP, a position that is blocked by a complementizer in dependent clauses.

Additional difficulties arise from the fact that in German arguments can move around with a high degree of freedom. Perfectly grammatical are the following sentences:

(German)

Hans gab seiner Freundin einen Blumenstrauß. Hans gave his.DAT girl_friend a bunch_of_flowers “Hans gave a bunch of flowers to his girl friend.”

(German)

Seiner Freundin gab Hans einen Blumenstrauß.   
Einen Blumenstrauß gab Hans seiner Freundin.   
Hans gab einen Blumenstrauß seiner Freundin.

The translation is always the same, but the topic-focus structure is different. Only (3-1) is neutral and can be answered out of the blue or as an answer to a question like “What happened?”.

Sentence (3-2) puts ‘Seiner Freundin’ into a position of contrastive topic; ‘einen Blumenstrauß’ can be interpreted as new information with (informational) focus. Together they can be seen as part of list of answers to the question:

Wem hat Hans was gegeben? Who.DAT has Hans what given “To whom did Hans give what?”

Seiner Freundin gab Hans einen Blumenstrauß. “Hans gave a bunch of flowers to his girlfriend.”

Seiner Mutter gab Hans eine Porzellanfigur. “Hans gave a porcelain figure to his mother.”

If we find ‘einen Blumenstrauß’ in the first position, as in (3-3), it can be either a topic or a contrastive focus. In the first case it takes up a theme, which has already been introduced. The second case sets the accusative object into a contrast to other options, such as: ‘it was a bunch of flowers that he gave to his girl friend, not a ring’.

The last sentence, (3-4), gives emphasis to the ‘Blumenstrauß’. It can be understood as the answer to the question ‘What did Hans give to his girl friend’. The ‘Blumenstrauß’ bears extra stress.

Sentences where the subject is neither in first position nor directly after the verb are ungrammatical or at least very marked:

(German)

(3-8) \* Seiner Freundin gab einen Blumenstrauß Hans.   
(3-9) \* Einen Blumenstrauß gab seiner Freundin Hans.

Given the different pragmatic interpretations and the different intonation structures with the grammatical sentences there is no doubt about the unmarked order base order Subject $>$ Indirect Object $>$ Direct Object.

If it comes to prepositional phrases, establishing an order among different types becomes extremely difficult. Even languages with relatively rigid word order like English show some liberty with respect to PPs. Of the following two pairs both word orders are considered grammatical. But of each pair the first sentence seems to be less marked.

# Temporal – Locative

(3-10) Hans slept in Munich on Sunday.   
(3-11) Hans slept on Sunday in Munich.

# Instrumental – Temporal

(3-12) Hans repaired the radio with the screwdriver on Friday.   
(3-13) Hans repaired the radio on Friday with the screwdriver.

If we follow the assumption that in English, or more generally in VO languages, we find PPs in inverted order following the verb, this gives us the basic order:

# Temporal $>$ Locative $>$ Instrumental

But the judgement of the difference in markedness is very weak and gives no clear coherent overall basic order. The whole corpus can be found in the Appendix C.

In German, the order between PP types seems to be even more liberal. We thus find the following order both acceptable and both seem to have the same interpretation.

(German)

(3-14) Ich habe für Herrn Mayer im Garten gearbeitet. I have for Mr. Mayer in_the garden worked “I worked in the garden for Mr. Mayer.”   
(3-15) Ich habe im Garten für Herrn Mayer gearbeitet. I have in_the garden for Mr. Mayer worked “I worked for Mr. Mayer in the garden.”

(German)

Most German speakers would not give any preference to one of the two sentences. Furthermore, both can be answers to the question “For whom did you work in the garden?”. But it would be precipitous to deduce that they have identical information structure. If we change the question and ask for the other PP constituent “Where did you work for Mr. Mayer?” the second sentence, (3-15), becomes slightly degraded as an answer to it.

This asymmetry is well known for arguments in German. We can take the first example and ask “To whom did Hans give a bunch a flowers?”. From the two examples with both PPs in the 'Mittelfeld' (to the right of the finite verb), both can be given as answers:

(German)

(3-16) Hans gab seiner Freundin einen Blumenstrauß.   
(3-17) Hans gab einen Blumenstrauß seiner Freundin.

But if we ask “What did he give to his girl friend?”, only one is an appropriate answer:

(3-18) Hans gab seiner Freundin einen Blumenstrauß.   
(3-19) \* Hans gab einen Blumenstrauß seiner Freundin.

(The questioned elements are underlined)

This examples shows that the search for an unmarked order between PPs is not an easy task. It is not sufficient to ask for judgements about which order is preferred. We have to look for more subtle tests.

Another obstacle is the proper analysis of the status of the PP in question. As we have seen in Chapter 2 there are cases where the PP is selected by the verb and has a status similar to an argument. The German verb ‘liegen’ (to lie) selects a locative PP, which cannot be left out:

(German)

(3-20) Hans liegt im Garten. “Hans lies in the garden.”

(3-21) \* Hans liegt.

The same PP can have a pure modificational status in other sentences and can be omitted without any problem:

(3-22) Hans arbeitet im Garten. “Hans works in the garden.” (3-23) Hans arbeitet.

There is another important syntactic difference between the two types of PPs. Pure modificators can be found in the ‘Nachfeld’, the space behind the right verb bracket. Arguments are excluded in this position:

(3-24) Hans hat gearbeitet im Garten.   
(3-25) \* Hans hat gelegen im Garten.

If we stick strictly to pure modifying PPs we will see, that they obey a restriction that cannot be explained by any adjunction theory: we cannot find two PPs of the same type in the same sentence together. Two Benefactives, two Instrumentals, two PPs of matter cannot appear together:

(German)

(3-26) \* Hans arbeitete für Herrn Mayer für Herrn Müller. Hans worked for Mr. Mayer for Mr. Müller (German)   
(3-27) \* Hans arbeitete mit einem Hammer mit einem Meißel. Hans worked with a hammer with a chisel   
(3-28) \* Hans sprach über Geschichte über Literatur. Hans talked about history about literature

The ungrammaticality of these sentences cannot be deduced from semantic constraints. Conceptually there is nothing which forbids to have two people that somebody can work for. Hans can use two tools at the same time and can talk about more than one subject. The sentences become grammatical if we coordinate the PPs:

(German)

Hans arbeitete für Herrn Mayer und für Herrn Müller. “Hans worked for Mr. Mayer and for Mr. Müller.” (German) Hans arbeitete mit einem Hammer und mit einem Meißel. “Hans worked with a hammer and with a chisel.” Hans sprach über Geschichte und über Literatur. “Hans talked about history und about literature.”

This behaviour can easily be explained if we assume that there is only one syntactic slot for each PP type. But this does not suffice. In a minimalist framework without the restrictions of antisymmetric structure we could adjoin as many benefactive PPs to the benefactive functional projection or to another projection as we would want. The fact that we have to use a coordinate structure indicates that we can insert only one single constituent into the appropriate slot. This is exactly what we expect in an antisymmetric world.

There seem to be some apparent counterexamples with temporals and locatives:

(3-32) Ich traf Hans in Italien in Venedig. “I met Hans in Italy in Venice.”   
(3-33) Wir treffen uns am Dienstag um 8 Uhr. “We will meet on Tuesday at 8 o'clock.”

But the two locative PPs in (3-32) cannot be interpreted as two (independent) modifiers of the same event. I did not meet Hans twice, once in Italy and once in Venice. Venice is not modifying the event, it gives a more specific description of the place where the single meeting took place. ‘in Italien’ gives a rough description of the place, which becomes more specific by ‘in Venice’. The same is valid for the temporals in (3-33): ‘am Dienstag’ gives a more general description of the time, ‘um 8 Uhr’ specifies this description.

If we exchange the order of the PPs in (3-32) we get another interpretation:

(German)

(3-34) Ich traf Hans in Venedig in Italien. “I met Hans in Venice in Italy.”

Here ‘in Italien’ does not give a fine graining of the place already determined by ‘in Venedig’. We neither get the same interpretation as in the reversed case. ‘in Venedig’ is not a fine graining of ‘in Italien’. What is meant by this sentence is a contrastive determination of ‘Venedig’. ‘I met Hans in the Venice which is situated in Italy, not the one which is in the United States’. I claim therefore that in the case of ‘Ich traf Hans in Italien in Venedig’, the second locative PP modifies the first locative PP, whereas in the case of ‘Ich traf Hans in Venedig in Italien’, the second PP modifies the DP ‘Venedig’.

The analogous changing of the order in the temporal expression of (3-33) is very marked, close to ungrammaticality:

(German)

(3-35) ?? Wir treffen uns um 8 Uhr am Dienstag.

The different structures can be exemplify with exposition to the 'Vorfeld'. While it is possible to raise a PP which is modified by another PP into the Vorfeld

(3-36) In Italien traf ich Hans in Venedig.

this is not possible with the PP whose DP is modified by a PP:

# (3-37) \* In Venedig traf ich Hans in Italien.

This shows, that the modifying PP in (3-34) is deeper imbedded. I assume that the extended projection projected by the modified noun is sitting in a specifier position with all its modifiers. The extended PP however is scattered along the main projection line and therefore parts of it can be left out.

That we have the same restrictions for locatives and temporals as for other types can be seen by putting two locatives or temporals of the same scale in one sentence:

(3-38) \* Ich traf Hans in Italien in Frankreich. \* “I met Hans in Italy in France.”   
(3-39) \* Wir treffen uns am Dienstag am Mittwoch. \* “We will meet on Tuesday on Wednesday.”

Of course these sentences can be repaired by adding a coordinator:

(3-40) Ich traf Hans in Italien und in Frankreich.   
(3-41) Wir treffen uns am Dienstag oder am Mittwoch.

I hope the above remarks make clear, that the establishing of an unmarked basic order of PPs is not a straightforward task. My first approach to collect judgements of preference of word orders was a complete failure. I collected data from different languages, among them German, English, Italian, Finnish, Hungarian, Russian. But it turned out, that they did not result in any coherent basic order. The same speakers could give different judgements for the same couple of PPs if presented in a different syntactic context. I had to look for more subtle syntactic tests.

But before presenting these tests I want to give a short overview of the gen eral sentence structure of German in Chapter 3.2.

A short description of certain test for German or other languages follows in Chapter 3.3. It turned out, that not all tests were usable for German. I will try to account for why this is so.

In Chapter $3 . 4 \ \mathrm { I }$ will add a short discussion about sentence structure and word order in the German 'Mittelfeld' that can be found in the literature.

Chapter 3.5 will introduce my own empirical findings. I used extensively three tests which in fact gave surprisingly consistent results. I will discuss them in more detail; the data can be found in Appendix A.

At the end of the chapter I will represent the results and some statistical evaluations.

# 3.2 General remarks on German sentence structure

As stated above the German main clause has two distinct positions for verb. In second position we find the finite verb or finite auxiliary. All infinitives and participles are to be found in a position after all arguments and normally all modifiers. These two positions form the ‘verb bracket’ of the German sentence.

(German)

(3-42) Hans spielt fröhlich mit dem Ball. Hans plays happily with the ball “Happily Hans plays with the ball.”   
(3-43) Hans hat fröhlich mit dem Ball gespielt. Hans has happily with the ball play.Part “Happily Hans played with the ball.”

In dependent clauses with an overt complementizer all verbs are in the right verb bracket position:

(3-44) Ich glaube, dass Hans mit dem Ball spielt. I believe that Hans with the Ball plays “I believe that Hans plays with the ball.”

In first position we find fronted elements in topic or focus position and wh elements. They form one single constituent and this region is called 'Vorfeld'. In the case of neutral topic-focus structure and if the sentence contains temporals or higher modifiers they will usually occupy this space, otherwise the subject will be there.

(3-46) Am Samstag hat Hans mit dem Ball gespielt. “On Saturday, Hans played with the ball.”

Angeblich hat Hans mit dem Ball gespielt. “Allegedly Hans has played with the ball.”

Wann hat Hans mit dem Ball gespielt? “When did Hans play with the ball?”

(German)

The right verb bracket usually constitutes the end of the clause, but in spoken language we find very often destressed modifiers, also elements that can be analysed as afterthoughts. This part of the sentence is called 'Nachfeld'. Arguments can never be found here.

(3-49) Hans hat im Park mit dem Ball gespielt. Hans hat im Park gespielt mit dem Ball. Hans hat mit dem Ball gespielt im Park.

(German)

The region between the two brackets is the so-called 'Mittelfeld'. Here we usually find all modifiers and the objects. And it is this part, which gives us information about the unmarked order.

# 3.3 Potential tests for finding the base generation of phrases

# 3.3.1 Infinitival complex

This is a test, that is used by Heidolph et al. (1981). It is assumed to give the unmarked surface order of constituents in a German sentence. The idea is to compare complexes of modifiers, arguments and an infinitival verb. The criteria for non-markedness are:

the elements have not yet been introduced. This way they cannot be information topics, which might locate them in a different position.

all DPs are indefinite. The authors correlate this with the first criterion. According to them.an indefinite DP cannot refer to an element introduced before. Furthermore it is known, that definite objects move higher:

(German)

Hans hat seiner Freundin ein Buch geschenkt. Hans has his.DAT girl_friend a book give_as_a_present.PART “Hans has given a book to his girl friend as a present.”

(German)

(3-51) ? Hans hat ein Buch seiner Freundin geschenkt.   
(3-52) ? Hans hat seiner Freundin das Buch geschenkt.   
(3-53) Hans hat das Buch seiner Freundin geschenkt.

(the question mark indicates markedness)

there is only one main intonation stress, and we find it on the last constituent before the ‘Engere Prädikatsgruppe’ (more or less the set of obligatorily selected elements such as resultatives or directional arguments, but not direct or indirect object).

With the help of these criteria the authors try to establish ordering relations between unmarked constituents. They give the following example for unmarked order:

(German) mit einem Füller einem Schüler eine Note in ein Heft schreiben. with a pen a.DAT pupil a grade in a note_book write “to write a grade into a booklet of a pupil with a pen”

(German)

einem Jungen ein Buch geben a.DAT boy a book give “to give a book to a boy”

as opposed to

(German)   
(3-56) ? einem Schüler in ein Heft eine Note mit einem Füller schreiben a.DAT pupil in a note_book a grade with a pen write (German)   
(3-57) ? ein Buch einem Jungen geben a.DAT book a.DAT boy give (Heidolph et al. 1981: 707)

(expressions in bold bear main stress).

Given the fact that many other factors besides topicalisation influence the intonation structure this test does not seem to be clear enough for our purpose. Though it seems to work fine for the examples above, I could not establish an ordering among PPs even in cases that ought to be clear. Comparing temporals with locatives does not give a clear result, though other tests show, that temporals are clearly higher:

(German)

(3-58) an einem Wochentag in einem Park spazieren gehen on a week_day in a park walk “to walk in a park on a weekday”   
(3-59) in einem Park an einem Wochentag spazieren gehen

The same problems arise with locatives and instruments:

in einem Büro mit einem Computer arbeiten in an office with a computer work “to work with a computer in an office”

(3-61) mit einem Computer in einem Büro arbeiten

# 3.3.2 VP-topicalisation

In Nilsen (1998: 63 ff.) we find the following observation. In Norwegian, which is also a verb second language, complexes of a lexical verb and modifiers can be moved in front of the finite auxiliary. If we have two modifying PPs we get certain restrictions which can be seen in the following examples:

(Norwegian)

[Motte henne] gjorde jeg i parken på fredag. met her did I in park-the on Friday “I met her in the park on Friday.”

(Norwegian)

[Motte henne i parken] gjorde jeg på fredag.

[Motte henne i parken på fredag] gjorde jeg (ikke).

\* [Motte på fredag] gjorde jeg henne i parken.

[Motte henne på fredag] gjorde jeg i parken.

[Motte i parken] gjorde jeg henne på fredag.

[Motte] gjorde jeg henne i parken på fredag.

(Nilsen 1998: 63 f.)

The element in front of the finite auxiliary must be a single constituent. Nilsen shows, that the only possible structure for the full constituent ‘Motte henne i parken på fredag’ can only be:

(Norwegian)

# [[[Motte henne] i parken] på fredag]

Norwegian is a VO language for which Cinque proposes a pied piping analysis of verb movement around PPs. (e.g. in Cinque $2 0 0 0 \ \mathrm { b }$ ). According to this proposal, modifying PPs are base generated in rigid order above the VP. In the following step, the arguments move out of the VP, leaving a remnant, in which the verb is the only overt material left. This remnant VP moves up cyclically and pied pipes the PPs with it, one after the other. The PPs end up in the reversed order:

Since it is commonly assumed that temporals are higher than locatives, this would give us the right constituency for the element in first position of the Norwegian data.

For German, which is a OV language, Cinque proposes a different analysis. In dependent clauses the verb stays below the prepositional space, which therefore appear in direct order before the verb. In main clauses the verb moves up, but does not pied pipe the PPs, so they appear in direct order after the verb even in this case.

From this model we would expect certain restrictions for fronted V modifier complexes in German as well.

Unfortunately it is difficult to find good examples with two PPs fronted together with the verb. I tried several combinations, which all seemed to be very odd, without getting clear asymmetries in acceptance.

I want to present some of my data:

# Temporal – Benefactive

(German)

(3-70) Am Freitag für Bayern München gespielt hat er gerne. On Friday for Bayer München play.PART has he with_pleasure. “Playing for ‘Bayer München’ (soccer club) on Friday did he do with pleasure.”

(3-71) ? Für Bayern München am Freitag gespielt hat er gerne.

Both sentences are possible, (3-71), is slightly worse, but not ungrammatical as in the Norwegian case. If we move only one PP to the left, both sentences become equally acceptable:

(German)

(3-72) Am Freitag gespielt hat er für Bayer München.   
(3-73) Für Bayern München gespielt hat er am Freitag.

# Reason – Temporal

(German)

(3-74) ?? Am Freitag aus Angst gefehlt habe ich wirklich. On Friday because of fear miss.PART have I really “Missing because of fear on Friday I really did.”

(3-75) ?? Aus Angst am Freitag gefehlt habe ich wirklich.

Both examples are odd. I cannot see any difference in acceptance. Fronting only one PP gives a sharp contrast:

(German)

(3-76) Aus Angst gefehlt habe ich am Freitag.   
(3-77) \* Am Freitag gefehlt habe ich aus Angst.

# 3.3.3 Binding theory

The three binding principles played an important role in the Government and Binding framework. In fact the framework itself got part of its name from them. It is very often assumed, that they could be used to detect movement. For convenience I quote them here in the formulation given in Haegeman (1994: 228 f.):

Principle A: An anaphor must be bound in its governing category

Principle B: A pronoun must be free in its governing category

Principle C: An $R$ -expression must be free everywhere

The important question is when these principles apply. For the Government and Binding framework we find in Haegeman (1994: 345):

..., we conclude, that Principles B and $C$ apply to S-structure configurations. The evidence that Principle A can be fulfilled at $D$ -structure is controversial.

The levels of S-structure and D-structure don't exist anymore in minimalists frameworks. In Cook and Newson (1996: 332) we find:

In the Minimalist Programme, the Binding Theory applies at $L F$

In a more recent publication D. Sportiche defends the idea that Principle A can apply anywhere, whereas Principle C only at LF (Sportiche 2001).

If an anaphor is bound by an element which is base generated in a Ccommanding position we expect principle A to apply at this state. Any further movements of the anaphor across the binder should not have an effect on this. We find this in examples like:

(3-78) [These pictures of each other]i, I think they liked ti (Sportiche 2001: 16)

They seems to be at some state of the derivation C-commanding each other. At this point Principle A applies and the following movement of the constituent [These pictures of each other] preserve the binding.

To illustrate the application to the analysis of PP ordering Cinque quotes an example of Pesetsky:

(3-79) John spoke to Mary about [these people]i in [each other's]i houses on Tuesday.   
(3-80) \* John spoke to Mary in [each other's]i houses about [these people]i on Tuesday.   
(3-81) \* John spoke to Mary about [each other]i in [these people's]i houses on Tuesday.

The grammaticality of sentence (3-79) is surprising for a theory which assumes DPs as being complements of prepositions. From this position, ‘these people’ could never C-command and bind ‘each other’.

If we assume the ‘anywhere’- analysis for Principle A, the grammaticality of this sentence tells us that at some stage of the derivation ‘these people’ must C-command ‘each other’. We could assume that this sentence presents both PPs in base generated position. Then we would expect that moving ‘each other’ together with the preposition across the locative PP would preserve grammaticality. But this is not the case. Sentence (3-80) is ungrammatical, also sentence (3-81).

That the base order of the two PPs is not important is shown by sentence (3-81). The general rule seems to be that in English the PP to the right is bound by the PP to the left.

Therefore, this test does not give us a hint for PP ordering. But since we expect the surface order of PPs in German to be in the reverse order (with respect to the English order), it would be interesting to look for Principle A effects in German as well. Unfortunately German is very impoverished with anaphors. There exists a reflexive ‘sich’ and a reciprocal ‘einander’, but their use is very restricted and in modifiers nearly excluded.

Principle C seems to be more of interest. But it seems very hard to find good sentences, which are easy to judge. I want to illustrate this with a few examples. Take the following sentences:

(German)

Ich habe in Karls Haus an seinem Geburtstag gespielt. I have in Karl's house at his birthday play.PART “I played in Karl's house at his birthday.” (German) Ich habe an seinemi Geburtstag in Karlsi Haus gespielt.

Here we can coindex ‘Karl’ with the pronoun in front. But this is not very surprising, since ‘sein’ is too deep imbedded inside the DP to C-command ‘Karl’. Take the example:

(3-84) His wife saw John in the mirror. vs. (3-85) \* Hei saw Johni in the mirror.

In sentence (3-84) the pronoun does not C-command ‘John’; in sentence (3-85) it does. Therefore, pronoun and ‘John’ cannot be coindexed in the second sentence. For this reason I tried to find examples where the DP ‘complement’ of the first PP can be expressed by a pronoun. Furthermore the second PP should have a DP that could in principle be coindexed with this pronoun. If the first PP is temporal and the second locative it easy to see that these kind of examples are not easy to construct and even harder to judge. I tried with examples like:

(German)

Ich spielte in ihmi am Nationalfeiertag des Landesi. I played in it at_the nation holiday of_the country

This sentence is far too strange to be judged in a correct way. But as mentioned earlier sentences with the pronoun in Genitive position are easier to find, but I did not expect to find differences in co reference that depend on the order of PP types. But I was surprised to find the following asymmetries:

# Temporal – Locative

(German)

Ich habe in Karls Haus an seinem Geburtstag gespielt.   
I have in Karl's house at his birthday play.PART   
“I played in Karl's house at his birthday.” (German)   
Ich habe an seinemi Geburtstag in Karlsi Haus gespielt. (German)   
Ich habe an Karlsi Geburtstag in seinemi Haus gespielt.   
I have at Karl's birthday in his house play.PART   
“I played at Karl's birthday in his house.”

(German)

(3-90) \* Ich habe ins seinemi Haus an Karlsi Geburstag gespielt.

# Instrumental – Locative

(German)

Ich habe mit Karlsi Säge in seinemi Haus gearbeitet. I have with Karl's saw in his house work.PART “I worked with Karl's saw in his house.”

(German)

(3-92) \* Ich habe in seinemi Haus mit Karlsi Säge gearbeitet.   
(3-93) Ich habe in Karls Haus mit seiner Säge gearbeitet.   
(3-94) ?? Ich habe mit seineri Säge in Karlsi Haus gearbeitet.

# Instrumental – Temporal

(German)

Ich habe mit Karlsi Säge an seinemi Geburtstag gearbeitet. I have with Karl's saw on his birthday work.PART “I worked with Karl's saw oh his birthday.”

(German)

(3-96) \* Ich habe an seinemi Geburtstag mit Karlsi Säge gearbeitet.   
(3-97) Ich habe an Karlsi Geburtstag mit seineri Säge gearbeitet.   
(3-98) ? Ich habe mit seineri Säge an Karlsi Geburstag gearbeitet.

But the data are not coherent. If we take sentences where we can co index a pronoun in a PP with ad DP in a following PP to indicate that a movement has taken place, we can follow, that the PP to the left is basically lower. Then we get the results:

Locative $>$ Temporal Locative $>$ Instrumental Temporal $>$ Instrumental

Which would result in the order Locative $>$ Temporal $>$ Instrumental which does not correspond to any other observation. Therefore I assume that the observed asymmetries are not due to base generated syntactic ordering of PP types. It would be interesting to collect more data and see whether it is possible to find a systematic pattern.

# 3.3.4 Quantifier pronoun binding

Larson used this test to show that an indirect object C-commands the direct object. In Larson (1988: 336) we find:

A quantifier must $C$ -command a pronoun at S-Structure if it is to bind it. Double objects show asymmetries regarding quantifier-pronoun binding possibilities:

(3-99) I gave every workeri hisi paycheck.   
(3-100) \* I gave itsi owner every paychecki.

But as in the case of Principle C violations it is very difficult to find examples that can easily be judged. I will give here some of my sentences:

# Temporal – Locative

(German) (3-101) Ich habe in jedemi Land an seinemi Nationalfeiertag gearbeitet. I have in each country on its national_holiday work.PART “I worked in each country on its national holiday.”

and if every holiday had a proper country of origin:

(German)

(3-102) ?? Ich habe an jedemi Feiertag in seinemi Ursprungsland I have on each holiday in its land_of_origin gearbeitet. work.PART “I worked on each holiday in its land of origin.”

(3-101) is excellent, (3-102) despite its constructed semantics syntactically non-marked.

# Benefactive – Temporal

(German)   
(3-103) ?? Ich habe an jedemi Namenstag für seineni Heiligen gebetet. I have on each Saint's_day for its Saint pray.PART “I prayed on each Saint's day for its Saint.” (German)   
(3-104) Ich habe für jedeni Heiligen an seinemi Namenstag gebetet. I have for each Saint on its Saint's_day pray.PART “I prayed for each Saint on its Saint's day.”

# Benefactive – Locative

(German)   
(3-105) Ché Guevara hat in jedemi Land für seinei Unabhängigkeit Ché Guevara has in each country for its independency gekämpft. fight.PART “Ché Gueavara fought in each country for its independency.” (German)   
(3-106) ? Er hat für jedes Landi in ihmi gekämpft. He has for each country in it fight.PART “He fought for each country in it.”

These data shall suffice to show the difficulties in finding appropriate examples. The sentences seem so artificial that it is hard to tell whether the judgements are purely syntactic or due to the strangeness in meaning.

# 3.3.5 Semantic interpretation

Sentences in German with two PPs seem at first sight to have the same interpretation independent of the order between the PPs.

(German)

(3-107) Ich habe am Dienstag in Venedig geschlafen. I have on Tuesday in Venice sleep.PART “I slept in Venice on Tuesday.”   
(3-108) Ich habe in Venedig am Dienstag geschlafen.

Both sentences describe the event of sleeping. This event took place in Venice and it happened on Tuesday. In an extensional semantics this could be described as the intersection of three sets, the set of events of sleeping, the set of events that took place in Venice and the sets of events that happened on Tuesday.

But we can interpret the sentences in a slight different way as narrowing down of events. (3-107) can be analysed as first taking the events of sleeping, then taking from this set the subset of events that took place in Venice and as a last step taking from this subset the subset of events that happened in Tuesday. (3-108) is ambiguous between taking first the subset of events in Venice or the subset of events on Tuesday.

Since we always end up with the same subset, this test is very subtle and cannot serve to give a proper ordering. But nevertheless it is important to observe that the two orders correspond to different orders of narrowing down, an observation which is shared by several German speakers.

# 3.3.6 Weak cross over

Again in Larson (1988) we find weak crossover effects as tool to detect movement. On page 336 he writes:

A wh-phrase $C$ -commanded at $D$ -Structure by an NP containing a pronoun cannot be moved over that NP if wh- and the pronoun are coreferential. This is the so-called weak crossover effect. Double objects show weak crossover asymmetries:

(3-109) Which mani did you send hisi paycheck? (3-110) \* Whosei pay did you send his mother?

Here again I found it very difficult to construct sound examples. It is no easy to refer in one PP to an element of another PP of a different type:

(German)

(3-111) \* In welchem Haus hat er für $e s _ { i }$ Geld gesammelt? In which house has he for it money collect.PART “In which housei did he collect money or iti?” (German)   
(3-112) ? Für welches Hausi hat er in ihmi Geld gesammelt? For which house has he in it money collect.PART “For which house did he collect money in it ?”

# 3.3.7 Wh - pronouns used as indefinites

Certain wh-pronouns can in German be used as indefinite pronouns. They seem to be resistant against movement as Frey and Pittner (1998: 7) state. Though it seems unclear why this is so, they give quite a good tool for base orders. Dependent clauses give the clearest results.

(German)

(3-113) ..., weil wer wen beleidigt hat. ..., because somebody.NOM somebody.ACC offended has “..., because someone offended someone.”

(3-114) ? ..., weil wen wer beleidigt hat.

which give the base order Subject $>$ Direct Object

# Temporal - Locative

(German) (3-115) ..., weil Hans wieder wann wo gesoffen hat. ..., because Hans again some_time somewhere drink.PART has “..., because Hans has drunk again somewhere at some time.”

(German)

(3-116) \* ..., weil Hans wieder wo wann gesoffen hat.

# Locative – Instrumental

(German)

(3-117) ..., weil Hans den Klaus wo mit was ..., because Hans the.ACC Klaus somewhere with something bedroht hat. threaten.PART has “..., because Hans threatend Klaus with something somewhere.

(German)

(3-118) ?? ..., weil Hans den Klaus mit was wo bedroht hat.

# Benefactive – Locative

(German)

(3-119) \* ..., weil Hans für wen wo gearbeitet hat. ..., because Hans for someone somewhere work.PART has “..., because Hans worked somewhere for someone.”

(German)

(3-120) ..., weil Hans wo für wen gearbeitet hat.

# Benefactive – Instrumental

(German)

(3-121) ..., weil Hans für wen mit was geschossen hat. ..., because Hans for someone with something shoot.PART has “..., because Hans shot with something for someone.”

(German)

(3-122) \* ..., weil Hans mit was für wen geschossen hat.

# 3.3.8 Licensing of negative polarity items

A negative polarity item should be C-commanded by a licensing element, e.g. negation or a wh element. Clear simple elements like ‘any’ are not to be found. But larger constructions seem to have the properties in question. Translating from the Dutch “ook mar iets” and similar expressions we could try with “auch nur irgend- ” (any):

(German)

(3-123) Hans hat niemand auch nur irgendetwas geschenkt. Hans has nobody also only anything given_as_a_present “Hans has not given anything to anybody as a present.”

(German)

(3-124) \* Hans hat nicht nichts auch nur irgendjemandem geschenkt.

So far this seem to work, but with modifiers the appearance of a negative PP and the ‘auch nur irgend‘- element get the flavour of double negation, which is in standard German clearly out:

(German)   
(3-125) ? Ich habe nie auch nur in irgendeinem Raum geraucht. I have never also only in any room smoke.PART “I never smoked in any room.” (German)   
(3-126) ? Ich habe nirgendwo auch nur an einem Tag geraucht. I have nowhere also only on any day smoke.PART “I did not smoke anywhere on a single day.”

# 3.3.9 Quantifier scope (QS)

A quantifier can take scope over another quantified expression, if Ccommanding this expression or its trace. Thus we can use this tool to detect movements. If a lower constituent with a certain quantifier has been moved over a higher element with another quantifier, we find scope ambiguities.

The moved element can take scope over the crossed element or the crossed element over the trace.

If we use quantified phrases in base positions we don't expect to find scope ambiguity:

(German)

(3-127) Ich habe mindestens einem Freund alle Fotos gezeigt. I have to_at_least one friend all photos show.PART “I showed all photos to at least one friend.”

This sentence can only have the interpretation that there was at least one friend and to this friend I showed all the photos. But it can never have the interpretation that there was for each photo at least one friend (and maybe a different one) to whom I showed the photos. The existential quantifier takes scope over the universal:

But if we move the direct object over the indirect we get an ambiguity:

(German)

(3-128) Ich habe alle Fotos mindestens einem Freund gezeigt.

We can have the interpretation that there was at least one friend for each single photo and this could be always a different friend. In this case the universal quantifier takes scope over the existential quantifier:

$$
\forall ( \mathbf { y } ) \exists ( \mathbf { x } )
$$

But this time we get another interpretation. There is at least one friend to whom I showed all the photos, the existential quantifier takes scope over the universal.

Applying this test to modifying PPs gives good results for certain pairs. Starting from the base sentence:

(German) (3-129) Ich bin in jedem Jahr wegen mindestens einer Krankheit zum I am in every year because of_at_least one disease to_the Arzt gegangen. doctor go.PART “I went to the doctor every year because of at least one disease.”

We compare the following pair:

(German) (3-130) Ich bin wegen mindestens einer Krankheit in jedem Jahr zum Arzt gegangen. ∃ (reason) $\forall$ (time) $\forall$ (time) ∃ (reason)

(German) (3-131) Ich bin in mindestens einem Jahr wegen jeder Krankheit zum Arzt gegangen. ∃ (time) $\forall$ (reason) \* $\forall$ (reason) ∃ (time)

From these data we can conclude that Temporal PPs are generated higher than Reason PPs. In (3-130) the Reason PP has climbed over the Temporal PP giving rise to the observed scope ambiguity.

Unfortunately the contrast is not always so clear. In many cases we get both readings with both orders, though there is always a clear asymmetry. In each pair there is always one sentence for which the reverse reading (the interpretation with scope of the quantifier to the right over the quantifier to the left) is less available.

To be sure that the test itself was valid I compared every PP type with each other. I could not a priory assume transitivity. I needed to verify that the test gave a consistent result. If temporals turned out to be higher than locatives, locatives higher than instrumentals and instrumentals higher than temporals, I would not end up with a linear order.

I have used in all cases existential over universal and universal over existential quantifiers. To avoid indefinite readings I modified the existential with ‘mindestens’ (at least). To avoid a collective reading for the universal quantifier I used ‘jeder’ (each, every) instead of ‘alle’ (all). Under the examples I give the accessible scopes, using ‘∃’ for the existential operator and $\cdot \forall ^ { \bullet }$ for the universal. In front I give the relative accessibility in question marks.

(German)

(3-132) Ich habe an mindestens einem Tag für jeden Chef gearbeitet. I have on at_least one day for each boss work.PART I have worked for each boss on at least one day. (German)   
(3-133) Ich habe an mindestens einem Tag für jeden Chef gearbeitet. ∃ (time) $\forall$ (beneficiary) ? $\forall$ (beneficiary) ∃ (time) (German)   
(3-134) Ich habe für mindestens einen Chef an jedem Tag gearbeitet. ∃ (beneficiary)∀(time) $\forall$ (time)∃ (beneficiary) (German)   
(3-135) Ich habe für jeden Chef an mindestens einem Tag gearbeitet. $\forall$ (beneficiary) ∃ (time) ∃ (time) $\forall$ (beneficiary)

# (German) (3-136) Ich habe an jedem Tag für mindestens einen Chef gearbeitet. ∀ (time)∃ (beneficiary) ?? ∃ (beneficiary)∀(time)

I used the German perfect in all cases in order to have an auxiliary in second position. This gave me the possibility to posit a verum focus on it, to get clearer results in some cases. Putting stress on a finite lexical verb in second position focuses on the verb and not the reinforcement of the proposition (‘ Er hat geschlafen’ meaning ‘indeed did he sleep’ versus ‘Er schlief’ meaning ‘it was sleeping, what he did’).

The most challenging task was the evaluation of the observed asymmetries in getting the reverse readings. I needed a firm quantification that allowed me to compare the different asymmetries to each other.

I evaluated the scopal interpretations according to the following judgments: a ‘?’ indicates that the interpretation is more difficult to get than the corresponding one of the other sentence of the pair. ‘??’ indicate, that the interpretation is very difficult to get, but is possible, ‘\*’ means, the interpretation is not possible at all. Scope indications are in bold, when the reverse reading is the salient one.

Below the evaluated examples I list in brackets the evaluation as a 6-tuple in the form: $( \# ? \exists +$ , $\# ? \forall +$ , #?∃-, $\# ? \forall \cdot$ -, B∃, $\tt { B V }$ ) where ‘#?’ indicates the number of question marks ‘?’, where the star ‘\*’ counts as three ‘?’ ‘∃’ and $\cdot _ { \forall } ,$ indicate the sentences with the existential operator (‘∃’) respective the universal $( ^ { 6 } \overleftrightarrow { \boldsymbol { \nabla } } )$ coming first.

The first couple, marked by the $\cdot _ { + } ,$ sign give the evaluations if the results are in accordance with the resulting overall hierarchy.

In the beginning, I could not be sure that the evaluation of each sentence yields the same PP as the higher one. Theoretically it could be that three sentences gave one PP as the higher one, but the fourth sentence the other. In order to capture these cases as well, I added column three and four, marked by the ‘-’ sign. But these cases are extremely rare; actually in the corpus discussed here there were only three cases.

‘B’ means ‘Bold Type’ and tells whether the first reading one gets is the reverse reading. Here I distinguish also sentence with existential first (‘B∃’) from those with universal first $( ^ { 6 } \mathbf { B } \forall ^ { \prime } )$ .

So we get for the relation between Benefactive and Reason:

(German)   
(3-137) Er hat für mindestens einen Heiligen wegen jeder Sünde He has for at_least one saint because_of every sin eine Kerze aufgestellt. a candle put_up “He put up a candle because of every sin for at least one saint.” (German)   
(3-138) Er hat für mindestens einen Heiligen wegen jeder Sünde eine Kerze aufgestellt. ∃ (beneficiary) $\forall$ (reason) ? $\forall$ (reason) ∃ (beneficiary) (German)   
(3-139) Er hat wegen mindestens einer Sünde für jeden Heiligen eine Kerze aufgestellt. ∃ (reason) $\forall$ (beneficiary) $\forall$ (beneficiary) ∃ (reason) (German)   
(3-140) Er hat wegen jeder Sünde für mindestens einen Heiligen eine Kerze aufgestellt. $\forall$ (reason) ∃ (beneficiary) ? ∃ (beneficiary) $\forall$ (reason) (German)   
(3-141) Er hat für jeden Heiligen wegen mindestens einer Sünde eine Kerze aufgestellt. $\forall$ (beneficiary) ∃ (reason) ?? ∃ (reason) $\forall$ (beneficiary)

the grading: (1,2,0,1,0,0).

Comparing the first pair ((3-138) und (3-139)) we see, that only one of them (3-139) is ambiguous, which indicates derived order. In the second pair ((3-140) und (3-141)) we encounter an assymmetry between the two, giving (3-140) as the more ambiguous one. In both pairs it is the sentence with the Reason modifier in front of the Benefactive which is more ambiguous. Since this gives the derived order, we can conlude that the Benefactive is generated higher than Reason.

The numbers indicate:

# Sentences, whose evaluation is in agreement with the overall result:

The first two numbers give the number of question marks for interpretation of sentences where the lower element takes scope over the higher, when sitting to the right ((3-138), (3-141)). In this example, the result of the tests give Bene

factive as the higher element. Therefore, the two sentences which have the Benefactive to the left and the Reason to the right are evaluated here.

The first entry evaluates the sentence with the existential operator coming first (and the Benefactive to the left):

(German) (3-138) Er hat für mindestens einen Heiligen wegen jeder Sünde eine Kerze aufgestellt

The interpretation where the lower element, Reason, takes scope over the higher, Benefactive,

? ∀ (reason) ∃ (beneficiary)

has one question mark, the resulting number is therefore 1.

The second entry evaluates the sentence with the universal quantifier com ing first.

(3-141) Er hat für jeden Heiligen wegen mindestens einer Sünde eine Kerze aufgestellt.

The interpretation where the lower element, Reason, takes scope over the higher, Benefactive,

?? ∃ (reason) ∀ (beneficiary)

has two question marks, the resulting number is therefore 2.

# Sentences, whose interpretation point in the opposite direction:

In most cases, positions three and four are 0. This example is one of the very rare cases which have three sentences giving one PP (Benefactive) higher than the other (Reason) and one sentence pointing in the opposite direction. Therefore, the position four is not 0.

Evaluated are the two sentences where the lower PP sits to the left of the higher, that means the two sentences with the Reason PP to the left of the Benefactive PP ((3-139) und (3-140). In this cases we expect the higher element still able to take scope over the left. Measured in this couple is the deviance of this behaviour, the degree to which this scope is judged odd or even ungrammatical.

The third entry evaluates the interpretation of the one of this couple with the existential coming first

(German) (3-139) Er hat wegen mindestens einer Sünde für jeden Heiligen eine Kerze aufgestellt.

The interpretation where the higher element takes scope over the lower

∀ (beneficiary) ∃ (reason)

has no question mark, the result is therefore 0.

The fourth entry evaluates the interpretation of the sentence with the lower element to the left, modified by the universal quantifier:

(German) (3-140) Er hat wegen jeder Sünde für mindestens einen Heiligen eine Kerze aufgestellt.

This time we get one question mark for the relevant interpretation where the higher element takes scope over the lower

? ∃ (beneficiary) $\forall$ (reason)

Therefore the resulting number for entry four is 1.

Sentences, who have salient interpretation where the element to the right takes scope of the element to the left.

In cases where the two elements compared occupy distant positions in the resulting hierarchy the higher element tends to take scope over the lower element even when sitting to the right. If this interpretation is the salient one, the sentences are marked with bold face.

The fifth entry evaluates the sentence with the lower element (Reason) to the left, modified by the existential quantifier:

(German)

(3-139) Er hat wegen mindestens einer Sünde für jeden Heiligen eine Kerze aufgestellt.

Since the reverse reading, the one with the universal taking scope over the existential, is not salient the judgement evaluates to 0.

The sixth entry evaluates the sentence with the lower element (Reason) to the left, modified by the universal quantifier:

(German) (3-140) Er hat wegen jeder Sünde für mindestens einen Heiligen eine Kerze aufgestellt.

Again, the reverse interpretation is not salient giving rise to the evaluation of 0.

When evaluating these sentences I tried not to read into the data what I expected. If you have a certain expectation it can never be excluded that this has some influence on the result. I tried as good as I could to evaluate the sentences without thinking about what I wanted it to be. I hope that I succeeded.

I want to point out that the two readings, if available, are connected with fferent intonation patterns. The following data shall exemplify this:

(German)   
(3-142) Ich habe an mindestens 'einem Tag für 'jeden Chef gearbeitet. ∃ (time) $\forall$ (beneficiary) Ich habe an 'mindestens einem Tag für jeden Chef gearbeitet. ? $\forall$ (beneficiary) ∃ (time) (German)   
(3-143) Ich habe für mindestens 'einen Chef an 'jedem Tag gearbeitet. ∃ (beneficiary)∀(time) Ich habe für 'mindestens einen Chef an jedem Tag gearbeitet. $\forall$ (time)∃ (beneficiary) (German)   
(3-144) Ich habe für 'jeden Chef an mindestens 'einem Tag gearbeitet. ∃ (time) $\forall$ (beneficiary) Ich habe für jeden 'Chef an 'mindestens einem Tag gearbeitet. $\forall$ (beneficiary) ∃ (time) (German)   
(3-145) Ich habe an 'jedem Tag für mindestens 'einen Chef gearbeitet. ?? ∃ (beneficiary)∀(time) Ich habe an jedem 'Tag für 'mindestens einen Chef gearbeitet. $\forall$ (time)∃ (beneficiary)

Each PP can formally be described as P Q DP. To get the surface order scope, stress must be on the DP of the first PP and the Q of the second. To get the reverse scope reading, primary stress has to be on the Q of the first PP and secondary stress on DP of the second PP.

# 3.3.10 Focus neutral order

It seems that in most cases sentences with two PPs in the 'Mittelfeld', which differ only in the order of their PPs, have the same extensional interpretation. That means, they denotate the same subset of events. Nevertheless there are differences in markedness and language speakers very often refute one order in certain circumstances. A first hypothesis could attribute these judgements to a difference in focus structure. The marked order can only be understood as the answer to a constituent question. In the non marked order the sentence could be the answer to the most general question, like “What did you / has the person in question do?, What happened?”

(3-146) Was hast du (gestern) getan? What did you do (yesterday)?   
(3-147) Ich habe mit einem Ball im Park gespielt. I have with a ball in_the park play.PART “I played in the park with a ball.”   
(3-148) Ich habe im Park mit einem Ball gespielt. “I played with a ball in the park.”

Unfortunately both sentences can be understood as answers, though sentence (3-148) seems to be more marked.

(German)

(3-149) Ich bin mit einem Vaporetto nach Venedig gefahren. I am with a vaporetto to Venice go.PART “I went to Venice with a vaporetto(little public boat in Venice).” (German)   
(3-150) ? Ich bin nach Venedig mit einem Vaporetto gefahren. “I went with a vaporetto to Venice.”

In this example, sentence (3-150) is very marked. But this can be due to the fact that directional PPs are not pure modifiers of verbs of movement. Like resultatives they have a argument like status and tend to be close to the verb.

(German)   
(3-151) Vincent hat wegen des besonderen Lichts in der Provence Vincent has because_of the special light in (the) Provence gemalt. paint.PART “Vincent painted in Provence because of the special light.” (German)   
(3-152) ?? Vincent hat in der Provence wegen des besonderen Lichts Vincent has in (the) Provence because_of the special light gemalt. paint.PART “Vincent painted because of the special light in Provence.2”

Here, the second sentence, (3-152), sounds very odd and cannot be answered to the question “What did Vincent do (last year)?”. It is due to interpretative processes that the second sentence is not an appropriate answer. The first sentence, (3-151), can only be interpreted with the meaning: “Vincent painted in Provence, and the reason why he did so was the special light (of Provence).”

Sentence (3-152) with focus neutral intonation will be interpreted as “Vincent painted because of the special light and the place where he did so was Provence”. This would give the special light as the reason of the painting itself, an interpretation which is counterintuitive.

English speakers confirm the interpretation for the English translation. This is additional evidence, that in English PPs to the right take scope over PPs to the left.

In a classical extensional semantics both sentences should denotate identical subsets of events.

The denotation should in both cases be the intersection of the subset of events of John painting something, of events taking place in the French region of Provence and of events done because of special light.

But this interpretation does not account for the fact, that the place is meant to be under the scope of the reason.

Sentence (3-152) can only be used as an answer to either of the questions:

(German)

(3-153) Wo hat Vincent wegen des besonderen Lichts gemalt? “Where did Vincent paint because of the special light?” and (3-154) Warum hat Vincent in der Provence gemalt? “Why did Vincent paint in Provence?”

where the focused element in the answer gets prosodic stress:

(German)

(3-155) Vincent hat in der Prov'ence wegen des besonderen Lichts gemalt.   
(3-156) Vincent hat in der Provence wegen des besonderen L'ichts gemalt.

or

The apostrophe before a vowel indicates primary stress, the constituent in focus are underlined.

Modifier PPs seem to be inserted into the sentence in a rigid base order., the higher PP takes scope over the lower. This order can be reversed by subsequent movements for at least two reasons. Getting a marked focus structure is one motivation, reversing scope properties the other.

There is strong evidence, that locative modifiers are base generated higher than reason PPs. We can see this for example with the QS test:

(German) (3-157) Vincent hat in mindestens einer Region aus jedem Grund Vincent has in at_least one region because_of every reason gemalt. paint.PART “Vincent painted because of every reason in at least on region.”

Here we get at once the interpretation with the existential quantifier taking scope over the universal. The reverse scope, though still available, is very marked.

∃ (place) ∀ (reason) ∀ (reason) ∃ (place)

If we exchange the operators we get:

(German) (3-158) Vincent hat aus mindestens einem Grund in jeder Region gemalt.

Here we get both interpretations easily, the reverse scope interpretation is even preferred:

∃ (reason) ∀ (place) ∀ (place) ∃ (reason)

This gives us clearly the place PP as base generated above the reason PP. Nevertheless, in most descriptive grammars on German, reason modifiers appear to their left. This can be attributed to their scope characteristics. Reason modifiers tend to take a greater constituent into their scope.

In the example presented here, the first PP that is merged above the VP is the reason PP. It follows the merging of the locative PP. If no further movements take place, we get the sentence:

(German) (3-159) Vincent hat in der Provence wegen des besonderen Lichts gemalt.

Automatically ‘wegen des besonderen Lichts’ has in its focus only the VP, which does not make much sense. Further movements have to take place to reverse the scope. If a certain focus structure is required, further movement might be necessary, maybe with the effect of arriving at the original order as in the case of

(German)

(3-160) Vincent hat in der Prov'ence wegen des besonderen Lichts gemalt.

or

(3-161) Vincent hat in der Provence wegen des besonderen L'ichts gemalt.

If we take another example where the most natural interpretation does not require the locative in the scope of the reason PP we get a result, that is more in tune with the base order:

(German)

(3-162) Hans wurde in Bad Kreuznach wegen Rheuma behandelt. Hans was in Bad Kreuznach because_of rheumatisms cured “Hans was cured because of Rheumatism in Bad Kreuznach.”

(German) (3-163) ? Hans wurde wegen Rheuma in Bad Kreuznach behandelt.

In (3-162), the locative PP (‘in Bad Kreuznach’) and the reason PP (‘wegen Rheuma’) can be interpreted as independent modifiers of the nuclear proposition ‘Hans wurde behandelt’. The sentences

(German)

(3-164) Hans wurde wegen Rheuma behandelt.   
(3-165) Hans wurde in Bad Kreuznach behandelt.

are both grammatical.

However, (3-163), ‘? Hans wurde wegen Rheuma in Bad Kreuznach behandelt’ is slightly degraded. It becomes better, if we interpret ‘in Bad Kreuznach’ as being under the scope of the Reason modifier (meaning he was cured anyway , but the reason why this took place in Bad Kreuznach was the special disease). With a special focus intonation the second sentence becomes also acceptable, without changing the scope relations.

This example shows, that the base order of modifiers does not always coincide with the ‘unmarked’ order or the order that is found most in a statistical research over a corpus.

# 3.3.11 Informational focus (IF)

Informational focus gives rise to an interesting asymmetry concerning word order. This observation was made by Lenerz(1977). A good description of the effect is found in Cardinaletti and Giusti (1996: 63 f).

The informational structure of sentences can often be divided in a part conveying old information and a part conveying new information. The topic represents the old information, which repeats a part of speech that has been mentioned before or paraphrases entailments drawn from the context. It is the part the sentence about which the speaker wants to tell us something. The focus represents this something, the new information. A classical – but not the only example is the answer to a constituent question. It normally repeats part of the question and adds as new information the questioned constituent. If the question is

(3-166) What did John buy?

a possible answer is (3-167) John bought a book.

where ‘John’ is the topic and ‘a book’ the focus.

Double object constructions in German reveal a peculiarity regarding the information structure. If the indirect object is questioned, the orders indirect object – direct object or direct object – indirect object are both possible in the answer. If the direct object is questioned, only the order indirect object – direct object is valid. This effect is often taken to show that ‘indirect object – direct object’ represents the underlying base order.

(German)

(3-168) Ich habe dem Kassierer das Geld gegeben. I have the.DAT cashier the money give.PART “I gave the money to the cashier.”   
(3-169) Wem hast du das Geld gegeben? “To whom did you give the money?”

Was hast du dem Kassierer gegeben? “What did you give to the cashier?”

(3-173) Ich habe dem Kassierer das Geld gegeben.   
(3-174) ? Ich habe das Geld dem Kassierer gegeben.

We can clearly detect the asymmetry and assign the base order to the sentence:

(3-175) Ich habe dem Kassierer das Geld gegeben.

This test turns out to be valid for adverbial PPs as well.

# Temporal – Locative

(3-176) Hans hat am Sonntag in München geschlafen. Hans has on Sunday in Munich sleep.PART “Hans slept in Munich on Sunday.”   
(3-177) Wo hat Hans am Sonntag geschlafen? Hans hat am Sonntag in München geschlafen. ?? Hans hat in München am Sonntag geschlafen.   
(3-178) Wann hat Hans in München geschlafen? Hans hat in München am Sonntag geschlafen. Hans hat am Sonntag in München geschlafen.

The comparison shows, that in all cases the questioned modifier can be found to the right of the other. But to the left we find the questioned modifier only in one of the cases. If we generalize the idea of Lenerz, it is the higher modifier that we find to the left if focalised.

As in the case of the QS Test there is rarely a clear case where only in one case both answers are equally available and in the other case one answer is good, the other totally ungrammatical. Again, I had to look at asymmetries.

For each combination of PP types I constructed two constituent questions, for each PP type one. I then evaluated the possibility of having the focussed element to the left.

One ‘?’ indicates that both orders are available for both questions, but comparing the two answers with the focussed element to the right the one with the question mark is more marked. This is the weakest kind of asymmetry to be found.

Two question marks, ‘??’ are given to a sentence if it is remotely possible, but very marked, as an appropriate answer.

The asterisk, ‘\*’, marks sentences that are clearly impossible as answers to the question.

Sometimes the sentence with the focussed element to the left is preferred to the other order, especially when this PP is much higher in the hierarchy with respect to the other. In this case, I give the sentence in bold type.

The result of the evaluation is a pair of numbers. The first number is the sum of ‘?’, the asterisk counting as three. The second number is one, if the valid sentence with the focussed element to the left is in bold, otherwise it is zero.

# 3.3.12 Role disambiguation

Some German prepositions are ambiguous with respect to the thematic role they are related to. The preposition ‘mit’ could be related to many different roles: Instrumental, Comitative (these two share in many languages the same prepositions, e. g. in English ‘with’, in Italian ‘con’), Means of Transportation and Manner:

# Instrumental:

(3-179) Ich öffnete die Tür mit meinem Schlüssel. “I opened the door with my key.”

# Comitative:

(3-180) Ich ging mit Helga ins Kino. “I went with Helga into the cinema.”

# Manner:

(3-181) Er öffnete den Safe mit großem Geschick. “He opened the safe with great skill.”

Furthermore, we find the same preposition in some quasi-fixed expressions with the meaning of volitional modals

(German)

(3-182) Mit Absicht ließ sie ihren gläsernen Schuh zurück. With intention left she her glass(adj.) shoe back “Intentionally she left her glass shoe.”

# or epistemics

(German)

(3-183) Mit großer Wahrscheinlichkeit wird der Prinz sie finden. With great probability will the prince her find “Probably, the prince will find her.”

and many others. Most of them can be distinguished by semantic features of the noun that they select. So Comitative selects in the usual case a noun with the feature $[ + \mathrm { h u m } ]$ , whereas Instrumentals normally are not compatible with it. But in the rare cases where the same noun can be object of two identical (homophonous) prepositions, we would expect an influence of the position of the

PP to semantic disambiguation, if we are right in stipulating a fixed order for modifiers.

So let's assume for a moment that the Trojan horse had the name Archimedes. Then we can formulate the sentence:

(German)

(3-184) Odysseus eroberte Troja mit Archimedes. “Odysseus conquered Troja with Archimedes.”

Here, Archimedes is clearly instrumental. But if it is a name of a combatant it becomes commutative. Now if we put two together:

(German)   
(3-185) Odysseus eroberte Troja mit Achilles mit Archimedes. “Odysseus conquered Troja with Achilles with Archmides.” (German)   
(3-186) ? Odysseus eroberte Troja mit Archimedes mit Achilles. “Odysseus conquered Troja with Archimedes with Achilles.”

The second sentence, (3-186), becomes odd. If a German speaker would not know, which of the two, Achilles or Archimedes, is the instrument and which is the combatant he would clearly interpret always the first as combatant and the second as the instrument.

We can take this as an indication, that the Comitative is higher than the Instrumental. A good example is provided by Temporal and Locative ‘in’.

Think of a scientist of musical history, who worked the whole year on Vivaldi's ‘Four Seasons’. Let's call him John. One of his friends tells another that John has discovered some clues inside one of the parts and he says:

(German)

(3-187) Hans hat im Herbst im Frühling etwas Ungeheures John has in_the autumn in_the spring something incredible entdeckt. discovered “John discovered something incredible in the spring in autumn.”

This could only mean that John had discovered something in the part entitled ‘Frühling’ and he did so in the time of autumn. If we change the word order:

(German)

(3-188) Hans hat im Frühling im Herbst etwas ungeheures entdeckt.

we get a different interpretation. ‘Frühling’ becomes the temporal and ‘Herbst’ the name of the music piece. If we take the name of the music piece to be an abstract locative description, we get:

# Result (RD):

# Temporal $>$ Locative

If we are able to establish this to be a good test, we get a clear proof that word order between adjuncts is syntactically fixed.

# 3.3.13 Pair – List reading (PLR)

B. Bruening, following R. May (1988), observed certain asymmetries in the interaction of Wh-operators and universal quantifiers (Bruening 2001). Some questions, such as:

(3-189) Which sheet did he drape over every armchair? (3-190) Which book did he give to every student?

allow two different answers. The first possibility is to answer with a single constituent.

(3-191) It was the black sheet that he draped over every armchair.   
(3-192) It was ‘The Minimalist Program’ that he gave to every student.

But for both sentences we can possibly get a list of pairs as an answer. Each answer consists of an instance of the questioned constituent and an element over which the universal quantifier quantifies. In the case of the first question we can get:

(3-193) He draped the black sheet over the large armchair, the white sheet over the small armchair and the green sheet over the old armchair.   
(3-194) He gave ‘The Minimalist Program’ to Francesco, ‘The Antisymmetry of Syntax’ to Soon and ‘Adverbs and Functional Heads’ to Luigi.

The latter interpretations are called ‘pair – list readings’. They are not available for the following sentences:

(3-195) Which armchair did he drape every sheet over? (3-196) Which wall did he spray with every color of paint?

The only possible answers are single constituent answers. (All examples from Bruening 2001: 236 f.). The effect is considered by Bruening and May to be analogous to quantifier scope ambiguities.

I tried to apply the test for detecting asymmetries between two different PP types. I expected to get pair list readings only in the case when the lower PP is fronted as Wh-word. In base position it would be under the scope of the universal quantifier of the higher PP, which would give rise to the pair-list reading.

I constructed sentences with a Wh-phrase, which questions a prepositional modifier. In the Mittelfeld is modifying PP containing a DP with a universal quantifier.

(German)

(3-197) Wo hat Hermann an jedem Tag gespielt? Where has Hermann on every day played “Where did Hermann play each day?”

This question is ambiguous: the first reading questions the (unique) place where Hermann did play every day. The answer could be simply “Wimbledon” if Hermann played every day in Wimbledon. The second reading asks for a list of pairs, where each pair consists of a place and a day, e.g. “(Wimbledon, Monday), (New York, Tuesday), (Leimen, Wednesday)...”.

If the questioned PP had scope over the universal, before movement, we don't expect the pair-list reading (at least less available):

(German)

(3-198) Wann hat Hermann in jeder Stadt gespielt? When has Hermann in every town play.PART “When did Hermann play in every town?”

This time the salient interpretation is clearly the one of a question that asks only for a single constituent. We do get a pair-list reading, but with a greater effort than in the first example.

# 3.3.14 Reference to events

I got the idea for this test after a discussion with J. Higginbotham about event structure.

Neutral anaphors like ‘it’ or ‘something’ can refer to neutral objects as well as to events. They seem to be under-specified to a high degree. Take the following discourses:

(3-199) Yesterday I saw a pig on the street. It was pink and had blue dots all over its body. The pig dropped little green apples with red stripes. It was disgusting.   
(3-200) Van Gogh painted a pink pig with his thin paintbrush, something he has never done before.

In (3-199), the first ‘it’ clearly refers to the DP ‘a pig’, the most salient interpretation of the second ‘it’ relates it to the event of ‘the pig dropping green apples with red stripes’, but ‘it’ could also simply refer to ‘the pig’. In (3-200) the anaphoric ‘something’ could either take up the event of painting a pink pig or the event of painting a pink pig with his thin paintbrush. So (3-200) is ambiguous and could mean either that Van Gogh had painted a lot of pink pigs before, but never with his thin paintbrush or that he had never painted any pink pig before.

This ambiguity is unexpected under a Davidsonian analysis of events variables, where the antecedent sentence would roughly have an interpretation in LF as:

∃ e [ paint(Van Gogh, a pink pig, e) & with(his thin paint brush, e) ] where there is only one event variable available to which the predicates apply. It seems more plausible, that we would have at least two event variables e and $\mathbf { e ^ { \prime } }$ , which enter LF in the more adequate form:

∃ e ∃ e' [ ${ \bf { e } } ^ { \prime } =$ with(his thin pain brush, e) & $\mathrm { e } =$ paint(Van Gogh, a pink pig) ]

Here events are identified as full-saturated predicates, i.e. predicates with all their arguments. The lowest event is the semantic verb together with the subject and all objects. The modifiers become under this view predicates with at least a lower event variable as argument. Once saturated, they themselves become events. The under-specified anaphor can refer either to e or to e'. In the first case it refers only to the act of painting a pink pig. But in the second case to the full act of painting a pink pig with a thin paint brush. Note, that you can substitute the argument e of the with-predicate by the full lower predicate, so an equivalent form would be:

∃ e ∃ e' [ ${ \bf { e } } ^ { \prime } =$ with(his thin pain brush, $\mathbf { e } =$ paint(Van Gogh, a pink pig) )]

Thus $\mathbf { e ^ { \prime } }$ includes the whole event, described by the sentence.

If we take German sentences with two PPs, we get ambiguities of the above type, but an additional surprising result:

(German)   
(3-201) Van Gogh hat in Arles mit Tusche ein Café gemalt, Van Gogh has in Arles with Indian_ink a coffeehouse painted etwas was er vorher noch nie gemacht hatte. something, what he before until_now never done had. “Van Gogh painted a coffeehouse with Indian ink in Arles, something he had never done before.” (German)   
(3-202) Van Gogh hat in Arles mit Tusche ein Café gemalt, etwas was er vorher noch nie gemacht hatte.   
etwas $=$ “to paint a coffeehouse” or “to paint a coffeehouse with Indian ink” or “to paint a coffeehouse with Indian ink in Arles”   
\* $=$ “to paint a coffeehouse in Arles” (German)   
(3-203) Van Gogh hat mit Tusche in Arles ein Café gemalt, etwas was er vorher noch nie gemacht hatte.   
etwas $=$ “to paint a coffeehouse” or “to paint a coffeehouse with Indian ink” or “to paint a coffeehouse with Indian ink in Arles” or “to paint a coffeehouse in Arles”

As the example shows, the anaphor is 4 times ambiguous in (3-202) but only 3 times ambiguous in (3-201). In (3-201), where the PPs seem to be in the original, the basic order, the inner PP cannot be skipped in the interpretation of a possible antecedent for ‘etwas’. The possibility of skipping ‘in Arles’ in (3-202) could be an indication, that the first phrase is syntactically ambiguous, i.e. the phrase could be expressed by two different syntactic trees, which could give rise to different event interpretations:

(German)   
(3-204) Van Gogh hat [mit Tuschei] [[[in Arles[ti]] [ein Café gemalt]]], etwas was er vorher noch nie gemacht hatte. (German)   
(3-205) Van Gogh hat [[[mit Tusche] [[in Arles] [ein Café gemalt]]], etwas was er vorher noch nie gemacht hatte.

It is important to note that the referential ambiguity of the neutral anaphor is of semantic nature. This can be seen by clear monoclausal cases:

(3-206) Dass Van Gogh in Arles mit Tusche ein Café That Van Gogh in Arles with Indian_ink a coffeehouse gemalt hat,war etwas neues für ihn. painted has, was something new for him “It was (something) new for Van Gogh to paint a coffeehouse with Indian ink in Arles.”

Here, the neutral anaphor ‘etwas’ can only refer to the whole extended VP ‘to paint with Indian ink in Arles a coffeehouse’. The other interpretations are no longer available.

However, this behaviour could be explained if we can show that it is systematic and in some relation to the other asymmetries. If this turns out to be true, we have an additional test, which is by nature semantic, but seems to shed light on the syntactic structure.

I used in the examples for the second phrase of the sentences nearly always the expression ‘..., etwas was er vorher noch nie gemacht hatte’ (..., something he had never done before). Unfortunately it doesn't combine with phrases containing a definite temporal PP (since it is trivial that you have never done a certain thing on Friday before that Friday). So I chose for the combinations with temporals the phrase ‘..., etwas was er sich vorher nicht zugetraut hätte.’ (..., something he hadn't believed to be capable of).

# 3.4 Word order in the German Mittelfeld

# 3.4.1 The description in Heidolph et al. (1981: 707 ff.)

We find the best descriptive overview over the German sentence structure in Heidolph et al. (1981). Though sentence constituents in German can move more freely than in English, there are, according to Heidolph et al. (1981), several distinguished positions which represent the unmarked surface order of these elements. With the help of the Infinitival Complex Test the authors manage to distinguish the following sections:

13 Subj Subject

AdvbIII 12a Temp 12b Reason

Temporal modifier Reason modifier

# Praedikatsgruppe

# AdvbII

11 Loc Locative modifier   
10 Instr Instrumental adverbial /Manner adverbial   
9 ObjInd Indirect object   
8 ObjDir Direct object, either a PP or NP in Accusative, Dative or   
Genitive

# Engere Prädikatsgruppe

Advb   
7 LocObj Locative modifier, related to accusative object   
6 DirAbs Absolute determination of direction   
6a DirAbsS Source   
6b DirAbsM Means   
6c DirAbsG Goal   
5 DirRel Relative determination of direction

# Predicate

4 Pred Predicative, thematic Expression, could be NP, AP or PP   
3 Vz ‘Verbzusatz’ (separable prefix)   
2 V Main verb (semantic verb(s))   
1 Aux Temporal and modal auxiliaries   
0 fin Finite verb

Positions 13 and 12 can be found in the Vorfeld (only one).

The Mittelfeld is divided into ‘Prädikatsgruppe’ and ‘Engere Prädikatsgruppe’ where we find arguments and modifiers. The elements in the lower part, the ‘Engere Prädikatsgruppe’ have argumental or quasi argumental status which have a very close connection with the verb.

‘Predicate’ can roughly be identified with the right verb bracket. I don't want to discuss this order in detail. Of interest here is the thematic order of modifiers:

# Temporal $>$ Reason $>$ Locative $>$ Instrument $>$ Source $>$ Means $>$ Goal

It should be mentioned, that this order is mainly descriptive. The Infinitival Complex Test, which the authors used did not distinguish between argumental and pure modifying PPs, nor did it try to avoid combinations of PPs where one

tends to be in the scope of the other for semantic reasons (see the discussion above for the Focus Neutral Order test).

# 3.4.2 The data according to R. Hinterhölzl:

A more recent research is presented in Hinterhölzl (2000). Basic for detecting base order are intonation patterns:

We assume that sentences with neutral intonation correspond to the unmarked or basic word order, from which sentences with marked word order (often accompanied with a special intonation pattern) are derived by additional movement.

(Hinterhölzl 2000: 296)

As I stated above in the section about Focus Neutral Order test, we cannot directly deduce from intonational neutral order the base orders. Unmarked, in the sense of more frequent or in the sense of neutral topic-focus structure, does not necessarily mean base generated.

From the positioning of constituents in relation to negation and modal adverbs, Hinterhölzl arrives at the general conclusion:

a) Nominal complements of the verb always have to leave the VP before Spell-out (independently of whether they are definite or indefinite) and are licensed in functional projections above the position of manner adverbs. b) Also small clauses, idioms and directional PPs have to move out of the VP and are licensed in a position below manner adverbs.

(Hinterhölzl 2000: 304)

Apart of this, Hinterhölzl does not give us a rigid order between modifiers. He distinguishes VP adverbs (VP-Advs) and sentential adverbs (S-Advs). S-Advs appear to the left negation, VP-Advs to the right.

The NPs that move out of the VP are divided into long-scrambled NPs (LNPs), which appear to the left of sentential adverbs, and short-scrambled NPs (S-NPs), which sit between the negation and the VP-Advs.

We get:

L-NPs S-Advs Neg S-NPs VP-Advs V

Another more recent research which regards modifier positions is presented in Frey and Pittner (1998). The authors use several tests to determine the base order of modifiers in the Mittelfeld:

1. Focus Neutral Order   
2. Informational Focus   
3. Principle C-violation   
4. Question pronouns used as indefinites   
5. VP-topicalisation   
6. Quantifier Scope

Applying these tests to modifiers, they manage to establish five distinct groups:

1. Prozessbezogene Adverbiale (process-related modifiers)

These are mainly manner modifiers. Their positions is behind the direct object. In their base position they C-command the main predicate. Examples are:

(German)

(3-207) schüchtern “timidly”   
(3-208) auf bestimmte Art und Weise “in a certain manner”

2. Ereignisbezogene Adverbiale (event-related modifiers)

These are modifiers such as Instrumentals, Locatives and Comitatives. They are C-commanded by the (surface position of the) subject and C-command the direct object. Examples are:

(3-209) mit dem Schraubenzieher “with the screwdriver”   
(3-210) mit einem Freund “with a friend”   
(3-211) im Stadion “in the stadion”

# 3. Ereignisinterne Adverbiale (event-internal modifiers)

Here we find modifiers that characterise the attitude of the subject towards the action or some of its inner states that accompany the action. We find them also between subject and object. Examples are:

(3-212) absichtlich “intentionally”   
(3-213) gerne “with pleasure”

4. ‘Satzadverbiale’ (sentential modifiers)

These are Temporals, Epistemics and Evidentials. They C-command all principle arguments of the verb.

(3-214) wahrscheinlich “probably”   
(3-215) angeblich “allegedly”   
(3-216) erfreulicherweise “happily”

5. ‘Frame’- and ‘Bereichsadverbiale’ (frame modifiers)

These are modifiers that give a frame in relation to which the rest of the proposition can be evaluated. They can be viewed as a topic. Their base position is in the middle field and they C-command the base position of every other constituent. Examples are:

(3-217) juristisch betrachtet “seen from a legal point of view”   
(3-218) aus medizinischer Sicht “seen from a medical point of view”

Pittner and Frey claim that between these classes there are strict ordering relations, which are attributed to base generations. But between modifiers of the same class there are no syntactic motivated base orders. If we prefer one order or another, this would be attributed to semantic reasons. Thus we could have in one sentence two elements of the same class, but their order is (syntactically) free.

I want to present their reasoning with the example of Comitatives and Instrumentals.

(German)

(3-219) Er hat (zusammen) mit einem Freund He has (together) with a friend mit einem Kleintransporter den Schrank herbeigeschafft. with a truck the cupboard brought_here “He brought the cupboard with a truck (together) with a friend.”

(German) (3-220) ? Er hat mit einem Kleintransporter (zusammen) mit einem Freund den Schrank herbeigeschafft. (Frey and Pittner 1998: 22)

The authors confirm that there exists a tendency to prefer Comitatives in front of Instrumentals, but they believe this to be a only attributed to non-syntactic processes. They try to support this with several syntactic tests.

The QS Test produces:

(German)

(3-221) Er HAT mit mindestens einem Freund He HAS with at_least one friend mit fast jedem Transporter Waren herbeigeschafft. with nearly every truck goods brought_here “He brought goods with nearly every truck with at least one friend.”

(3-222) ? Er HAT mit mindestens einem Transporter mit fast jedem Freund Waren herbeigeschafft.

(Frey and Pittner 1998: 22)

The authors claim that both sentences are non-ambiguous giving only scope of the existential over the universal operator. I get in (3-222) also the reverse interpretation with scope of the universal over the existential operator. This becomes more clear if we put the main stress on the first syllable of ‘mindestens’.

A test with VP-topicalisation produces the sentences:

(German) (3-223) Mit dem Kleintransporter Waren herbeigeschafft hat er heute (zusammen) mit seinem Onkel.

(German) (3-224) ? (Zusammen) mit seinem Onkel Waren herbeigeschafft hat er heute mit dem Kleintransporter.

(Frey and Pittner 1998: 23)

Though the authors confirm the different acceptability, which posits the Instrumental closer to the verb, they attribute, however, to semantic preferences.

Wh-pronouns used as indefinites give us:

(German)

(3-225) weil er mit wem mit einem Lastwagen because he with someone with a truck Waren herbeigeschafft hat. goods brought has “because he brought goods with a truck with someone.”

(3-226) weil er mit was mit einem Bekannten because he with what with an acquaintance Waren transportiert hat goods transported has “because he transported good with a friend with somewhat.”

(Frey and Pittner 1998: 23)

I agree that these sentences do not exhibit much difference, but if we use both wh-pronouns in one sentence we get much clearer results:

(German)

(3-227) weil er mit wem mit was Waren transportiert hat because he with someone with something goods transported has “because he transported goods with somewhat with someone”

(German)

(3-228) \* weil er mit was mit wem Waren transportiert hat.

Though (3-227) is not very common, to me it sounds correct. (3-228), however, is totally out.

Their last test to support the hypothesis of belonging to the same class is the IF Test:

(German)   
(3-229) Mit wem hat er mit einem Kleintransporter den Schrank herbeigeschafft? “With whom did he bring the cupboard with a truck?” (German)   
(3-230) Er hat (zusammen) mit einem FREUND mit einem Kleintransporter den Schrank herbeigeschafft.

(German) (3-231) Womit hat er zusammen mit einem Freund den Schrank herbeigeschafft? “With what did he bring the cupboard together with a friend?”

(German) (3-232) Er hat mit einem KLEINTRANSPORTER (zusammen) mit einem Freund den Schrank herbeigeschafft. (Frey and Pittner 1998: 23)

I admit, that the second order is possible, though the first seems more natural to me. I want to refer here to my own data which give a better contrast:

(German)

(3-233) Mit wem ist Klaus mit dem Porsche gefahren? Klaus ist mit Gisela mit dem Porsche gefahren. Klaus ist mit dem Porsche mit Gisela gefahren.   
(3-234) Womit ist Klaus mit Gisela gefahren? Klaus ist mit Gisela mit dem Porsche gefahren. \* Klaus ist mit dem Porsche mit Gisela gefahren.

(These examples can be found in Appendix A under the combination ‘MeansComitative’ since I make distinction between Means of Transportation and Instrumental.)

The resulting order of Mittelfeld-modifiers for Pittner and Frey is:

1. Frame und Bereichsadverbiale   
2. Satzadverbiale   
3. Ereignisbezogene Adverbiale   
4. Ereignisinterne Adverbiale   
5. Prozessbezogene Adverbiale)

With this order they give a finer grading of Modifier with respect to former distinction between sentential modifiers and VP-modifiers as we find for instance in the work of Hinterhölzl.

# 3.4.4 Recent works by W. Frey

Using the same techniques Frey (2003) presents a slightly different view on modifying positions, this time looking more in detail on prepositional modifiers. He does not end up with a fixed grid of distinct position but proposes rather a model where different modifier classes have to obey certain Ccommand relations with the arguments of the main predicate. He distinguishes five major classes:

1. Sentence adjuncts , i.e. modifiers by which the speaker estimates the proposition expressed by the clause. Main representants of this class are evaluatives ( 'erstaunlicherweise', 'surprisingly'), evidentials ('offensichtlich', 'apparently') and epistemic modifiers ( 'wahrscheinlich', 'probably'). Their base position C-commands the finite verbal form, the base position of all the arguments and the base position of the other classes.   
2. Frame adjuncts. He refers with this term to certain modifiers that restrict the claim which the speaker makes by his assertion, presented also by Maienborn (1998). These are mainly locative expression ('In Deutschland bin ich weltberühmt', 'In Germany I am world-famous') but also some temporals $\mathrm { ~ ? m ~ } 1 6$ . Jahrhundert haben in Deutschland Mönche viel Bier getrunken', 'In the 16th century monks drank a lot of beer'). Their base position C-commands the base positions of the arguments and the base positions of the following classes.   
3. Event-related adjuncts. These are mainly modifiers that position an event in a time frame such as 'gestern' ('yesterday') or 'vor einer Woche' ('a week ago'). Frey also subsumes causal modifiers under this class and gives as example the sentence 'For Mary's valour she was awarded a purple heart.' I want to point out here, that this seems not to correspond to my class of Reason modifiers, which in English are usually introduced by ‘because of’. The 'for'- PPs seems to have more the status of selected by the verb 'awarded'. The base position of this class C-commands the base position of the arguments and the base position of the following classes.   
4. Event-internal adjuncts, Type I. These comprise the majority of my thematic roles: Locative, Instrumentals, Comitatives, Benefactives. Their base positions are C-commanded by a highest ranked argument in the extended projection of the lexical verb.   
5. Event-internal adjuncts, Type II. Here we find mental-attitude modifiers such as 'freiwillig' ('deliberately') and 'versehentlich' ('inadvertently'). Their base positions are C-commanded by a highest ranked argument in the extended projection of the lexical verb.   
6. Process-related adjuncts. )These are Manner modifiers such as 'heftig' ('strongly') or 'auf jede Art und Weise' ('in every way'). Their base positions minimally C-command a base of the lexical verb.

The most important result which is of interest here is the order of the modifying PPs. On highest position we find the Temporals, on lowest position Manner PPs. In the middle we find as a block all the rest. As I will show below, the order corresponds to the one that I established with my tests, the main difference being the fact, that I managed to dissolve the middle block into a sequence of distinct positions. As for the status of Frey's causal modifiers, I cannot give a clear correspondence to my thematic roles.

# 3.5 My data

# 3.5.1 General methodology

I concentrated on three tests, namely the QS Test, the IF Test and the PLR Test. They proved to be easily applicable to German and to work with most combinations of PP types. With PP types I intend PPs which bear a certain thematic role.

In order to give valid results, each test has to result in a linear order. To define an order, the relation between two PPs A and B of different type has to be

1. antisymmetric: no PP type A can be higher than a PP type B and at the same time lower.   
2. transitive: If PP type A is higher than PP type B and B is higher than PP type C, then A has to be higher than C.

In order to be linear, the order has also to be

3. total: For all distinct PP types A and B, there has to be relation which sets one of them higher.

Since the test give in some cases very subtle results I decided to apply all three tests on every possible combination. Thus we could get in the end an evaluation of the tests themselves.

I started with the presentation of Temporals. Then I added Benefactives and applied the tests to the combination of both. At the next level I added Reason PPs. I applied the tests to every possible combination among the three. In this way I added at each level another PP type – or thematic role. Of course the number of possible combinations increases at each level by one. Since I had 14 principal PP types we get $1 3 + 1 2 + 1 1 + . . . + 3 + 2 + 1 = 9 1$ combinations.

I tried to use examples with only pure modifying PPs and never use PPs where one is modifying the other or the DP of the other.

Another obstacle regards ‘natural scope’. As showed in the discussion of Focus Neutral Order, there are combinations of PPs, where one tends automatically to be interpreted in the scope of the other:

(3-235) Vincent hat wegen des besonderen Lichts Vincent has because_of the special light in der Provence gemalt. in the Provence paint.PART “Vincent painted in Provence because of the special light.”

Here ‘in der Provence’ will be interpreted automatically under the scope of the Reason modifier. Certainly these dependencies influence the results of the tests in an unwanted manner. I therefore tried to accept only examples where both PPs can be understood as independent modifiers of the pure VP.

# 3.5.2 The main thematic roles

The fourteen PP types corresponding to thematic roles that I chose are not exhaustive. There are probably many others, some of which I will name below. The 14 types that I chose for the first research were compatible with all three tests. They are:

# 3.5.2.1 Temporal

These expressions determine the time interval in which the actual event takes place. It could be a month, an hour, a year, a certain day etc. The preposition in German is either ‘an’/‘am’ (with day), ‘um’ (with time) or ‘in’ (with month, year, season):

Am Sonntag (On) sunday Am gestrigen Tag Yesterday Um 14 Uhr At 2 pm Im Dezember In December Im Jahre 1492 In 1492 Im Herbst In autumn

# 3.5.2.2 Benefactive

The Benefactive introduces a participant who benefits from the action done by the actor. In German the preposition is always ‘für’.

Für seine Frau For his wife Für seinen Chef For his boss

Maybe this role must be distinguished from similar roles, often realised by the same proposition, which express someone who gives the order for the action or someone who has been substituted by the subject. I tried to stick to the above definition.

# 3.5.2.3 Reason

This role determines the reason, why a certain action was done. Typical prepositions are ‘wegen’ and ‘aus’:

wegen einer Krankheit because of illness aus Angst because of fear

As I pointed out above, reason modifiers are more sensitive to scope effects than most of the other types. There is a big difference between ‘playing in the park because of the nice weather’ and ‘playing because of the nice weather in the park’.

# 3.5.2.4 Locative

This is maybe the most common, in any case the most described thematic role. It determines the place where the action takes place. This is usually done by relating this to an object, described by a DP. A great variety of prepositions make this relation explicit.

in Venedig in Venice hinter der Schule behind the school vor der Schule in front of the school neben der Schule beside the school auf dem Tisch on the table unter dem Tisch under the table über dem Tisch above the table

Each of these preposition describe a different relation, a fact which gave rise to put propositions in the set of lexical elements (as opposed to functional elements). But several of those can be used also with other thematic roles:

im $( =$ in dem) Dezember in december (Temporal) über Mathematik about mathematics (Matter) auf mannigfache Weise in manifold ways (Manner)

This fact gave rise to the idea that all prepositions are originally locative and changed their meaning and usage, partly to become case assigners. (See for instance Anderson 1971).

In some languages the same relation can be expressed by different prepositions. The ‘in-‘ relation in Italian is expressed by ‘in’ together with country names, but by ‘a’ with city names:

a Venezia in Venice in Italia in Italy

# 3.5.2.5 Instrumental

This thematic role determines the instrument, the tool, which was used in order to commit the action. In German this role is exclusively realised by the preposition ‘mit’.

mit einem Schraubenzieher with a screwdriver

Since the same prepositions is used with Comitatives and Means, they are often confused with each other. I am not very sure whether Means and Instrumental take different positions. But Comitative and Instrumental have rather different semantics and sit in distinct positions.

# 3.5.2.6 Manner

This is maybe the most problematic group. Prepositional modifiers determine the manner in which a certain action was done. Frequently used prepositions introducing this theme role are ‘mit’ and ‘auf’. Speed modifiers are very often subsumed under this category. Since Cinque establishes frequentative and celerative adverbs as own classes in his hierarchy, I was careful which expressions to use. In order to be always in the same class, I constructed examples with PPs of the type.

auf besondere Art und Weise in a special way

If taken in a broader sense, you would find examples such as:

mit Vorsicht carefully mit hoher Geschwindigkeit with high speed

# 3.5.2.7 Comitative

Comitatives add a person, which share the role of the subject. If the subject is an agent, they are semantically also agents. But these additional agents are not introduced via coordination, but by means of a prepositional modifier. The accompanying preposition is in many languages the same as the one introducing instruments. In German this is ‘mit’, in Russian ‘s’, in English ‘with’ and in Italian ‘con’. I do not think, this is a sheer coincidence, but for the moment I have no explanation for it. The syntactic test show clearly that its position is much higher than the one of the Instrumental.

mit einem Kollegen with a colleague

# 3.5.2.8 Evidential

This group of prepositional modifiers adds the source of the proposition. This can be a person, but legends, stories and rumours can also be stated. German has two adpositions, which introduce them, ‘nach’ and ‘gemäß’. Both can be used as prepositions or postpositions. ‘Nach’ is more common with non human DPs. ‘Gemäß’ as preposition can have either a genitive or a dative complement; as postposition it always follows a dative DP.

einem Zeugen gemäß according to a witness gemäß eines Zeugen according to a witness nach einer alten Legende according to an old legend einer alten Legende nach according to an old legend

# 3.5.2.9 Matter

With these somehow artificial term I named a group of modifiers that give the topic of a talk, the subject of research or a book. In German it is used with the preposition ‘über’

über Mathematik about mathematics

# 3.5.2.10 Goal

This is a special kind of directional modifier which adds the goal of a movement. Since in many languages you can use nearly the same prepositions as with Locatives, Directionals and Locatives are often grouped together. In English you have to add the particle ‘-to’ to some of the locative prepositions: ‘into’, ‘onto’, others like ‘under’ are ambiguous. The preposition ‘to’ by itself is only directional. In German, all locative prepositions can be used in directional goal modifiers. Additionaly, there exists ‘nach’

nach Hamburg to Hamburg

# 3.5.2.11 Source

Source modifier specify the origin of a movement. They belong to the group of Directionals and are also related to locatives. In many languages, combinations of a preposition like ‘from’ and locative preposition are used together to form something like ‘from under’. Standard German does not allow for this construction, but several dialects have it (‘von unter der Brücke’). Source modifiers are usually introduced by ‘von’.

von München from Munich

# 3.5.2.12 Path

In addition to source and goal of a journey we can name a place, which has been passed by. In German, the preposition ‘über’ introduces the place, sometimes you find ‘durch’.

über Mainz through Mainz durch Mainz through Mainz

# 3.5.2.12 Malefactive

This modifier adds an opponent, an obstacle to the proposition, a person or a weather condition which wants to block the action. Malefactives can also introduce a rival. Principal preposition in German is ‘gegen’

gegen das schlechte Wetter against the bad weather gegen seinen Erzkonkurrenten against his arch-rival

# 3.5.2.13 Means

This term is meant as abbreviation for ‘Means of Transportation’. Cars, public busses, bicycles, airplanes are all examples of instruments, which can be used for movement. It is not clear, whether this thematic role has to be distinguished from Instrumentals. But since verbs of movement have a particular behaviour, I decided to make this distinction. The results showed, that Instrumentals and Means PPs are close neighbours, if separate at all. In German as in many other languages, they share the same preposition ‘mit’. In English, Means modifiers are often introduced by ‘by’.

mit dem Bus by bus mit einem Ferrari with a Ferrari

# 3.5.3 One example of the data

I want to give here the example of the combination of locative and temporal PPs.

# Locative – Temporal

# Quantifier Scope

(German)

(3-236) Er hat an mindestens einem Tag in jedem Bett geschlafen. He has on at_least one day in each bed sleep.PART “He slept in each bed on at least one day.” (German)   
(3-237) Er hat an mindestens einem Tag in jedem Bett geschlafen. ∃ (time) $\forall$ (place) $\forall$ (place) ∃ (time) (German)   
(3-238) Er hat in mindestens einem Bett an jedem Tag geschlafen. ∃ (place) $\forall$ (time) $\forall$ (time) ∃ (place) (German)   
(3-239) Er hat in jedem Bett an mindestens einem Tag geschlafen. ∀(place) ∃ (time) ∃ (time) $\forall$ (place) (German)   
(3-240) Er hat an jedem Tag in mindestens einem Bett geschlafen. $\forall$ (time) ∃ (place) ?? ∃ (place) $\forall$ (time) (German)   
(3-241) Er hat an mehr als einem Tag in fast jedem Bett geschlafen. M (time) F (place) ? F (place) M (time) (German)   
(3-242) Er hat in mehr als einem Bett an fast jedem Tag geschlafen. M (place) F (time) F (time) M (place)

# Result (QS)

# (0,2,0,0,0,0) Temporal $>$ Locative

# Pair-List Reading

$( 3 - 2 4 3 )  I n$ welchem Bett hat er an jedem Tag geschlafen?

(3-244) An welchem Tag hat er in jedem Bett geschlafen?

# Result (PLR)

# Temporal $>$ Locative

# Informational Focus

(3-245) ?? Hans hat am Sonntag in München geschlafen. Hans has on Sunday in Munich sleep.PART “Hans slept in Munich on Sunday.”

(3-246) Wo hat Hans am Sonntag geschlafen? Hans hat am Sonntag in München geschlafen. ?? Hans hat in München am Sonntag geschlafen.

(3-247) Wann hat Hans in München geschlafen? Hans hat in München am Sonntag geschlafen. Hans hat am Sonntag in München geschlafen.

# Result (IS)

# (2,1) Temporal $>$ Locative

First, we see the QS Test in the example. I started with the translation of the base phrase, (3-236), which in most cases exemplifies the unmarked order. I present the German sentence, in a word to word gloss and a translation.

In the word to word gloss I grouped the elements of a PP together. In the translation I reversed the order of the PPs to account for our hypothesis that English reveals the reverse order of the German order. Thus, if the German unmarked order is Temporal $>$ Locative we should have Locative $>$ Temporal as the unmarked order in English. Of course, this is not a general rule since different topic-focus structures in the two languages could have additional effects.

After that I gave the first example with the existential operator coming first, (3-237). Below the sentence I give the possible scope interpretations. In the case of the first sentence, both interpretations are possible: There is one single day and on this day he slept in every bed (∃ (time) $\forall$ (place)). The other interpretation is that he slept in every bed, not necessarily on the same day. But for every bed, there exist a day on which he slept in that specific bed.

After this sentence I kept the sequence of the operators and exchanged the thematic roles. Here, I get the two interpretations as well.

In the following two examples I exchanged the sequence of operators. In sentence (3-239) and (3-240), the universal operator comes first. This time we get a sharper contrast. While in (3-239) both interpretations are equally available, (3-240) reveals a strong asymmetry. The scope interpretation following the surface order is easy to get. But the reverse interpretation (there exists one concrete bed in which he slept on every day) is very hard to get. It is still possible to interpret the sentence with this scope relation, but with a greater effort.

In some examples, like this one, I added two other sentences, (3-241) und (3-242), with the operators ‘mehr als eine’ (more than one) and ‘fast jedem’ (almost every). In the evaluation below I abbreviated the operators as ‘M’ and ‘F’. These sentences in fact could sharpen the contrast but in the end they did not add any new information. Therefore, I did not count them in the final statistics.

In the final row of the QS Test, I give the result. It is a 6-tuple of numbers, which in the above example have the following meaning:

0: no difference in the first pair, with the existential operator first   
2: two question marks for the unmarked order in the second pair with the   
universal operator first   
0: In the first pair, there is no result pointing in the wrong direction   
0: In the second pair, there is no result pointing in the wrong direction   
0: In the first pair, the reverse scope is never salient   
0: In the second pair, the reverse scope is never salient

(I gave the exact definitions in the section about the QS Test).

Then follows the PLR Test. Since the sentences, (3-243) und (3-244), are derived from the first test, I did not give translations. The arrow indicates, which of the questions can be answered by a Pair-List. The result of this test is just an indication of the observed order, no grading.

The IF Test starts again with the translation of the base sentence, (3-245). Next, I presented the first constituent question, containing a PP, (3-246). The question is followed by two sentences. Each of the sentences has two PPs. One of them, $\mathrm { P P _ { 1 } }$ , has already been in the question. The other, $\mathrm { P P } _ { 2 }$ , can be understood as the questioned constituent. In these two sentences the order of the two PPs is exchanged. The questioned constituent represents the informational focus of the sentence and is underlined. In front of the sentence we find either one question mark (?), two question marks (??), an asterisk, $( ^ { * } )$ or nothing, according to the availability of the sentence as possible answer to the question above. One question mark is given, if the sentence is available as an answer, but less available as the other answer to the same question and if, in addition, this contrast is sharper than the contrast between the answers of the other question.

Two question marks are given if the sentence is rather odd as an answer to the question. The asterisk indicates that the sentence cannot be used as an answer.

In the example, we see ‘??’ in front of the sentence ‘Hans hat in München am Sonntag geschlafen.’

This means, that this sentence could hardly count as answer to ‘Wo hat Hans am Sonntag geschlafen’, but still is possible in this context.

In (3-247) “Hans hat am Sonntag in München geschlafen.” is given in bold letters. This indicates, that it is the preferred word order, though the focussed element is in front. This is a pattern, which I found only when this element is the higher one.

I conclude with the validation of the IF Test. It is a pair of numbers which in this case mean:

2: Two question marks for the asymmetric pair   
1: One sentence in bold shows preference for the higher PP to stay in front

# 3.5.4 Results

The results we get from the tests are quite convincing. They reveal the validity of the three tests and give me the rigid linear order of PP classes, distinguished by thematic roles. I put the results into a database, that I wrote especially for this data, so they were easier to handle. I used SQL Base as database and SQL Windows by Centura (SQL Builder, Version 1.0.0) as programming language. This gave me the possibility of doing statistical processing over the data.

The following Table 1 comprises the relevant data needed to compute the resulting hierarchy from the QS-Test. The entry ‘1’ states, that the thematic role to the left is higher than the one below. ‘-1’ is indicated, if it is lower. ‘NC’ means that the two roles are not compatible with each other. The thematic roles are ordered by their position in the resulting hierarchy. The highest types are to the top and to the right. Deviations from the linear order are easily detectable: The higher left triangle should have only entries of ‘1’.

Table 1: Results of the QS Test, original sample   

<html><body><table><tr><td>Evidential</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>11</td><td>1</td><td>1</td><td>11</td><td>11</td><td></td></tr><tr><td>Temporal</td><td>11</td><td>11</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td></tr><tr><td>Locative</td><td>11</td><td>11</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td></tr><tr><td>Comitative</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Benefactive</td><td>1</td><td>1</td><td>11</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>11</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Reason</td><td>11</td><td>11</td><td>1</td><td>1</td><td>1</td><td>1</td><td>11</td><td>11</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Source</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Goal</td><td>1</td><td>1</td><td>11</td><td>NC</td><td>1</td><td>11</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Malefactive</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Path</td><td>1</td><td>1</td><td>1</td><td>0</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Means</td><td>11</td><td>NC</td><td>1</td><td></td><td>0</td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Instrumental</td><td>11</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Matter</td><td>11</td><td></td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td> Manner</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td></td><td>Man</td><td>Mat</td><td>Ins</td><td>Mea</td><td>Pat</td><td> Mal</td><td>Goa</td><td>Sou</td><td>Rea</td><td>Ben</td><td>Com</td><td>Loc</td><td>Tem</td><td>Evi</td></tr></table></body></html>

The resulting hierarchy is:

# Evidential $>$ Temporal $>$ Locative $>$ Comitative $>$ Benefactive $>$ Reason > Source $>$ Goal $>$ Malefactive $>$ Path/Means $>$ Instrumental $>$ Matter $>$ Manner

The relation established by the test among the PP types is transitive without exceptions.

The asymmetry between Path and Means was too weak to give any preference, so I could not establish any order between them.

The order is not total, since I could not apply the test for Means and Goal and for Means and Matter. These thematic roles seem to be incompatible with each other for independent reasons. Means modifiers only go together with motion verbs.

Goal PPs tend to have a very argumental status with motion verbs. Since in this part of the research I wanted to exclude strictly PPs which behave as being selected, I could not include the combination of Means and Goal.

Matter is very restricted in use and does not go together with motion verbs, probably for semantic reasons.

The cases where the results where ambiguous, where one of the observed pairs showed an asymmetry in the opposite direction, were extremely rare. In the narrow corpus of pure modifiers, I found this only once with the pair Path – Means.

For the PLR Test I got:

Table 2: Results of the PLR Test, original sample   

<html><body><table><tr><td>Evi</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td></tr><tr><td>Tem</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td></tr><tr><td>Loc</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td></tr><tr><td>Com</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Ben</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Rea</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Sou</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Goa</td><td>1</td><td>1</td><td>1</td><td>NC</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Mal</td><td>1</td><td>1</td><td>1</td><td>-1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Ins</td><td>1</td><td>1</td><td>1</td><td>0</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Mea</td><td>1</td><td>NC</td><td>1</td><td></td><td>0</td><td>1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Pat</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Mat</td><td>1</td><td></td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Man</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td></td><td>Man</td><td>Mat</td><td>Pat</td><td>Mea</td><td>Ins</td><td>Mal</td><td>Goa</td><td>Sou</td><td>Rea</td><td>Ben</td><td>Com</td><td>Loc</td><td>Tem</td><td>Evi</td></tr></table></body></html>

This time, the test gives a relations that is not entirely transitive. Means, which is not listed above, appears higher than Malefactive, Manner and Path, at the same level as Instrumental and lower than the rest. It is not compatible with Matter as in the case of QS.

The only problematic relation is the one between Malefactive and Means. Without this one relation from 76, we get the order:

# Evidential $>$ Temporal $>$ Locative $>$ Comitative $>$ Benefactive $>$ Reason $>$ Source $>$ Goal $>$ Malefactive $>$ Instrumental/Means $>$ Path $>$ Matter $>$ Manner

The result from the IF-Test are comprised in Table 3 and point in the same direction:

Table 3: Results of the IF Test, original sample   

<html><body><table><tr><td>Evi</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td></tr><tr><td>Tem</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td></tr><tr><td>Loc</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td></tr><tr><td>Com</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Ben</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Rea</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Sou</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Goa</td><td>1</td><td>1</td><td>1</td><td>NC</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Mal</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Ins</td><td>1</td><td>1</td><td>O</td><td>O</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Mea</td><td>1</td><td>NC</td><td>1</td><td></td><td>O</td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Pat</td><td>1</td><td>1</td><td></td><td>-1</td><td>O</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Mat</td><td>1</td><td></td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Man</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td></td><td>Man</td><td>Mat</td><td>Pat</td><td>Mea</td><td>Ins</td><td>Mal</td><td>Goa</td><td>Sou</td><td>Rea</td><td>Ben</td><td>Com</td><td>Loc</td><td>Tem</td><td>Evi</td></tr></table></body></html>

This order is totally transitive. Differences between Means and Instrumental and between Path and Instrumental could not be detected, but Means appears above Path (with the grading (2,0)).

As always Means and Goal are not compatible, neither are Means and Matter. The resulting hierarchy is:

# Evidential $>$ Temporal $>$ Locative $>$ Comitative $>$ Benefactive $>$ Reason $>$ Source $>$ Goal $>$ Malefactive $>$ Instrumental / Means $>$ Path /Instrumental $>$ Matter $>$ Manner

These results seem to be string evidence that each of the three tests is a valid instrument to give rise to a linear order of modifying PP types.

If we compare the hierarchies obtained by the three syntactic test we get the result shown in Table 4:

Table 4: Hierarchy of Thematic Roles resulting from the three tests, original sample   

<html><body><table><tr><td>QS</td><td>PLR</td><td>IF</td></tr><tr><td>Evidential</td><td>Evidential</td><td>Evidential</td></tr><tr><td>Temporal</td><td>Temporal</td><td>Temporal</td></tr><tr><td>Locative</td><td>Locative</td><td>Locative</td></tr><tr><td>Comitative</td><td>Comitative</td><td>Comitative</td></tr><tr><td>Benefactive</td><td>Benefactive</td><td>Benefactive</td></tr><tr><td>Reason</td><td>Reason</td><td>Reason</td></tr><tr><td>Source</td><td>Source</td><td>Source</td></tr><tr><td>Goal</td><td>Goal</td><td>Goal</td></tr><tr><td>Malefactive</td><td>Malefactive</td><td>Malefactive</td></tr><tr><td>Path /Means</td><td>Instrumental / Means</td><td>Instrumental/Means</td></tr><tr><td></td><td></td><td></td></tr><tr><td>Instrumental</td><td>Path</td><td>Path/Instrumental</td></tr><tr><td>Matter</td><td>Matter</td><td>Matter</td></tr><tr><td> Manner</td><td> Manner</td><td> Manner</td></tr></table></body></html>

Comparing the three tests, we get a surprisingly consistent result. The whole region above the Malefactive and the lower region with Matter and Manner are identical for all three tests. The part in between, consisting of Path, Instrument and Means, is a bit blurry. No test was able to establish definite relations between each combination of the three. Whether Instrumentals and Meanss are really distinct PP types is indeed a matter of question, given the similar semantics, the difficulty in finding adequate examples, and the sameness of the preposition. Thus we get the overall linear order:

# Evidential $>$ Temporal $>$ Locative $>$ Comitative $>$ Benefactive $>$ Reason $>$ Source $>$ Goal $>$ Malefactive $>$ Instrumental / Means /Path $>$ Matter $>$ Manner

# 3.5.5 Relative distances

The gradings of the QS Test and IF Test appear to give additional support. The very surprising result was that the judgements about the asymmetry between the two orders sharpened clearly with the distance of the two PPs in the hierarchy. In order to receive a measurable effect I had to quantify this judgement somehow. I assigned to each pair of PP types two numbers, which I calculated from the two result n-tuples of the QS Test and the IF Test.

The first number, nQS, I calculated from the 6-tuple of the grading. Positive numbers of the 1st, 2nd, 5th and 6th place indicate high asymmetry. Thus I simply added them. Positions 3 and 4, in the rare cases they were different from 0, were subtracted, since they were pointing in the opposite directions. The formula is:

$$
\mathrm { n _ { Q S } = Q S _ { 1 } + Q S _ { 2 } - Q S _ { 3 } - Q S _ { 4 } + Q S _ { 5 } + Q S _ { 6 } }
$$

In the example from above, Temporal – Locative, this is

$$
\mathtt { n _ { Q S } } = 0 + 2 - 0 - 0 + 0 + 0 = 2
$$

The maximal entries for QS1 and QS2 are 3, which correspond to an asterisk. QS5 and QS6 can be maximal 1 each, if the reverse scope is salient. Thus the maximal value of $\boldsymbol { \mathrm { n } } _ { \mathrm { Q S } }$ is

$$
\mathtt { n _ { Q s m a x } } = 3 + 3 + 1 + 1 = 8
$$

The second number, $\mathtt { n m }$ , is the sum of the two number of the pair of the IF grading:

$$
\boldsymbol { \mathrm { n } } _ { \mathrm { I F } } = \boldsymbol { \mathrm { I F } } _ { 1 } + \boldsymbol { \mathrm { I F } } _ { 2 }
$$

For the above example we get: $\mathtt { n _ { I F } } = 2 + 1 = 3$

The maximal entry for IF1 is 3, if I gave an asterisk to the incremented sentence. The maximal value for IF2 is 1, which corresponds to a sentence in bold. We get for the maximal value:

$$
\mathrm { n } _ { \mathrm { I f m a x } } = 3 + 1 = 4
$$

For each PP type this gives me a range of 6 distance units above and below for the QS Tests and $+ / - 4$ units for the IF Test.

Now I could give a list of distances for each PP type. Holding one type fixed, I could assign to each other type the $\mathfrak { n } _ { \mathrm { Q S } }$ and the $\mathtt { n m }$ to express the relative distance. Elements which are lower than this fixed point were assigned this number multiplied by (–1).

Therefore, I got two tables for each PP type, one for Qs and one for IF, which expresses the distances of the others relative to this fixed point.

I will present these tables in Appendix F in the form of diagrams, where we find on the y-axis the relative distance (positive or negative number) and on the $\mathbf { X }$ -axis the PP types. Since I did not want to represent negative values, I added the number 5 to each value as ground level for the IF-Test and the number 10 for the QS-Test.

# 3.5.5.1 Average

Since the judgement about the distance is not so firm as the pure higher-orlower decision, the results for each of the thematic roles can not be taken absolutely. One has to consider also, that, in the case of QS, there are only 8 distinct positions available above the point of reference and below, given by $\boldsymbol { \mathrm { n } } _ { \mathrm { Q s m a x } }$ . In the case of IF there are only 4 distinct positions above and below.

For central positions like Source or Goal this is not much of a problem, but Evidential, as the highest, has to fill 13 distinct thematic roles into these 8, resp. 4 slots. The same is valid for Manner from the other side. Therefore, we get the best results for the central positions.

If each single diagram is taken by itself, the results are not quite exact. My next idea was, to look whether I could sharpen is with the instrument of statistics. If for each position the judgement of distances was a bit blurry, how would be the average of distances, integrating over all judgements?

I chose Manner as an arbitrary point of reference $\mathrm { T R } _ { \mathrm { r e f } }$ . For every other thematic role TR1 I calculated their average distance to $\mathrm { T R } _ { \mathrm { R e f } }$ in the following manner:

This formula has to be interpreted in the following way:

For each thematic role TR2, distinct from TR1, I calculated the distance to TR1 and the distance to $\mathrm { T R } _ { \mathrm { R e f } }$ . Then I took the difference of the two. It is this difference that I added up for all thematic roles TR2.

But not all thematic roles were compatible with each other. I pointed out, that it is impossible to have Means and Goal modifier PPs in the same sentence. For this reason, the number had to be corrected. I divided the resulting number by the number of hits, i.e. the number of thematic roles TR2 compatible with TR1.

To get a better contrast for the diagram, I multiplied the resulting numbers by ten.

Table 5 lists in its first column all thematic roles ordered by distance from the lowest point, Manner. In the second column you find the average distance from Manner and in the third columne the average distance from the lower immediate neighbour. As you can easily verify, this simply the difference between the two average distances from Manner.

Diagram 1 gives a graphical presentation of these distances.

Table 5:Average Distances for QS Test, original sample   
Diagram 1: Average Distance, QS Test, original sample   

<html><body><table><tr><td>Thematic Role</td><td>Average Distance from Manner</td><td>Average Distance from lower Neighbour</td></tr><tr><td>Evidential</td><td>101,67</td><td>15,83</td></tr><tr><td>Temporal</td><td>85,83</td><td>11,67</td></tr><tr><td>Locative</td><td>74,17</td><td>16,67</td></tr><tr><td>Comitative</td><td>57,50</td><td>6,67</td></tr><tr><td>Benefactive</td><td>50,83</td><td>5,00</td></tr><tr><td>Reason</td><td>45,83</td><td>6,25</td></tr><tr><td>Source</td><td>39,58</td><td>0,49</td></tr><tr><td>Goal</td><td>39,09</td><td>4,92</td></tr><tr><td>Malefactive</td><td>34,17</td><td>2,92</td></tr><tr><td>Path</td><td>31,25</td><td>3,75</td></tr><tr><td>Instrumental</td><td>27,50</td><td>0,50</td></tr><tr><td>Means</td><td>27,00</td><td>14,27</td></tr><tr><td>Matter</td><td>12,73</td><td>12,73</td></tr><tr><td> Manner</td><td>0,00</td><td>0,00</td></tr></table></body></html>

![](img/5f1d4ccde70275d4c75d6d5963387f28bfc93d8151ae0f35f1813f9e87e4c120.jpg)

The first column in Table 4 presents the PP types ordered by their distance to Manner. As we see, they come in perfect accordance with the hierarchy resulting from the three tests. Path, Instrumental and Means are the three types, for which we did not get a consistent order from the single tests. Here we can see that the difference between Instrumental and Means is very small, compared to the others. To get an overview over the distances between neighbours, I added the third column.

A graphical representation of the distances between neighbours is given below in Diagram 2

![](img/a9fb968dcfc8521d0b8ec4060e4da2ad3e602d9b89073c08c300510b25ca4dc9.jpg)  
Diagram 2: Distances between neighbours, QS Test, original sample

We can see, that besides Instrumental and Means, there is another couple, which is close together, namely Source and Goal. But in their case I would not think that they occupy the same slot, since they can be present in one and the same sentence without any problems. In fact, sentences like

(German)

(3-248) Ich fuhr von Hamburg nach Köln. “I went from Hamburg to Cologne.”

are very common.

Apart from the two couple with distance 0.5, we can distinguish three groups by neighbour distance:

distance about 5: Comitative-Benefactive, Benefactive-Reason, Reason  
Source, Goal-Malefactive, Malefactive-Path, Path-Instrumental   
distance about 10: Temporal-Locative   
distance about 15: Evidential-Temporal, Locative-Comitative, Means  
Matter, Matter-Manner

If these distances are really correlated with distances between (extended) functional projections, we could infer that the group of distance 5 represents direct neighbours. The group of 5 indicates, that is one (extended) functional projection in between and the group of 15 a gap of two (extended) functional projections.

Applying the same evaluation for the IF- Test gives the results displayed in Table 6. Below in Diagram 2 you find again the graphical representation of the average distances.

Table 6: :Average Distances for IF Test, original sample   

<html><body><table><tr><td>Thematic Role</td><td>Average Distance from Manner</td><td>Average Distance from lower Neighbour</td></tr><tr><td>Temporal</td><td>51,67</td><td>1,67</td></tr><tr><td>Evidential</td><td>50,00</td><td>9,58</td></tr><tr><td>Locative</td><td>40,42</td><td>2,50</td></tr><tr><td>Comitative</td><td>37,92</td><td>6,25</td></tr><tr><td>Benefactive</td><td>31,67</td><td>4,17</td></tr><tr><td>Reason</td><td>27,50</td><td>2,92</td></tr><tr><td>Source</td><td>24,58</td><td>4,58</td></tr><tr><td>Goal</td><td>20,00</td><td>4,17</td></tr><tr><td>Malefactive</td><td>15,83</td><td>2,83</td></tr><tr><td>Means</td><td>13,00</td><td>0,50</td></tr><tr><td>Instrumental</td><td>12,50</td><td>1,25</td></tr><tr><td>Path</td><td>11,25</td><td>8,52</td></tr><tr><td>Matter</td><td>2,73</td><td>2,73</td></tr><tr><td>Manner</td><td>0,00</td><td>0,00</td></tr></table></body></html>

![](img/2d8cb36234505951933bf0aaf50979e0fb939056dc70b627515e1c985745895c.jpg)  
Diagram 3: Average Distance, IF Test, original sample

Compared with the above result, Temporals and Evidentials are reversed and instead of having the order Path $>$ Instrumental $>$ Means, we get the order Means $>$ Instrumental $>$ Path. The difference between Means and Instrumental is very low as in the above case. If we take Means and Instrumental as obtaining the same position the difference in the two hierarchies reduce to the order Evidential $>$ Temporal, Path $>$ Instrumental for QS and Temporal> Evidential, Instrumental $>$ Path for IF.

The distance between Source and Goal is this time much bigger and cannot be neglected.

Comparing the neighbour distances, obtained from both test, we cannot find any correlation. I will give both diagrams below.

![](img/344a741aae4788a307405c94cddfda4313d310ed30aaf973bd23164febfcd23d.jpg)  
Diagram 4: Distances between neighbours, IF Test, original sample

![](img/14cc156581ffe2c295b8c170c0f52493d4a7a63d80df149e501bfc6a47a06d60.jpg)  
Diagram 2,repeated: Distances between neighbours, QS Test, original sample

Finally we can add up the distances of both tests and obtain results given in Table 7 and graphically represented in Diagram 5 (average distances) and Diagram 6 (neighbour distances):

Table 7: :Average Distances for QS Test and IF Test, original sample   

<html><body><table><tr><td>Thematic Role</td><td>Average Distance from Manner</td><td>Average Distance from lower Neighbour</td></tr><tr><td>Evidential</td><td>151,67</td><td>14,17</td></tr><tr><td> Temporal</td><td>137,50</td><td>22,92</td></tr><tr><td>Locative</td><td>114,58</td><td>19,17</td></tr><tr><td>Comitative</td><td>95,42</td><td>12,92</td></tr><tr><td>Benefactive</td><td>82,50</td><td>9,17</td></tr><tr><td>Reason</td><td>73,33</td><td>9,17</td></tr><tr><td>Source</td><td>64,17</td><td>5,08</td></tr><tr><td>Goal</td><td>59,09</td><td>9,09</td></tr><tr><td>Malefactive</td><td> 50,00</td><td>7,00</td></tr><tr><td>Path</td><td>43,00</td><td>2,00</td></tr><tr><td>Instrumental</td><td>41,00</td><td>4,75</td></tr><tr><td>Means</td><td>36,25</td><td>20,80</td></tr><tr><td>Matter</td><td>15,45</td><td>15,45</td></tr><tr><td> Manner</td><td>0,00</td><td>0,00</td></tr></table></body></html>

![](img/c96cbf1aa4399882e1840ebc049089b710e6d33825ec16555acb17097c170772.jpg)  
Diagram 5: Average Distance, QS Test $^ +$ IF Test, original sample

![](img/baa9946320a49b564d6a41b4c7852ff7cfd4bc11335e90e4c4379d3785a73765.jpg)  
Diagram 6: Distances between neighbours, QS Test $^ +$ IF Test, original sample

# 3.5.6 The larger sample

Several PP types, concerned with aspectual and temporal behaviour, turned out not to be compatible with the QS-Test and the PLR-Test, since their DP could not be quantified.

For some of them I tried to work with an asymmetric PLR-Test, i.e. I only used one sentence with a Wh-phrase questioning the new thematic role. If a list interpretation was available, I gave it a lower position than the universal quantified role, otherwise a higher one. Since this was not a contrastive test, judgments were more difficult and the results have to be handled with care. You will find them in the appendix, though I did not use them for the general evaluation.

I applied the IF-Test to all of the new roles, getting some additional results and a finer graining of the hierarchy. First I want to introduce the different PP types:

# 3.5.6.1 Duration

The PPs of duration of time behave a bit differently from the others. They describe the duration of a process or a state. In German, there are three different types depending on their aspectual behaviour and their inner syntax: The prepositional ‘für’-PP and ‘in’- PP and the post-positional ‘lang’-PP.

The three types differ with respect to their aspectual behaviour. ‘Für’ and ‘lang’-PPs go together with imperfective state of affairs; they describe the duration of a process which has not come to some natural end, while the ‘in’-PP describes the time for reaching a natural end point.:

(German)

(3-249) Krügers sind drei Stunden lang nach Paris geflogen. Krüger(name, pl) are three hours long to Paris fly.PART “The Krüger family flew three hours in the direction of Paris.”

Here it is not clear, whether the Krüger family ever reached Paris. It could have happened, that some UFO captured them or some other accident prevented them from reaching their presumed goal.

(German)

(3-250) Krügers sind in drei Stunden nach Paris geflogen. Krügers are in three hours to Paris fly.PART “The Krüger family flew in three hours to Paris.”

This time, it is clearly stated, that the Krüger family reached Paris.

The ‘für’- PrepositionalP differs semantically from the ‘lang’- PostpositionalP in determining a planned duration (e.g. the time one plans to stay in another town). At the time of reference it describes an action in the future:

(German)

(3-251) Krügers sind für drei Stunden nach Paris geflogen. Krügers are for three hours to Paris fly.PART “The Krüger family flew to Paris and intended to stay there for three hours.”

There is no specification of the duration of the flight itself, but a statement of the intended duration.

I called the three types Duration Temporal1 (prepositional ‘für’), Duration Temporal2 (prepositional ‘in’) und Duration Temporal3 (postpositional ‘lang’).

# 3.5.6.2 Source Temporal

With this term I indicate a group of PP types that determine the beginning of a state of affairs. There are two prepositions: ‘seit’ and ‘ab’ which have slightly different semantic. ‘Seit’-PPs are only compatible with a state of affair that is still going on at the time of reference, while ‘ab’-PPs select a state of affair either in the past or in the future:

(3-252) Ich arbeite seit Mittwoch. I work.PRS since Wednesday. “I have been working since Wednesday.”   
(3-253) \* Ich arbeite ab Mittwoch. I work.PRS since Wednesday. “I had been working since Wednesday.”   
(3-254) Er arbeitete ab Mittwoch. He work.PST since Wednesday. “He had been working since wednesday.”   
(3-255) ? Er arbeitete seit Mittwoch.   
(3-256) \* Er arbeitete gestern seit 8 Uhr. “Er worked yesterday from 8 o'clock on.”   
(3-257) Er arbeitete gestern ab 8 Uhr.   
(3-258) \* Ich werde morgen seit 8 Uhr arbeiten. “I will work tomorrow from 8 o'clock on.”   
(3-259) Ich werde morgen ab 8 Uhr arbeiten.

There is another difference between the two prepositions. ‘Seit’ can be used with a temporal point that marks the beginning of a state of affair as well as with an expression of time length:

(3-260) Ich arbeite seit Mittwoch. “I am working since Wednesday.”   
(3-261) Ich arbeite seit drei Tagen. “I am working for three days now.”

But ‘ab’ is only possible with a time point:

(3-262) Ich arbeitete gestern ab 3 Uhr. “I was working yesterday since 3 o'clock.”

(3-263) Ich arbeitete seit 3 Stunden, als... “I was working for three hours, when (something suddenly happened).”

(German)

(3-264) \* Ich arbeitete ab 3 Stunden, als...

The distinction between time point and time interval is crucial in Spanish. It is expressed by the usage of different prepositions:

‘Desde’ indicates the point in time where a certain state of affair initiates.

(Spanish)

(3-265) Trabajo aquí desde el jueves pasado. work.1PS here since the thursday last “I have been working here since last Thursday.”

‘Hace’ gives the amount of time which has passed between a certain punctual event and the point of reference.

(Spanish)

(3-266) Llegué a España hace tres años. arrive.PST.1PS in Spain ago three years “I arrived (here) three years ago.”

‘Desde hace’ specifies the amount of time which has passed since the beginning of an event that is still in progress.

(Spanish)

(3-267) Trabajo aquí desde hace tres años. work.1PS here since ago three years ”I am working here for three years (now).”

The German ‘seit’ can be translated either with ‘desde’ or with ‘desde hace’. In certain dialects it is possible to translate the last example with:

(Non Standard German)

(3-268) # Seit vor drei Jahren arbeite ich hier.

So it seems possible, that we will find three different positions. I called the three PP types: Source Temporal1 (‘seit’ $^ +$ time interval), Source Temporal2 (‘seit’ $^ +$ time point) and Source Temporal3 (‘ab’ $^ +$ time point).

# 3.5.6.3 Past Temporal (‘vor’ $^ +$ time interval)

The ‘Past Temporal’ is a PP that consist of the preposition ‘vor’ and a DP, indication a time interval. This interval specifies the time that has passed since the state of affair under discussion. As in the case of duration and source temporals the DP cannot be quantified with a universal quantifier, so the Quantifier Scope and Pair List Reading tests cannot be performed. The past Temporal responds to a question beginning with ‘Wann’ (when).

# 3.5.6.4 Future Temporal (‘in’ $^ +$ time interval)

The Future Temporal with ‘in’ is the mirror of the Past Temporal with ‘vor’. It describes an event that takes places after the specified time interval. The same restrictions as in the ‘vor’-case are valid. I tested the whole paradigm in order to see, whether we could distinguish different positions for future and past temporals, which could be identified with the two neighbouring positions T(past) and T(future) of the Cinque Hierarchy.

# 3.5.6.5 Results

Table 8 summarizes the results obtained by applying the IF test to the new thematic roles combined with all others.

Table 8: Results of the IG Test, larger sample   

<html><body><table><tr><td>Evi</td><td>11</td><td>1</td><td></td><td></td><td>1</td><td></td><td></td><td></td><td>-</td><td>-</td><td></td><td></td><td></td><td>11</td><td>11</td><td>11</td><td>1</td><td>11</td><td>1</td><td>1</td><td>11</td><td>1</td><td></td><td>1</td></tr><tr><td>Fut</td><td></td><td></td><td></td><td></td><td>-</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>-</td><td>1</td><td></td><td>NC</td><td></td><td></td><td>NC</td><td>NCNC</td><td></td><td></td><td>-1</td></tr><tr><td>Past</td><td></td><td></td><td>1</td><td></td><td></td><td>-</td><td></td><td>-</td><td>-</td><td></td><td></td><td></td><td></td><td>-</td><td>1</td><td></td><td>NC</td><td></td><td></td><td>NC</td><td>NC</td><td></td><td>NC</td><td>-1</td></tr><tr><td>ST1</td><td></td><td></td><td>1</td><td></td><td></td><td></td><td></td><td>-</td><td>-</td><td></td><td></td><td></td><td></td><td></td><td></td><td>NC</td><td>NC</td><td></td><td>NC</td><td>NC</td><td></td><td>NC</td><td>NC</td><td>-1</td></tr><tr><td>Tem</td><td></td><td>1</td><td></td><td></td><td></td><td></td><td></td><td>-</td><td></td><td></td><td></td><td></td><td></td><td></td><td>1</td><td>1</td><td></td><td></td><td>1</td><td></td><td></td><td>NC|NC</td><td>NC</td><td>-1</td></tr><tr><td>ST3</td><td></td><td>1</td><td></td><td></td><td>-</td><td>-</td><td></td><td></td><td></td><td>NC</td><td></td><td></td><td></td><td></td><td>1</td><td></td><td>NC</td><td></td><td></td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Loc</td><td></td><td>1</td><td>1</td><td></td><td></td><td></td><td></td><td>-</td><td></td><td></td><td></td><td></td><td></td><td></td><td>1</td><td>1</td><td></td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>ST2</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>NC</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>NC</td><td>-1</td><td></td><td>NCNC</td><td>NC</td><td>-1</td></tr><tr><td>DT3</td><td></td><td>1</td><td>-</td><td></td><td>-</td><td>-</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>-</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Com</td><td></td><td></td><td>-</td><td></td><td>-</td><td>-</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Ben</td><td></td><td></td><td></td><td></td><td></td><td>-</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>- </td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Rea</td><td></td><td>1</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-</td><td>-1</td><td>-1</td><td>-1</td><td></td><td>-1</td></tr><tr><td>Sou</td><td></td><td></td><td>1</td><td></td><td>-</td><td>-</td><td></td><td>-</td><td></td><td></td><td></td><td>- 1</td><td></td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>DT1</td><td></td><td></td><td>NC</td><td></td><td></td><td>NC</td><td></td><td>- </td><td>NC</td><td></td><td>-1</td><td>- 1</td><td></td><td></td><td>-1</td><td>-1</td><td>NC</td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Goa</td><td></td><td></td><td>1</td><td></td><td>NC</td><td>1</td><td></td><td></td><td></td><td>NC</td><td>-1</td><td></td><td></td><td></td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-</td><td>-1</td><td>-1</td><td>-1</td><td></td><td>-1</td></tr><tr><td>DT2</td><td></td><td></td><td>1</td><td></td><td>1</td><td>1</td><td></td><td></td><td>-1</td><td></td><td>-1</td><td>-</td><td></td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Mal</td><td></td><td></td><td>1</td><td></td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td></td><td></td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Ins</td><td>1</td><td></td><td>1</td><td></td><td></td><td></td><td>-1</td><td>-1</td><td>-1</td><td>NC</td><td>-1</td><td>- </td><td></td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Mean</td><td></td><td>NC</td><td></td><td></td><td></td><td>0</td><td>- </td><td>-1</td><td>NC</td><td>-1</td></table></body></html>

Applying the IF-Test to the full sample of modifiers returns a nearly linear order. The only judgement destroying the otherwise consistent picture is the combination Goal – Duration Temporal2. If I ignore this judgment the resulting hierarchy is:

# Evidential $>$ Future Temporal/Past Temporal/Source Temporal1/Temporal $>$ Source Temporal3 $>$ Locative $>$ Source Tempora $\begin{array} { r } { \vert 2 > \mathbf { D } \mathbf { u } \cdot } \end{array}$ - ration Temporal3 $>$ Comitative $>$ Benefactive $> \mathbf { R e a s o n } > \mathbf { S o u r c e } > \mathbf { D u r a } -$ tion Temporal2 $>$ Duration Temporal1 $>$ Goal $>$ Malefactive $>$ Instrumental/Means $>$ Instrumental/Path $>$ Matter $>$ Manner

As before, there could be no difference detected between Means and Instrumental, nor between Path and Instrumental. Several combinations turned out to be incompatible for semantic reasons:

Future Temporal Past Temporal Future Temporal Source Temporal1 Future Temporal Temporal Future Temporal Source Temporal2 Past Temporal Source Temporal1 Past Temporal Temporal Past Temporal Source Temporal2 Source Temporal3 Source Temporal1 Source Temporal3 Source Temporal2 Source Temporal2 Duration Temporal1 Source Temporal2 Source Temporal1 Source Temporal2 Duration Temporal1 Source Temporal1 – Temporal Source Temporal1 Duration Temporal3 Duration Temporal1 Goal Duration Temporal1 Instrumental Duration Temporal1 Matter Means Goal Means Matter

Taken just these data, we could think of having only one temporal projection between Evidential and Locative, which hosts the types that I called Temporal, Source Temporal1, Source Temporal3, Future Temporal and Past Temporal.

The average distances can be computed as in the smaller sample giving the results as displayed in Table 9. The graphical presentation you find in Diagram 7:

Table 9: Average Distances for IF Test, larger sample   

<html><body><table><tr><td>Thematic Role</td><td>Average Distance from Manner</td><td>Average Distance from lower Neighbour</td></tr><tr><td>Temporal</td><td>53,53</td><td>2,53</td></tr><tr><td>Evidential</td><td>51,00</td><td>1,71</td></tr><tr><td>SouTemp1</td><td>49,29</td><td>3,66</td></tr><tr><td>PastTemp</td><td>45,63</td><td>1,25</td></tr><tr><td>FutTemp</td><td>44,38</td><td>3,79</td></tr><tr><td>SouTemp3</td><td>40,59</td><td>1,25</td></tr><tr><td>SouTemp2</td><td>39,33</td><td>0,58</td></tr><tr><td>Locative</td><td>38,75</td><td>3,50</td></tr><tr><td>Comitative</td><td>35,25</td><td>5,25</td></tr><tr><td>DurTemp3</td><td>30,00</td><td>2,50</td></tr><tr><td>Benefactive</td><td>27,50</td><td>2,25</td></tr><tr><td>Source</td><td>25,25</td><td>1,75</td></tr><tr><td>Reason</td><td>23,50</td><td>4,06</td></tr><tr><td>Goal</td><td>19,44</td><td>1,44</td></tr><tr><td>DurTemp1</td><td>18,00</td><td>0,50</td></tr><tr><td>DurTemp2</td><td>17,50</td><td>3,00</td></tr><tr><td>Malefactive</td><td>14,50</td><td>4,50</td></tr><tr><td>Instrumental</td><td>10,00</td><td>1,67</td></tr><tr><td> Means</td><td>8,33</td><td>0,58</td></tr><tr><td>Path</td><td>7,75</td><td>3,86</td></tr><tr><td>Matter</td><td>3,89</td><td>3,89</td></tr><tr><td>Manner</td><td>0,00</td><td>0,00</td></tr></table></body></html>

![](img/c118be5e58bec32b5ad4b492ecb892fd27d4bd97e9bb836bad153b39f65e64e6.jpg)  
Diagram 7 : Average Distance, IF-Test, large sample

The average distances suggest that the temporal space between Evidential and Locative comprises also Source Temporal2. This would situate all three Source Temporals, Future Temporal, Past Temporal and the ordinary Temporal in this area. A look at the relative distances between the positions helps to answer the question, whether these types can be found in the same projection:

![](img/ebf5f8adff53c2b816e27d718b3331c19a01195e28567ca3e40972be2e54162e.jpg)  
Diagram 8: Distance between Neighbours, IF-Test, large sample

Source Temporal3 and Source Temporal2 are close together. Given the fact that both describe the temporal distance between a punctual event and the reference time, there is reason to take their positions as being identical.

The same distance can be found between Past Temporal and Future Temporal. On the other side, their ordering, resulting from the average distance calculation, is the same that Cinque postulated for his hierarchy.

An even smaller distance is between Source Temporal2 and Locative, which are definitely different types.

This leads to the conclusion, that the neighbouring distances are not a good device for deciding the question, whether two types are in the same position. To get better insight, this data should be supported by additional tests.

In any case, the larger sample adds two new regions for the durative types: one below Locative and above Benefactive, which hosts Duration Temporal3. The other region is between Source and Malefactive and hosts Duration Temporal1 and Duration Temporal2.

We have now three points in this thematic hierarchy that we can identify with elements of the Cinque Hierarchy: Evidential, Temporal and Durative. In both hierarchies, Evidential is very high, followed in a small distance by Temporal. Duratives are much lower in both sequences. This indicates, that the two hierarchies actually present different positions of one and the same hierarchy. Adverbs are not sitting in a higher region, followed by a distinct hierarchy of PPs.

It is more likely that there is a position for evidential, tense, frequentative aspect, egressive aspect, locative and all the other elements of the combined hierarchy. Each position can be filled with a different kind of modifier such as an extended PP, adverbial phrase, modal, auxiliary or simply a suffix. It remains to be seen, whether for each of these positions we have the same extended projection with several functional heads. In this case the difference in category will be realised by the properties of these heads.

# 3.5.7 Argumental PPs

Finally, I added PPs that were selected by the verb to the sample. Omitting them usually results in ungrammaticality. Additionally, all objects (ore more general: all DPs and PPs selected by the verb) in German have in common that they cannot be found in the Nachfeld. The goal was to see, whether there were differences between PPs of the same semantic type depending on their status as pure modifier or argument. Since the three tests could be considered valid by the time I added these PP types, I applied them only to a subset of the possible combinations.

I chose the following four types:

# 3.5.7.1 LPO – Locative Prepositional Objects

By locative prepositional phrases I mean phrases that are selected by the verb. In most cases they cannot be omitted without rendering the sentence ungrammatical. I chose the verb ‘liegen’ (to lie) for my examples. Furthermore, they cannot be found in the Nachfeld.

(German)

(3-269) Hans liegt auf dem Bett. “Hans lies on the bed.” (3-270) \* Hans liegt. (3-271) \* ..., dass Hans gelegen ist auf dem Bett.

# 3.5.7.2 DPO – Directional Prepositional Object

These PPs are selected by verbs that describe the change of location of an object. They describe the final position of the object. The prototypical verb in German is ‘legen’ (to lay, to put). These PPs are secondary objects, since the moved element is the direct object.

(3-272) Hans legt das Buch auf den Tisch. “Hans puts the book on the table.” (3-273) \* Hans legt das Buch. (3-274) \* ..., dass Hand das Buch gelegt hat auf den Tisch

This is a control group of DPOs with the verb ‘schicken’ (to send). The argumental status is less obvious, since the omission is possible. Nevertheless it behaves syntactically more like an argument than a modifier. Therefore, I take it to be identical to the DPO type.

(German)

(3-275) Hans schickte einen Brief nach Hamburg. “Hans sent a letter to Hamburg.”   
(3-276) ? Hans schickte einen Brief.   
(3-277) ?? ..., dass Hans einen Brief geschickt hat nach Hamburg.

(German)

# 3.5.7.4 RPO – Reason Prepositional Object

The German word ‘folgen’, usually translated as ‘to follow’, is manifold ambiguous. In one of its usages it requires a prepositional object, which indicates the conditions for the validity of the subject. Mathematical sentences make extensive use of the construction; it is widely used especially in logic.

(German)

(3-278) Die Relativitätstheorie folgt aus der Konstanz The theory_of_relativity follows out the constancy der Lichtgeschwindigkeit. the speed_of_light “The theory of relativity is the consequence of the constancy of the speed of light.”

(German)

(3-279) \* Die Relativitätstheorie folgt.   
(3-280) \* ..., dass die Relativitätstheorie folgt aus der Konstanz der Lichtgeschwindigkeit.

It was not easy to determine the semantics of this PP type; closest came the identification with reason, but source resembles it as well. The tests could confirm this. Since ‘folgen’ is not a motion verb, many thematic roles that require a motion verb are not compatible with the RPO. Duration Temporals do not go together with it either, because mathematical sentences are either valid for ever or not at all.

# 3.5.7.5 Results

I added the four PP types to the sample and applied the three tests to all possible combinations. The results are given below

Table 10: Result of QS Test for original sample $^ +$ argumental PPs.   

<html><body><table><tr><td>Evi</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>11</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>1 1</td><td>1</td><td>1</td><td></td></tr><tr><td>Tem</td><td>1</td><td>11</td><td>1</td><td>11</td><td>1</td><td>11</td><td>1</td><td>1</td><td>11</td><td>11</td><td>11</td><td>1</td><td>11</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td></tr><tr><td>Loc</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>11</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td></tr><tr><td>LP</td><td>1</td><td>NC</td><td>1</td><td></td><td>NC</td><td></td><td>NC</td><td>NC</td><td>NC</td><td>NC</td><td>1</td><td></td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Com</td><td>11</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>11</td><td></td><td>11</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Ben</td><td>1</td><td>1</td><td>1</td><td>11</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>RP</td><td>11</td><td></td><td>1</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>1</td><td></td><td>-1</td><td></td><td></td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Rea</td><td>11</td><td>11</td><td>1</td><td>1</td><td>1</td><td>11</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Sou</td><td>1</td><td>1</td><td>1</td><td>11</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td></td><td>-1</td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>DP</td><td>1</td><td>NC</td><td>1</td><td></td><td>1</td><td></td><td>NC</td><td>NC</td><td></td><td>-1</td><td>-1</td><td></td><td>-1</td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Goa</td><td>1</td><td>11</td><td>1</td><td>NC</td><td>1</td><td>1</td><td>NC</td><td></td><td>NC</td><td>-1</td><td>-1</td><td></td><td>-1</td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>DP2</td><td>1</td><td>NC</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>NC</td><td>NC</td><td>-1</td><td>-1</td><td></td><td>-1</td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Mal</td><td>11</td><td>1</td><td>1</td><td>11</td><td>1</td><td></td><td>-1</td><td>-1</td><td></td><td>-1</td><td>-1</td><td></td><td>-1</td><td>-1</td><td></td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Pat</td><td>1</td><td>1</td><td>1</td><td>0</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td></td><td>-1</td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Mea</td><td>1</td><td>NC</td><td>1</td><td></td><td>0</td><td>-1</td><td>-1</td><td>NC</td><td></td><td>-1</td><td>-1</td><td></td><td>-1</td><td>-1</td><td></td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Ins</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td> -1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Mat</td><td>1</td><td></td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>NC</td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td></td><td>-1</td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Man</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td></td><td>Man</td><td>Mat</td><td>Ins</td><td>Mea</td><td>Path</td><td>Mal</td><td>DP2</td><td>Goa</td><td>DP</td><td>Sou</td><td>Rea</td><td>RP</td><td>Ben</td><td>Com</td><td>LP</td><td>Loc</td><td>Tem</td><td>Evi</td></tr></table></body></html>

Table 11: Result of PLR Test for original sample $^ +$ argumental PPs   

<html><body><table><tr><td>Evi</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>11</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td></tr><tr><td>Tem</td><td>11</td><td>11</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>11</td><td>11</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td></tr><tr><td>Loq</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>1</td><td></td><td>-1</td><td>-1</td></tr><tr><td>Com</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>11</td><td>1</td><td>1</td><td></td><td>1</td><td>1</td><td>O</td><td></td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>LPO</td><td>11</td><td>NC</td><td>NC</td><td></td><td>1</td><td></td><td>NC</td><td>NC</td><td>NC</td><td>NC</td><td></td><td>1</td><td>1</td><td></td><td>O</td><td>O</td><td>-1</td><td>-1</td></tr><tr><td>Ben</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Rea</td><td>1</td><td>1</td><td>11</td><td>11</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>RPC</td><td>1</td><td></td><td></td><td></td><td>1</td><td></td><td></td><td></td><td></td><td></td><td></td><td>-1</td><td>-1</td><td></td><td></td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Sou</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td></td><td>-1</td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>DPO</td><td>1</td><td>NC</td><td>1</td><td></td><td>11</td><td></td><td>NC</td><td>NC</td><td></td><td>-1</td><td></td><td>-1</td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Goa</td><td>1</td><td>1</td><td>1</td><td>NC</td><td>11</td><td>1</td><td>NC</td><td></td><td>NC</td><td>-1</td><td></td><td>-1</td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>DP2</td><td>1</td><td>NC</td><td>1</td><td>11</td><td>1</td><td>1</td><td></td><td>NC</td><td>NC</td><td>-1</td><td></td><td>-1</td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Ma1</td><td>11</td><td>1</td><td>11</td><td>-1</td><td>1</td><td></td><td>-1</td><td>-1</td><td></td><td>-1</td><td></td><td>-1</td><td>-1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Ins</td><td>1</td><td>1</td><td>1</td><td>O</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Mea</td><td>1</td><td>NC</td><td>1</td><td></td><td></td><td>1</td><td>-1</td><td>NC</td><td></td><td>-1</td><td></td><td>-1</td><td>-1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Pat</td><td>11</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td></td><td>-1</td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Mat</td><td>1</td><td></td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>NC</td><td>-1</td><td>NC</td><td>-1</td><td></td><td>-1</td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Man</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td></td><td>Man</td><td>Mat</td><td>Pat</td><td>Mea</td><td>Ins</td><td>Ma1</td><td>DP2</td><td>Goa</td><td>DPO</td><td>Sou</td><td>RPO</td><td>Rea</td><td>Ben</td><td>LPO</td><td>Com</td><td>Loq</td><td>Tem</td><td>Evi</td></tr></table></body></html>

The difference between the two resulting hierarchies is only minimal. DPO, Goal and DPO2 are not compatible with each other and seem to sit in the same positions. This gives good reason to identify these types.

RPO appears as a neighbour to Reason. The QS-Test posits it above, the PLR-Test below. The sentences combining both are indeed quite odd:

(German)

(3-281) Die Relativitätstheorie folgt wegen mindestens The theory_of_relativity follows because_of at_least einem Prinzip aus jedem Axiom. one principle from every axiom “The theory of relativity is a consequence of every axiom because of every principle.”

Source is direct neighbour of RPO according to the PLR-Test and very close according to the QS-Test. It seems difficult to decide which of the both, Reason or Source, could be identical with RPO, maybe none of them.

LPO is according to the QS-Test between Locative and Comitative. The PLR-Test cannot distinguish between LPO and Comitative. Again, I opt for identification of LPO and Locative.

The results from the IF-Test as given in Table 12 reveal a surprise

Table 12: Result of IF Test for original sample $^ +$ argumental PPs   

<html><body><table><tr><td>Evi</td><td>1I</td><td></td><td></td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>1</td><td>1</td><td></td><td></td><td>1</td><td></td></tr><tr><td>Tem</td><td>1</td><td></td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td></td><td></td><td>1</td></tr><tr><td>Loc</td><td>1I</td><td></td><td>1</td><td>1</td><td></td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td></td><td></td><td>1</td><td></td><td></td><td></td><td></td><td>-1</td><td>-1</td></tr><tr><td>Com</td><td>1</td><td></td><td>1</td><td></td><td></td><td>1</td><td>1</td><td></td><td>1</td><td></td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td></td><td>1</td><td>-1</td><td>1</td></tr><tr><td>Ben</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Rea</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>1</td><td>1</td><td></td><td>1</td><td></td><td>1</td><td></td><td></td><td>1</td><td></td><td>-1</td><td>1</td><td>-1</td><td>-1</td></tr><tr><td>Sou</td><td>1</td><td>1</td><td>NC</td><td></td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>1</td><td></td><td>1</td><td>1</td><td></td><td>-1</td><td>1</td><td>-1</td><td>-1</td></tr><tr><td>Goa</td><td>NC</td><td>NC</td><td>NC</td><td></td><td>1</td><td>1</td><td>1</td><td>NC</td><td>1</td><td>1</td><td></td><td></td><td>-1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Ma1</td><td>1</td><td></td><td></td><td></td><td></td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>1</td><td></td><td>-1</td><td>1</td><td>-1</td><td>-1</td></tr><tr><td>Ins</td><td>1I</td><td></td><td>1</td><td>1</td><td></td><td>1</td><td>O</td><td></td><td></td><td></td><td>-1</td><td>-1</td><td>1</td><td>1</td><td></td><td>-1</td><td></td><td>-1</td><td>-1</td></tr><tr><td>Mea</td><td>1I</td><td></td><td></td><td></td><td></td><td>NC</td><td>1</td><td></td><td></td><td>-1</td><td>NC</td><td>-1</td><td>-1</td><td>-1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Pat</td><td>1I</td><td></td><td>NC</td><td></td><td></td><td>1</td><td></td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>1</td><td>-1</td></tr><tr><td>Mat</td><td>NC</td><td>NC</td><td>NC</td><td></td><td></td><td></td><td>-1</td><td>NC</td><td>-1</td><td></td><td>-1</td><td>-1</td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>1</td></tr><tr><td>Man</td><td>1</td><td></td><td>1</td><td>1</td><td></td><td>-1</td><td></td><td>-1</td><td>1</td><td>-1</td><td>-1</td><td>1</td><td>-1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>1</td></tr><tr><td>RP</td><td></td><td></td><td></td><td></td><td>-1</td><td></td><td></td><td></td><td>-1</td><td></td><td></td><td></td><td>1</td><td></td><td>1</td><td></td><td>-1</td><td>-1</td><td>1</td></tr><tr><td>LP</td><td>NC</td><td>NC</td><td></td><td></td><td>-1</td><td>NC</td><td>NC</td><td></td><td>-1</td><td></td><td>NC</td><td></td><td>NC</td><td>-1</td><td>1</td><td>-1</td><td>-1</td><td>-1</td><td>1</td></tr><tr><td>DP</td><td>NC</td><td></td><td>NC</td><td></td><td>-1</td><td>NC</td><td>-1</td><td></td><td>-1</td><td></td><td>NC</td><td>-1</td><td>1</td><td>1</td><td></td><td>-1</td><td>1</td><td>-1</td><td>1</td></tr><tr><td>DP2</td><td></td><td>NC</td><td>NC</td><td></td><td>1</td><td>NC</td><td>1</td><td>-1</td><td>-1</td><td>-1</td><td>NC</td><td></td><td>1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td></td><td>DP2</td><td>pP</td><td>LP</td><td>RP</td><td>Man</td><td></td><td></td><td>Mat PathMea</td><td>Ins</td><td>Ma1</td><td></td><td>Goa</td><td>Sou Rea</td><td></td><td>Ben</td><td>Com</td><td>Loc</td><td>Tem</td><td>Evi</td></tr></table></body></html>

All prepositional objects appear below the lowest modifier position! This is the first time a fundamental difference between the IF-Test and the two scope tests appears.

A possible explanation is to take the prepositional objects to be base generated in the VP shell from where they have to climb to the relevant functional projection in the modifier space. These projection license their thematic role. Pure modifier PPs are generated directly in the modifier space in the extended projection related to their thematic role.

This analysis has consequences for the explanation of scope relations. If scope is established via simple C-command, we expect the scope relations to refer to base generated positions. Therefore, the QS-Test and the PRL-Test should give us the same results as the IF-Test, namely all selected PPs below Manner.

The fact, that they appear in the functional projection related to the appropriate thematic role indicates that the prepositional objects have to climb up into a specific position to establish scope. Scope cannot be established simply by C-Command between base generated elements.

I add the statistics related to the distances. In Table 13 you find the results of the average distances for the QS Test ( original sample $^ +$ argumental PPs). The following Diagram 9 gives the corresponding graphical representation.

Table 13: Average Distances for QS Test, original sample $^ +$ argumental PPS   

<html><body><table><tr><td>Thematic Role</td><td>Average Distance from Manner</td><td>Average Distance from lower Neighbour</td></tr><tr><td>Evidential</td><td>99,38</td><td>13,75</td></tr><tr><td>Temporal</td><td>85, 63</td><td>7,81</td></tr><tr><td>Locative</td><td>77,81</td><td>19,81</td></tr><tr><td>Comitative</td><td>58,00</td><td>4,88</td></tr><tr><td>Benefactive</td><td>53,13</td><td>0,27</td></tr><tr><td>LPO</td><td>52,86</td><td>8,17</td></tr><tr><td>Reason</td><td>44,69</td><td>3, 62</td></tr><tr><td>Source</td><td>41,07</td><td>1,98</td></tr><tr><td>Goal</td><td>39,09</td><td>4,09</td></tr><tr><td>RPO</td><td>35,00</td><td>1,36</td></tr><tr><td>DPO2</td><td>33,64</td><td>1,33</td></tr><tr><td>Malefactive</td><td>32,31</td><td>1,95</td></tr><tr><td>Path</td><td>30,36</td><td>3,69</td></tr><tr><td>DPO</td><td>26,67</td><td>0,42</td></tr><tr><td>Instrumental</td><td>26,25</td><td>0,80</td></tr><tr><td>Means</td><td>25,45</td><td>12,73</td></tr><tr><td>Matter</td><td>12,73</td><td>12,73</td></tr><tr><td>Manner</td><td>0,00</td><td>0,00</td></tr></table></body></html>

![](img/8dd75cfb2c2aba2395e07734e682b75d19652a23332c6d7bd53573a53df3d6f3.jpg)  
Diagram 9: Average Distances, QS-Test, original sample with argumental PPs

Though the two scope tests posit the prepositional objects in the position of their modifying equivalents they appear in the Average Distance calculation in all cases lower. This could indicate that they are moving from a position below Manner to their destination in the extended projection of the thematic role.

Table 14: Average Distances for IF Test, original sample $^ +$ argumental PPS   

<html><body><table><tr><td>Thematic Role</td><td>Average Distance to Manner</td><td>Average Distance to lower Neighbour</td></tr><tr><td>Temporal</td><td>43,13</td><td>1,25</td></tr><tr><td>Evidential</td><td>41,88</td><td>7,19</td></tr><tr><td>Locative</td><td>34,69</td><td>1,69</td></tr><tr><td>Comitative</td><td>33,00</td><td>5,50</td></tr><tr><td>Benefactive</td><td>27,50</td><td>4,38</td></tr><tr><td>Reason</td><td>23,13</td><td>0,63</td></tr><tr><td>Source</td><td>22,50</td><td>2,50</td></tr><tr><td>Goal</td><td>20,00</td><td>3,85</td></tr><tr><td>Malefactive</td><td>16,15</td><td>4,34</td></tr><tr><td>Means</td><td>11,82</td><td>0,57</td></tr><tr><td>Instrumental</td><td>11,25</td><td>0,89</td></tr><tr><td>Path</td><td>10,36</td><td>5,81</td></tr><tr><td>DPO2</td><td>4,55</td><td>0,26</td></tr><tr><td>LPO</td><td>4,29</td><td>1,56</td></tr><tr><td>Matter</td><td>2,73</td><td>1,06</td></tr><tr><td>RPO</td><td>1,67</td><td>1,67</td></tr><tr><td>Manner</td><td>0,00</td><td>1,11</td></tr><tr><td>DPO</td><td>-1,11</td><td>0,00</td></tr></table></body></html>

![](img/12a59fcc543ff920d1b44b4bc68dc7174ac0eb6e6e72b56fa1f32aeb6b77cb40.jpg)  
Diagram 10: Average Distances, IF-Test, original sample with argumental PPs

Here all prepositional objects appear in very low positions, but with view differences between each other. DPO2 and DPO, which I assumed to be identical, appear at both ends of the space spanned by the selected PPs. Therefore, the Average Distance calculation does not distinguish different base positions for the selected PPs. Probably they are all base generated in the direct or indirect object slot.

# 3.5.8 English

Two English speakers gave some judgements about word order and scope ambiguities in English. I asked them to give preferences for word order. I used only a subset of the small sample. I was interested in two aspects:

1. whether this simple test would lead to consistent results and a comparable hierarchy   
2. whether the preferred word order is identical or reversed to the German one.

Question 2 could be mainly confirmed. Evidentials were accepted only in a position to the right of other PPs. Temporals were always preferred to the right of Manner, Comitatives, Instrumentals and Locatives. Exceptions were Matter and Reason (and of course Evidential). Therefore, I inserted a ‘1’, if the preferred order had the higher PP to the right.

The results are given in Table 15:

Table 15: Judgements about word order in English   

<html><body><table><tr><td>Evidential</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>O</td><td>1</td><td>1</td><td></td></tr><tr><td>Temporal</td><td>1</td><td>1</td><td>-1</td><td>1</td><td>1</td><td>-1</td><td>O</td><td></td><td>-1</td></tr><tr><td>Benefactive</td><td>-1</td><td>-1</td><td>-1</td><td>1</td><td>-1</td><td>1</td><td></td><td>O</td><td>-1</td></tr><tr><td>Reason</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td></td><td>-1</td><td>1</td><td>O</td></tr><tr><td>Locative</td><td>O</td><td>-1</td><td>1</td><td>1</td><td></td><td>-1</td><td>1</td><td>-1</td><td>-1</td></tr><tr><td>Instrumental</td><td>-1</td><td>-1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>Matter</td><td>-1</td><td>1</td><td></td><td>-1</td><td>-1</td><td>-1</td><td>1</td><td>1</td><td>-1</td></tr><tr><td>Comitative</td><td>1</td><td></td><td>-1</td><td>1</td><td>1</td><td>-1</td><td>1</td><td>-1</td><td>-1</td></tr><tr><td>Manner</td><td></td><td>-1</td><td>1</td><td>1</td><td></td><td>-1</td><td>1</td><td>-1</td><td>-1</td></tr><tr><td></td><td></td><td>ManCom</td><td>Mat</td><td>Ins</td><td>Loc</td><td>Rea</td><td>Ben</td><td>Tem</td><td>Evi</td></tr></table></body></html>

The upper left triangle has 23 entries of ‘1’ and 10 entries of ‘-1’; 3 entries are ‘0’. Reason is given higher than Temporal, Comitative and Locative. This effect is due to the tendency of Reason to take the other elements into its scope. If we take this into account, we get a result, that is not totally consistent, but nevertheless reveals a clear tendency of having higher elements to the right.

The second speaker judged some examples of the QS-Test. He evaluated combinations of Temporals, Instrumentals, Locatives and Reason.

You can see the evaluation in Table 16:

Table 16: QS-Test in English, very small sample   

<html><body><table><tr><td>Temporal</td><td>0</td><td>1</td><td>1</td><td></td></tr><tr><td>Reason</td><td>1</td><td>0</td><td></td><td>-1</td></tr><tr><td>Locative</td><td>1</td><td></td><td>0</td><td>-1</td></tr><tr><td>Instrumental</td><td></td><td>-1</td><td>-1</td><td>0</td></tr><tr><td></td><td>Ins</td><td>Loc</td><td>Rea</td><td>Tem</td></tr></table></body></html>

This result is relatively consistent. In all cases of un-ambiguity it was the element to the right, which took scope over the element to the left.

The two test together give strong evidence to confirm the hypothesis that, in unmarked English sentences, the PPs surface in inverted order with respect to the German order. Quantifier scope is evaluated in this case from right to left.

There are few exceptions with respect to the surface order. The Evidential does not sound good behind the verb, it is much better at the beginning of the sentence. This might be due, to its very high position in the hierarchy, maybe even higher than the AgrS position.

Source, Path and Goal come almost always in direct order, which could be attributed to semantic effects.

# 3.5.9 Reference to events

This is the last test I applied to the sample. I used it with only few combinations. You will find the results in Appendix B. As long as I stayed with purely modifying PPs, the results are in perfect harmony with the other three tests.

Since for the larger sample QS and PLR were not available, I applied this test to one of the critical combinations, which indicated that indeed the Duration Temporal2 is above Goal. Duration Temporal1 and Duration Temporal2 are now between Source and Goal and sit maybe in the same extended projection.

Duration Temporal3, however, sits more likely above Locative and thus participates in the temporal section between Evidential and Locative.

With respect to argumental PPs, the ‘RE’-Test behaves differently. In most cases, the argumental PP can not be omitted in the referred event. I take this as a strong indication that they are an integral part of the lowest event possible, the verb with all its arguments.

Sometimes it is remotely possible to omit them, but only, if they are in front of the modifying PP. But even then, this interpretation is odd:

(German)   
(3-282) Er hat die Kartoffeln auf einen Teller mit einer Gabel gelegt, He has the potatoes on a plate with a fork lay.PART etwas, was er vorher noch nie gemacht hat. something what he before yet never make.PART has “He placed the potatoes with a fork on a plate, something what he never has done before.”   
etwas $=$ ‘to place the potatoes on a plate with a fork’ or ‘to place the potatoes on a plate’ ? ‘to place the potatoes with a fork’

I get in this case the interpretation of an arbitrary argument, specified by a modifier. In the above case something like: “He placed the potatoes somewhere with a fork and this he did on a plate”.

The data strongly suggest that we interpret sentences as a recursive description of events: First we evaluate the core proposition, consisting of the verb and its arguments. This whole proposition constitutes the core event, which becomes an argument for a higher modifier and so on.

# 3.5.10 Conclusion

Three syntactic tests were applied to combinations of PPs in the German Mittelfeld. QS, PLR and $\mathrm { I F }$ gave rise to the same linear order of PP types or thematic roles:

# Evidential $>$ Temporal $>$ Locative $>$ Comitative $>$ Benefactive $>$ Reason > Source $>$ Goal $>$ Malefactive $>$ Instrumental / Means /Path $>$ Matter $>$ Manner

A larger sample of temporal expression gave a bigger distinction of the temporal sector and added a durative sector between Source and Malefactive.

Argumental PPs behave different with respect to the tests. The two scope tests, QS and PLR, posit them in the same position as their modifying partners. According to IF they are lower than the lowest modifier projection.

This could be interpreted that prepositional objects are base generated in the VP shell and rise to the appropriate extended projection later. Pure modifiers are base generated directly in this extended projection.

A close inspection of English gave rise to the hypothesis that this language has the same basic hierarchy, but the elements surface in the unmarked case in reverse order. Scope is evaluated in English usually from right to left.

The ‘RE’-Test and other data suggest that sentences are interpreted as recursive description of events.

Several things remain to be investigated. I started to test, whether subjects and ordinary objects can be included in the sample. The data are not clear yet. It remains to be seen, whether the scope tests assign them different positions according to their different case and/or their different thematic role (agent versus experiencer, theme versus goal, benefactive versus goal etc.).

Another line to be followed is to apply appropriate tests for other languages. It still remains to be seen to which degree the hierarchy is universal.

# CHAPTER 4

# RESTRICTIONS ON STRUCTURE AND MOVEMENT

# 4.1 Introduction

The first attempts of Generative Grammar resulted in systems that could generate all possible grammatical sentences of a language. Unfortunately, they were more powerful than expected because they could generate an infinite number of ungrammatical sentences and structures that were never found in human languages. Subsequent models tried to define a more restrictive theory, which could derive all possible grammatical sentences of a language, but exclude the ungrammatical ones. One of the major goals was to restrict theory in a plausible manner.

Since the early GB framework it has commonly been assumed amongst generativists that the structure of sentences can be modelled using binary trees. These are collections of nodes and relations between them that are all connected and have a single root node, the sentence node that dominates the entire structure.

In the 90s two developments modify this approach. The minimalist program by Chomsky replaces the levels of DS and SS with a dynamic, derivational system, which starts with a set of lexical items that are put together by the computational system of the language faculty in a highly unified way. At the end we still get two representational levels, LF and PF, which are sent over to the conceptual-intentional and the senso-motoric interfaces. The initial set, the numeration, consists of all lexical and functional elements in their fully inflected forms. These are needed to build up the sentence. They form the basic constituents for the derivational process, which mainly consists of the merging of two such constituents to create a new one. This new constituent can be merged with others, either basic or complex ones, which are already the result of a computational process. The transformational component is introduced by allowing a complex constituent to be merged with one of its own sub component, a process which is commonly called Move. The inclusiveness principle (which excludes the introduction of new elements during the derivation) and considerations of economy build strict restrictions into this derivational process.

The second principal modification that enters the discussion of Generative Grammar is Kayne's antisymmetrical approach. He starts with the observation that a free head parameter would lead to symmetric variations of word orders among languages, which we actually do not find.

These observations lead him to define certain restrictions on the structure of trees. He relates linear word order to hierarchical dominance relations in a surprisingly simple way. This leads to restrictions on constituent structure, which are identical to the common left headed X-bar structures. In particular we get the restriction that every XP is headed by exactly one and only one head (which, in his approach, could be made complex by head movement). It has at most one complement which – if present- is a right sister of the head and at most one specifier which – if present – is the left sister of the $X ^ { \prime }$ node which directly dominates the head (and a potential complement). A principled difference with respect to Chomsky's minimalist approach is the exclusion of more than one specifier, which is crucial for Chomsky's system.

In all variants of Transformational Generative Grammar, it is the head that determines the category and the behaviour of its projection.

Lexical selection restrictions of the head determine whether it has a complement or not and, if so, these restrictions determine some of the semantic and syntactic properties of the complement. Thus, ‘love’ selects either an infinitival clause or a noun phrase. In case of a noun phrase it has to have the feature [+hum] (human). But note that semantic restrictions are not so strict: you can ‘love a pet’, or ‘love this kind of music’ or ‘love Venice’, but at least it assigns a theta role to the object.

The role of the specifier is less clear. During the history of Generative Grammar, different constituents where associated with it. In early analyses auxiliaries were assumed to be in the specifier of verbs, determiners in the specifier of nouns. Both ideas were later abandoned. Longer lasting was the idea that specifiers host subjects, though even this is much debated lately.

GB theories demand moved elements to C-command their traces. This excludes complements from the set of possible landing positions, since these would never C-command their traces. This gives us specifiers as the only landing positions for full XPs. In early GB the transformational component mainly consisted of ‘move alpha’, a rule that allowed every component (heads or XPs) to move freely to any landing position, if not forbidden by some other principle. This freedom allows every specifier to serve as a landing position for a full phrase. Head movement to a specifier position is excluded by structure preserving principles as well as antisymmetric considerations.

In minimalist theories the existence of a specifier is entirely determined by the head. Specifiers of lexical heads are demanded by their argument structure. Specifiers of functional heads are needed for checking reasons. If the functional head has an uninterpretable feature that has to be cancelled (early versions), it attracts overt material.

Another operation that we find in the minimalist framework is adjunction of a maximal projection XP to another maximal projection YP. It expresses modification of YP by XP without changing neither the categorial status of the YP nor its general semantic interpretation. The antisymmetric framework allows only one adjunction to a maximal projection, which can be identified with the unique specifier.

Adjunction of a head $\mathrm { X }$ to a head Y, on the other side, exists even in Kayne's model. It is usually assumed to be responsible for movement of lexical heads to get their affixes assigned or (in a minimalist view) to check their (morphological) features. This movement seems to be restricted by the head movement constraint (HMC), which prohibits skipping intervening heads.

While minimalism tries to search for the most economical implementation of a language device, antisymmetry gave us a theory with highly restricted bare phrase structure. In this chapter I want to give an overview of possible restrictions on structure and movement. I will start with the presentation of a new formalisation of antisymmetric syntax, which is slightly more restrictive than Kayne's original proposal. Then I want to show what kind of restrictions on movement we might expect. Finally I will conclude with a (not complete) discussion about possible parameters that could distinguish languages.

# 4.2 Trees and subtrees

In the following I will assume that syntax is antisymmetric. This means that the sentence can be represented by a tree structure consisting of atomic substructures of maximal projections which have

obligatorily a (overt or covert) head as a defining element, optionally one (and only one) specifier and optionally one (and only one) complement position.

Specifiers and complements can (recursively) host other maximal projections. For the moment, I will ignore the possibility of head adjunction, which raises unwelcome complications. This can be represented as:

![](img/2e19b0600cdffba9ca8439db7ae08b36531709d6d793659c7ee105f9d7ff4ef6.jpg)

I am interested here only in the minimal structure, consisting of the head, the two segments of the maximal projection, and the potential edges to the specifier and the complement. These structures are fully determined by their head. Additionally, I am interested in the connection of this substructure to the rest of the tree. If it not the root of the structure, this projection sits either in the specifier or the complement of another projection, which is defined by its head Y.

Thus the whole tree structure can be fully determined by two sets: the set of all heads and a set of relations R between these heads.

This relation R will be defined as a set of triples R(X, Y, Rel) where Rel could be either ‘Spec’ or ‘Comp’. If Rel is ‘Spec’, XP sits in the specifier position of YP, if Rel is ‘Comp’, XP is in the complement position of YP. ) For example, the notation R(D, I, Spec) is an abbreviation for the configuration of a DP (projection defined by D) sitting in the specifier of an $\mathrm { I P }$ (projection defined by I).

If we exclude the root from the description of a tree, there are two restrictions to the relation R:

1. For each head X there will be exactly one triple R(X, Y, Rel) with this head in first position (every projection is in the specifier or complement of another).   
2. There is at most one entry with a head in second position with the relation $\mathrm { R e l } = \mathrm { S p e c }$ and at most one with the relation ${ \mathrm { R e l } } = { \mathrm { C o m p } }$ (there is at most one specifier and one complement).

The first condition states that we could rewrite the relation R as a function Link with a single argument of heads and an image of a pair consisting of another head and a relation:

$\mathrm { L i n k } ( \mathrm { X } ) = ( \mathrm { Y } , \mathrm { R e l } )$ . Our example from above would be stated in this formulation: $\mathrm { L i n k ( D ) } = \left( \mathrm { I } , \mathrm { S p e c } \right)$ .

To include the root, which, by definition, is not located in the specifier or complement of some other projection, I add the reflexive relation NULL, which is only defined on the root node. We define for the root node A: R(A,A,NULL) or in functional notation $\mathrm { L i n k } ( \mathrm { A } ) = ( \mathrm { A } , \mathrm { N U L L } )$ .

Thus, we get the definition:

A tree is a set $_ \mathrm { H }$ of different heads together with a total function Link: $\mathrm { H } $ $_ { \textrm { \tiny H x } }$ {Spec, Comp, NULL} on this set with exactly one head $\mathbf A \in \mathrm { ~ H ~ }$ with $\operatorname { L i n k } ( \mathbf { A } ) = { \mathfrak { i } }$ (A, NULL), where A represents the sentence.   
The function Link: $\mathrm { ~ H ~ }  \mathrm { ~ H ~ x ~ }$ {Spec, Comp, NULL} is defined on the whole set of heads H with the properties:   
a) NULL is reflexive, i.e. for every A, $\mathrm { B } \in \mathrm { H }$ if $\mathrm { L i n k } ( \mathrm { A } ) = ( \mathrm { B } , \mathrm { N U L L } )$ then $\mathbf A = \mathbf B$   
b) Spec is injective, i.e. for every A, B, $\mathrm { \Sigma } \subset \mathrm { \Sigma } \mathrm { H \Sigma }$ if $\mathrm { L i n k } ( \mathrm { A } ) = ( \mathrm { C } , \mathrm { S p e c } )$ and $\mathrm { L i n k } ( \mathbf { B } ) = ( \mathbf { C } , \mathbf { S p e c } )$ then $\mathbf A = \mathbf B$   
c) Comp is injective, i.e. for every A, B, $\mathrm { \Sigma } \mathrm { C } \in \mathrm { \Sigma } \mathrm { H }$ if $\operatorname { L i n k } ( \mathbf { A } ) = ( \mathbf { C } , \mathbf { C o m p } )$ and $\operatorname { L i n k } ( \mathbf { B } ) = ( \mathbf { C } , \mathbf { C o m p } )$ then $\mathbf A = \mathbf B$

H is the set of non-terminal, non-splitting elements, i.e. the categories that we find in head position of the tree. It is possible to have several heads of the same category in the set, in this case they should be distinguished by subscripts: $\mathrm { D } _ { 1 }$ , $\begin{array} { r } { \mathrm { D } _ { 2 } , } \end{array}$ ,, $\mathrm { D } _ { 3 }$ etc.

As is well known from the earliest linguistic research, human languages embody several hierarchically ordered levels between the full sentence and the single word. A transitive sentence consists of a subject DP and a VP. The VP is further subdivided into Verb and Object DP. Each DP consists of at least a determiner and a NP. Correspondingly, the theory should be concerned with substructures of a tree, i.e. subtrees:

# DEF 2

A connected subtree of a given tree $\{ \mathrm { H . \ L i n k } \}$ is a set ${ \textsc { S } } \subseteq { \mathrm { H } }$ of different heads together with the total function Link/S: $\mathrm { ~ S ~ }  \mathrm { ~ S ~ } \mathrm { ~ x ~ }$ {Spec, Comp, NULL} on this set with exactly one head $\mathbf B \in \mathbf S$ with $\mathrm { L i n k } ( \mathbf { B } ) = ( \mathbf { B } , \mathrm { N U L L } )$ (Link/S means the restriction of the total function Link to the subset S).

But we cannot be sure that the relevant structures we are interested in are connected in all cases. It could be that relevant constituents of the sentence start out as different parts scattered around the basic structure of a tree and only come together during the later derivation. For generality I will add the definition:

A (generalised) subtree G is the union of connected subtrees $\mathrm { S _ { i } }$ .

# 4.3 Basic projections

Thus a subtree, formally consisting of a set of heads together with a function, which relates every head to another one, is different from the notion of phrase. For each head (except root heads) the relation defines how its maximal projection is linked to the rest. In this picture the most natural basic building blocks of sentences are not pure heads but heads with structure: the smallest subtree is one with only one head X, projecting an $X ^ { , , }$ including possibly (empty) edges to specifier and complements without any connection to another projection:

![](img/15d87a888b0d8c82f34853db548a8681b8d8c8a0621bce5b41548bb535bd93b6.jpg)

I will call this atomic subtree a ‘Basic Projection’:

A basic projection is a subtree with only one single head.

Besides their phonetic and semantic content, words in the lexicon also have syntactic information. They are assumed to have certain selectional properties, which dictate whether they need a complement and in that case certain semantic and syntactic restrictions on this complement. Furthermore, many generative theories assume that they have information about their need for overt material in their specifier. Thus the identification of heads with a basic projection seems naturally to come out right. Whether a basic projection has a specifier and/or a complement is dictated by lexical information of the head. In the case of no specifier and no complement the X –head can be directly identified with the basic projection. In the case of having a complement but no specifier the basic projection consists of a head, a mother node $X ^ { , , }$ and an edge to a complement. These identifications are close to Chomsky's definition of bare phrase structure.

This gives us the following basic projections as lexical entries:

a) only head b) head and complement c) head and specifier d) Head, specifier and complement

![](img/e7d08549299a569619a817ad6bcf75658ea080ecbad6854dc26f7895fab12510.jpg)

![](img/d277c096a8288840d234b90c2bedce2fe5a86aac52cbc9986996c05422ae876d.jpg)

In the following I will use only basic projections with all branches (case d), but it should be kept in mind that this is only an abbreviation. For real cases it has to be substituted by one of the above trees.

To express the difference between phrases and maximal nodes of a basic projection I use the notation $X ^ { , , }$ (two bars are added for convenience, since there cannot exist any intermediate $X '$ -level in an antisymmetric structure anymore). So $X ^ { , , }$ is just the name of the (doubled) highest node, whereas XP also subsumes the complete structure below (including all material iteratively found under specifiers and complements).

Whether to include the edges of possible specifiers and complements into a basic projection is arbitrary. In most mathematical definitions of trees edges are always connecting two nodes. In this sense these edges have to be excluded from the structure because specifiers and complements don’t need to be filled in every basic projection (otherwise we would have infinite recursion). But if we just view them as possible links to other atoms we can include them and in the following I will do so.

In contrast to basic projections, XPs are complete phrases made up of all the material under the highest node including everything that is found under the specifiers and complements, including insertion of all lexical material. Formally they are subtrees of a tree which include all the heads that are dominated be the highest node. (Domination beingdefined in the usual way). VP (in the traditional interpretation) is an atomic subtree over $\mathrm { v }$ together with DP (- phrases) linked to specifier and complement position:

![](img/75e769109cb53dc9052255e984cf6c632208aa8f67394ef72a2ab7d903357bb1.jpg)

DEF 5

A phrase XP is a connected subtree $\{ \mathrm { S } , \mathrm { L i n k } / \mathrm { S } \}$ of a tree $\{ { \mathrm { H } } , { \mathrm { L i n k } } \}$ where for every head A, $\mathrm { B } \in \mathrm { ~ H ~ }$ with $\mathrm { L i n k } ( \mathrm { A } ) = ( \mathrm { B } , \mathrm { S p e c } )$ or $\mathrm { L i n k } ( \mathrm { A } ) = ( \mathrm { B } , \mathrm { C o m p } )$ and $\mathbf B \in \mathbf S$ , also $\mathbf { A } \in \mathbf { \Gamma } S$ .

# 4.4 Basic relations

We have to redefine basic relations like domination and sisterhood according to this new picture, since there are no longer any nodes and edges. The relation of sisterhood does not make much sense anymore. This seems to be at first sight an undesirable consequence. We have been used to thinking in these terms for a long time. But do we really want the relation between specifier and $X '$ to turn out to be the same as the one between head and complement? The LCA dictates an antisymmetric structure which contradicts a symmetry of sister nodes. Thus our basic relations, as defined by the definition of trees, are specifiers and complements. But we haven’t expressed the antisymmetry yet. So far, the structure of the basic projection looks very symmetric: there is an open link to the left and one to the right. We could express it thus by the equivalent symbol:

![](img/e08d1dde147e30633cf51bb467b089df0af95040e3c2b2c5ed3f69df616e18f9.jpg)

But this structure is too symmetrical! Specifiers are not in the same relationship to heads! So we need at least the relationship of C-command between them to differentiate.

As a reminder, here again is the definition of Kayne (1994: 16):

# X C-commands Y iff X and Y are categories and X excludes Y and every category that dominates X dominates Y

Thus, specifiers clearly C-command heads and heads C-command complements and everything dominated by them. Specifiers of specifiers C-command the same head as well. This gives us the required transitivity: If one basic projection C-commands another one it C-commands those commanded by the latter as well.

To achieve a suitable definition of C-command I take recourse to the notion of dominance, which serves no other purpose. Because I identify heads with their projections I want to have in the scope of dominance not only the specifier and the complement, but also the basic projection itself:

# DEF 6

A basic projection A dominates a basic projection B of the same tree {H.   
Link} iff   
a) $\mathrm { L i n k } ( \mathbf { B } ) = ( \mathbf { A } , \mathbf { S p e c } )$ or   
b) $\mathrm { L i n k } ( \mathbf { B } ) = ( \mathrm { A } , \mathrm { C o m p } )$ or   
c) $\mathbf { B } = \mathbf { A }$ or   
c there is another basic projection C of {H. Link}with A dominates C and C dominates B

Note that I included the identity relation in definition of the domination thus making it reflexive. A basic projection always dominates itself.

A special case of domination is the immediate dominance relation.

# DEF 7

A basic projection A immediately dominates a basic projection B of the same tree {H. Link}iff

a) $\mathrm { L i n k } ( \mathbf { B } ) = ( \mathbf { A } , \mathbf { S p e c } )$ or   
b) $\mathrm { L i n k } ( \mathbf { B } ) = ( \mathrm { A } , \mathrm { C o m p } )$ or   
c) $\mathbf { B } = \mathbf { A }$

# DEF 8

A basic projection A (antisymmetrically) C-commands a basic projection B of the same tree $\{ { \mathrm { H } } . { \mathrm { L i n k } } \}$ iff

a) $\mathrm { L i n k } ( \mathrm { A } ) = ( \mathrm { B } , \mathrm { S p e c } )$ or   
b) there is a basic projection C with $\mathrm { L i n k } ( \mathbf { C } ) = ( \mathbf { A } , \mathbf { C o m p } )$ and B is domi nated by C or   
c) there is another basic projection C of {H. Link}with A C-commands C and C commands B

It is in fact this definition of C-command that renders the tree structure antisymmetric and thus should be part of the definition of an antisymmetric tree.

The following complex relations will be needed in the course of this chapter:

DEF 9

A right branch of a maximal projection $X ^ { , , }$ is the phrase headed by the complement of X.

A basic projection B belongs to the straight right branch of a maximal projection $X ^ { , , }$ iff there is a basic projection A belonging to the same straight right branch and $\mathrm { L i n k } ( \mathbf { B } ) = ( \mathrm { A } , \mathrm { C o m p } )$ .   
A left branch of a maximal projection $X ^ { , , }$ is the phrase headed by the specifier of X.   
A basic projection B belongs to the straight left branch of a maximal projection $X ^ { , , }$ iff there is a basic projection A belonging to the same straight left branch and $\mathrm { L i n k } ( \mathbf { B } ) = ( \mathbf { A } , \mathbf { S p e c } )$ .

That means that a straight right branch is a sequence of projections connected by a straight line of complements:

![](img/2d9e376b515a35816ddff0971647cc0dc94b81632f236d792bdebb0824c3fbfd.jpg)

whereas a straight left branch is a sequence of basic projections along a straight line of specifiers :

![](img/048ac02620fe85f18e9a789ee729deac68260659039bce35f9918c67db4103f9.jpg)

With these definitions we can also express in a formal way the main skeleton of the sentence, the line leading down from CP over IP to the VP

The main projection line (MPL) is the straight right branch of CP.

# 4.5 Extended projections

Traditionally, phrases are viewed as structures of intermediate level situated between sentence and word. In the simplest picture, a basic sentence consists of NP and VP, the latter being made up of a Verb and optionally another NP. Eventually linguists had to add the functional projections $\mathrm { I P }$ (where auxiliaries or inflections should be situated) and CP (responsible for introducing dependent clauses) above the VP to explain linguistic data. Pollock split the IP further into a Tense Phrase, TP, and an Agreement Phrase, AgrP. It became common to view the new functional projections as building an “extended projection” of V.

Abney renewed the traditional view of the nominal projection (Abney 1987). Previously determiners were viewed as specifiers in the maximal projection of a nominal head. He showed that by taking them as heads of their own projection DP, selecting for the nominal NP as complement, one could explain more data than under the old view. Soon the DP-hypothesis was widely adopted. In analogy to the CP as extended VP, the DP could be analysed as the extended projection of M. Bittner and Hale added a second functional projection above the DP, responsible for assigning case, which they called KP (Bittner and Hale 1995). This completed this analogy.

In the last decade much work has been done to describe the structure of extended projections more explicitely. Nouns can be modified by quite a number of different elements, like adjectives, numerals, qualifiers and demonstratives, which have to be situated in a rich structure with many functional projections above the N, especially when Kayne’s antisymmetric framework is adopted. For the whole sentence, Cinque proposed an extremely rich structure with a hierarchy of over 30 functional projections above the VP, which might be seen as an extended projection of the verb. Rizzi showed that the sentence part, usually called CP, has a much richer structure than assumed in earlier works. Further research (Koopman) showed that even for prepositions we have to adopt a richer structure to account for many elements that come (optionally?) with prepositions (like degree elements such as “right over the bridge”). Kayne’s recent work on prepositions has a structure with two maximal projections, with one being in the complement of the other.

As such, extended projections have to come to play an increasing role in modern generative grammar, particularly when Kayne’s LCA is adopted. But to define them precisely is extremely difficult.

At least for the verbal extended projection we can distinguish three different parts or layers:

The predication layer where predicate (verb) and arguments are inserted in certain local relationship: the VP shell, where we could take arguments as sitting in specifier positions C-commanding their predicate. The modifier layer with adverbs, PPs, modifying affixes and modals which make up the Cinque Hierarchy and replace the old (split) IP. The ‘pragmatic’ layer with positions dictating interlocutory force and information packaging (focus, topic), Rizzi's split CP.

Analogous subdivisions can be made for the DP as extended projection of N. For example:

L'invasione italiana dell'Albania “The Italian invasion of Albania”

The adjective ‘Italian’ and the Genitive DP ‘of Albania’ express the subject and the object of the underlying verb. In addition we have a layer with modifying adjectives and PPs. Demonstratives and determiners finally have more pragmatic value in assigning referential, deictic and (text-) anaphoric properties to the noun.

Modifiers like adverbs, prepositional phrases; modals and dependent clauses as well as inflectional elements specify and modify the meaning of the expression. But one could see this the other way around: the verb with its arguments constitutes an event which itself becomes an argument of another predicate, the modifier: thus, in the sentence

# (4-2) I gave Jane the ball in the afternoon

we could analyse ‘in the afternoon’ as the modifier of the verbal expression “I gave Jane the ball” or we could view “in the afternoon” as predicate designating all events that took place in the afternoon, where the event “I gave Jane the ball” is its argument. The preposition itself could be viewed as a predicate with two arguments: the DP (the afternoon) and the event (I gave Jane the ball). If all lexical elements have extended projections with analogous structure, we have to expect for PPs a (inner) layer where the predicate argument structure is expressed in a way similar to the structure of a VP shell.

Which part obligatorily belongs to an extended projection? Is every functional projection above the VP part of its extended projection? If we take the strong analysis of Cinque’s hierarchy then every FP of the hierarchy is part of the sentence, whether it is expressed overtly or not. In this case we could take every projection above the VP (including the VP itself), to be the extended projection of V. This gives us (in most theories, which state the VP to be lowest part of the sentence structure) the whole sentence. If we take a weaker interpretation of Cinque’s theory, which takes only the overt parts to be present, we can still have the whole sentence as the extended projection of the verb, but with a different structure. So the first question is whether extended projections can have different structures even when extending an XP projected by the same lexical element.

The strong interpretaion of the Cinque hierarchy encounters an additional difficulty. There is a group of modals that seem to be incompatible with questions and imperatives:

(4-3) \* Did you probably go to school? (4-4) \* Go allegedly to school!

This could mean that the value of some force operator in the highest part of sentence selects a different group of functional projections. It seems that a certain part of the split $\mathrm { I P }$ is dependent on two sides of the hierarchy: one projected by the verb from below and the other selected (or not) by the force operator from above. A possible explanation could be that the extended projection of the Verb goes only up to a certain point of the functional hierarchy (below the modal section) sitting in the complement of another (functional) element, which has its own extended projection. But this is highly speculative and the question remains: How high does the extended projection go?

Are extended projections connected? In general there is no reason to exclude unconnected extended projections. We might think of Kayne' s latest proposal of (argumental) PPs generated above the VP and attracting their DP from a position embedded in the VP as an example for this kind of structure:

![](img/06e19d245ed976e8f851fe4a3446e98cf124e68cd432278033c839fce72831d4.jpg)

The two segments in boxes could be viewed as parts of the same extended projection. They are obviously separated be the intervening $\mathrm { v }$ -projection. Another interpretation could be to locate the total extended projection of $\mathrm { P }$ in the upper box including a structural position for the DP.

Some theories (and I will adopt these) postulate functional heads responsible for assigning/checking thematic suffixes such as applicatives to the verb. There are languages like Chichewa that have thematic suffixes that refer to PPs. So it would be desirable to have the corresponding functional heads in the same extended projection as the prepositions. We could think of a structure like this:

![](img/d8d760218501c06cf7d296a02a65074480ea0f7b89f022c6bf745e30aef76a28.jpg)

or the order between $\mathrm { P } \mathrm { - }$ and morph-projections reversed. But theoretically they also could be separated by some intervening material (overt or covert):

![](img/3c6293eb18e741cd97a5cb2baa9cfefc19cd39424b6cc52dbe8132b174efd4a7.jpg)

If the intervening projection cannot be made part of the extended projection, we have the (undesirable) case of disconnected parts that are in some way related. But following the intuition that extended projections are more than just a union of somehow semantically related projections, that they constitute a structural unit layered between basic projections and trees, and given the fact that we have some freedom of definition, I would regard in this case the two parts as different extended projections, which are related externally. So I would stipulate extended projections as being structurally connected.

Another question remains regarding the structure. At first sight, as we look upon VPs and DPs, there is no problem. Their extended projections seem to be complete phrases. But if we look at the Split-IP part of the sentence and extend the Cinque hierarchy to prepositional phrases, we encounter some difficulties.

If we take Kayne's idea of positioning prepositions directly as heads on the main projection line and consider sentences with two prepositional expressions then we would get stacked PPs, one above the other:

![](img/f3bab0e5c9f6173b16925bdf72b82b320518c46930489465f6402f7fc8b08407.jpg)

In the case of two prepositional phrases that independently modify the nuclear event, I prefer not to include the extended projection of one preposition in the extended preposition of the other. In this case it is advisable to take extended prepositions very generally as subtrees. With this structure it is no problem to exclude $\mathrm { P P } _ { 2 }$ from the extended preposition of $\mathrm { P P } _ { 1 }$ .

These considerations lead me to the following provisory definition:

An extended projection of category C is a connected subtree that provides the maximal functional structure that is projected by a word of category C.

This is not a very formal definition. How can it be made more concise? Looking at the structural relation between nodes, or better basic projections and extended projections, we find the following possibilities:

a) Each basic projection belongs to at least one extended projection   
b) There are basic projections that cannot be assigned to an extended projection. We could think of some functional structure, which provides a kind of skeleton to which extended projections are attached (e.g. in specifier positions).

Let’s first look closer at case a), which can be subdivided into the following three subcases:

a1) Each basic projection belongs to one and only one basic projection.

This would clearly define a subdivision of basic projections into equivalence classes, each defined by the membership to some extended projection. Remember that relations of equivalence are symmetrical, reflexive and transitive. If extended projections bear some syntactic reality, the relation “being a member of an extended projection” should be expressed syntactically. Tree structure as dictated by the LCA is narrowly restricted and there are not many possibilities to define meaningful relations of equivalence among basic projections (or nodes).

For instance, the relation “being dominated by the same node” only constitutes a trivial relationship of equivalence. Every node in a tree is dominated by the same node, namely the highest node, the sentence node. Since we defined extended projections as being connected, the relation of equivalence should rely on our basic projections. A minimal non-trivial set of connected basic projections is either in a Spec or in a Comp relationship. Thus, every relation that defines extended projections must be based on one of these two or both.

But neither the Spec nor the Comp relation alone constitute an equivalence relation, because they are not even symmetrical: If the basic projection B sits in the complement or specifier position of A then A could not sit in either of these position of B! But we could extend the Spec relationship to the two relations:

“Sitting on the same straight right branch” and “Sitting on the same straight left branch”, which are both clearly 1. reflexive: trivially every basic projection sits on the same straight right (left) branch as itself. 2. symmetric: If A is on the same straight right (left) branch as B so is B on the same straight right (left) branch as A.

3. transitive: If A is on the same straight right (left) branch as B and B in the same as C then A and C belong to the same straight right (left) branch.

Generally, it can be shown that every equivalence relation that results in connected structures and that is purely structural determined consists of either only specifier relations (the straight left branch relation), only complements (the straight right branch relation) or both (the trivial constituent relation, which has only one class, the whole tree).

![](img/99012e6a19796cf394850fe20465acc68956b0318880c6a56c76c1209fabdb15.jpg)

If the moved constituent has on top an unlinked specifier position, this would be available as a landing site for other elements. No other positions would C-command their traces! This model seems to be too restrictive. More plausible seems to be the only other equivalence relation, the straight right branch model.

This would mean that the whole sentence would entirely consist of extended projections, which build right branch skeletons, to which other extended projections could dock in specifier positions. A possible model could look like this:

![](img/a099e3d26270f6d1a3efd60e384c70647cf8ba62865022874d7ef7e4d27aace8.jpg)

This partly resembles Cinque's model. AdvP, with possibly their own projections, sit in specifiers of the main projection line. But the heads of the functional projection do not. They could be viewed as the link between the extended projections of the verb and the adverbs.

Formally we would define:

# DEF 12

An extended projection of a basic projection A is the set of basic projections that sit on the same straight right branch as A.

a2) At least some extended projections lie entirely within another one. We could view the whole main projection line as the extended VP which bears as an integral part certain extended projections of modifiers. This would coincide with Kayne's view of prepositions as sitting in heads of the main projection line. We could think of $\mathrm { P s }$ sitting below their argument DPs, where they would remain in the case of postpositions but would undergo head movement in the case of prepositions. Their base position would be the focal point from where they project. Here again the question arises of how high we would like to view the extended projection. One possibility would be to stop the extended projection at the beginning of the next modifier:

![](img/5551d4dd28c6ef6b5e1227b097da6013abcdf0e1bf36e0290c20acddb1a6d99e.jpg)

Another possibility would be to view higher extended projections as part of lower ones. If we take a modifying PP as a predication over events, we can say that each higher PP modifies this predication. This could give us the very simple definition for extended projections as taking everything above the projecting category. Problematic in this case would be the CP layer. If there is only one topic and one focus position for the whole sentence, this clearly cannot be reanalysed as information structure of a single constituent like a PP.

Formally we could define the extended projection as a partial straight right branch with the lowest element being the basic projection, which projects:

# DEF 13

An extended projection of a basic projection A is the set of basic projections sitting on the same straight right branch as A and dominating it.

Or if we want to close the extended projection at a (as yet unspecified) height:

# DEF 14

An extended projection of a basic projection A is the set of basic projections sitting on the same straight right branch as A and dominating it, but not dominating a certain barrier projection.

a3) Some extended projections intersect non vacuously with others. This hypothetical possibility does not resemble any linguistically interesting configuration.

If as proposed here the intuitive notion of extended projection has some kind of uniform syntactic structure in a restricted antisymmetric framework, then we do not have many choices. The simplest realisations are the strict right branch equivalence class and the model in which everything above the projection category belongs to its extended projection. But noteworthy also is the model in which several extended categories (e.g. of PPs) can follow each other, like pearls on a string. Data about internal structure and theoretical considerations about movement constraints might help to decide between the different models.

If the complete extended projection sits in the specifier of a projection on the main projection line, we would encounter no problems with internal movements. Consider for example a PP. The lowest projection should determine the whole extended projection. This could be either the preposition itself or an (empty) head of more abstract nature (like PLACE, TIME or INSTRUMENT), but let us assume for the moment it is the $\mathrm { P }$ without overt material in the specifier or the complement. Above we could find a projection with the (‘complement’-) DP sitting in its specifier (as in early version of Kayne's proposal for PPs):

![](img/a41a501651c55de987e506bd9162261e08754ab857df86242d0d9ef9da033706.jpg)

If we don't have any subsequent movements, then the order DP P would correspond to the surface order and we could analyse the $\mathrm { P }$ (or more generally the adposition) as a postposition. But the PP could move to a higher specifier above the DP, so that we arrive at the normal word order for prepositions: P DP

![](img/ce9c93905f45ffe76e679d26070a0e6deb176da7211ef4ed2b29c44663ea1367.jpg)

(X and Y some covert heads)

If the $\mathrm { P }$ is attached directly to the main projection line, we can not move the PP independently without the material sitting in the complement position, which means the whole lower tree. The only recourse would be to move the overt material of the lower tree to an intermediate position between the DP and the landing position of the P, otherwise we violate the Cyclicity Constraint. But then we would have intervening material between the preposition and its complement DP, which is highly undesirable.

![](img/a735fbd1a67e4a198c17839f08185b762a8aa110f3632600a99d87ded44e1519.jpg)

A better solution, if we attach the P directly to the main projection line, would be to abandon the idea of $\mathrm { P }$ moving at all. The contrast between prepositions and postpositions would then have to be accounted for in a different way. A possibility would be to assume that the overt adposition in prepositional languages is base generated above the projection with the DP in its specifier. The head that projects the whole extended projection would be below the latter and overt only in the case of postpositions.

![](img/7d03db9075152ac33ab807ba08527a20b5a2fe151137ed005779503463e81f1e.jpg)

Going back to a head movement analysis, in which Prep is generated below DP and hops around the DPs does not seem to be a good solution. A P sitting along the main projection line would block V-movement by means of the HMC. We would end up with a mixed system with XP-movement for $\mathrm { V } ( \mathrm { P } )$ and head movement for P. On the other hand, there is evidence in Dutch and in German for having both heads circumscribing the DP. Certain complex prepositions can be expressed before and after their noun complement:

um den Berg herum around the mountain ‘her’around “around the mountain”

daar over heen there across to “across it”

er achter vandaan there behind away “away behind it”

(Helmantel 2002: 39)

A more serious problem arises with external movements. If Kayne is right in assuming that certain DPs are moved from below (e.g. the VP shell) into the extended projection of the adposition, we would get a serious violation of the C-command Constraint if the extended projection sits in a specifier position and the landing position is not the outermost specifier. And if it were the outermost specifier, then there would be no position above available for hosting the preposition (after moving from below or base generated after moving the DP). Another serious problem with extended PPs sitting complete in a specifier concerns preposition stranding. Any separation of preposition and DP would be a violation of the strong Island Constraint. If we want at least to respect the weak Island Constraint, we would have to move the constituent we want to extract to the outermost specifier first.

So far we have discussed the possible configurations of extended projections and whether they have a simple syntactic description. But we cannot exclude that the notion of extended projection has no uniform syntactic counterpart.

# 4.6 Sequences of modifiers of the same category

With modifiers I mean all kinds of elements that modify the core sentence. They do not have to be expressed overtly to render a sentence grammatical. There are several types such as adverbs, prepositional expressions, modals or even clauses of various types. The general hypothesis for the following is that modifiers of the same category have analogous internal and external structure. That means they can be represented by the same extended projection, which is linked to the next higher node always in the same way, always as a complement or a specifier.

Hypothesis of Equivalence: all modifiers of the same category have the same extended projection and are linked to the rest of the tree in the same way.

If we think of syntactic structure as mirroring (resp. being mirrored by) semantic relationship we could go one step further and postulate that all modifiers in the same relationship to the lower part of the sentence (in modifying the core proposition) are structurally related in an analogous way to the (lower part of the) tree:

Hypothesis of Linkage: all modifiers are linked to the rest of the tree in the same way.

There has been recently considerable progress in showing that modals, auxiliaries and adverbs can be treated analogously, especially by Cinque's work. One of the major goals of this research is to examine whether it is possible to include prepositional expressions.

# 4.7 Derivations

If we take the view that the principal building blocks of syntactic structures are not heads but basic projections, at first sight we seem to be going against the basic intuition of the Merge operation.

The common way of looking at Chomsky’ s basic operation of connecting pieces is to select a head from the numeration, merge a complement, then merge to this resulting structure a specifier, and so on. But this recursive merging process does not prevent the building of structures that do not obey the restrictions imposed by the LCA. This is quite reasonable, because Chomsky does not restrict himself to the LCA. Let us take a closer look at Chomsky’ s exact description of the mechanism. He states:

derivations make a one-time selection of a lexical array LA from Lex, then map LA to expressions, dispensing with further access to Lex. (Chomsky 1998: 100 f.)

Elements of the lexicon which are considered as assemblies of feature sets, are selected and gathered in the numeration. There follows...

… the operation Merge, which takes two syntactic objects $( \alpha ~ \beta )$ and forms $K \left( \alpha \beta \right)$ from them

Syntactic objects are either elements from the numeration or structures already merged from other syntactic objects. They are combined to build up a new syntactic object.

Imposing the restrictions of the LCA on this mechanism, we could say that UG provides every lexical element (redundantly) with the ability to project at least into a basic projection. In other words, elements in the numeration are words with potential structure, or basic projections dominating lexical words. Let’s look at a very simplified example:

![](img/e012a12cf1e3c1c5bbf5b95650573257e1847526ad68961eb1b6c4af5a8bea0f.jpg)

The operation Merge takes two of these elements and combines them, putting one of the structure either in the specifier or in the complement of the other:

![](img/01ffd973e6769cacb34f87bd3036380d9cbbca1e2556068558fb9ea06b264022.jpg)

Merge can combine elements of the numeration with already merged struc tures:

![](img/156033153d9ddf8df7b751a2905ae122916075e5c610d430b6b0f171adc76df2.jpg)

man In this way, the complete sentence structure can be built out of basic projections with the difference from Chomsky’s definition being that only structures are generated that obey the LCA. We can formally define the Merge operation:

# DEF 15

Given two connected subtrees $\{ \mathrm { H } , ~ \mathrm { L i n k } \}$ and $\{ \mathrm { H } ^ { \prime } , ~ \mathrm { L i n k } ^ { \prime } \}$ with highest nodes A and $\mathbf { A } '$ where A’ has an unlinked specifier, i.e. there exists no $\mathbf { B } \in$ $\mathrm { H } '$ with $\mathrm { L i n k ^ { \prime } ( B ) } = ( \mathrm { A ^ { \prime } , S p e c } )$ . Then the we define the new subtree $\mathbf { M } = \{ \mathrm { H }$ $\cup \mathrm { H } '$ , Link’’ $\}$ with Link’ $\mathrm { \Delta ^ { \prime } / H = L i n k }$ , Link’ $\ ' / \mathrm { H } ^ { \ast } = .$ Link’ and $\operatorname { L i n k } ( \mathbf { A } ) = ( \mathbf { A } ^ { \prime }$ , Spec) and call it the resultant subtree of the operation of Spec- merging $\{ { \mathrm { H } } , { \mathrm { L i n k } } \}$ to $\{ \mathrm { H } ^ { \prime } , \mathrm { L i n k } ^ { \prime } \}$ .

Given two connected subtrees $\{ { \mathrm { H } } , { \mathrm { L i n k } } \}$ and $\{ \mathrm { H } ^ { \prime } , \mathrm { L i n k } ^ { \prime } \}$ with highest node $\mathbf A \in \mathrm { H }$ and lowest node $\mathbf { A } ^ { \prime } \in \mathbf { H } ^ { \prime }$ where $\mathbf { A } '$ has an unlinked complement, i.e. there exists no $\mathrm { \mathbf { B } } \in \mathrm { \mathbf { H } }$ ‘ with $\mathrm { L i n k } ( \mathbf { B } ) = ( \mathbf { A } ^ { \prime } , \mathbf { C o m p } )$ . Then the we define the new subtree $\mathbf { M } = \{ \mathrm { H } \cup \mathrm { H } ^ { \prime }$ , Link’ $\}$ with Link’ $\dot { \boldsymbol { \mathscr { M } } } = \operatorname { L i n k }$ , Link’ $\mathbf { \dot { \Delta } } / \mathrm { H } ^ { \prime } = \mathrm { L i n k }$ ’ and $\operatorname { L i n k } ( \mathbf { A } ) = ( \mathbf { A } ^ { \prime }$ , Comp) and call it the resultant subtree of the operation of Comp- merging $\{ { \mathrm { H } } , { \mathrm { L i n k } } \}$ to $\{ \mathrm { H } ^ { \prime } , \mathrm { L i n k } ^ { \prime } \}$ .

# 4.8 Movement

The next elementary operations besides Merge in the minimalist framework are Agree and Move. Quoting again Chomsky (1998: 101):

…Agree, which establishes a relation (agreement, Case checking) between an [linguistic item w.s.]LI α and a feature $F$ in some restricted search space (its domain)…

…A third operation is Move, combining Merge and Agree. The operation Move establishes agreement between $\alpha$ and $F$ and merges $P ( F )$ to a, where $P ( F )$ is a phrase determined by $F$ (perhaps, but not necessarily its maximal projection) and αP is projection headed by α. $P ( F )$ becomes the specifier (Spec) of $\alpha$ ([Spec, α]). Let us refer to Move of $P$ to [Spec,Φ] as A-movement, where $\phi$ is an agreement feature ( $\Phi _ { - }$ feature); other cases of Move are A’-movement.

Move is an operation which attracts a lower phrase to a higher specifier position in the course of establishing an agreement relation between the head of the attracting projection and a feature in the attracted phrase. This definition of Move is quite restricted, though fully compatible with the view of building up structure out of basic projections.

First consider the moved element: Chomsky describes it as a phrase, though not necessarily a maximal projection, pied – piped by the feature. The fact that he describes a phrase together with the only possible landing site as being a specifier suggests that he is not thinking of moving a head. Head movement is commonly thought of as moving from head to head position in keeping with the head movement constraint (HMC), which forbids skipping intervening heads. In Chomsky’s subsequent paper ‘Derivation by Phase’, we encounter another hint that he does not consider head movement as part of syntax. There we find a remark concerning verb movement, which has been the traditional prototype of head movement (Chomsky 1999: 30):

The account so far leaves open the possibility that V-raising is comparable to TH/EX and DISL: not part of the narrow-syntactic computation but rather an operation of the phonological component.

In the framework presented here, where the atomic building blocks are basic projections, heads do not exist as independent elements. Of course it would be possible to expand the theory to include subparts of basic projections such as heads as independent atoms, in the same way as going from protons to quarks, but we would arrive at a structurally less restrictive model and lose its simplicity. What would it mean to move a head? If we take the head out of its projection and move to another position (adjunct to another head), we leave behind a structure with a possible specifier and complement without the head that projected them. In a copy theory of movement (which is commonly assumed nowadays) the moved element is a copy of the head. The remaining head will not be pronounced. What does it mean to adjoin the copy to another head? In the new position it cannot project its syntactic properties any more. A possible solution would be to view head movement as a movement of only phonetic features to the next head, leaving its syntactic features behind (which would also mean having Agree in situ). But this would be very different from certain kinds of XP-movement, such as focus-movement or Wh-movement, where the moved element takes its wh-feature along to a position where it can be checked and interpreted. In Chomsky (2001: 5) we find:

Let us assume so, understanding this to mean that there is no feature movement and hence no “modified lexical items”(MLIs) with features attached to them. That improvement is of some importance: feature movement is a complex operation, requiring some notion of “feature occurence” that is not very clear; MLIs also introduce many complications, best avoided if possible.

Another asymmetry between head adjunctions and XP adjunctions (or specifiers) concerns the origin of the adjoined element. In the case of XP, the ‘Merge’ of the adjoined element (or the element in the specifier) can be either external (pure Merge) or internal (Move). In contrast there does not seem to exist external Merge of a head to adjoin to another head. The adjoined head must move to its position from inside the structure and not from the numeration. It was suggested that certain kinds of symmetric compounds such as the German ‘Gastarbeiter’ or the English ‘guest worker’, where both elements seem to be in a symmetric relation could be analyzed as merged both in adjoined head positions. Though their relation is more or less a coordination (a guest worker is a worker and a guest), the meaning of the compound is not entirely compositional (a guest worker is not a guest in Bed and Breakfast who repairs the sink!). So we have to assume that the whole construction is found in the lexicon. It is probable that it was originally a coordinated structure like ‘guest and worker’ with a possible subsequent movement from worker to guest - or vice versa. At a certain stage the construction was reinterpreted as a head and entered the lexicon. Furthermore, there is no obvious explanation why the assymetric relation of head adjunction in Kayne's framework should serve as suitable structure of a symmetric construction.

Besides structural arguments, movement of non-phrasal subtrees would betray everything phrases were invented for. They were originally defined as the parts that could not be split via movement.

This is good reason to restrict ourselves to XP movement.

Phrase movement is very easily obtained. One copies the phrase and links the copy to a free specifier branch in the higher structure. The lower copy would either be replaced by a trace with the same linking properties or it remains and loses its property of being pronounced overtly. We achieve this by adding a copy of the phrase to the tree and also by establishing a new relation between the new phrase and the old tree (meaning that we link the whole copy to some empty specifier or complement position).

# DEF 16

Given a tree $\{ \mathrm { H } , \ \mathrm { L i n k } \}$ with heads A, $\textbf { B } \in \mathrm { H }$ , a Relation $\mathrm { R e l } _ { 1 } \in \{$ { Spec, Comp}and $\mathrm { L i n k } ( \mathrm { A } ) = ( \mathrm { B } , \mathrm { R e l _ { 1 } } )$ and another head C and a $\mathrm { R e l } _ { 2 } \in \{$ Spec, $\operatorname { C o m p } \}$ with $( \mathbf { C } , \mathbf { R e l } _ { 2 } )$ ) not in the image of Link (either Spec or Comp is unlinked) then we define the tree $\{ \mathrm { H } ^ { \prime } , \mathrm { L i n k } ^ { \prime } \}$ with $\mathrm { H } ^ { * } \mathrm { = H \cup \mathrm { t } _ { i } }$ and Link’ $=$ Link except for Link $( \mathrm { A } ) = ( \mathrm { C } , \mathrm { R e l } 2 )$ and $\mathrm { L i n k ( t _ { i } ) } = \left( \mathbf { B } , \mathrm { R e l _ { 1 } } \right)$ . We call this the tree deduced from $_ \mathrm { H }$ by Move of the phrase XP with maximal head A from B to C.

This defines Move as building a copy of any element and connecting it to any free link in the tree. However, this definition on its own is quite unrestricted and generates more sentences than wanted. Remember that a good syntactic theory should not only be able to generate all grammatical sentences but also to exclude all ungrammatical ones. What we need, after having constrained X-Bar structure, are well-motivated restrictions on movement.

# What are the elements that can be moved?

According to their categorical status, we have shown that the only elements that can be moved are maximal projections (phrases). This means only XPmovement, there is neither head-movement nor movement of intermediate pro jections.

# What are the possible starting positions?

There are two possibilities: phrases in complement position and phrases in specifier position. Syntactic theory has so far excluded neither. In GB and most minimalist approaches, analyses concentrated mostly on movement from specifier position. But movement of the object, which sits in a Comp position, had also been discussed. Movement out of a complement has lately played a greater role, particularly in antisymmetric analyses especially with the notion of remnant movement. From a greater constituent sitting in a complement position nearly all overt material is moved away. Afterwards, the remaining constituent, the remnant, is moved from its Comp position. Typically this remnant is a VP (shell) from which all arguments have been stripped away. There is no exclusion of one or the other type of movement. For the moment, however, I simply want to present the possibility that movement should be restricted either to specifier movement or to complement movement.

# What are the possible landing positions?

Up to now, we have not defined the possible landing position of movement. In principle, either a complement or a specifier can be moved to complement or specifier position. This is different from Chomsky’ s proposal.

Free complement positions can be found in a projection sitting in the specifier of another projection. But I am not aware of any analysis that involves movement to a complement position. Though not excluded by the structure, it does not seem plausible. X-bar structure is not symmetrical in this respect. Complements are sisters of the head, whereas specifiers sit under one segment of the maximal projection.

Things look a bit clearer once we consider the ECP, which states that empty categories should be properly governed and especially that traces are Ccommanded by their antecedents. A free complement position to the left of the moved category would never C-command it, because complement nodes can only C-command the selecting head. Moreover, every node contained within the complement node cannot C-command anything outside the complement node, so that the possible candidate of movement is clearly outside. I want to examine this condition in detail:

Using the above definitions of straight left and straight right branches we can say that the only available landing site for movement is an unlinked specifier position on the straight left branch of a maximal projection which heads a straight right branch that includes the initial position of the movement. (The LCA in Kayne’s formulation allows asymmetric C-command from specifier of a specifier position, but a complement can never C-command out of its maximal projection):

![](img/d3bed85c9aadc23c36e07ca0637027979416f5d1d3083b86b7a7d8335f06fe71.jpg)

A landing site in the specifier of A in the above diagram is impossible, because it does not C-command the trace.

There is a problem this constraint raises in connection with remnant movement. Most theories of remnant movement give examples where the remnant raises higher in the tree than the first moved element. This ends up in a configuration where the first moved element no longer C-commands its trace (because the latter has moved together with the remnant). But it could be argued that in copy theory of movement, there is still a trace of the first element in its basic position that is C-commanded. To cover these cases (which play a great role if we assume cyclic movement), I will distinguish two constraints:

C-command constraint on movement (strong version): the moved element must C-command its trace at all steps of the derivation (assuming that traces can be removed by subsequent movements and not copied)

C-command constraint on movement (weak version): the moved element must C-command its trace (only) directly after the movement.

A further constraint comes into play in pure minimalist models. In Chomsky’ s model, structure is built from bottom to top. Each step of the derivation is either Merge or Move to the highest position of the actual derivation. Once a level above a given projection XP is constructed, then no further movement is possible to (the specifier position of) XP.

Cyclicity constraint on movement: constituents cannot move to a position below the landing position of an already moved element.

This has consequences for remnant movement. The remnant must always be moved higher than the elements that have been moved out of it. However, this conclusion is in contradiction with the strong C-command constraint. If we maintain both constraints, remnant movement is forbidden!

Another often used constraint should be mentioned:

Island constraint on movement (strong version): No phrase can be extracted out of a specifier via movement.

This constraint has strong validation from existing data. In many cases, where movement has clearly taken place, the moved elements can no longer be separated. Haider (2004) takes this to be a strict constraint:

If grammar theory has produced insights into cross-linguistically valid invariants at all in the last decades, the prime candidate is the opacity effect for constituents in spec positions. Extraction of subconstituents of phrases in spec positions produces robust unacceptability effects. (Haider 2003: 2)

But this claim is not undisputed. If we analyse PPs as components sitting together in a specifier position it is impossible to explain preposition stranding in sentences such as:

Wherei do you come from ti?

Another problem is the case of quantifier floating. Several theories take quantifiers as base generated in the (subject or object) DP, which can potentialy be left behind in all intermediate positions that the DP passes through on its way up to its surface position.

(German)

All die Jungs haben am Dienstag im Park gesungen. All the boys have on Tuesday in_the park sing.PART “All the boys sang in the park on Tuesday.”

(German)

Die Jungs haben alle am Dienstag im Park gesungen.   
Die Jungs haben am Dienstag alle im Park gesungen.   
Die Jungs haben am Dienstag im Park alle gesungen.

In order not to abandon the Island constraint totally, another version can be formulated :

Island constraint on movement (weak version): No phrase can be extracted, via movement, out of a specifier, apart from its outermost specifier.

This gives us an escape hatch: Every constituent that can be stranded first has to move to the highest specifier. Then it can move out.

# Locality constraints, how far can a constituent be moved?

In GB certain barriers blocked constituents from crossing over. In his most recent publications Chomsky defined phases, which serve a similar purpose: to constrain movement. CP and vP are considered strong phases. Movement inside is unconstrained, but for anything to move out, it first has to pass the escape hatch of the ‘edge’ of the phase, which is the highest head (in the case of head movement) or the highest specifier. This constraint can be viewed as a generalisation of our Island constraint in its weak version.

# Relativized Minimality

Rizzi proposed a special type of locality constraint, Relativized Minimality, which is now generally accepted. It states that a relation between two syntactic nodes can only hold if there is no intervening node that could participate in the same relation. For movement, this means a higher element attracts the closest constituent which bears the required features. Rizzi (2002) offers the following example for wh-movement:

(4-11) How did you solve the problem t ? (4-12) I wonder who could solve the problem in this way. (4-13) \* Howi do you wonder who could solve this problem ti ?

In (4-12), which is ungrammatical, a covert wh-operator attracts a wh-element. But between the lower ‘how’ is another intervening wh-element, ‘who’, which is closer. The attraction of ‘how’ is therefore excluded. In order to specify what counts exactly as a potential intervener, Rizzi defines the following feature classes:

Argumental: person, number, gender, case   
Quantificational: WH, Neg, measure, focus, ...   
Modifier: evaluative, epistemic, Neg, frequentative, celerative, measure, manner, ...

(Rizzi 2002: 19)

Thus a quantificational element like a wh-word counts as a potential intervener for a quantificational relation, but not for a modifier.

A last question concerns the motivation for movement:

# Why do constituents move?

There is no exhaustive list of possible answers to this question. There has been much speculations and here I give a short overview of the more important answers.

In the eighties movement was considered unmotivated. The operation ‘move α’ could take place whenever possible, so long as it did not violate other principles. This situation changed with the development of Chomsky's minimalist program. Movement is now confined to the task of feature checking. The derivation starts with a set of items taken from the lexicon, which are bundles of features. Among the features we find semantic features that are interpretable at the conceptual-intensional interface and phonetic features that are interpretable at the sensomotoric interface. But we also find purely syntactic features like case and agreement, which are not interpretable at either of these two interfaces. According to the principle of full interpretation, they have to be eliminated during the derivation. The proper way to do this according to Chomsky is the movement of a (lexical) element with equivalent features into the local neighbourhood of the element with the uninterpretable syntactic features. Here they can be compared, checked, and, if the features are equal, cancelled.

Another motivation for movement often found in the literature is licensing. Syntactic elements with certain features have to be licensed in a certain position. Nominative case could be viewed as this kind of feature. The subject is base generated in the VP shell as an argument of the verb, but its nominative case cannot be licensed there. It must move up to spec IP, which is the usual licensing position for nominative case. Wh-movement is another example. In the sentence:

(4-14) Which book do you read t ?

the object is base generated in the VP shell and bears an wh-feature, which can only be licensed in spec CP. It must therefore move up. As stated in (Koopman 2000: 3):

The specifier-head configuration emerged as “the” syntactic licensing configuration: particular constituents (DPs, wh-phrases, etc.) must appear in a specifier-head relation with a designated head, and they get into this configuration by movement, either overt or covert.

Kayne (2000) proposes a new analysis of the scope relation. In the past, it was commonly assumed that the constituents that are interpreted as being under the scope of a certain operator, have to appear to its right at the interface level of LF, which very often involves movement (overt or covert) of the operator to their left. For certain operators like negation, focus and ‘only’, Kayne shows that their behaviour can be better explained by moving the constituent under consideration to the specifier of the scope-taking operator. One condition seems to be that this movement be overt, another that it be accompanied by verb movement. I will return to the exact kind of derivation later. Here it shall suffice that a motivation for movement can be the need to enter into the scope of a certain operator.

In the previous Chapter, I outlined the idea of Barbiers (1995), who proposed a correlation between X-Bar structure and semantic interpretation. A semantic relation between two nodes is always mediated by an intervening node (a head can establish a relation between its specifier and its complement). A special relation called qualification is defined between a node and its moved copy. I repeat here the relevant definitions for convenience:

# Principle of Semantic Interpretation (PSI)

I. A node Z establishes a S(emantic)-Relation between a node $X$ and a node $Y$ iff $X$ immediately C-commands $Z$ and $Z$ immediately Ccommands Y.

II. A node Z is a Qualifier of a node X iff Z establishes a S(emantic)- Relation between X and Y, and X and Y are coindexed.

(Barbiers 1995: 7)

The moved element moves into a position from where it C-commands the qualifier in order to establish a qualification. For Barbiers, this is the only valid motivation for movement:

# The interpretative nature of movement

All movement is triggered by the need to establish a qualification configuration. If a movement operation does not yield a qualification configuration it does not take place.

(Barbiers 1995: 34)

# No look ahead

Early versions of the minimalist program viewed grammatical sentences as the result of a competition between possible derivations starting from the same numeration. Each of the derivations has to pass over a string to LF with features that are all interpretable by the cognitive-interpretative system and another string to PF with features that are all interpretable by the sensomotoric module. If both strings are fully interpretable, then the derivation converges and survives. Otherwise it crashes.

This idea permits local movements (or their omission) whose motivation is not clear by itself, but is justified only at the end of the derivation. A common view of verb movement in German is to assume that verbs are base generated low. The C head needs to be filled overtly, either by an overt complementizer or by the verb. In dependent clauses with an over complementizer the verb does not move at all, so we get verb final structure. In main clauses the verb rises to the C position and topicalised material goes in front, so that we get a verb second structure. If we consider head movement, the verb has to pass through several heads before eventually arriving at the C position. The question arises of how the verb knows whether at some later step of the derivation an overt C will be inserted or not. Since it needs to move cyclically it cannot wait until the Merge of the C-position and then move from the bottom to the top. It has to move to the next available intervening head position as soon as this head is merged. This means it has to ‘look-ahead’ in order to anticipate the future of the derivation.

This is a view that has changed radically in recent minimalist analysis. Chomsky writes:

... much recent work, which has sought to eliminate comparison of derivations, backtracking and look-ahead, and “non-local” operations generally.

(Chomsky 2000: 3)

Today it is generally assumed that constituents do not ‘look ahead’ to fulfil the needs of a future step. Movement is motivated locally at the step of the movement itself.

# 4.9 The parameters

One of the most intriguing questions of modern linguistics concerns parametric variation among languages. In earlier versions of Generative Grammar, especially in Government and Binding theories of the eighties, we find a vast number of very different kinds of parameters. Salient among these was the head parameter.

A common analysis at this time was to assume that languages differ from each other as to whether heads are found to the left or to the right of their complements. The former property was attributed to VO languages, the latter to OV languages. But mixed cases were also debated. German, for example, which was assumed to have the V and I heads to the right, but the C to the left. In an antisymmetric framework, this parameter is of course no longer available.

Early versions of Chomsky's minimalist program reduced the variational system to only one type of parameter, the weak versus strong feature, which states that every uninterpretable feature of a functional head searches for a counterpart to be checked and cancelled. In order to do this, the element bearing the partner feature has to be inserted or moved up into the specifier of the functional head. Each feature has a meta property: If the property is weak, movement can be delayed until after Spell Out. Principles of economy will assure that in this case the movement must indeed be delayed. Strong features require the cancelling feature in the specifier before the deviation to PF.

Later versions of the minimalist program give a variant of this condition in terms of the EPP parameter: A ‘probe’ can search for an equivalent feature among the elements that are C-commanded by it. Once found, it establishes an ‘Agree’ relation with this goal. Independent of this Agree relation, the EPP feature determines whether the probe needs overt material in their specifier. This can either force the goal to move into this position or an expletive to be inserted there.

The distinction between overt and covert movement can be reviewed in terms of pronunciation of elements in a chain. The minimalist approach can be restated without taking recourse to delayed movement. We can assume that in every language every element moves overtly, but the difference is the place where the moved element is spelt out. Covert movement would thus be equivalent to spelling out the trace and not the moved copy; overt movement would correspond to spelling out the moved copy.

The important new idea here is the assumption that derivational processes themselves do not differ among languages. Parameters are reduced to differences in properties of functional elements. Since functional elements are words, housed in the lexicon, we arrive at a very uniform picture of UG: The general way a numeration is processed is universal, languages differ from each other only in their lexicons. Kayne (2003: 1 f.) shares in general this view:

Now a widespread idea about syntactic parameters is that they are limited to being features/properties of functional elements, as opposed to ever being features of lexical elements. … Limiting syntactic parameters to features of functional heads is also intended to exclude the possibility that there could be a syntactic parameter that is a feature of no element of the lexicon at all, e.g. there could presumably not be a parameter of the sort ' language $L _ { I }$ has or does not have bottom-to-top derivations'.

This constraint dramatically reduces the number of possible parameters. We cannot assume e.g. that one language obeys the C-command Constraint on movement while another does not. Another commonly assumed parameter, the pied-piping parameter, becomes problematic as well.

It is well known that certain constituents that are attracted to a higher position take with them a bigger chunk, i.e. they pied pipe the bigger constituent. Wh-raising is the standard example.

(4-15) Whose cari did you see ti? (4-16) \* Whose did you see $\mathbf { t } _ { \mathrm { i } }$ car?

‘Whose’ is the questioned constituent, but it is unable to move up to sentence initial position without pied piping the whole constituent ‘whose car’. Sometimes it is assumed that the ability to pied pipe is a general property of a language and constitutes a parameter. This would however contradict the idea of restricting parameters to features/properties of functional elements.

If in some language only certain constituents permit pied piping, but others do not, we have the possibility of reducing this parameter to a meta property of a functional head. Let us take the case of a VP that sits in the specifier of a functional head. The VP is supposed to move up via specifier movement in all languages. But languages differ as to whether the VP pied pipes material that is below this functional head. In this case, we can attribute this language variation to a property of the functional head. A parameter such as language A permits pied piping and language B does not at all however could never be reduced to a difference in this kind of property.

Kayne (2003) discusses pronunciation versus non pronunciation of grammatical elements as a possible parameter. He claims that e.g. French has no overt counterpart of the English (grammatical) word ‘little’. What at first sight seems to be the proper translation, ‘un peu’, has, in fact, a nominal character and is more equivalent to English ‘a bit’. This explains the difference between

(French)

(4-17) peu \*(de) sucre (4-18) little (\*of) sugar

He takes ‘little’ as the overt realisation in English of an abstract universal functional element LITTLE, which is only covertly realised in French.

Koopman and Szabolsci (2000) discuss another type of parameter concerning the ‘heaviness’ of constituents in certain specifier positions. Some projections do not tolerate constituents with a certain complexity, at least at the end of the derivation.

In this chapter I have introduced a tree definition based on basic projections, which I hope will lead to new insights into the relationship between syntax and the lexicon. Apart of the restriction that it does not permit head movement, this definition is entirely compatible with traditional antisymmetric views of tree structure. Therefore, I will not make extensive use of these notions in the following chapters. But I will try to evaluate the different derivational models that I present against the possible constraints and restrictions that are presented in this chapter. I will adhere to the hypothesis that a correct grammar, apart from satisfying descriptive and explanatory adequance, should be simple, restrictive and plausible.

# CHAPTER 5

# AFFIXES IN SYNTAX

# 5.1 Introduction

Most linguistic theories propose that the verb is generated in a low position, if not in the very lowest projection. During the derivation it moves up, either overtly (before Spell Out) or covertly (after Spell Out). During this rising, it either checks morphological features in associated functional projections or gets attached to its affixes. Problems with head movement led to the idea of attributing verb movement entirely to PF (Chomsky 1999: 30) as presented in the first chapter. If verb movement is accepted, it is usually supposed to be realised via head movement.

In addition to the conceptional arguments presented in Chapter 2, here I would like to present more data in favour of verb raising via XP movement. In order to get an explanation for certain typological correlations between affixation and syntactic properties, I propose a model where the VP moves into certain specifier positions where it gets attached syntactically to its affixes.

The morphemes I am concerned with here are pure modifiers such as mood, tense and aspect markers. I want to exclude agreement affixes and negation elements as well as valency-changing morphemes such as applicatives and causatives.

Agreement markers seem to be of a different kind as noted earlier by Kayne (1994) and Chomsky. In Cinque (1999: chapter 5.1) we find:

As Chomsky (1995: chapter 4) notes, if all there is to agreement is a morphological relation (with no $L F$ relevance) between a DP in specifier position and the corresponding head, little justification remains for positing the existence of an independent (AgrP) projection (also see Mitchell 1993).

Consequently, we do not find any position for agreement in his hierarchy of functional heads. Speas (1991) agrees with this, giving an example in Hindi in which the semantic verb and several auxiliaries show all morphemes that express agreement with the subject, something we do not find with other types of morphemes:

Raam roTii khaataa rahtaa thaa. Raam.M bread eat.IMP.M PROG.IMP.Masc be.PST.M “Raam used to keep on eating bread.”

(Speas 1991: 412)

Regarding negation, Cinque gives in Cinque (1999) some arguments which show that negation can appear in several distinct positions. For more details I refer the interested reader to chapter 5.5 of this book.

Valency changing morphemes are morphemes which change the argumental structure of the verb. Applicatives render an oblique modifier into a direct object. Causatives add an agentive subject. Reciprocals identify the object with the subject; the resulting verb has one argument less. In this respect passive can also be considered a valency changing element, since it reduces the number of arguments.

It is this close relation to arguments that renders the valency-changing morphemes special. Whether or not they can be considered modifiers like tense, aspect and mood, thus having a place in the hierachy of functional projections is a question beyond the scope of this paper. For recent discussion see Damonte (2004). However, I would like to mention that in most cases where we find superficially non-rigid ordering of morphemes, at least one of these special morphemes is involved. Baker gives several examples from which I present one here. It is from Bemba, a Bantu language:

(Bemba) Naa-mon-an-ya Mwape na Mutumba. 1SG.PST-see-RECIP-CAUS Mwape and Mutumba “I made Mwape and Mutumba see each other.” Mwape na Chilufya baa-mon-eshy-ana Mutumba. Mwape and Chilufya 3pS-see-caus-recip Mutumba “Mwape and Chilufya made each other see Mutumba.”

Quechua is a agglutinating language which allows only suffixing. A huge number of morphemes can combined in one word. This makes Quechua an interesting source of ordering relations among morphemes. Baker gives the example:

(5-4) Maqa-ku-ya-chi-n. beat-REFL-DUR-CAUS-3SG $\mathrm { \Phi ^ { \mathrm { \Phi } } H e _ { i } }$ is causing $\mathrm { { h i m } _ { j } }$ to beat himselfj”

The observed patterns could indicate that these morphemes have a greater degree of freedom to move than other morphemes. An alternative would be to stipulate several distinct positions for each of them, correlated with a slightly different meaning. Either way, both explanations require more research and therefore I want to exclude them here.

# 5.2 Prefixes and suffixes

We have seen in the first chapter that there is a correlation between the order of verbal morphemes and the order of certain adverb types. If we attribute morpheme ordering entirely to an independent morphological module, there is no easy way to explain this correlation. Another surprising pattern is Greenberg's observation that there is a relation between morphology and syntax. His Universal 27 correlates the order noun adposition to the place of affixation:

(27a) If a language is exclusively suffixing, it is postpositional (27b) If it is exclusively prefixing, it is prepositional. (quoted by Hawkins 1983: 21 f.)

If we look at Greenberg's 30 language sample, we find 12 languages that are purely suffixing. They are all postpositional. We find 17 languages that have prefixes as well as suffixes. 15 of them are prepositional, 2 postpositional. Only one of the observed languages is exclusively prefixing and this is prepositional. (Greenberg 1963: 92).Based on this corpus, the generalization (27a) seems to be well founded. The universal (27b) however, is based only on a single language and a generalisation is difficult to derive.

Following this, J. A. Hawkins later published, with G.Gilligan, the results of research of different groups with special interest in the relation between syntactic (VO versus OV and postpositional versus prepositional) and morphologic (prefixing versus suffixing) properties (Hawkins and Gilligan 1988). Altogether they considered about 200 languages and one of the statistical results was the predominance of suffixing over prefixing. Furthermore the authors made a distinction between different types of affixes. Here I give only the results for verbal affixes:

(11) If a language has $N P + P o$ , MOOD affixes on $V$ (if any) are suffixed...   
(12) If a language has SOV, MOOD affixes on $V$ (if any) are suffixed with greater than chance frequency...   
(13) If a language has $N P + P o$ , TENSE affixes on $V$ (if any) are suffixed with overwhelming greater than chance frequency...   
(14) If a language has SOV, TENSE affixes on $V$ (if any) are suffixed with greater than chance frequency...   
(15) If a language has $N P + P o$ , ASPECT affixes on $V$ (if any) are suffixed with greater than chance frequency...   
(16) If a language has VALENCE affixes on $V$ (i.e. INTRANSITIVE / TRANSITIVE / DITRANSITIV affixes), they are suffixed with more than chance frequency...   
(17) If a language has SOV, CAUSATIVE affixes on $V$ (if any) are suffixed with more than chance frequency...

(Hawkins and Gilligan 1988)

Important here is the correlation between the order of the adposition and the MOOD, TENSE and ASPECT affixes, which are pure modifiers according to our definition. For CAUSATIVEs we have a correlation between principal word order (SOV) and affixation, and VALENCE affixes are unconditioned suffixed. The latter two are elements that change the argument structure and the data presented here does not indicate clearly whether we could include them in the set of modifiers.

But agreement affixes are clearly excluded by Hawkins and Gillian from this behaviour:

For the following five affix categories, all four logically possible affix order co-occurrences with word order appear to be possible (i.e. anything goes): POSSESSIVE affixes on N; PERSON-MARKING (SUBJECT) affixes on V; PERSON-MARKING (OBJECT) affixes on V; NEGATION affixes on V; and VOICE affixes on V.

(Hawkins and Gilligan)

Negation and Agreement have been considered by Cinque to not behave like the other modifiers. Since Voice is an argument changing category (passive reduces one argument) it is a candidate for a valency changing element.

Researchers have found that (nearly) all languages that have only postpositions do not have prefixes. If this proves to be a true universal, it would mean that there must be some syntactic explanation for the nature of affixation. If we take both, lexical roots and morphemes, to be seated in heads (and for the moment I don't see any reason why to abandon this assumption) then a pure head movement analysis would have difficulties in deriving suffixing in a way different from prefixing.

Since we know that it is the morpheme that determines the category of the construction root- morpheme and not the root the only possible structure in an antisymmetric head adjunction analysis is:

![](img/79c8f21d2cbf399284b4779e925b04f2812c91650e96700c6e6f75277c75b85d.jpg)

The root climbs up thereby following the head movement constraint and adjuncts to the left (s. Kayne). This gives only suffixing with no room for a syntactic prefixing.

Note that because of the head movement constraint (HMC) the verb cannot skip the prefix and climb to a higher position, so that the prefix could rise later to the same position to adjoin to the verb. Even if this were possible, it would result in a structure like:

![](img/d4c942e82bb28b65d75bfefab8806ec9ed0ec9e1faf5d2dc4938c57e2e7a6865.jpg)

where the head of the construction is not the morpheme, but the root.

But if we take XP movement of a (remnant) VP that has no overt material besides the verb and if we assume that the local relation for establishing affixation is the spec head relation, we have two possibilities:

a) the (remnant) VP moves directly into the spec of the SuffP which gives rise to the structure:

![](img/1bc537032984861d3483f07075566e2021f807af9ece326d7b51aebc1d1c19fc.jpg)

b) the VP moves above the PrefP, but inside its extended projection (let us say to spec, PREFP) and subsequently the pref- moves to the spec, VP:

![](img/b15bd3ed5b4eed07a86744a2a71a39db8ed9f13e66df730f6a6b35ff5b56e4b1.jpg)

The VP, not being restricted by the HMC, can skip the intervening spec, PrefP and the category of the whole construction is determined by the highest head along the main projection line, the PREF-head.

While the second condition seems quite plausible, there are some problems with skipping. It would mean that we would lose all the explanatory force the HMC was constructed for. It seems we cannot get rid of it without substituting it with another constraint.

Rizzi (2002) has shown that the HMC can be viewed as a special concretisation of a more general constraint, Relativized Minimality. He identifies different kinds of categories that inhibit blocking effects for movement of elements of the same kind. These categories are heads, argumental XPs, quantificational non-argumental XPs and non-quantificational non-argumental XPs and modificational XPs. If we abandon head movement, we have to replace the notion of heads with another category. I would suggest the notion of predicate phrase, which would be responsible for (remnant) movement of lexical XPs like VPs, APs or NPs. Movement of these Elements should be blocked by certain interveners. Let's define these possible interveners as elements, which have the same categorical feature as the predicate phrase. For VPs these are the features $[ - \mathrm { N } , + \mathrm { V } ]$ , which are shared by auxiliaries and via percolation also by their projections.

With these instruments we can provide derivations for the patterns of affixation that we find in the languages of the world. Cinque (1999) demonstrated that the order of the affixes are, in the case of suffixes, always in the reverse orders of their functional projections, whereas in the case of prefixes we find either the original order or the reverse order.

# 5.3 Derivation of the inverted order of suffixes.

Let us start with a basic structure with VP at the bottom and one suffix projection above. For the moment we abstract away from arguments in the VP shell. It is either possible that they have been removed from the VP earlier or that they sit in their own projections above the VP:

![](img/2e65fb05637683ff960874aa6ae24487e423f9a87f2140390a2ece0d0f0b4cc3.jpg)

Movement of the VP into the spec of $\mathrm { S u f f _ { 3 } P }$ , thus forming a complex word form:

![](img/dc98c10140c0fef68cbea77fac359de9435eb02a577cac02f12c5785b29c758a.jpg)

Merge of the next higher suffix portion of the sentence:

![](img/22dfda4680fa4735e1a009cb397aae142a1c2165181c7d8a27073002618e0cea.jpg)

Move of $\mathrm { S u f f } _ { 3 } \mathrm { P }$ into the spec of the next higher $\mathrm { S u f f } _ { 2 } \mathrm { P }$ :

![](img/3b63b1819099548bec030ca5f43296934ce13e6453020db05eb1405d4850b268.jpg)

The next affixal projection $\operatorname { S u f f } _ { 1 } \mathrm { P }$ is merged above:

![](img/e33f7e55c53b39f356b06acf81f9d336fdc16b62c78c368ad183f70211a4dbd3.jpg)

and finally the Move of the $\mathrm { S u f f _ { 2 } P }$ into the spec of the $\operatorname { S u f f } _ { 1 } \mathrm { P }$ :

![](img/c652c2ca54da3fcc7895f92d53ce1a5469aa905501723c574b243707b90b61f2.jpg)

which ends with the correct order V-suff –suff –suff .

# 5.4 Derivation of the direct order of prefixes:

Basic structure of remnant VP and one prefixal projection complex:

![](img/7fe0018ca64395e660baffe1f4dd290e71fda34202e22683388faf2dd25abae1.jpg)

Movement of the VP into the spec of $\mathrm { P R E F } _ { 3 } \mathrm { P }$ :

![](img/c2a1a047a5b7bbca31c3c4f6301fb864b9aee08326a120ea5b983088475a32ba.jpg)

Movement of the $\mathrm { P r e f } _ { 3 } \mathrm { P }$ into the spec,VP, being the outermost specifier of the actual highest projection, $\mathrm { P R E F } _ { 3 } \mathrm { P }$ , thus C-commanding (according to Kayne's definition) its trace:

![](img/c4b997b91f17338d672b8d55b246c83044c7495748844b8ad6c632f1cd577901.jpg)

The next prefixal complex is merged:

![](img/964401d4341f38b5f1e4c16c77a43f96518b59ba173dfe6ccdfff1e49a5f5b4d.jpg)

Now the complex built up by the verb and the innermost prefix is moved into the spec position of the $\mathrm { P R E F } _ { 2 } \mathrm { P }$ . This could either be the $\mathrm { P R E F } _ { 3 } \mathrm { P }$ or the VP. I show here the option of moving just the VP. At the end of the derivation I will present the final structure obtained by moving the $\mathrm { P R E F } _ { 3 } \mathrm { P }$ .

![](img/c067bc510ad3043341a9638d696c6e5a1d86970795cfc8656eb8f92add33319e.jpg)

As next step we have to move the $\mathrm { P r e f } _ { 2 } \mathrm { P }$ into the spec of the Pref P:

![](img/cd69df03ba6ae3ec02caef9daed78fd4337f891bc5f9029ff62ca5f7527312e6.jpg)

![](img/dbc13d88a1da28f8cf05dfdd6e6670a5233f3effac22a05e7efcd28efbae140f.jpg)

Movement of VP into spec, $\mathrm { P R E F _ { 1 } P }$ :

![](img/3618141eb0f128009da1aef009795cb97ecf02f6655ec45acc3c173082c98a9c.jpg)

which gives us the right direct order pref1 –pref2 –pref3 –V.

If we move the entire $\mathrm { P R E F _ { n } P }$ instead of the VP out of the spec position we get the following derivation:

![](img/36a9b4b5f8ac5de09cae1195cb04cae9b02df5e751886528ecaaf0b4a0a65b0d.jpg)

Movement of Pref P into spec, Pref P:

![](img/5e63ec6747c71ccaf4a03f207f610bbb7abefbcc7215ea2bd869fc3d28876dd9.jpg)

Merge of PREF P:

![](img/3a3050fdf863f8bf72ee2b8b6ac5033ff9d07318bfbb34a7408f43bc55a1d8dd.jpg)

Movement of $\mathrm { P R E F } _ { 2 } \mathrm { P }$ into $\mathrm { P R E F _ { 1 } P }$ :

![](img/5e4bc0f581a7c49220c996426545f402849c96cfc7b0a9948436e8b6b5a48f6a.jpg)

and finally movement of the Pref P into the spec of Pref P:

![](img/0c16ae7182f33f31e8391b2de635f584665a3b97e9b736429d1b8e94a94913bb.jpg)

From a technical point of view this derivation has two major advantages compared to the one where the VP hops from specifier position to specifier position:

1. The derivation is made up entirely of merge and complement movement. No specifier movement is involved. In this respect it is a step toward a more restrictive theory. In chapter 5 I show that we can derive the various word orders of prepositional phrases with the same kind of movement.   
2. We have a uniform attraction of constituents by their counterparts of the next cycle. $\mathrm { P r e p } _ { \mathrm { n } } \mathrm { P }$ is attracted to the specifier of $\mathrm { P r e p } _ { \mathrm { n - 1 } } \mathrm { P }$ and $\mathrm { P R E P _ { n } P }$ to the specifier of $\mathrm { P R E P _ { n - 1 } P }$ . This also is a step to a more uniform and restricted theory of movement.

The derivation for suffixes and the one for prefixes share some interesting properties. In both the verb rises up as part of a maximal projection into a specifier position. In the case of suffixes it ends up in the specifier of a projection with an overt morpheme. Together they build some kind of complex. The whole constituent sitting in the specifier of the $\operatorname { S u f f } _ { 1 } \mathrm { P }$ together with its head is interpreted as a word.

In the case of prefixes the head of the target is empty but an XP with the overt prefix moves into the specifier of the VP. Here also the word is comprised of a head (the root) and its specifier (the prefix). This could indicate that the structure between specifier and head does not constitute a word boundary.

The first chapter presented the modified LCA presented by Koopman, which states that no overt material can be found in the specifier and the head of the same projection. Like Sportiche she assumes this to be a generalisation of the Doubly Filled Comp Filter. While I rejected the implications concerning the LCA, I still think that the data presented in Koopman (2000) and Sportiche (1996) is convincing. But maybe the constraint is too restrictive and should be replaced by the following constraint:

# Axiom of word boundary:

There can be no overt independent words in the specifier and the head of the same projection.

To clarify, there can be overt material in both, but then the material in the specifier and in the head build parts of the same word. A proposal like this of course implies a greater structure than usually assumed, however a lot of data points in exactly this direction. I again refer the interested reader to Koopman (2000) and Sportiche (1996).

So far we have only stated that there is no word boundary between the specifier and its head. There is no constraint on the inner structure of the constituent sitting in the specifier. This definition gives us the possibility to include phrasal clitics like English genitive ‘s’ into morphological descriptions.

A phrase like ‘the mayor of London's key’ could be analysed as the complex DP ‘the mayor of London’ sitting in the specifier of a projection with the overt head ‘s’.

If we look for a more uniform treatment of prefixes and suffixes we have two possibilities:

1. Suffixes and prefixes are seated always in the same projection AffP and both have an additional projection AFFP above. In the case of prefixes, AFFP attracts the VP and the AffP moves into the specifier of the latter. In case of suffixes, the VP moves directly to the AffP and the AFFP is just an empty projection above.

2. The VP is always attracted by the same projection, the AFFP which is the projection where we find suffixes. The AffP below host prefixes. This generalisation has two advantages over the first: Conceptionally, it is preferred to always have the same projection that attracts the VP. Empirically, we have an account for circumfixes which seem to sit in the same extended projection. In section 3.5 is as an example the derivation of past participles in German.

In the following I will assume a SuffP on top of a PrefP.

The general idea is for each affix to have an extended projection consisting (at least) of a lower PrefP and a higher SuffP. Both heads can either be empty or filled with overt morphological material. If only the lower head has overt material, it is a prefix. If only the higher head is filled overtly we have suffixing. If both heads are overt, they form a circumfix.

Movement is attraction of equivalent projections. A SuffP attracts the SuffP of the lower extended affix projection and PrefP attracts the lower PrefP. Somehow the VP seems to have the same properties as a SuffP for movement properties and thus is attracted to the lowest SuffP.

The suffix derivation and the second prefix derivation share another surprising property: there is no specifier movement involved. The only kind of movement is one which starts from a complement position. If this could be generalized to all kind of movements we would not only arrive at a more restrictive theory as mentioned above, we would also have an explanation for the axiom of word boundary. If movement of a specifier is prohibited, then a head can never be seperated from its specifier. A word can be constructed of several words during a syntactic derivation, but the derivation cannot tear the consituents apart. This has consequences for the analysis of separable verb prefixes in German.

# 5.5 Separable prefixes

Words like ‘aufessen’ (to eat up), ‘umfahren ’ (to run over), ‘anziehen’ (to dress) are usually considered single lexical entries. Their meaning is idiosyncratic and not compositional, though they internally are made up of a root and a prefix that shares the phonological form with a preposition. In dependent clauses the prefixes stay attached to the verb in sentence final positions:

Die Mutter will, dass Peter seine Suppe auf-isst. The mother wants that Peter his soup UP-eats “The mother wants that Peter eats up his soup.”

(German)

Ich habe gesehen, dass Peter den Mann um-fuhr. I have seen that Peter the man AROUND-drove “I saw that Peter hit the man.”

(German)

Ich möchte, dass du eine Krawatte an-ziehst. I want that you a tie ON-pull “I want you to put on a tie.”

In main clauses however, the verb climbs up into second position leaving the prefix behind:

(German)

(5-9) Peter isst seine Suppe auf. (5-10) \* Peter aufisst seine Suppe. (5-11) Peter fuhr den Mann um. (5-12) \* Peter umfuhr1 den Mann. (only possible with the meaning “Peter drove around the man” ) (5-13) Ich ziehe eine Krawatte an. (5-14) \* Ich anziehe eine Krawatte.

These verbs are not to be confused with another group of verbs with prefixes that are not separable like ‘umfahren2’ (to surround by car) und ‘verkaufen’ (to sell). Superficially they are very similar to the first group, consisting also of a root and a prefix which sometimes resembles a preposition. In the second group, however, the prefixes are carried along by the verb during the movement:

(5-15) Peter um-fuhr den Brunnen. Peter AROUND-drove the fountain. “Peter drove around the fountain.”   
(5-16) \* Peter fuhr2 den Brunnen um.   
(5-17) Hans ver-kaufte seinen Wagen. Hans VER-buy his car “Hans sold his car.”   
(5-18) \* Hans kaufte seinen Wagen ver.

The difference between the two groups becomes clearer if we look at the formation of the participle. The formation of the past participle for ordinary words is a circumfix consisting of the prefix ‘ge-’ and one of the two suffixes ‘-t’ or ‘- en’. But in the case of non-separable prefixes, the ‘ge-’ prefix cannot be attached:

(5-19) Ich bin ge-fahren.   
I am PART-drive “I drove.” (5-20) Ich habe Wasser ge-holt.   
I have water PART-fetch “I fetched water.” (5-21) Peter hat seine Suppe auf-ge-gessen.   
(5-22) \* Peter hat seine Suppe ge-auf-essen.   
(5-23) \* Peter hat seine Suppe auf-essen.   
(5-24) Peter hat den Mann um-ge-fahren.   
(5-25) \* Peter hat den Mann ge-um-fahren.   
(5-26) \* Peter hat den Mann um-fahren1.   
(5-27) Ich habe eine Krawatte an-ge-zogen.   
(5-28) \* Ich habe eine Krawatte ge-an-zogen.   
(5-29) \* Ich habe eine Krawatte an-zogen.   
(5-30) Peter hat den Brunnen um-fahren.   
(5-31) \* Peter hat den Brunnen ge-um-fahren.   
(5-32) \* Peter hat den Brunnen um-ge-fahren2.   
(5-33) Hans hat seinen Wagen ver-kauft.   
(5-34) \* Hans hat seinen Wagen ge-ver-kauft.   
(5-35) \* Hans hat seinen Wagen ver-ge-kauft.

The prefix ‘ge’- is blocked in the case of non-separable prefixes. However we do find it in the case of separable prefixes. The interesting point is that here it is not in front of the prefix but directly in front of the verb root. The data suggests that separable prefixes are not prefixes at all. In German there seems to exist a rule that excludes more than one prefix.

However, as Cecilia Poletto pointed out to me, there are some verbs with two prefixes in German. I found the following list:

beantragen, beanstanden, beanspruchen, beaufsichtigen, beauftragen, bemitleiden, benachrichtigen, bevormunden, bevorraten, bevorrechten, bevorschussen, bevorteilen, bevorzugen, veranlagen, veranlassen, veranschaulichen, veranstalten, verausgaben, verauslagen

What is surprising is the order of the prefixes; the separable one is always closer to the verb root than the other. If we took them to be generated higher, German would also be an example of inverted prefix order.

Interesting also is the fact that in nearly all cases there does not exist a verb with only one of the prefixes:

besichtigen, \*aufsichtigen, betragen, auftragen, ?antragen, \*bestanden, \*bespruchen, \*anspruchen, \*beleiden, mitleiden, berichtigen, \*nachrichtigen

On the other side we find related nouns to all of the verb $^ +$ inner prefix complexes:

Antrag, Anstand, Anspruch, Aufsicht, Auftrag, Mitleid, Nachricht, Vormund, Vorrat, Vorrecht, Vorschuss, Vorteil, Vorzug, Anlage, Anlass, Anschauung, Anstalt, Ausgabe, Auslage.

It appears quite plausible that this class of verbs does not exemplify cases of two verbal prefixes but instead denominalisation of deverbal nouns.

Given these facts, the separable prefixes seem to be a counterexample only at first sight. They are not real prefixes and therefore can be separated from the verb. This means we do not expect an internal structure where the prefix sits in the specifier of the VP, shown here with the verb ‘anziehen’:

![](img/f5f0dbf3278c0c3f7a66b4bf40468048cd1eb8f35e86c88186159b441f5c1792.jpg)

But on the other hand the meaning of the whole expression is not compositional. We cannot simply add the meanings of ‘an’ (preposition) and ‘ziehen’ (to pull) to get something like ‘to put on’. Maybe there is a more complex structure in the lexicon which comprises both verbal root and prepositional prefix, together with a tree structure.

![](img/579c313772988300e4bca1af1fb9b2113358ea7be46ad81fef247b175f080df4.jpg)

-zieh This would permit the verb root to move up higher to other affix positions. But the ‘prefix’ has to follow cyclically. The verb would rise to the specifier from where it would attract the participal ‘ge-’ prefix and the ‘an-’ prefix would follow to an even higher position.

Since the participle affix in German is realized as a circumfix, we could posit an overt suffix in the head to which the verb root is attracted:

![](img/e96dd90ffacc129f3969c6623a0798f1d104b978791dbf84e87a67945437f10d.jpg)

Movement of the verb:

![](img/689fbe4a8cfdfb1ef58e1b25ee2a2a61e7531d42f532986e77544eff745514f5.jpg)

Now the PrefP cannot move directly up to the specifier of the VP, because it would take the PP with it and we would end up with the order: \*ge-an-zieh-en. (The alternation from ‘zieh’ to ‘zog’ in the correct form ‘an-ge-zog-en’ is due to allomorphic processes, which are not of interest here). To get the correct word order we have to move the PP first up to the specifier of a higher projection XP with an empty head X:

![](img/53b5bb80c9655d5059458c7a2d70e577a1b7d3fc6559f513e005e50e8eadafe9.jpg)

Now we could move the PrefP with the prefix ‘ge-’ into the specifier position of the verb and arrive at the correct order: ‘an-ge-zieh-en’ with ‘ge-zieh-en’ corresponding to a word. But this last move would violate the cyclicity constraint by not moving to the highest position available in the actual derivation. Or in other words, it would be moved to a position below another moved element. The only way out of this dilemma is to ‘park’ the PP between the suffix and the prefix place, then we can move the prefix. An additional move of the PP would give us the right order. But first we have to move the VP to a position above the PP and below the PrefP.

Let us start with the ‘VP shell’ and an intermediate landing position fo the VP above:

![](img/7d4667b4a34d0d5c6ebbf8d986ed33f2771d42854f68e7cac9d9035b19c10b98.jpg)

First the verb moves up to the intermediate position in spec ZP:

![](img/66df29bfa2bf13e598546d671834c5a08c6e8b76f44d59b7664658e5411a9327.jpg)

Next the PrefP is merged, followed by the Merge of the intermediate landing position YP for the PP:

![](img/67f193b30ee59366cc8fe06c73149ab653dfd6a64ec2a9545bd75b61cfa94338.jpg)

an The prepositional phrase is now available for cyclic movement to its intermediate position in the space between prefix and suffix:

![](img/a13a8432112ebe0df53c3e5386ac381ef878b997e85f7dce19b22abae19060a4.jpg)

Now the SuffP will be merged and attracts the VP into its specifier. As mentioned before, this can be either as pure VP, extracting from the ZP as specifier, or as a component of the ZP. I chose here the second variant in order to be consistent in using only complement movements. But note that this is the only step where there is a choice.

![](img/245ea3a40fac1422871f372079b5df30545c123c4daa23a5ceb059e7feefdb0d.jpg)

The Prefix is now attracted to the specifier of the Verb:

![](img/19e7de5f111fe47da991e27c3ac77c0a4d9453034dacb3d5c73b944a07ef07c3.jpg)

Finally the last projection XP is merged, which attracts the PP (here again the choice between specifier movement of PP or complement movement of YP) to its specifier:

![](img/08ccb71a8a96ffcd519fbc86818c7434e9acd9cfeca64ec8f0b30678d103bf0f.jpg)

This gives us the right order ‘an-ge-zieh-en’ which, after a phonological (or lexical) transformation, becomes ‘angezogen’.

In order to respect the cyclicity constraint various intermediate postions were added. This seems at first sight a prize too high to pay.

One of the intermediate steps was reserved for verb movement, which highly resembles the old interpretation of head movement. It seems that the verb on its way up moves cyclically through many intermediate positions. If we want to eliminate head movement this behaviour must be mimiced in a certain way.

The intermediate position for the PP presents more of a problem. We will see, however, in chapter 5 that there are many independent reasons for assuming this position. It seems that for each modifier corresponding to the Cinque hierarchy (and the extended functional projection which is correlated with the past participle is one of these) we have to assume a much larger extended projection than assumed before. Apart from overt material (like the prefix ‘ge’), there are landing positions for the verb and landing positions for lower modifier material (the PP) in this case. The latter could be responsible for establishing a predication relation between modifiers and events. Here it suffices to notice that this position is made necessary by the idea of assigning affixes in syntax and the Cyclicity Constraint on one side and the ordering of (separable and real) affixes in German.

# 5.6 Derivation of the inverted order of prefixes

Deriving the inverted order for prefixes seems to be more of a problem, because the prefix which is in the basic order syntactically closest to the verb phrase, does not appear closest to the verb on surface order. On the contrary, the closest prefix is generated on top of the others.

Languages that exhibit this pattern seem to be rare, though Navajo is considered one of them. M. Speas gives the following examples:

(Navajo)

(5-36) At'ééd ashkii yidoots'qs. yi-do-o-0-ts'qs girl boy $3 _ { \mathrm { O b j } }$ -Asp-NPST-3Subj-FUT:kiss “The girl will kiss the boy.”   
(5-37) Shíínígháád. shi-0-i-ni-gháád $1 \mathrm { { S G } _ { \mathrm { { O b j } } } }$ -Asp-PST-2SGSubj-shake “You shook me.”

(Speas 1991: 390)

We invariably get the order: AgrObj – Aspect – Tense – AgrSubj – Verbroot

Even if we don't regard the agreement morphemes as part of the Cinque Hierachy, tense and aspect are in reversed order in front of the verb. Refering to Ouhalla (1991) Speas mentions also Berber and Arabic as potential candidates for this type of language and cites these examples:

(Berber)

(5-38) Ad-y-segh Mohand ijn teddart. FUT- ${ \cdot 3 } \mathrm { M } . \mathrm { S g }$ -buy Mohand one house 'Mohand will buy one house.'   
(5-39) Sa-y-ashtarii Zayd-un dar-an. FUT–3M.SG-buy Zayd-NOM house-ACC “Zayd will buy a house.” (Speas 1991: 393 and Ouhalla 1991: 106)

Both languages have the order Tense-AgrSubj – verb root. But the agreement morphems behave differently compared to the morphemes of the Cinque Hierarchy as we saw above in the introduction to this chapter.

Thus I would be careful to establish morpheme ordering just by comparing one of the Cinque morphemes with an agreement morpheme. Ouhalla gives additional data of Berber which justifies the doubt in putting this language into the set of languages with inverted prefixes:

(Berber)

ad-y-ttw-attef uxwwan dudsha. FUT-3SG-PASS-catch thief tomorrow “The thief will be arrested tomorrow.”

(Ouhalla 1991: 93)

Here we have the affix-order Tense – Agr – Voice – verb root. Tense is much higher in the Cinque Hierarchy than Voice which gives evidence for a direct prefix order.

But at least Navajo seems to be a candidate with the correct properties. Given that most languages have a morphology where morphemes that correspond to lower functional projections are closer to the verb stem, this behaviour is unexpected. Speas offers three possible analyses, which all share the same order of syntactic projections above the VP: AgrSP – TP – AP – Agr P – VP.

The Lowering Analysis: The affixes are generated in the heads of the appropriate functional projections. They move downwards and suffix to the next lower head until AgrOP. Finally the whole complex prefixes to the verbal head. It is not clear why we have this asymmetry between suffixing and prefixing. Even worse is the movement analyis. Lowering leaves ungoverned traces which nowadays are excluded by nearly all variants of generative syntax. Speas, also, discards this analysis.

The Long Head Movement Analysis: The head moves across the other morphemes directly in a one step move to adjoin to the (empty) C-head. The rest of the affixes rise in an affix hopping manner to combine with each other. Together they prefix to the V-C-complex. In order to allow for the skipping, the HMC must be weakened in such a way, that certain heads don't count as possible interveners. There is also no syntactic motivation as to why we have suffixing in one case and prefixing in the other.

The Checking Analysis: This analysis can be seen as a predecessor to Chomsky's minimalist approach. The affixing takes place in the lexicon before inserting into the base structure. During the syntactic derivation the verb moves up to check its morphological features. This rising can take place after Spell Out (as in the case of Navajo). Languages with prefixes in direct order exhibit the lucky case where the checking goes from the outside to the inside.

... features are checked from the outside in, as though features of the head of the entire complex are checked and then 'peeled off', saturated, discharged or whatever.

(Speas 1991: 409 f.)

Unfortunately these languages are the only ones. Verbs with suffixes in inverted order or prefixes in direct order have to check from the inside to the outside. Attempts to correlate the directionality of checking with the time of verb raising failed. Speas expected languages with verb movement after Spell Out to check from the outside to the inside. Unfortunately, languages like Japanese which have the verb rising after spell as well do not reveal the same affix order as Navajo. Speas mentions another problem with checking theories:

The sort of cases that become problematic are those in which GFchanging morphology is supposed to be amalgated through syntactic incorporation. Since inflectional morphemes generally appear outside of GF-changing morphemes, a syntactic incorporation theory for GFchanging morphemes is incompatible with a theory in which inflection is added in the lexicon.

(Speas 1991: 410)

The Lowering Analysis is not compatible with the antisymmetric framework presented here. The Checking Analysis, however, is not based on particular assumptions about phrase structure. Since we have no idea how the checking correlates to syntactic derivation, I will not deal with this analysis here, but it could be interesting to see, whether and how the Long Head Movement Analysis could be modelled in terms of pure XP-movement.

Instead of the verb moving to adjoin to another head (whether this is C or something else does not play any role for the argument) the entire VP moves via XP movement to a higher spec position. In contrast to the long head movement, there are no conceptual difficulties with intervening heads.

The affixes cannot simply move up after this VP- movement because this would be a strict violation of the Cyclicity Constraint. If the whole tree of affixes first moves into the specifier of the VP (prefixing) and then the single affixes rise via XP - movement inside the tree, we get a less problematic derivation. To exemplify, I start with a structure containing a VP at the bottom and two affix-projections on top. As a next step a higher XP is merged, which I take to be some part of the left periphery. XP attracts the VP. In the next step the whole affixal complex $( \mathrm { { S u f f } _ { 1 } P ) }$ is attracted to the specifier of the VP:

![](img/434dc1c26a49b3d4508bac26e5b8f3d4d60219cffd78a390ea62c0e7dc4449ed.jpg)

Now $\operatorname { S u f f } _ { 1 } \mathrm { { P } }$ (which corresponds to $\mathrm { P R E F _ { 1 } P }$ in the above derivation!) attracts $\mathrm { S u f f } _ { 2 } \mathrm { P }$ (the former $\mathrm { P R E F } _ { 2 } \mathrm { P }$ ):

![](img/e51b1bca4886d3e64e1dc54a748cefa477d5de1a32071097e91149bcf6e4696e.jpg)

This gives the right inverted prefix order as expected. Note that it makes no difference whether we have overt elements under the Suff-head, corresponding to suffixes, or overt elements under the Pref-head, corresponding to prefixes. In both cases the derivation would be the same.

However it seems odd to have movements inside the subtree of a specifier. Though theoretically possible, this would be a new kind of derivation, which, for the moment, I would like to avoid. Furthermore, this derivation raises the question as to why the $\operatorname { S u f f } _ { 1 } \mathrm { P }$ does not attract the $\mathrm { S u f f _ { 2 } P }$ at an earlier point of the derivation, when the full (overt) VP is still sitting in the complement position of the $\mathrm { P r e f } _ { 2 } \mathrm { P }$ . This is a violation of the rule ‘attract as early as you can’ which we can view as a variant of the Cyclicity Constraint. For these reasons I don't consider this type of derivation a valid solution.

To avoid the cyclicity violations, we have to move the VP cyclically up as in the case of ordinary prefixing. The difference is that the attraction of the lower prefix to the spec of VP is blocked.

We start with the VP below and one extended affix projection above:

![](img/ea757618b5ef559cc86b8b32bee4a4583f93a030a839e9337d402c639447c299.jpg)

As usual (as in ordinary suffixing an prefixing) the VP is attracted to the specifier of SuffP:

![](img/70c0101781889e845b5615d2f23f18950f601a75d72bcd3dd56ec17aa7e0d447.jpg)

This time the attraction of the PrefP to the spec of VP is blocked. The next prefix projection is merged instead:

![](img/b1a3a4007e79565cd04f2940fcc853b9fa798960b0917e4b1318b194ff525f1d.jpg)

This Pref P can this time attract directly the Pref P, which hops around the VP:

![](img/ca41089ad339112bf021858ac4efb32c256094ba67a02780cb38721059bb6372.jpg)

Now the second part of the affix2- projection is merged, the $\mathrm { S u f f _ { 1 } P }$ :

![](img/7f1dd1789b706ac16b794e353b8edb137fb3ac6d1ed1925f745fdd5995881589.jpg)

Suff $\mathrm { \dot { \Omega } _ { 1 } P }$ can attract the $\mathrm { S u f f _ { 2 } P }$ which carries along the verb:

![](img/7e3a7f110c1f1641eb1668a0c39b83189076978fd01ca35c23498cdeb411700e.jpg)

This derivation continues cyclically until all prefixes are passed. At the end they are all in inverted order to the right of the verb. The last step moves the $\mathrm { P r e f _ { 1 } P }$ to the specifier of the VP. Without losing generality I present the case of only two prefixes.

![](img/9db16fb6855f837731527f59c93033fee1634623a2f90205e26b4f1c7a00767f.jpg)

This derivation is very close to the prefix derivation. The major difference is that only the highest prefix can be attached to the verb.

We can immagine that every functional PrefP has a property which determines whether it can be attracted to the verb or not. This would be a perfect parameter in the sense of Kayne (2003). If all of the PrefPs had this property, the lowest would be attracted to the VP and occupy this position, so the others cannot go there. Thus, we can only detect the lowest in the sequence of prefixes which can be attracted to the VP. If this is the right way of thinking, than we expect languages where the lowest PrefP that can be attracted is neither the lowest prefix of all, nor the highest, but some prefix inbetween. Let's assume we have a sequence of four prefixes, where the second (from below) has this property, but the lowest does not. The value of this parameter for the prefixes above does not play any role. The derivation in this case would be absolutely equal to the one above until the two lowest prefixes are moved to the spec of the VP.

With a little renumbering we get:

![](img/b6af47074dfff96c5d48513677c90e61549cca20cba417153823f93d0ee647ee.jpg)

Merge of the next extended affix projection with Pref P and $\mathrm { S u f f } _ { 2 } \mathrm { P }$ :

![](img/7204df87c71bd742910a41bfb846e55143ec14568bb2c2e308a7aa687c195922.jpg)

Pref P cannot attract any PrefP, because they are too imbedded in the specifier. $\mathrm { S u f f } _ { 2 } \mathrm { P }$ can attract $\mathrm { S u f f } _ { 3 } \mathrm { P }$ :

![](img/4945e18ad050fdacb01a3ab1b6e27e53d6ac415e957ba13423888e6fa38eaf3f.jpg)

Now the Pref P is in a position from where it can attract the Pref P:

![](img/6f5153972f00ff8e0e1a9fb090f1d1befd0b829dde155164da9ef89106b38b69.jpg)

The last extended affix projection is merged and its $\operatorname { S u f f } _ { 1 } \mathrm { P }$ attracts the lower $\operatorname { S u f f } _ { 1 } \mathrm { P }$ :

![](img/7c506fde7bfa52df181f220f05782bfba69626203b509b710e8bd2bca7a7036e.jpg)

and the Pref P can be attracted to the Pref P:

![](img/e1203290c79e3c31ea28074e59ba22394b76f0cc9eb1d870ad63cfcda7d961ee.jpg)

This gives us the order pref1- pref2- pref4- pref3 – verb root, or more generally the direct order of prefixes up to a certain point followed by reverse order followed by the verb root. To my knowledge so far no language has been detected, that exhibits this pattern. If this pattern would be found in a natural language, this would be, indeed, a fact in favour of this kind of derivation.

Now I want to present a much simpler idea which could explain the facts of Navajo and related languages. The affixes that appear in front of the verb are in inverted order, something which happens with suffixing. One might think that in fact they are suffixes of an empty head. The prefixed verb would be in reality a complex of an inflected auxiliary, whose root is unpronounced followed by the lexical verb in infinite form. Let us take the Navajo example from before:

(Navajo)

(5-37) Shíínígháád. shi-0-i-ni-gháád 1SGObj-Asp-PST-2SGSubj-shake “You shook me.”

We might interpret it as

(5-37)' Shííní gháád. $\emptyset$ -shi-0-i-ni gháád AUX-1SGObj-ASP-PST-2SGSubj shake “You shook me.”

where the Aux is an unpronounced auxiliary. This reduces the problem to simple, ordinary suffixing. This hypothesis is in perfect agreement with Kornfilt's analysis of certain Turkish verb forms as verb auxiliary complexes, which were previously considered simple verbs.

In Kornfilt (1996) she compares two types of inflected verb forms, ‘genuine verbal forms’, i.e. Definite Past and Conditional, and ‘fake tenses’, which constitute more or less the rest. I want to exemplify the difference of these two for the verb ‘git’ (go) with the paradigms of the definite past as a representative of the genuine forms and the paradigm of the future for the fake forms:

<html><body><table><tr><td>Definite Past</td><td></td><td>Future</td></tr><tr><td>1.sg</td><td>git -ti-m</td><td>gid - eceg - im</td></tr><tr><td>2.sg</td><td>git-ti-n</td><td>gid -- eceg - sin</td></tr><tr><td>3.sg</td><td>git-ti-</td><td>gid- eceg-</td></tr><tr><td>1.pl</td><td>git-ti-k</td><td>gid - eceg - iz</td></tr><tr><td>2.p1</td><td>git-ti-niz</td><td>gid - eceg - siniz</td></tr><tr><td>3.pl</td><td>git  ti - ler &#x27;go&#x27; - PST - Agrs</td><td>gid - eceg - ler go&#x27; - FUT - Agrs</td></tr></table></body></html>

The accent represents stress, which is usually word final in Turkish. There are two striking differences between the two groups. First, the agreement morphemes are a bit different; second, the stress patterns are not alike. In the first group the stress is always on the last syllable as expected. In the second group we find the stress at the last syllable of the tense morpheme. Kornfilt's explanation is simple and convincing. What seems to be a simple inflected verb form in the second group is, in fact, a complex of a participle and an inflected auxiliary.

She argues, that in Turkish the copula in the present tense is phonetically empty, a phenomenon that is found in many other languages, (e.g. Russian). The difference between the agreement morphemes is due to the difference of the selecting verbs. The stress pattern in the second group becomes regular if we add a rule that deletes final word stress of a word that is cliticized to another word. And so we get for the second group:

1.sg gid – ecég Ø – im   
2.sg gid – ecég Ø – sin   
3.sg gid – ecég Ø – Ø   
1.pl gid – ecég Ø – iz   
2.pl gid – ecég Ø – siniz   
3.pl gid – ecég Ø – ler   
‘go’ – Fut. Cop. – AgrS

Regarding stress the two parts behave like two words, where the second is cliticized on the first. With respect to vowel harmony, they behave as one word. The root vowel dictates the set of vowels for the whole group. Kornfilt writes:

The values for the backness and rounding features of all regular suffixes, irrespective of whether they are derivational or inflectional and irrespective of their category features, are not specified; these two values are determined by VH, depending on the values of the harmony domain which spread from the initial vowel of that domain.

(Kornfilt 1996: 113)

She distinguishes between the ‘small word’ which determines stress and the ‘word’ which is the domain of vowel harmony. In the cases of the ‘fake tenses’ the words are composed of two small words.

This distinction resembles the subdivision of morphemes into two strata that we find in lexical morphology. Stratum 1 contains non-neutral affixes which when attached to the root, could change the word stress. Stratum 2 contains neutral affixes, which never change the stress of the base they are attached to. The common idea of lexical morphology was that stratum 1 affixes are attached to the root before stratum 2 affixes.

It seems unlikely that the analysis of Kornfilt can be generalised to all of these cases. An important question however is whether the distinction between the two types of affixation can be modelled structurally in the framework pre sented here.

A close examination of the possible solutions would be beyond the scope of this work. I present here just some raw ideas.

So far the Axiom of Word Boundary is the only relevant definition, giving us some constraints in the search for a structural representation of affixation, leaving some freedom for the internal structure. Until now we had words that are represented as sequence of basic projections, sitting in a specifier of each other. The head of each basic projection bears either the root or a morpheme:

![](img/55c0cf525cc72bbddb412cb7a68b08b23762f8f029215881da622bb2032a8408.jpg)

We could think of more complex structures where in the specifiers there are not just basic projections but larger constituents with the overt morpheme imbedded more deeply:

![](img/ba0c2194a3bfe7d6841defcde528f9e14895bdec1123a8be45841bff580499a6.jpg)

There is no word boundary between the empty copula and its specifier, which has the whole morphological material of the participle ‘gideceg’. There is, however, a word boundary between the head $\mathrm { X }$ and its complement, which bears the same participle. What looks at first sight to be a contradiction could be, in fact, a possible way to stipulate different grades of word boundary.

Along these lines we might interpret the Navajo example (5-37) as the clitizisation of an inflected unpronounced auxiliary to the root of the main verb. I repeat the relevant example here:

(5-37) Shíínígháád. shi-0-i-ni-gháád $1 \mathrm { s g } _ { \mathrm { 0 b j } }$ -Asp-Past-2sgSubj-shook “You shook me.”

which I might interpret as (5-37)' Shííní gháád. $\emptyset$ -shi-0-i-ni gháád AUX-1SGObj-ASP-PST-2SGSubj shake “You shook me.”

The auxiliary is base generated in a very low position and rises as AuxP up to the SuffPs above where the overt heads of the latter become Suffixes. The main verb either rises in one step to a position above the highest SuffP or cyclically around the single Aux–Suff-complexes. Finally a projection (let's call it XP) that dominates the inflected auxiliary moves up into the spec of the VP.

The last configuration would be something like:

![](img/3a3767043d01572700a3f10a792be87c786c5386dfea74d729db731b47b0ad26.jpg)

If this analysis turns out to be correct, then the question arises whether we can obtain a structure which seem to be superficially like a verbal root followed by suffixes in direct order, but is, in reality, the cliticising of a prefixed (empty) auxiliary to the moved verb. For the moment I see no reason, why this should be excluded, although, so far, no languages with suffixes in direct order have been described.

# 5.7 Fused morphemes

So far we have seen affixation in the case of agglutinative morphology, where every morpheme corresponds to a single phonological element. I will rely on a definition given by W. Bisang (personal communication) who also refers to Haspelmath.

Kumulation (Flex) vs. Trennung (Aggl) von Funktionen:   
In flektierenden Sprachen erfüllt ein Morphem oft gleichzeitig mehrere Funktionen, in agglutinierenden Sprachen erfüllt jedes Morphem nur eine   
Funktion   
In fusional languages, each morpheme serves several purposes; in agglutinating languages, each morpheme has only one function.

Formale Varianz (Flex) vs. Formale Invarianz (Aggl) von Morphemen: In flektierenden Sprachen variiert die Form der Morpheme - sowohl des Stammes als auch der Affixe (vgl. Allomorphie). In agglutinierenden Sprachen erscheinen die Morpheme konstant in der gleichen Form. In fusional languages the form of morphemes (affixes and root) can vary, in agglutinating languages the form of morphemes is constant.

Diversität (Flex) vs. Einheitlichkeit (Aggl) von Affixen:   
In flektierenden Sprachen werden für ein und dieselbe Funktion oft mehrere   
unter-schiedliche Morpheme verwendet, in agglutinierenden Sprachen wird die   
gleiche Funktion immer durch das gleiche Morphem ausgedrückt. Fusional languages often use several different morphemes to express one function, agglutinating languages always use the same morpheme.

(Translations by me)

In this passage we find a tripartite distinction between morpheme, function and form, where morpheme seems intermediate between function and form. If ‘Kumulation’ and ‘Diversität’ are combined we get as definition for agglutinative languages, a one to one correspondence between function and form.

An example of a fusional language is Italian which I exemplify with the paradigms of the ‘imperfetto’ and the ‘passato remoto’. These two forms have the same tense feature, namely $\left[ + \mathsf { p a s t } \right]$ , and are distinguished by a feature [- perf] for ‘imperfetto’ and [+perf] for ‘passato remoto’ (‘perf’ being an abbreviation for ‘perfective’). I choose the verbs ‘amare’ (to love) and ‘temere’ (to fear). The suffix ‘-re’ marks the infinitive. For comparison, the present tense form are also shown.

<html><body><table><tr><td></td><td>Presente</td><td>Imperfetto</td><td>Passato Remoto</td></tr><tr><td>1.sg</td><td>amo</td><td>amavo</td><td>amai</td></tr><tr><td>2.sg</td><td>ami</td><td>amavi</td><td>amasti</td></tr><tr><td>3.sg</td><td>ama</td><td>amava</td><td>amo</td></tr><tr><td>1.pl</td><td>amiamo</td><td>amavamo</td><td>amammo</td></tr><tr><td>2.pl</td><td>amate</td><td>amavate</td><td>amaste</td></tr><tr><td>3.pl</td><td>amano</td><td>amavano</td><td>amarono</td></tr><tr><td></td><td>Presente</td><td>Imperfetto</td><td>Passato Remoto</td></tr><tr><td>1.sg</td><td>temo</td><td>temevo</td><td>temei</td></tr><tr><td>2.sg</td><td>temi</td><td>temevi</td><td>temesti</td></tr><tr><td>3.sg</td><td>teme</td><td>temeva</td><td>teme</td></tr><tr><td>1.pl</td><td>temiamo</td><td>temevamo</td><td>tememmo</td></tr><tr><td>2.pl</td><td>temete</td><td>temevate</td><td>temeste</td></tr><tr><td>3.pl</td><td>temono</td><td>temevano</td><td>temerono</td></tr></table></body></html>

The two verbs belong to different verb classes, those that end with ‘-are’ and those that end with ‘-ere’. The ‘-re’ we already determined as an infinitive suffix. The vowel in front (‘a’ and ‘e’) is a class suffix whose semantic value is not clear. It is not independent of the verb root, since we cannot combine class suffixes and roots in a free manner: \*amere, \*temare. Thus it must be somehow in the lexicon. I will return to this issue later.

Comparing the three forms, we can establish agreement morphemes (-o, -i, -0, -mo, - te, -no). However, we see that in the case of the 1st person plural present tense, 1st person singular passato remoto, the phonetic form is not easy to recognize, but this could be attributed to some phonological process.

For the imperfetto we can establish ‘v’ as the determining suffix. This must somehow encode two features: $[ +$ past] and [-perf]. We can infer, that one of the two features is realised by an empty phonetic form. Given the fact that we do not have any overt morpheme for the present tense ([-past]) we could choose $\mathbf { \Delta } ^ { \circ } \mathbf { v } ^ { \prime }$ to be the representation of the past morpheme. This gets support from the idea, that imperfectivity is the unmarked form.

Then we expect to find the ‘v’ in the passato remoto as well, since it shares the [+past] feature with the imperfetto. But we don't find it there. Even worse we don't find any phonetic form, that all morphemes of the passato remoto have in common (apart of the root and the class suffix). It seems that especially in this case tense features, aspect features and agreement features are fused into an entire phonetic complex, which cannot be subdivided into distinguishable morphemes.

In order to explain this phenomenon without giving up the idea of affixes in syntax, I will rely on an idea presented by Michal Starke at the East European Summer School 2002 in Novi Sad. As in many modern morphological theories such as Distributed Morphology, we can assume a distributed lexicon. This assumption gets some support based on new results from neurolinguistic research.

One lexicon, Lex , lists all so called lexical elements such as noun or verb roots with their semantic and syntactic properties such as argument structure and thematic role selection. The entries to this $\mathrm { L e x } _ { 1 }$ are feature bundles, from which the numeration selects for insertion into the syntactic structure.

I take the set of functional elements such as $[ +$ past], [-epistemic] or $\left[ + \mathrm { p e r f } \right]$ to be universal. As presented in Chapter 2, Kayne proposed to locate all parametric variation in properties of functional elements. If we want to follow this line, we have to fix these properties in lexical entries. Whether functional elements and feature bundles of verb roots are to be found in the same lexicon is another question, which has no effect on the ideas presented here.

The syntactic module operates with these entries and builds via Move and Merge a hierarchical structure that is passed over to a morpho-phonological module, which has access to another lexicon. This second lexicon, $\operatorname { L e x } _ { 2 }$ , correlates syntactic structure including feature bundles in terminal nodes to phonological representations. Morpho-phonological rules form the phonetic string, which represents the sentence.

In the case of agglutinating morphology there will be an entry in $\mathrm { L e x } _ { 2 }$ for every root and for every morpheme.

But for fused morphology there will also be entries for more complex syntactic structures. I agree with Starke's assumption that the morphophonological module first tries to retrieve bigger syntactic trees in $\mathrm { L e x } _ { 2 }$ , before searching for smaller chunks. I want to describe this process in more detail for the representation of the 1st person plural, passato remoto for the verb ‘amare’.

At the end of the derivation we can have a structure like:

![](img/b40fcd6c3816d509d5ac0e3195d1fa3142f42ae315dc7f95ba60b9fb27e4df2f.jpg)

The morpho-phonological module first searches in $\mathrm { L e x } _ { 2 }$ for the maximal entry. In this case this is the whole tree together with root and all suffixes. But the module won't find an entry. The next steps will be to look for entries for trees with ‘ama- +perf - +past’ and ‘ama- +perf’ which will not give a positive result. Only the search for ‘ama-’ will be successful. The result is the phonetic string ‘ama-’

Now the module will look for the tree that comprises ‘+perf- +past 1st.Pl’. This entry will also be empty. So the module will look for ‘ +perf- +past’. This time the search is successfull and will reveal the phonetic string ‘-m-‘.

Finally the module has to look up the tree for ‘1st.Pl’. It will return the string ‘-mo’. Note, that in the representation of the last string there is no ‘-‘ to the right. This indicates that the morpheme closes the word.

Now the strings are concatenated and after some phonological processes (which in this case maybe redundant) the module produces the string ‘amammo’.

This example should only serve to exemplify the assumed procedures. It is by no means meant to provide the correct morpho phonological correlations. In fact it might be more plausible that ‘-mmo’ represents the fusion of the morphemes ‘+perf- $^ +$ pass 1st.Pl’.

There remains a small puzzle. In the 1st.sg and 2nd.sg forms of the present tense there is no trace of the class suffix. This becomes more surprising if we look at the forms of the ‘congiuntivo’ (subjunctive):

<html><body><table><tr><td>amare</td><td>temere</td></tr><tr><td>ami 1.sg</td><td>tema</td></tr><tr><td>2.sg ami</td><td>tema</td></tr><tr><td>ami 3.sg</td><td>tema</td></tr><tr><td>1.p1 amiamo</td><td>temiamo</td></tr><tr><td>2.p1 amiate</td><td>temiate</td></tr><tr><td>3.pl amino</td><td>temano</td></tr></table></body></html>

In the singular forms we do not find the class suffix at all. But the endings for the verbal form are determined by it. As already said, it does not give any semantic contribution. Furthermore the suffix seems to be part of the lexical representation. I assume that the representation of the verb root of ‘amare’ is the following syntactic tree together with the features of ‘am’:

![](img/dc0b28250bd29ef6ad9a0cb6a56b6dbdcc991ebe68392a658ed98a101dd861be.jpg)

This tree will be inserted as VP in the sentence and it will move up as one constituent to take the rest of its suffixes. In the case of the ‘congiuntivo’ it will meet a suffix with the abstract features $[ +$ subj] before climbing further up to get the agreement suffixes. The resulting structure will be:

![](img/8c60a36a8dcff1256fd62f8d2e96c35b431dcf2f0a8555048d1d64dcbeea3d57.jpg)

This time the module will find an entry for ‘am-‘ giving ‘am-’ and an entry for ‘-a- +cong 1st.sg’ giving ‘i’. After concatenation we get ‘ami’.

# 5.8 Arguments

So far I described only the movement of the verb in order to get its affixes attached. Including arguments, such as subject and object, complicates the picture.

In the case of pure suffixing the derivation can be extended straightforwardly. I choose the sentence ‘John loved Mary’ where we can analyse the verb as composed of (at least) two morphemes: the root ‘love’ and the tense morpheme [+past]. The root is inserted in the lowest part of the VP Shell.

Above the root we find projections that host the object and the subject.:

![](img/29d36df175b5e36946288ad76117a9c5d83a3ce2cb8151da9724d577c06fbe4d.jpg)

Abstracting away from agreement and other possible invisible modifiers the next level to merge is the extended projection of the past morpheme. First the empty PrefP is merged, then the SuffP with the past morpheme.

![](img/513592deaf58e0982e4f3cdbe8335d94b51512255e1a0c874d9753743cca10ab.jpg)

The verb moves into the suffix projection:

![](img/95f73a61549d660aa54f34c5f72c7ec784feec7383c938e200ec62502c925e8d.jpg)

In the case of further morphemes above (abstract agreement), there must be a movement up of the two arguments prior to movement of the SuffP to the next SuffP. Further movements should give the correct word order (see also the discussion below).

Prefixing is the problematic case. After the verb is raised to the Suffix Projection position the Prefix Projection has to move to its specifier without any material below. The objects and the subject have to be moved up higher before the movement of the verb. So this material has to end up somewhere in the space between the SuffP and the PrefP. To exemplify I will take an example from Swahili, a language exhibiting a large number of class prefixes for nouns. The verb agrees with the class of the subject as well as with the class of the object via single morphemes. Together with a tense morpheme we find these morphemes realised as prefixes in the order AgrS – Tense – AgrO – root. I will take a sentence from a lesson of W. Bisang, given in Mainz, 1995.

(Swahili)

(5-40) Na-li-ki-ona ki-tabu. AGRSubj-PST-AGRObj-look kiClass-book “I looked at the book.”

‘Na’ expresses agreement with the subject pro, which we expect before the verb, the usual place for subjects in Swahili.

We assume a VP shell with the bare verb sitting in the lowest position. Above we find projections for the object and the verb.

![](img/aac6e75d7425c0a8a3d98e24a000a45c24903cc248686651ab8aa0e6dab581c7.jpg)

We could next merge the PrefP of the extended AgrO-projection and above landing positions for the arguments. At a higher position the SuffP would be merged and attract the VP. Since the whole shell is empty we could either move up the whole VP Shell or only the lower ${ \mathrm { V } } ^ { 2 } { \mathrm { P } }$ with the verb. In the first case the resulting structure would be:

![](img/5cdfe3195dcbd8f47d006fea16d27e79fbee0e0f7b64b83d2352bdce9b5797e4.jpg)

(LSP and LOP represent landing positions for the subject and the object.) Now we see that there is no place for the Prefix to move to. The highest specifier of the shell, the specifier of ${ \mathrm { v } } ^ { 0 } { \mathrm { P } }$ is occupied by the trace of the subject. Movement to the specifier of ${ \mathrm { V } } ^ { 2 } { \mathrm { P } }$ is impossible, since the moved element would not Ccommand its trace. An escape hatch could be to assume an empty projection above ${ \mathrm { v } } ^ { 0 } { \mathrm { P } }$ , which is moved along with the shell. In this case the Prefix could attach to it, but we would end up with a structure like:

![](img/4f1ad00448e2f6c18104675a248a85ab97c1bd7bfe14b8bb0435c1069908d614.jpg)

This is not the structure that we assumed to represent a word. Between ‘ki-’ and ‘-ona’ there are at least four word boundaries (between heads and complements).

The second option was to move just the lowest element of the VP shell, the ${ \mathrm { V } } ^ { 2 } { \mathrm { P } }$ up to the specifier of the specifier of the SuffP:

![](img/065e15855cacb77924580e16ce7cac92d4829771e1990ec72f8ae17eaf5275a8.jpg)

As we see, there is no way to move just the PrefP up; it has to take the whole lower part with it, giving rise to the structure:

![](img/35572935804bf4130803053ff7ec5ce8fe606e2d8c1e7e26ebe98601969d2c75.jpg)

This structure is again ambiguous with respect to the word status of the prefixroot complex. There is no word boundary between the overt material in the specifier of ${ \mathrm { V } } ^ { 2 } { \mathrm { P } }$ and the root in the head, but inside the PrefP we find three word boundaries. This could indeed be a possible structure, but we expect to find some data that confirms this ambiguity. In the case of Turkish we saw that stress pattern is correlated with the ‘little word’ where we have no internal word boundaries. Vowel harmony was spread over the whole ‘big word’, which can have internal word boundaries.

We can avoid this ambiguous structure, if we restrict ourselves to complement moves. The verb has to move above the arguments before they can be raised into the space between SuffP and PrefP. This intermediate landing position of the verb must be below the PrefP, otherwise the PrefP cannot be moved cyclically into its specifier.

![](img/7696e0597f33acd51659a7d3b211c2a67e19814a7fb8a0d26954c708c13872fd.jpg)

Now the PrefP can be merged and the landing positions for the object and the subject both attracting the corresponding arguments:

![](img/ee7f37c09928f90e4ec9b0ebf87081506074bf36ab830a9ba2abed85ca8b9d3a.jpg)

![](img/036f66ba4ea9f625f51703b0c8c1939670d71f6d4501142496c15a0f1d9afcac.jpg)

![](img/14a5c0aea0ed9934ac37bd766f268a643226777000795b739fc42b9f5d1fbe78.jpg)

Now the SuffP can be merged and attract the LVP, which contains the verb:

![](img/b4159f7a7e2554d709c191c5e157476c78e249a4fc2b5db17c3a10017c8af6a5.jpg)

![](img/43c8bbfdc1eed0c2b021c7798f8336afdec8aa92fcd60d5d3788567241b0f4b3.jpg)

I will stop here, due to the repetitive nature of this derivation. It is easy to see, how the other two prefixes can be attached. An extended projection, consisting of SuffP – LSP – LOP – PrefP, will be merged for each Prefix. LOP will attract the lower LOP, LSP the lower LSP and SuffP the lower PrefP. The lower PrefP, now sitting in the highest specifier, attracts the PrefP of the actual extended projection.

This gives the order ‘na-li-ki-ona pro kitabu’ with the pro in the wrong position after the verb. Specifier movement could transpose it to the left of the verb. But there still seems to be something missing. We would like to correlate the positions of the subject and the object to certain projections inside the hierarchy of extended projections. Therefore, it would be necessary to determine the argument positions not only with respect to the verb, but also to modifiers. I will return to this issue later after having introduced prepositional modifiers. For the moment suffices it to say, that the arguments have to move into a space between the SuffP and the PrefP if we want to maintain the Cyclicity Constraint and the C-Command Constraint.

# 5.9 Open questions

We saw in this chapter how simple processes like suffixing, prefixing and circumfixing could be explained in a mainly syntactic analysis. Future research will show, whether this analysis can be used to explain more complex processes.

Infixes probably are not a homogenous group and might be explained in different ways. Sometimes the German ‘ge-’ in participle constructions with separable prefixes is considered an infix. Above we saw an example with the verb ‘an+ziehen’ (to dress). The past participle is ‘angezogen’. I showed above that ‘ge’ could be analysed as an ordinary prefix, while ‘an’ does not have a proper prefix status.

We find a different case of infixing in Tagalog. The subject focus affix $\mathrm { \dot { \Omega } u m } ^ { \prime }$ is usually realised as a prefix as in ‘um+aral’ where it attaches to the root ‘aral’. But with roots starting with a consonant the affix ends up inside the root. An example is ‘sumulat’ for the root ‘sulat’. Tagalog seems to prefer syllables without a coda. Therefor we could analyse ‘um’ even in the case of ‘sumulat’ as a prefix. Its appearance inside the root is attributed to some phonological process after syntax. (The examples are taken from Russell 1997: 118)

More problematic are the cases of non-concatenative morphology. In modern German and English certain verbs have past tense forms that differ from the present tense form by the root vowel, a process which is known under the name of ‘ablaut’. ‘I sleep’ vs. ‘I slept’ or ‘I run’ vs. ‘I ran’ are famous examples in English; in German we find ‘Ich schlafe’ (I sleep) vs. ‘Ich schlief’ ( I slept) or ‘Ich laufe’ (I run) vs. ‘Ich lief’ (I ran). These processes are nowadays irregular and the corresponding form will be single entries in the lexicon.

But at an earlier stage and probably in Indo-European this formation was supposedly productive. If we want to understand the underlying process we have to compare carefully root vowels and changed vowels before we can attempt a generalisation. A possible explanation might be to assume an underspecified vowel as past tense affix. This element might consist of only a single phonetic feature like [+backness] which needs a vowel to be pronounced. A morpho-phonological rule links this feature with the root vowel (which might be itself underspecified) with the result of changing its quality.

More challenging are parts of semitic morphology which are commonly referred to as ‘template morphology’. Verb roots in Arabic are clusters of three or four consonants. ‘ktb’ is the root of the verb ‘write’. These root consonants will be projected on a certain ‘skeletal tier’ with vowels interspersed. ‘Kataba’ with the meaning ‘he wrote’ has the skeletal tier ‘CVCVCV’. ‘Kattaba’ means ‘he caused to write’ and has the skeletal tier ‘CVCCVCV’. The skeletal tier is associated with a grammatical function usually described as being derivative. Examples are ‘causative’ and ‘reciprocal’. The vowels provide information about tense and aspect. Future research might show whether a combination of affixal syntax and autosegmental phonology can derive a plausible analysis of the involved processes.

# 5.10 Conclusion

In this chapter I proposed an analysis, which accounts for the assignment of affixes to the verb via XP movements. I assume there to be different lexicons. One contains a list of all lexicon items together with their syntactic properties. Functional elements are supposed to be universal, but their syntactic properties can differ from language to language. Therefore I assume that they are also part of this lexicon. It is this lexicon from which elements are taken to feed the numeration. Merge and Move give rise to a morpho-syntactic structure, represented by a binary tree.

A morpho-phonological module translates this tree into a phonetic string. It has access to a second lexicon where we find a correlation between tree chunks and phonological representations.

Certain typological observations indicate a correlation between syntactic properties and the order of affixes. This led me to the idea that the difference between prefixing and suffixing is attributed to different syntactic processes. From this basic assumption I deduced a model that proposes for each affix an extended projection with rich structure. Suffixes are inserted in a very high part of the projection, prefixes in the lowest. In between we find landing positions for overt material from below such as subjects, objects and prepositions.

This rich structure follows automatically from few restrictions on structure (being antisymmetric) and movement (Cyclicity Condition and C-Command Constraint).

The transformational processes involved consist mainly of movements out of complement positions. If we could generalise this to a universal constraint, which prohibits head movement and specifier movement, we would have a very restrictive theory. The Axiom of Word Boundary, which I introduced here in a stipulative way, could be derived by explicitly forbidding specifier movement.

In the next two chapters I want to explore in an analogous way the syntactic behaviour of prepositional modifiers. First I will give motivation for assuming a basic order of different PP types. I will introduce some syntactic test, which I used with German sentences. In the following chapter I try to explain how we can derive different surface orders in English and German from the same basic order. We will see whether and/or how we can combine the structural and derivational analysis for affixes and prepositional modifiers.

CHAPTER 6

# SYNTACTIC ANALYSIS OF THE SURFACE WORD ORDER OF PPS

# 6.1 The basic patterns

The PLR-Test introduced in Chapter 3 is applicable to PPs in German, English, Dutch and Italian and gives in all languages the same hierarchy. Nevertheless, we find different unmarked surface orders of the PPs in the different languages. They seem to be correlated with the OV versus VO parameter. A generalisation seems to be that we find strictly inverted order or direct order of PPs if they follow the verb, but only direct order in front of the verb.

In the following I will use a numeration which assigns $\mathrm { P P _ { 1 } }$ to the highest element in the hierarchy, $\mathrm { P P _ { n + 1 } }$ corresponds to an element which follows $\mathrm { P P _ { n } }$ in the hierarchy. Thus the basic and direct order is represented by:

$$
\mathrm { P P } _ { 1 } \mathrm { P P } _ { 2 } \mathrm { P P } _ { 3 } \ldots \mathrm { P P } _ { \mathrm { m a x } - 1 } \mathrm { P P } _ { \mathrm { m a x } }
$$

The inverted order, however, will have the representation:

$$
\mathrm { P P } _ { \mathrm { m a x } } \mathrm { P P } _ { \mathrm { m a x - 1 } } \ldots \mathrm { P P } _ { 3 } \mathrm { P P } _ { 2 } \mathrm { P P } _ { 1 }
$$

# 6.1.1 The Direct Order

OV languages seem to show the direct order. PPs to the left take scope over PPs to the right in the unmarked case. German is an example of this pattern. In the Mittelfeld, unmarked PPs normally appear in the direct order. Reordering is due to scope or focus effects. In main clauses, where the verb climbs to a high position in the left periphery, we get the pattern:

$$
\mathrm { \nabla { V } \ P P _ { 1 } \ P P _ { 2 } \ldots \ P P _ { \mathrm { m a x } } }
$$

and in dependent clauses the pattern:

$$
\mathrm { P P } _ { 1 } \mathrm { P P } _ { 2 } \ldots \mathrm { P P } _ { \operatorname* { m a x } } \mathrm { V }
$$

In some cases, purely modifying PPs can be found after the right verb bracket. It is not easy to detect their unmarked order in this position, but they might be found in the inverted order, see below under mixed cases.

# 6.1.2 The Inverted Order

VO languages seem to reveal the inverted pattern. In the unmarked case, PPs to the right take scope over PPs to the left.

We get the general pattern:

$$
\mathrm { \Delta V ( O b j ) P P _ { m a x } P P _ { m a x - l } \dots P P _ { 3 } P P _ { 2 } P P _ { 1 } }
$$

English

Appendix C shows data which confirm that the unmarked order is the inverted one. Appendix D indicates that the scope relation are from right to left in the unmarked case.

# Norwegian

Nilsen shows that in Norwegian certain restrictions hold for combinations of a verb and two PPs that have been raised in front of an auxiliary. In Chapter 3 I already introduced the following examples as (3-62) - (3-69):

(Norwegian)

[Møtte henne] gjorde jeg i parken på fredag. met her did I in park.the on Friday “I met her in the park on Friday.”

(Norwegian)

[Møtte henne i parken] gjorde jeg på fredag.   
[Møtte henne i parken på fredag] gjorde jeg (ikke).

(Norwegian)

\* [Møtte henne på fredag] gjorde jeg i parken.

\* [Møtte i parken] gjorder jeg henne på fredag.

\* [Møtte] gjorde jeg henne i parken på fredag.

\* [Møtte på fredag] gjorde jeg henne i parken.

(Nilsen 1998: 61 f.)

Nilsen concludes from the data, that the basic constituency structure of the the selected IP before movement is:

[[[Møtte henne] i parken] på fredag]

which is in agreement with the inverted pattern after the verb for VO languages.

# 6.1.3 Mixed Order

The above two patterns seem to divide the languages of the world into two groups which seem to correspond to VO and OV languages. But we also find some mixed cases in verb final languages, where the verb optionally can climb the lower PPs which appear in inverted order. The general pattern would be:

$$
\mathrm { P P } _ { 1 } \mathrm { P P } _ { 2 } \ldots \mathrm { P P } _ { \mathrm { n } } \mathrm { V P P } _ { \mathrm { m a x } } \mathrm { P P } _ { \mathrm { m a x } - 1 } \ldots \mathrm { P P } _ { \mathrm { n } + 1 }
$$

Dutch

J.Koster observed the so-called mirror effect: PPs that appear in a certain order in the Mittelfeld reveal the reverse order when extraposed to the Nachfeld (Koster 1974. The example is quoted in Barbiers 1995: 103).

(Dutch)

Hij is [PP3 door’n stuurfout] [PP2 met een knal] [PP1 op het hek] He is by a steering_error with a bang on the fence [VP gestrand].   
stranded   
“He is stranded on a fence with a bang by a steering error.”

(Dutch)

Hij is [PP3 door’n stuurfout] [PP2 met een knal] [VP gestrand] [PP1 op het hek].

Hij is [PP3 door’n stuurfout] [VP gestrand] [PP1 op het hek] [ met een knal]

Hij is [VP gestrand] [PP1 op het hek] [PP2 met een knal] [PP3 door’n stuurfout]

Hij is [PP3 door’n stuurfout] [PP1 op het hek] [VP gestrand] [ met een knal]

Hij is [PP1 op het hek] [VP gestrand] [PP2 met een knal] [PP3 door’n stuurfout]

Hij is [PP2 met een knal] [PP1 op het hek] [VP gestrand] [PP3 door’n stuurfout]

Hij is [PP2 met een knal] [VP gestrand] [PP1 op het hek] [PP3 door’n stuurfout]

All other possible combinations (16) are listed with a star. We can draw the conclusion that PPs which are in front of the verb appear in direct order, elements that somehow show up in the Nachfeld have to be in inverted order. We get the following patterns:

a) PP PP PP V b) PP PP V PP c) PP V PP PP d) V PP PP PP e) $\mathrm { P P } _ { 1 } \mathrm { P P } _ { 3 } \mathrm { V P P } _ { 2 }$ f) $\mathrm { P P } _ { 3 } \ : \mathrm { V } \ : \mathrm { P P } _ { 2 } \ : \mathrm { P P } _ { 1 }$ g) $\mathrm { P P } _ { 2 } \mathrm { P P } _ { 3 } \mathrm { V P P } _ { 1 }$ h) $\mathrm { P P } _ { 2 } \vee \mathrm { P P } _ { 3 } \mathrm { P P } _ { 1 }$

Some comments on the ungrammaticality of the excluded combinations are in order. Barbiers verified the combinations by using unmarked intonation (personal communication). That means that some of the starred examples become grammatical if pronounced with a different intonation. This approach is different to mine. I evaluated all possible intonations and gave a star only when there was no possible intonation pattern.

Furthermore, it is not possible to generalise the example to all possible combinations of PPs. The PPs involved are not all pure modifiers. ‘Op het hek’ has argumental character. One of the constraints for Dutch is, that this element has to be adjacent to the verb, either in front or behind. Only four sentences of the excluded combinations obey this constraint.

The last four examples, (6-11)- (6-14), where the PPs in the Nachfeld have skipped others seem to be less acceptable than the other four, though an exact judgment is hard to give. After some discussions with Dutch speakers, it seems not totally clear whether

(Dutch) (6-11) Hij is [PP3 door’n stuurfout] [PP1 op het hek] [VP gestrand] [ met een knal]

is much better than:

5) Hij is [PP1 op het hek] [VP gestrand] [PP3 door’n stuurfout] [PP2 met een knal]

# German

In German we also find modifying PPs in the Nachfeld, although it seems that they appear less frequently there than in Dutch. Argumental PPs are in contrast to Dutch totally excluded in the Nachfeld. Therefore, I cannot verify the German translations of the above data:

(6-16) \* Er ist gestrandet auf dem Zaun. He is stranded on the fence

I tried to compare scope properties of two PPs in the Nachfeld, but the data where not easy to interpret. The higher element tends to take scope over the lower to a higher degree than in the Mittelfeld. It could be that the scope taking of the lower element over the higher slightly increases, if it is to the right. The data can be found in Appendix E. If anything, I can detect a slight mirror effect for German as well.

# 6.1.4 Patterns of Other Constituents

The same pattern is found with other constituents. The lexical head of a construction can be followed by modifiers in direct or inverted order, but only proceeded by them in their direct order.

DPs

Greenberg noticed this pattern for DP in his Univesal 20:

When any or all of the items – demonstrative, numeral, and descriptive adjective –   
precede the noun, they are always found in that order. If they follow, the order is either the same or its exact opposite.

Cinque exemplifies this with the inner structure of the semitic DP. In Standard Arabic we have:

(Standard Arabic)   
(6-17) s-suhuf-u l-jadiidat- $_ { \cdot u }$ t- talaat- $\mathbf { \nabla } \cdot \mathbf { \mu } \cdot \mathbf { \mu } \cdot \mathbf { \mu }$ haadihi the-newspapers-nom the-new-nom the-three-nom these “These three new news papers” (N A Num Dem) (Standard Arabic)   
(6-18) \* s-suhuf-u haadihi t- talaat-u l-jadiidat- $_ u$ $\ast \mathbf { N }$ Dem Num A) (Standard Arabic)   
(6-19) haadihi s-suhuf-u l-jadiidat-u t- talaat- $_ { \cdot u }$ (Dem N A Num) (Standard Arabic)   
(6-20) ? haadihi t- talaat-u s-suhuf-i/in l-jadiidat- $_ u$ (Dem Num N A)

A more detailed inspection gives different classes of adjectives $\mathbf { A } _ { 1 }$ , ${ \bf A } _ { 2 }$ , ${ \bf A } _ { 3 }$ and quantifiers Q that participate in this behaviour:

# Q Dem Num N A A A Q Dem N $\mathbf { A } _ { 3 }$ A A Num Q N ${ \bf A } _ { 3 }$ A2 A1 Num Dem N A A A Num Dem Q

The examples are taken from Cinque $( 2 0 0 0 \mathrm { b } )$ .

Verbal Complexes

According to Cinque (2000), certain restructuring verbs can be viewed as functional elements, basegenerated in functional projections above the VP and they behave like modifiers. Therefore, we expect a similar pattern of verb – auxiliary combinations.

# Hungarian

Koopman and Szabolsci (2000) describe this exact pattern for Hungarian. Similar to German, we find verbs with separable prefixes in Hungarian. ‘be menni’ (to go in, to enter). Some subject control verbs with infinitival complements build complexes with the main verb, amongst those ‘fog’ (will), ‘akar’ (want) and ‘kezd’ (begin). ‘fog’ can only be found in finite form. Several sentences with the same interpretation (' I will not begin to want to go in') can be formed with different word orders:

(Hungarian)

Nem fogok kezde-ni akar-ni be men-ni not will.1SG begin-inf want-inf in go-inf “I will not begin to want to go in.”

(6-22) Nem fogok kezde-ni be men-ni akar-ni (6-23) Nem fogok be men-ni akar-ni kezde-ni (6-24) Nem fogok kezde-ni be men-ni akar-ni all other combinations are excluded:

(6-25) \* Nem fogok kezde-ni be akar-ni men-ni (6-26) \* Nem fogok akar-ni be men-ni kezde-ni (6-27) \* Nem fogok akar-ni kezde-ni be men-ni

If we abbreviate formally ‘fogok’ with $\mathbf { A u x } _ { 1 }$ , ‘kezdeni’ with $\mathbf { A u x } _ { 2 }$ , ‘akarni’ with $\mathbf { \dot { A u x } } _ { 3 } ,$ and ‘be menni’ with $\mathrm { v }$ we get the following patterns:

a) ${ \begin{array} { r l } & { { \mathrm { A u x } } _ { 1 } \ { \mathrm { A u x } } _ { 2 } \ { \mathrm { A u x } } _ { 3 } \ { \mathrm { V } } } \\ & { { \mathrm { A u x } } _ { 1 } \ { \mathrm { A u x } } _ { 2 } \ { \mathrm { V } } \ { \mathrm { A u x } } _ { 3 } } \\ & { { \mathrm { A u x } } _ { 1 } \ { \mathrm { V } } \ { \mathrm { A u x } } _ { 3 } \ { \mathrm { A u x } } _ { 2 } } \\ & { { \mathrm { A u x } } _ { 1 } \ { \mathrm { A u x } } _ { 3 } \ { \mathrm { V } } \ { \mathrm { A u x } } _ { 2 } } \\ & { { \mathrm { A u x } } _ { 1 } \ { \mathrm { A u x } } _ { 3 } \ { \mathrm { A u x } } _ { 2 } \ { \mathrm { V } } } \end{array} }$   
b)   
c)   
d) \*   
e) \*

Note, that pattern d) corresponds with the pattern e) of Barbiers' example of Dutch PPs in the Nachfeld. Pattern e) was evaluated grammatical. But see the general remarks with respect to grammaticality evaluations of the Dutch example. The Hungarian example points in the direction that skipping of an element in the post verbal, inverted order is less possible.

# German

In German there are modals that could be easily assigned to functional projections of the Cinque hierarchy. In main clauses we find the finite modals in second position, the lexical verb sentence final.

(German)

(6-28) Hans musste ein Haus bauen. Hans must.PST a house build “Hans had to build a house.” (Modnecessitiy).   
(6-29) Hans konnte ein Haus bauen. Hans could a house build “Hans was able to build a house.” (Modability)   
(6-30) Hans wollte ein Haus bauen. Hans wanted a house build “Hans wanted to build a house.” (Modvolitional)   
(6-31) Hans durfte ein Haus bauen. Hans was_allowed a house build “Hans was allowed to build a house.” (Modpermission)

The next one is ambiguous:

(6-32) Hans sollte ein Haus bauen. Hans should a house build   
between “Hans ought to build a house.” (Modobligation)   
and “Hans allegedly built a house.” (Modevidential)

Things become interesting, when combining two modals. One modal is final, the other appears behind the verb in final position. Some combinations are possible, others not:

(6-33) Hans musste ein Haus bauen können.   
(6-34) \* Hans konnte ein Haus bauen müssen.   
(6-35) Hans musste ein Haus bauen wollen.   
(6-36) \* Hans wollte ein Haus bauen müssen.   
(6-37) ? Hans musste ein Haus bauen dürfen.   
(6-38) \* Hans durfte ein Haus bauen müssen.   
(6-39) \* Hans konnte ein Haus bauen dürfen.   
(6-40) Hans durfte ein Haus bauen können.   
(6-41) Hans wollte ein Haus bauen können.   
(6-42) \* Hans konnte ein Haus bauen wollen.   
(6-43) Hans wollte ein Haus bauen dürfen.   
(6-44) \* Hans durfte ein Haus bauen wollen.   
(6-45) Hans sollte ein Haus bauen dürfen.   
(6-46) \* Hans durfte ein Haus bauen sollen.   
(6-47) Hans sollte ein Haus bauen müssen.   
(6-48) \* Hans musste ein Haus bauen sollen.   
(6-49) Hans sollte ein Haus bauen können.   
(6-50) \* Hans konnte ein Haus bauen sollen.   
(6-51) Hans sollte ein Haus bauen wollen.   
(6-52) \* Hans wollte ein Haus bauen sollen.

The permitted examples with “sollen” are all more likely interpreted as evidential than obligational, in the combination with ‘müssen’ the evidential interpretation becomes obligatory.

Though some of the starred examples as (6-38) seem to give no meaning; therefore they could be excluded for semantic reasons.Others like (6-36) are no more odd than their reversed counterpart (6-35). The data gives the following (syntactic) hierarchy:

which perfectly corresponds to Cinque’s partial hierarchy:

$$
\mathbf { M o o d } _ { \mathrm { e v i d e n t i a l } } > \dots \mathbf { M o d } _ { \mathrm { n e c e s s i t y } } > \dots \mathbf { M o d } _ { \mathrm { v o l i t i o n a l } } > \dots \mathbf { M o d } _ { \mathrm { a b l i t y / p e r m i s s i o n } }
$$

Furthermore, the data allows a distinction between the two functional projections subsumed by the last in the way:

$$
\mathbf { M o d } _ { \mathrm { p e r m s i s i o n } } > \mathbf { M o d } _ { \mathrm { a b i l i t y } }
$$

Interesting are also the cases of combination of three modals.

(6-53) Hans musste ein Haus bauen können wollen.   
(6-54) \* Hans musste ein Haus bauen wollen können.   
(6-55) \* Hans wollte ein Haus bauen können müssen.   
(6-56) \* Hans wollte ein Haus bauen müssen können.   
(6-57) \* Hans konnte ein Haus bauen wollen müssen.   
(6-58) \* Hans konnte ein Haus bauen müssen wollen.

We see here the well-known fact that the verbs in sentence final position appear in the reverse order.

In final position we thus get verb auxiliary complexes of the form:

V   
V Mod   
V Mod2 Mod1

# 6.1.5 Conclusion:

Modifiers of lexical items can be found in direct or inverted order behind the lexical item (verb, noun), but only in direct order in front. For verbs with 5 PPs we get the following patterns:

1. ${ \mathrm { P P } } _ { 1 } { \mathrm { P P } } _ { 2 } { \mathrm { P P } } _ { 3 } { \mathrm { P P } } _ { 4 } { \mathrm { P P } } _ { 5 } { \mathrm { V } }$ (German, dependent clauses)   
2. $\vee \mathrm { P P } _ { 5 } \mathrm { P P } _ { 4 } \mathrm { P P } _ { 3 } \mathrm { P P } _ { 2 } \mathrm { P P } _ { 1 }$ (English etc.)   
3. $/ \mathrm { \ P P _ { 1 } \ P P _ { 2 } \ P P _ { 3 } \ P P _ { 4 } \ P P _ { 5 } }$ (German main clauses)

and the mixed cases:

4. $\mathrm { P P } _ { 1 } \mathrm { P P } _ { 2 } \mathrm { P P } _ { 3 } \mathrm { V P P } _ { 5 } \mathrm { P P } _ { 4 } \mathrm { ( D u t c h ) }$   
5. ${ \mathrm { P P } } _ { 1 } { \mathrm { P P } } _ { 2 } { \mathrm { P P } } _ { 3 } { \mathrm { V P P } } _ { 4 } { \mathrm { P P } } _ { 5 }$ (to be expected)

# ${ \pmb 6 . 2 A }$ symmetric analysis

At first sight, a symmetric grammar seems to explain the data in very simple way. The hierarchy of thematic roles associated with the PP types underlies universally the structure of each sentence in each language. One thematic role selects another as its complement; the lowest selects the extended VP. Languages differ with respect to the order of complements or specifiers with respect to the head.

Since the base order of the PPs is never free, I do not consider the adjunct hypothesis here, which would not account syntactically for the data presented in Chapter 4.

If we take free order of specifier and complement with respect to the head we get the following possibilities:

A: spec left, comp right, asymmetric case B: spec left, comp left

![](img/1581c8950869fa5dd816391fb2d44c6b877a446424daca73ccb8521f82197fb5.jpg)

C: spec right, comp right D: spec right, comp left

![](img/f5ec2e1a86717426ca82db1fe1a420fc8e511198af0d575b1d3af6cbc1b215b1.jpg)

Symmetric analyses of the English sentence structure take structure A as the principal pattern for CP, IP and VP:

![](img/d8c788e0aa452394efb01fb7adb7c354fd7a7713c723c247716e49b622eeb363.jpg)

For German, however, IP and VP are usually in symmetric models assumed to be head final (structure B), while CP shows structure A:

![](img/3d5a142b1d0f749e9194bc42ab24879ce381d1cda41471c82a9c3939d19aad6d.jpg)

PPs are traditionally viewed as projections of the prepositional head, which selects the DP as its complement. Since I excluded adjunction, the only way for a PP of this kind to enter the picture is to sit in the specifier of a functional projection between CP and VP. Still above these PPs is a functional projection that hosts the subject. I will call it AgrP.

In English, the PPs follow the verb in reverse order. This comes out naturally without any movement if the functional projections hosting them are specifier final. Since the head is invisible, structures C and $\mathrm { D }$ are compatible with this model. For the whole sentence we get

with structure C:

with structure D:

![](img/156e58dde6a1747e0bf19accdce50aa9e73ba914c8e97b1f2cbdb39f2fc46f07.jpg)

For the German case we expect a specifier initial projection, i.e. structure A or B. For the whole sentence we get with structure A:

![](img/affa4024daa51c0a6b2bebf27ef312ed102988f5bb4c5b179b32cd89b82e67bb.jpg)

The resulting structures for each of the lexical and functional projections in each language are:

<html><body><table><tr><td> Projection</td><td>English</td><td>German</td></tr><tr><td>VP</td><td>Structure A</td><td>Structure B</td></tr><tr><td>FP</td><td>Structure C or D</td><td>Structure A or B</td></tr><tr><td>AgrP</td><td>Structure A</td><td>Structure B</td></tr><tr><td>CP</td><td>Structure A</td><td>Structure A</td></tr><tr><td>PP</td><td>Structure A or C</td><td>Structure A or C</td></tr></table></body></html>

We see that neither of the two languages has consistently the same structure for all projections. Except for CP and maybe PP, the two languages differ with respect to the structure of each projection. If we take the structure difference for each projection to be correlated with independent parameters, we get at least 3 different independent parameters in a relevant section of the grammar. Since German and English are historically closely related, we do not expect a grammatical distinction like this.

Furthermore, we hope to find the principal distinction between VO and OV languages to be mirrored in these structures. If the structural parameter is indeed independent for each projection, we expect to find languages which have structure B for the VO and structure C for the FP, resulting in a OV language with inverted PPs, something which is not attested until now.

The only way out is to stipulate additional restrictions that exclude certain combinations. Haider's projective grammar, which introduces directions of licensing, is one way to do this. The end result is an antisymmetric world. It seems, that the language faculty is not symmetrical in the sense of permitting all possible combinations of word order.

# 6.3 Directionally licensing and the proposal of Haider

Haider's model lies somewhere in between a free (symmetric) approach and a total antisymmetric one. He does not restrict syntactic structures to left headedness, but confines himself to the Basis Branching Constraint. In Haider (2004) we find the following definition:

Projection-internal branching nodes of the (functionally or lexically extended) projection line follow their sister node.

(Haider 2004: 7)

This excludes right adjunction. Haider correlates the inverted post verbal order in English and direct preverbal order in German with the VO – parameter. In order to do this he assumes a head-initial structure for the VO type (English) and a head final-structure for OV languages (German):

![](img/4725e486638ee7664086df16cbade1162d9e7041b1abfd554e33ca88f187e125.jpg)

The arrows indicate the licensing direction. In head initial languages the verb licenses its complements to the right, in head final languages they are licensed to the left. This also holds for VP internal modifiers which comprises all our PP modifiers.

In OV languages these modifiers can appear to the left as adjuncts to the VP shell where the all are licensed by the verb which has the rightmost position in the VP shell. In a head-initial language the licensing direction is to the right. So they have to appear at the right of the verb. Since right adjunction is excluded by the Basic Branching Constraint, they are embedded under the verb.

The mirror order is guaranteed by a principle of incremental compositionality. Each prepositional modifier belongs to a certain semantic type. These types obey a (semantic) order. (Haider 2004) writes:

The semantically lower type domain is addressed before the higher one. So in the extraposition domain, the adverb that needs to be integrated into the lower domain precede the adverbs that are integrated into higher type domains.

(Haider 2004: 20)

# 6.4 Collective versus indivual checking in the work of Koster

Koster (2000a) presents another analysis which is totally based on Minimalism and Antisymmetry. In his work all heads precede their complements and so the famous OV / VO parameter is a merely surface distinction. All languages are underlying VO. The word order differences that we observe in the different languages are attributed to difference in movement of argument. According to Koster all languages have the following universal base sentence structure:

...[XP AgrS [XP $\mathrm { \mathbf { A } d v _ { 1 } } ^ { * }$ [XP T [XP Dat [XP Acc [XP $\mathrm { \bf A d v } _ { 2 } *$ [XP [Pred\* [VP]]]]]]]]] ( Koster 2000a.: 7

The asterisks indicate specifier positions. AgrS projects the usual agreement projection where subject-verb agreement is checked and the subject is moved to. The old AgrOP is split into two projections; DatP licences the indirect object and AccP the direct object. $\mathrm { A d v _ { l } P }$ is the field where we find sentence modifiers, adverbs that precede in both in Dutch/German and in English the verb. In $\mathrm { \bf A d v } _ { 2 } \mathrm { \bf P }$ we find modifiers that precede in German and Dutch dependent clauses the verb but follow it in English. These comprise all prepositional modifiers but also lower manner adverbs. PredP is a licensing projection for prepositional complements (selected PPs).

All internal arguments are base generated in the VP shell and have to be licensed overtly in their functional licensing projections. The difference between the two types of languages is the amount of material that is moved to these places. In OV languages such as German and Dutch only the arguments are moved, so that they end up in their proper positions and the verb remains at the end. Koster calls this individual checking:

...[XP AgrS [XP $\mathrm { \mathbf { A d v } _ { 1 } } ^ { * }$ [XP T [DP Dat [DP Acc [XP Adv2\* [AP [Pred\* [VP]]]]]]]]] ( Koster 2000a.: 9 )

In VO languages such as English, however, the arguments pied pipe the entire VP shell. This preserves the original order VO and the internal order of the arguments. Thus, this collective checking moves the entire VP across the lower adverbs and the prepositional modifiers:

...[XP AgrS [XP $\mathrm { \bf A d v _ { \mathrm { l } } } ^ { * }$ [XP T [VP Dat [VP Acc [XP Adv \* [VP [Pred\* [VP]]]]]]]]] ( Koster 2000a.: 7 )

With this parameter Koster succeeds in relating the surface VO/OV distinction to the difference in position for the PPs.

For explaining the mirror effect in Dutch Koster proposes ‘parallel construal’, a mechanism that he explains in length in Koster (1999) and Koster (2000b).

Koster starts with the observation that in Dutch (and in German) certain coodinations of DPs can be separated by the main verb:

(Dutch)

(6-59) Zij heeft Marie gezien en mij She has Mary seen and me “She saw Mary and me.”

which has the same semantic interpretation as the alternative construction with both conjuncts in direct neighbourhood:

(Dutch)

(6-60) Zij heeft Marie en mij gezien.

(Koster 2000b: 16)

Koster assumes that coordinated elements are headed be the coordinator ‘en’ which selects the second conjunct ‘mij’ whereas in the specifier we find a constituent which contains the first conjunct. This constituent can either be the DP ‘Marie’ itself or the bigger constituent AgrOP ‘Marie gezien’.

Parallel construal is a generalisation of this process which can be applied to modification. In the case of several PPs each of the modifiers is doubled with the first element being empty. Since the modifiers are constructed from the inside to the outside the elements which appear after the verb show the mirror order.

The main problem with this analysis is the fact that it predicts that in English only direct order is available, since the verb is moved together with the arguments across the prepositional space and therefore cannot serve as a focus of the mirror image. But as is well known by now (Nilsen 2000, Cinque 2004, my own data below) in English the mirror order (Instrumental before Locative before Temporal) is the unmarked order.

# 6.5 The pied piping analysis of Cinque

Cinque proposes a pied piping analysis for the PP surface orders (Cinque 2004: 11), in which he uses strictly antisymmetric phrase structures. The PPs are merged in their basic order. The verb is base generated below and moves overtly or covertly up; a second parameter determines whether it pied pipes the passed PPs or not. The following shows the derivation of the five patterns with a pied piping analysis in a schematic way.

Pattern 1 shows the base generated order. Nothing has moved, everything remains in its base position.

a $\mathbf { P } \mathbf { P } _ { 5 }$ V b $\mathbf { P } \mathbf { P } _ { 4 }$ PP V c $\mathbf { P } \mathbf { P } _ { 3 }$ PP $\mathbf { P P _ { 5 } } \mathrm { ~ V ~ }$ d $\mathbf { P } \mathbf { P } _ { 2 }$ $\mathbf { P } \mathbf { P } _ { 3 }$ PP4 $\mathbf { P } \mathbf { P } _ { 5 }$ V e PP1 PP PP PP PP5 V

In pattern 2 the verb moves cyclically over the PPs and takes the PP now sitting to its right with it on its next move:

a V   
merge $\mathrm { P P } _ { 5 }$   
b PP5 V   
move VP   
c V PP5   
merge $\mathrm { P P _ { 4 } }$   
d PP V PP5   
move VP and pied pipe $\mathrm { P P } _ { 5 }$   
e [VPP5] PP4   
merge $\mathrm { P P } _ { 3 }$   
f PP3 [VPP5] PP4   
move $[ \mathrm { V } \mathrm { P P } _ { 5 } ]$ and pied pipe $\mathrm { P P _ { 4 } }$   
g [[VPP5]PP4] PP3   
merge $\mathrm { P P } _ { 2 }$   
h PP2 [[VPP5]PP4] PP3   
move $[ [ \mathrm { V } \mathrm { P P } _ { 5 } ] \mathrm { P P } _ { 4 } ]$ and pied pipe $\mathrm { J P P } _ { 3 }$   
i $[ [ [ \mathrm { V P P } _ { 5 } ] \mathrm { P P } _ { 4 } ] \mathrm { P P } _ { 3 } ] \mathrm { P P } _ { 2 }$   
merge $\mathrm { P P _ { 1 } }$   
j $\mathbf { P P _ { 1 } } \ [ [ \mathrm { V P P } _ { 5 } ] \mathrm { P P } _ { 4 } ] \mathrm { P P } _ { 3 } ] \mathbf { P P } _ { 2 }$   
move [[[V $\mathrm { P P _ { 5 } ] \ P P _ { 4 } ] \ P P _ { 3 } ] }$ and pied pipe $\mathrm { P P } _ { 2 }$   
k $[ [ [ \mathrm { V P P } _ { 5 } ] \mathrm { P P } _ { 4 } ] \mathrm { P P } _ { 3 } ] \mathrm { P P } _ { 2 } \mathbf { P P } _ { 1 }$

# In pattern 3 the VP either

a) moves all the way up in one step, a V b $\begin{array} { r l } & { \mathbf { P P _ { 5 } } \mathrm { ~ V ~ } } \\ { * } & { \mathbf { P P _ { 5 } } \mathrm { ~ V ~ } } \\ { * } & { \mathbf { P P _ { 5 } } \mathrm { ~ V ~ } } \\ { * } & { \mathbf { P P _ { 5 } } \mathrm { ~ V ~ } } \\ { * } & { \mathbf { P P _ { 5 } } \mathrm { ~ V ~ } } \\ { * } & { \mathbf { P P _ { 5 } } \mathrm { ~ V ~ } } \\ { * } & { \mathbf { P P _ { 5 } } \mathrm { ~ V ~ } } \\ { * } & { \mathbf { P P _ { 5 } } } \end{array}$ c PP d $\mathbf { P } \mathbf { P } _ { 3 }$ $\mathbf { P } \mathbf { P } _ { 4 }$ e PP $\mathbf { P } \mathbf { P } _ { 3 }$ $\mathbf { P P _ { 4 } }$ f PP1 PP PP $\mathbf { P P _ { 4 } }$ g V PP1 $\mathbf { P } \mathbf { P } _ { 2 }$ PP3 $\mathbf { P P _ { 4 } }$ b) or it moves cyclically around every PP without pied piping a V b $\mathbf { P } \mathbf { P } _ { 5 }$ V c V PP5 d $\mathbf { P } \mathbf { P } _ { 4 }$ V PP5 e V $\mathbf { P } \mathbf { P } _ { 4 }$ PP5 f $\mathbf { P } \mathbf { P } _ { 3 }$ V $\mathbf { P } \mathbf { P } _ { 4 }$ $\mathbf { P } \mathbf { P } _ { 5 }$ g V PP3 $\mathbf { P } \mathbf { P } _ { 4 }$ $\mathbf { P } \mathbf { P } _ { 5 }$ h PP2 V $\mathbf { P } \mathbf { P } _ { 3 }$ $\mathbf { P } \mathbf { P } _ { 4 }$ PP5 i V PP2 $\mathbf { P } \mathbf { P } _ { 3 }$ $\mathbf { P } \mathbf { P } _ { 4 }$ $\mathbf { P } \mathbf { P } _ { 5 }$ j PP1 V PP2 PP3 PP PP5 k V PP1 PP2 PP3 $\mathbf { P } \mathbf { P } _ { 4 }$ PP5

The two mixed cases exhibit the case that the verb neither stays in its base position, nor moves all away up across all PPs, but crosses some PPs and then stops before other PPs are still merged.

In pattern 4 the verb crosses $\mathrm { P P } _ { 5 }$ and pied pipes it along the next move across $\mathrm { P P _ { 4 } }$ , but then stops and the rest of the PPs are merged to its left. It has the same derivation as pattern 2 till step f, but then only PPs are merged:

a V b $\mathbf { P } \mathbf { P } _ { 5 }$ V c V $\mathbf { P } \mathbf { P } _ { 5 }$ d PP4 V PP5 e [VPP5] PP4 f PP3 [VPP5] PP4 g PP2 PP [VPP ] PP h PP1 PP2 PP3 [VPP ] PP4

As in the case of pattern 3 we find two possible derivations for pattern 5:

a) the verb is moved in a single step to a position to the left of $\mathrm { P P _ { 4 } }$ , then the rest is merged

a V b $\mathbf { P } \mathbf { P } _ { 5 }$ V c PP4 $\mathbf { P } \mathbf { P } _ { 5 }$ V d V $\mathbf { P } \mathbf { P } _ { 4 }$ $\mathbf { P } \mathbf { P } _ { 5 }$ e PP V $\mathbf { P } \mathbf { P } _ { 4 }$ $\mathbf { P } \mathbf { P } _ { 5 }$ f $\mathbf { P } \mathbf { P } _ { 2 }$ $\mathbf { P } \mathbf { P } _ { 3 }$ V $\mathbf { P } \mathbf { P } _ { 4 }$ $\mathbf { P } \mathbf { P } _ { 5 }$ g PP1 PP2 PP3 V PP4 PP5

b) the verb moves around two PPs without pied piping them and then stops. We have the same derivation as with pattern $3 \ \mathrm { b }$ ) up to step f . Then the remaining PPs are simply merged.

a V b $\mathbf { P } \mathbf { P } _ { 5 }$ V c $\mathrm { { \bf ~ V } } \ \mathbf { P } \mathbf { P } _ { 5 }$ d $\bf { P P _ { 4 } } ~ \vee ~ \bf { P P _ { 5 } }$ e V PP4 PP5 f PP3 V PP4 PP5 g $\mathbf { P } \mathbf { P } _ { 2 }$ PP3 V PP4 PP5 h PP1 PP2 PP3 V PP4 PP5

Barbier's first four patterns are in fact examples of pattern 4 with different ending positions for the verb (and its pied piped constituents). His last four patterns are a bit more difficult to explain. One possible solution within the pied piping analysis would be to assume, that the VP not only pied pipes the sister node, but also some nodes above to a position higher. We would obtain the following derivations:

e) V   
merge $\mathrm { P P } _ { 3 }$ PP3 V   
merge $\mathrm { P P } _ { 2 }$ $\mathbf { P } \mathbf { P } _ { 2 }$ PP3 V   
move VP and pied pipe $\mathrm { P P } _ { 3 }$ [PP3 V] PP2   
merge $\mathrm { P P _ { 1 } }$ PP1 [PP3 V] PP2   
f) V   
merge $\mathrm { P P } _ { 3 }$ PP3 V   
merge $\mathrm { P P } _ { 2 }$ $\mathbf { P } \mathbf { P } _ { 2 }$ $\mathbf { P } \mathbf { P } _ { 3 }$ V   
move VP and pied pipe $\mathrm { P P } _ { 3 }$ [PP3 V] PP2   
merge $\mathrm { P P _ { 1 } }$ PP1 [PP3 V] PP2   
move VP and pied pipe $\mathrm { P P } _ { 3 }$ and $\mathrm { P P } _ { 2 }$ $[ [ \mathrm { P P } _ { 3 } \ \mathrm { V } ] \ \mathrm { P P } _ { 2 } ] \ \mathrm { P P } _ { 1 }$   
g) V   
merge $\mathrm { P P } _ { 3 }$ $\mathbf { P } \mathbf { P } _ { 3 }$ V   
merge $\mathrm { P P } _ { 2 }$ PP2 PP3 V   
merge $\mathrm { P P _ { 1 } }$ PP1 PP2 PP3 V   
move VP and pied pipe $\mathrm { P P } _ { 2 }$ and $\mathrm { P P } _ { 3 }$ [PP2 PP3 V] PP1   
h) V   
merge $\mathrm { P P } _ { 3 }$ $\mathbf { P } \mathbf { P } _ { 3 }$ V   
move VP V PP3   
merge $\mathrm { P P } _ { 2 }$ PP2 V PP3   
merge $\mathrm { P P _ { 1 } }$ PP1 PP2 V PP3   
move VP and pied pipe $\mathrm { P P } _ { 2 }$ and $\mathrm { P P } _ { 3 }$ [PP2 V PP3] PP1

If movement is always due to the attraction of (lexical) elements from higher functional elements, one could argue against the analysis of Pattern 5.e). The question arises, why the functional element between $\mathrm { P P } _ { 2 }$ and $\mathrm { P P } _ { 3 }$ , which normally attracts the VP is skipped over. One way out, is to assume that the whole complex $[ \mathrm { P P } _ { 3 } \ \mathrm { V } ]$ is moved into the spec of an (empty) functional head between the two prepositional expressions. A complete analysis with all functional heads would be:

e) V   
merge $\mathrm { P P } _ { 3 }$ PP3 V   
merge f f3 PP3 V   
move VP and pied pipe $\mathrm { P P } _ { 3 }$ [PP3 V] f3   
merge $\mathrm { P P } _ { 2 }$ PP2 [PP V] f   
merge f2 f2 PP2 [PP V] f   
move VP and pied pipe $\mathrm { P P } _ { 3 }$ [[PP3 V] f3] f2 PP2   
merge $\mathrm { P P _ { 1 } }$ PP1 [[PP3 V] f3] f2 PP2

This kind of analysis states, that in Dutch the verb can climb optionally across the PPs. However, this option is highly restricted to few types of PP combinations. In the case of pied piping, the VP can transport the PP to its right, but also PPs above. How many of these PPs are pied piped is also optional.

I want to give now a closer look on the distinct derivations of the pied piping analysis. At the beginning of the derivation we insert the VP with all its arguments:

![](img/fcc571c41197244c17baebd739c124a0782400b12527150e9e9f7f101c74e954.jpg)

In the highest spec position we find the subject, followed by the direct and the indirect object, related all to light verbs in the sense of Larson (though differently from him in not allowing complements lower than the verb). With this structure we also obey the modified LCA of Koopman, which states, that no overt material in a specifier and a head are to be found together. If we want our theory to be so restrictive, that it prevents extraction out of specifiers, we cannot move the whole $\mathbf { v } _ { 1 } \mathbf { P }$ up as one constituent and extract the individual arguments and the $\mathrm { v }$ later independently to different locations. The single parts have to move on their own from the beginning. That means that landing positions for each element have to be provided cyclically in each single step. For the moment, I will abstract away from the argument part and take only the lowest VP into consideration.

For each preposition, I propose an expanded projection that takes into account Kayne's proposal of having a Case Projection KP in the lowest position which is selected by a preposition P. This preposition could directly attract the VP to its specifier, but in order to be in agreement with the ideas of the morphological chapter, I add another projection, which provides a landing position for the VP, called LVP.

As next step the lowest prepositional expression is merged:

![](img/e02c83197005d1077edb362dd2433b4450662a73cfaecf9b40bc8a4f7ce056f6.jpg)

Pattern 1 results when the VP stays below and the other PPs are merged in direct order. In all other cases the verb moves to the spec of LVP.

![](img/155cf2786e95c9107ad197ce06abc467a06a4772ab7dcb9427ba96fa66607252.jpg)

The next prepositional material is merged:

![](img/9df6c92e7867d580d78eaead3c8e3048ce7e2a1d38ae94fb088a981e69f1b53c.jpg)

Now the VP is attracted to the $\mathrm { L V } _ { \mathrm { m a x - 1 } } \mathrm { P }$ . In the pied piping case (patterns 2 and 4) it pied pipes the entire $\mathrm { L V } _ { \mathrm { m a x } } \mathrm { P }$ along with it:

![](img/e93d54e4b04123dc0daf0f9c61294bc6c67f386c83c5decf0681907241faa13f.jpg)

thus we get the inverted PP order (with the verb in front).

In the non pied piping case (patterns 2 and 5) the VP just jumps alone from [spec, $\mathrm { L V } _ { \mathrm { n } } \mathrm { P } ]$ to [spec, $\mathrm { L V _ { n - 1 } P ] }$ :

![](img/b49557cbbcb00e62740011b4f93e8f43993fa1706918e3b9e0bc1bfa9cf75ca0.jpg)

So we get the direct order of the PPs with the verb in front.

The ‘upward’ pied piping of the last 4 patterns of Barbiers' corpus remains to be accounted for. As an example I will show the derivation for pattern 5.f)

It starts like the other with the VP in base position.

![](img/2753b90c431753736661205abf630c7ebd9183cb050fbadd32e87042cf7fc1ac.jpg)

Now the $\mathrm { L V } _ { \mathrm { m a x } } \mathrm { P }$ attracts the VP, which pied pipes upward, i.e. what moves as a whole is the $\mathrm { \Delta P _ { m a x } P }$ :

![](img/f5840a3014d81b0c4b9af1e9eb0c49a1903e156f33739ebd25986fb15de7f419.jpg)

The next KP – PP – LVP complex is merged:

![](img/cd1fb4dd88c3a6bbd8deae147be951d1a72a60825313ffd7c4675f70aad6d2bf.jpg)

The $\mathrm { L V } _ { \mathrm { m a x - 1 } } \mathrm { P }$ attracts the VP. Since we do not allow for extraction out of specifiers, the smallest constituent, which contains the VP that can move is the $\mathrm { { P } _ { m a x } \mathrm { { P } } }$ . Whether the $\mathrm { L V } _ { \mathrm { m a x } } \mathrm { P }$ is pied piped (downward) along or not cannot be decided according to the data, since it is void of overt material. But we have shown above, that languages either always pied pipe downward or never. So we take the whole $\mathrm { L V } _ { \mathrm { m a x } } \mathrm { P }$ to be moved up:

![](img/6de85efc5730f3083eef6d064baced4374c8c26e41187cb680f3afdbd68289b9.jpg)

Above the $\mathrm { L V } _ { \mathrm { m a x - 1 } } \mathrm { P }$ the next extended projection is merged. Since no intermediate projections attract lower material I again give the full merged tree until $\mathrm { L V } _ { \mathrm { m a x } - 2 } \mathrm { P }$ :

LVmax-2P

![](img/0e28d59140dd0066e2da2fa1d6c91a16216328cc546739a6db3fbf80d3142cc4.jpg)

The $\mathrm { L V } _ { \mathrm { m a x } - 2 } \mathrm { P }$ attracts the VP which is contained in the $\mathrm { L V } _ { \mathrm { m a x - 1 } } \mathrm { P }$ (remember, that it is a pied piping language, so at least downward pied piping is obligatory.

![](img/3d1c701c266acc3da6279ef2f400f53413a4b9014724d57314511165e2f89eb5.jpg)

and we get the surface order $\mathrm { P P } _ { 3 } \ : \mathrm { V } \ : \mathrm { P P } _ { 2 } \ : \mathrm { P P } _ { 1 }$ .

The theory presented so far is permits movements of maximal projections out of specifier and complement positions. They obey the usual restrictions such as the C-command condition and Cyclicity. Nothing is extracted out of a specifier.

What are the parameters in play? They span two dimensions of parametric variation:

First we have the common parameter which states how far the verb moves overtly. In English, it moves across all PPs before Spell Out. In German main clauses it also moves up across all PPs. In dependent clauses it stays in situ (presumably moving up after Spell Out). The Dutch data (maybe this is partly true for German as well) show, that the verb can optionally move across an arbitrary number of PPs.

If we abstract away from the Dutch data, this parameter can be identified with the common weak versus strong feature of the Minimalist Program. It is a characteristic of a functional head and thus compatible with Kayne's (2003) ideas.

The second dimension is spanned by the pied piping parameter. In a minimalist framework this means that the attracted feature (here base generated in V) is percolated to a node above its projection (the VP). In the example this is the LVP, which dominates the PP. Thus, the whole LVP is attracted, including the VP and the PP.

If we follow Kayne (2003), we want to exclude any syntactic parameter that permits pied piping in language A in general, but prohibits it in language B (see also Chapter 4). We would like to correlate parameters with properties of certain functional heads. In this case the appropriate head would be LV, which forces the attracted feature of the verb to percolate to its maximal projection. This means that all LV in the different extended projections have to be identified. Otherwise we would have to deal with a statement like: In English all LVs trigger pied piping, in German none and there is no language in which some LVs trigger pied piping and others not.

In the Dutch case, where sometimes a PP above can be pied piped, this means that the pied piped $\mathrm { P }$ has the same property optionally. This means that we have to view $\mathrm { P }$ as a functional head.

Note, that this analysis adds an additional mechanism to the theory. A functional head can attract a maximal projection to its specifier, which results in the known process of Move. It also can attract the feature of a dominated head without any overt movement. This percolation permits its maximal projection to be attracted by another head, which attracts the percolated feature.

Ordinary attraction of an XP to a specifier usually implies the percolation of features from the head to its maximal projection. Features in most theories are not attributed to maximal projections, only to heads. The only way to avoid percolation at all is to take basic projections to be in the lexicon instead of heads as proposed in Chapter 4.

There is another problem with the Dutch example. There are two ways for the verb to raise up: in main clauses via movement from specifier to specifier without pied piping and in dependent clauses via pied piping. The first movement is obligatory, the second optional. What determines whether the verb raises with or without pied piping?

Optional pied piping raises a problem for the theory. J. Koster and S. Barbiers pointed out to me (p.c.) that the semantic/pragmatic interpretation of the different word orders is not identical. It is totally unclear, how these interpretations can be linked to a feature of a functional head, which gives rise to optionality.

A last observation is in order. The pied piping analysis is by no means compatible with the morphological analysis of Chapter 5. It is crucial for the latter that there is no intervening material between morphemes. In the pied pip ing approach, the verb moves together with a complex of PPs (and the object)

from modifier projection to modifier projection. Certain affixes are certainly higher than certain PPs. Thus a complex phrase with the verb followed by PPs would land in the specifier of suffixes. In the morphological approach of Chapter 5, the whole complex, including V, PPs and suffix would have to be interpreted as a single word.

Another problem arises with verb second languages:

# 6.6 The verb second problem

We saw that in German main clauses the verb raises above all modifiers into the left periphery. In dependent clauses, this movement is blocked by the overt complementiser. In head movement theories it is assumed, that the landing position of the head V is C, which in case of dependent clauses is already occupied. The head movement constraint demands that it has to pass every intervening head, i.e. at least I.

Even theories in which the maximal projection VP is moved have to deal with intermediate landing positions in which morphological features are checked or affixes are assigned. I n German we have at least to assume tense and agreement inflection. Tense projections are definitely higher than locative adjuncts. What happens exactly when the complementizer occupies the C-position? Why does the verb not move to the penultimate position and the complementizer blocks only the successive movement to C?

main clauses:

Topic/Focus Verb … Adj … Agr … Adj … Tense … Adj … tVerb

![](img/c65cb4eda47b110a5b7bbebea465dda23c4d10bd327c66038cc0ef875c009bc7.jpg)

dependent clauses:

Topic/Focus … Adj … Agr … Adj … Tense … Adj … Verb

![](img/cf2713cf02e333ed1e22819f5f8251f57957fa6f5ad0ec29a891a18ad9f33bcf.jpg)

How does the verb at the beginning of the derivation know, that at some very late stage the whole movement up to C will be blocked and so doesn't even move to Tense and Agr?

A possible answer is to assume, that Agr and Tense have weak features that can be satisfied after Spell Out, whereas C has a strong feature, which can be satisfied either by C or the verb, but this must happen overtly. If there is no complementiser, the verb has to move before spellout to C. The head movement constraint guarantees that the verb passes on its way up the intermediate positions.

If the verb waits until the only functional head with strong features, C, is merged before moving up, the movement to the intermediate stops is not done cyclically. Movement to the intermediate heads has to be done at the moment they are created. In early minimalist frameworks this contradiction is solved by introducing the competition of derivations. Every possible movement, which obeys locality and economy principles is done, but only the convergent derivations survive. In this model there is no local motivation for a single movement. The principle of interpretation is the only justification for the dislocation of elements.

This implies that V moves locally to an intermediate head with weak features at a certain stage, where no head with weak feature has been merged. Modern minimalist analyses tempt to avoid this mechanism of ‘look ahead’. Every moment has to be motivated locally. Therefore, these approaches have a problem with verb movement to intermediate positions.

But it is easy to see, that this cannot be done in a local cyclic way. The verb must look ahead a long way that definitely passes at least two phases.

Kayne showed in recent works, that many linguistic phenomena, such as operator variable binding, which originally were the reason to invent covert movement to LF, are expicable totally by means of overt movement. If we follow these lines it could be interesting to see, whether we could explain verb movement without any covert post Spell Out component.

In the case of German dependent clauses this means that the verb always moves to the intermediates stops. This movement will be hidden by additional movement of the other material across the verb.

# 6.7 Overt verb movement driven only by morphology

There are several ways to achieve this. One would be to first move the verb all the way up to the next morpheme and then move the rest that is left behind in front of it.

A projection, which in any case provides morphology for the verb to check or to get assigned to, is TP. Let us take a sentence like

(German)

(6-61) ..., dass Hans wahrscheinlich im Garten mit der Schaufel .., that John probably in_the garden with the shovel arbeitete. worked “..., that John probably worked with the shovel in the garden.”

The epistemic ‘wahrscheinlich’ is higher than the TP, the Locative ‘im Garten’ and the Instrumental ‘mit der Schaufel’ according to the assumed hierarchy. If we abstract away from the subject we get the following derivation:

basic verb position   
a V first PP (instrumental) merged   
b $\mathrm { P P } _ { 2 }$ V second PP (locative) merged   
c PP1 PP2 V TP merged   
d TP PP1 PP2 V the verb moves to check its (past) morphology   
e TPV $\mathrm { P P _ { 1 } }$ PP2 the two PPS have to move now, for the derivation to be cyclic   
f $\mathrm { P P } _ { 1 } \mathrm { P P } _ { 2 }$ TPV   
the epistemic is merged.   
g EpP PP1 PP2 TPV

Now, the verb is in sentence final position, the basic order, though several movements have ocurred. If no complementiser is merged next, the tensed verb will move up and some other topicalised material will follow in first position.

In case of a complementiser these additional movements are blocked. If the verb moves via head movement, we can retain the analysis, that both, verb and complementiser, compete for the same position. If the verb moves via XP movement, this analysis is not available.

It seems, that German dependent clauses with overt complementisers do not have the full left peripherical structure as main clauses have. Especially topics seem to be excluded. Compare:

(German)

(6-62) Was hat Hans am Freitag gemacht? “What did Hans do on Friday?” (German)   
(6-63) Am Freitag hat Hans Fußball gespielt. “On Friday Hans played soccer.” (German)   
(6-64) Ich glaube, dass Hans am Freitag Fußball gespielt hat. “I think that John played Soccer on Friday.”

(6-65) \* Ich glaube, dass am Freitag Hans Fußball gespielt hat.

While in the main clause answer, (6-63), ‘am Freitag’ is in the typical topic position in front of the verb, this position is not available in dependent clauses. ‘Am Freitag’ has to appear after the complementiser and, as the example shows, after the subject. If these type of clauses do not have topic positions, then no movement into first position is possible. The left periphery of dependent clauses is reduced in German and probably the prototypical landing position for verbs in main clauses is also missing.

Now we have a possible derivation for the German case, where the verb (VP) movement is driven purely by morphological reason. The verb moves in one step from the merge position to the affix positions, skipping all intervening PPs and other adjuncts (and thus revealing an asymmetry between affixes and other modifiers). If we compare this derivation with the pied piping analysis seen for English, it seems not very obvious how to find a parameter accounting for the different behaviour of the two (types of) languages. In English, the verb stops in every intervening PP area and pied pipes its overt material on its way up. So there are at least two parameters at work: the pied piping parameter and the “don’t skip intervening PPs”- parameter. The latter at least seems to be dispensable. We could assume, that in German the verbs stops also in the PP area in a specifier position and moves from there cyclically up to the affix position. The difference with English would reduce to the pied piping parameter.

As we saw above, pied piping is not compatible with the morphological approach of Chapter 5. Therefore, in both languages verb and modifier move independently around the higher (over) modifiers. The difference between the two languages has to be found in the way they move. I will call this the cyclic approach, where each ‘cycle’ is linked to the merge of a modifier.

# 6.8 Cyclic approaches

The general idea behind this approach is to relate to each prepositional modifier an extended projection which consist at least of the overt material of the PP itself, i. e. the preposition $\mathrm { P }$ and the DP. Whether the DP has moved into this position from below or is directly merged there, is not important for this analysis. I will abbreviate this complex with $\mathrm { P P _ { n } }$ .

The cyclic approach hinges crucially on the idea that the verb, moving as part of an XP, makes an intermediate stop in each of these extended projections. Therefore, the extended projection of a PP has to provide at least one landing position for the VP. In the general case I will assume that the relative position of the verb to the PP complex will be preserved at each intermediate step. Before entering the PP area different processes may be involved. The same is valid for movements that follow this part of the derivation (for instance movements of the verb into the left periphery).

In the English case, the PPs, though base generated in direct order, end up in reversed order. The most economic way to achieve this is to reverse their order cyclically. Since we want to exclude movement to a position below, the extended projection of an English PP also has to provide landing positions for the lower (already inverted) PP complex. For the German case I argued for additional movements of PPs across the moved V, which “hide” this verb raising. This means that we have to assume landing positions for PPs in German as well. In both cases these landing positions can be above or below the overt material of the actual PP. I will exclude the possibility that anything can land between the $\mathrm { P }$ and its DP-“complement”. If this were the case, than we would probably find languages that show this separation on their surface order. The lower PP complex will be called in the following $\mathrm { P P _ { n - 1 } }$ , its landing position LPrepP.

I will now give a complete list of the possible derivations, depending on the landing positions of the lower PP complex and the verb relative to each other and the actual PP.

Borders between extended projections are indicated with dashed lines.

6.8.1 A Derivations that result in direct order:

# A.1 LPrepP below

If we abstract away from the verb for the moment we get

![](img/90980f2b38a17c028602709f11d5975ec2996b739de07c7567a5c4f446d5bacc.jpg)

Each additional movement would be redundant. Adding V movement, where the position of the verb either in front of the whole complex or behind is preserved, we get the two possibilities:

A.1.1 LPrepP below, verb final:

PrepnP V V PrepnP PrepnP V Prepn-1P PrepnP V

A.1.2 LPrepP below, verb initial:

V PrepnP PrepnP V Prepn-1P PrepnP V V Prepn-1P PrepnP

# A.2 LPrepP above

If the landing position is above, we need an additional move of the higher adjunct to the left of the moved element to arrive at superficial direct order:

![](img/53665760cc7521b19642a4794af0e7f815144b14415c73f0cc96a4376532ab32.jpg)

For the preserved verb final position we get two derivations, one with the landing position of the verb below the base position of $\mathrm { P r e p } _ { \mathrm { n - 1 } } \mathrm { P }$ and one (immediately) above:

A.2.1 a) LPrepP above, verb final, LVP low

PrepnP V V PrepnP Prepn-1P V PrepnP PrepnP Prepn-1P V Prepn-1P PrepnP V

A.2.1 b) LPrepP above, verb final, LVP higher

Prep P V PrepnP V PrepnP

Prepn-1P V Prepn-1P PrepnP V Prepn-1P Prepn-1P PrepnP V

A.2.2 LPrepP above, verb initial

V PrepnP V PrepnP V   
V

Prepn-1P PrepnP Prepn-1P Prepn-1P PrepnP V Prepn-1P PrepnP

6.8.2 B Derivations that result in inverted order:

B.1 LPrepP below

![](img/ee8df66c5633273fd0ad124c123478cf9f5bdbe8d20c376099d9bd94a5896afa.jpg)

This is a derivation with two moves of $\mathrm { P r e p } _ { \mathrm { n } } \mathrm { P } !$ The first seems to be entirely redundant. Furthermore, it is improbable that the extended projection of a PP has two landing positions of the same element. I will exclude this derivation therefore from the list.

B. 2 LPrepP above

![](img/17a1d938d4b6bdc100514ab32f8ef1c1b8cdb03564d5aec387e072c062a51b46.jpg)

For the verb movement, there are in principle two options possible

B.2.1 LPrep above, verb final

PrepnP V V PrepnP Prepn-1P V PrepnP PrepnP Prepn-1P V

B.2.2 LPrepP above, verb initial

V PrepnP Prepn-1P V PrepnP PrepnP Prepn-1P V V PrepnP Prepn-1P

I started this discussion with the idea, that the verb even in German dependent clauses moves cyclically around the modifier space resulting in a direct order of PPs, verb final. In the case of empty complementiser, the verb does one additional step and moves in front. Thus, we can deduce the verb initial, direct order case from the verb final, direct order case.

The verb final, inverted order case is never observed in nature. Though, in prinicple, one could think that the verb initial order could be derived from the inverted, verb final case in the same way the German verb second position is derived, this does not seem very plausible. We would expect to find in nature traces of the inverted, verb final case. Therefore, I will exclude the inverted verb final derivation from the list.

Most modern syntactic theories assume structural universality. Kayne's proposal that parameters are only properties of functional elements is an example of this tendency. Following this line we can exclude that the German type languages have the landing position of the PP complex below the overt material whereas we find this position above in the English type languages.

Nevertheless we can think of a very extended projection connected with each modifier, which has several possible landing positions for the lower modifier complex and the verb. To cover all possible cases we get in principle the following positions:

# LPrep P LVP LPrepP LVP PP LPrepP LVP

Different languages could activate different landing positions for the lower PPs and the verb. For each of the remaining schemes we can assume a possible derivation.

Following Kayne's proposal that prepositions sit in heads directly attached to the main projections line, further exclusions have to be made. Since attraction of the actual prepositional material would have to be necessarily a movement out of a complement position, all lower material would be transported with. This renders the schemes A.2.1 a) and A.2.2 impossible. If we accept this analysis only four schemes remain: A.1.1, A.1.2, A.2.1 b) and B.2.2.

The only possible derivation of the inverted order is represented by scheme B.2.2. Both landing position, of the verb and the lower PP complex, are above the actual prepositional material. I will take this as a guideline and assume that there is only one fixed position for the LVP in relation to the overt PP material. This position is above. For the verb final direct order case remains only scheme A.2.1 b).

Though I do not want to exclude the other schemes in principle, I take B.2.2 to be the one which gives me the correct derivation for the English case with postverbal PPs in inverted order and A.2.1.b) the scheme for the German dependent clause structure, with PPs in direct order in front of the verb. The main clause structure with verb second in German is derived from this scheme by an additional movement of the verb.

Both schemes are cyclically and contain only movements from a complement position, which goes together with the derivations described in Chapter 5. Therefore, the two types of derivation can show the direction of a highly restricted theory of movement.

In the following I want to show a schematic sketch of the derivations of the two pure types (PPs in inverted order after the verb, PPs in direct order in front of it). I will abstract away from arguments and other overt material. After a small discussion of the necessary extensions I will give full derivations of real sentences.

# 6.8.3 Derivation of the inverted structure

For the pattern with the inverted PPs there was only one scheme left, B.2.2, which I will repeat here for convenience:

Prepn-1P PrepnP Prepn-1P V PrepnP Prepn-1P

$$
\left| \begin{array} { l } { \mathrm { ~ V ~ } \mathbf { P r e p } _ { \mathrm { n } } \mathbf { P } } \\ { \mathrm { ~ V ~ } \mathbf { P r e p } _ { \mathrm { n } } \mathbf { P } } \\ { \mathrm { ~ V ~ } } \end{array} \right.
$$

I will abstract away for the moment from arguments and take a reduced VP shell of the form (overt material is presented in bold face):

![](img/31a5c804971bd28f10f8946a529d85c0c3bb1756480f1b1ab6a6a6dfe136603b.jpg)

I choose the extended form to the left, which is more general, though the complement branch seems entirely unnecessary.

For the prepositional expression I adopt Kayne's analysis with two projections: the PP, which hosts the preposition and the KP, with a case assigning head and the ‘complement’-DP in its specifier. According to scheme B.2.2, the extended projection has to provide in addition a landing position for the lower PP complex above the PP, which I call LPrepP. A further projection LVP which attracts the verb in its specifier is merged on top. For the minimal structure we get :

![](img/9c981d18f9b5da8a0d39d9bc227b852886bda08a871bf206355b47e800b0d95a.jpg)

At the beginning of the derivation the lowest extended PP projection is merged with the VP:

![](img/9cb09ba21c014f07a33c643f87b260a0788a386456c80d2fda81ad243bb34b8a.jpg)

$\mathrm { L P r e p } _ { \mathrm { m a x } } \mathrm { P }$ does not attract anything, because there is no modifier in a lower cycle. LVP, however attracts the VP with the overt verb, followed by merging of the next overt material:

![](img/2091db954c21f00f7f7c54edcb1be5746ebb27e1ddd86533880b162f3c977f40.jpg)

The highest projection of the tree, the $\mathrm { L P r e p } _ { \mathrm { m a x } - 1 } \mathrm { P }$ , attracts the lower overt PP material. The minimal projection which contains this and only this material is the $\mathrm { P P } _ { \mathrm { m a x } }$ itself. The maximal projection is the $\mathrm { L P r e p P _ { \mathrm { m a x } } }$ . Since at each cycle the whole inverted complex has to be moved up, it is the LPrepP $\operatorname* { m a x }$ that is attracted.

![](img/2f2172803812e82830eb17083ec9896b0bdbc20f79f7ff059af1b870d9d8b4cc.jpg)

The next LVP is merged and attracts its lower counterpart $\mathrm { L V } _ { \mathrm { m a x } } \mathrm { P }$ . Specifier movement of the VP alone is a possible solution, but attraction of the whole LVP results in a more coherent derivation.

![](img/373e1c3dacf26dbbdb23bcb4696d09c5e4f266681ab5db96c4d2f715c2013bc2.jpg)

In case of a third PP, the highest extended projection will be merged in an analogous way.

![](img/7a60a7b5e18e4c73cb8b39fd939fbbd74df5e642549086b38b7ecbe715942b1d.jpg)

The $\mathrm { L P r e p } _ { \mathrm { m a x } - 2 }$ attracts the lower LPrepP. This time it is clear that attraction of only the PP would not give the correct result:

![](img/f9cf5b88f6de0f079ccc5da6a8b57bc285152c142f7069d3cca3caee64f605db.jpg)

Finally, the last LVP is merged and attracts $\mathrm { L V } _ { \mathrm { m a x - 1 } } \mathrm { P }$

![](img/7734cfe7eb078d468553d21fb51a38997d62d80a0614d30cb649c0f9d22e4433.jpg)

Now we got the desired result of having the verb in front of a group of inverted PPs. We used only two types of operations during the derivations: Merge of another projection and movement of a complement (no head movement, no specifier movement). The movements were driven by cyclic attractions of similar elements: $\mathrm { L P r e p _ { n } P }$ attracts $\mathrm { L P r e p } _ { \mathrm { n + l } } \mathrm { P }$ , $\mathrm { L V _ { n } P }$ attracts $\mathrm { L V _ { n + 1 } P }$ . In the resulting structure we never find overt material in the specifier of an overt head. Note also, that all the movements are cyclic in the sense of Chomsky's extension condition.

# 6.8.4 Derivation of the direct order

Among the remaining schemes for the direct order, verb final case, A.2.1 b) was the one which came closest to the remaining inverted order scheme. I repeat it her for convenience.

Prepn-1P V Prepn-1P PrepnP V Prepn-1P Prep P Prep P V

PrepnP V PrepnP V PrepnP

Here, as in the above case of inverted, postverbal PPs, both landing positions are above, but their relative order is reversed. Maintaining the idea of structure universality, this means either that a different landing position of the verb is activated or a different landing position of the prepositional complex. There is another difference to the above case: the actual $\mathrm { P r e p } _ { \mathrm { n - 1 } } \mathrm { P }$ is attracted to a position above the $\mathrm { P r e p } _ { \mathrm { n } } \mathrm { P }$ . Certainly, we do not want these two differences to be attributed to two independent parameters. Activating a different landing position of the verb below $\mathrm { P r e p } _ { \mathrm { n } } \mathrm { P }$ can not easily be made responsible for the movement of the $\mathrm { P r e p } _ { \mathrm { n - 1 } } \mathrm { P }$ .

If another landing position for the $\mathrm { P r e p } _ { \mathrm { n } } \mathrm { P }$ is activated, then this $\mathrm { P r e p } _ { \mathrm { n } } \mathrm { P }$ could attract the $\mathrm { P r e p } _ { \mathrm { n - 1 } } \mathrm { P }$ to its outermost specifier. This means, we do not have to include an additional landing position for the actual PP in its own extended projection.

I therefore take the same extended prepositional projection with the addition of a further projection above the LVP, which I call PREPP. In English it is empty and has no visible effects. In German, however, it is capable of attracting a lower PrepP. We get for the extended projection:

![](img/7b83959a94451682381b22d69e41969d94b53f73f58324e0577d2cdc8e14aa56.jpg)

With this structure the derivation of the German clause structure with preverbal PPs in direct order can be done with exactly the same mechanism as in the English case. The only difference is the first movement of the lowest prepositional material into the specifier of the next higher PREPP. The following steps lead automatically to the expected surface order.

Let us start the derivation with this starting point. The VP has moved to the spec of the lowest $\mathrm { L V } _ { \mathrm { m a x } } \mathrm { P }$ , and from there to the second $\mathrm { L V } _ { \mathrm { m a x - 1 } } \mathrm { P }$ . The lowest LPrep $\mathrm { \ m a x { P } }$ sits in the specifier of the $\mathrm { P R E P } _ { \operatorname* { m a x } - 1 } \mathbf { P }$ .

![](img/081cde0db4aca33f5a520cc42758ff73c0d6f2aec854b602c31968352458a62b.jpg)

Now $\mathrm { L P r e p } _ { \mathrm { m a x } } \mathrm { P }$ asymmetrically C-commands LPrep $\mathrm { \ m a x { - } 1 ^ { P } }$ and attracts it to its specifier:

![](img/706dd8a2a736217cd597ffbba6f709d961de9fa1da1739da4601b7e43768a47e.jpg)

From this starting point the derivation proceeds as usual. $\mathrm { K P _ { m a x - 2 } P }$ , $\mathrm { P } _ { \mathrm { m a x } - 2 } \mathrm { P }$ and $\mathrm { L P r e p } _ { \mathrm { m a x } - 2 } \mathrm { P }$ are merged. Again, $\mathrm { L P r e p } _ { \mathrm { m a x } - 2 } \mathrm { P }$ cannot attract neither $\mathrm { L P r e p } _ { \mathrm { m a x } - 1 } \mathrm { P }$ nor $\mathrm { L P r e p } _ { \mathrm { m a x } } \mathrm { P }$ because they are too deep imbedded in $\mathrm { P R E P } _ { \operatorname* { m a x } - 1 } \mathbf { P }$ . $\mathrm { L V } _ { \mathrm { m a x } - 2 } \mathrm { P }$ , however attracts the lower $\mathrm { L V } _ { \mathrm { m a x - 1 } } \mathrm { P }$ with the overt verb.

![](img/0bf446feea4bf9748e8f85fe57e9d384093fa7c2fa3f6e6309f1770a4c957b80.jpg)

Next, $\mathrm { P R E P } _ { \operatorname* { m a x } - 2 } \mathrm { P }$ is merged and attracts the lower $\mathrm { P R E P } _ { \operatorname* { m a x } - 1 } \mathbf { P }$ . The latter transports the lower prepositional material.

![](img/94daaebd5a2c36e3d1f542d619a61e89af6c41e3f977a0bca92ba23faf1da07c.jpg)

As last step of this cycle, $\mathrm { L P r e p } _ { \mathrm { m a x } - 1 } \mathrm { P }$ attracts $\mathrm { L P r e p } _ { \mathrm { m a x } - 2 } \mathrm { P }$ to its specifier:

![](img/be57c2b4c6a329698e0736420c524051b577cf61d11407b08cb4b329fb23582c.jpg)

In the same way every higher PP will end up to the left giving thus rise to PPs in direct order in front of the verb. Several problems arise with the derivation presented so far.

How does is the starting position with LPrep $\mathrm { \ m a x { P } }$ in the specifier of PREPmax-1P derived?   
Nearly all movements part from a complement position except for the VP which moves into the spec of $\mathrm { L V } _ { \mathrm { m a x } } \mathrm { P }$ from where it extracts and moves to the spec of $\mathrm { L V } _ { \mathrm { m a x - 1 } } \mathrm { P }$   
If extraction of the VP out of the specifier position of LVP is possible, why can $\mathrm { L P r e p } _ { \mathrm { m a x } } \mathrm { P }$ be not attracted from specifier position to $\mathrm { L P r e p } _ { \mathrm { m a x } - 2 } \mathrm { P }$ ?

The following proposal for the first part of the derivation can resolve the problems connected with the movements out of a specifier position.

Above the verb and all arguments I propose a projection Proposition Phrase (PropP) as closure of the VP shell. It represents the core proposition, the nuclear event. Its head is unpronounced in German. Abstracting away from argument positions the VP shell is:

![](img/6be4e5648154d9cc27a641b8d6951e37a760507212c69dc74e27bd65c662507a.jpg)

This PropP has the same features as the above PREPP which all can be viewed as closures of subevent structure: PropP is the closure of the VP shell, the PREPPs are closures of the extended projections of prepositions or maybe more generally of modifiers. Like other PREPPs PropP can be attracted by higher PREPPs. Furthermore, in German it has a feature in common with the LPrepPs, which permits it to attract LPrepPs, but not to be attracted by them. Above the PropP the lowest prepositional modifier is merged, beginning with $\mathrm { K } _ { \mathrm { m a x } } \mathrm { P }$ , $\mathrm { { P } _ { m a x } \mathrm { { P } } }$ and $\mathrm { L P r e p } _ { \mathrm { m a x } } \mathrm { P }$ .

![](img/4ce13af589c9f8416d118cc4347da8a1c74983d30007cfb581a1ae2974b5475b.jpg)

PropP cannot be attracted by LPrepP. It can only attract other LPrepPs. Therefore, the derivation continues with the Merge of $\mathrm { L V } _ { \mathrm { m a x } } \mathrm { P }$ , which attracts VP:

![](img/0216df6fa306a140377ca923eb948091c76c83fcfc36c2dcaae5b7965ebe6db6.jpg)

$\mathrm { P R E P _ { \operatorname* { m a x } } P }$ is merged and attracts PropP:

![](img/c68d9c005abbd004a94c2f9c1fe1d30f6dc4e2c68eadcd5608d98b7260c58667.jpg)

![](img/931ba01ac94036cda6f804b409975b3f198b4fc72d04415f531845b47ceb27fe.jpg)

The lower part of the next extended prepositional projection is merged with $\mathrm { K } _ { \mathrm { m a x - l } } \mathrm { P }$ , $\mathrm { P } _ { \mathrm { m a x } - 1 } \mathrm { P }$ and LPrep $\mathrm { \ m a x { - } 1 ^ { P } }$ :

![](img/dbfd852a0793658602371f7f7040354ac9bdc71b6a194df8627b2971223d833c.jpg)

Since PropP cannot be attracted by LPrepP the next LPrepP available for $\mathrm { L P r e p } _ { \mathrm { m a x } - 1 } \mathrm { P }$ is $\mathrm { L P r e p } _ { \mathrm { m a x } } \mathrm { P }$ . Note that this time $\mathrm { L P r e p } _ { \mathrm { m a x } } \mathrm { P }$ does not sit in the specifier of $\mathrm { P R E P _ { \operatorname* { m a x } } P }$ but in the specifier of its specifier. We do not need to exclude specifier movement in general in order to prohibit attraction of LPrep$\mathrm { \ m a x { P } }$ by $\mathrm { L P r e p } _ { \mathrm { m a x } - 1 } \mathrm { P }$ . It is sufficient to exclude extraction out of a specifier.

$\mathrm { L V } _ { \mathrm { m a x - 1 } } \mathrm { P }$ is merged next and attracts the lower $\mathrm { L V } _ { \mathrm { m a x } } \mathrm { P }$ . It is not necessary to attract VP directly out of its specifier position.

![](img/21bcc255a7635a4796144f60e6f323ba8eca3cfbf4939fcc10efab48fda69e7e.jpg)

$\mathrm { P R E P } _ { \operatorname* { m a x } - 1 } \mathbf { P }$ is merged next and attracts its lower counterpart $\mathrm { P R E P _ { \operatorname* { m a x } } P }$ :

![](img/8de7bdcc8865a37311bdb7533a5572dedd3715ccfede679d4dc28a6bd8b598f0.jpg)

where LPrep $\mathrm { \ m a x { P } }$ in turn attracts LPrepmax-1P

![](img/1a13641e4410272a6fd7f9b9a6f591502c0416824429817f530ba2aacb66c9e0.jpg)

This derivation is cyclically and obeys the C-Command constraint, if we take Kayne's definition of asymmetric C-Command which permits the specifier of a specifier of a projection $\mathrm { P }$ to C-Command the head and the complement of the projection P.

Furthermore, this derivation has only movements out of a complement position. In all cases elements of a specific cycle attract analogous elements of a cycle below. These properties are shared by the derivation of the English case and the German case.

The difference is attributed to the properties of PropP, the closure of the VP shell. Though this element can be present in both languages its properties with respect to attraction differ. In German, PropP can attract a lower LPrepP, in English it cannot. This difference suffices to derive the different word orders of PPs with respect to each other and the verb.

# 6.8.5 Modifications in order to include morphology

The derivation proposed here resembles in many aspects the ideas presented in Chapter 5 about morphology. For each modifier, be it an affix or a prepositional expression, there is an extended projection with the overt material of the modifier and a landing position of the verb. The Axiom of Word Boundary is respected in both derivations. That means there are no projections that have overt constituents in the specifier and the head if they do not form part of the same word. Movements always start from a complement position.

In the case of having an affix and a PP of the same type, let's say for instance temporal, the interesting question arises, whether they make part of the same extended projection. In a theory that takes all the members of the hierarchy of modifiers to be present in every sentence, it seems plausible to assume that they in fact do sit in the same projection.

The SuffP can easily be identified with the LVP of the extended prepositional projection. For the PrefP things do not seem to be that easy. In Chapter 5 it was shown, that it has to sit in a very low position of the extended projection with no overt material below at the time of its movement to the VP, sitting in the SuffP. This posits it below PP and below DP. We have to assume an additional projection PrefP below KP.

Let us assume this projection is present in every extended projection of a prepositional modifier. If its head bears a feature, that permits its attraction to the higher VP, we call it a prefix. If its head is not empty but does not bear this feature, it can be identified with a postposition. In the case of German this would explain the similarity of certain prefixes like ‘um-’ to prepositions. This could give an explanation for Greenbergs Universal 27, which I want to repeat here:

(27a) If a language is exclusively suffixing, it is postpositional (27b) If it is exclusively prefixing, it is prepositional.

If prefixes and postpositions are in competition for the same position, the Universal follows automatically.

There is another problem in combining the two models. Cyclicity constrained us in the morphological chapter to take the SuffP very high in the extended projection. After the movement of the PrefP to the higher VP, no material of a lower cycle can be moved to a higher position; it had to be moved before to an intermediate position.

The same reasoning can be applied to the movement of overt material to PREPP. Since in German the LPrepP, which is higher than the PrefP, has to be moved to a specifier in PREPP, no lower overt material can be left below. This gives PREPP as higher than the SuffP in contradiction to the above constraints. Is there a possibility to resolve this contradiction?

At first we can state, that languages of the English type do not have a problem. There is never overt material that has to be transported to a specifier in PREPP. Prefixes that move to a verb, sitting in the specifier of SuffP can transport the lower empty PREPP without affecting the rest of the derivation.

Next, there is no problem with suffixing. If there is no prefixing, languages of the English type and the German type do not have to respect the condition that SuffP has to be the highest projection to which overt material can be transported.

Problematic is only the case of languages of the German type that have prefixing. If we glance at Greenbergs Universal 4:

# With overwhelmingly greater than chance frequency, languages with normal SOV order are postpositional.

and combine it with his Universal 27, we might find the way out of the apparent contradiction. Languages seem to be dividable into two mayor types: OV and VO languages. OV languages are postpositional and according to Universal 27 have no prefixing, German is one representative of them. VO languages have neither a restriction on prefixing nor on pre-or postpositions. They behave like English with respect to modifiers and as we have seen, they do not have any problems with the clash of the two constraints.

So, universally prefixing is excluded as normal way of affixing in languages of the German type. If this turns out to be the correct generalisation, we have to explain the facts, that there are prefixes to be found in German.

But the prefixing in German is in most cases not productive. The only case of productive prefixing is connected with the formation of the past participle. Furthermore, there is a rule, which does not permit more than one prefix in German. It remains to be seen, whether we can account for this behaviour in German within the framework presented here.

# 6.8.6 Modifications in order to include arguments

Since all arguments are base generated in the VP shell they have to move cyclically up to their final surface position. Therefore, each extended projection has to provide intermediate landing positions for each of them up to their landing position. For the English object with its fixed position after the verb, it can be assumed that it lands in a position between the LPrepP and the ${ \mathrm { S u f f P } } =$ LVP. Thus, it is transported with the other prepositions from cycle to cycle. Since it is the first in this sequence, its finally position will be directly after the verb. The landing position for the subject must be higher. If further investigations indicate, that it will be above the verbal landing position, I might have to revise the structure for the VP-shell. The easiest way to move the arguments into these landing positions would be to start with a base position of the Object below the verb and the subject above, which is closer to Larson's original proposal. The derivation would then start with this VP-shell:

![](img/aef748971ef6174b373e8bc0c9078b3350c133765fb9962dc096d7c9c5c8d2b6.jpg)

Above the first extended modifier will be merged which consists of a landing position for the object LObjP, the LPrepP, a landing position for the verb LVP and a landing position for the subject LSubjP. They are merged cyclically and attract the various parts of the VP-shell in turn:

![](img/85d78c6f5b8cca6785cc2b49a040a814dfaf3f6e381f09f187bab3a7f4cae306.jpg)

![](img/ce1d3331c626d06054d39f4aec55b9ff58f3968d876c5718b84d296cb3fff54a.jpg)

As closure, the PREPP merges and attracts PropP, which has not effect, since in English, it cannot attract LPrepP:

![](img/28fb5fb1104ed4c1d54ab2e435d307bcfdadb92cd3c9cb72c4e9df8fb11457df.jpg)

An extended prepositional expression is merged in the usual way: first an empty PrefP (which is only added here to confirm to the results of Chapter 5, then KP, PP and LPrepP, which attracts its lower counterpart.

![](img/5ed537d3f2f92a087219c853ff3e0c068f6cd40c75bc9db05f4face81cae85d9.jpg)

The nexts steps, merge of LVP, LSubjP and PREPP with the attraction of their lower counterparts will be presented in one step:

![](img/b371451b6000675d440534a048f3600796926f959fc5d9bd68b7f407377425f1.jpg)

German starts with the same derivation until the attraction of PropP by the first PREPP. In German, however, this functional projection is able to attract LPrepP.

![](img/df67e8c82c5415e8555bf04f446dea861badbc7c5ecc1189e0849773188f8718.jpg)

PrefP, KP, PP and LPrepP are merged without any further consequences. LPrepP cannot attract its lower counterpart, because it is too deep imbedded in PREPP:

![](img/818ab2ab16d23730d6fae8dcea4995c242097169d0fb9627257972501dd6b4b0.jpg)

The following steps, merge of LVP, LSubjP and PREPP and the attraction of their lower counterparts, will presented here also in one step.

![](img/eed200ee2a179147249376141f117d1cd6c8a9edb38cab58d418fec2f6ced08b.jpg)

The highest specifier in the tree is represented by a LPrepP, which attracts the lower LPrepP with the prepositional material:

![](img/2ef5fc4d1bdb83af48b1281600bb6ca0c8acd8fa542a7ec35e627d8f3ba3acb4.jpg)

PP, Object and verb appear in the right order. The subject has to go further movements until it reaches its surface position. In main clauses additional movements have to posit the topicalised element in first position and the verb in second position.

The exact position of the subject has to be in the focus of further research, as well as the movements in the left periphery. Maybe this research will show that the restriction to movements out of complement position is not valid for this area.

6.8.7 Recursive extended projections and event structure

So far, the attempt to develop a derivational model without head movement and post Spell Out rising of the verb resulted in a very rich structure assigned to every prepositional modifier. This might seem at first sight contra intuitive, but becomes more obvious if we take into consideration the ideas about extended projections presented in Chapter 4.

Crosslinguistic data suggest that lexical verbs and nouns project a rich structure which consists of a low argumental part corresponding to the VP shell, a middle field of modification (roughly the old IP) and a higher area related to pragmatic functions like information structure and illocutionary force in the case of verbal projections and deixis in the case of nouns. If we extend this structure to the case of prepositional modifiers we get an explanation for the rich structure.

We expect for each modifier an extended projection consisting of three parts: a lower argumental part, a middle field for further modifiers and a higher field for pragmatic elements.

The argumental part consists of the main predicate of the PP and its arguments. We expect the positions of the arguments in relation to their predicate to be alike for all kinds of predicates. Thus, the structure we have to stipulate for the argumental part of prepositional modifiers depends on our choice for the VP shell.

If we chose a VP shell model with the object in a complement position of the verb, we are led to view the prepositions as as predicates. If we take a sentence like:

(6-66) John read a book in Venice.

we can view the preposition ‘in’ as a predicate with two arguments, the DP ‘in Venice’ and the event ‘John read a book’ :

in $\mathrm { I } _ { \mathrm { e v } }$ John read a book], [DP Venice])

The DP ‘Venice’ can be viewed as the object of the preposition and is found inside the KP which is in complement position of the P. To strengthen this analogy we can posit the verbal object in the specifier of a $\mathrm { V } _ { 2 } \mathrm { P }$ which is the complement of V.

The event ‘John read a book’ has to be represented by some structural node above the overt part of the VP shell, I will call it evP and posit it somewhere below PropP. This node has to move up into a position from where it Ccommands locally the preposition. I take this to be the specifier of a projection called ArgP, which is merged above PP.

We thus get in analogy for the VP shell and the argumental space of the prepositions:

![](img/df98900cacd2d66986c81e935cc5f0df328309d3086867c05099f9b9d1aae3b8.jpg)

If we assume a VP shell with the verb in the lowest position and all arguments above, we expect an analogous structure for prepositional modifiers. In Kayne's proposal, prepositions are base generated higher than their DP – ‘complements’. Thus, they cannot be the predicates. The lowest projections in each prepositional field so far have been the PrefPs which were related to prefixes or postposition. Let us assume that they constitute the predicates. In the case of the above example

(6-66) John read a book in Venice.

it is not the preposition ‘in’ but the lower abstract head of the PrefP, which in this case could be called PLACE. We might view this as a predicate with three arguments which states that there is a locative relation between a DP and an event. The preposition ‘in’, which specifies this local relation, is the third argument. We thus would get:

PLACE $\mathrm { I _ { e v } }$ John read a book], [ in], [ Venice])

The two structures for the verbal and prepositional argumental space would be:

![](img/2425ea8a21e2573ea714afbab76c21aa95ec203d6e89dbd7c210495bb3893925.jpg)

In the following I want to give schematic derivations for the two PPs in the English and German case starting from a position after Merge of the lowest PP with all subsequent moves from below. PrefP will be left out for reasons of space.

In English I start with:

![](img/15574ea58b58ed822ed3e689eca09370e916f1836f167a5fc6679ea45690bd61.jpg)

Merge of the next cycle:

![](img/9765263dfef7502031b7599f4f742a5b2ccda54f13efff96aa01057bbd931b48.jpg)

$\mathrm { { A r g } _ { \mathrm { { m a x } - 1 } } \mathrm { { P } } }$ attracts the lower $\mathrm { e v } _ { \mathrm { m a x } - 1 } \mathrm { P }$ into its specifier. The event projections transports the overt prepositional material:

![](img/9a10bb4f1914686b189365287d065e45c8829b58d72b990f0db6b85568e43134.jpg)

The rest of the derivation continues as described above. $\mathrm { L V } _ { \mathrm { m a x - 1 } } \mathrm { P }$ is merged and attracts the verbal component. I will end the derivation here.

For the German case we need a projection between evP and ArgP, which is attracted to PREPP. I will call it for convenience again LPrepP. Then, after the first cycle, the lowest LPrepP sits in the specifier of PropP, sitting itself in the specifier of the lowest PREPP:

![](img/3924ce3aa179dd5ed192480493def4d47a5bf16c6a687d205acc0e122c245a88.jpg)

The next prepositional extended projection is merged. $\mathrm { { A r g } _ { \mathrm { { m a x } - 1 } } \mathrm { { P } } }$ attracts the lower $\mathrm { e v } _ { \mathrm { m a x } } \mathrm { P }$ which is vacuous but satisfies the argumental need of the higher predicate.

![](img/6987ec04035234d595dfd0f664620a7f1fb501932d698c6b819db23e46b78e34.jpg)

LPrepP, EvP, LVP and PREPP are merged next and attract their lower counterparts

![](img/eb227dd72931d28237601e900507ba00f473b528f8515f28092fbfb1f984f8c9.jpg)

$\mathrm { L P r e p } _ { \mathrm { m a x } } \mathrm { P }$ attracts the lower LPrep $\mathrm { \ m a x { - } 1 ^ { P } }$ :

![](img/9c50210def076b9912b7b99fa39009a983b86732fc2c7b31d95b94f1e05fc66e.jpg)

Thus, there is a repetitive movement of lower event projections into higher argument positions. This movement could trigger part of the other movements from cycle to cycle.

Above the argumental shell we expect the modifier part. A candidate for a modifier can be seen in the following sentence:

# (6-67) John met Jane in Venice in St. Marks Square.

‘in St. Marks Square’ specifies the locative expression, makes it more precise. Unfortunately it appears behind the expression it modifies. Since rightward movement is excluded in an antisymmetric framework, the PP ‘in Venice’ must have moved across it. If the preposition $\mathrm { P }$ is directly attached to the main projection line, it cannot move across a higher modifier without pied piping all material below. If it waits until all lower overt material (besides the KP) has been moved up, the movement across the modifier would be to a lower position than the highest projection, therefore not obeying cyclicity. How can we account for this movement?

If we take the modifier to be base generated as ModP somewhere above the ArgP and below the evP and the LPrepP, then we have for both types of derivation a step where evP or LPrepP sit in the highest specifier. For English this would be:

![](img/3f32e7dea96fa13d49238e06888cc48bc00c71414a0e2a7fba6effdf51a58bcc.jpg)

In the German case the relevant step would be:

![](img/10c1243e01cd9a27267505bb0be720296dcd14622ef42c8d75d3084e3d6e46b1.jpg)

In both structures the lower $\mathrm { { P } _ { m a x } \mathrm { { P } } }$ can climb to the highest specifier across the modifier. The details must be worked out. In the German case, the resulting structure most still provide an attracting highest modifier for the movement of the next LPrepP.

But the interesting aspect, that climbing across the modifier results in both languages in the same order:

John met Jane in Venice in St. Marks Square. John traf Jane in Venedig auf dem Markus Platz

If we find the narrower locative description to the left:

John met Jane in Venice in Italy.   
John traf Jane in Venedig in Italien.

we get in both cases a contrastive interpretation: it was Venice in Italy, not Venice in California, where they met. I will take ‘in Italy’ not as a modifier of the PP ‘in Venice’ but as a modifier of the DP ‘Venice’ alone. It specifies which Venice was ment.

Another example for modification is provided by the sentence:

(6-70) A plane was flying high above the bell tower.

The degree adverb high does not seem to modify the whole prepositional expression ‘above the bell tower’, it rather modifies the bare preposition P. If this turns out to be right, we have to revise the base structure for the lower part of the extended projection. Above the KP we find an RelP which give the exact kind of Relation between the event and the DP. In its specifier we find the extended PP with the preposition at the bottom and a degree phrase on top:

![](img/5a97aa14435d33617edcf21c70c9d2079e53b7ce74accda4ef392640baa6f8ca.jpg)

This structure would go well with the idea of having a PLACE predicate with three arguments, all sitting in specifier positions above.

The highest part of the extended projection for modifiers is provided by the ‘pragmatic shell’. Here we find landing positions for the subject and the objects. Evidence for these positions comes from quantifier floating. Certain operators that quantify the subject and the object can be found in all intermediate positions of the argument movements. In German we can find the quantifier ‘alle’ between each prepositional modifier:

(German)

Alle Jungen haben am Sonntag in der Kirche gesungen. All boys have on Sunday in the church sing.PART “All the boys sang in the church on Sunday.”

(German)

(6-72) Die Jungen haben alle am Sonntag in der Kirche gesungen.   
(6-73) Die Jungen haben am Sonntag alle in der Kirche gesungen.   
(6-74) Die Jungen haben am Sonntag in der Kirche alle gesungen.

also for the object:

(German)

Hans hat am Sonntag in der Kirche alle Lieder gesungen. Hans has on Sunday in the church all songs sing.PART “Hans sang all songs in the church on Sunday.”

(6-76) Hans hat alle Lieder am Sonntag in der Kirche gesungen.   
(6-77) Hans hat die Lieder alle am Sonntag in der Kirche gesungen.   
(6-78) Hans hat die Lieder am Sonntag alle in der Kirche gesungen.   
(6-79) Hans hat die Lieder am Sonntag in der Kirche alle gesungen.

A derivation, which excludes specifier movement must provide at each circle additional landing positions for elements that move into the left periphery if they bear a wh-feature or are focussed or topicalised. If for any reason, these elements cannot move to the left periphery they can be interpreted in their low position. Therefore, we expect low focus and low topics.

The considerations of this section could only sketch certains outlines of what a theory with recursive extended projections and cyclic movement can yield. Closer look on empirical data and deeper insight in theoretical issues will help to bring the pieces together.

# CHAPTER 7

# CONCLUSION

I tried to show with certain empirical test that there is syntactic hierarchy of thematic roles above the VP shell. This hierarchy can be combined with the Cinque Hierarchy of adverbs, affixes and auxiliaries to a field of modifiers between the CP layer and the VP shell. These three layers are commonly viewed as the extended projection of the verb.

A similar partitioning can be found for the DP. Base generated low we find the lexical predicate, above modifiers and in the uppermost layer projections related to more pragmatic functions.

Generalising this partitioning to modifiers we expect a much richer structure for each modifier than assumed before. Only part of this structure is filled with visible elements that are base generated in this area. Other constituents are moved from below and many move further on. It seems that some of the movements are attributed to the different roles a constituent plays in a sentence. A DP for instance can be an agent, a topic and the subject at the same time. In order to establish these roles it has to move in certain positions, which are related to these functions. Other more abstract constituents are related to the event structure. If a sentence has a recursive structure of predications where events are arguments for higher predicates, which become arguments of even higher predicates, more internal movement has to take place. If we accept this picture a rich syntactic structure and a high number of movements appear to be natural.

I started with very general considerations about the syntactic differences between suffixes and prefixes and how to account for different surface orders for prepositional expression. Very few restrictions – antisymmetry, only XP movement, cyclicity of derivations and C-Command Constraint for traces – together with general problems with verb second languages (why does the verb in German dependent clauses not move up at least to TP?) lead me to a model of cyclic verb movements around the modifier space. It turned out, that we do not need movements out of a specifier position for all processes relevant in the work here. If we can generalise this behaviour to a general constraint, which prohibits specifier movements, we can derive the Axiom of Word Boundary, which I had to stipulate in order to explain certain morphological data. This Axiom states that there is no word boundary between overt elements in a head and its specifier. It opens a way of integrating great parts of morphology into syntax.

The research led me far beyond the original scope of investigating whether and how prepositional modifiers can be related to the Cinque Hierarchy. It showed how structure and movement can be more restricted to general principles with the price of a richer structure. It opens up a new view on old problems, but it remains to be seen whether the theory is powerful enough to explain the data of languages and – even more important – whether it is restrictive enough to exclude data which we do not find in human languages.

The open questions below are among many that remain to be researched:

Can the morphological approach be extended to include phenomena such as template morphology, umlaut, reduplication?   
Is there an easy way to derive the different patterns of verb auxiliary complexes in German and Dutch, whose great variation has puzzled linguists for a long time?   
How do we have to include subjects and objects into the model?   
Do the syntactic tests distinguish different subject and object types according to their thematic role?   
How can we account for the different behaviour of adverbs and prepositions in English?   
How are marked surface orders of PPs derived?   
Can we refine the internal structure of the extended projection related to modifying PPs? Can we give a better map for their argumental, their modifier and their pragmatic part?

Continuing this path of research will show whether it will lead to a consistent theory with great descriptive and explanatory power.

Abney, S. 1987. The English noun phrase in its sentential aspect Ph.D.Dissertation Cambridge: Cambridge University Press.   
Anderson, J. 1971. The grammar of case: towards a localistic theory Cambridge: Cambridge University Press.   
Baker, M. 1985. “The mirror principle and morphosyntactic explanation”. Linguistic Inquiry 16(3): 373–415.   
Barbiers, S. 1995. The syntax of interpretation Den Haag: Holland Academic Graphics.   
Belletti, A. 1990. Generalized verb movement Torino: Rosenberg and Sellier.   
Bittner, M. and Hale, K. 1996. “The structural determination of case and agreement”. Linguistic Inquiry 27: 1-68.   
Bruening, B. 2001. “QR obeys superiority: Frozen scope and ACD”. Linguistic Inquiry 32(2): 233-273.   
Cardinaletti, A. and Giusti, G. 1996. Problemi di sintassi tedesca Padova: Unipress.   
Chierchia, G. 1995. “Individual-level predicates as inherent generics”. In The generic book, 176-223 Chicago, London: University of Chicago Press.   
Chomsky, N. 1995. The Minimalist Program Cambridge, Mass.: MIT.   
Chomsky, N. 1998. “Minimalist inquiries: The framework”. MIT Occasional Papers in Linguistics 15   
Chomsky, N. 1999. “Derivation by phase”. MIT Occasional Papers in Linguistics 18   
Chomsky, N. 2001. “Beyond explanatory adequacy”. MIT Occasional Papers in Linguistics 20   
Cinque, G. 1999. Adverbs and functional heads: A cross-linguistic perspective Oxford: Oxford University Press.   
Cinque, G. 2000. “ ‘Restructuring’ and functional structure”. University of Venice Working Papers in Linguistics 11: 45-127.   
Cinque, G. 2000b. “On Greenberg's universal 20 and the Semitic DP”. University of Venice Working Papers in Linguistics 10 (2): 45-61.   
Cinque, G. 2004. “Issues in adverbial syntax”. Lingua 114 (6): 683-710.   
Cook, V. and Newson, M. 1996. Chomsky's Universal Grammar: an introduction Oxford: Blackwell.   
Damonte, F. 2004. The thematic field. The syntax of argument structure enhancing morphology Ph.D.Dissertation Padua: University of Padua.   
Dowty, D. 2003. “The dual analysis of adjuncts/complements in Categorial Grammar”. In Modifying adjuncts, 33-66 Berlin: Mouton de Gruyter.   
Emonds, J 1978 “The verbal complex V'-V in French”. Linguistic Inquiry 9: 151-175.   
Fillmore, C. 1968. “The case for case”. In Universals in linguistic theory, 1-90 New York: Holt, Rinehart and Winston.   
Frey, W. 2003. “Syntactic conditions on adjunct classes”. In Modifying adjuncts, 163-210 Berlin: Mouton de Gruyter.   
Frey, W. and Pittner, K. 1998. “Zur Positionierung der Adverbiale im deutschen Mittelfeld“. Linguistische Berichte 176: 489-534.   
Greenberg, J. 1963. “Some universals of grammar with particular reference to the order of meaningful elements” . In Universals of language, 73-113 Cambridge, Mass.: MIT.   
Haegeman, L. 1994. Introduction to Government and Binding theory, second edition Oxford: Blackwell.   
Haider, H. 2003. “V-clustering and clause union: Causes and effects”. In Verb constructions in German and Dutch, 91-126 Amsterdam: Benjamins.   
Haider, H. 2004. “Pre- and postverbal adverbials in OV and VO”. Lingua 114 (6): 779-807.   
Hawkins, J. 1983. Word order universals New York: Academic Press.   
Hawkins, J. and Gilligan, G. 1988. “Prefixing and suffixing universals in relation to basic word order”. Lingua 74: 219-259.   
Heidolph, K. , Flämig, W. and Motsch, W. 1981. Grundzüge einer deutschen Grammatik Berlin: Akademie.   
Helbig, G. 1992. Probleme der Valenz- und Kasustheorie Tübingen: Niemeyer.   
Helmantel, M. 2002. Interactions in the Dutch adpositional domain Ph.D.Dissertation Leiden: University of Leiden/ULCL.   
Hinterhölzl, R. 2000. “Licensing movement and stranding in the West Germanic OV-languages”. In The derivation of VO and OV, 293-326 Amsterdam: Benjamins.   
Jacobs, J. 1994. Kontra Valenz Trier: Wissenschaftlicher Verlag.   
Kayne, R. 1994. The antisymmetry of syntax Cambridge, Mass.: MIT.   
Kayne, R. 2000. “Overt versus covert movement”. In Parameters and universals, 223-281 Oxford: Oxford University Press.   
Kayne, R. 2003. Some notes on comparative syntax, with special reference to English and French ms. New York: New York University.   
Koopman, H. 2000. “The spec head configuration”. In The syntax of specifiers and heads: Collected essays of Hilda J. Koopman , London, New York: Routledge.   
Koopman, H. and Szabolcsi, A. 2000. Verbal complexes Cambridge, Mass.: MIT.   
Kornfilt, J. 1996. “On copular clitic forms in Turkish”. ZAS Papers in Linguistics 6: 96-114. rd als spiegelcentrum”. Spektator 3: 601-   
Koster, J. 1999. Empty objects in Dutch ms. Groningen: University of Groningen.   
Koster, J. 2000a. “Pied piping and the word orders of English and Dutch”. In NELS 30: Proceedings of The North East Linguistic Society , 415-426 Amherst, Mass.: GLSA Publications.   
Koster, J. 2000b. Extraposition as parallel construal ms. Groningen: University of Groningen.   
Kratzer, A. 1995. “Stage-level and individual-level predicates”. In The generic book, 125-175 Chicago, London: University of Chicago Press.   
Larson, R. 1988. “On the double object construction”. Linguistic Inquiry 19: 335-391.   
Lenerz, J. 1977. Zur Abfolge nominaler Satzglieder im Deutschen Tübingen: Gunter Narr Verlag.   
Maienborn, C. 1998. The grammar and pragmatics of locative modifiers ms. Berlin: Humboldt University at Berlin.   
Maienborn, C. 2003. A pragmatic explanation of stage-level/individual-level contrast in combination with locatives ms. Berlin: Humboldt University at Berlin.   
May, R. 1988. “Ambiguities of quantification and wh: A reply to Williams”. Linguistic Inquiry 19: 118-135.   
Nilsen, Ø. 2000. The syntax of circumstantial adverbials Oslo: Novus Press.   
Ouhalla, J. 1991. Functional categories and parametric variation London, New York: Routledge.   
Pearson, M. 2000. “Two types of VO languages”. In The derivation of VO and OV, 327-363 Amsterdam: Benjamins.   
Pollock, J. 1988. “Verb movement, universal grammar and the structure of IP”. Linguistic Inquiry 20: 365-424.   
Rizzi, L. 1997. “The fine structure of the left-periphery”. In Elements of grammar: A handbook of generative syntax , 281-337 Dordrecht: Kluwer.   
Rizzi, L. 2002. “Locality and left periphery”. In Structures and beyond. The cartography of syntactic structures, vol. 3, Oxford: Oxford University Press.   
Russell, K. 1997. “Optimality theory and morphology”. In Optimality theory: An overview, 102-133 Oxford: Blackwell.   
Shaer, B. 2003. “‘Manner’ adverbs and the association theory”. In Modifying adjuncts, 211-259 Berlin: Mouton de Gruyter.   
Speas, M. 1991. “Functional heads and inflectional morphemes”. Linguistic Review 8: 389-417.   
Sportiche, D. 1996. “Clitic constructions”. In Phrase structure and the lexicon, 213-276 Dordrecht: Kluwer.   
Sportiche, D. 2001. Reconstruction, binding and scope ms. Cambridge, Mass.: MIT.

Abbney, S. 144   
Anderson, J. 13, 98   
Baker, M. 38, 172   
Barbiers, S. 35, 166, 241, 242, 245,   
263, 269   
Belletti, A. 22   
Bisang, W. 220, 227   
Bittner, M. 144   
Bruening, B. 82   
Cardinaletti, A. 77   
Chierchia, G. 11   
Chomsky, N. 5, 16, 25, 27, 44–45,   
133, 156, 158, 159, 164, 165,   
168, 171, 284   
Cinque, G. 2, 5, 39–44, 57, 59, 98,   
119, 122, 144, 145, 156, 171,   
177, 255–70   
Cook, V. 59   
Damonte, F. 172   
Davidson, D. 84   
Dowty, D. 12, 13   
Emonds, J. 19   
Fillmore, C. 11, 14, 16   
Frey, W. 64, 89–93, 93–95   
Gilligan, G. 173, 174   
Giusti, G. 77   
Greenberg, J. 173, 298, 299   
Haegeman, L. 23, 24, 31, 33, 58   
Haider, H. 163, 252–53   
Hale, K. 144   
Haspelmath, M. 220   
Hawkins, J. 173, 174   
Heidolph, K. 54, 86–88   
Helbig, G. 9   
Helmantel, M. 155   
Higginbotham, J. 83   
Hinterhölzl, R. 88, 93   
Jacobs, J. 9   
Kayne, R. 2, 5, 18, 27, 29, 41, 43,   
133, 135, 140, 144, 146, 148,   
151, 166, 169, 171, 208, 222,   
260, 269, 271, 277, 278   
Koopman, H. 30, 31, 144, 166,   
170, 189, 244, 260   
Kornfilt, J. 215, 216   
Koster, J. 241, 253–55, 269   
Kratzer, A. 11   
Larson, R. 32, 62, 64, 260   
Lenerz, J. 77, 79   
Maienborn, C. 11, 94   
May, R. 82   
Newson, M. 59   
Nilsen, Ø. 56, 240, 255   
Ouhalla, J. 200   
Pearson, M. 43   
Pesetsky, D. 59   
Pittner, K. 64, 89–93   
Pollock, J. 19, 22, 42, 144   
Rizzi, L. 31, 144, 164, 176   
Russell, K. 236   
Speas, M. 171, 200, 201, 202   
Sportiche, D. 31, 59, 189   
Starke, M. 222   
Szabolsci, A. 170, 244   
Tesnière, L. 8

# LANGUAGE INDEX

Arabic 200, 237   
Bemba 172   
Berber 200   
Chichewa 146   
Chinese 24, 25, 40   
Dutch 31, 66, 155, 241–42, 254,   
259, 269   
French 19, 40, 43, 170   
Hebrew 40   
Hindi 171   
Hungarian 244–45   
Italian 1   
Italian 32, 39, 42, 98, 99, 145, 221   
Japanese 202   
Malagasy 43   
Navajo 40, 200, 201, 215, 218   
Norwegian 40, 56, 57, 240   
Polish 23, 25, 33   
Quechua 38, 172   
Russian 99, 216   
Spanish 42, 118   
Swahili 227   
Tagalog 236   
Turkish 215   
Tzotzil 43   
Zapotec 43

# SUBJECT INDEX

adjunct 12   
adjunction 1, 17, 29, 41, 45, 50,   
134   
adverb 5, 39, 122   
affix hopping 22   
affix lowering 22, 25   
affix phrase (AffP) 189   
AFFP 189   
agglutinating affix 40   
agree 44, 159, 168   
agreement 174, 221   
agreement marker 171   
agreement phrase (AgrP) 20, 22   
A-movement 32, 159   
anaphor 58, 60   
antisymmetric 95   
antisymmetric C-command 142   
antisymmetry 5, 18, 27–32, 41, 43,   
51, 133, 135, 140, 168   
applicative 38, 172   
argument 5, 6, 8, 15, 84, 145   
argument structur 32–35   
aspect 174   
asymmetrical C-command 27   
autosegmental phonology 237   
auxiliary 5   
axiom of word boundary 2, 189,   
217, 238, 298   
barrier 164   
basic projection 138, 137–40   
basis branching constraint 252   
Benefactive 11, 57, 63, 65, 69, 94,   
96   
Bereichsadverbiale 90, 93, 94   
binary branching 16, 28   
binary tree 133   
binding theory 58–62   
case phrase (KP) 144   
case projection (KP) 260   
categorial grammar 13   
category 29   
causative 32, 38, 172, 174   
C-command 27, 28   
C-command constraint on   
movement 163   
celerative adverb 98   
checking 168   
checking analysis 201   
Cinque, G. hierarchy 39–44, 119,   
122, 199, 245   
circumfix 190, 192   
clitic criterion 31   
Comitative 80, 81, 89, 91, 94, 98,   
99   
complement 12, 16, 140   
complementizer 5   
complementizer phrase (CP) 18,   
143, 144   
Comp-merging 158   
connected subtree 137   
contrastive topic 47   
coordination 51   
copy theory of movement 169   
covert movement 23–25   
cyclicity constraint on movement   
163   
database 104   
Davidson, D.ian 84   
dependency grammar 8   
derivation 156–58   
determiner 5   
did so-test 10   
Directional Prepositional Object   
(DPO) 123   
distributed morphology 222   
ditransitive verb 32, 37   
Diversität 220   
dominance 141   
double object constructions 78   
Doubly Filled Comp Filter 31, 189   
DP-hypothesis 144   
D-structure 24, 25, 26, 59   
dual analysis 13   
Duration 115   
Duration Temporal1 116, 131   
Duration Temporal2 116, 120, 131   
Duration Temporal3 116, 131   
Durative 10, 122   
empty category principle (ECP)   
162   
engere Prädikatsgruppe 55, 87   
Epistemic 80, 90, 94   
EPP parameter 168   
equivalence class 149   
equivalence relation 150   
ereignisbezogene Adverbiale 89,   
93, 94   
ereignisinterne Adverbiale 90, 93,   
94   
evaluation 69, 79, 95, 103   
evaluative 94   
event 64, 75, 84, 145, 309–23   
event internal modifier 90, 93, 94   
event related modifiers 89, 93, 94   
Evidential 90, 94, 99, 110, 122,   
130   
existential quantifier 67, 91   
extended projection 123, 148, 151,   
152, 143–55, 155, 199, 273, 278,   
298, 309   
extended projection principle (EPP)   
44   
extension condition 284   
external argument 5   
feature checking 165   
feature movement 160   
focus 15, 18, 47, 54, 73, 78, 88,   
103   
focus neutral order 73–77   
focus neutral order test 88, 89   
frame modifier 90, 93, 94   
Frameadverbiale 90, 93, 94   
frequentative adverb 98   
functional element 5, 7, 16   
fused morphemes 220–25   
Future Temporal 119   
generalised subtree 137   
goal 44, 168   
Goal 87, 99, 105, 120, 130, 131   
governing category 58   
Government and Binding 58   
head 16   
head adjunction 17, 27, 28   
head movement 134, 159, 171,   
175, 176   
head movement constraint (HMC)   
22, 135, 159, 176, 270   
head parameter 17, 134, 168   
hierarchy of thematic roles 132   
hypothesis of equivalence 156   
hypothesis of linkage 156   
island constraint on movement 164   
immediate dominance 141   
inclusiveness principle 133   
indefinite pronoun 64–66, 89   
individual level predicate 11   
infinitival complex test 54–56, 86   
infix 236   
inflection phrase (IP) 18, 20, 22,   
143   
informational focus 47, 89   
informational focus test 77–79, 92,   
95, 102, 103, 106, 108, 112, 126   
informational structure 1, 77   
injective 137   
Instrumental 61, 65, 80, 81, 87, 89,   
91, 94, 98, 100, 106, 107   
internal argument 5, 16   
island constraint on movement 163   
Kumulation 220   
landing position LPrepP 274   
late merge 45   
left branch 142   
Lex1 222   
Lex2 222   
lexical element 7   
lexical morphology 217   
lexical selection restriction 134   
lexicon 222, 237   
licensing 166   
light verb 32   
linear correspondence axiom   
(LCA) 28, 144, 157, 162   
linear order 95, 104, 108, 120   
Link 136   
Locative 1, 11, 51, 61, 62, 63, 65,   
75, 79, 81, 87, 89, 94, 97, 99,   
101, 131   
Locative Prepositional Objects   
(LPO) 123   
logical form (LF) 23–25, 133   
long head movement analysis 201   
look ahead 167, 271   
LOP 229   
lowering analysis 201   
LSP 229   
main projection line (MPL) 143   
Malefactive 100, 106   
Manner 80, 87, 94, 98, 110   
Matter 11, 99, 105, 106   
Means of Transportation 80, 87,   
98, 100, 105, 106, 107   
mental-attitude modifier 94   
merge 25, 133, 156, 158, 160   
minimalist program 5, 25–27, 44–   
45, 133, 165, 167   
mirror effect 241, 254   
mirror order 253   
mirror principle 38–39   
Mittelfeld 54   
Modalisation 9   
modified LCA 30, 189, 260   
modified lexical items (MLI) 160   
modifier 8, 17, 39   
mood 174   
morphology 22, 27, 39, 269, 273,   
298–99   
move 25, 133, 159, 160, 161   
Nachfeld 15, 50, 54, 242   
nAverage 110   
negation 172, 174   
negation phrase (NegP) 20   
negative polarity item 66   
$\mathfrak { n } _ { \mathbb { F } } \ 1 0 9$   
non-concatenative morphology   
236   
nQS 109   
nQsmax 109   
numeration 25, 27, 133   
obligatoriness 9   
OCC 44   
OV 1, 17, 43, 47, 57, 168, 173,   
239, 252, 253, 299   
pair list reading (PLR) 82–83   
pair list reading test 95, 102, 103,   
106, 125   
parameter 168–71   
passive 38   
Past Temporal 118   
Path 100, 105, 107, 130   
percolation 269   
perfectivity test 10   
person marking affix 174   
phase 164   
phonetic feature 26   
phonological form (PF) 24, 133   
phrase 140   
pied piping 57, 170, 254, 255–70,   
273   
pied-piping parameter 169   
PLACE 310   
possessive 174   
postposition 298   
Praedikatsgruppe 87   
predicate 5, 6, 16, 84, 87, 145   
predicate phrase 177   
predicate-argument relation 37, 38   
prefix 40, 173–77, 237, 298   
PrefP 176, 190   
PREFP 176   
PREPP 285   
presente 221   
principle A 58, 59   
principle B 58   
principle C 58, 60   
principle C-violation 89   
principle of full interpretation 165   
principle of semantic interpretation   
(PSI) 36, 166   
probe 44, 168   
process related modifiers 89, 93,   
94   
procrastinate 25   
projective grammar 252–53   
pronoun 58   
proposition phrase (PropP) 291   
prozessbezogene Adverbiale 89,   
93, 94   
qualification relation 36   
qualifier 36   
quantifier pronoun binding 62–63   
quantifier scope (QS) 89   
quantifier scope test 66–73, 75, 91,   
95, 101, 103, 104, 108, 111, 125   
Reason 58, 69, 75, 86, 94, 97   
Reason Prepositional Object (RPO)   
124   
reciprocal 60, 172   
recursion 16   
reference to events 83–86, 131   
reflexive 60, 136   
Rel 136   
relation NULL 136   
relation R 136   
relativized minimality 164, 176   
remnant movement 57, 161, 177   
restructuring verb 43   
R-expression 58   
right branch 142   
role disambiguation 80–82   
root node A 136   
Satzadverbiale 90, 93, 94   
scope ambiguity 66   
segment 29   
semantic feature 26, 80   
semantic interpretation test 63–64   
sentential modifier 90, 93, 94   
separable prefixes 190–200   
skeletal tier 237   
Source 87, 100, 130, 131   
Source Temporal 116   
Source Temporal1 118   
Source Temporal2 118   
Source Temporal3 118   
specifier 16, 134, 140   
specifier head configuration 27   
Spec-merging 158   
spell out 27   
split CP 31   
Split Infl Hypothesis 19–22, 42   
S-structure 24, 26, 59   
straight left branch 142   
straight right branch 142   
stratum 216   
strong feature 168   
subcategorized adjunct 13   
suffix 40, 173–77, 237   
SuffP 175, 190   
syntactic feature 27   
Temporal 1, 11, 51, 57, 58, 61, 62,   
63, 65, 68, 81, 86, 90, 94, 96,   
101, 122   
tense 174   
tense phrase (TP) 22, 144   
T-model 24   
topic 15, 47, 54, 77, 88, 90, 103,   
272   
total order 95   
TP tense phrase 20   
transitive 95   
transitivity 68   
tree 136   
tree structure 5, 16, 134, 135   
und zwar –modification 10   
uninterpretable feature 27, 165,   
168   
universal quantifier 67, 82, 91   
valence 174   
valency changing morpheme 172   
verb bracket 15, 53   
verb movement 171   
verb second 15, 47, 53, 56, 167,   
270–71   
verb valency 8   
verbal complex 244–47   
VO 1, 17, 43, 47, 49, 57, 168, 173,   
239, 240, 252, 253, 299   
voice 174   
volitional 80   
Vorfeld 15, 54   
VP shell 32–35   
VP-topicalisation 89, 91   
VP-topicalisation test 56–58   
V-raising 44   
weak cross over 64   
weak feature 168   
wh - pronouns used as indefinites   
64–66   
wh-element 18   
wh-movement 23   
wh-operator 82   
word boundary 189   
X’’ 139   
X-Bar structure 5, 16–19, 27, 35,   
134   
X-Bar theory 5   
XP 139   
XP movement 160, 171   
XP-adjunction 18

In the series Linguistik Aktuell/Linguistics Today the following titles have been published thus far or are scheduled for publication:

87 JULIEN, Marit: Nominal Phrases from a Scandinavian Perspective. Expected October 2005   
86 COSTA, João and Maria Cristina FIGUEIREDO SILVA (eds.): Studies on Agreement. Expected December 2005   
85 MIKKELSEN, Line: Copular Clauses. Specification, predication and equation. viii, 212 pp. Expected September 2005   
84 PAFEL, Jürgen: Quantifier Scope in German. ca. 354 pp. Expected December 2005   
83 SCHWEIKERT, Walter: The Order of Prepositional Phrases in the Structure of the Clause. 2005. xii, 338 pp.   
82 QUINN, Heidi: The Distribution of Pronoun Case Forms in English. 2005. xii, 409 pp.   
81 FUSS, Eric: The Rise of Agreement. A formal approach to the syntax and grammaticalization of verbal inflection. xii, 323 pp. $^ +$ index. Expected October 2005   
80 BURKHARDT, Petra: The Syntax–Discourse Interface. Representing and interpreting dependency. viii, 256 pp. $^ +$ index. Expected October 2005   
79 SCHMID, Tanja: Infinitival Syntax. Infinitivus Pro Participio as a repair strategy. 2005. xiv, 251 pp.   
78 DIKKEN, Marcel den and Christina M. TORTORA (eds.): The Function of Function Words and Functional Categories. viii, 285 pp. $^ +$ index. Expected August 2005   
77 ÖZTÜRK, Balkız: Case, Referentiality and Phrase Structure. 2005. x, 268 pp.   
76 STAVROU, Melita and Arhonto TERZI (eds.): Advances in Greek Generative Syntax. In honor of Dimitra Theophanopoulou-Kontou. 2005. viii, 366 pp.   
75 DI SCIULLO, Anna Maria (ed.): UG and External Systems. Language, brain and computation. 2005. xviii, 398 pp.   
74 HEGGIE, Lorie and Francisco ORDÓÑEZ (eds.): Clitic and Affix Combinations. Theoretical perspectives. 2005. viii, 390 pp.   
73 CARNIE, Andrew, Heidi HARLEY and Sheila Ann DOOLEY (eds.): Verb First. On the syntax of verb-initial languages. 2005. xiv, 434 pp.   
72 FUSS, Eric and Carola TRIPS (eds.): Diachronic Clues to Synchronic Grammar. 2004. viii, 228 pp.   
71 GELDEREN, Elly van: Grammaticalization as Economy. 2004. xvi, 320 pp.   
70 AUSTIN, Jennifer R., Stefan ENGELBERG and Gisa RAUH (eds.): Adverbials. The interplay between meaning, context, and syntactic structure. 2004. x, 346 pp.   
69 KISS, Katalin É. and Henk van RIEMSDIJK (eds.): Verb Clusters. A study of Hungarian, German and Dutch. 2004. vi, 514 pp.   
68 BREUL, Carsten: Focus Structure in Generative Grammar. An integrated syntactic, semantic and intonational approach. 2004. x, 432 pp.   
67 MIŠESKA TOMIĆ, Olga (ed.): Balkan Syntax and Semantics. 2004. xvi, 499 pp.   
66 GROHMANN, Kleanthes K.: Prolific Domains. On the Anti-Locality of movement dependencies. 2003. xvi, 372 pp.   
65 MANNINEN, Satu Helena: Small Phrase Layers. A study of Finnish Manner Adverbials. 2003. xii, 275 pp.   
64 BOECKX, Cedric and Kleanthes K. GROHMANN (eds.): Multiple Wh-Fronting. 2003. x, 292 pp.   
63 BOECKX, Cedric: Islands and Chains. Resumption as stranding. 2003. xii, 224 pp.   
62 CARNIE, Andrew, Heidi HARLEY and MaryAnn WILLIE (eds.): Formal Approaches to Function in Grammar. In honor of Eloise Jelinek. 2003. xii, 378 pp.   
61 SCHWABE, Kerstin and Susanne WINKLER (eds.): The Interfaces. Deriving and interpreting omitted structures. 2003. vi, 403 pp.   
60 TRIPS, Carola: From OV to VO in Early Middle English. 2002. xiv, 359 pp.   
59 DEHÉ, Nicole: Particle Verbs in English. Syntax, information structure and intonation. 2002. xii, 305 pp.   
$5 8$ DI SCIULLO, Anna Maria (ed.): Asymmetry in Grammar. Volume 2: Morphology, phonology, acquisition. 2003. vi, 309 pp.   
57 DI SCIULLO, Anna Maria (ed.): Asymmetry in Grammar. Volume 1: Syntax and semantics. 2003. vi, 405 pp.   
56 COENE, Martine and Yves D’HULST (eds.): From NP to DP. Volume 2: The expression of possession in noun phrases. 2003. x, 295 pp.   
55 COENE, Martine and Yves D’HULST (eds.): From NP to DP. Volume 1: The syntax and semantics of noun phrases. 2003. vi, 362 pp.   
54 BAPTISTA, Marlyse: The Syntax of Cape Verdean Creole. The Sotavento varieties. 2003. xxii, 294 pp. (incl. CD-rom).   
53 ZWART, C. Jan-Wouter and Werner ABRAHAM (eds.): Studies in Comparative Germanic Syntax. Proceedings from the 15th Workshop on Comparative Germanic Syntax (Groningen, May 26–27, 2000). 2002. xiv, 407 pp.   
52 SIMON, Horst J. and Heike WIESE (eds.): Pronouns – Grammar and Representation. 2002. xii, 294 pp.   
51 GERLACH, Birgit: Clitics between Syntax and Lexicon. 2002. xii, 282 pp.   
50 STEINBACH, Markus: Middle Voice. A comparative study in the syntax-semantics interface of German. 2002. xii, 340 pp.   
49 ALEXIADOU, Artemis (ed.): Theoretical Approaches to Universals. 2002. viii, 319 pp.   
48 ALEXIADOU, Artemis, Elena ANAGNOSTOPOULOU, Sjef BARBIERS and Hans-Martin GÄRTNER (eds.): Dimensions of Movement. From features to remnants. 2002. vi, 345 pp.   
47 BARBIERS, Sjef, Frits BEUKEMA and Wim van der WURFF (eds.): Modality and its Interaction with the Verbal System. 2002. x, 290 pp.   
46 PANAGIOTIDIS, Phoevos: Pronouns, Clitics and Empty Nouns. ‘Pronominality’ and licensing in syntax. 2002. x, 214 pp.   
45 ABRAHAM, Werner and C. Jan-Wouter ZWART (eds.): Issues in Formal German(ic) Typology. 2002. xviii, 336 pp.   
44 TAYLAN, Eser Erguvanlı (ed.): The Verb in Turkish. 2002. xviii, 267 pp.   
43 FEATHERSTON, Sam: Empty Categories in Sentence Processing. 2001. xvi, 279 pp.   
42 ALEXIADOU, Artemis: Functional Structure in Nominals. Nominalization and ergativity. 2001. x, 233 pp.   
41 ZELLER, Jochen: Particle Verbs and Local Domains. 2001. xii, 325 pp.   
40 HOEKSEMA, Jack, Hotze RULLMANN, Víctor SÁNCHEZ-VALENCIA and Ton van der WOUDEN (eds.): Perspectives on Negation and Polarity Items. 2001. xii, 368 pp.   
39 GELDEREN, Elly van: A History of English Reflexive Pronouns. Person, Self, and Interpretability. 2000. xiv, 279 pp.   
38 MEINUNGER, Andre: Syntactic Aspects of Topic and Comment. 2000. xii, 247 pp.   
37 LUTZ, Uli, Gereon MÜLLER and Arnim von STECHOW (eds.): Wh-Scope Marking. 2000. vi, 483 pp.   
36 GERLACH, Birgit and Janet GRIJZENHOUT (eds.): Clitics in Phonology, Morphology and Syntax. 2001. xii, 441 pp.   
35 HRÓARSDÓTTIR, Thorbjörg: Word Order Change in Icelandic. From OV to VO. 2001. xiv, 385 pp.   
34 REULAND, Eric (ed.): Arguments and Case. Explaining Burzio’s Generalization. 2000. xii, 255 pp.   
33 PUSKÁS, Genoveva: Word Order in Hungarian. The syntax of Ā-positions. 2000. xvi, 398 pp.   
32 ALEXIADOU, Artemis, Paul LAW, Andre MEINUNGER and Chris WILDER (eds.): The Syntax of Relative Clauses. 2000. vi, 397 pp.   
31 SVENONIUS, Peter (ed.): The Derivation of VO and OV. 2000. vi, 372 pp.   
30 BEUKEMA, Frits and Marcel den DIKKEN (eds.): Clitic Phenomena in European Languages. 2000. x, 324 pp.   
29 MIYAMOTO, Tadao: The Light Verb Construction in Japanese. The role of the verbal noun. 2000. xiv, 232 pp.   
28 HERMANS, Ben and Marc van OOSTENDORP (eds.): The Derivational Residue in Phonological Optimality Theory. 2000. viii, 322 pp.

A complete list of titles in this series can be found on the publishers website, www.benjamins.com