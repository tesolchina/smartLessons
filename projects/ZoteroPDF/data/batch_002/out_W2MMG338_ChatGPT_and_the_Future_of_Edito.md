# ChatGPT and the Future of Editorial Writing

Marie Alina Yeo $\textcircled{1}$ SEAMEO RELC, TRAC, Singapore

As I came to writing this editorial, I was struck by two existential questions: “What is the purpose of a journal editorial?” and “What is my purpose in writing this editorial?”. During the days of print issues, editorials served to introduce, highlight, summarize and even challenge the content within a specific issue, often through the lens and in the voice of the editor. However, in the age of online journal publication when articles are published online as soon as they have completed the post-production process, what purpose does an editorial serve? Does anyone even read the editorial?

Two articles about the role of journal editors and editorials have urged me to reconsider my view about how I approach writing an editorial. Giannoni’s (2008) assertion about the popularizing and gatekeeping functions of editorials coupled with Plakhotnik’s (2023) view of editorials as a leadership practice suggest that editors should approach this task responsibly, thoughtfully and creatively. In her survey of 120 editorials in 103 journals by 21 publishers, Plakhotnik (2023) found vast inconsistency in the content of editorials, ranging from introductory articles to topical discussions to presentation of original research. She also noted that that editorials mainly served to validate knowledge, with few editorials used to “predict, create, propose or hypothesize something new” (7). Particularly poignant was her criticism about the inconsistency between the journal editors’ intentions of seeking “cutting-edge and thought-provoking” submissions while themselves continuing to write editorials in the form of “traditional essays that explain, clarify, and describe” (7).

The editorial for the April 2024 issue of the RELC Journal hopes to address this contradiction by looking at the technological zeitgeist of generative artificial intelligence (GenAI) in juxtaposition with academic research and publication in the field of language teaching and teacher education. Allow me now to describe and evaluate how I used GenAI to help me write this editorial.

# How I Used ChatGPT to Help Me Write this Editorial

The release of ChatGPT in November 2022 has evoked ongoing public awareness and interest in the widespread use of artificial intelligence (AI), particularly GenAI, in our lives. While the education field was initially, and rightly so, cautious about the use of tools such as ChatGPT, Bing and Bard (now Gemini), there seems to be wider (though sometimes grudging) acceptance that the use of GenAI in education, as in other fields, is here to stay.

Echoing the sentiments of my co-editor, Joel Meniado, who encapsulated current sentiments about GenAI with the words “From Wow! To How?”, the current concern of most educators is how GenAI tools can be used to encourage, stimulate, enhance and maximize learning rather than replace it.

Whether systematically, as in the case of ministries of education, or individually, as teachers and learners, many were quick to experiment with GenAI. Statistics from OpenAI revealed that within two months of its public release, there were more than 100 million monthly active users (Hu, 2023). In Singapore, as early as February 2023, the Ministry of Education urged teachers and students to learn to use GenAI tools “to enhance learning, given that these tools are likely to become pervasive over time” (Abdullah, 2023: para. 1). International organizations such as the United Nations Educational, Scientific and Cultural Organization (UNESCO, 2023) and many of the world’s top ranked universities (Moorhouse et al., 2023) also began to issue papers and guidelines on how to promote ethical use and deter mis-use of GenAI. The UNESCO guide, for example, listed ways to apply ChatGPT in teaching and learning, research, administration and community engagement, while many higher education institutions issued guidelines about academic integrity, how to redesign assessments and communicate with students (Moorhouse et al., 2023).

The above-mentioned UNESCO guide describes possible uses of ChatGPT in the research process for coding data and suggesting themes or topic for analysis. Early research on using AI for qualitative data analysis suggests that such tools hold potential for qualitative analysis, especially at the level of identifying descriptive themes, but are less effective for deriving subtle and speculative patterns in data (Morgan, 2023). In the spirit of experimentation, I decided to put ChatGPT to the test to identify themes from the 32 manuscripts in this issue comprising nine research articles, 13 book reviews, three Innovations in Practice reports, three Technology Reviews, two Thematic Reviews, one Viewpoint article and one Conversation with Experts interview based on the titles and abstracts. Truth be told, I was bracing myself for the time and intellectual energy it would take to examine the abstracts to try to categorize them into themes and then synthesize and summarize the abstracts under each thematic category, so, like a thirsty traveller drawn to the mirage of an oasis, I was enticed by the benefits of using ChatGPT for qualitative data analysis noted by Morgan (2023), namely, the simplicity of the process and potential time savings.

In my ChatGPT 4 window, I typed in the prompt:

I need to write an editorial for an issue of the RELC Journal of about 800–1000 words. Based on all 32 of the titles and abstracts below, suggest 5 themes and list the titles and authors according to the themes.

In its first response, ChatGPT 4 successfully listed five themes, but only categorized 16 of the 32 titles/abstracts under these themes. Almost in an attempt to excuse itself (and here I fear anthropomorphizing ChatGPT!), it added, “The remaining manuscripts, including book reviews and innovations in practice reports, can be aligned with these themes based on their content focus, such as reviews on pedagogical strategies, technology use, language acquisition theories, or teacher development”. This thematic structure ensures a coherent and comprehensive exploration of current trends and research in language education. (OpenAI ChatGPT, 2024).

Patiently, I added “Please help to align the remaining manuscripts with the above themes according to the titles”. Not to disappoint me, ChatGPT then categorized the remaining 16 manuscripts under the five themes it had earlier identified, but not alongside the previous titles and authors. This necessitated a third prompt: “Now let’s combine the first list with the second list so that all 32 titles are listed under 5 themes according to the title and/or abstract”. Following this, ChatGPT added 12 more titles to the five themes but four titles remained unaccounted for. A further prompt was needed from me: “These add up to 28, but there are 32 titles. Please add the 4 remaining titles and authors to the existing 5 themes”. Finally, ChatGPT gave me the desired results, which can be found in the Appendix in their unadulterated form, complete with errors in the capitalization and repetition of some authors’ names.

In brief, ChatGPT suggested these five themes in the following order: feedback and assessment in language learning; engaging and motivating learners; teacher development and beliefs; technology in language education; and innovative practices and theoretical insights.

# Feedback and Assessment in Language Learning

Under this theme, ChatGPT listed five articles that looked at the role of feedback in writing (Zabihi and Erfanitabar; Cao and Mao), validation of a strategy questionnaire (Chou), a book review on second language (L2) reading testing (Lam) and, unexpectedly, an article on shadowing strategies (Hamada and Suzuki).

# Engaging and Motivating Learners

Included under this collection were four titles that covered information gap tasks (Xu and Qiu), brainstorming techniques (Kim et al.), a languaging curriculum (Tangsarittihun and Todd) and a book review on extensive reading (Kohnke).

# Teacher Development and Beliefs

There were seven titles listed under this theme, which included manuscripts with words such as “identity/ies” (Yuan and Liu; Li and Xu; Moodie),“mindsets” (Zarrinabadi and Afsharmehr) “beliefs” (Gao and Cui) and “perspectives” (Garcia and Uysal). For some unexplained reason, Perkins and Zhang’s thematic review of the history of first language (L1) transfer research and recent methodological advances, such as neuroimaging, also appears in this grouping.

# Technology in Language Education

Four of the five titles listed under this theme describe and evaluate the use of technology: ClassIn (Wang and Huang), WordSift (Hu et al.) and Wordwall (Moorhouse and Kohnke)

and Gather.Town (Zhao and McClure). It was confounding that a report on the use of dialogue journals (Pak and Aubrey), albeit interesting and useful but that did not utilize technology in any way, was included in this category.

# Innovative Practices and Theoretical Insights

Under this theme, ChatGPT listed 11 titles, nine of which were book reviews on topics as diverse as learner engagement (Li), content and integrated learning (CLIL; Rakhshandehroo), English as a medium of instruction (EMI; Xie), individual differences (Han), vocabulary (Peng et al.), lack of teaching resources (Kong and Chen), open education (Chen and Zheng), assessment (Huan) and micro-reflection (Karim). The other two were research papers, one on types of student participation (Wei and Cao) and the other on the effect of prior exposure to English on EMI learning (Pun). I wondered why some of these book reviews, for example, Li’s review of the title Engaging Learners in Contemporary Classrooms and Huan’s review of Assessment for Learning in Primary Language Learning and Teaching, had not been placed under their respective categories.

Based on the “experiment” described above, in which I used ChatGPT to identify themes for this editorial, several questions may be asked about the effectiveness and even the ethics of using GenAI. Let us start with the question of effectiveness. For the purpose of deriving themes, I would say that ChatGPT demonstrated very limited capacities in identifying themes from the titles and abstracts provided. What worked well was coming up with the five over-arching themes and labelling them using familiar categories found in teaching English to speakers of other languages (TESOL) journals. However, the order of presentation of the themes seems to lack any logical basis. One way I might have arranged the themes is to go from the “who?” to the “how?” and the “how well?”: “engaging and motivating learners”; “teacher development and beliefs”; “innovative practices and theoretical insights”; “technology in language education”; and “feedback and assessment in language learning”. Although my co-editors (and you as a reader) may have other ways of ordering the themes, it is unlikely any of us would have started with “feedback and assessment in language learning”. More importantly, in looking carefully at the titles under each theme (and with my knowledge of the content of many of the papers), it was clear to me that some of the articles had been incorrectly categorized. For example, under the theme of “feedback and assessment in language learning”, ChatGPT included an article on shadowing techniques. I also wondered why an article on the use of social media had been placed under the theme of “engaging and motivating learners” instead of “technology in language education” and why a thematic review on developments in neuroimaging and cognitive science to investigate L1 to L2 transfer appeared under the theme of “teacher education and beliefs”. Most of all, I could not fathom why nine book reviews were clumped into the final category “innovative practices and theoretical insights” when other book reviews had been assigned under more appropriate themes. I felt as if ChatGPT was behaving like a student who was burning the midnight oil and thought “That’s it – I’ve had enough!” and simply put everything else in the final group of papers! Upon reflection, though, I wonder if the above limitations occurred because I had provided ChatGPT with insufficient information in the form of the title and abstracts? If I had used some of the new AI research assistant tools, such as Elicit (https://elicit.com), which claims on its website to be able to “analyze research papers at superhuman speed” by analysing entire multiple PDFs of articles, would the result have been better? Should I also have prompted ChatGPT to arrange the themes and titles in a specific order? (Here’s a possible topic for an aspiring AI researcher!)

As for the ethics of using GenAI to suggest themes or topics, we need to ask several questions: firstly, did the author publicly disclose which GenAI tool was used, how it was used (including the prompts) and why it was used? Secondly, were the unadulterated prompts and responses presented so that readers could check the verisimilitude of claims and conclusions? Thirdly, do the “Gen-AI data consumers”, that is, those who receive, use and read the AI-generated responses, accept the use of GenAI as part of the research process? In this editorial, I have used ChatGPT 4, included the prompts and unadulterated responses and justified the use of the tool for the purpose of demonstrating and evaluating how GenAI can be used for data analysis. As readers, you can decide if we should reject the use of GenAI in favour of manual coding or challenge the “dominant paradigm for qualitative analysis” (Morgan, 2023: 9) and consider ways to use GenAI tools for selected purposes in the research process, never instead of but alongside humans.

# How I Did Not Choose to Use ChatGPT to Help Me Write this Editorial

After ChatGPT identified the five broad themes, I could easily have asked ChatGPT to summarize and synthesize the content of the titles under each theme, then maybe get it to hypothesize how the use of GenAI like ChatGPT might impact English language teaching in the Southeast Asian region. I felt confident that ChatGPT might be able to accomplish these tasks well enough that I could include the response in this editorial. In some ways, ChatGPT might do an even better job than me as it could without bias “introduce complex content in a way that is acceptable also to less-experienced scholars and peers” (Giannoni, 2008: 213) and “enhance readers’ knowledge and understanding of a phenomenon” (Plakhotnik, 2023: 7), avoiding any unintended “popularizing” effect that a human editor might bring.

# However, What Would be the Point of this?

With the existing AI research assistants, such as Elicit and SciSpace (https://scispace. com/) available, what would be the point of presenting a summary of the articles in this editorial generated by ChatGPT, since readers can easily do this on their own? Instead, I asked myself: What is something I can do in this editorial that ChatGPT cannot? The answer is simple: I can share how I believe GenAI might be used (or used more extensively) in the area of language teaching and teacher education in the Southeast Asian region that resonates with me. As a teacher educator, my focus is on how GenAI can be used in the area of “teacher development and beliefs”.

# Using Artificial Intelligence for Cycles of Lesson Observation and Feedback

Applying “blue-sky thinking”, which is a creative approach to problem-solving unconstrained by current limitations and practicalities, GenAI could be used to review recordings of teachers’ microteaching, practicum or lessons, give feedback and suggest improvements. This could be done with an interactive chatbot styled around an avatar selected by the user (which might promote an emotional bond). In viewing subsequent recordings, the AI observer could pay attention to areas previously highlighted for improvement. To promote feedback literacy (Carless and Boud, 2018) and help teachers to manage their emotions, the chatbot could adjust the feedback language and style accordingly to the recipients’ reactions and emotions (perhaps by monitoring pulse rates or facial expression). Based on these analytics, the chatbot could also ask feelingfocussed questions (Yeo, 2023) to help teachers manage their emotions when receiving feedback.

As for the other themes, I invite scholars and researchers to indulge in some “blue sky thinking” about how you hope GenAI can be used in these areas of language teaching and teacher education.

As I end this editorial, which has focussed on the purpose of editorials, the disruptive potential of GenAI in the research process as demonstrated by my use of ChatGPT to identify themes for this issue, allow me to answer the questions I posed at the beginning: “What is the purpose of a journal editorial?” and “What is my purpose in writing this editorial?”. Plakhotnik’s (2023) vision of editorials as a form of leadership is particularly compelling. With online journal publication, readers rarely pick up an entire journal issue at a time (with the exception perhaps of special issues), so the function of writing editorials to highlight, validate and synthesize the content within the issue has become largely obsolete, since editorials are often read in isolation. Like Plakhotnik (2023), I believe that editorials should be used more purposefully, meaningfully and systematically, and I have attempted to do this by not only introducing the articles thematically but also by questioning the very purpose of editorials and the possible use of GenAI for qualitative data analysis. Finally, in closing, I would also like to bring us back to the human aspect of GenAI, which can be captured in the idea of Education 5.0. How can we re-humanize, re-conceptualize and re-imagine language education within an era of AI and digital transformation without leaving behind those with little access to technology? I hope that future papers in the RELC Journal will take up the challenge of answering this question.

# ORCID iD

Marie Alina Yeo https://orcid.org/0000-0003-0136-2532

# References

Abdullah Z (2023) Students, teachers will learn to properly use tools like ChatGPT: Chan Chun Sing. Available at: https://www.straitstimes.com/singapore/politics/students-teachers-willlearn-to-properly-use-tools-like-chatgpt-chan-chun-sing (accessed 23 February 2024).   
Carless D and Boud D (2018) The development of student feedback literacy: Enabling uptake of feedback. Assessment & Evaluation in Higher Education 43: 1315–1325.   
Giannoni DS (2008) Popularizing features in English journal editorials. English for Specific Purposes, Special Issue in Honor of John Swales 27: 212–232.   
Hu K (2023) ChatGPT sets record for fastest-growing user base – analyst note. February 2, 2023. Reuters. Available at: https://www.reuters.com/technology/chatgpt-sets-record-fastest-growinguser-base-analyst-note-2023-02-01/ (accessed on February 23, 2024)   
Moorhouse BL, Yeo MA and Wan Y (2023) Generative AI tools and assessment: Guidelines of the world’s top-ranking universities. Computers and Education Open 5: 100151.   
Morgan DL (2023) Exploring the use of artificial intelligence for qualitative data analysis: The case of ChatGPT. International Journal of Qualitative Methods 22: 16094069231211248.   
OpenAI (2024) ChatGPT-4 Plus. https://chat.openai.com/chat   
Plakhotnik MS (2023) How do editors use editorials to lead their journals? Insights from the field of human resource management. Learned Publishing. Epub ahead of print 2023. DOI: 10.1002/ leap.1591 (accessed on December 8, 2023)   
UNESCO (2023) ChatGPT and Artificial Intelligence in higher education. Paris: UNESCO.   
Yeo M (2023) Peer review circles: The value of working in triadic groups and oral observational peer feedback in the development of student feedback literacy. Chinese Journal of Applied Linguistics 46: 270–288.

# Appendix: Chat GPT’s listing of themes, titles and authors

Apologies for the oversight. Let’s correctly integrate the remaining 4 titles into the existing 5 themes. Here are the updated themes with all 32 titles included:

# Feedback and Assessment in Language Learning (5 Titles)

1) The revision effects of varying degrees of written corrective feedback explicitness on L2 learners’ writings (Reza Zabihi, Danial Erfanitabar)   
2) Validating the Vocabulary Learning Strategies used by EFL university students in Taiwan (Mu-Hsuan Chou)   
3) Assessing Second Language Reading: Insights from Cloze Tests (Ricky Lam)   
4) Studies on positive evidence feedback in L2 writing: Status quo and implications (Zhenhao Cao, Zhicheng Mao)   
5) Shadowing in the framework of deliberate practice: A guide to using 16 techniques (Yo Hamada, Yuichi Suzuki)

# Engaging and Motivating Learners (4 Titles)

1) Engaging L2 learners in information-gap tasks: How task type and topic familiarity affect learner engagement (Jian Xu, Xuyan Qiu)   
2) Instructional Guidance for Promoting Creativity in EFL Writing Classrooms: A Korean Case Study (Hyun-Ju Kim, Stewart Gray, Christopher Lange)   
3) Book Review: Extensive Reading: The Role of Motivation (Lucas Kohnke)   
4) The Languaging Curriculum in Practice: Communicating Successfully on Social Media (Ronnakrit Rangsarittikun, Richard Watson Todd)

# Teacher Development and Beliefs (7 Titles)

1) Understanding EFL Instructor Identity Changes towards Online Teaching during COVID-19: A Case Study in China (Kaihao Yuan, Shuwen Liu)   
2) Teachers’ Mindsets about Language Learning: Exploring the Influences on Pedagogical Practices (Nourollah Zarrinabadi, Elnaz Afsharmehr)   
3) EFL teachers’ pedagogical beliefs about teacher role and their agentic actions amid and after COVID-19 (Yuan Gao, Yaqiong Cui)   
4) Book Review: Teachers as Professional Learners: Contextualising Identity across Policy and Practice (Xia Li, Jinfen Xu)   
5) Book Review: Transnational Identities and Practices in English Language Teaching: Critical Inquiries from Diverse Practitioners (Ian Moodie Moodie)   
6) The Effect of L1 Transfer on L2 Acquisition and Learning: Contrastive Analysis to Contemporary Neuroimaging (Kyle Perkins, Lawrence Jun Zhang)   
7) Conversation with Experts: A Conversation with Ofelia García: Critical Perspectives on Translanguaging and Adolescent English Learners (Ofelia García and Huseyin Uysal)

# Technology in Language Education (5 Titles)

1) Internet-mediated Joint Construction: Engaging L2 learners in synchronous online writing instruction through ClassIn (DI WANG, Yu Huang)   
2) Technology Review: WordSift: Reading Easier by Understanding Key Words (Ke Hu, Ying Deng, Xiaobin Liu)   
3) Technology Review: Creating the Conditions for Vocabulary Learning with Wordwall (Benjamin Luke Moorhouse, Lucas Kohnke)   
4) Technology Review: Gather.Town: A gamification tool to promote engagement and establish online learning communities for language learners (Xin Zhao, Colin Derek Derek McClure)   
5) Strengthening teacher–student rapport through the practice of structured dialogue journaling (Pak Hei Chan, Scott Aubrey)

# Innovative Practices and Theoretical Insights (11 Titles)

1) Willing, silent or forced participation? Insights from English for Academic Purposes classrooms (Wei Wei, Katherine Cao)   
2) Effects of prior English exposure on Hong Kong tertiary science students’ experiences in EMI learning (Jack K.H. Pun)   
3) Book review: Engaging Language Learners in Contemporary Classrooms (Zhiyong Li)   
4) Book Review: International perspectives on CLIL (Mahboubeh Rakhshandehroo)   
5) English-Medium Instruction and the Internationalization of Universities (Xiaowen (Serina) Xie)   
6) Individual Differences in Language Learning: A Complex Systems Theory Perspective (Turgay HAN)   
7) Review of The Routledge Handbook of Vocabulary Studies. Routledge, London, New York (Yule Peng, Shifa Chen, Lulu Cheng)   
8) Book Review: Research on Teaching and Learning English in Under-resourced Contexts (Delin Kong, Jiaoyue CHEN)   
9) Book Review: Open Education and Second Language Learning and Teaching: The Rise of a New Knowledge Ecology (Xi Chen, Xinmin Zheng)   
10) Book Review: Assessment for Learning in Primary Language Learning and Teaching (Huan Mei)   
11) Book review: Micro-Reflection on Classroom Communication: A FAB Framework (Noorjihan Karim)

This distribution ensures that all 32 titles are accurately categorized under the five overarching themes.