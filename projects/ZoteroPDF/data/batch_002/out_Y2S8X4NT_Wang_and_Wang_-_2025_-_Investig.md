# Investigating L2 writers’ critical AI literacy in AI-assisted writing: An APSE model

Chaoran Wang a,\* , Zhaozhe Wang

a Department of Writing, Colby College, 5290 Mayflower Hill, Waterville, ME 04901, USA   
b Institute for the Study of University Pedagogy, University of Toronto Mississauga, Department of Curriculum, Teaching and Learning, OISE,   
University of Toronto, 3359 Mississauga Road, Mississauga, Ontario L5L 1C6, Canada

# A R T I C L E I N F O

# A B S T R A C T

Keywords:   
Generative AI   
Artificial intelligence   
ChatGPT   
AI literacy   
Critical   
AI-assisted writing   
L2 writing

While the need to foster critical AI literacy (CAIL) among L2 writers has gained increasing recognition, research offering empirically grounded models for integrating CAIL into L2 writing remains limited. To contribute to the ongoing research in AI-assisted L2 writing and CAIL, we designed the current study to understand how students used ChatGPT, a popular generative AI technology, to support their writing and to uncover their CAIL in their writing practices in two first-year writing classes in the US. Adopting a qualitative case study design, we analyzed stu dents’ interview data, written reflections, AI logs, and screencasts of students’ interactions with AI. Findings show that students utilized AI in various ways, including topic selection and brainstorming, outlining, revising, editing, and sourcing. We propose an APSE model based on four dimensions identified in students’ CAIL while using ChatGPT: (1) critical awareness of AI (A), (2) critical positionality (P), (3) critical strategies for interacting with AI (S), and (4) critical evaluation of AI affordances (E). The model highlights the distinct yet overlapping components of CAIL and addresses specific concerns that L2 writers face to leverage generative AI’s linguistic and rhetorical resources critically. Pedagogical implications include explicit instruction on CAIL, developing students’ AI feedback literacy, fostering meta-skills in communication and evaluation, and enhancing their AI-assisted self-directed learning skills.

# 1. Introduction

From the initial hype to varying degrees of resistance and acceptance of generative AI, numerous discussions have emerged in both public and academic communities. L2 writing teachers have been striving to adapt their practice to this technological influence, either willingly or reluctantly (Praphan & Praphan, 2023). Today’s writers have unprecedented access to learning resources based on large language models and advanced technologies, presenting both opportunities and challenges. These changes put at the forefront the need to understand students’ AI-assisted writing practices to inform L2 writing pedagogy. As Pecorari (2023) points out, the question now is not whether but how to use generative AI. Writing teachers bear the responsibility to guide students in critically inquiring into the evolving linguistic, educational, and ethical implications of generative AI.

This responsibility aligns with the critical pedagogical tradition which advocates for empowering students as active participants in their learning and considering the social and ethical dimensions of their literacy practices (Freire, 1970; Giroux, 1997). As underscored by many language and literacy educators, teaching critical AI literacy (CAIL) to foster students’ critical use of generative AI is of paramount importance and urgency (MLA-CCCC, 2023; Kern, 2024). Although various AI literacy frameworks have been proposed (e. g., Cardon et al., 2023; Long & Magerko, 2020; Ng et al., 2021; Warschauer et al., 2023), empirical research examining how students understand and develop critical AI literacy within the context of L2 writing remains in its early stages (Ou et al., 2024). We designed the current study to examine the construct of CAIL based on students’ perspectives of and experiences with generative AI-assisted writing, informing ongoing scholarly discussions and conceptualizations of CAIL frameworks. We begin with reviewing current dis cussions on generative AI-assisted writing and models on AI literacy. Thereafter, we describe the research design and major findings of the study, shedding light on students’ AI-assisted writing practices and their engagement with AI in developing CAIL. Drawing upon the findings, we propose an APSE model that conceptualizes critical AI literacy as comprising four interconnected components: critical AI awareness, critical positionality towards AI, critical strategies for human-AI interaction, and critical evaluation of AI’s affordances within specific rhetorical and linguistic contexts. We conclude with practical strategies and pedagogical possibilities for L2 writing teachers to develop students’ CAIL based on the APSE model.

# 2. Literature review

# 2.1. Generative AI-assisted writing

The discussion around generative AI and writing has been contentious. Scholars argue that generative AI has advantages such as supporting L2 writers’ linguistic development (Yan, 2023), providing personalized and immediate feedback (Barrot, 2023), and relieving students’ cognitive load (Wang, 2024) while offering affective benefits (Wang, Li, et al., 2024). However, they also acknowledge the challenges it poses to L2 students’ learning and writing development, including various ethical and authorship concerns and issues of educational equity (Su et al., 2023).

Among the existing empirical studies on L2 writers’ generative AI-assisted writing, many focus on students’ academic writing at the postsecondary level. Tsai et al. (2024), in their experimental study with 44 undergraduate EFL students, found that ChatGPT-assisted revision significantly improved students’ writing quality in vocabulary, grammar, organization, and content. Similarly, in Yan (2023) study, ChatGPT was found to be helpful in enhancing L2 writers’ grammatical accuracy and lexical diversity. In another mixed-methods study by Woo et al. (2024), EFL students showed increased motivation and satisfaction with using ChatGPT for writing. However, they reported that the students also experienced high cognitive load, contrasting with Wang (2024) findings. This discrepancy may be attributed to Woo et al.’s (2024) use of a think-aloud protocol during students’ writing, as well as factors such as students’ prior experience and familiarity with the AI tool and their digital self-management skills.

In another qualitative study of L1 and L2 students’ generative AI-assisted writing process, Wang (2024) found that the students employed AI in various stages of their writing to address both higher-order (e.g., argument, structure) and lower-order (e.g., syntax, diction, grammar) issues. The study foregrounded two dilemmas faced by students: (1) maintaining one’s own voice while preventing their writing from being “AI-nized,” i.e., the temptation to adopt AI suggestions which may lead to a similar machine-like linguistic and rhetorical style among diverse writers; and (2) balancing missed versus new learning opportunities, as AI could provide shortcuts to linguistic and ideational generation, potentially leading to learning loss – a common critique and concern among scholars (e.g., see Barrot, 2023; Tseng & Warschauer, 2023). Wang (2024) study also revealed that students sought to develop a sense of agency and criticality, indicating that they did not use AI technologies passively but tried to pursue new learning opportunities to enhance their writing. The study complicates the common concerns and oversimplified assumptions of students’ behaviors, highlighting the importance of researching the tacit learning moments that arise from students’ interactions with AI, as well as the nuances and di lemmas students encounter in their decision-making in AI-assisted writing.

Similarly, Warschauer et al. (2023) also identified three contradictions that L2 writers may face when using ChatGPT and other AI technologies: the "imitation" contradiction, the "rich get richer" contradiction, and the "with or without" contradiction. While there are conflicting scholarly opinions and empirical evidence that complement and challenge these contradictions (for example, see Sasaki, 2023), they all underscore the need for L2 writing instruction to consider how to effectively utilize generative AI technologies to empower students. This suggests that L2 writing teachers should provide explicit guidelines and instructions to help students leverage the AI tools without compromising their learning. Additionally, it highlights the necessity for further empirical evidence to validate the current scholarly discussions.

# 2.2. AI Literacy

Scholars argue that the various challenges and contradictions L2 writers face call for the development of writers’ AI literacy, so they can “navigate the unknown future of a technological revolution” (Kubota, 2023, p. 1). Recent studies show that despite students’ frequent use of and easy access to various AI technologies, they have a limited understanding of AI on a deeper level, and they tend to have various misconceptions and myths about AI (Bewersdorff et al., 2023). For instance, students demonstrate a lack of clarity regarding different critical aspects of AI use, including inclusiveness, bias, fairness, data privacy, social inequality, and academic integrity (Bewersdorff et al., 2023; Memarian & Doleck, 2023). Hence, critical AI literacy (CAIL) is of paramount importance in helping students become informed and conscientious users of AI.

AI literacy, as a term, was first coined by Konishi (2015). Based on their review study, Laupichler et al. (2022) report that research on AI literacy is still in its infancy and that the question of how to teach AI literacy still remains unexplored. Similarly, Southworth et al. (2023) argue for the urgency of defining and establishing models of AI literacy. One of the widely cited models of AI literacy is by $\mathrm { N g }$ et al. (2021, 2024), which conceptualizes and categorizes AI literacy into four aspects: namely, (1) know and understand the basic concepts and functionalities of AI, (2) use and apply AI applications in different contexts, (3) evaluate and create AI applications, and (4) be ethical and socially responsible users. $\mathrm { N } g$ et al.’s (2021) AI literacy framework draws upon the foundational elements and hier archical model of Bloom’s taxonomy to outline the progressive skill levels essential for cultivating AI literacy.

Table 1 Instructional Design and Practices Informed by AI Literacy Models $( \mathrm { N } g$ et al., 2021; Warschauer et al., 2023).   

<html><body><table><tr><td>Elements in AI Literacy</td><td>Learning Goals</td><td> In-Class Learning Activities</td><td>Assignments</td></tr><tr><td>Know and understand AI (Ng et al., 2021; Warschauer et al., 2023)</td><td>Introducing the basics of generative AI</td><td>Watching an instructional video on AI basics designed for lay audiences; Reading and discussing Chomsky et al.</td><td>Reading assignment</td></tr><tr><td>Use and apply AI (Ng et al., 2021); Access, navigate, and prompt AI ( Warschauer et al., 2023)</td><td>Practicing using ChatGPT; Exploring ChatGPT&#x27;s</td><td>Discussing Chomsky et al.&#x27;s critiques on AI; Discussing prompting strategies; Practicing using ChatGPT to edit a piece of</td><td>Screen-recording task that involves interaction with ChatGPT and think-aloud reflections;</td></tr><tr><td>Evaluate (Ng et al., 2021); Corroborate AI-generated content (Warschauer et al., 2023)</td><td>affordances and weaknesses; Critiquing ChatGPT- generated texts</td><td>freewriting; Comparing and discussing AI-made changes to reflect on use experiences</td><td>Written reflection assignment</td></tr><tr><td>AI ethics (Ng et al., 2021); Incorporate AI-generated content in ethically and effectively ( Warschauer et al., 2023)</td><td>Discussing academic integrity and ethical issues</td><td>Collaboratively researching and developing AI policies for the course, based on sample AI policies in higher education and academic publishing</td><td>Written reflection assignment + AI log and essay drafts submission</td></tr></table></body></html>

Partially drawing upon $\mathrm { N g }$ et al. (2021, 2024), Tseng and Warschaeur (2023) and Warschauer et al. (2023) proposed a five-component AI literacy framework specifically for L2 writers to navigate the contradictions associated with using AI to enhance their learning. The components include: (1) understand the basics of AI writing tools’ learning affordances and shortcomings including biases; (2) access and navigate AI-writing tools for specific writing purposes and contexts; (3) prompt AI to generate useful information; (4) corroborate AI-generated information to evaluate the accuracy and biases; (5) incorporate AI-generated content in effective and ethical ways. Although Warschauer et al. (2023) pioneered this AI literacy framework for L2 writing, further research is needed for validation.

In accordance with the scholarly conversation, the Modern Language Association-Conference on College Composition and Communication (MLA-CCCC) Joint Task Force on AI and Writing (2023) advocates for fostering critical AI literacy (CAIL) among both students and educators as a priority. They regard CAIL as part of digital literacy, briefly defining it as “literacy about the nature, capacities, and risks of AI tools as well as how they might be used” (p. 7). So far, research remains scarce on conceptualizations of critical AI literacy, specifically in terms of what CAIL encompasses within L2 writing and how students engage with it in their AIassisted writing and language learning practices. We thus design the current study to uncover how students incorporate CAIL in their real-life writing practices and to inform an empirical evidence-based CAIL framework. This, in turn, will provide writing instructors with insights to foster students’ CAIL in their instructional practices. The research questions guiding our inquiry are as follows:

(1) How do L2 students use ChatGPT, a popular generative AI technology, to assist with their writing? (2) How are the L2 student writers’ CAIL (or lack thereof) evidenced in their interactions with ChatGPT and their linguistic and rhetorical decision-making?

# 3. Method

This study is part of a larger research study on critical AI literacy in postsecondary writing classrooms that involve both L1 and L2 writers. For this study, we adopted an exploratory qualitative case study design (Yin, 2018) to understand how L2 students engage with CAIL in their AI-assisted writing. We both identify as multilingual, international teacher-researchers, professionally trained and working at the intersection of writing studies and applied linguistics within the North American context. While we recognize the potential of technologies to empower L2 writers, we remain concerned about a general perception of students’ uncritical reliance on them, as discussed in the existing scholarship (e.g., Barrot, 2023; Cardon et al., 2023; Stojanov et al., 2024). Overall, our multilingual identities and writing experiences inform us to adopt an open attitude towards understanding participants’ diverse decision-making regarding whether and how they chose to use generative AI in their writing. However, we also acknowledge that our professional training and roles as teacher-researchers may have influenced both our analytical lenses and participants’ willingness to disclose certain behaviors or attitudes.

# 3.1. Context of the study

The study was conducted in two sections of the same first-year writing course at a liberal arts college in the Eastern United States in 2023. The writing classes followed the same syllabus and were taught by the first author. There were 27 students, including seventeen L1 and ten L2 students from diverse cultural-linguistic backgrounds, enrolled in the two classes. The writing course had three major units, each coming with one major writing assignment. One of the major assignments invited students to write about a family-related concept of their choice. The goal of the assignment was to encourage students to reflect on and offer fresh insights into cultural concepts, drawing upon their personal experiences and secondary research. The unit covered seven class sessions, each lasting 75 minutes. Topics discussed included strategies for concept explanation, source evaluation, artificial intelligence, finding one’s voice as an academic writer, and peer review.

Table 2 Demographic information of the student participants.   

<html><body><table><tr><td>Pseudonym</td><td>Gender</td><td>L1</td><td>Educational Background</td></tr><tr><td>Hyun</td><td>Male</td><td>Korean</td><td>International high school in Mainland China</td></tr><tr><td>Aye</td><td>Female</td><td>Burmese</td><td>International high school in Hong Kong</td></tr><tr><td>Yun</td><td>Female</td><td>Chinese</td><td>International high school in Canada</td></tr><tr><td>Dawei</td><td>Male</td><td>Chinese</td><td> International high school in Mainland China.</td></tr><tr><td>Shuya</td><td>Female</td><td>Chinese</td><td>Private high school in the US</td></tr><tr><td>Yawa</td><td>Male</td><td>Twi</td><td>Public high school in Ghana</td></tr><tr><td>Dofi</td><td>Female</td><td>Twi</td><td>Public high school in the US.</td></tr><tr><td>Paulo</td><td>Male</td><td> Spanish</td><td>Public high school in the US.</td></tr><tr><td>Felix</td><td>Male</td><td> Spanish</td><td>Public high school in the US</td></tr><tr><td>Nadia</td><td>Female</td><td>Arabic</td><td> Public university in Egypt</td></tr></table></body></html>

Two class sessions were dedicated to discussing generative AI and large language models inspired by the broad ideas presented in previous AI literacy frameworks (e.g., Warchauer et al., 2023), such as introducing the basics of the technology, exploring its affordances, weaknesses, biases, and relevant academic integrity issues, and practicing using ChatGPT and critiquing ChatGPT-generated texts (see Table 1 for a detailed description of our instructional design). The sessions were exploratory in nature, meaning that the students experimented with ChatGPT and formed their understandings through hands-on experiences – an approach aligned with our research design as an exploratory, qualitative case study. To be more specific, in the first class, students discussed Chomsky et al. (2023) opinion piece “Noam Chomsky: The False Promise of ChatGPT” published in The New York Times (Chomsky, Roberts, & Watumull, 2023). Following this, students used ChatGPT to edit a piece of their own freewriting, and then compared and discussed the AI-made changes to reflect on their use experiences. The second session introduced common academic integrity concerns about the use of generative AI in educational settings. Working in collaborative groups, students reviewed various policies on AI usage in higher education and academic publishing, ultimately developing a policy for their own use in this course. Thus, the CAIL examined in this study is grounded in students’ direct engagement with the technology, reflecting their authentic, first-hand experiences as opposed to following prescriptive, teacher-fronted instructional models. ChatGPT (GPT 3.5) was selected because it was one of the most popular generative AI technologies at the time of the study and was free, making it accessible to everyone in the class.

While learning about the generative AI tool, the students also completed a task that involved screen-recording their interactions with ChatGPT while articulating their thoughts, feelings, and perceptions about their use experience. This was designed to help the instructor gauge the students’ thought processes while using the AI tool. For the final assignment, students were encouraged, but not required to incorporate ChatGPT into their writing. The instructor made the decision because she would like to give students the flexibility to choose the approaches that best suit their individual needs and learning styles. This decision also helps mitigate the potential impact of researchers’ positionality on students’ engagement with AI. Those who opted to use ChatGPT were required to submit their AI use logs along with a reflection detailing their specific use of AI, and the decision-making and critical thinking involved in their decision. All ten L2 writers enrolled in the classes reported utilizing ChatGPT to varying extents and were subsequently invited to participate in this study.

# 3.2. Data collection and analysis

Following the college’s IRB protocol, the researchers sent research participation invitations via email after the students had completed the writing courses, ensuring there was no conflict of interest. After participants provided written consents, face-to-face interviews were scheduled and conducted. Table 2 shows the demographic information of the ten students who voluntarily partici pated in this study. Coming from diverse cultural-linguistic and educational backgrounds, the students generally demonstrated advanced English language proficiency, though their experiences with academic English writing varied. Hyun, Aye, Yun, and Dawei, who attended international high schools that adopted the International Baccalaureate (IB) curriculum, had extensive practice in ac ademic English writing in their former education. Shuya, Dofi, Paulo, Yun, and Felix, having completed high school education in the US/Canada, demonstrated integrated proficiency through their immersion in English-speaking environments. Yawa and Nadia had comparatively less practice in academic English writing during their formal instruction in public schools in Ghana and Egypt.

Primary data sources include semi-structured interviews with nine participants, each lasting from 35 minutes to 1 hour. The in terviews were designed to understand students’ AI-assisted writing processes, their perceptions of using ChatGPT for writing, and their experiences of navigating ChatGPT to achieve their particular writing goals. One student chose not to participate in the interview but provided written consent for the research team to use all other types of data. In addition to interviews, the ten participants’ written products and other documents, such as essay drafts, critical reflections on AI usage, AI log data, and screencasts of their AI interaction, were also collected. These written and multimodal data sources showed students’ progress over the project, documenting how they prompted ChatGPT and evaluated and utilized the AI-generated information, as well as the thinking underlying their decisions. Thus, the various data sources not only served triangulation purposes but also helped to create a holistic understanding of students’ CAIL.

Table 3 An example of the coding approach featuring Theme 4 for the second research question.   

<html><body><table><tr><td>Theme #4</td><td>Higher level code</td><td>Lower level code</td><td>Interview data</td><td>Other types of data (i.e., AI logs/ screencasts, written self-reflection, essay drafts)</td></tr><tr><td>Critical evaluations of AI affordances</td><td>Evaluation of information accuracy</td><td>Human</td><td>&quot;You should at least know something about it...like interaction with friends or the professor.&quot; (Dofi, Interview) &quot;I knew that was accurate because I&#x27;m from that place.&quot; (Dofi, Interview) &quot;The reading we did in class, I finally used that as a source.&quot; (Shuya, Interview)</td><td>&quot;The inaccuracy of ChatGPT can be countered by having prior knowledge about the topic...If ChatGPT was inaccurate from the knowledge I carried, I could consider the authenticity of that piece of information.&quot; (Dofi, Reflection) Shuya&#x27;s AI log: &quot;why individuals engage in multiple simultaneous relationships&quot; (Shuya,</td></tr><tr><td rowspan="4"></td><td></td><td></td><td></td><td>AI Log, Dialogue 1 &amp; 2) Shuya&#x27;s final draft citing a course reading: &quot;They [HaiWang] believe that maintaining a committed and long-term relationship is impossible to maintain happiness (Kimmel, 2008).&quot; (Shuya, Final Draft) Shuya&#x27;s comments on ChatGPT&#x27;s edits: &quot;A</td></tr><tr><td>Evaluation of linguistic and rhetorical repertoire</td><td>Language proficiency Perception of</td><td>&quot;I don&#x27;t use ChatGPT because such sophisticated language doesn&#x27;t look like mine... I know what kind of stuff I can write based on my abilities.&quot; (Shuya, Interview) &quot;When it comes to the Western kind of</td><td>dynamic lexicon emerges continually&#x27; - That sounds complicated. And the word nuances.&#x27; I normally wouldn&#x27;t use these words.&quot; (Shuya, AI Screencast) &quot;It facilitates the communication of my ideas</td></tr><tr><td></td><td>good English academic writing</td><td>writing, GPT is really good with that.&quot; (Yawa, Interview)</td><td>to fit with academic writing.&quot; (Yawa, Reflection) Yawa&#x27;s AI log: &quot;create a transition&#x27; between two ideas. (Yawa, AI Log, Dialogue 4)</td></tr><tr><td></td><td>Intended audience</td><td>&quot;My positioning for my audience is they should be at the level of native language speakers.&quot; (Dawei, Interview)</td><td>Dawei&#x27;s AI log: &quot;correct the grammar in the following paragraph&quot; (Dawei, AI Log, Dialogue 1) Dawei&#x27;s final draft which adopted all AI&#x27;s edits</td></tr><tr><td rowspan="2"></td><td>Evaluation of learning context</td><td>Type of learning task</td><td>&quot;I used it to explain concepts I don&#x27;t understand in the source.&quot; (Nadia, Interview)</td><td>(Dawei, Final Draft, p. 5, para. 1) &quot;Summarize this reading as a point&quot; (Yawa, AI Log as in the Reflection)</td></tr><tr><td></td><td>Goal of learning</td><td>&quot;I really think the essence of having the first year writing classes is help us to basically read and write. I feel it&#x27;s an essential part of schooling and learning.&quot; (Dofi, Interview)</td><td>&quot;The reason for using ChatGPT should be centered on learning rather than perfecting the work already done.&quot; (Dofi, Reflection)</td></tr></table></body></html>

The data analysis was a recursive process that started with thematic analysis (Saldana, ˜ 2015) of the interview transcripts. The first author first coded four interview transcripts, and then the two authors went through four rounds of collaborative debriefing to refine the codebook and resolve any disagreements. With the co-developed coding scheme, the first author continued coding the remaining six interview transcripts. Following the coding scheme developed from the primary interview data, the authors then coded and grouped other types of data. Table 3 demonstrates our coding approach, featuring one of the themes developed for the second research question as an example. This coding process helped make connections between students’ perceptions and understandings of CAIL and their writing practices. Comparisons and modifications for synthesizing findings across data were made through a recurring process of close reading, checking, doubting, and re-confirming the analysis between the two co-authors.

# 4. Findings

4.1. How do L2 students use ChatGPT, a popular generative AI technology, to assist with their writing?

The students used ChatGPT in various ways, including topic selection and brainstorming, outlining, revising, editing, translating sources, and using AI-generated texts as sources. Eight out of the ten students used ChatGPT for brainstorming. One reason, as Dofi mentioned, was to manage the “overwhelming amount of information” (Dofi, Interview) on unfamiliar topics. Similarly, Shuya noted that AI could “provide a basic overview of everything” (Shuya, Interview), which helped her to explore possible directions. Paulo mentioned that ChatGPT helped with his usual writer’s block: “It was a good change from the usual staring at a blank wall I do when trying to come up with ideas” (Paulo, Reflection). Other students purposefully chose to use AI for brainstorming even when they were already familiar with a topic. Hyun explained, “I want to explore other perspectives, so I compare the contents between what I had, and what it created. And then I used some of it that seemed to fit my topic.”

Six students also used ChatGPT for outlining, driven by similar reasons and purposes. For instance, Yawa followed his regular writing habit of creating a one-pager with everything he wanted to say, then used ChatGPT to organize these initial ideas into an outline for him to build upon. Similarly, Hyun wanted to save the mental struggle and time needed to connect paragraphs: “I’m good at structures because I spent really a lot of time structuring the essay, like two or three hours…AI can make me spend less time considering how to connect it mutually, like, paragraph to paragraph.” Shuya also believed that she could do the work well, but she opted to use AI for time-saving purposes: “I know myself even without AI, I can still sort it out. I would be like sorting information bit by bit. But ChatGPT gave you result within seconds…It was soooo fast.”

Table 4 Sample prompts participants used for revising and editing suggestions from ChatGPT.   

<html><body><table><tr><td>Prompt types</td><td>Sample</td></tr><tr><td rowspan="4">Generic prompts</td><td>Which part do you think it lacks? Which parts do you think I should improve? (Hyun)</td></tr><tr><td>What suggestions do you have for me to improve ...? (Aye)</td></tr><tr><td>If you were to like grade this, what would be my grade? How would you suggest to make this better? (Yawa)</td></tr><tr><td>Modify this essay. (Shuya)</td></tr><tr><td rowspan="7">Tailored prompts</td><td>Are my arguments clear? (Yawa)</td></tr><tr><td>Create a transition between XX [sentence A] and XX [sentence B] (Yawa)</td></tr><tr><td>Please correct the grammar in the following paragraph. (Dawei)</td></tr><tr><td>Less overdone give me a word that can replace this [Note: This&quot; means less overdone&quot;]. (Yawa)</td></tr><tr><td>Revise the wording only and not the content so as to keep my original ideas. (Yun)</td></tr><tr><td>Change my word choice. (Hyun)</td></tr><tr><td>Reduce this to 400 words. (Felix)</td></tr></table></body></html>

Seven students also reported using ChatGPT for revising and editing. AI log data showed that the students input chunks of text into ChatGPT and prompted the AI to provide feedback. Grammar and vocabulary were two common aspects for which the students sought ChatGPT’s help. Table 4 provides a list of sample prompts students used from their AI logs and screencasts. These include generic prompts that ask ChatGPT for broad feedback without identifying specific areas for improvement, as well as more tailored prompts that ask ChatGPT to target specific aspects of writing such as argument, transition, grammar correctness, diction, and text reduction. Apart from using ChatGPT to directly edit one’s writing, Yawa, for instance, also utilized it like a dictionary or Thesaurus for wording suggestions. As he shared: “I already have a word in my mind, but I’ll ask it…Could you suggest another word that would be more suitable? Would you suggest five words that would be suitable? Then I’ll look through and find which is the best.” Notably, the process of seeking feedback for editing and revision was usually iterative, moving from general to specific or from addressing one specific point to another. For instance, in the screencast of his interaction with ChatGPT, Hyun first prompted the AI to “check my grammar,” and then asked, “Is there any other feedback for my essay in terms of structure or APA in-text citations?”

Five students also used ChatGPT for sourcing, which was reported to be particularly helpful to address topics related to their own cultures. This included translating L1 sources, finding relevant L2 sources, and incorporating L2 sources into their writing. Hyun pointed out that because he was writing about gender roles in South Korean households, the translating function of ChatGPT was more effective than GoogleTranslate, allowing him to use sources more easily and present the latest local information to his global readers (Hyun, Reflection). Shuya, on the other hand, noted another interesting use of ChatGPT for searching English sources in her essay:

I couldn’t find direct sources related to my topic. But after asking ChatGPT, it gave me something relevant in English, which helped me to find ways to use English to explain this very Chinese term. ChatGPT gave me these directions you can take to explain, and based on these directions, you can find sources.

Shuya’s essay topic was Haiwang (海王), an emerging term among young people in China. She was unsure where to begin her research because she was unfamiliar with both the academic language related to the phenomenon and the English equivalent of the term. Thus she framed her understanding of the term into an AI prompt: “people who are ambiguous with many people at the same time but are not committed to a love relationship,” trying to elicit related English concepts from the AI (see Fig. 1). Upon reading ChatGPT’s responses, Shuya located a few key terms like “multi-lover” and “non-monogamous relationship” that aided her later academic search (Shuya, Reflection). In addition to identifying academic registers for research, Shuya acknowledged that this use of ChatGPT allowed her to consider how the cultural meaning of a Chinese word “could be possibly used in the English context” (Shuya, Interview). This illustrates her effort to leverage the capabilities of the large language model to write for cross-cultural audiences.

Another student Dofi directly cited ChatGPT as evidence. Table 5 presents a comparison between her AI log and part of a paragraph in her final draft discussing meal sharing and meal preparation, in which she incorporated AI’s responses into her writing. Notably, she used “research discovered from ChatGPT” to refer to the AI-generated information, treating AI as a secondary research source. This is also evident in her approach to integrating the information, where she summarized and paraphrased the AI text to represent its meaning. Similar to Shuya, Dofi struggled to find sources related to her argument about Ghanaian family practices, so she resorted to ChatGPT. Dofi knew that ChatGPT was not a “good source,” but she used it anyway as she believed it necessary to find external evidence to back her own experience, so as to meet her understanding of the expectations of English academic writing. She explained: I knew that [the ChatGPT-generated information about Ghana] was accurate because I’m from that place, but I just needed a source to back it up. Sometimes you just like to put down your perspective, but you want evidence to back you up…I feel like coming here [the US], I definitely had to learn to write again, learn how to do an essay. (Dofi, Interview)

Other AI-assisted source use also included summarizing articles for integrating sources into writing. For instance, in Yawa’s AI log, he prompted ChatGPT to “summarize this article as a point” (Yawa, AI log) for the convenience of incorporating it into his writing. He explained that this approach allowed him to “retrieve the main ideas without having to read everything,” and that ChatGPT helped summarize scholarly sources into “only the important parts I needed for evidence in my essay” (Yawa, Reflection). Nadia took a different approach, using ChatGPT to help her understand a source by asking it to “provide explanations for a paragraph or the whole reading.” She highlighted the importance of reading the source herself to verify the information, noting that “ChatGPT was not always

# Anonymous

why some young people like to be ambiguous with to many people at same time but not have a love relationship

# 5 ChatGPT

There can be several reasons why some young people may choose to be ambiguous or non-committal in their interactions with multiple individuals without pursuing traditional love relationships:

![](img/3bdbbb8cef86a0f684bac0f3cfd4736de790575bc3221e887ce620fd08d45e23.jpg)  
Fig. 1. A screenshot of Shuya’s AI log.

1. Fear of Commitment: Many young people may have a fear of commitment, which can be associated with concerns about being tied down or losing personal freedom. They might prefer to keep their options open and avoid getting into a serious, committed relationship.   
2.Exploration and Self-Discovery: Young adults often go through a period of self-discovery and exploration. They may want to meet and interact with a variety of people to better understand their own preferences, desires, and what they are looking for in a partner.   
3. Emotional Unavailability: Some young individuals may not be emotionally ready for a committed love relationship. They might have unresolved emotional issues, past traumas, or simply not feel emotionally prepared for the demands of a serious relationship.   
4. Fulfilling Different Needs: Being ambiguous or non-committal can allow individuals to fulfilldifferent needs from different people. They may seek emotional support, physical intimacy, companionship, or intellectual stimulation without putting all these expectations on a single partner.   
5. Pressure to Settle Down: Young people may also face societal or peer pressure to settle down and have a serious relationship. Choosing to remain ambiguous with multiple people can be a way to resist these pressures and maintain independence.   
6. Focus on Personal Growth: Some individuals prioritize personal growth and development over romantic relationships during certain phases of their lives. They may choose to keep things ambiguous with others to focus on their goals and aspirations.   
7. Avoiding Relationship Drama: Young people may have witnessed or experienced relationship drama and conflicts, leading them to avoid entering into committed relationships that could potentially involve such drama.   
8.Casual Dating Culture:In some cultural or social contexts, casual dating without the expectation of a Iove relationship is more common and accepted. This can influence the behavior of young people.

correct but it could give me a better idea” (Nadia, Interview).

This section shows students’ diverse ways of utilizing ChatGPT to assist with their writing and research processes, demonstrating how they leveraged ChatGPT’s affordances to achieve their specific purposes while addressing the challenges they encountered during the writing task.

4.2. How are the L2 student writers’ CAIL (or lack thereof) evidenced in their interactions with ChatGPT and their linguistic and rhetorical decision-making?

Following an inductive thematic analysis, we identified four aspects in which students demonstrated CAIL while utilizing ChatGPT to assist with their writing: (1) having a critical awareness of AI affordances and limitations, (2) maintaining a critical positionality, (3)

Table 5 A comparison between Dofi’s AI log and final draft.   

<html><body><table><tr><td>AI Log</td><td>Anonymous Benefits of meal sharing and meal preparation? ChatGPT Meal sharing and meal preparation offer various benefits within a family or a community: Meal Sharing: 1. Social Bonding:Sharing meals fosters social connections and strengthens relationships within the family or community.. 2.Communication and Connection:It provides a platform for conversation, sharing stories, and exchanging ideas,enhancing communication. 3. Cultural Transmission: Meals are often a platform for passing down traditions, recipes, and cultural values from generation to generation. 4. Emotional Nourishment: It provides emotional support, comfort, and a sense of belonging. Meal Preparation: 1. Collaboration and Togetherness:Working together to prepare meals encourages</td></tr></table></body></html>

Table 6 A comparison of Hyun’s first draft, AI log, and final draft.   

<html><body><table><tr><td>First Draft</td><td>[1] In recent decades, South Korea has undergone a remarkable transformation, not only in it economic and technological landscapes but also in the dynamics of its sct..2] One of the most string and profound changes has ben the shift in traditional gnder roles within South Korean households, particularly the evolving role of men. [3] The family members had no choice but to be dependent on the patriarch the representative of the family, responsible for the family&#x27;s livelihood and the flow of information from society.</td></tr><tr><td>Hyun&#x27;s Prompt ChatGPT&#x27;s response</td><td>Check my grammar. Your essay is well-written, but I can provide some suggestions for improving the grammar and clarity of certain sentences: 1. In the opening paragraph, consider rephrasing to enhance clarity: *In recent decades, South Korea has undergone significant</td></tr><tr><td></td><td>transformations, not only in is economic and technological landscapes but also in the dynamics of it society. One f the most striking changes has been the shift i traditional gender roles within South Korean households, particularl the evolving roles of both genders . 2. In the same paragraph, when discussing the patriarchal structure, it might be clearer to say: Family members had no choice but to be</td></tr><tr><td>Final Draft</td><td>dependent on the patriarch, who was responsible for the family&#x27;s livelihood and the flow of information from society.&quot; [1] In ret deades, South Korea has underone sigficant tranomations, not only i is eonomic and technological landscapes but also in the dynamics of it society. 2] One of the most striking changes has ben the shift intraditional gender roles within South Korean households, particularly the evolving role ofboth gender..[3] Family members had no choice but to be dependent on th patriarch, who</td></tr></table></body></html>

developing and applying critical strategies for interacting with AI, and (4) critically evaluating AI’s affordances. Below we explain each aspect with specific examples from the participants.

Critical AI awareness. Apart from understanding and utilizing ChatGPT’s functionalities as demonstrated in the previous research question, students also exhibited critical awareness of the algorithmic operational logic of generative AI as well as the data upon which these technologies are trained. In particular, they showed criticality towards two issues regarding training data – coded bias and underrepresented languages. For instance, based on his personal experiences interacting with AI and what he had read on social media, Hyun pointed out that ChatGPT is especially biased towards “political things” due to the whiteness of its training data:

There is an island in Korea called Dokdo. We are fighting with Japan about this territory…ChatGPT said it’s a Japanese territory. So it depends on where they get it, what is more common, what is more stereotypical about those things. Also, I saw some article that there is some kind of bias in making on AI, especially for making a human face. Most of the training data are based on White people.

Yawa also acknowledged AI’s inadequacy in providing information related to underrepresented languages and cultures like his first language Twi, given the scarcity of linguistic resources in the training of the large language model. As he shared: “Twi is not a popular language, like French or Chinese. For Twi, it all comes down to the fabrication of information, it would probably give a more generalized, ‘Oh, it might mean this.’”

Another notable aspect of students’ critical AI awareness is their recognition of how generative AI is programmed can result in patterned, inconsistent, and inaccurate responses that limit its effectiveness and reliability as a learning and writing assistance. Yawa, in his reflection, acknowledged that a large language model is essentially “a predictive model,” thus providing information that can be repetitive. Yun noted that the “black-box” nature of ChatGPT algorithms led to inconsistent responses even with the same prompt, and sometimes irrelevant information. Similarly, Hyun observed that generative AI might not follow prompts precisely. He noted: “So I put my entire essay and then said ‘change my grammar.’ Sometimes it’s kind of annoying because it doesn’t just change my grammar, it entirely changes the sentence structure although I said JUST change my grammar” (Hyun, Interview). Aye, when asking ChatGPT how parenting styles in Myanmar impact children’s academic success, observed that “some of the answers were quite repetitive, and others contradicted each other” (Aye, Reflection). Consequently, she believed that ChatGPT lacked sufficient knowledge about her culture and was not reliable.

Critical AI positionality. Discerning generative AI’s powerful affordances for assisting with various aspects of writing and its limitations, the participants developed nuanced positionalities to navigate their relation with AI in multifaceted ways. Firstly, all the students emphasized the necessity of one’s originality and authorial voice when using AI in the writing process, ensuring that the work reflects one’s unique thinking. Hyun pointed out that “AI is all based on data people have already created but cannot provide any new kind of thing” (Hyun, Interview). Shuya and Yawa contrasted the human writer’s need to “invent” with AI’s tendency to produce “clich´e, generalized” texts.

Even though students shared agreement on the importance of originality, they practiced being “original” in different ways. Dofi, for instance, believes that “the writer has to generate your own ideas before seeking the help of AI” (Dofi, Interview). Similarly, Yawa did not use AI for topic selection and brainstorming because he felt it required personal creativity (Yawa, Reflection); thus, he only started to use AI for creating an outline based on his freewriting. Shuya, on the other hand, used ChatGPT to generate a list of ideas for her essay, and from there, she did more research and expanded them. She described using AI to get “some inspiration” and “a rough shape of an idea,” but emphasized that it is the author who must “sketch it out” and create a vivid piece of work that represents their own voice. Shuya used a “key” metaphor to describe her relationship with AI: she treats AI as a “basic key to a door behind which there is a range of possibilities,” but it is the writer who unlocks the door and explores “different paths to destinations by themselves” (Shuya, Interview).

Another student Hyun commented on the challenge of navigating the two sides of using AI, noting that while it can “inspire” ideas, it may also “suppress creativity and critical thinking.” He doubted that “finding information based on AI’s ideas” contradicts the purpose of writing which is to “show your own style, your own experiences, and your own thinking” (Hyun, Interview). On the other hand, he also questioned to what extent using AI-suggested word choices could harm the author’s voice: “AI gives better word choices or something. So this for sure is a better tool, but I’m just afraid that it’s not going to be your essay” (Hyun, Interview). Hyun’s concern highlighted both the qualitative aspect of using AI for ideas and language, as well as the quantitative aspect of how much AI use differentiates between maintaining and losing one’s own authentic voice in human-AI collaboration.

Table 7 A comparison of Shuya’s AI log and her final essay.   

<html><body><table><tr><td>Shuya&#x27;s. AI log</td><td>3. Unfulfilled Needs: Some individuals may feel that they cannot meet all their emotional or physical needs within the confines of a monogamous relationship. Having multiple partners may provide them with the opportunity to fulfill different aspects of their desires. 4. Social and Cultural Factors: Cultural norms and attitudes towards monogamy and non- monogamy can vary significantly around the world. In some cultures or social circles, non- monogamous relationships are more accepted or common. 5. Technology: Online dating apps and social media have made it easier for people to connect with others, potentially leading to more casual or simultaneous dating or relationships. 6. Lack of Commitment: Some people may prefer to avoid long-term commitment or may not be ready for it, leading them to have multiple partners rather than settling into a single, exclusive relationship.</td></tr><tr><td>Shuya&#x27;s final essay</td><td>term, faithful relationship. In addition, in a relationship, everyone has some expectations and needs for their partner. But Haiwang just doesn&#x27;t put his needs and expectations on one person. They will meet the expectations of different people. For example, emotional needs, physical needs, companionship, etc. They have their unmet needs within the confines of a monogamous relationship. (Kimmel, 2008)</td></tr></table></body></html>

Hyun’s question relates to another caution: writers should attend to possible AI induction, particularly for L2 writers who may harbor perceptions of their linguistic abilities as inferior to those of large language models. Hyun admitted his own tendency to regard AI suggestions as better, stating: “As long as it provides word choices, then you’re going to be biased and think that word choice looks very good in this sentence” (Hyun, Interview). Table 6 compares an excerpt of Hyun’s introduction paragraph across his first draft, AI log, and final draft. Hyun accepted ChatGPT’s grammatical and wording suggestions for all three sentences, though for slightly different reasons in each case. He admitted that while the change from “a remarkable transformation” to “significant transformations” did not make a notable difference on the meaning, he accepted it due to his general tendency to trust AI’s suggestion when it does not “damage the writer’s voice and originality” (Hyun, Reflection). For the second and third sentences, however, Hyun clearly noted that AI’s edits contributed to greater conciseness (e.g., “striking changes”) and improved accuracy (e.g., “both genders”), while correcting grammatical errors and enhancing clarity (e.g., “family members,” “who was responsible”), thus enhancing his voice.

Three students particularly noted that their attitudes towards AI were culturally influenced, emphasizing the need to reflect on one’s AI disposition in light of their cultural background. A notable example was Dofi, who moved to the US four years ago from Ghana. She shared,

I definitely feel I’m more traditional, especially because I’m from Ghana, we barely would encourage this [AI-assisted writing]. It’s always been the traditional – read books to enhance your vocabulary, to gain more knowledge, then apply them to your writing. And that’s how you became a better writer overall. So I feel like I do have some hesitation when it comes to using AI completely. And I may not be the best at using AI completely just because of where I’m from. (Dofi, Interview)

Similarly, Aye and Hyun acknowledged that integrating AI into their writing practices is a new concept and was not encouraged in the cultures where they came from, thus influencing their attitudes and proficiency with the AI tool.

Overall, the students shared their dilemmas and different perspectives on balancing AI use with maintaining their own originality, voice, and autonomy. Their positionalities were shaped by their views on the responsibilities and ethics of being a writer, AI’s intervention in their role in the writing process, and their culturally mediated AI disposition. The challenge of navigating the criticality spectrum is deeply personal, requiring thoughtful reflection on the extent to which one trusts AI. The student cases demonstrate that rather than a simple critical/uncritical divide, they positioned AI and themselves in complicated ways of navigating how AI fits into their vision of preserving originality and authorial voice within their specific writing practices.

Critical strategies for human-AI interaction. To engage effectively and critically with AI, the students made efforts in developing critical strategies in various areas. The first area is prompt engineering. Hyun defined prompt engineering as “communication between human and AI,” placing AI not merely as a tool for human use, but as an active participant and learner in communication. He explained, “AI is also learning from humans through the questions [humans ask], and how to communicate through that. We keep giving them data and then they keep improving” (Hyun, Interview). Hyun believed that the benefits of prompt engineering skills extend beyond the context of AI, as it could help with “learning how to ask people, how to better ask something, like communicating with people.” In this sense, the student viewed prompt engineering as part of a larger communication skill for today’s world. Similarly, Yawa noted from his experience that AI could be either a “bad” or “good” tool, depending on how the user prompts it: “I found a pattern: the specificity of my prompts affected AI’s efficiency. When my prompts were not clear and specific, AI produced verbose content.” (Yawa, Reflection).

Table 8 A comparison between Shuya’s paragraph and ChatGPT’s edits.   

<html><body><table><tr><td>Shuya&#x27;s text</td><td>In China, thee ralmany inteting words popular among ontmporary young people, bth ironc and otie, and hy ll hae thir nque conct.ry, in soct, sf may dife ons th oig Hng, ik scil, and schol ens, le ae his</td></tr><tr><td>AI&#x27;s edits</td><td>situation where they find out that they are a HaiWang after being in love with a person. In China, a dynamic exicon emerge continually, especill among today&#x27;s youth, who employ words both ironic and afirmative, each with its unue ane.his ter tricll htr inls, prenly me, w  lit and a nt for va ithin their relationships.</td></tr></table></body></html>

In addition to communicating with AI, the students who used ChatGPT for brainstorming particularly engaged in interactive processes that leverage AI’s strengths in big data and information synthesis – an approach they used to help solicit and validate ideas to enhance their research process. For instance, Shuya used ChatGPT to confirm her hypothesis by cross-checking AI-generated information with her own knowledge. According to her reflection, she had already formed some hypotheses about the formation of the Haiwang phenomenon. Upon getting ChatGPT’s answers, she felt validated and then conducted further research: “Once I knew exactly what I was looking for, I quickly figured out that some of the articles we had read were related to them, so I located the content immediately” (Shuya, Reflection). Below are two screenshots showing part of her AI log (Table 7) and the final paragraph she wrote, which incorporated a course reading that supported the hypothesis she and ChatGPT shared regarding “unfulfilled needs.” It is worth noting that she adopted the exact wording “within the confines of a monogamous relationship” from ChatGPT without acknowledging the source.

The students’ acknowledged that critical human-AI interaction was a proactive and continuous process of “adapting to AI’s rhythm” (Dawei, Interview) and adjusting one’s learning strategies to leverage the technology. This ongoing adaptation and trial process is a crucial part of the learning of AI. Another important aspect of this interaction is learning with AI, which entails active cognitive engagement and intellectual growth from the use of AI. Dofi noted that it required one’s conscious efforts and the ability to manage ChatGPT’s “contribution” to one’s learning. She illustrated this with a before and after example:

Before: Depending on the way you use AI, you may lose or you may gain, I feel like losing is in a sense that you don’t do an intensive work in the background before using AI. But I do feel like I’m working extensively in the background before seeking AI’s help.

After: If AI gives us good vocabulary, but then we’re not even going back to look at the meaning of the word, just replace something, just put it in your essay, you just submit it. I feel like the next moment, you’re not adding to your vocab in any way…If it gives you these words that you’ve never heard of, you should look at the meaning and learn from there. This I feel is helpful, because then it will decrease the overdependence, because you know you can put that in an essay again. (Dofi, Interview)

Thus, the dual dimensions of learning associated with effective and critical human-AI interaction represent a new type of learning that emerges from the technology. One needs to develop strategies in both to ensure they are “truly learning” (Dofi) from interaction with AI.

Critical evaluation of AI affordances. While critical AI awareness highlights how generative AI technologies function, critical evaluation of AI affordances emphasizes how well these technologies perform within specific rhetorical and linguistic contexts to achieve particular objectives. Students acknowledged the importance of critical evaluation of AI’s outputs in terms of information accuracy (Felix, Dofi, Yawa, Shuya, Nadia, Hyun, Paulo), linguistic and rhetorical repertoire (Yun, Yawa, Dofi, Hyun, Nadia, Dawei), as well as their own learning context (Dofi, Dawei, Paulo, Nadia, Shuya, Aye) so that the use of AI fits their specific writing purposes. Aware of AI’s inner workings and its impact on outputs, students evaluated AI’s information quality, accuracy, and biases through various ways such as “interaction with friends and professors” (Dofi), “reading” (Nadia), and “research” (Felix).

Students’ evaluations of generative AI’s rhetorical and linguistic affordances for writing assistance varied, and had to do with their self-assessment of language proficiency, their perception of what constitutes good writing, and their consideration of the intended audience. Yawa exemplifies one typical perspective, stating that “when it comes to the Western kind of writing, GPT is really good with that” (Yawa, Interview). Yawa believed that AI could help “facilitate the communication of my ideas” to better align with western rhetorical conventions (Yawa, Reflection). He also preferred to use ChatGPT than Grammarly to edit papers:

It [ChatGPT] could add words. It could bring in new sentences. If I was really good at writing, I would probably see it as an obstacle because it could change what I’m trying to convey. But sometimes the sentence it edits might actually improve what I’m trying to convey. But Grammarly doesn’t really change anything. It’s just fixing. (Yawa, Interview)

This quote suggests that Yawa found it more beneficial to seek ChatGPT’s extensive assistance with deeper structural and rhetorical improvements beyond basic error correction. His metacognitive awareness of his current level of language proficiency and experience with Western rhetorical styles shaped his view of ChatGPT’s affordances. Similarly, although feeling “overwhelmed” comparing her writing with ChatGPT’s edits word by word, Yun acknowledged that she “felt grateful” for the benefits ChatGPT provided in helping her edit “a grammatically correct, well-structured essay” and “learn new ways of expression in English” (Yun, Reflection). However, for the same reason, Shuya preferred to use Grammarly, as she felt that the sophisticated language generated by ChatGPT did not match

# You

please correct the grammar in the following paragraph: As a non-native English speaker who is not so good at English writing, I usually use a lot of subordinate clauses and passive voice. The reason why I wrote in that way is not showing my ability of organizing sentences and logic. Oppositely, this way of writing helps me clear up my logic. Because I don't know how to explain and idea in a comprehensive and tidy way, I choose to use subordinate clauses and passive voice. After using them, I could easily organize the information of the whole sentence. Nothing could be better than explaining some concepts in a sentence with subordinate clauses and passive voice when you forgot to, or don't want to explain it before.

# 5 ChatGPT

As a non-native English speaker who struggles with writing,I often resort to using numerous subordinate clauses and the passive voice. The reason for adopting this style is not to showcase my ability to structure sentences and logic. On the contrary, this approach aids in clarifying my thought process. Because I find it challenging to explain ideas in a comprehensive and orderly manner, Iopt for subordinate clauses and passive voice. These tools enable me to organize the information within a sentence more effectively.When I forget or prefer not to explain certain concepts in advance,there is nothing better than using subordinate clauses and passive voice to elucidate these concepts within a sentence.

Fig. 2. A screenshot of Dawei’s AI log showing ChatGPT’s edits on his writing.

her proficiency level:

I don’t let myself use it for editing. I just use Grammarly. I don’t use ChatGPT because such sophisticated language doesn’t look like mine. The words it uses are too fancy…I know what kind of stuff I can write based on my abilities. (Shuya, Interview)

Table 8 shows an excerpt of Shuya’s introductory paragraph and ChatGPT’s modification. She commented that AI’s phrasing, such as “a dynamic lexicon emerges continually especially,” sounded unnecessarily complicated to her. Shuya also pointed out that those “specialized and advanced words like ‘nuances’ and ‘penchant’” were not expressions she would typically use (Shuya, AI Screencast), and could also change her original meaning (Shuya, Reflection). Thus, Shuya kept all her original text without taking any suggestion from ChatGPT.

Dawei, on the other hand, decided to use AI’s linguistic suggestions despite believing that ChatGPT produces writing that is too “advanced” and exceeded his current proficiency level, as he commented on ChatGPT’s edits on his writing in Fig. 2:

Dawei’s willingness to accept the suggestions stemmed from his assumption that his readers would be “more accepting” to this style: “My positioning for my audience is they should be at the level of native language speakers. It’s leaning towards this level, at least their level is higher than mine. I tend more towards lifting this thing a bit higher” (Dawei, Interview). Dawei regarded native-like proficiency and native-speaker norms as integral to the academic authority he felt compelled to demonstrate in his writing, despite his actual audience being multicultural. In this sense, AI became a literacy broker catering to his idealization that English academic writing should “present the logic in a way more akin to a native language speaker” (Dawei, Reflection).

In contrast, other students like Dofi commented that “excessive” use of academic language might not be appropriate: “I feel like if it puts way too much advanced vocabulary, it’s our responsibility to check through and make sure that the vocab in is perfect for the audience” (Dofi, Interview). Aye, another student highly attuned to nuances in language, noted that AI edits could lead to “inap propriate phrasing or word choices” and sometimes “a different interpretation” of her original meaning, thus failing to “personalize the text to my specific needs and voice” (Aye, Reflection). The distinction in students’ perspectives shows that students’ language proficiency and metalinguistic awareness as well as their understanding of what constitutes good academic writing and audience ex pectations influence how they evaluate AI’s linguistic and rhetorical affordances.

Students also critiqued how generative AI’s neutral formality, such as its emotionless and formal language style, may influence how one engages with and evaluates its outputs. Yawa described AI-generated texts as having “no flavor” (Reflection) while Hyun noted they contain “no personal experiences, opinions, or emotions” (Reflection), making them “unappealing” (Dofi, Interview). Yawa further noted that AI always takes a neutral stance due to how it is programmed; however, this “neutrality” might disguise its coded biases and thus requires critical evaluation. One way such “neutrality” influenced students is evident in Shuya’s defensive stance towards AI’s biases: “One limit of ChatGPT is that it does not have biases. If it had biases, AI wouldn’t be qualified. It can’t please everyone. You can’t blame AI for this limitation; AI is created by people. What AI provides is a general societal view” (Shuya, Interview). Consequently, Shuya did not consider that she had any stakes in “finding faults with AI” as a user and writer, stating that “I just needed to get this thing [the assignment] done, so I didn’t consider it [bias]…If you find it wrong, leaving it to them.”

Another aspect of critical evaluation considered to be essential when using AI for writing involves evaluating the learning context and the goals of learning within that context. Yawa, Paulo, Nadia, and Hyun mentioned that using AI to explain complex terms and concepts to assist with reading comprehension, could be acceptable and beneficial. For tasks that require deeper engagement with the material, critical thinking, and the development of original ideas, AI is very “limiting” (Shuya, Reflection). Dofi echoed this sentiment, emphasizing the importance of learning to “generate your own ideas and learn how to piece your ideas together” (Dofi, Interview). All students recognize that while AI can be a useful tool for certain types of learning tasks, it is important to ensure that it complements rather than replaces the essential elements of the learning process.

# 5. Discussion

# .1. Complicating and navigating the contradictions in AI-assisted writing

Confirming the scholarly literature, the study found that L2 writers utilized the affordances of generative AI to assist with various aspects of writing, such as vocabulary, grammar, organization, and idea development (Yan, 2023; Wang, 2024; Woo et al., 2024). AI-assisted source use and research process, an aspect of AI-assisted writing that is less examined in the current scholarship (Sun, 2024), was found to be another major use of AI in the current study. Participants employed generative AI to translate L1 sources into English, locate discipline-specific terms and relevant L2 sources, and incorporate L2 sources into writing. This finding highlights the potential of AI in facilitating students’ multilingual and cross-disciplinary source engagement and research, while also calling for more empirical work in light of the growing number of specialized AI tools (e.g., NoteBookLM, Elicit) that assist with source summarization, synthesis, and analysis in research writing. Using generative AI for brainstorming and source integration, like Yawa’s use of it for summarizing and compiling articles, may risk disrupting the synergistic relationship between reading and writing. Automating aspects of source engagement (e.g., distill information from scholarly sources for convenience or for consolidation of one’s ideas) may lead to a transactional approach to reading and writing, where synthesizing sources becomes detached from the critical analysis that informs thinking and writing, undermining the foundational skills that writing pedagogy aims to cultivate. This raises important concerns for L2 writing teachers.

In addition to the benefits of AI in supporting L2 writers’ linguistic and writing development through personalized and immediate feedback reported by previous studies (Yan, 2023; Barrot, 2023), the study found that students regarded accelerating the writing process (e.g., sorting out information, building connections between ideas, creating an outline from a jumble of thoughts) as some of the advantages of using AI technologies. The study also revealed that the students’ inquiry with AI turned to be an iterative process with a lot of trials, which could lead to confusion and frustration and require significant cognitive effort. This finding helps explain the point of divergence observed in previous studies where L2 writers reported reduced cognitive load in Wang (2024) study but expe rienced heavy cognitive load in Woo et al. (2024). While generative AI reduces the cognitive load associated with the writing task, it may increase the cognitive load in navigating the technology to obtain meaningful outputs and critically integrate its feedback. We thus suggest that developing students’ AI literacy should also involve carefully scaffolding skills such as prompt engineering, AI-related feedback literacy, and self-directed learning skills to help students effectively monitor and manage AI learning resources (Li et al., 2024; Wang, Li, et al., 2024) at metacognitive levels. This finding underscores the need for a pedagogical shift towards connecting AI literacy with learning goals that have been traditionally regarded as essential for writing courses, rather than treating it as a separate or add-on skill.

We found a noteworthy contradiction regarding AI’s linguistic power and its influence on L2 writers. While acknowledging that LLMs can be a valuable aid in learning English academic writing, some students also expressed concern about feeling tempted to rely on and even submit to AI’s linguistic eloquence. The finding brings to the forefront perils regarding integrating AI into the writing process, extending Wang (2024) concern about language AI-nization. AI may act as a new colonizing tool that reinforces standard language ideology (Nee et al., 2022), linguistic neo-imperialism (Lai, 2021), and the marginalization of other literacies and rhetorics. We contend the need to position AI literacy for L2 writers within the critical pedagogical tradition, moving beyond a practical and use-based orientation foregrounded in existing AI literacy frameworks. As such, critical AI literacy should entail empowering multi lingual writers to be active agents in interrogating and questioning the socio-political and cultural implications of AI in shaping language, knowledge, and power dynamics in academic writing as well as fostering students’ awareness to critically examine the broader systems of power that govern AI technologies and their development. From this perspective, writing with AI transcends the acts of critiquing and utilizing AI outputs; it becomes a site of interaction and negotiation with broader ethical and epistemological questions that allow students to see themselves as creators of meaning relevant to their multilingual identities, rather than consumers of AI-generated content.

# 5.2. A framework for critical AI literacy

The study examined L2 writers’ critical AI literacy in their AI-assisted writing, providing evidence for reconsidering existing AI literacy frameworks. The study complicates many literacy educators’ shared concern about student writers’ uncritical reliance on AI assistance (Gupta et al., 2024). The L2 writers in this study demonstrated a spectrum of criticality towards AI and its affordances. However, our findings reveal that while the L2 writers’ critical AI awareness, positionality, strategies, and evaluations are intertwined, their beliefs and practices may not always align. For instance, some participants adopted generative AI’s language suggestions despite recognizing them as “excessive,” or treated the coded biases in AI with a pragmatic “it-has-nothing-to-do-with-me” attitude. This finding suggests the importance of engaging in reflective praxis to align beliefs with practices to enhance CAIL holistically. We also want to highlight that certain approaches such as Hyun’s tendency to trust AI suggestions and Dawei’s full embrace of AI’s language suggestions may appear uncritical, yet a deeper understanding of their positionalities reveals a more complex dynamic. The students’ reliance on AI is a reflection of language ideologies shaped by their academic socialization, where native-speaker norms were regarded as benchmarks of “good” academic writing. Similarly, Dofi’s dilemma and decision in presenting ChatGPT as a research source to fulfill her conceived norm of English academic writing while feeling inadequate to claim her authority in writing about her own culture, also shows how the student positions her own cultural-linguistic repertoire as an L2 writer in relation to LLMs as authoritative repre sentations of L1 perfection and big-data driven knowledge bases. Thus, rather than simply labeling their use of AI as uncritical, it is more important to inspect and contextualize how their deliberate practices of orchestrating AI outputs, existing on a spectrum of criticality, were shaped by their efforts to meet their (mis)understandings of rhetorical demands.

![](img/b3e93d74af98ce0b4ba37e47f77a59a614ef20d790dfe811d704d97eb3812b02.jpg)  
Fig. 3. An APSE model of critical AI literacy.

Moreover, an AI literacy model based on Bloom’s taxonomy may be inadequate and inaccurate, as it presents a linear and pro gressive approach to the development of AI literacy, failing to capture the interconnectedness of its different components. Thus, we propose the following critical AI literacy framework for L2 writing based on our findings, as shown in Fig. 3. The CAIL framework encompasses (1) critical AI awareness (A) of AI’s algorithmic inner workings, functionalities, training data, and biases. This aligns the “know and understand” component of the models by $\mathrm { N g }$ et al. (2021) and Warscheauer et al. (2023). (2) critical AI positionality (P), which involves recognizing one’s disposition towards AI and critically reflecting on one’s voice and role in relation to AI, seeking a balanced position within the spectrum of reliance on versus resistance to AI. This aspect was not particularly addressed in Ng et al. (2021) and Warschauer et al. (2023); however, we highlight its importance as AI can play an active role in L2 writers’ meaning-making processes and shape how they viewed their relationship with writing and technology. As Leander and Burriss (2020) argues, AI is not a passive tool; it exists “inside,” “with,” “alongside,” “above,” “toward,” “against,” and “among” us, especially in an increasingly AI-mediated world and where authoring the posthuman text is becoming more and more common (Gourlay, 2015). (3) critical strategies for human-AI interaction (S), which refers to adopting critical approaches to utilizing AI tools to support writing and self-learning in responsible and meaningful ways. This involves a dynamic process of prompt engineering to effectively communicate with AI, elicit appropriate responses, and proactively adjust one’s strategies to assist with writing. This dimension extends $\mathrm { N } g$ et al.’s (2021) “use and apply” and Warschauer et al.’s (2023) “access and navigate” and “prompt.” Additionally, we emphasize the social nature of prompt engineering (Bao & Li, 2023), and the importance of taking a proactive role and being adaptive in the self-directed learning process of using AI (Li et al., 2024). (4) critical evaluation of AI affordances (E) entails evaluating AI’s outputs in terms of information accuracy and quality, linguistic repertoire and possible linguicism, rhetorical and cultural sensibility, and ideological biases, as well as their usefulness and appropriateness according to one’s specific learning and rhetorical context, writing purposes, and audiences, to ensure ethicality. This dimension corresponds to $\mathrm { N } g$ et al.’s (2021) “evaluate” and Warschauer et al. (2023) “corroborate,” but specifically addresses the unique challenges L2 writers may face. While their models focus on evaluating the accuracy and biases of AI-generated content, we also consider how such texts might influence L2 writers linguistically and rhetorically, and conversely, how L2 writers might creatively leverage these linguistic and rhetorical repertoires for their specific writing contexts.

The four components represent distinct yet overlapping aspects of CAIL. For instance, one’s awareness of AI biases and limitations can influence their positionality and evaluation of AI’s affordances for writing. The strategies that L2 writers develop through their interactions with AI can also enhance their understanding of AI’s affordances and their critical awareness. One’s critical evaluation of AI can also be shaped by their positionality and perspective, which are impacted by their experiences and backgrounds. Thus the framework considered the multifaceted nature of learning involved in AI-assisted writing: learning of AI and learning with AI. Developing a comprehensive understanding and application of these four components fosters a holistic approach to critically and

Table 9 Strategies and pedagogical possibilities for developing CAIL based on the APSE model.   

<html><body><table><tr><td>Critical Dimensions</td><td>Strategies</td><td>Pedagogical Possibilities</td></tr><tr><td>Critical AI awareness</td><td>: Develop knowledge on AI&#x27;s operational basis : Understand the discourse features and patterns of AI- generated responses : Analyze how AI&#x27;s foundational operational mechanisms shape</td><td>: Equip students with interdisciplinary knowledge related to the technical aspects of AI : Interrogate AI biases by drawing upon L2 writers&#x27; own cross- cultural knowledge, experiences, and reflections</td></tr><tr><td>Critical AI positionality</td><td>its responses and interaction with human . Reflect on one&#x27;s views on writing and writerly virtues : Reflect on one&#x27;s language and technology ideologies (e.g., L1 vs. L2, human vs. AI) : Reflect on how these perceptions and positionalities come into being through one&#x27;s academic literacy practices, educational</td><td>: Foster student peer collaboration to examine their positionalities and underlying beliefs : Engage in discussions about the ethical implications (e.g., academic integrity, social and environmental considerations) of various human-AI positionalities</td></tr><tr><td>Critical strategies for human-AI interaction</td><td>experiences, and cultural backgrounds : Learn effective prompt engineering skills to communicate with AI : Engage in iterative and adaptive processes of refining AI interaction and learning strategy : Monitor one&#x27;s learning with AI</td><td>: Develop prompt engineering skills by leveraging L2 learners and teachers&#x27; strengths, for instance, through linguistic, discourse, and genre analysis approaches and communication perspectives. : Cultivate students&#x27; disposition and strategies for self-directed</td></tr><tr><td>Critical evaluation of AI affordances</td><td>. Evaluate AI&#x27;s information accuracy, quality, and reliability : Evaluate AI&#x27;s linguistic and rhetorical affordances in relation to the writer&#x27;s proficiency and the rhetorical context : Evaluate the learning context and the goal of learning within the context in relation to the role of AI</td><td>learning with AI, focusing on self-monitoring and managing one&#x27;s learning with AI (Wang, Li, et al., 2024) : Verify AI outputs with human (e.g., teachers and peers) and nonhuman resources (e.g., research) (Li et al., 2024) : Develop students&#x27; metalinguistic knowledge to evaluate AI&#x27;s usefulness and appropriateness for specific writing contexts : Foster students&#x27; metacognition of the learning task and</td></tr></table></body></html>

ethically engage with AI technologies.

# 6. Conclusion and implications

Following a qualitative design, we explored L2 writers’ critical AI literacy in their AI-assisted writing processes. Complicating the scholarly literature on the dilemmas and contradictions L2 writers are likely to encounter in AI-assisted writing, the study discussed how students perceived and navigated the various challenges in balancing AI use with their own voice through unpacking their critical decision-making involved in AI-assisted writing. To fill the gap in evidence-based models on critical AI literacy in the current literature, the study proposes a CAIL model focusing on critical awareness, positionality, strategies, and evaluations in AI use.

The study is limited due to its small sample size and short duration, which may restrict the applicability of the findings to a broader range of settings, such as students of different age groups, language proficiencies, writing experiences, as well as L2 writing instruction in various educational and cultural contexts. We thus recommend that scholars examine diverse student populations and conduct more large-scale studies across different learning contexts to test, validate, and expand the framework. We also suggest that future studies explore, in greater depth, how students’ language proficiency levels and prior writing experiences may influence their CAIL. Furthermore, the study focused on students’ use of ChatGPT (GPT 3.5) and did not consider other AI models and generative AIpowered writing tools. Future studies should examine the latest advancements as well as various specialized AI writing tools to un derstand how they may influence students’ writing differently. Future research should also take into account the multimodal func tionalities of AI for assisting students’ digital multimodal composing (Tan, Xu, & Wang, 2025).

We make a list of strategies and pedagogical possibilities for developing critical AI literacy based on the APSE model as shown in Table 9. These considerations are meant to be illustrative rather than exhaustive. We would like to highlight that explicit instruction on critical AI literacy is fundamental to prepare students for making informed and ethical decisions about when, where, and how to use, evaluate, and incorporate AI. Writing and language instructors should discuss specific scenarios and break down the skills for critical AI use, such as prompt engineering and feedback literacy. They should also encourage students to reflect on how AI technologies affect their language use, the learning process, and ethical considerations. Instructors should also help students develop relevant language skills and metalinguistic knowledge to identify ways of using AI appropriate for specific writing contexts, considering disciplinary writing conventions, goals and audiences for writing, and the learners’ own attributes and differences. Finally, instructors should encourage students to explore the use of various semiotic repertoires for creative communications and identity expression, rather than pursuing correctness and native speaker-like perfection. AI should be a means to help students leverage linguistic and multimodal meaning-making resources, instead of a convenience tool for producing grammatically correct sentences and streamlining formulaic academic writing. The study urges language and writing educators to rethink our current writing education that privileges certain linguistic, rhetorical, and discursive features that can be easily replicated by AI, for instance, embracing decolonizing academic writing pedagogies (Canagarajah, 2023). In addition to supporting students, it is crucial to provide professional development and training for L2 writing instructors and teacher educators, so that they are equipped to integrate critical AI literacy into their teaching. Such CAIL training opportunities should center around enhancing teachers’ technological and pedagogical readiness to cultivate students’ critical awareness, positionality, interaction strategies, and evaluation skills in using AI, enabling their pedagogy to engage with the sociopolitical, linguistic, and ethical complexities of AI in writing.

# CRediT authorship contribution statement

Wang Zhaozhe: Writing – review & editing, Visualization, Validation, Resources, Methodology, Formal analysis, Conceptuali zation. Wang Chaoran: Writing – review & editing, Writing – original draft, Visualization, Validation, Resources, Project adminis tration, Methodology, Formal analysis, Conceptualization.

# Data availability

Data will be made available on request.

# References

Bao, Y., & Li, B. (2023). A preliminary study on graduate student instructors’ exploration, perception, and use of ChatGPT. International Journal of Computer-Assisted Language Learning and Teaching, 13(1), 1–23. https://doi.org/10.4018/IJCALLT.332873   
Barrot, J. S. (2023). Using ChatGPT for second language writing: Pitfalls and potentials. Assessing Writing, 57, Article 100745. https://doi.org/10.1016/j. asw.2023.100745   
Bewersdorff, A., Zhai, X., Roberts, J., & Nerdel, C. (2023). Myths, mis- and preconceptions of artificial intelligence: A review of the literature. Computers and Education: Artificial Intelligence, 4, Article 100143. https://doi.org/10.1016/j.caeai.2023.100143   
Canagarajah, S. (2023). Decolonizing academic writing pedagogies for multilingual students. TESOL Quarterly. https://doi.org/10.1002/tesq.3231. tesq.3231.   
Cardon, P., Fleischmann, C., Aritz, J., Logemann, M., & Heidewald, J. (2023). The challenges and opportunities of AI-assisted writing: Developing AI literacy for the AI age. Business and Professional Communication Quarterly, 86(3), 257–295. https://doi.org/10.1177/23294906231176517   
Chomsky, N., Roberts, I., & Watumull, J. (2023). The false promise of ChatGPT. The New York Times. https://www.nytimes.com/2023/03/08/opinion/noamchomsky-chatgpt-ai.html.   
Freire, P. (1970). Pedagogy of the oppressed. Continuum.   
Giroux, H. A. (1997). Pedagogy and the politics of hope: Theory, culture, and schooling. Westview Press.   
Gourlay, L. (2015). Posthuman texts: Nonhuman actors, mediators and the digital university. Social Semiotics, 25(4), 484–500. https://doi.org/10.1080/ 10350330.2015.1059578   
Gupta, A., Atef, Y., Mills, A., & Bali, M. (2024). Assistant, parrot, or colonizing loudspeaker? ChatGPT metaphors for developing critical AI literacies. Open Praxis, 16 (1), 37–53. https://doi.org/10.55982/openpraxis.16.1.631   
Kern, R. (2024). Twenty-first century technologies and language education: Charting a path forward. The Modern Language Journal, 108(2), 515–533. https://doi.org/ 10.1111/modl.12924   
Konishi, Y. (2015). What is Needed for AI literacy? Priorities for the Japanese economy in 2016. https://www.rieti.go.jp/en/columns/s16_0014.html.   
Kimmel, M. (2008). Guyland: The perilous world where boys become men. HarperCollins.   
Kubota, R. (2023). Another contradiction in AI-assisted second language writing. Journal of Second Language Writing, 62, Article 101069. https://doi.org/10.1016/j. jslw.2023.101069   
Lai, M. L. (2021). English linguistic neo-imperialism – a case of Hong Kong. Journal of Multilingual and Multicultural Development, 42(4), 398–412. https://doi.org/ 10.1080/01434632.2019.1702667   
Laupichler, M. C., Aster, A., Schirch, J., & Raupach, T. (2022). Artificial intelligence literacy in higher and adult education: A scoping literature review. Computers and Education: Artificial Intelligence, 3, Article 100101. https://doi.org/10.1016/j.caeai.2022.100101   
Leander, K. M., & Burriss, S. K. (2020). Critical literacy for a posthuman world: When people read, and become, with machines. British Journal of Educational Technology, 51(4), 1262–1276. https://doi.org/10.1111/bjet.12924   
Li, B., Bonk, C., Wang, C., & Kou, X. (2024). Reconceptualizing self-directed learning in the era of generative AI: An exploratory analysis of language learning. IEEE Transactions on Learning Technologies, 17. https://doi.org/10.1109/TLT.2024.3386098   
Long, D., & Magerko, B. (2020). In R. Bernhaupt, F. Mueller, D. Verweij, J. Andres, J. McGrenere, A. Cockburn, et al. (Eds.), CHI 2020 Proceedings. What is AI literacy? Competencies and design considerations (pp. 1–16). ACM.   
Memarian, B., & Doleck, T. (2023). Fairness, Accountability, Transparency, and Ethics (FATE) in Artificial Intelligence (AI) and higher education: A systematic review. Computers and Education: Artificial Intelligence, 5, Article 100152. https://doi.org/10.1016/j.caeai.2023.100152   
MLA-CCCC Joint Task Force on Writing and AI Working Paper: Overview of the Issues, Statement of Principles, and Recommendations (July, 2023). Retrieved from https://hcommons.org/app/uploads/sites/1003160/2023/07/MLA-CCCC-Joint-Task-Force-on-Writing-and-AI-Working-Paper-1.pdf.   
Nee, J., Smith, G. M., Sheares, A., & Rustagi, I. (2022). Linguistic justice as a framework for designing, developing, and managing natural language processing tools, 205395172210909 Big Data Society, 9(1). https://doi.org/10.1177/20539517221090930.   
Ng, D. T. K., Leung, J. K. L., Chu, S. K. W., & Qiao, M. S. (2021). Conceptualizing AI literacy: An exploratory review. Computers and Education: Artificial Intelligence, 2, Article 100041. https://doi.org/10.1016/j.caeai.2021.100041   
Ng, D. T. K., Wu, W., Leung, J. K. L., Chiu, T. K. F., & Chu, S. K. W. (2024). Design and validation of the AI literacy questionnaire: The affective, behavioural, cognitive and ethical approach. British Journal of Educational Technology, 55(3), 1082–1104. https://doi.org/10.1111/bjet.13411   
Ou, A. W., Khuder, B., Franzetti, S., & Negretti, R. (2024). Conceptualising and cultivating critical GAI Literacy in doctoral academic writing. Journal of Second Language Writing, 66, Article 101156. https://doi.org/10.1016/j.jslw.2024.101156   
Pecorari, D. (2023). Generative AI: Same same but different? Journal of Second Language Writing, 62, Article 101067. https://doi.org/10.1016/j.jslw.2023.101067   
Praphan, P. W., & Praphan, K. (2023). AI technologies in the ESL/EFL writing classroom: The villain or the champion? Journal of Second Language Writing, 62, Article 101072. https://doi.org/10.1016/j.jslw.2023.101072   
Saldana, ˜ J. (2015). The coding manual for qualitative researchers (4th ed.). Sage.   
Sasaki, M. (2023). AI tools as affordances and contradictions for EFL writers: Emic perspectives and L1 use as a resource. Journal of Second Language Writing, 62, Article 101068. https://doi.org/10.1016/j.jslw.2023.101068   
Southworth, J., Migliaccio, K., Glover, J., Glover, J., Reed, D., McCarty, C., Brendemuhl, J., & Thomas, A. (2023). Developing a model for AI Across the curriculum: Transforming the higher education landscape via innovation in AI literacy. Computers and Education: Artificial Intelligence, 4, Article 100127. https://doi.org/ 10.1016/j.caeai.2023.100127   
Stojanov, A., Liu, Q., & Koh, J. (2024). University students’ self-reported reliance on ChatGPT for learning: A latent profile analysis. Computers and Education: Artificial Intelligence, 6. https://doi.org/10.1016/j.caeai.2024.100243   
Su, Y., Lin, Y., & Lai, C. (2023). Collaborating with ChatGPT in argumentative writing classrooms. Assessing Writing, 57, Article 100752. https://doi.org/10.1016/j. asw.2023.100752   
Sun, Q. (2024). Exploring human-generative AI interaction in L2 learners’ source use practices: Issues, trials, and critical reflections. Journal of Academic Writing, 14 (1), 24–42. https://doi.org/10.18552/joaw.v14i1.1055   
Tan, X., Xu, W., & Wang, C. (2025). Purposeful remixing with generative AI: Constructing designer voice in multimodal composing. Computers & Composition, 75. https://doi.org/10.1016/j.compcom.2024.102893   
Tsai, C., Lin, Y., & Brown, I. (2024). Impacts of ChatGPT-assisted writing for EFL English majors: Feasibility and challenges. Education and Information Technologies. https://doi.org/10.1007/s10639-024-12722-y   
Tseng, W., & Warschauer, M. (2023). AI-writing tools in education: If you can’t beat them, join them. Journal of China Computer-Assisted Language Learning. https:// doi.org/10.1515/jccall-2023-0008   
Wang, C. (2024). Exploring students’ generative AI-assisted writing processes: Perceptions and experiences from native and nonnative english speakers. Technology, Knowledge and Learning. https://doi.org/10.1007/s10758-024-09744-3   
Wang, C., Li, Z., & Bonk, C. (2024). Understanding self-directed learning in AI-Assisted writing: A mixed methods study of postsecondary learners. Computers and Education: Artificial Intelligence, 6, Article 100247. https://doi.org/10.1016/j.caeai.2024.100247   
Warschauer, M., Tseng, W., Yim, S., Webster, T., Jacob, S., Du, Q., & Tate, T. (2023). The affordances and contradictions of AI-generated text for writers of English as a second or foreign language. Journal of Second Language Writing, 62, Article 101071. https://doi.org/10.1016/j.jslw.2023.101071   
Woo, D. J., Wang, D., Guo, K., & Susanto, H. (2024). Teaching EFL students to write with ChatGPT: Students’ motivation to learn, cognitive load, and satisfaction with the learning process. Education and Information Technologies. https://doi.org/10.1007/s10639-024-12819-4   
Yan, D. (2023). Impact of ChatGPT on learners in a L2 writing practicum: An exploratory investigation. Education and Information Technologies. https://doi.org/ 10.1007/s10639-023-11742-4   
Yin, R. (2018). Case study research and applications: Design and methods (6th ed.). Sage.

Chaoran Wang is a Multilingual Writing Specialist and Assistant Professor of Writing at Colby College. Her research examines the issues of literacy development of multilingual students and technology enhanced language learning through the intersecting perspectives of writing studies, applied linguistics, and educational tech nologies. Her recent work has appeared in Computers and Education: Artificial Intelligence, Applied Linguistics, Language Learning & Technology, IEEE Transactions on Learning Technologies, Research Methods in Applied Linguistics, among others. She is currently co-editing two books on AI and writing/language education with Routledge.