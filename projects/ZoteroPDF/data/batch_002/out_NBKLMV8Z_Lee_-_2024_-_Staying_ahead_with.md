# Staying ahead with generative artificial intelligence for learning: navigating challenges and opportunities with 5Ts and 3Rs

Alwyn Vwen Yen Lee

To cite this article: Alwyn Vwen Yen Lee (2024) Staying ahead with generative artificial intelligence for learning: navigating challenges and opportunities with 5Ts and 3Rs, Asia Pacific Journal of Education, 44:1, 81-93, DOI: 10.1080/02188791.2024.2305171

To link to this article: https://doi.org/10.1080/02188791.2024.2305171

# Staying ahead with generative artificial intelligence for learning: navigating challenges and opportunities with 5Ts and 3Rs

Alwyn Vwen Yen Lee

National Institute of Education, Nanyang Technological University, Singapore, Singapore

# ABSTRACT

Generative Artificial Intelligence (AI)’s emergence is viewed as a disruptive technological advancement that has been beneficial for most educational purposes but also coupled with emerging challenges and potentially destabilizing effects. Given the unprecedented onset and surge in interests, education stakeholders are often pressured to adopt such emergent technologies with little space and time to seek better understanding and to attain literacy. This paper brings together existing contributions to identify a list of five common themes (5Ts) and various uses of generative AI for improving students learning and future education research. The challenges and opportunities from the use of generative AI in education were also explored, and as part of a rethink of how stakeholders can continue to be relevant in a dynamic learning environment with emerging technologies, three $" \mathsf { R } ^ { \prime \prime }$ guidelines (3Rs) are also proposed to aid educators and students to stay ahead of the curve in addressing challenges and embracing opportunities arising from the use of generative AI for learning.

# ARTICLE HISTORY

Received 9 August 2023   
Accepted 17 December 2023

# KEYWORDS

Generative AI; AI in education; Learning; Challenges and opportunities; Emergent Technologies

# Introduction

Technology has time and again revolutionized teaching and learning, creating abundant opportunities for educators to tap on to improve teaching and for students to leverage for learning (Collins & Halverson, 2018). Like how the advent of the World Wide Web (also generally known as the internet) disrupted the way in which information is being made available to educators and students within and outside of classrooms (Owston, 1997), the gradual adoption of Artificial Intelligence (AI) tools and methods may also potentially disrupt and revolutionize teaching and learning in the $2 1 ^ { \mathsf { s t } }$ century. While such developments may often be unprecedented and disruptive, there remains a need for education stakeholders to be able to view the achievement of new levels of competency, the showing of levels of skill, and a responsibility for their learning that do not appear to be at an end, as demonstrations of them being able to stay ahead of the curve (Psiropoulos et al., 2016).

However, there remains a certain lack of clarity in how AI may be adopted and used for education, especially with the emergence of generative AI and related content generation capabilities. The ambiguity and “black box” phenomenon are not uncommon, due to how studies are often created, customized, with reported findings from “opaque” instruments that enable even novices to perform advanced experiments (Resnick et al., 2000), such as the use of generative AI for educational outcomes. This has also led to greater difficulties for assessment in education settings (Lee, 2023; Rudolph et al., 2023).

Popular exemplars of large language models (LLM) in generative AI include Bidirectional Encoder Representations from Transformers (BERT; Devlin et al., 2018), Generative Pre-trained Transformers (GPT; Radford et al., 2018), and T5 (Raffel et al., 2020) that can generate believable text in an instant; and DALL-E 2 that is built on the same GPT technology to create photorealistic images. What is less known about generative AI is the heavy dependence of the technology’s performance on two main factors, which can be identified from comprehensive overviews of LLMs (e.g., Naveed et al., 2023): First, an abundance of data is required for algorithms to train and operate upon; second, substantial and elaborate computational resources are needed to run the mentioned algorithms. Based on these two factors, it is likely that most real-world applications using consumer-grade computing devices with limited resources from public spaces will not be able to easily deploy such algorithms, let alone have the adequate resources to sustain them over time.

Hence, with the launch of the ChatGPT application by OpenAI (2022) that is built on the GPT architecture and considered as a revolutionary development, the two abovementioned obstacles were able to be overcome, providing ease-of-access to the large language model and avoidance in charging users extensive resources for its use. Boasting surprisingly superior performance, other similar applications have also revealed their large language models (e.g., Google’s Bard, BLOOM as a free LLM) and are also moving the research communities towards artificial general intelligence.

The surge in use cases seem promising, especially for resolving long-standing issues such as climate change (Biswas, 2023), debugging of programming-related issues (Surameery & Shakor, 2023), and even seen as a tool for open education (Firat, 2023). Yet, it poses its own set of implications and repercussions including fake information and plagiarism (Lo, 2023). Even industries that were formerly less affected by technological advancements, such as scriptwriting and acting, felt that corporations may use generative AI and replace them (Barnes et al., 2023). Within the education landscape, a common question is whether AI may one day also duplicate the major responsibilities of teachers and unknowingly transform students into robot-like models with sole purposes of performing better than others.

From historical observations (Blinder, 2009; Scepanovič, 2019), it may not seem the case, as technological transitions that revolve around industrial revolutions are often marked by the persistence of relevant technologies rather than a marked change in teachers and students. For example, automation with computer-assisted developments in the third industrial revolution during the late $2 0 ^ { \mathrm { t h } }$ century and the ongoing information and communication technology (ICT)-driven push into the current fourth industrial revolution with cyber-physical systems and AI are already taking the lead in instituting changes across all industries. However, in general, educators and students have thus far remained relatively unscathed from major disruptions as they are able to flexibly adapt to emerging trends and ICT developments from the third industrial revolution, but it is also possible that the fourth iteration promises to be something more radical that educators and students need to reexamine and reconsider (Scepanovič, 2019).

It is nearly impossible to address disruptions in student learning within a single paper, as the field of learning comprises large domains with considerable contributions from the field of education. The three main domains of learning (Sousa, 2016), namely the cognitive, affective, and psychomotor domains, have decades of literature and progress that already largely addressed different students’ needs and ways of learning, and how educators should ensure that appropriate methods and pedagogy are implemented while planning and delivering lessons.

Therefore, this paper first focuses on bringing together and drawing on existent contributions from experts, identifying a list of five common themes (5Ts) and related uses of generative AI for improving students learning and future research. The focus then shifts to the exploration of how one can stay head of the curve when confronted with the identified challenges and opportunities arising from the use of generative AI for learning, with the use of the proposed $3 ^ { \prime \prime }$ guidelines (3Rs). Although ChatGPT is the primary platform of investigation for this paper, the findings and implications are likely to also apply to other technologies with functionalities similar to ChatGPT. The following two research questions are addressed in this paper:

(1) What are common themes that have arisen from the use of generative AI for learning and future research?   
(2) How does one stay ahead when confronted with the challenges and opportunities related to the use of generative AI technologies for learning?

# Background

# Origins and types of AI

The development and use of Artificial Intelligence (AI) across regions and countries around the world has been ongoing since the 1950s (McCarthy et al., 2006), existing in many forms and with varying levels of success and progress. The general perception of AI has mostly been of computers and even robots with awesome calculating powers that can provide insightful and make intelligent decisions, but AI is not just about robots; instead, it is about understanding the nature of intelligent thought and action using computers as experimental devices (Buchanan, 2005). This goal has not deviated much over the years into the $2 1 ^ { \mathsf { s t } }$ century, with researchers and educators still looking towards the use of AI to reason on provided inputs and explain on outputs, with hopes of using it to augment human intelligence, rather than replacing it (De Cremer & Kasparov, 2021).

Among the three most recognized types of AI, the most traditional AI that we have often seen and worked with are considered artificial narrow intelligence (ANI), consisting of machine learning and neural network algorithms that help to complete specific tasks. For example, a vision recognition application based on computer vision analysis may learn to recognize different flowers from a botanical database with very high accuracy but cannot perform other activities beyond its specified functions. Generative AI can be thought of as the preliminary stages of how the next generation of AI will look like, moving towards artificial general intelligence (AGI) that can learn and perform a wider range of actions like humans. The eventual goal is to create machines that can perform humancapable tasks with human-like performance. In education, some implementations like intelligent tutoring systems and chatbots (e.g., Haristiani, 2019) seek to emulate and tap on such developments in hopes of helping with student learning. The third type of artificial superintelligence (ASI) currently remains science fiction content where an AI is capable of general intelligence and can supersede humans and become more capable by itself.

# Generative AI for learning

Different from traditional AI that processes data and returns expected results, generative AI’s enormous potential stems from how content can be generated from its large language models using prompts, providing personalized and effective learning experiences to students via customized feedback and interactions, or even realistic virtual simulations for hands-on engineering learning (Qadir, 2023). Apart from the engineering field, other fields such as education and sciences have also benefitted, including generative chemistry for drug discovery (Bian & Xie, 2021) and science education in general (Cooper, 2023), along with implementations in non-K-12 age-groups (e.g., early childhood; Su & Yang, 2022), which signifies the huge potential of generative AI across fields and ages.

Several ways have been proposed and implemented to test the cognitive abilities of generative AI. For example, ChatGPT that is built on the GPT architecture was used to provide answers to a Wharton MBA examination, which passed off as a decent attempt (Terwiesch, 2023). One of the major benchmarks for a machine’s ability to display intelligent behaviour as a strong indicator of AI is the Turing test, which is a significant milestone on whether machines can think (Turing, 1950), and it is still debatable whether ChatGPT has acquired such a capability (Biever, 2023) or whether the Turing Test is outdated and unsuitable (Shin, 2023). Nevertheless, the fact that this debate even took place already shows the tremendous progress of AI development that calls for comparisons against human capabilities, while it also highlights how we need innovative and dependable rubrics or mechanisms for assessing AI.

In short, the assessment of an emergent technology such as generative AI possibly requires the design and development of newer and novel mechanisms. Considering GPT-3 was already released in 2020 as OpenAI’s large language model that can interpret responses and respond using its model of more than 175 billion parameters (Floridi & Chiriatti, 2020), it is not surprising that newer versions of GPT-4 (OpenAI, 2023) and GPT-5 will have even more robust capabilities, let alone cognitive dynamics, that will be difficult to assess. This field is also nascent and emergent, but potential work has already been proposed. For example, designs and practices for sustainable student discourse and knowledge creation are already in place (e.g., Lee et al., 2023), and cognitive dynamics of generative AI can potentially be assessed thorough the scrutiny of underlying psychological principles and delving into factors that captivate user attention (Luan et al., 2023), which can inform and implicate ramifications on the future of learning.

# The need to stay ahead of the curve

The field of education is no exception, as AI transforms the world and evolves to become an integrated part of everyone’s lives. The adaptation of teaching practice for new affordances from emergent technologies are similar to how teaching and learning experiences of learners are enhanced with the power and mobility of technology from recent years (Crichton et al., 2012; Schuck et al., 2012). With AI, teachers are enabled to further personalize learning experiences and provide targeted feedback to help students succeed. However, these benefits are only attainable if teachers possess the literacy and understanding to stay ahead of the curve, by redrawing their existing boundaries and redefining their practices to meet new teaching norms and requirements while respecting AI for social good (Ng et al., 2021). When students consider such technological use in their learning, they will also require proper guidelines and literacy (Wong & Looi, 2023).

The use of AI, however, does not negate the need for teachers in classrooms, but rather emphasizes the need to have teachers play a pivotal role in shaping and moulding the way in which students interact with daily learning activities (Fahimirad & Kotamjani, 2018). In the context of education practices, AI is most likely not going to take over the role of the teacher, due to the way in which teaching and learning happens in the classroom, and the ways in which it is profoundly different from human intelligence that AI seeks to emulate (Cope et al., 2020). More importantly, AI tools and systems can complement and support teachers in lesson and course designs that improve humanistic aspects such as students’ communications and critical thinking skill development, through provision of formative feedback that are more timely, meaningful, and actionable (Lee et al., 2023).

# Method for answering of research questions

This paper is partially written as a position and reflection paper, drawing on contemporary and evidencebacked conclusions from literature to identify, question, and critically evaluate challenges and opportunities that arise during the use of generative AI. The references stem from both academic and grey literature, based on convenience sampling as a faster method for consolidating insights from recent articles and available literature within the last five years. Considering the nascent nature of generative AI-related studies that incorporate pedagogical insights, the goal is to stimulate new or useful understandings about the use of generative AI for learning in a time-critical manner for informing education stakeholders.

After identifying the challenges, opportunities, and common themes from the use of generative AI, another focus is to explore and exemplify the possible avenues of how one can stay head of the curve when confronted with the identified challenges and opportunities arising from the use of generative AI for learning. Although several of the proposed themes and guidelines originate from the experiential use of ChatGPT, the findings and implications are not limited to the GPT family of LLMs and can also apply to other technologies with functionalities akin to what ChatGPT has to offer.

# Answering research question 1: identifying five common themes (5Ts) from the use of generative AI and for research

It will be an understatement to claim that research, teaching, and learning will be affected with the emergent use of generative AI. From an increasing literature pertaining to generative AI that is continuously being added to an already vast repository of AI research, this paper identifies several common main themes from the use of generative AI with exemplars. This synthesis will hopefully be useful to better inform educators and for future research.

# Theme 1: generative AI as an enabler for automated and productive work

Due to the large language models utilized in generative AI, it has the capacity to process huge amounts of data and communicate its outputs in clear natural language. Therefore, it is most suitable to conduct summarization work in an automated manner and at scale with good accuracy and outcomes. Summarisation is considered an important and effective skill for learning in education (Friend, 2000) due to how the process reinforces connections among new ideas that needs to be learnt and helps create new connections between prior knowledge and the new ideas. The extent of possible summarizable content includes abstract text (Liu et al., 2018) and multi-document summarization (Kim & Yoon, 2022) based on generative adversarial networks (GANs), and video summarization based on GPT-2 that takes user inputs into consideration (Huang et al., 2021), thus providing only relevant video content that is of interest to users.

Together with summarization, the automation of mundane tasks has also provided the possibility of using generative AI for work on non-repetitive and creative work (Stevenson et al., 2022), and users have experienced positive effects on productivity after using ChatGPT to aid with their language skills, obtaining of useful resources and even to provide support and motivation (Fauzi et al., 2023). The ways in which huge amounts of information can be accessed and handled was also seen to be augmented from existing keyword-based searches because of the use of natural language-based query search with ChatGPT (Cadamuro et al., 2023; Firat, 2023).

# Theme 2: transparency-related issues remain

The reactions to the use of generative AI range from direct adoption and usage to outright bans by national institutes and universities (Xiao et al., 2023). These stances are understandably justified due to the novelty and suddenness of application but have also since softened over time as more information and knowledge of the generative AI’s functions are being accrued over time.

Since some of the drawbacks will also be explicated in other subsections, the focus in this subsection is on the issue of transparency in generative AI, which is believed to also be the root cause of other related drawbacks, such as concerns about ensuring proper and ethical use of generative AI (Lund & Wang, 2023), doubtful accuracy and unreliable outcomes from the model (Johnson et al., 2023), whether there are inherent or systemic biases in the models (Lucy & Bamman, 2021), and insufficient explainability of AI use that generates the outcomes (Guleria & Sood, 2023).

Like how traditional AI became more complex and opaquer over time, there is a need to apply principles of explainable AI (XAI) to the design and implementation of generative AI, where transparency is required to better understand of how the tools and implementations work, and not expect users to trust black boxes without questioning the underlying algorithm and reasoning (Dwivedi et al.,

2023). Attempts to do so have started to emerge (Yue et al., 2023), combining XAI with conversational models like ChatGPT to explain predictions made by nonlinear black box machine learning models.

To some users, the lack of immediacy is a detrimental factor for real-time work that taps on generative AI, especially since current implementations needs to depend on provided Application Programming Interfaces (APIs) and third-party implementations to keep developments up to date (Blain, 2023; Tarantola, 2023). This however also leads to the formation of unnecessary biases due to outdated information in pre-trained large language models. Although a time gap is necessary for pre-training processes to take place, it is expected to also narrow as technology advances significantly over time.

# Theme 3: originality and novelty are still treasured

Generative AI’s ability to synthesize content turns out to be one of the trickier features to be handled in education. The different ways in which content can be generated for student work have often converged into what many consider to be plagiarism, as students are likely using content pieced together by the AI, which is tapped from large language models that are trained from prior work that belongs to other people (McCoy et al., 2023). To some, this could be viewed as an ethical issue and potentially considered misuse, while others are leaving plagiarism checks to anti-plagiarism software to detect such instances in assignments and electronic examinations. Although educators are also on the hunt for such content with partial success (Perkins et al., 2023), the recommended approach will be to tweak assessment strategies to become more resistant to the evolutions of AI, or to use AIinclusive assessment when possible. An example of moving away from the more typical uses of AI for performative assessments of individual students to a more AI-inclusive manner, is to utilize AI for social and relational aspects of pedagogy that are the hallmarks of inclusion (Serholt, 2019).

# Theme 4: users are still important partners in generative AI-related work

To effectively tap on affordances from generative AI, it is also dependent on the users, how they approach a given task, and the way in which they consider the circumstances to deploy generative AI. For example, a naive implementation due to the lack of understanding of an AI method or algorithm can generate results that can be misinterpreted and misunderstood, therefore leading to cascading problems. Therefore, even though generative AI was created with intentions to benefit society, it is still essential to ensure that AI literacy, as a means and set of skills to enable individuals to learn about and work with AI-related activities, is provided to ensure that AI users can know and understand, appropriately apply, and evaluate technologies as potent as generative AI (Ng et al., 2021).

Picking up AI literacy is likely to be a continuous and arduous process, with prior studies involving K-12 students already attempting to use scaffolds to aid them in understanding AI concepts, via syntax-based programming (e.g., Wong et al., 2020) and using gamified and social media tools (e.g., Ng, 2020). The education of general users and researchers in this endeavour is essential to strengthen their social responsibility, and to also consider social inclusion and diversity when applying AI for societal good (Dignum, 2019).

# Theme 5: Re-examine competencies or be replaced

Even in education, international perspectives reveal that teachers worry that their jobs will be replaced by AI (Felix, 2020), similarly felt in other settings (Oh et al., 2017), as some teachers realize what they are doing in schools are routine and robots are equally capable of performing what they are doing (Coombs et al., 2021). Just as how sewing machines have replaced the need for manual sewing, it however did not eliminate the position of the seamstress who helps to use the machine to assemble clothing at a faster pace. Teachers likewise will eventually need to recognize the fact that they will need to re-examine their existing competencies in a dynamic world, as students are possibly able to even out-skill the teachers themselves if the teachers do not upskill themselves.

# Answering research question 2: how does one stay ahead of the curve – proposed 3 $\mathbf { \prime } _ { \mathbb { R } ^ { \prime } }$ guidelines

The identified themes may have showed some signs of disruption on teaching and learning, but the impact from ChatGPT’s use is likely only the beginning of how generative AI may significantly alter the way in which education functions in the future. Generative AI is likely here to stay and thus there is an increasing demand to be able to design and institute new practices and procedures for managing the issues brought about by it (Sullivan et al., 2023). The following three $\mathbf { \chi } ^ { \prime \prime } \mathbf { \Sigma } ^ { \prime \prime }$ guidelines are proposed as part of a rethink and discussion of how educators, students and even policymakers can continue to be relevant in a dynamic learning environment with emerging technologies.

# R1: Re-tuning assessment of student work and student development to match emerging needs

There are several aspects in which the impact is likely to be more significant than others, the first being the assessment of students work and how students develop in the new age of AI. Before the rollout of ChatGPT at the end of 2022, educators can competently mitigate the impact of plagiarism in students’ work by banking on teachers’ experience to spot blatant plagiarism and with the help of anti-plagiarism software (e.g., Turnitin, Grammarly, Unicheck) to provide a similarity score that indicates how much of a submitted text is similar to content from a database of current and archived content, extracted from the internet or from a repository of previously submitted works. This default course of action centred around academic integrity was seen to be fair use by both teachers and students with the same goal in preventing plagiarism (Atkinson & Yeoh, 2008), but with students using ChatGPT to synthesize answers to their own work, the evaluation of a finished assignment as summative assessment is no longer considered reliable.

What this emergent trend calls for is the need to explore alternative strategies that involves and integrates formative and digital-free components into assessment, such as interactive oral presentations and design of student portfolios to better gauge students’ understandings and quality of work. This course of action ensures that students can be fairly assessed during these forms of alternate presentations and expressions of work, showcasing how they synergize with the online component of work that they have supposedly developed and worked on, with an underlying opportunity for educators to verify that students completed their own work without significant reliance on generative AI. For example, students who cannot explain their work with adequate explanations or display a mismatch of competencies between online and offline components of work are likely utilizing ChatGPT’s results without thoughtful considerations or use.

On the flipside, there are also opportunities for authentic learning and assessment to take place, by not avoiding generative AI and instead leveraging the technology (e.g., Farrokhnia et al., 2023; Kasneci et al., 2023) to generate diversified responses that a class of students may not be able to provide, thus providing an authentic learning environment where students could be exposed to real problems sourced from large language models. Students will then need to demonstrate their deep understanding, higher-order thinking, and complex problem solving through the performance of exemplary tasks (Koh, 2017).

Regardless of use cases, there should not be an over-dependence on AI that may result in a decline in the mentioned higher-order cognitive skills (Farrokhnia et al., 2023), and it is imperative that focus still be given to the development of higher-order learning outcomes such as creativity and critical thinking skills when planning lessons and learning activities (González-Pérez & Ramírez

Montoya, 2022). For example, assigning written tasks may no longer provides the assessment result that most teachers sought after, but by leveraging AI to provide adaptive learning for promoting higher-order learning outcomes (Gašević et al., 2023), it is plausible to still design learning tasks that support higher-order learning outcomes.

# R2: Re-educating educators and students in terms of data and AI literacy

The use of data and AI technologies is no longer limited to just computer scientists and researchers but are also now relevant to many school subjects. Existing education frameworks are likely to undergo revamps to incorporate AI literacy, but AI cannot be appropriately grasped without data literacy, which is akin to trying to run before learning to walk. Hence, there needs to be a reconsideration of frameworks that holistically address how data lifecycles can be used to reflect on data literacy competencies relevant to AI (Olari & Romeike, 2021) and this will be ideally a comprehensive approach to the education of educators and students.

More specifically, on one hand, within the boundaries of a classroom of educators and students, students face the dilemma of either using ChatGPT cautiously or avoiding it entirely to avoid scrutiny of their academic success. With the belief that AI may become a major part of new practices and how students learn in the near future (Sullivan et al., 2023), students should be informed of the capabilities of ChatGPT, be allowed to experiment and to satiate their curiosity, and be fully aware of the limitations for education purposes (Ray, 2023).

On the other hand, educators should tap on the potential of ChatGPT to create educational content, improve student interaction and engagement, and to personalize learning experiences. For example, the automated creation of quizzes from large language models not only alleviates the manual labour of quiz design, but also allows students to continuously test their knowledge while learning from textbooks and during exam preparations (Dijkstra et al., 2022). This serves as a persistent testing tool similar to a chatbot but with productive interactions that can aid learning, notwithstanding the possibility that some responses may be based on false information, but the benefits of this tool should heavily outweigh this drawback.

In the long run, consistent disruption and change may become commonplace especially in dynamic learning environments. A possible way of anticipating such disruptions will be the need to continuously attain skills that cannot be easily disrupted by AI developments. In retrospect, the emergence of generative AI may have been an opportune time for in-depth reflection on how educators can continue to be key contributors to students’ learning and for students to also realize how they can leverage AI for better learning. This requires the design of learning for students to develop soft skills such as critical and creative thinking, complex problem-solving, using new digital resources (Pappas & Giannakos, 2021).

# R3: Re-tweaking existing frameworks and principles for research, practice, and policy

When educators and students are brought together in settings such as higher education institutes and universities, there needs to be consistent policies and guidelines from universities and institutes of higher education to instil appropriate practices that both educators and students can conduct for academic work. While educators should proactively engage students in underscoring the significance of academic integrity and consequence of malpractice during courses (Perkins, 2023), common guidelines for students should stipulate responsible references to authoritative sources (Halaweh, 2023) with caution on the limitations of generative AI.

In consideration of long-term implications and repercussions, it might even be beneficial to reconsider if intelligent tutor systems (ITS) and educational chatbots can play a larger role in the teaching and learning processes in universities. The underlying technologies started in the 1960s and recent developments have already been studied for some time, showing that ITS and educational chatbots are more than just information retrieval tools, but also one that facilitates learning and amplifies information (Shawar & Atwell, 2007). With multiple instances showing how ITS and educational chatbots can assist in learning under conditions similar to those of a human tutor (Pérez et al., 2020), perhaps it is now an appropriate time for ITS and educational chatbots to be considered viable educational tools that complement educators, and not replace them.

For an integrated approach to education, one that is based on the inclusion of significant technological reforms (e.g., learning analytics, AI in education, and AI literacy in mainstream teaching and learning; Lee et al., 2023), new and existing frameworks can be modelled after the four pillars of Education for the 21st century that Delors (1996) referred to the United Nations Educational, Scientific and Cultural Organization (UNESCO). This framework is based on the four principles: learning to know, learning to do, learning to be, and learning to live together. In relation to the use of generative AI and using ChatGPT as an exemplar, it is already viewed as an alternative source of knowledge to some learners, with designed steps and recognized methods (e.g., prompt engineering) to aid usage. ChatGPT has also been utilized as a reflection platform and mechanism to help users learn to be, while allowing users to also interact and understand other’s cultural differences and contexts. These principles could be used to support initial infrastructure required for the meaningful design and development of good and effective learning activities, with AI as a reliable and trustworthy learning partner.

# Conclusion

It might be said that teaching and learning in the past few decades may have been nothing less than transformative, given how the internet has provided connectivity between learners and digitalized materials are almost instantly accessible to all. The development and use of AI as a result has also seen a resurgence with the need to handle big data obtained via classrooms and shared data repositories, and the emergence of generative AI has offered a significant boost to how teaching and learning can be improved in education settings.

This paper has identified five common themes (5Ts) that have arisen from the use of generative AI for learning and future research, along with ways of how one can stay ahead when confronted with challenges and opportunities related to generative AI. Possible avenues of actions are proposed and are represented by three $\mathbf { \chi } ^ { \prime \prime } \mathbf { \mathbb { R } } ^ { \prime \prime }$ guidelines – re-tuning assessment of student work and student development to match emerging needs, re-educating educators and students in terms of data and AI literacy, and re-tweaking existing frameworks and principles for research, practice, and policy.

Owing to the emergent nature of ongoing technological disruptions to the education landscape, other themes apart from the mentioned 5Ts may emerge. Nonetheless, this paper has consolidated and emphasizes existential themes that are predominantly common across the board and also provides a set of guidelines that should stand the test of time in framing how one should view the immersion of generative AI (or AI in general) in education and to be able to stay ahead.

In all, the future of knowledge work should be one where humans and artificial agents are able to collaborate (Siemens et al., 2022), where educators and students should not replicate what AI already does, but rather coordinate on what can be done to create and enhance meaningful learning experiences for learners. The challenges arising from generative AI and similar upcoming developments are likely to persist, but emerging opportunities will also be available, and therefore it is critical for both educators and students to stay ahead of the curve in addressing challenges and embracing opportunities.

# Acknowledgements

The views expressed in this paper are the author’s and do not necessarily represent the views of the host institution.

# Disclosure statement

No potential conflict of interest was reported by the author(s).

# Funding

The author(s) reported there is no funding associated with the work featured in this article.

# Notes on contributor

Alwyn Vwen Yen Lee is an education research scientist and lecturer at the National Institute of Education, Nanyang Technological University, Singapore. His main research and teaching interests are in Artificial Intelligence in education (AIED), learning analytics, knowledge building, technology-supported assessment (TSA), and Internet of Things (IoT).

# ORCID

Alwyn Vwen Yen Lee $\textcircled{1}$ http://orcid.org/0000-0002-3682-017X

# Data availability statement

There is no data from this paper to be shared or deposited.

# References

Atkinson, D., & Yeoh, S. (2008). Student and staff perceptions of the effectiveness of plagiarism detection software. Australasian Journal of Educational Technology, 24(2), 222–240. https://doi.org/10.14742/ajet.1224   
Barnes, B., Koblin, J., & Sperling, N. (2023, July 13). Actors Join Writers on Strike, Bringing Hollywood to a Standstill. Retrieved July 5, 2023 from https://www.nytimes.com/2023/07/13/business/media/sag-aftra-writers-strike.html   
Bian, Y., & Xie, X.Q. (2021). Generative chemistry: Drug discovery with deep learning generative models. Journal of Molecular Modeling, 27(3), 1–18. https://doi.org/10.1007/s00894-021-04674-8   
Biever, C. (2023, July 25). ChatGPT Broke the Turing Test — the Race is on for New Ways to Assess AI. Retrieved August 1, 2023 from https://www.nature.com/articles/d41586-023-02361-7   
Biswas, S.S. (2023). Potential use of chat GPT in global warming. Annals of Biomedical Engineering, 51(6), 1126–1127. https://doi.org/10.1007/s10439-023-03171-8   
Blain, L. (2023, March 24). ChatGPT can now access the internet and run the code it writes. Retrieved July 5, 2023 from https://newatlas.com/technology/chatgpt-plugin-internet-access/   
Blinder, A. (2009). Education for the third industrial revolution. In D. Goldhaber & J. Hannaway (Eds.), Creating a new teaching profession (pp. 15–28). Urban Institute Press.   
Buchanan, B.G. (2005). A (very) brief history of artificial intelligence. AI Magazine, 26(4), 53–60. https://doi.org/10.1609/ aimag.v26i4.1848   
Cadamuro, J., Cabitza, F., Debeljak, Z., De Bruyne, S., Frans, G., Perez, S.M., Ozdemir, H., Tolios, A., Carobene, A., & Padoan, A. (2023). Potentials and pitfalls of ChatGPT and natural-language artificial intelligence models for the understanding of laboratory medicine test results. An assessment by the European federation of clinical chemistry and laboratory medicine (EFLM) working group on artificial intelligence (WG-AI). Clinical Chemistry and Laboratory Medicine, 61(7), 1158–1166. https://doi.org/10.1515/cclm-2023-0355   
Collins, A., & Halverson, R. (2018). Rethinking education in the age of technology: The digital revolution and schooling in America. Teachers College Press.   
Coombs, C., Stacey, P., Kawalek, P., Simeonova, B., Becker, J., Bergener, K., Carvalho, J.Á., Fantinato, M., GarmannJohnsen, N.F., Grimme, C., Stein, A., & Trautmann, H. (2021). What is it about humanity that we can’t give away to intelligent machines? A European perspective. International Journal of Information Management, 58, 102311. https:// doi.org/10.1016/j.ijinfomgt.2021.102311   
Cooper, G. (2023). Examining science education in ChatGPT: An exploratory study of generative artificial intelligence. Journal of Science Education and Technology, 32(3), 444–452. https://doi.org/10.1007/s10956-023-10039-y   
Cope, B., Kalantzis, M., & Searsmith, D. (2020). Artificial intelligence for education: Knowledge and its assessment in AI-enabled learning ecologies. Educational Philosophy and Theory, 53(12), 1229–1245. https://doi.org/10.1080/ 00131857.2020.1728732 proje arning, 10(1),   
De Cremer, D., & Kasparov, G. (2021, March 18). AI should augment human intelligence, not replace it. Harvard Business Review. https://www.daviddecremer.com/wp-content/uploads/HBR2021_AI-Should-Augment-Human-IntelligenceNot-Replace-It.pdf   
Delors, J. (1996). Learning: The treasure within. UNESCO.   
Devlin, J., Chang, M.W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv. https://doi.org/10.48550/arXiv.1810.04805   
Dignum, V. (2019). Responsible artificial intelligence: How to develop and use AI in a responsible way. Springer.   
Dijkstra, R., Genc, Z., Kayal, S., & Kamps, J. (2022). Reading Comprehension Quiz Generation using Generative Pre-trained Transformers. Accessed 10 October 2023. https://www.e.humanities.uva.nl/publications/2022/dijk_read22.pdf   
Dwivedi, R., Dave, D., Naik, H., Singhal, S., Omer, R., Patel, P., Qian, B., Wen, Z., Shah, T., Morgan, G., & Ranjan, R. (2023). Explainable AI (XAI): Core ideas, techniques, and solutions. ACM Computing Surveys, 55(9), 1–33. https://doi.org/10. 1145/3561048   
Fahimirad, M., & Kotamjani, S.S. (2018). A review on application of artificial intelligence in teaching and learning in educational contexts. International Journal of Learning and Development, 8(4), 106–118. https://doi.org/10.5296/ijld. v8i4.14057   
Farrokhnia, M., Banihashem, S.K., Noroozi, O., & Wals, A. (2023). A SWOT analysis of ChatGPT: Implications for educational practice and research. Innovations in Education and Teaching International, 1–15. https://doi.org/10.1080/14703297. 2023.2195846   
Fauzi, F., Tuhuteru, L., Sampe, F., Ausat, A.M.A., & Hatta, H.R. (2023). Analysing the role of ChatGPT in improving student productivity in higher education. Journal on Education, 5(4), 14886–14891. https://doi.org/10.31004/joe.v5i4.2563   
Felix, C.V. (2020). The role of the teacher and AI in education. In E. Sengupta, P. Blessinger, & M.S. Makhanya (Eds.), International perspectives on the role of technology in humanizing higher education (pp. 33–48). Emerald Publishing Limited. https://doi.org/10.1108/S2055-364120200000033003   
Firat, M. (2023). How chat GPT can transform autodidactic experiences and open education? OSF Preprints. https://doi. org/10.31219/osf.io/9ge8m   
Floridi, L., & Chiriatti, M. (2020). GPT-3: Its nature, scope, limits, and consequences. Minds and Machines, 30(4), 681–694. https://doi.org/10.1007/s11023-020-09548-1   
Friend, R. (2000). Teaching summarization as a content area reading strategy. Journal of Adolescent & Adult Literacy, 44 (4), 320–329.   
Gašević, D., Siemens, G., & Sadiq, S. (2023). Empowering learners for the age of artificial intelligence. Computers and Education: Artificial Intelligence, 4, 100130. https://doi.org/10.1016/j.caeai.2023.100130   
González-Pérez, L.I., & Ramírez-Montoya, M.S. (2022). Components of education 4.0 in 21st century skills frameworks: Systematic review. Sustainability, 14(3), 1493. https://doi.org/10.3390/su14031493   
Guleria, P., & Sood, M. (2023). Explainable AI and machine learning: Performance evaluation and explainability of classifiers on educational data mining inspired career counseling. Education and Information Technologies, 28(1), 1081–1116. https://doi.org/10.1007/s10639-022-11221-2   
Halaweh, M. (2023). ChatGPT in education: Strategies for responsible implementation. Contemporary Educational Technology, 15(2), ep421. https://doi.org/10.30935/cedtech/13036   
Haristiani, N. (2019, November). Artificial intelligence (AI) chatbot as language learning medium: An inquiry. Journal of Physics Conference Series, 1387(1), 012020. https://doi.org/10.1088/1742-6596/1387/1/012020   
Huang, J.H., Murn, L., Mrak, M., & Worring, M. (2021, August). Gpt2mvs: Generative pre-trained transformer-2 for multi-modal video summarization. Proceedings of the 2021 International Conference on Multimedia Retrieval, 580–589. https://doi.org/10.1145/3460426.3463662   
Johnson, D., Goodman, R., Patrinely, J., Stone, C., Zimmerman, E., Donald, R., Wheless, L., Chang, S., Berkowitz, S., Finn, A., Jahangir, E., & Scoville, E. (2023). Assessing the accuracy and reliability of AI-generated medical responses: An evaluation of the chat-GPT model. Researchsquare. https://doi.org/10.21203/rs.3.rs-2566942/v1   
Kasneci, E., Seßler, K., Küchemann, S., Bannert, M., Dementieva, D., Fischer, F., Kasneci, E., Gasser, U., Groh, G., Günnemann, S., Hüllermeier, E., Krusche, S., Kutyniok, G., Michaeli, T., Nerdel, C., Pfeffer, J., Poquet, O., Sailer, M., Schmidt, A., Seidel, T., & Kuhn, J.. . . Kasneci, G. (2023). ChatGPT for good? On opportunities and challenges of large language models for education. Learning and Individual Differences, 103, 102274. https://doi.org/10.1016/j.lindif. 2023.102274   
Kim, S., & Yoon, B. (2022). Multi-document summarization for patent documents based on generative adversarial network. Expert Systems with Applications, 207, 117983. https://doi.org/10.1016/j.eswa.2022.117983   
Koh, K.H. (2017). Authentic assessment. Oxford research encyclopedia of education. https://doi.org/10.1093/acrefore/ 9780190264093.013.22   
Lee, A.V.Y. (2023). Supporting students’ generation of feedback in large-scale online course with artificial intelligenceenabled evaluation. Studies in Educational Evaluation, 77, 101250. https://doi.org/10.1016/j.stueduc.2023.101250   
Lee, A.V.Y., Koh, E., & Looi, C.K. (2023). AI in education and learning analytics in Singapore: An overview of key projects and initiatives. Information and Technology in Education and Learning, 3(1), Inv–p001. https://doi.org/10.12937/itel.3. 1.Inv.p001   
Lee, A.V.Y., Luco, A.C., & Tan, S.C. (2023). A human-centric automated essay scoring and feedback system for the development of ethical reasoning. Educational Technology & Society, 26(1), 147–159. https://doi.org/10.30191/ETS. 202301_26(1).0011   
Lee, A.V.Y., Tan, S.C., & Teo, C.L. (2023). Designs and practices using generative AI for sustainable student discourse and knowledge creation. Smart Learning Environments, 10(1), 59. https://doi.org/10.1186/s40561-023-00279-1   
Liu, L., Lu, Y., Yang, M., Qu, Q., Zhu, J., & Li, H. (2018, April). Generative adversarial network for abstractive text summarization. Proceedings of the AAAI Conference on Artificial Intelligence, 32(1), 8109–8110. https://doi.org/10. 1609/aaai.v32i1.12141   
Lo, C.K. (2023). What is the impact of ChatGPT on education? A rapid review of the literature. Education Sciences, 13(4), 410. https://doi.org/10.3390/educsci13040410   
Luan, L., Lin, X., & Li, W. (2023). Exploring the cognitive dynamics of artificial intelligence in the post-COVID-19 and learning 3.0 Era: A case study of ChatGPT. arXiv. https://doi.org/10.48550/arXiv.2302.04818   
Lucy, L., & Bamman, D. (2021, June). Gender and representation bias in GPT-3 generated stories. In Proceedings of the Third Workshop on Narrative Understanding (pp. 48–55). Association for Computational Linguistics. https://doi.org/10. 18653/v1/2021.nuse-1.5   
Lund, B.D., & Wang, T. (2023). Chatting about ChatGPT: How may AI and GPT impact academia and libraries? Library Hi Tech News, 40(3), 26–29. https://doi.org/10.1108/LHTN-01-2023-0009   
McCarthy, J., Minsky, M.L., Rochester, N., & Shannon, C.E. (2006). A proposal for the Dartmouth summer research project on artificial intelligence. AI Magazine, 27(4), 12–14. https://doi.org/10.1609/aimag.v27i4.1904   
McCoy, R.T., Smolensky, P., Linzen, T., Gao, J., & Celikyilmaz, A. (2023). How much do language models copy from their training data? evaluating linguistic novelty in text generation using raven. Transactions of the Association for Computational Linguistics, 11, 652–670. https://doi.org/10.1162/tacl_a_00567   
Naveed, H., Khan, A.U., Qiu, S., Saqib, M., Anwar, S., Usman, M., Barnes, N., & Mian, A. (2023). A comprehensive overview of large language models. arXiv. https://doi.org/10.48550/arXiv.2307.06435   
Ng, T.K. (2020). New interpretation of extracurricular activities via social networking sites: A case study of artificial intelligence learning at a secondary school in Hong Kong. Journal of Education and Training Studies, 9(1), 49–60. https://doi.org/10.11114/jets.v9i1.5105   
Ng, D.T.K., Leung, J.K.L., Chu, K.W.S., & Qiao, M.S. (2021). AI literacy: Definition, teaching, evaluation and ethical issues. Proceedings of the Association for Information Science and Technology, 58(1), 504–509. https://doi.org/10.1002/pra2.487   
Oh, C., Lee, T., Kim, Y., Park, S., Kwon, S., & Suh, B. (2017, May). Us vs. them: Understanding artificial intelligence technophobia over the Google DeepMind challenge match. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (pp. 2523–2534). https://doi.org/10.1145/3025453.3025539   
Olari, V., & Romeike, R. (2021, October). Addressing AI and data literacy in teacher education: A review of existing educational frameworks. The 16th workshop in primary and secondary computing education, pp. 1–2. ACM, https://doi. org/10.1145/3481312.3481351 .   
OpenAI. (2022, November 30). Introducing ChatGPT. Retrieved July 5, 2023, from https://openai.com/blog/chatgpt   
OpenAI. (2023, July 6). GPT-4 API General Availability and Deprecation of Older Models in the Completions API. Retrieved August 1, 2023 from https://openai.com/blog/gpt-4-api-general-availability   
Owston, R.D. (1997). Research news and comment: The world wide web: A technology to enhance teaching and learning? Educational Researcher, 26(2), 27–33. https://doi.org/10.3102/0013189X026002027   
Pappas, I.O., & Giannakos, M.N. (2021). Rethinking learning design in IT education during a pandemic. Frontiers in Education, 6, 652856. https://doi.org/10.3389/feduc.2021.652856   
Pérez, J.Q., Daradoumis, T., & Puig, J.M.M. (2020). Rediscovering the use of chatbots in education: A systematic literature review. Computer Applications in Engineering Education, 28(6), 1549–1565. https://doi.org/10.1002/cae.22326   
Perkins, M. (2023). Academic integrity considerations of AI large language models in the post-pandemic era: ChatGPT and beyond. Journal of University Teaching & Learning Practice, 20(2), 07. https://doi.org/10.53761/1.20.02.07   
Perkins, M., Roe, J., Postma, D., McGaughran, J., & Hickerson, D. (2023). Game of tones: Faculty detection of GPT-4 generated content in university assessments. arXiv. https://doi.org/10.48550/arXiv.2305.18081   
Psiropoulos, D., Barr, S., Eriksson, C., Fletcher, S., Hargis, J., & Cavanaugh, C. (2016). Professional development for iPad integration in general education: Staying ahead of the curve. Education and Information Technologies, 21(1), 209–228. https://doi.org/10.1007/s10639-014-9316-x   
Qadir, J. (2023, May). Engineering education in the era of ChatGPT: Promise and pitfalls of generative AI for education. In 2023 IEEE Global Engineering Education Conference (EDUCON) (pp. 1–9). IEEE. https://doi.org/10.1109/EDUCON54358. 2023.10125121   
Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). Improving language understanding by generative pre-training. Technical report, OpenAI.   
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., & Liu, P.J. (2020). Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research, 21(1), 5485–5551.   
Ray, P.P. (2023). ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope. Internet of Things and Cyber-Physical Systems, 3, 121–154. https://doi.org/10.1016/j.iotcps.2023.04.003   
Resnick, M., Berg, R., & Eisenberg, M. (2000). Beyond black boxes: Bringing transparency and aesthetics back to scientific investigation. Journal of the Learning Sciences, 9(1), 7–30. https://doi.org/10.1207/s15327809jls0901_3   
Rudolph, J., Tan, S., & Tan, S. (2023). ChatGPT: Bullshit spewer or the end of traditional assessments in higher education? Journal of Applied Learning & Teaching, 6(1). https://doi.org/10.37074/jalt.2023.6.1.9   
Scepanovič, S. (2019, June). The fourth industrial revolution and education. In 2019 8th Mediterranean Conference on Embedded Computing (MECO) (pp. 1–4). IEEE. https://doi.org/10.1109/MECO.2019.8760114   
Schuck, S., Aubusson, P., Kearney, M., & Burden, K. (2012). Mobilising teacher education: A study of a professional learning community. Teacher Development, 17(1), 1–18. https://doi.org/10.1080/13664530.2012.752671   
Serholt, S. (2019). Interactions with an empathic robot tutor in education: Students’ perceptions Three Years Later. In J. Knox, Y. Wang, & M. Gallagher (Eds.), Artificial intelligence and inclusive education. Perspectives on rethinking and reforming education. Springer. https://doi.org/10.1007/978-981-13-8161-4_5   
Shawar, B. A., & Atwell, E. (2007). Chatbots: Are they really useful? Journal for Language Technology and Computational Linguistics, 22(1), 29–49. https://doi.org/10.21248/jlcl.22.2007.88   
Shin, R. (2023, June 21) The Turing Test for Measuring A.I. Intelligence is Outdated Because of ChatGPT’s Wizardry, and a New Test Would Be Better, DeepMind Cofounder Says. Retrieved August 1, 2023 from https://fortune.com/2023/06/ 20/turing-test-proposed-update-ai-chatgpt-deepmind-cofounder/   
Siemens, G., Marmolejo-Ramos, F., Gabriel, F., Medeiros, K., Marrone, R., Joksimovic, S., & de Laat, M. (2022). Human and artificial cognition. Computers and Education: Artificial Intelligence, 3, 100107. https://doi.org/10.1016/j.caeai.2022.100107   
Sousa, D.A. (2016). How the brain learns. Corwin Press.   
Stevenson, C., Smal, I., Baas, M., Grasman, R., & van der Maas, H. (2022). Putting GPT-3‘s creativity to the (alternative uses) test. arXiv. https://doi.org/10.48550/arXiv.2206.08932   
Sullivan, M., Kelly, A., & McLaughlan, P. (2023). ChatGPT in higher education: Considerations for academic integrity and student learning. Journal of Applied Learning & Teaching, 6(1), 1–10. https://doi.org/10.37074/jalt.2023.6.1.17   
Surameery, N.M.S., & Shakor, M.Y. (2023). Use chat GPT to solve programming bugs. International Journal of Information Technology & Computer Engineering, 3(1), 17–22. https://doi.org/10.55529/ijitc.31.17.22   
Su, J., & Yang, W. (2022). Artificial intelligence in early childhood education: A scoping review. Computers and Education: Artificial Intelligence, 3, 100049. https://doi.org/10.1016/j.caeai.2022.100049   
Tarantola, A. (2023, March 23). ChatGPT’s new plugins will deliver real-time stats. Retrieved July 5, 2023 from https:// www.engadget.com/chatgpts-new-plugins-will-deliver-real-time-stats-182900388.html   
Terwiesch, C. (2023). Would Chat GPT3 Get a Wharton MBA? A Prediction Based on Its Performance in the Operations Management Course. Mack Institute for Innovation Management at the Wharton School, University of Pennsylvania. Retrieved July 5, 2023 from https://mackinstitute.wharton.upenn.edu/wp-content/uploads/2023/01/ChristianTerwiesch-Chat-GTP.pdf   
Turing, A.M. (1950). Computing machinery and intelligence. Mind, 59(236), 433–460. https://doi.org/10.1093/mind/LIX. 236.433   
Wong, L.H., & Looi, C.K. (2023, April 4). Commentary: Want ChatGPT to do your homework? Learn how to use it first. Channel NewsAsia. https://www.channelnewsasia.com/commentary/chatgpt-schools-students-teachers-educationsingapore-ai-literacy-3338881   
Wong, G.K., Ma, X., Dillenbourg, P., & Huan, J. (2020). Broadening artificial intelligence education in K-12: Where to start? ACM Inroads, 11(1), 20–29. https://doi.org/10.1145/3381884   
Xiao, P., Chen, Y., & Bao, W. (2023). Waiting, banning, and embracing: An empirical analysis of adapting policies for generative AI in higher education. arXiv. https://doi.org/10.2139/ssrn.4458269   
Yue, T., Au, D., Au, C.C., & Iu, K.Y. (2023). Democratizing financial knowledge with ChatGPT by OpenAI: Unleashing the power of technology. SSRN Electronic Journal, 4346152. https://doi.org/10.2139/ssrn.4346152