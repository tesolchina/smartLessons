# Informal professional learning through collaborative action research: Fostering backstage dialogue among new EAP teachers

Teck Heng Tana,\*, Woon Hong Eunice Tanb

a NUS College, National University of Singapore, Singapore b Language and Communication Centre, Nanyang Technological University, Singapore

# ARTICLEINFO

# ABSTRACT

Handling Editor: Guangwei Hu

Keywords:   
Backstage   
Collaborative action research   
Dialogic   
Professional development   
Rubric design   
Teacher training

Researchers agree that informal professional learning is crucial for developing new EAP teachers' expertise, but there exist few teacher-centred accounts of how context-specific projects and practices create favourable conditions for such learning. Through presenting and analysing a collaborative action research (CAR) project, this paper illustrates how CAR can facilitate informal learning among new EAP teachers. The project was conducted in the context of a large-scale EAP course at a Singaporean university, where three teachers, each possessing under three years' experience teaching EAP, co-created an 11-page analytic rubric and reflected on their collaboration. Drawing on the written reflections of these three teachers, this paper examines how collaborative rubric development created a "backstage' setting where teachers engaged in trusting and stimulating dialogue, aimed at addressing shared concerns surrounding performance expectations and scoring practices. Through the process of drafting, revising, disseminating, and using the rubric, the three teachers clarified and adjusted their own assessment-related beliefs and practices, reflected on the limits of using rubrics to align assessment standards, and experimented with different methods of sharing their findings with other teachers. In the process, the rubric was reinvented as a dialogical tool that enabled teachers to scaffold professional learning for each other.

# 1. Introduction

English for Academic Purposes (EAP) refers to teaching and research that address the communicative needs of students in higher education (Hyland & Shaw, 2016). EAP teachers support students in acquring academic literacy, which includes both textual and social dimensions. This acquisition of academic literacy may begin with a text-centred approach, wherein students are taught to understand, apply, and even citique the discoursal conventions of written genres within and across isciplines; however, this process also involves social practice, in that students re re-orienting thmselves to the world through disciplinary discourses (Hyland, 2018, p. 384). The complexity of teaching EAP requires teachers to develop expertise across multiple domains, including aplied linguistics, education research, and target disciplines (Hyland, 2018).

The broad range of expertise needed for teaching EAP presents challnges for teacher training. Researchers have found that standardised approaches to profesional learning are ineffective due to the varied needs of EAP teachers and the diverse educational contexts within which they operate (Fitzpatrck et al., 2022); therefore, long-term, on-the-job informal learning is crucial for new teachers to develop their expertise (Campion, 2016). Such learning should ideally be bottom-up, collaborative, and independent of authority (Ding & Bruce, 2017; Leung, 2009; Mann, 2005). Despite this, there exis few teacher-centred acounts of how informal learning can be initiated, sructured, and sustained (Ding & Bruce, 2017; Ding & Campion, 2016). While some scholars have studied how EAP teachers conceive of and develop their expertise (e.g. Campion, 2016; Fitzpatrick et al., 2022), ther studies typically rely on what teachers are rporting in surveys and interviews acrossdifferent contexts. Such forms of eicited data do not reveal how teachers address ssues in authentic practice (Bao et al., 2024), or how context-secific projects and practces create favourable conditions for informal learning.

In response to the lack of teacher-centred and context-specific accounts of how informal learning can be facilitated, this paper presents and analyses collborative action rearch (CAR) project to ilustrate how CAR can promote informal learning among new EAP teachers. This project was conducted at a Singaporean university. It involved thre teachers, each of whom possessed under three years' experience teaching EAP, who co-created a rubric for a frst-year undergraduate EAP course, before reflecting on their collaboration. In line with reconised CAR practice, thethreeteachers functioned as both reearchers and participants inthe project, two of them co-authored this present paper. This paper scrutinises how the general principles underlying CAR, and the practices specific to this project, transformed an authentic professonal task-rubric development-into a conducive activity for informal learning.

# 2. Literature review

# 2.1. Defining CAR

CAR is a form of action research (AR). In educational sttings, AR refers to teacher-led inquiry that adapts pedagogical research to address ssues that arise in teaching and lerning (urns, 2010). As McTaggart (191) explains, AR requires teachers to test and modfy research-informed solutions for localised issues through the action of reflective practice. Oftentimes, new issues arise during AR, so teachers may adapt their plans intuitively by drawing on tacit knowledge or by responding to their students needs (Burns & Williams 2023). Such flexible uses f theory for practice (Buns, 2010, p. 14) generate "personal knowledge (Polanyi, 2012) that isubjective, context-specific, experience-based, and informed by one's values (McNiff & Whitehead, 2002). However, such personal knowledge should also be further theorised and strengthened by drawing on existing research, before its dissemination to a larger community (Burns, 2010).

What makes educational AR collborativ is when research is conducted by or with (rather than on) multiple teachers, staff, and students (Burns, 199). For this paper, our definition and use of the term \*CAR" include related approaches such as \*cooperative inquiry" (Greenwood & Kell, 2020) and \*participatory action research" (Alam, 2020). Such approaches require teachers to engage with issues not merely through "task division, but through the genuine consideration and incorporation of sugestions from other participants (Messiou, 2019, p. 201). As Diaz-Maggioli (2023) explains, task division is merely a cooperative approach, where par. ticipants work in isolation before compiling their work to achieve an immediate goal; contrastively, collaboration involves learning from each other's expertise, in ways that potentially exceed immediate goals.

# 2.2. CAR facilitates informal professional learning

Researchers have argued that \*informal, on-the-job learning" i crucial for new EAP teachers to develop their expertise (Ding & Bruce, 2017, p. 101), which may include activities like peer mentoring, lesson observations, and job shadowing (Fitzpatrick et al. 2022). Mann (2005) privileges informal learning of this nature, characterising it as "bottom-up efforts" that are usually self or community initiated, which sustain teachers' ongoing formation and revision of their pedagogical values (p. 105). Likewise, Leung (2009) argues for the cultivation of an \*independent professionalism that adopts a reflexive and critical stance towards top-down and received notions of professionalism (p. 53).

Informal learning of this variety can be facilitated by educational AR In her survey of 21 artices published since 2006, Edwards (2021) reports that AR benefits language teachers in the following ways: It ehances reflective practice develops their professional identities, increases intrinsic motivation and autonomy, and encourages collaborative effrts with colleagues. Mitchell e al. (2009) further argue that CAR in particular is more effective than professional seminars for developing expertise, especially when teachers trust each ther and share common goals, neds, and responsibilies. In such communitie, teachers are more likely to transform their uncertainties into knowledge by tapping on the wisdom of the crowd, opening themselves to criticism, experimenting with new approaches, supporting each other's development, and taking ownership of their learning (Mitchell et al, 2009). This form of collaborative learning recalls Vygotsky's (1978) asertion that learning involves a social aspect that requires interactions with pers and mentors (Matusov, 2001).

# 2.3. Backstage settings

Recently, educational researchers outside the field of CAR have theorised that informal professonal learning tends to take place in "backstage" settings. The term backstage," taken from Goffman (1959, is useful for distinguishing betwen frontstage communication within larger networks, where teachers position themselves professinall i relation to others, and backstage communication within smallr networks, where teachers incubate ideas before delivering them to the larger network (Roxa & Martensson, 2009). According to Roxa and Martensson's (2009) survey of 109 teachers, teachers are most likely to change their understanding and practice through \*significant conversations" with peers, which generally take place in backstage settings characterised by privacy, trust, intellectual curiosity, and mutual exchange of ideas (pp. 552-557). Their study shows that $8 3 \%$ of their respondents reported having such conversations with only up to 10 colleagues, and that such conversations were typically spontaneous and informal, involving two to three interlocutors at lunch, in a private office, or during a car ride.

Eikeland (2012) adds that as with theatre practice, backstage activity in educational contexts provides a space where teachers can shrug off their scripted frontstage roles, critically examine their daily performances with pers, and moot altenatives to existing practices. However, unlike Goffman (1959), who associates backstage settings with privacy, Eikeland conceives of backstage settings as a "counter-public sphere (Habermas, 1991; Negt & Kluge, 2016), where teachers can work collaboratively to critique, resist challenge, or even transform the status quo. Eikeland thus echoes Roxa and Martensson's claim that backstage settings are where smaller \*significant networks" are formed that function as "gatekeepers for development and change" (Roxa & Martensson, 2009, pp. 556-557).

# 2.4. Backstage settings in CAR

Within the field of CAR, recent empirical studies sugest that backstage settings ought to be intentionally designed into CAR projects to hance informal profesional learning. While these studies do not use thetermbackstage settings, they decribe projects with settings that match our defintion of the term. These projects typicall involve 12 or fewer participants engaging i activities that prompt informal dialogue within even smallr groups or pairs. Take, for instance, Grenwood and Kelly's (2020) study of how 11 teachers and staf conducted cooperative inquiry to implement person-centred practices at an English secondary school. The project was initiated by Greenwood, then a trainee psychologist at the schol, but the project's focus was jointly decided by all participants. The study describes how regular sharing sessions allowed participants to share and deepen their different understandings of person-centred practice, in pairs and with the larger group. They collaboratively developed themes such as celebrating [leaners] small steps of progress"--that informed changes to classroom practices (p. 223).

In addition, Alam's (2020) study shows how backstage exchanges are even more important in contexts where teachers tend to defer to authority. During his project at a rural secondary school in Bangladesh, Alam was a doctoral researcher who aimed to enhance reflective practice among teachers; however, the 12 teachers involved intilly relied on him for direction, instead of building a self-sustining learning community. In response, Alam deliberatly created what we call a backstage seting" by inviting teachers to share their hardships, and to reflet on a national catastrophe that ocurred around the time the project was conducted: the collapse of Rana Plaza. This activity was inspired by a villge custom, to take tea and tall" (p. 139). The conversations evolved from personal matters t teachers professional motivations and values, efectively inaugurating a \*communicative space that grew throughformal and informal conversations' over weeks (p. 141). Through this proces, Alam established norms for critical exchanges so teachers became more confident of giving, receiving, and using peer critique to complete their projects.

The studies above involve projects that were aligned with recognised CAR practices, because these projects were bottom-up ini. tiatives that were led by community members addressing shared concerns (Burns, 199; Kemmis et a., 2014). However, other studies suggest that top-down projects mandated by authorities are also effective for informal learning, so long as backstage setings are present. Chen's (2022) data suggests that in the Chinese context, where rofessional lerning is intutionalised as Teaching Research Groups (TRGs), and where techers usually defer to educational rarchers and authrities, bacstage seings sil emain key sites of learning in CAR. Her study, which focuses on a TRG comprising 11 teachers, reports that formalised activities, such as open lessons or reflective sharing, led to informal, yet critical exchanges between teachers that were used to improve classroom instruction.

Likewise, Wang and Zhang's (2014) study of CAR in the Chinese context effectively describes backstage setings that nurtured enthusiasm for autonomous learning among teachers. Their study involves 45 teachers from different senior secondary schools in Beijing, who were divided into subgroups comprising two to nine teachers and one to two university researchers. Teachers worked on individual AR projects, but exchanged findings and ideas in workshops and sharing sessions. Of the 45 teachers, 34 completed 17 AR projects, even though 23 f these teachers were initiall pasive or uncommited participants. Many reported incorporating rflective practice and exchanges with colleagues into their routines, even afer their projects conclusion. The authors attribute this shift in mindset to a climate of mutual support created through interaction in the subgroups, which transformed a previously \*isolated teaching culture" into a collegial one (p. 231).

In sum, backstage settings" describe potentially subversive spaces where smalle goups of teachers discs experimental ideas and practices in informal, private, and trusting conversations. The studies reviewed suggest that backstage sttings ought to be designed into CAR projects, because such settings help build communities that sustain informal learning.

# 3. Study and methods

# 3.1. Context and study design

This paper analyses how backstage exchanges during a CAR project facilitated informal learning among three new EAP teachers. The project took placeat a Singaporean universty in the context of a mandatory academic writing course for first-year undergraduates. The course is taught by approximately 60 teachers and taken by around 2500students each semester. I can be described as a general EAP course that focuses on foundational sills in academic writing (Hyland, 2016). Through proces writing, students develop a researched argument about a place, a community, or their own writing practices. Emphasis is placd on asequence of eight discursive "moves" common to academic genres (Swales, 1990).

1. Describing primary data   
2. Analysing patterns in the primary data   
3. Explaining the implications of those patterns   
4. Posing a research question related to the patterns   
5. Summarising a secondary source's claim(s) to address the question   
6. Reflecting on a secondary source's claim(s) critically   
7. Synthesising claims from two secondary sources   
8. Adding one's original contribution

In addition, the course is informed by First-Year Composition (FYC) approaches that frame academic writing as a form of civic engagement (Tardy & Jwa, 2016), thus creating a hybridised EAP-FYC approach that is emerging in Singapore (Frattarola, 2023)

During course delivery, a rating workshop involving 52 teachers revealed high interrater variability in their judgements of three student papers. I response, seven of the 52 teachers formed a working group to develop an analytic rubric aimed at reducing inerrater variability acrossdifferent sections of the course. The completion and dissemination of the rubric spanned five months. After these tasks were completed, threeof the seven teachers decided to extend rubric development into CAR, which required that they consult the relevant literature to reflect on the personal knowledge gleaned from thir experiences. The other four teachers delined to participate in CAR due to work commitments.

This present study analyses the written reflections of the three teachers who participated in CAR in order to address the following research questions:

1. How did CAR facilitate informal professional learning among new EAP teachers?   
2. What did the teachers learn?   
3. Which factors impeded learning?

Our retroactive application of the CAR framework to already completed tasks may seem unorthodox, because CAR should typically inform the genesis f a project, so that plans and actions are informed by both CAR principles and research specific to the problem at hand (Buns, 2010). Some might therefore argue that the process of rubric development ought tobe labelled as merely a\*professional task" or "reflective practice," rather than as "CAR." However, we defend our approach on two counts: First, the proces of rubric development conformed to the basic definition of CAR, in that the seven teachers initiated and led the working group to address a practical isue. Second, this present study focuses only on the work done by the thre teachers, who formally extended a professional task into CAR; they have since engaged with the relevant litrature to reflect, albeit belatedy, on what they learnt from rubric development. In these ways, their project qualifies as CAR. We propose that our unorthodox approach is more realistic for tachers who need to prioritise immediate teaching duties, before engaging more deply with research to evaluate the outcomes of their ctions and the personal knowledge generated, as and when conditions are appropriate.

# 3.2. Researcher-participants

In what follows, we use the term esearcher-participants' to indicate the thre teachers who designed, executed, and participated in the CAR project, two of whom co-authored this present paper. Specific researcher-participants wil be referred to in coded form as RP1, RP2, or RP3 to preserve anonymity. Their actions overlapped with, but will be distinguished from, those of other group members, which refer to the other four teachers who co-wrote the rubric but did not participate in CAR. Where necessary, we use "working grougp to indicat all seven teachers who co-wrote the rubric, in order to distinguish them from other "course teachers" who taught the same EAP course. I accordance with the Institional Review Boards guidelines allidentifying information of researcher. participants, other group members, and course teachers in the data has been removed.

The three researcher-participants were self-selected teachers who were both the researchers and the researched (Neuman, 2014). Self-selction is appropriate because CAR is most efective when participatio is voluntary, and because the researcher-participants had privileged knowledge of institutional processes and group dynamics, which enabled them to addresues or even transform the status quo in ratoal, just, and sustanable ways (Burns, 199; Kemmis et al, 2014). l thre were relatively new to teaching AP: One had taught EAP for three years and held a MATEsOL, whereas the other two had taught for two years and held PhDs in the humanities (Table 1).

Table 1 Researcher-participants' demographic information.   

<html><body><table><tr><td>Researcher-Participants</td><td>EAP Teaching Experience (years)</td><td> Educational Level</td><td>Position</td></tr><tr><td> RP1</td><td>3</td><td> MA in Teaching English to Speakers of Other Languages</td><td>Lecturer</td></tr><tr><td>RP2</td><td>2</td><td>PhD in English Literature</td><td>Lecturer</td></tr><tr><td> RP3</td><td>2</td><td>PhD in English and Comparative Literature</td><td>Lecturer</td></tr></table></body></html>

# 3.3. Data collection and analysis

The data comprises the three researcher-participants written reflections ranging from 1400 to 200 words each. To generate these reflections, researcher-participants independently reviewed field notes and correspondence related to rubric development, including their personal notes; meting minutes; sample student scripts; emails; slides; video recordings and chatlogs associated with online course briefings, rating workshops, and rubric-writing meetings; and multiple drafs of the analytic rubric annotated with peer crit icism. Subsequently, the researcher-participants separately wrote refections that described and analysed incidents they found significant for their own learning. These reflections were structured according to the action research reflective spiralplanning, acting, observing, reflecting (PA0R)first outlined by Kurt Lewin (Adelman, 193), then schematised by Kemmis and McTaggart (1988) (Table 2). The PAOR structure enabled researcher-participants to recal their plans, actions, and the outcomes of those actions, to reflect on the tacit reasoning behind their actions, and to track how new issues arose during CAR that demanded further action.

In the first phase of data analysis, the researcher-participants collectiely reviewed all thre written reflections and constructed a timeline of the project's PAOR cycles. As Atkinson (1994) explains, PAOR cycles can be difficult to delineate, because teachers may make rapid decisions and act intuitively during research, resulting in numerous mini or incomplete cycles. In our case, this difficulty was compounded because multiple researcher-participants were involved; they initially disagreed on where one cycle ended and another began, and on which cycles warranted deeper study. Further, some researcher-participants independently intiated cycles that yielded important findings, which needed to be reviewed by fellow researcher-participants. So, constructing a common timeline allowed researcher-participants to negotiate which cycles to focus on during analysis.

In the second phase of data analys, reflexive thematic analysis (RTA) was performed on the written reflections according to Braun and Clarke's (2006) six-step process with reference to Byrne's (2022) worked example. RTA was chosen because it is compatible with a "constructionist' and "experiential' approach to qualitative analysis, which assumes that meaning is actively created through researcher-participants' interpretations of the data, as opposed to the "essentialist" view that meaning lies in the data waiting to be found (Braun & Clarke, 2013, 2019; Byrne, 2022). A constructionist and experiential approach allows that meaningfulness can be subjectively determined by researcher-participants, and not purely determined by the frequency of recurring codes in the data (yrne, 2022). These aspects of RTA enable rich analysis of smallbut complex datasets such as the written reflections from the three researcher-participants--where uncommon or unique codes could, in fact, generate meaningful analysis. Further, RTA requires the meanings generated to be context-specific, which allowed rearcher-participants to use their knowledge of their hared socio-cultural context to inform their analysis. Such knowledge was especially relevant when researcher-participants analysed how the organisational culture at the language centre might have made CAR more effective at facilitating informal professional learning.

The three researcher-participants contributed to RTA to varying degrees. First, RP3 performed two iterations of initial coding based on the thre resarch questions listed in section 3.1.In the firt itration, written reflections were semented into data extracts and taged, producing 49 semantic codes (e.g. "vague rubric descriptors"; "disagreement over performance expectations"). In the second iteration, latent coding was performed. Codes were refined by activating concepts from the literature reviewed (e.g. Diaz-Maggioli's [2023] definitions of \*collaboration' and \*cooperation'), or revised to indicate relationships to other codes (e.g. some codes were reworded to include the term \*dificulty, to express challenges that researcher-participants faced). This second iteration of coding reduced the number of codes to 36.

Next, thematic analysis was conducted on the 36 codes over two online meetings by RP1 and RP3; at this point, RP2 had withdrawn from authoring this present paper due to other commitments. Afer sorting the codes according to the thre research questions, RP1 and RP3 clustered codes based on their \*internal homogeneity" (i.e. similarity to other codes), while ensuring that there was "external heterogeneity" (i.e. sufficient differentiation from other codes) between them (Byrne, 2022; Patton, 1990). Within each cluster, codes with broader meanings were promoted to sub-themes (.g.\*institutional presures" and \*ideological differences") then, a sub-theme was promoted to a theme to encapsulate the general meaning of the cluster (e.g. lack of participant and community investment").

Following RTA, the data extracts were retagged accordingly for easy referencing during report writing. Subsequently, RP3 produced a preliminary RTA report that was revised in dialogue with RP1 across 10 online meetings lasting approximately 2 hr each. The findings are presented in the next section.

# 4. Findings

The three researcher-participants established that the project involved two stages: Stage 1 pertained to rubric development among the working group of seven teachers, whereas tage 2 involved disseminating the rubric to all ours teachers. Each stage comprised two cycles, with the second responding to a freshissue that emerged from the first, notably by altering the group's approach from a cooperative to a collaborative one that allowed for backstage dialogue. The finalised timeline is presented in Table 3.

Table 2 Description of Kemmis and McTaggart's (1988) reflective spiral (p. 10).   

<html><body><table><tr><td>Plan</td><td>Develop a plan of critically informed action to improve what is already happening.</td></tr><tr><td>Act</td><td>Act to implement the plan.</td></tr><tr><td>Observe</td><td>Observe the effects of the critically informed action in the context in which it occurs.</td></tr><tr><td>Reflect</td><td>Reflect on thesefects as the basis for further planning, subsequent criticall informed action and so on, through a succession of stages.</td></tr><tr><td></td><td></td></tr></table></body></html>

Table 3 Project timeline.   

<html><body><table><tr><td colspan="6">Stage 1 Drafting the Rubric</td></tr><tr><td>Stage/Cycle 1.1</td><td>Issue A rating workshop</td><td>Plan 7 teachers formed a</td><td>Actions The 7 group members</td><td>Observations All 3 researcher-</td><td>Reflections RP1 reflected that</td></tr><tr><td></td><td>revealed high interrater variability among 52 course teachers. Some teachers identified the broadly worded holistic rubric in the course guide as a contributing factor to interrater variability.</td><td>working group to expand the existing holistic rubric. into an analytic rubric, with quality definitions for column:. differentiated performance . Observations levels.</td><td>They listed 9 evaluative criteria in the leftmost : Analysis of observations : Research question(s) : Selection and quality of sources : Summaries of sources : Evaluation of sources : Synthesis of sources : Conclusion . Language They listed 4 performance levels in the topmost row: Below average . Average . Good : Very good Working alone or in pairs, members drafted quality definitions for each performance level of their chosen evaluative criteria. Then, the group</td><td>created a shared document. participants reported that the following issues: : Group members had rubric components written by other members. . Group members found it difficult to word the rubric components precisely and concisely. . Group members held differing performance expectations for the final assignment.</td><td>collaborative rubric writing the online meeting revealed was time-consuming and inefficient. Group members misinterpreted or were difficulty interpreting the uncertain of what rubric components drafted by others meant. Clarifications were made verbally and in writing, which added to the length of the rubric, creating an unwieldy document. RP2 reflected that collective review of the drafted rubric revealed fine-grained disagreements between members that were previously glossed over. These disagreements could not be attributed to disciplinary differences, because most of the group held degrees in literary studies. RP3 did not write reflections specific to this</td></tr><tr><td>Stage/Cycle 1.2</td><td>Issue disagreed on performance expectations for the final assignment.</td><td>Plan The 7 group members The group changed their approach from task division, where most members worked independently on their self-assigned sections of the rubric, to collaborative writing. draft of the rubric, before meeting online to</td><td>consolidated and reviewed the rubric during an online meeting. Actions Group members worked in pairs to conduct peer review over online meetings and to revise their views more clearly. respective sections of the rubric. Then, group members independently reviewed the consolidated second</td><td>Observations other to articulate their own because it was time-. RP1 and RP3 reported modifying their own views. after considering the views RP1&#x27;s beliefs regarding</td><td>cycle. Reflections RP1 and RP2 reported that RP1 reflected that while group members helped each the project was inefficient consuming, it was nonetheless effective in clarifying and sharpening</td></tr></table></body></html>

Table 3 (continued)   

<html><body><table><tr><td colspan="5">Stage 1 Drafting the Rubric</td></tr><tr><td> Stage/Cycle</td><td>Issue</td><td>Plan</td><td>Actions</td><td>Observations</td><td>Reflections</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>some autonomy when delivering the course and conducting assessment.</td></tr></table></body></html>

Stage 2 Disseminating the Rubric   

<html><body><table><tr><td>Stage/ Cycle</td><td>Issue</td><td>Plan</td><td>Actions</td><td>Observations</td><td> Reflections</td></tr><tr><td>2.1</td><td>The 7 group members wanted to disseminate the completed 11-page analytic rubric to all course teachers to communicate the group&#x27;s unified performance expectations, and to solicit feedback.</td><td>The group submitted the rubric to the centre director for vetting, and requested approval to email the rubric to all course teachers.</td><td>The rubric was sent via mass email with a request for feedback. In accordance with the centre director&#x27;s instructions, the email stated that course teachers are not obliged to use this rubric. It was also stated that the</td><td>RP1 and RP2 made no mention of this cycle. RP3 reported that most teachers gave brief feedback or criticised the length of the rubric, which were not useful comments. Only 1 teacher gave extensive and helpful</td><td>No reflections specific to this cycle were written.</td></tr><tr><td>2.2</td><td>seemed uninvested in the 11-page rubric and/or they found it too lengthy.</td><td>RP1 planned to disseminate and test the rubric via an optional and informal online rating workshop. RP1 did so during the first round of summative assessment for the course, with the concurrent goal of supporting teachers who faced difficulties with grading.</td><td>RP1 invited all course teachers to the informal rating workshop via the university&#x27;s official workspace chat application. 5 teachers including RP1 participated in the 1.5-hr session. The session began with all teachers clarifying their understanding of the rubric. Subsequently, 4 teachers shared scripts that they found difficult to grade. (1</td><td>RP1 reported that all 5 teachers reached consensus on ratings for 3 of 4 student scripts that were considered difficult to grade. Their ratings diverged slightly on the remaining script; 2 teachers rated the script a band lower than the other 3, because they weighed the evaluative criteria differently.</td><td>RP1 reflected that teachers interpreted the rubric differently, so extensive discussion was necessary for clarifying what the rubric meant, before teachers could use it effectively as a rating tool to reduce interrater variability. Further, RP1 also noted that the discussion facilitated Vygotskyian social learning, because teachers helped</td></tr></table></body></html>

The timeline demonstrates how rubric development, which was originally intended to address high interrater variability among course teachers, transformed instead into a venue for informal professional learning for the three researcher-participants. The researcher-participants initiall identified the broadly worded holistc rubric in the course guide as the cause of interrater variabilit. So, they decided to draft an analytic rubric with quality definitions for differentiated performance levels, and conceived of this new rubric as an authoritative scoring tool that would be imposed on other course teachers.

However, their plans were disrupted by two developments: First, in Cycle 1.1, researcher-participants witnessed deep disagree ments between working group members, and realise that interrater variability should not be olely atributedt issues with the text of either the holistic rubric or the newly drafted analytic rubric. Rather, there was a social dimension to the problem: members held different beliefs about performance expectations and scoring practice, and therefore employed personal evaluative criteria when rating student scripts. Researcher-participants realised that these disagreements had to be unearthed and negotiated during rubric development.

Second, in Cycle 2.1, the centre director decided that course teachers were not obliged to use the newly drafed rubric, due to a concern that an authoritative rubric would impede the development of teacher autonomy by encouraging rigid pproaches to teaching academic writing. This decision meant that the new rubric provided recommended rather than mandated assesment practices, so it was unlikely to be efftive at reducing inerrater variabilit. The developments prompted reearcher-participants to reconceive of rubric development as a venue for reciprocal learning, through which they could collectively clarify, challenge, and/or modify their own beliefs and practices.

![](img/79dab6415330f17d7fb50a4ad07269eb5eb3c36a15f73d97ec98fbfd8a712b9f.jpg)  
Fig. 1. Finalised thematic map.

In what follows, the results of RTA are presented as a thematic map (Fig. 1) and explained. In total, three thematic clusters were generated, each comprising a theme and four to five linked sub-themes. We elaborate on how each cluster addresse  specific research question below.

4.1. How did CAR facilitate informal professional learning among new EAP teachers?

CAR-informed rubric development enabled the three researcher-participants to critically reflect on their understanding of assesment standards. Researcher-participants used rubric writing to plot out their varied understandings of erformance expectations and scoring practices, which enabled them to clarify ambiguitie, identify problems, negotiate diffrences, and consider alternatives during group meetings. Subsequent revisions of the rubric captured the reconciliations made between researcher-participants and other group members, which helped unify the group's understanding of assessment standards. Throughout this process, the rubric functioned as a dialogical tool that helped reconcile differences and facilitate reciprocal learning.

# 4.1.1. Backstage setting and bottom-up approach

It was noted that the working group comprised only seven teachers who initiated and led the project; in addition, the three researcher-participants were relatively equal in terms of qualifications and EAP teaching experience (Table 1). These features of the group created a backstage seting where members were comfortable with articulating their views and contesting those held by peers (Roxa & Martensson, 2009; Mitchell et al., 2009).

# 4.1.2. Collaboration with critical friends

Within this backstage setting, members functioned as "critical friends' (Heller, 1988) who helped each other articulate their own views more clearly, while also considering each other's views. RP1 reported that \*hJaving an audience for my thoughts forced out a clarity that I might not have produced on my own," whereas RP2 recalled \*overhear[ing] some of the other discussions for the other sections,' which helped shape the writing in their self-assigned sections of the rubric.

However, the data revealed that such critical exchanges also presented a problem; as RP2 pointed out, disagreements were not always reconciled, noting that \*rJecognising the validity of another's perspective did not necessarily mean that the alternative view had to be adopted." Yet, RP3 reported making compromises even in such cases:

I kept asking myself: "'Do I want to die on thishill?" and the answer was almost always a resounding no." I did not want to waste everyone's time and effort (or to exhaust their goodwill and patience) ...

These comments suggested that acollgial atmosphere encouraged RP3 to address only their mostpressing concerns, instead of turning peer critique into an exercise in nit-picking.

In other cases, the data showed that disagreements were resolved by deferring to the principle of the Outcome-based Teaching and Learning approach. Acording to RP3, some members argued that \*writing proper transitions' ought to be emphasised, but this suggestion was ultimatel reected because transition writing was not astipulated leaning outcome, so "teachers should not penalise students to harshly. This compromise was admittedly unsatisfactory, because members were implicitly discouraged from critiquing and revising the existing learning outcomes. However, RP3 also stated that the language centre valued teacher autonomy on the whole, which made such compromises palatable:

The [centre] director has repeatedly stresed that this rubric is meant to be used voluntarily and as a guide, it will not be forcibly imposed on every teacher ..I did feel that more lasse-faire approach made me open to considering altenat views deeply, as opposed to just following the letter of the law (grudgingly) ...

So, the data demonstrated that while a bottom-up aproach to CAR and backstage dialogue did not guarantee true consensus, they did encourage meaningful compromises, due in part to an organisational culture that valued teacher autonomy.

# 4.1.3. Modifications to beliefs and practices

In some cases, the data confirmed that exchanges with criticl fiends inspired modifications to researcher-participants beliefs and practices. RP1 reflected that \*for some parts of the esay, I was asking too much of my students, and in some areas, like the summaries, I hould expect more robust and targeted writing." Likewise, RP3 realised that I do not place enough emphasis on how a student's original claim must be built on their synthesis of claims from sources .. I made plans to change my instruction and assesment practices." Notably, both RP1 and RP3's reflections pointed to "sustained' learning that could lead to improvements in instructional practices, which exceeded the immediate assessment-related concerns of the project (Diaz-Maggioli, 2023, p. 13).

# 4.2. What did the teachers learn?

The researcher-participants learnt that the detailed analytic rubric they drafted was limited in its capacity to align assessment standards between teachers, because teachers faced difficulties with interpreting rubric components written by others, and with wording components. Teachers also disagreed over performance expectations and scoring practices, and some found the rubric unhelpful because it was too lengthy. These issues needed to be resolved via extensive discussions.

# 4.2.1. Difficulty interpreting rubric

The data showed that group members had dificulty interpreting sections of the rubric drafted by others. RP1 reported that when members met o reviw he firs consolidatddraft f he rubric, there wre ot of clfiction qustions .. the more we disussed, the more elements we found needed explanation." The discussion was so rigorous that the group only dealt with three out of nine evaluative criteria, so a second meeting had to be scheduled.

4.2.2. Disagreements over performance expectations and scoring practices

Further, members contested the validity of the first draft of the rubric, particularly with respect to (1) performance expectations and (2) the relative weights of the evaluative criteria. In relation to (1), RP2 stated that some members \*did not require the summaries [of secondary sources] toaddress the research question directly as long as the main points were written coherently," whereas others like RP3 insisted that a \*very good" paper should contain summaries that \*addres the question upfront." In relation to (2), RP3 explained:

One overarching disagreement was whether a "very good" essay was one that demonstrates cohesive, coherent, and structured writing with a predictable argument, or one that makes an original argument at a conceptual level, but which suffers from issues with cohesion and coherence.

This data extract suggested that the rubric should inform teachers which evaluative criteria were associated with higher-order learning outcomes and ought to carry a heavier weight.

Some of these disagreements can be attributed to personal evaluative criteria held by group members. For example, RP2 reported that some membersrated STEM students more leniently, because they perceived STEM students to be "at a natural disadvantage in an EAP course as compared tostudents from the humanities and the social sciences. Other members pushed back sucessully on this practice, arguing that the lessons ought to have "levelled the playing field" (RP2).

# 4.2.3. Difficulty wording rubric precisely and concisely

Even when there was agreement on performance expectations, the data showed that group members found itdifficult to word the rubric components precisely and concisely. RP1 offered an example:

while we all agreed that verbose and flowery" language was not needed, some of us pointed out that . metaphors and descriptive language were need[ed] to re-present the topic for the reader. How could we word the rubric [to distinguish] between "flowery" language and relevant, descriptive language?

Due to such complications, the final draft of the analytic rubric stretched to 11 pages.

# 4.2.4. Perception of rubric as unwieldy

Researcher-participants noted that course teachers outside of the rubric-writing group found the 11-page analytic rubric unwieldy. RP3reported that fllowing the dissemination of the rubric via mass mail in Cycle2.1, \*a] few complained that the rubric was fartoo long." Similarl, RP1 observed that when the rubric was disseminated via an online rating workshop in Cycle 2.2, the rubric was too engthy to be used as  scoring tol. Rather, tachers referred to the rubric before [rating scripts to refresh their memory, instead of referring to the rubric \*constantly during the evaluations (RP1). These observations suggested that while the 11-page analytic rubric might have functioned well as a dialogical too for teachers to clarify and reflect critically on their assessment-related beliefs and

practices, it needed to be shortened for use as a scoring tool

# 4.3.  Which factors impeded learning?

The researcher-participants expressed different level of investment in the project, which can be attributed to intrinsic factors, such as one's ideological leanings, and extrinsic factors, such as the institutional context, which can influence one's experience and evaluation of the project. Unsurprisingly, those expressing less investment reported less learning.

# 4.3.1. Ideological differences and differing perceptions of CAR

The data hinted that intrinsic ideological differences between researcher-participants resulted in diffring perceptions of the project's eficacy after its completion. RP2 semed most scetical of the project, because RP2 focused (understandably) on the original goal of resolving interrater variabilit, rather than on whether rubric development could inspire informal professional learning Therefore, RP2 prioritised aligning teachers' assessment practices with a normative standard in the interest of accountability and fairness, and expressed concerns that the project seemed to be ineffective:

It was undeniable that this exercise [helped] us understand what we were not comfortable with, as wellas [laid] out the specific reasons for the disagreements. However, it was les clear whether reconciling these differences would be possible .. the descriptors m[ight] have been more detailed than intended, ironically leaving the marking process possibly more subjective than before instead of enhancing interrater reliability .. Some were convinced that this was a natural consequence of the task re quirements, which gave students and tutors alike the space to craft innovative and unique pieces .. Personally, I was unsure whether this was an acceptable conclusion .. my concerns came in terms of how this would look to the school administration.

Here, RP2 reflected that the project seemed counterproductive because it was widening the gulf between members' assessment standards, and implied that the project should prioritise ddressing interratr variability over cultivating teacher autonomy, due to concerns about how the university administration may view the course's credibility.

Conversely, RP1 and RP3 seemed amenable to pivoting away from the original goal of addressing interrater variabilit, because they realised that the project clarified or even challenged their beliefs. For example, RP1 noted:

While we did not do what we set out toaccomplish (that is, solve all marking problems ssociated with the rubric), . it] helped me understand ... what I was asking my students to produce.

Similarly, RP3 reflected:

I valued concision of writig and source selection .. highly--perhaps too highly ..I leant that even if the writing appears to meander, such moments may be important for a richer contextualisation of a concept or a research problem.

Both valued the ferment generated from the group's lengthy exchanges: RP1 argued that the "disemination of knowledge through common interests produces community leaning,] since one's learning can depend on the input of others around them," whereas RP3 stated that \*th[e] process made me more pen to . what academic writing can look like a opposed to what I think i should look like."

# 4.3.2. Top-down dissemination

The data showed that the mode of disseminating CAR findings influenced the level of community investment in, and learning from, said findings. In Cycle 2.1, the rubric was disseminated via mass email, creating afrontstage seting comprising 52 course tachers; these teachers received in atop-down fashion, the recommended ssessment standards and  request for fdback. Course teachers did not seem invested in the rubric; RP3reported that only a few teachers "gave brief feedback that  [RP3] ignored or did not find useful." Of the littl feedback reeived, most comments criticised the rubric's length and the cognitive load required to processits content RP3 reported finding the complaints about the rubric's length "disheartening,' because they "did not think that the rubric could be shortenedthat would erase the complexities of what was discussed ater multiple rounds of co-writig, pr citique, and revisions." The contrast between RP3's investment in the rubri, and the lukewarm reception from course teachers outside of the working group, suggested that top-down and frontstage dissemination of findings did not lead to the kind of "experiential knowing" among course teachers that researcher-participants cultivated during CAR (Heron, 1996, p. 54). Further, the lack of feedback also meant that researcher-participants were not learning from course teachers. Notably, RP1 and RP2 made no mention of this cycle, so no learning was reported.

Conversely, RP1 reported that diseminating the rubric in a backstage setting led to greater community investment and learning. In Cycle 2.2, RP1 organised an optional, informal rating workhop, which targeted teachers who faced dificulties with grading during the frst round of summative assesment for the course. A small group of five teachers including RP1 participate in the workshop, four of whom shared student scripts they found difficult t rate. RP1 reported that ollowing a clarification of the rubrics components, the participating teachers rated the cripts independently and gave thre fthe four scripts the same rating. For the remaining script, Script B, two out of five teachers rated the script \*upper-average (i. cloer to ood" than \*average") while others rated it god." espite this discrpancy, the teachers "rorted understanding thr olleague rsons for their ndividual luations" ther rating differed only because they weighed the evaluative criteriadifferently (RP1). For example, some valued the collction and description of data over critical or creative research questions," whereas others placed more weight on the questions (RP1). While teachers were \*not amenable to changing thir initial grades for Script B, those who rated it higher "'conceded that . they would downgrade th script's assigned grade if there were more well written papers (RP1). Therefore, this second mode of dissemination not only resolved the initial problem of intrrate variailit (albeit at a smalle scale) it also led to unfored consensus" among teachers regarding scoring practices (Kemmis et al., 2014, p. 35).

RP1's reflections supported our earlier finding that teachers commonly face difficultis with interpreting rubrics written by others (Section 4.2.1), while also offering evidence that such difficulies could be resolved through the isemination of rubrics in backstage settings:

while rubrics can be a solution for teachers facing grading difficultie, conversations are necessary to clarify what rubrics mean in practice. This is similar to what Kemmis et al. (2014) seeas necessary for successful participatory action research[:] \*enter [ing] a space of communicative action .. when we engage one another in genuine, open dialogue or (better) conversations' (p. 35). (RP1)

In other words, RP1's informal rating workshop facilitated dialogue through an authentic activity i.e. rating difficult-to-rate student scripts) that clarified assessment standards and mediated disagreements between critical friends.

# 5. Discussion

# 5.1. Backstage settings as key sites of informal learning

Our study corroborates assertions that CAR can faciliat informal professional learning among new teachers due to the critical dialogue generated (Mitchell e al., 2009). We add that such dialogue is more likely to occur in backstage"sttings characterised by privacy, informality, and trust, because such settings foster mutual exchange of ideas geared towards addressing teaching-related issues (Roxa & Martensson, 2009). Both the literature reviewed and our findings suggest that bacstage exchanges tend to emerge from sharing sessions or collaborations between teachers with similar goals, needs, and responsbilities, especially when there are opportunitie for intimate sharing within small groups or between pairs (e.g. Alam, 2020; Greenwood & Kell, 2020). Such exchanges can lead to social learning in the Vygotskian vein, where teachers scaffold learning for each other (Shabani, 2016).

Further, our study shows that the dissemination of CAR findingsto localised networks should also be done in backstage settings to enhance community investment in the findings. Backstage setigs make dissemination more accessble and collegial (Bleicher, 2014; Greenwood & Kell, 2020), while encouraging dialogue and participation that could extend or modify findings. This point is demonstrated by RP1's informal rating workshop in Cycle 2.2 (Section 4.3.2), which created a "community of practice" (Lave & Wenger, 1991, p. 138), where five teachers rated self-nominated student scripts with more confidence nd accuracy. In the process, the rubric became part of the group's shared repertoire of resources' through a practical and authentic activity (Wenger-Trayner & Wenger-Trayner, 2015). The exchanges between workshop participants, which included laying out differences and making compromises, resembled the bacstage interactions between the seven group members in Cycle 1.2 (Section 4.1). The success RP1 achieved with this mode of dissemination contrasted sharply with the failure of disseminating the rubri via mass email in Cycl 2.1 (Section 4.3.2), which was a mode of frontstage disemination that did not build a community of ractice, and which sought cooperation rather than collaboration from other course teachers (Diaz-Maggioli, 2023).

# 5.2. Ideological differences affect the efficacy of CAR in fostering informal learning

Scholars have asserted that CAR can transform authoritative and hierarchical cultures by promoting teacher autonomy (e.g.Chen. 2022; Wang & Zhang, 2014). However, our study qualifies that as framework for informal professioal learning, CAR works better for teachers who favour exploratory approaches to addressing isues, as opposed to those who prefer or are pressured to find definitive solutions. This is because CAR's emphasis on teacher autonomy and democratic participation can create unresolved disagreements between participants, or surface new issues that underlie the original, resulting in protracted projects and unintended outcomes (Ebbutt, 1985; Burns, 2010; Kemmis et al., 2014; McNiff & Whitehead, 2002). In particular, RP2 reflected that the project was ineffective, because RP2 was primarily concerned with solving the initial problem of high intrratr variabilit, and because RP2 was motivated by (thir perception of) institutional pressures to solve this problem. Conversely, RP1 and RP3 found the project useful for clarifying and adjusting their own performance expectations and scoring practices, because they were amenable to a shift in the project's goal away from reducing interrater variability, towards fostering informal professional learning.

# 6. Implications

# 6.1. Collaborative rubric development as a professional learning activity

Our study ofers evidence for Diaz-Maggioli's (2012) claim that collaborative rubric development can promote professional learning among new and aspiring teachers. Our findings show that researcher-participants reinvented the rubric as a dialogical tool that enabled critical reflction of their belies and practices surrounding assessment. Through this process, the rubric became the foundation of "intersubjectivity," which refers to "a temporary shared social world within which researcher-participants aligned their efforts to complete atask (Wertsch, 1985; Shabani, 2016, p.8). Their use of the rubric transcended typical conceptions of the rubric as prescriptive instruments that are used as (1) auditing tool for evaluating the eficacy of courses in relation to programme and state standards, (2) scoring tools for rating summative assessments, (3) intructional tols for communicatig assesment standards to students, and (4) self-assesment tool for students to personalise their learning according to course learning outcomes (e.g. Brookhart,

2018; Brookhart & Chen, 2015; Dawson, 2017; Jonsson & Svingby, 2007; Panadero & Jonsson, 2013; Reddy & Andrade, 2010).

The researcher-participants' approach to rubric development is aligned with call for rubrics to be used in less authoritative ways. Earlier research suggests that rubrics are clearer and more efective for learning when student feedbackis incorporated into rubric design (Andrade, 2000; Moni et al., 2005; Orsmond et al., 2002). Such suggestions have recently developed into more radically democratic forms of co-designing assessment proceses with students in higher education, whichcan reportedly create inclusive and highly motivated learning communities (Deey & Bovill 2017). Our study suggests that similar benefits aply to teachers when they co-create a rubric and reflect on their experiences via CAR in a backstage setting.

# 6.2. Implications for addressing interrater variability

Our findings also have implications for addressing interrater variability in assessment. In our project, researcher-participants realised that there are limits to using rubrics to align asessment practices, due to the difficulties group members faced with (1) interpreting sections of the rubri drafted by others (Section 4.2.1), (2) reconciling their diferent performance expectations and scoring practices (Section 4.2.2), and (3) wording the rubric precisely and concisely (Section 4.2.3). These limits have been reported elsewhere in empirical studies. Bloxham et al. (2016) found that even among experienced teachers, published evaluative criteria cannot ensure uniform interpretations and weightings of said criteria, or guarante that teachers wl not draw on personal evaluative criteria and tacit knowledge during judgement. The rearchers attibut the inevitability of interrater variabilit to the complexity of assigments in higher education. lsewhere, Bloxham et l. (2011) stres the limits of relying solely on the text of published rubrics to align assessment standards, and advocate for \*talking more rather than writing more to align asessment standards (p. 68). Similarly, our data demonstrates how during rubric development, \*talking more' inspired two researcher-participants to adjust their perfor. mance expectations for pecific criteria, namely summarising and synthesising sources (Section 4.1.3). Further, our data shows how during the dissemination of the rubric, an informal online rating workshop, where participants engaged in critical dialogue about the rubric, resulted in consensus among five course teachers on the ratings for three out of four student scripts (Section 4.3.2)

# 6.3. Limitations

Our approach to initiating informal professional learning through CAR may not work in more authoritarian settings. This study was conducted in a language centre where teacher autonomy was prioritised. While the centre director was concerned with standardising asesment practices acos a large-scale EAP course the drector has aostated that techers are fee to mphasise relevant aspects of academic writing that may not be foregrounded in the course guide, and to assess students acordingly. Further, the director also encouraged the extension of rubric development into CAR. The absence of such autonomy would have impeded teachers from experimenting with new approaches to teaching and professional learning.

Also, this study did not scrutinise the deper ideological disagrements between reearcher-participants regarding their approaches to addressing issues, and how those beliefs influenced their participation and investment in the project. Future studies could investigate the relationship between teachers ideological beliefs and their rceptivity to employing CAR for informal professonal learning, and how this relationship plays out in different organisational cultures.

# 7. Conclusion

This study shows how CAR fostered informal professional learning among three new EAP teachers through detailing and analysing the stages and cycles of a specific project. The project involved collaborative rubric development, through which teachers clarified, challenged, and even modified their own understanding of course expectations and their asessment-related knowledge and practices. In our project the proessof drafting, revising, minating, and using the rubric helped reearcher-participants concretise what they learnt through dialogue with critical friends. Further, our study also provides context-bound evidence that backstage settings comprising small groups of self-selecte teachers wh share common gols, neds, and resonsibilitieunction as crucial sites of informal learning in CAR. Such setings foster learning both during project execution and the dissemination of findings to the localised community.

# CRediT authorship contribution statement

Teck Heng Tan: Writing - rview & editing, Writing - original draft, Methodology, Investigation, Formal analysis, Data curation, Conceptualization. Woon Hong Eunice Tan: Writing - review & editing, Writing - original drat, Visualization, Project administration, Methodology, Investigation, Formal analysis, Data curation, Conceptualization.

# Declaration of competing interest

Teck Heng Tan was, and Tan Woon Hong unice is, an employeeat the department whose professional development practices were analysed in this study.

# Acknowledgements

We thank the editors of the journal and the guest editors of the special issue, especially Guangwei Hu and Rosmawati, for their encouragement and suport, the anonymous per reviewers for their investment in our scholarship, Angela Frattarola and Ho Jia Xuan for their insightful comments on drafts, and Koo-Cheah Swit Ling, Nicole Ong, Nuraliah Norasid, Prasanthi Ram, and Joanne Chia for their input.

# References

Ademan, C. (1993). rt n nd h ri f action rch. tio Action ch 1(1) 724. p/i./10.1080/096507930010102   
Alam .i n 18(2), 136-152. https://doi.org/10.1177/1476750318786780   
Andrade, H. G. (2000). Using rubrics to promote thinking and learning. Educational Leadership, 57(5), 13-18.   
Atkion . 19e af   tc n8301. https://doi.org/10.1080/0965079940020306   
Ba, . of English for Academic Purposes, 68, Article 101343. https:/doi.org/10.1016/j.jeap.2024.101343   
Blechr, 014ien n  i,  0-1..g 10.1080/19415257.2013.842183   
Bm     . 11    i  .   6, 655-670. https://doi.org/10.1080/03075071003777716   
la,  -tr  on,   rie,  2016. ts sth f ste mg pig th miltiof a riteria Assessment & Evaluation in Higher Education, 41(3), 466-481. https:/doi.org/10.1080/02602938.2015.1024607   
rn,  0   i  ./11803a   
Braun, V., & Clarke, V. (2013). Successful qualitative research: A practical guide for beginners. SAGE. 2159676X.2019.1628806   
Brookhart, .. (2018). Aprriate critri: e t effctive rubric. Frontiers in Ecation 3, (22) htp:/di.g/0.39/fec.2018.0022   
Brookhart . Che  (2015. The quait d fftivs of dive rubric. io Rew (3) 3-368. h/i.10.1080/ 00131911.2014.929565   
Burns, A. (1999). Collaborative action research for English language teachers. Cambridge University Press.   
Burns, A. (2010). Doing action research in English language teaching: A guide for practitioners. Routledge.   
Burs  ims, . 2023. whe  w Rins  iion an ction h. l for th Pc f  g 2) 9-20.   
Byne, D.202  x of Br d s h  xive thi s t  Qit, 56, 1391-142 h/o./10.007 s11135-021-01182-y   
amin, . 016).h n r  E crv  ttirish .  h or e, 23, 59-70. https://doi.org/10.1016/j.jeap.2016.06.003   
Che .    thtti Education, 119, Article 103875. https://doi.org/10.1016/j.tate.2022.103875   
awson, .017). uri  r d mrelia ,  d icio g o, 23, 347-360. https://doi.org/10.1080/02602938.2015.1111294   
Deey,  1f       tn Higher Education, 42(3), 463-477. https://doi.org/10.1080/02602938.2015.1126551   
Diaz-Maggioli, G. (2012). Teaching language teachers: Scaffolding professional learning. Rowman & Littlefield.   
Diaz-Maggioli, G. (2023). From cooperation to collaboration: Why does the distinction matter? The English Connection, 27(1), 12-13.   
Ding, A, & rce I (2017). The Egish for c p pcitioner prigr Itiol Publishig. hp/i.0.107/78-3-319-59737-9   
Ding,  . 016)  c     .), Th  hookf s    . 547-559) Routledge. (pp. 152-176). Falmer Press.   
Edards,  2021). eogil mct facion rch n g thr dmt:  ef th it iotin ch, 29(3), 396-413. https://doi.org/10.1080/09650792.2020.1718513   
Ekeland, .012).ti h d tiog  ch ai  i p . o ion Research, 20(2), 267-290. https://doi.org/10.1080/09650792.2012.676303   
Fitric  li, .citio  tice English for Academic Purposes, 59, Article 101140. https://doi.org/10.1016/j.jeap.2022.101140   
Frato  ai 368383. https://doi.org/10.1080/02188791.2021.1914546   
Goffman, E. (1959). The presentation of self in everyday life. Penguin.   
Gre  i qr   .nch 1 (2), 212-229. https://doi.org/10.1177/1476750317730651   
Habermas, J. (1991). Thestcal ansfomation f the public phre n inqury in a catgry f brgis sciet (T. Brgr, ts.). Pres.   
Hellr, H. (1988). The advisory service and consultancy. In H L. Gray (Ed.), Management consultancy inschool (p. 117-128). Casell.   
Heron, J. (1996). Co-operative inquiry: Research into the human condition. Sage Publications.   
Hyland, 016l   l  .)   h    . 79. doi.org/10.4324/9781315657455.   
Hyland, K (2018). Sympath for the devil?A defence of EAP. Language Teching, 51(3), 383-399. ttps:/oi.org/10.1017/5026144818000101   
Hyland,.06 l .  s  1 /. org/10.4324/9781315657455.   
nson,  7   t,    0 doi.org/10.1016/j.edurev.2007.05.002   
Kemmis, S., & McTaggart, R. (1988). The action research planner. Deakin University.   
is ,     .. .007 978-981-4560-67-2   
Lave, J., r, (191). d ng e h paio. mbridg rt Pes./i./0.1017/09780511815355   
Leug . 209. d  tcer si J.  .), g   c in (. 4958) Cambridge University Press. https://doi.org/10.1017/9781139042710.009.   
Mann, S. (2005). The language teacher's development. Language Teaching, 38(3), 103-118. https:/doi.org/10.1017/0261444805002867   
tso,01) r ) social & behavioral sciences (pp. 16339-16343). Pergamon. https://doi.org/10.1016/B0-08-043076-7/02407-4.   
McNiff, J., & Whitehead, J. (2002). Action research: Principles and practice (2nd ed.). RoutledgeFalmer.   
Mesiou, 2019.ative ci h litting sio in ch. o tin c, 27, 97-209. t/g/0.1080 09650792.2018.1436081   
Mithel, . ll .   09. is ctie ai for the  r n  chin 52) 344-349. https://doi.org/10.1016/j.tate.2008.06.008   
oni,  c ,005).  t k t a  ubric o t m  p. i Education, 29(4), 197-203. https://doi.org/10.1152/advan.00066.2004   
et . ge  016). Pic p ad r: s f t  d ri ubi spe . ai, J l, iff . Verso.   
Neuman, W. L. (2014). Social research methods: Qualitative and quantitative approaches. Pearson.   
rnd  00  i r rir t Assessment & Evaluation in Higher Education, 27(4), 309-323. https:/doi.org/10.1080/0260293022000001337   
a  i doi.org/10.1016/j.edurev.2013.01.002   
Patton, M. Q. (1990). Qualitative evaluation and research methods. SAGE Publications.   
Polanyi, M. (2012). Personal knowledge: Towards a post-critical philosophy. Routledge. https://doi.org/10.4324/9780203442159   
ey,   e .2010 f ric u hig  o 5), 3548. /.g 10.1080/02602930902862859   
Roxa  t   r-tht tion 34 (5), 547-559. https://doi.org/10.1080/03075070802597200   
Shaai06   1 7. org/10.1080/2331186X.2016.1252177   
Swales, J. (1990). Genre analysis: English in academic and research setings. Cambridge University Press.   
Tdy, C.M wa 2016).   a AP.  d .  .), h  oo f h o   . 568.) Routledge.   
tky, . 198). -ir  .),      g   rad University Press.   
ang, Q  g  014)  c   i i h    18 22-241. https://doi.org/10.1177/1362168813505942   
nger- ,5.   /r practice/.   
Wertsch, J. V. (1985). Voices of the mind: A sociocultural approach to mediated action. Harvard University Press