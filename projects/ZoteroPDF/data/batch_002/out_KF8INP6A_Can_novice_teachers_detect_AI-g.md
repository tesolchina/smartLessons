# Can novice teachers detect AI-generated texts in EFL writing?

Vanessa De Wilde

The introduction of generative artifcial intelligence (AI) to the wider public could have a huge impact on EFL learning and teaching. Researchers have voiced concerns that learners might lean too much on technology. Previous studies have investigated the use of AI tools in L2 writing with various populations and found that it was difcult for teachers to detect use of AI and that teachers mainly relied on linguistic strategies to detect AI-generated texts. This paper reports on a qualitative study that investigated whether novice English teachers were able to detect AI-generated writing and which strategies they used to do this. The results show that some novice teachers are quite good at detecting AI-generated texts, while others proved to have more difculties. The teachers used both linguistic and content-related strategies to detect AI-generated writing. The results point towards the value of including this topic in teaching methodology courses in (initial) teacher training programmes.

Key words: writing, artifcial intelligence, ChatGPT, teacher training, detection

A lot has been said and written about large language models (LLMs) since the release of ChatGPT, the most widely used LLM, at the end of 2022. LLMs such as ChatGPT and Google Bard make it possible to understand and generate text. They interact in a conversational way by responding to questions, admitting mistakes, challenging incorrect premises, and declining inappropriate requests (OpenAI 2024). The tools rapidly gained popularity, and with this popularity also came discussions within the feld of (language) education.

Kasneci et al. (2023) wrote a commentary on the opportunities and challenges of LLMs in education. The authors mention various opportunities to optimize the learning process such as chances to personalize the learning experience and increase student engagement. At the same time, they also point towards challenges that come with these tools. One of the challenges particularly relevant to this study is the risk that the learners might rely too heavily on the tool and use the tool to do all the work. On top of that, the authors mention that it is becoming very difcult to distinguish between texts written by humans and texts generated by a machine.

The concern that learners lean too much on technology has also been expressed in studies focusing on second-language writing by foreign language teachers. This concern was already formulated in studies looking into the use of machine translation (e.g. Maimone and Jolley 2022) and it was also voiced in relation to second-language writing using ChatGPT by Barrot (2023) and Warschauer et al. (2023). Similar to Kasneci et al. (2023), Barrot formulated concerns that learners would become too reliant on ChatGPT and that teachers might not be able to distinguish between learners’ own writing and texts generated by LLMs. The focus of the current paper is precisely this issue. The study addressed two questions: (1) Can teachers distinguish between human and artifcial intelligence (AI)- generated writing? (2) Which characteristics do novice teachers associate with human and AI-generated texts?

As ChatGPT has been used widely since its release, a number of studies have been conducted to assess the quality of the texts produced by this tool. One of the frst large-scale studies comparing the quality of AI-generated writing to human writing was the study by Herbold et al. (2023). In this study, 111 teachers rated 270 texts; 90 texts were written by human writers, 90 texts were generated by ChatGPT-3, and 90 texts were generated by ChatGPT- $^ { \cdot } 4$ . The study showed that the texts generated by both versions of ChatGPT received higher scores than the texts written by humans and that the texts generated by ChatGPT- $^ { \cdot } 4$ received higher scores than the ones generated by ChatGPT-3. The human writers were secondary school students for whom English was a foreign language and the raters were also non-native speakers of English. The study thus showed that, at least for L2 writers, ChatGPT outperformed humans. The study did not look into whether teachers were able to spot the diferences between human and AI-generated texts and if so, how they did this.

As foreign language teachers have repeatedly expressed the concern that their learners might rely too heavily on tools such as ChatGPT and would complete writing assignments without doing any efort (e.g. Barrot 2023), a few studies have looked into whether it is possible for raters to diferentiate between texts written by humans and texts written by ChatGPT. Clark et al. (2021) conducted a study in which they investigated whether untrained raters could detect machine-generated text. The authors found that the raters could not distinguish between texts written by humans and machine-generated texts. The raters reported that they mainly looked at the texts’ grammar, spelling, and style to make a decision but at the time the article was written (i.e. 2021), raters underestimated the quality of the text that could be generated through AI. Alexander, Savvidou, and Alexander (2023) looked into the ability of ESL lecturers to detect whether academic essays contained AI-generated text. Six lecturers with fve to twenty years of experience in teaching academic English at university rated four

academic essays. Three essays contained varying amounts of AI-generated text. The fourth essay was entirely written by a university student with a CEFR C1-level in English. The lecturers had to assess whether the texts were written by a human or generated by ChatGPT. They were also asked to indicate which criteria they used to make these assessments. The participants were not always able to identify which texts were written by humans and which parts were generated by ChatGPT. The participants mainly took into account linguistic characteristics such as spelling mistakes and sentence structure, but they did not mention any content-related criteria or fact-checking. The lecturers also expressed the expectation that there would be no mistakes in the AI-generated texts whereas they expected their students to make language mistakes.

The present study was set up to look further into the concern that learners might rely too heavily on ChatGPT and use it to generate a written text rather than writing the text themselves. The study investigated whether novice English teachers can distinguish between texts written by EFL learners in upper secondary school and texts generated using ChatGPT. We also looked into the criteria that were used to determine whether the text was written by a human or generated by an AI tool.

Procedure Context

The study was conducted in Flanders, the northern half of Belgium. The ofcial language spoken in Flanders is Dutch, which is a closely related language to English. English lessons typically start in the frst or second year of secondary school when the learners are twelve to thirteen years old. Depending on the curriculum, the learners receive one to three hours of English instruction per week. Because there are a lot of opportunities to engage with English outside the classroom (cf. De Wilde, Brysbaert, and Eyckmans 2020) this sufces for learners to achieve a CEFR B1-level (and sometimes even a higher level) of English by the end of secondary school.

English teachers in Flemish secondary education are specialized teachers. In lower secondary education teachers are expected to have an educational bachelor’s degree in English. In upper secondary education, teachers should have an educational master’s degree in English.

Texts

The material consisted of twenty texts. Fifteen texts were written by EFL learners who were in the ffth year of secondary school in Flanders and who were between sixteen and eighteen years old. The learners were all in an academic track that prepared them for higher education but with no explicit focus on languages. They received two hours of English per week. In the writing tasks the learners were asked to write a TripAdvisor comment about Central Park in New York, an activity they had practised in class in a diferent context. They were explicitly asked to use two second conditionals and four advice phrases and the verbs ‘to stroll’ and ‘to explore’, content they had previously discussed.

Fifteen learners wrote a text. They gave consent for their work to be used in the study. All texts were anonymized and transcribed by the researcher to ensure similar layout with the generated texts. Typos and spelling errors were all copied in the transcriptions. The fve remaining texts were generated by the researcher with ChatGPT version 3.5 in December 2023 (cf. Appendix). This version was chosen as, at the time of the study, it was freely available online and thus easily accessible for learners. In a frst phase the researcher generated three texts. The frst text was generated with a broad prompt. The researcher gave ChatGPT the same instructions the learners received but in a second instruction asked to shorten the text. The second text was derived from the frst text, but an extra prompt was given to write a text written by a young person which is meant as a writing task for school. For the third text an extra prompt was added, namely that the text was written by an intermediate learner. In a piloting phase teachers gave feedback on the generated texts. They mentioned that they could spot the generated texts partly because they were very alike in terms of touristic sights and some formulations. The researcher then adapted two of the texts. Text two was adapted by asking ChatGPT to make the vocabulary easier and to add conditionals (in accordance with the instructions). The researcher then manually deleted meta-language that was found in the text: ‘Now, for some advice phrases’ and ‘On to my second conditional’. In the third text the same meta-language was also left out. Taking into account the feedback provided on the frst three texts, the researcher generated two additional texts which were generated with the same instructions but in a diferent chat to avoid building on the text which was generated frst. For the fourth text, the following extra instructions were given: ‘Can you please write a text written as if by a 17-year-old intermediate L2 English learner? The text should be between 100 and 150 words and is meant as a school writing task.’ Finally, a ffth text was generated in a new chat with the same prompt. The researcher changed ‘Bethesda Terrace’ to ‘lake’ and ‘Ramble’ to ‘Central Park Zoo’ because these sights were known to the actual learners. Finally, explicit references to conditionals and advice phrases were left out. Adaptations such as the deletion of meta-language and changing the sights was done as this is something learners might also change when relying on ChatGPT for a school writing task to make their writing more credible. In the end, these twenty texts (ffteen human texts and fve AI-generated texts) were all used in the experiment.

Participants

The participants in the study were six novice English teachers. They were students in the abridged programme of the educational master in languages and had all received a master’s degree in English. The students had all done at least two micro-lessons for their peers, and they had also taught English in secondary schools during teaching practice. The study was done with novice English teachers following initial teacher training because they are the least experienced teachers and we aimed to investigate whether it was possible for them to distinguish between human and AI-generated texts and which strategies they employed to do this. All participants actively gave consent to use their answers for this study.

Procedure and analysis

To get an insight into whether the participants were able to detect AI-generated texts and to fnd out which strategies they used to do this, we conducted the study in two phases. First, the participants each received all twenty texts, and they were asked to assess whether these texts were written by L2 learners or generated by AI. They were encouraged to write down why they decided a text was written by a human or AI-generated. After this individual activity, a focus group discussion was held which was led by the researcher. The number of participants $( n = 6 )$ ) was ideal for a focus group discussion (cf. Ho 2006). During the focus group discussion, participants were frst asked about strategies that they used to detect AI-generated text. In the second part of the focus group interview, the participants discussed specifc texts and whether they were written by EFL learners or generated by ChatGPT. The interview was transcribed verbatim, and the researcher coded instances in the interview in which participants discussed strategies used to distinguish between human and AI-generated texts (Mackey and Gass 2005). They were put in two broad categories: linguistic and content-related strategies (see below).

In the frst part of the focus group interview, the participants were asked about the strategies they used to detect whether a text was generated by AI or written by a learner.

Various strategies were mentioned (see Table 1 for an overview of the strategies). Some of the strategies were linguistic strategies. The frst strategy pertained to non-standard language and mistakes. The argument was formulated in two ways. Some participants mentioned that they suspected a text was written by AI because it was ‘too good to be true’. Other participants mentioned that when a text contained too many mistakes, they assumed it was not written by AI. This is similar to what was found for university lecturers of English in Alexander, Savvidou, and Alexander (2023). The authors mentioned that the lecturers often started from a defcit model of assessment where errors were considered to be a sign of L2 learners’ writing as opposed to error-free language which was generated by AI. Even though the task was targeted at the learners’ profciency levels, teachers still expect their students, who are in the process of learning a foreign language, to make mistakes which would not be made by a chatbot such as ChatGPT. One of the participants in our study expressed that she sometimes suspected that errors were added by a human in the AI-generated text afterwards to make it more credible that they were written by a human. She mentioned that she inspected the texts and considered L1 infuence to be a clear indicator of L2 learner language. Another aspect that was mentioned was fuency. A participant mentioned that if a text was very fuent, this was also an indication that the text might be generated. What was meant with the term ‘fuency’ was not further specifed. A third language-related factor was the use of advanced vocabulary, collocations, and idiomatic use of English. This was also mentioned as a factor which indicated that the text might be generated by ChatGPT. The results are similar to what Maimone and Jolley (2023) found in their study which investigated whether teachers were able to detect the use of machine translation. The most frequently used argument by teacher in Maimone and Jolley (2023) was language beyond the expected level of

<html><body><table><tr><td>1. Linguistic strategies</td><td>a. The amount of non-standard language and mistakes</td></tr><tr><td></td><td>b. Fluency of the text c. The use of advanced vocabulary, collocations,</td></tr><tr><td></td><td>and idiomatic use of English</td></tr><tr><td></td><td>2. Content-related strategies a. Texts written by humans: a personal touch b. Al-generated text resembles a company blog c. Recurring patterns, ideas in Al-generated texts</td></tr></table></body></html>

L2 intermediate learners, and the second most used argument was the absence of typical L2 errors in machine-translated text. Both arguments were also often mentioned in the present study.

The participants did not only mention linguistic strategies. Some strategies were related to the content of the texts. The frst strategy pertained to the texts which were generated in the same chat. Here, participants spotted similarities in the constructs, formulations, and content of the three texts that were linked. This was already mentioned in the pilot phase of the study, and it was the reason why additional texts were added. Two other arguments were given. First, some participants mentioned that the AI-generated texts felt too much like company blogs. Second, texts written by L2 learners were sometimes identifed as human because of a personal touch that the participants thought could not be generated by AI. These texts were characterized as having ‘realistic thoughts for pupils that age’ or being ‘unique’. These arguments were less present in previous studies (Alexander, Savvidou, and Alexander 2023). This could be due to the fact that the technology has only recently become widely available, and it takes some time for users to get acquainted with the specifcities of the tool and characteristics of the content in the generated output.

We then looked into whether novice teachers were able to distinguish between human and AI-generated texts. Of the ffteen texts that were written by L2 English learners, twelve texts were consequently identifed as texts written by humans. Very often, participants reported that they identifed the text as human based on frequent mistakes in spelling, typos, punctuation, sentence structure, etc. Sometimes participants mentioned that the text was considered as written by a human because arguments were original, the text was unique, or there was a personal touch to the text.

Three texts were written by EFL learners, but some participants considered the texts to be generated by AI. Two texts were considered to be written by an EFL learner by four participants and AI-generated by two participants, one text was considered to be written by an EFL learner by fve participants and AI-generated by one participant. All three texts were well-written and received a high score from their L2 English teacher. The third text was slightly of-topic, and this was an argument for some participants as to why it probably was not generated by AI but by a human who misinterpreted the instruction.

Finally, none of the texts generated with ChatGPT were identifed as AI-generated by all participants. The three texts that were written in the same chat but in which the researcher adjusted the prompt were identifed as generated by fve out of six participants. One of the arguments given by the participants was that the texts were very similar. Other arguments referred to the use of collocations, the fact that there were no language mistakes but also the fact that the texts lacked ‘personality’ and were not very unique. Two participants explicitly mentioned they believed the texts came from the same source but were then fne-tuned using specifc prompts. The participants wrote that ‘it seemed as if someone typed more conversational please’ or the text was ‘written to sound cool’, which is precisely what was done by the researcher when writing the prompts. The texts that were generated in separate chats were harder to detect. One text was considered AI-generated by four out of six participants. One participant doubted whether it was written by an EFL learner or not but opted for the learner. Another participant mentioned that the text was ‘written by a strong student’. The last text was considered AI-generated by half of the participants. The other participants expressed doubts but opted for human writing. One participant reported: ‘Even though AI’s sentence structure can be quite repetitive, I feel this much repetition indicates human writing.’ Another participant said: ‘My instincts say AI, but I believe this is just someone trying very hard to make it fun and upbeat.’

Only one participant was able to identify all fve AI-generated texts, but this participant also identifed two texts as AI-generated which were in fact written by EFL learners. Four participants were able to identify four out of fve AI-generated texts. All four participants selected the three texts that were linked. Finally, one participant only identifed two texts as AI. This participant also selected one text written by a learner as an AI-generated text. Interestingly, the fnal participant did not select any of the texts that were generated in the same chat.

The results of this study are in line with previous studies that have investigated the use of AI in L2 writing. Alexander, Savvidou, and Alexande (2023) and Maimone and Jolley (2023) found that teachers often start from a defcit model in which teachers attribute lower-profciency texts to L2 learners because they expect characteristics of learner language to be visible in the text. The participants in the present study did the same and looked for errors (such as spelling and grammatical errors) to attribute texts to L2 learners. As the learners’ level was intermediate this often proved to be a successful method. However, some texts that were written by learners were considered to be AI-generated because they did not contain these errors. The results of the study show that it can be challenging for novice teachers to detect AI-generated text. Therefore, it is important that this topic is covered during teacher training so learners can get more insights into AI-generated output and the ways to look at this. This could be done by sharing results from studies such as these and pointing towards linguistic and content-related aspects that might help to detect AI-generated text. Teacher trainers could provide their students with a checklist. As there were diferences in the success rate between the participants and not all novice teachers relied on the same strategies, it might also prove interesting to collaborate with other novice teachers during teacher training in order to get acquainted with various possible strategies. Hopefully, they will then continue this practice as EFL teachers. As EFL teachers, they will know the learners who wrote the text and their overall performance and writing style. This will also be helpful when assessing their learners’ writing.

The results of the current study further show diferences with previous studies (e.g. Alexander, Savvidou, and Alexander 2023). The participants in our study did not only take linguistic features into account but they also considered the text’s content. More personal and creative texts were often considered to be written by EFL learners. This fnding suggests that teachers were now more acquainted with the type of output generated by ChatGPT than in previous studies and could therefore additionally look at content.

As the technology is still relatively new, further studies should be conducted that investigate how teachers integrate ChatGPT and other AI tools in their teaching. These studies could compare text generated by various LLMs and texts written by EFL learners and could address various types of writing tasks.

Recent studies have further recommended that teachers should try and integrate AI in the writing process and should modify their writing assignments accordingly. Barrot (2023), for example, suggests that rather than relying on ChatGPT to do the actual writing, learners could refne and edit their written work using ChatGPT. Various studies investigated the afordances of ChatGPT in academic writing (e.g. Nugroho et al. 2024) and found that ChatGPT can help students improve their writing through paraphrasing, help with writing mechanics, etc. As the present study shows that it is difcult for teachers to distinguish between texts written by learners and AI-generated texts, and LLMs seem to be here to stay, future studies should address the ethical inclusion of LLMs in writing and explore ways to meaningfully incorporate the tools in the EFL classroom.

Final version received May 2024

# Supplementary material

Supplementary material is available at ELT Journal online.

# References

Ho, D. G. E. 2006. ‘The Focus Group Interview: Rising to the Challenge in Qualitative Research Methodology. Australian Review of Applied Linguistics 29(1):5.1–5.19. https://doi.org/10.2104/aral0605   
Kasneci, E., K. Sessler, S. Küchemann, M. Bannert, D. Dementieva, F. Fischer, U. Gasser, G. Groh, S.   
Günnemann, E. Hüllermeier, S. Krusche, G. Kutyniok, T. Michaeli, C. Nerdel, J. Pfefer, O. Poquet, M.   
Sailer, A. Schmidt, T. Seidel, G. Kasneci, J. Weller, J. Kuhn, and G. Kasneci. 2023. ‘ChatGPT for Good? On Opportunities and Challenges of Large Language Models for Education.’ Learning and Individual   
Diferences 103:102274. https://doi.org/10.1016/j.   
lindif.2023.102274   
Mackey, A., and S. Gass. 2005. Second Language   
Research: Methodology and Design. Routledge, New York.   
Maimone, L., and J. Jolley. 2023. ‘Looks Like Google to Me: Instructor Ability to Detect Machine Translation in L2 Spanish Writing.’ Foreign Language Annals   
56(3):627–44. https://doi.org/10.1111/fan.12690   
Nugroho, A., E. Andriyanti, P. Widodo, and I.   
Mutiaraningrum. 2024. ‘Students’ Appraisals PostChatGPT Use: Students’ Narrative After Using   
ChatGPT for Writing’. Innovations in Education and Teaching International 1–13. https://doi.org/10.1080/147 03297.2024.2319184   
OpenAI. 2024. ChatGPT. https://openai.com/blog/ chatgpt/. Consulted on 25 February 2024. Belgium. She received a PhD in linguistics from   
Ghent University. Her research interests are secondlanguage teaching methodology and second-language development. She teaches courses in second-language teaching methodology and is involved in the guidance and coaching of student teachers. Her work has   
been published in journals such as Journal of Second Language Writing, Language Learning, Language   
Teaching Research, and Studies in Second Language Acquisition.   
Email: vanessa.dewilde@ugent.be