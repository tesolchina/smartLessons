# Integrative Literature Review

# Teaching AI Ethics in Technical and Professional Communication: A Systematic Review

NUPOOR RANADE $\textcircled{1}$ AND MARLY SARAVIA $\textcircled{1}$

Abstract—Introduction: This article presents the results of an integrative literature review on artificial-intelligence (AI) literacy and AI ethics in technical and professional communication (TPC). This article demonstrates how these concepts have or have not been discussed and studied by the field. By analyzing the literature from adjacent fields and trade journals, this article sets the groundwork for pedagogies and best practices that prepare technical and professional communicators to evaluate AI technologies using ethical perspectives. Research methodology: We used the hermeneutic methodology to conduct a systematic literature review that allowed repeated cycles of searching, filtering, and interpretation across wide-ranging, interdisciplinary academic sources. Following this method to include and exclude sources resulted in a total of 32 articles that describe different case studies, frameworks, theories, and other pedagogical activities to incorporate AI ethics literacy in the curriculum. Results and discussion: Recent trends within AI ethics education document and advocate for a redesign of educational programs and curricula. To be more intentional in adopting AI ethics in pedagogy, we propose a thre -level framework (consisting of institutional, course, and instruction levels) that can be aligned to include AI ethics literacy in course and program objectives and outcomes. By drawing from technical communication work on AI literacy and mapping other TPC work that can be utilized for teaching AI ethics, we recommend incorporating AI ethics in existing courses or new ones. We also list the challenges of choosing one approach over another. Conclusions and further research: A systematic approach to AI pedagogy can help TPC instructors use existing resources to help students use, understand, and evaluate AI technology in strategic ways. This research can be expanded to include new pedagogical approaches, and by drawing connections of AI ethics to specific TPC theory, especially social justice and audience analysis.

Index Terms—Artificial-intelligence (AI) ethics, course level, hermeneutic literature review, institutional level, instruction level AI literacy, literacy.

user research through their rhetorical understanding and sensitivity to observe similarities and differences across cultures and user groups. Ethics is embedded in technical communication (TC) pedagogy and curricula through topics, such as user analysis, social justice, accessibility, and so on. As we prepare to incorporate artificial intelligence (AI) in the TC curriculum, we also need to consider including AI ethics and topics beyond user research, such as privacy, surveillance, bias, discrimination, human roles in augmented AI spaces, etc., to help students make informed decisions while using AI technology for content development. While using AI to support content development, technical communicators can and should use their user research skills to consider audience needs and individual characteristics that create these needs.

Despite being relevant to TC work, research on AI ethics or AI in general has been sparse in the field of TC as well as in writing and rhetoric [1]. Scholars and practitioners alike are finding connections and developing methods to learn and teach AI as relevant to technical communicators. In Writing Futures, Duin and Pedersen [2] emphasized the need for technical communicators to expand their understanding of digital literacy as humans and machines work together as the first step to learn about the potential of AI. They argue that although AI plays a supporting role, digital literacy for writing futures means no longer viewing humans and machines as separate agents but developing the ability to view the world as these fragments stitched together. Most other literature that describe AI and algorithmic writing (see, for example, [3], [4], and [5]) focuses on computational rhetoric and digital writing. Verhulsdonck, Howard, and Tham [6] argued that AI introduces a “responsibility gap” where it is not clear who (engineers, companies, software) is responsible for the outcomes. This makes AI ethics a crucial field and technical communicators, with their focus on user-friendliness, fit to work in this burgeoning area [6].

![](img/e4c1ff15ccdf7d85e40355f3bdd15863719e1548fee320e2e0e55786de145944.jpg)

Our motivation for this article comes from understanding the significance of AI ethics in TC curricula and the lack of methods and pedagogical approaches to do so in TC literature. In this article, we seek to address two main research questions.

RQ1. What are important considerations for incorporating AI ethics literacy in technical and professional communication (TPC) curricula?

RQ2. What specific strategies can be used to incorporate AI ethics literacy in TPC curricula?

As conversations about responsibility for social and ethical implications of AI continue, it is important to identify what kind of training our future technologists are receiving and what are some useful interventions for those training practices. Although the TC field has only recently started thinking of ways to include AI and AI ethics, other disciplines, such as computer science, education, human–computer interaction, and business, have been working toward it for some time. However, those programs are also struggling with defining specific strategies. In the US, computer science programs are required to include ethics in their curricula for accreditation, yet universities and professors are left to determine how to implement it [7]. This article attempts to address this issue by surveying adjacent literature from various disciplines and drawing from works that provide specific directions to carry out this work. We use the hermeneutic literature review method to do so.

The hermeneutic analysis provided us opportunities to find relevant work that could be borrowed from the TPC field. Since AI ethics literacy is a burgeoning field, a substantial amount of literature has been produced in the past few years, especially since 2015. But AI research is more than 50 years old. Significant research on data and algorithms contributing to AI ethics has been done in the last two decades. Therefore, systematic literature methods, such as PRISMA [8], which focus on specific time ranges to analyze the breadth of research, would have fallen short for our study. A hermeneutic analysis helped us look at more focused and relevant work.

The next sections provide more details on our process of conducting the systematic literature review and will describe our findings. The Results section provides details about our observations that resulted in a three-level framework that can be beneficial not only to the TPC field, but to any other programs that are attempting to include AI ethics in their curricula. Finally, we provide specific takeaways for TPC programs based on opportunities and challenges of incorporating AI ethics in new courses versus existing courses in

# Practitioner Takeaway

The target audience for this study is those who are responsible for developing and managing academic programs. This study will help them be more intentional in adopting Al ethics in pedagogy by using our framework consisting of institutional, course, and instruction levels that can be aligned to include Al ethics literacy in course and program objectives and outcomes. The summary and linking of literature and scholarly work can be used by TPC instructors seeking specific guidance on incorporating Al ethics in their coursework. Researchers can use the hermeneutic literature analysis method to find relevant work from adjacent fields that cannot be found in the TPC field. This paper provides a systematic explanation on how to do that.

TPC programs. We conclude with some future directions of this work.

# RESEARCH METHODOLOGY

In this study, we used the hermeneutic literature review method, as defined by Boell and CecezKecmanovic [9]. This decision is supported by its uniquely iterative process, which proved necessary to our review as the key concepts of our study, AI, ethics, and education, are fluctuating in nature, and the interpretation of pedagogical materials for these concepts presents an element of subjectivity. We also found this approach necessary as the fields of technology and ethics continually evolve, making it difficult to remain both exhaustive and relevant to our search. Although this approach might seem too broad, it allowed us to include overlapping fields that are adjacent to AI and its educational efforts (i.e., computing, engineering, and general ethics education). As noted in Carter, Liu, and Cantrell [10], we were able to identify “highly relevant publications” to our inquiry, rather than examine all resulting literature from our search, as the variety of sources was not all directly related to our research.

Our method relies on two hermeneutic circles: the search and acquisition circle and analysis and interpretation (see Fig. 1). The search and acquisition circle refers to our searching, selecting, acquiring, and reading relevant literature. This process of reading is directly linked to the intertwined, wider circle of analysis and interpretation—as literature is “identified, search strategies are refined and the hermeneutic searching circle continues” [9, p. 263]. For this study, we define both circles by the mentioned parameters and identify our methods to understand the trends, practices, and discussions for AI literacy and ethics education.

![](img/06e8fd856686f99a55bc07a87c637d51e486f0240e47e9eed5d902501cb45d45.jpg)  
Fig. 1. Hermeneutic framework for the literature review [9].

# Search and Acquisition

Searching for Literature: We defined a search strategy relevant to AI ethics, literacy, and its education efforts. We began this survey of literature through the search of various keywords, such as AI, ethics, postsecondary, and education, on multiple databases, including ACM Digital Library, ProQuest, and similar platforms. All used search terms and their combinations were contained in a spreadsheet with their numerical results. Following the nature of a hermeneutic review, sources outlined in this spreadsheet were not exhaustive and were included based on their relevance to the research questions. We then adjusted our search to the keywords with the most generated output of sources, with consideration to any overlapping references. This decision was supported by 1. the continual use of specific keywords, such as AI literacy and ethics, and 2. the minimal output for other keywords (i.e., interdisciplinary, postsecondary, and pedagogy).

TABLE I DATA COLLECTION FOR LITERATURE ANALYSIS   

<html><body><table><tr><td>Time Period Considered</td><td>Databases Used</td><td>Primary Keywords</td><td></td><td>Secondary Keywords</td></tr><tr><td>2017-2022</td><td>: ACM Digital Library</td><td>:</td><td>Al Ethics</td><td>:</td><td> AI Ethics AND Literacy</td></tr><tr><td></td><td>:</td><td>ProQuest</td><td>: Education</td><td>:</td><td>Al Ethics, Education</td></tr><tr><td></td><td>.</td><td> Taylor &amp; Francis</td><td></td><td></td><td>AND Case Studies</td></tr><tr><td></td><td></td><td>Wiley Online</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td>Springer Link</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td>NIH</td><td></td><td></td><td></td></tr></table></body></html>

It is important to note that the resulting keywords are derived from fields adjacent to TC, of which AI ethics and/or literacy education were already implemented—this is due, in part, to the current, narrow selection of such literature in the field. As our review intends to examine educational efforts, our keywords remain specific to AI education curricula, but general to the field of AI and machine learning. Similarly, the intentions for the following keywords were to limit any intricacies expected of literature centered on AI and its related subtopics.

The following review focuses primarily on five key terms: AI, ethics, literacy, education, and case studies. A variation of keywords was used for each search; this includes the use of primary keywords (i.e., AI ethics and education), and their combination with secondary keywords (i.e., AI ethics and literacy) (see Table I). Due to the nature of the study, all keywords were selected based on their relevance to pedagogical efforts; this is best demonstrated in keywords, such as AI, literacy, and education. Keywords, such as ethics and case studies, were included based on current discourse on AI literacy, which inevitably include ethical discourse and intervention efforts, many of which are documented via case studies.

For our search, we focused on literature published from 2017 until 2022. This is mainly supported by the exponential presence of AI seen in both education and interdisciplinary fields, and the recent discussion of its ethical considerations. Our concentration on contemporary literature aims to include relevant discussions of AI technologies and their capabilities, as this influences the discourse of our review. Similarly, recent publications are included due to the evolving nature of ethics— specifically, what was considered ethical 10 years ago may not be applicable for today.

literature was examined based on the criteria set for the basis of inclusion and exclusion. Literature was excluded if it 1. focused on any one domain extensively and 2. only briefly shared their findings. This basis was supported by their inability to holistically contribute to the discussion due to a limited and singular focus.

After applying the mentioned parameters, three sources were excluded, resulting in a total of 34 sources. As such, the following literature review is based on the remaining 34 sources.

Acquiring and Reading: All included sources were screened by our research team and collected in a word processing document with their appropriate citation and included notes. In a bulleted format, we recorded notes with the intention of highlighting any relevant pedagogical practices or findings. Following Geisler and Swarts, all notes were written under a memo format “to reflect on emerging themes, patterns in the data, potential points of significance in the analysis, problems, and solutions” and to support “ … an analytic design, a coding scheme, or an analysis” [11, p. 25]. All documentation was referenced to write memos and highlight keywords within each source. In this process, we explained the applicability of each source to teaching efforts, the way that each reference applied to the research topic, and any additional relevant findings. Using an iterative method, our reading informed our search, as we used our notes to source similarly based literature. Following the reading and resulting notes, we concluded that data saturation was complete.

Analysis and Interpretation As suggested by Boell and Cecez-Kecmanovic, we used analytic readings to distinguish “key concepts, findings, theories and their interpretations” and established an understanding and perspective on the literature [9, p. 265]. With the additional use of oriented

remaining literature. All literature was collected in a data extraction sheet, outlining the information for each publication, including its subject matter, application, article keywords, research methods, authors, year published, title, objective, and a brief conclusion. Based on our interdisciplinary approach, we also included sections for each source’s identifying discipline, research method, and an explanation of its methods. For each source, we composed a brief summary of 1–2 sentences, indicating relevant findings, and a separate section for any mentioned or suggested deliverables (i.e., group discussions, games, etc.); these summaries were developed with the aid of the memos mentioned earlier.

Using our notes, we mapped and classified all the literature into an identification system based on major concepts. We approached this process by first identifying initial themes in the literature, including case studies, frameworks, theories, cultural shifts, role-playing activities, and large initiatives. We identified all themes by examining the main points from our summaries, relevant findings, and memos. We then narrowed down the initial themes to three categories:

1. Hands-on pedagogical materials   
2. AI literacy and ethical AI theory and pedagogy   
3. AI ethics in curriculum design

Validity and Reliability To achieve reliability, we applied the categories to the entire dataset to demonstrate its relevance and applicability. With only a few exceptions, the units of analysis within the categories were consistent. All categories were mutually exclusive. In the case of any inconsistencies, we deliberated on the most appropriate category. Our application of the categories ultimately defined each theme appropriately, validated its inclusion, and presented the sources’ interpretation of each theme. All literature was critically assessed and examined to question or challenge our assumptions. Consequently, we arrived at a developed argument, relative to the levels at which AI literacy and ethics education may be influenced. We identify these three categories at these levels, including the instructional, institutional, and course level in postsecondary education. The next section discusses our results and interpretation of these levels.

# RESULTS

This section describes the findings of our systematic literature review. The 32 articles selected for this study were published between 2017 and 2022. Because we wanted our source journals to be multidisciplinary, we focused less on the journals and more on databases. Our sample consists of works published in the ACM Digital Library, ProQuest, Taylor & Francis, Wiley, Springer Link, and the US National Institutes of Health (NIH), which are well-known and pertinent digital databases in the study of AI ethics.

We want to note that all the sources that we found are not directly from the TPC space. Very little research on AI is published in TPC journals, and almost none of it discusses AI ethics literacy. However, we made sure to include articles that are from adjacent disciplines. That adjacency was determined based on the international organizations that recognize TPC scholarship, such as IEEE, ACM, and CHI.

Some significant literature contributions include Javed et al. [12], who discuss the tendency of AI ethics instruction to focus on a single domain with specific skill sets. Instead, they recommend an extensive approach to ethics education through a hybrid course that blends general ethics modules with a domain-specific or profession-specific ethics module. Green [13] describes efforts to combine technical and ethical methods that have resulted in technical applications with an emphasis on representative, explicit ethical agents. Hybrid methods with ethics integrated into traditional assignments or courses have been favored among AI education practitioners [13]. The advantages of this approach include addressing time constraints while demonstrating the applicability of ethics to students [14]. However, hybrid methods may lead students to a limited ethical perspective of AI with a restricted range of subjects and must address technical gaps between students [7]. Borenstein and Howard [15] recommend including teaching the ethical design of algorithms by holding potential practitioners accountable for their systems. Although the intention of such initiatives aims to broaden the scope of AI ethics by steering away from a solely technical perspective, efforts must consider the disparities in technical competence by addressing barriers in AI literacy. Suggestions emphasize group work and drawing upon prior knowledge to see connections that provide a holistic perspective of AI [16].

These works can be broadly divided into three pedagogically differentiated categories:

Hands-on pedagogical materials that might include works describing classroom activities,

such as analyzing specific case studies and   
issues using three ethical theories to find   
similarities, differences, and potential   
advantages and disadvantages, simulated   
role-playing, and others   
AI literacy and ethical AI theory and pedagogy   
that might consist of work describing theories   
and concepts that can be used to teach AI ethics   
AI ethics in curriculum design to demonstrate   
innovative approaches to incorporate AI content   
in curriculum development

Although these categories provide a useful way to overview literature, we wanted a more suitable method that would help transfer our findings to incorporate AI ethics in curricula. Therefore, we developed a conceptual framework (see Table II) based on our analysis and application of the three categories. It is important to note that all levels in the framework, like the applied categories, are mutually exclusive in their use of the discussed literature. The following section describes the framework by explaining the levels, citing relevant examples from the literature and their applicability for course development.

Institutional Level Institutional efforts are considered as administrative engagement on behalf of any institution. This may refer to a university, industry, or workforce. References at this level concentrate on the container of AI literacy and ethics education, and the way that this context may consequently shape it. Initiatives at this level may consider the transfer from student to practitioner in developing, supporting, or encouraging curriculum at a given university. Such efforts ultimately found themselves on support from larger collectives, rather than individual educators or practitioners. The examined literature discusses initiatives, based on institutional influence and its motivation for curriculum design.

Considerations at the institutional level have critically examined the current state of AI and ethics education to include its further implications, influence, and reform. Historically, educational approaches to ethical AI have been met with time constraints, leading most undergraduate programs to prioritize technical competency; previous discussions between either an embedded or stand-alone ethics approach have further highlighted such tensions [7]. Alternative methods have proposed a modular approach in which ethical theory, discourse, and consideration are condensed into a one-week module and applied to a larger course [17]. Other one-week modules have focused extensively on project-based pedagogy and emphasized deliverables to attain after discussing ethical applications [18].

A flipped-classroom approach similarly asks students to interact with course materials at home and present their perspectives in class through debate or discussion [19]. Such methods are, however, temporary solutions to teaching and advocating for ethical AI, all of which are reflective of the limited time designated to ethics education and the priority placed on the mastery of applied or technological skills. Most critiques of current AI ethics and literacy education have suggested institutional reform of undergraduate programs, their objectives, and curriculum design to include more influence on ethical thinking.

Raji, Scheuerman, and Amironesei [20] note the relatively exclusionary nature of current programs and advocate for a reset in AI ethics pedagogy, as students are often led to assume technical competency and superiority above anyone outside their field, resulting in a general dismissal of responsibility. Incidentally, Morley et al. [21] found that AI practitioners often allocated ethical responsibilities to other departments and were uncertain how to apply critical, ethical thinking; practitioners were unsure how to follow ethical principles or value anything beyond privacy and security, which hold the greatest risk if compromised.

Ultimately, there is considerable overlap between AI ethics and AI literacy, and, as such, teaching efforts should aim to approach the two with a combined, interdisciplinary perspective. This includes advocacy for institutional reform and equally distributed time, resources, and priority placed on ethical and technical interventions to do so.

Course Level Efforts at the course level refer to the material used to direct, guide, and support course content. Such material establishes clear frameworks to guide content and may be ethical, technological, or similarly related to other principles, theories, or frameworks. The following review examines current discourse on AI literacy and ethical theory, as it may relate to education and its potential to guide instructional content.

Educators may broadly follow ethical theory and therefore draw inspiration from and extend it to other fields. Limitations with current ethical theories for AI literacy and ethics education, or related fields, include its sole focus on Westerncentric principles and theory [22]. This trend has led practitioners to advocate for cross-cultural approaches and practices. Discussions of AI and digital technologies currently include approaching theories, such as decolonial ethics. For example, Zembylas outlines AI technology and its potential to act as a valid vehicle for coloniality and racism, and suggests a reform or redesign in courses with emphasis on decolonial ethics [23]. Although varied, the current sources present the range at which content is referenced and used for courses, and acknowledge further considerations for educators when managing instructional content. This includes the relevance of course content to current issues or student interests. This may extend to concern for the society or culture with which AI literacy and ethics education is engaging, demonstrating a level of sociocultural responsibility. Similarly, integration with other fields and sources may present other implications for the direction of course content. Further use of ethical theory that indirectly applies to AI ethics and literacy must consider potential biases as well. Including resources presents an element of interpretation on behalf of the instructor. This may compromise the intentions of the course and implicitly suggest a perspective. The integration of varying resources and fields, therefore, can mitigate the issue and present further implications

TABLE IICONCEPTUAL FRAMEWORK FOR INCORPORATING AI ETHICS IN TPC CURRICULUM  

<html><body><table><tr><td>Level</td><td>Description</td><td colspan="2">Considerations</td><td colspan="2">Keywords</td><td colspan="2">Literature Samples</td></tr><tr><td>Institutional level</td><td>Administrative engagement. on behalf of any institutional</td><td></td><td>Design student assessment to get</td><td></td><td>Interdisciplinary efforts</td><td></td><td>Garrett, Beard, and Fiesler [7]</td></tr><tr><td>Where in hs i ing</td><td>fone iy,. uniwernityicec</td><td></td><td>feedback on tical</td><td></td><td>Aopratitionerss</td><td></td><td>Long ano [16]</td></tr><tr><td>that context shape it?</td><td></td><td></td><td>Assess professional demands on AI</td><td></td><td>career Transparency from</td><td></td><td>Furey and</td></tr><tr><td></td><td></td><td></td><td>ethics</td><td></td><td>educators</td><td></td><td>Martin [17] Vilaza and</td></tr><tr><td></td><td></td><td></td><td>Avoid exclusionary thinking or design</td><td></td><td> University culture</td><td></td><td>Baekgaard [18]</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>Taylor and Deb [19]</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>Amironesei [20]</td></tr><tr><td>Course level</td><td>Material used to direct,.</td><td></td><td>Student and faculty</td><td></td><td>Ethical framework</td><td></td><td>Adams [22]</td></tr><tr><td>What do we need to</td><td>guide, and support course. content</td><td></td><td>interactions</td><td></td><td>Ethical principles</td><td></td><td>Zembylas [23]</td></tr><tr><td>teach?</td><td></td><td></td><td>. Syllabus design</td><td></td><td> Ethical guidelines</td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>Theory or framework.</td><td></td><td> Sociocultural</td><td></td><td></td></tr><tr><td>Instruction level</td><td> Material used to engage</td><td></td><td></td><td></td><td></td><td></td><td>Shih et al. [24]</td></tr><tr><td></td><td>students</td><td></td><td>Case studies Practical projects that</td><td></td><td>Situated learning Reflections</td><td></td><td></td></tr><tr><td>How do we best/ effectively teach it?</td><td></td><td></td><td> mirror industry</td><td></td><td>Discussion</td><td></td><td>Hingle et al. [25]</td></tr><tr><td></td><td></td><td></td><td> Role-playing</td><td></td><td> Emotional</td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>engagement Technical</td><td></td><td>Martin et al. [26]</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>assignments</td><td></td><td>Skinner, Brown,</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>and Evans [27] Burton et al. [28]</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>Hishiyama and Shao [29]</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>Knowles [31]</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>Garingan and Pickard [32]</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>Dean and</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>Nourbakhsh [33] Skirpan et al. [34]</td></tr></table></body></html>

This independent analysis of sources may guide and motivate all course content, ranging from syllabus design to the structure of student and faculty interactions. As the integration of resources differs, the influenced course content is also at the discretion of the instructor. The literature encourages the use of varied sources, acknowledging their limitations and integrating their findings to arrive at further implications. This process may be deductive in nature (by formulating assignments and course content based on the integration or individual framework) or inductive (by supporting observed classroom trends and patterns through such frameworks). Ultimately, however, course-level efforts answer questions about what instructors need to teach and how to support these teaching efforts.

Instructional Level Applications for instructional content refer to the deliverables and media to engage or interact with students. Materials may be defined by the nature of assignments and/or the assignments themselves. Content developed at this level is independent of the frameworks and references at the course level. Instructional material can be defined as the delivery of the mentioned supportive ideologies and theories. The current literature discusses hands-on pedagogical materials focused on ethical or moral reasoning with an overall understanding of AI.

Instructional content may center on stimulating authentic experiences, with a foundation of situated learning as students “engage in an authentic experience” and interact with “real situations to build a complete body of knowledge” [24, p. 3]. This includes assignments, such as the recent adoption of role-playing, where students assume the role of actors facing an ethical or moral dilemma in a technical field [25], [26]. Similarly,

game-playing presents an extension to role-playing, by asking students to weigh potential stakes and maximize benefits specific to their characters [28]. Students may also assume technical roles similar to those in industry or the workforce, such as scenarios to design an autonomous vehicle and consider its ethical design [24].

These practices outline the benefits of accurately representing industry constraints by presenting potential advantages to gain through incentive, competition, or technical application, and the risks to consider. Moreover, situated learning, or efforts to stimulate the role of AI in the workforce and its ethical dilemmas, can be seen as an ideal exercise to foster ethical thinking or moral reasoning. The range of assignments also demonstrates the ability to integrate and utilize varying activities, situations, and roles with which students may empathize.

Although methods vary, instructional content may concentrate on a degree or variation of reflection usually following an assignment. Assignments may be reflective in nature, as instructors may ask students to analyze case studies or readings, or depend on reflection questions for assessment [28], an approach that has been shown to increase student interest and provide a holistic, ethical perspective to the subject of interest [29]. Efforts to stimulate reflection may also rely on students’ emotional or personal involvement and support current trends to use socially based applications [30].

Alternatively, reflections may be demonstrated in peer-to-peer discussions and through interviews among faculty members; Knowles [31] found that discussions are necessary and integral for AI ethics education. Similarly, opportunities for reflection may present themselves outside the structure of assignment or discourse, such as cases in which students are asked to continually reflect upon assignments, discussions, or class content [32], [33], [34]. Such reflections provide an opportunity for students to examine their level of understanding, but may also act as evaluations for the course in providing immediate feedback [34].

These outlined uses illustrate the merit of reflection in pedagogical content and its ability to engage student interest or involvement, and provide interaction in the classroom via student-to-student or student-to-faculty. Moreover, the interpretation of a “reflective” component may center itself on its ability to stimulate a student’s independent opinion, its impacts on their practices, and its

influence on their role as a potential practitioner. Regardless of the assignment, the focus on reflection can encourage outside involvement and continual engagement in which students interact with the assignment beyond grading or assessment. Reflection may therefore foster ethical reasoning independent of the course and applicable to the student’s current ethical thinking.

Instructional content includes all methods to engage students and may include assignments centered on reflection or situated learning, or practices to build upon or foster a student’s ethical reasoning. This may further extend to the application’s focus on either technical or ethical components. Content at the pedagogical level addresses concerns on the best or most effective approach to teaching a given course and its theoretical components. Relative to AI literacy and ethics, the included references may arrive from a variety of disciplines and domains; consequently, the deliverables must consider the context of the course and prospective students to remain applicable and appropriate. These approaches may be inspired or supported by course-level materials, but are distinguished as the materials that, inevitably, reach students.

The next section outlines recommendations and suggestions for both existing and new courses. The intention to include both is based on and is rooted in current limitations for course redesign; both directions are defined to anticipate the challenges, opportunities, and interrelations between them.

# DISCUSSION

Scholars and experts have suggested for years that AI is poised to significantly disrupt future education and work [35]. Generative AI has forced the TPC field to get up to speed with the technology. Such breakthroughs have always challenged instructors to address the pedagogical impacts of new technology and to discuss their impact on society, and given the ethical concerns surrounding it, AI is no exception.

In her work from 2003, Eaton [36] discussed how to include technology to support pedagogy in business, technical, and professional communication. She described how simple technologies, such as the Find feature of Microsoft Word to find content and the comment function to respond to texts within word processors, impact the work of technical communicators. She argued that TPC instructors should include innovative

technologies in pedagogy as soon as they are available to help students learn their use and implications on workplace tasks. Similarly, it is crucial for educational systems to integrate AI into teaching and learning, much like how the calculator was seamlessly incorporated into math classrooms.

But including AI in classrooms is not as simple. First, AI technology is evolving quickly. Accommodating it in classrooms requires a great amount of research and experimentation, and by the time that is done, the technology has shifted. Second, the functionalities vary tremendously. For example, in content development alone, AI tools can be used for text summarization, automated transcription, evaluating communication (oral and written), providing personalized feedback, and so on. The most important incorporation of AI technology in pedagogy is to help students critically analyze the capabilities of these tools alongside the known, emerging, and potential challenges [35].

The key is to consider AI as a narrative device for thinking about its autonomous decision-making capability and what that conveys about its risks and possibilities for AI designers and programmers [28]. Mere criticism is not enough. TPC instructors must start looking for ways to include such concerns in the curriculum, and facilitating discussions on topics surrounding AI ethics will provide an opportunity to do so.

Our findings show that such discussions must happen at the institutional, course, and instruction levels. To recap: institutional level relates to policies and programmatic decisions; course level involves tasks, such as syllabus design and considerations of theories and frameworks, to be included for teaching; and instruction level determines what assignments and activities to include in a course. We recommend two broad approaches of incorporating AI into curricula at the institutional, course, and instruction levels through existing courses and through new course modules.

Existing Courses In addition to broad policies for all sectors of society, we need education-specific changes to address issues of AI. As AI gets more and more integrated with day-to-day practices in the classroom, especially with the deep impact on professional communication, concerns about ethical practices of using AI need to be addressed within existing frameworks that take into consideration other aspects of communication and workplace practice. The quickest approach is to

include activities and discussions in existing TPC courses. For example, the edited collection Teaching with Text Generation Technologies, published by WAC Clearinghouse in August 2023, lists more than 20 assignments, most of which were part of existing courses in rhetoric and composition. This section describes the opportunities and challenges of modifying existing course curricula to incorporate AI ethics.

Opportunities: Cardon et al.’s [37] latest research from May 2023 found that most communication instructors needed to change their teaching to integrate AI-related content into their courses. Whether they were enthusiastic about the change or not, most instructor participants started integrating AI by implementing course modules in their existing courses. They believed that AI tools should be addressed in classrooms because they will be widely used in the workplace and that students are already using them outside the classroom.

Through our literature analysis, we found that the implementation of AI ethics curriculum in AI classes is more direct. State the following for what students should do:

1. Think about the ethical issues that AI technologies and systems raise   
2. Learn about ethical theories (deontology, utilitarianism, and virtue ethics) that provide frameworks that enable them to think about the ethical issues   
3. Apply their knowledge to one or more case studies, both to describe what is happening in them and to think about possible solutions to the ethical problems they pose [28]

A similar structure can be followed in existing courses, for example, in professional writing classrooms when students are working on developing cover letters.

1. The use of generative AI, such as ChatGPT (or other technology), can be brought to the discussion.   
2. Instead of all ethical theories, students would be taught to critically analyze the work produced by AI in comparison to a human-written cover letter by looking at aspects, such as application, authenticity, accountability, agency [37], autonomy of human versus the AI (that is, where the AI’s decisions of content development are being accepted or rejected by humans), and so on. Such questions must then be addressed through proper reasoning.

3. To apply their knowledge, we can practice what Cardon et al. [37] described as workplace integration.

A major advantage of integrating AI ethics in existing coursework follows the findings from the literature. To innovate, instructors need resources, support, and encouragement from the institution they are part of. Changes to courses can be made quickly, and student feedback through course evaluations can help demonstrate the impact on student learning to administrators. Accordingly, administrators can then consider how the institutional culture and structure hinder instructor-driven innovation and how they can facilitate it. For example, if larger classroom sizes hinder the ability to conduct extensive exercises that utilize complex technological knowledge and implementation in classrooms, administrators can consider how to reallocate other resources to allow smaller teaching loads and smaller class sizes so that instructors can deliver more personalized learning.

An alternative approach to incorporate AI ethics in existing TPC courses is the one proposed by Getchell et al. [35]. TPC instructors can do the following.

# - Use frameworks to guide discussion:

Frameworks are valuable because they allow decision makers to assess the situation from multiple angles while providing a structure for the process. It also does not force the learner into choosing a singular possibility for action. Scholars have described several cultural political frameworks to address the question of currency, such as Jones’s [38] work on the “power of rhetorical design,” Daskalaki’s [39] work on “resistance assemblages,” Spinuzzi’s [40] work on learning across boundaries, and so on. Another crucial resource is Haas and Eble’s [41] edited collection Key Theoretical Frameworks: Teaching Technical Communication in the Twenty-First Century. The book utilizes a top–down approach to apply social justice and critical race theoretical frameworks to TC. It argues that to see changes in TC, major adjustments are necessary in TC pedagogy. The frameworks mentioned in the book can help administrators imagine a program-wide implementation (in TPC programs), considering the diversity of topics and applications. TPC instructors can benefit at the course and instruction level from the class-level case studies and student response data.

Align research and instruction with practices from current business environments: We can explore possible partnerships with TC businesses to cultivate workplace integration through individual initiatives to fulfill our responsibility to the field’s needs and a shared research agenda. Dubinsky’s [42] concept of “engagement” needs to be reinvoked. He suggested that academics at land-grant universities should build relationships with industry, not with the mindset of expert problem solvers but as participants who want to help document a community’s assets. Other scholars, such as Herb Smith, Susan Katz, and Kenneth Price have also affirmed the need to establish bridges with industry research units by establishing internships, mentoring, and experiential learning, which not only prepare students for their lives after graduation but also benefit academic programs. Students can bring back valuable knowledge about practice from these experiences that can inform teaching and curriculum.

- Develop teaching practices to improve students’ ethical proficiency alongside technical proficiency: Industry partnership can help bring relevant case studies for discussion into the classroom. Through internships, service-learning, consulting, and research, TC faculty and students can engage in meaningful collaborations, thus bringing useful insights to the classroom.

Challenges: Instructors can be resistant to changing their existing curricula to include AI ethics for several reasons. Cardon et al.’s [37] study found that some instructors resisted incorporating AI concepts because they worried about their ability to adapt based on their existing knowledge or skill sets, or simply because they did not have time to get up to date. Another challenge for incorporating the discussion of technology is related to the complexity of the technology. Universities and colleges have embraced the importance of speaking and communication skills across multiple disciplines. Professional communication courses work well as service-learning courses and are adopted extensively across all major institutions. However, AI is a technology that is close to data science, and communicating about complex topics in data science might be needed for teaching as well as analyzing case studies. Creating a new course through intercollege partnerships that includes multiple instructors might be a good solution to overcome some of these challenges.

New Course Modules This section briefly presents considerations for AI ethics and literacy as a new course, relative to the consequential opportunities and potential limitations. Opportunities highlighted include the ability to accurately cover AI ethics as a separate function, present multidisciplinary advantages, and provide relevant industry experience. Similarly, we define challenges by outlining the current university structure, costs and funding, and lack of industry partners. It is important to note that the central topic does not list every instance and instead focuses on connections relevant to our literature.

# Opportunities:

AI Ethics as a Separate Component As previously established in the literature, incorporating ethics into traditionally technical courses has resulted in varying methods, including but not limited to current discussions of an embedded or integrated approach to ethics instruction [44]. Such applications are motivated by limitations of time versus the density of ethics instruction. Technically based AI courses may allocate time for ethics “if time allows” and offer a limited, condensed perspective for such instruction [7, p. 276]. The advantages of a newly established course, therefore, allow for comprehensive and inclusive ethics instruction. Curriculum developments can disregard current or previously established courses, permitting instructors and instructional designers to expand course material and promote an extensive AI ethics and literacy course. Moreover, the introduction of a new course affords the ability to discuss ethical interventions in-depth and grants liberty to instructors to launch a varied foundation of theories, applications, and relevant case studies.

- Multidisciplinary Influence New course development and a focus on AI literacy and ethics also lend themselves to multidisciplinary influence and perspectives. Using an interdisciplinary approach, TC programs may benefit from outsourcing relevant course materials from other related programs, remaining responsive to changes in the field, and building a broad range of skills for students [45]. Students also benefit from observing and participating in interdisciplinary behaviors, on behalf of their instructors, thereby encouraging similar efforts during postgraduation [46]. Although existing courses may still engage in interdisciplinary or multidisciplinary efforts, there is merit in introducing such methods with a new course. Courses are developed with multiple disciplines at its core and foundation, presenting a path of less resistance.

- Relevant Industry Experience As TC continues to evolve and intersect with other fields, its implementation remains a reflection of industry changes, mirroring its practices and preparing students for its current state. Verhulsdonck, Howard, and Tham [6] discuss these “streams” that TC is interacting with, including recommendations for instructors and practitioners, and illustrate the exigence to adopt such trends. This includes design thinking, content strategy, and AI. Similarly, AI curriculum initiatives stress the importance of career development and industry experience by adhering to current workforce demands, presenting valid skill sets, and connecting student learning with professional opportunities [47]. The adoption of AI tools by the TC field is inconsistent with current teaching efforts and urgently calls for a basis in AI literacy. The implementation of a new course can equip students with industry-related and relevant experience based on current trends through its advocacy of multiple disciplines, varied approaches, and affordances to stay current.

Challenges: Challenges in the new course model are limitations in university structure, funding, and potential partnerships.

The current university structural model accommodates varying and potentially conflicting goals, as all levels and their participants (administrators, instructors, and faculty members) have different aims [48]. Moreover, universities are no longer incentivized to protect tenured positions, limiting faculty and their autonomy in introducing new pedagogies and lines of research. Universities are centered on their capitalization, hiring more administrators as a result, and eroding the “shared governance” in which faculty members advocate for institutional decision making [49]. Such structures are intimidating and discourage instructors seeking to initiate and promote new courses or overall change.

Relative to the current university structure, cost and funding models are inconsiderate of new course development. Mehaffy [48] notes the instability of the current tuition model, as prices increase and universities continue to operate as businesses with little allocation of resources to encourage innovation. Consequently, advocating for a new course and its required resources may prove to be inefficient. Instructors, with minimal influence over curriculum and institutional initiatives, may also find it difficult to justify such developments. Implications and challenges for such a model are unique to introducing a new course and may instead lead instructors to integrate materials into their existing courses.

A course relevant to industry must prepare students with appropriate experience. In the past, TC courses have successfully guaranteed skill sets, with emerging fields such as content strategy [50]. In doing so, TC has relied on partnerships between universities and the specified industry, either through casual or formal interactions, and courses have included such instances based on a relationship. Current gaps in TC and AI interactions provide a minimal opportunity to provide industry experiences.

Currently, limited partnerships between practitioners in both fields present challenges in implementing such coursework. Moreover, issues and conflicts of interest arise when preferences and goals are not aligned between industry and academe; ethical contentions may result from the lack of incentive for companies to act responsibly, compared to academe [51]. Current dynamics may lead instructors with limited course materials relevant to industry; this may include datasets, client projects, and appropriate tools.

# CONCLUSION

The goal of this article was to highlight the importance of fostering AI literacy and teaching ethical perspectives to students. Although current methods suffice to demonstrate our perspective, they are not exhaustive and are still limited. Challenges were present in conducting our hermeneutic review, including the potential to narrow our focus, leading to a restricted sample of literature, and inaccurately capturing the scope of our review. In addition, as this review was conducted prior to the mainstream use of AI systems, such as ChatGPT, our review does not include the incoming flux of experimental, theoretical, and observational research currently populating all fields. Terms such as “Big Data and ethics,” though relevant, would have posed bigger challenges for scoping this work and therefore were not included. Such limitations are relative to and are a reflection of our constraints, considering time and resources.

This literature review is by no means meant to be comprehensive. The timeframe we used (five years) is short, and the research is exponentially growing. Despite these challenges and the risk of including fewer but most relevant keywords, literature pieces, and case studies for pedagogical concepts, the findings we report serve as a nonexhaustive repository of resources that can be continually updated to include the latest and useful resources that impact the pedagogy of AI ethics in TC curricula.

Consequently, future research will certainly benefit from the inclusion of more literature, the

development of a timeline conscious of AI advancements, and the use of more case studies from the field. The use of other literature review frameworks may also document findings that are different from those proposed in this article. Researchers may benefit from considering this aspect with respect to their research objective. Ultimately, future research may address and expand upon the challenges present in this article. The outlined methods serve our research questions by highlighting the recent efforts for AI literacy and ethics education, resulting in recommendations for both new and existing courses.

# REFERENCES

[1] N. Ranade, M. Saravia, and A. Johri, “Using rhetorical strategies to design prompts: A human-in-the-loop approach to make AI useful,” AI Soc., pp. 1–22, 2024. [2] A. H. Duin and I. Pedersen, Writing Futures: Collaborative, Algorithmic, Autonomous. Berlin, Germany: Springer, 2021. [3] W. Hart-Davidson, “Writing with robots and other curiosities of the age of machine rhetorics,” in The Routledge Handbook of Digital Writing and Rhetoric, J. Alexander and J. Rhodes, Eds., Evanston, IL, USA: Routledge, 2018, pp. 248–255. [4] H. A. McKee and J. E. Porter, “Human-machine writing and the ethics of language models,” in Proc. 21st Annu. Conf. Assoc. Internet Res., Oct. 2020, pp. 1–5. [5] G. Marcus and E. Davis, “Insights for AI from the human mind,” Commun. ACM, vol. 64, no. 1, pp. 38–41, 2020. [6] G. Verhulsdonck, T. Howard, and J. Tham, “Investigating the impact of design thinking, content strategy, and artificial intelligence: A ‘streams’ approach for technical communication and user experience,” J. Tech. Writing Commun., vol. 51, no. 4, pp. 468–492, 2021. [7] N. Garrett, N. Beard, and C. Fiesler, “More than” if time allows” the role of ethics in AI education,” in Proc. AAAI/ACM Conf. AI, Ethics, Soc., Feb. 2020, pp. 272–278. [8] R. Sarkis-Onofre, F. Catalá-López, E. Aromataris, and C. Lockwood, “How to properly use the PRISMA Statement,” Systematic Rev., vol. 10, no. 1, pp. 1–3, 2021. [9] S. K. Boell and D. Cecez-Kecmanovic, “A hermeneutic approach for conducting literature reviews and literature searches,” Commun. Assoc. Inf. Syst., vol. 34, no. 1, pp. 257–286, 2014.   
[10] L. Carter, D. Liu, and C. Cantrell, “Exploring the intersection of the digital divide and artificial intelligence: A hermeneutic literature review,” AIS Trans. Human-Comput. Interaction, vol. 12, no. 4, pp. 253–275, 2020.   
[11] C. Geisler and J. Swarts. Coding Streams of Language: Techniques for the Systematic Coding of Text, Talk, and Other Verbal Data. Ft. Collins, CO, USA: WAC Clearinghouse, 2019.   
[12] R. T. Javed et al., “Get out of the BAG! Silos in AI ethics education: Unsupervised topic modeling analysis of global AI curricula,” J. Artif. Intell. Res., vol. 73, pp. 933–965, 2022.   
[13] B. Green, “Data science as political action: Grounding data science in a politics of justice,” J. Social Comput., vol. 2, no. 3, pp. 249–265, 2021.   
[14] L. Bezuidenhout and E. Ratti, “What does it mean to embed ethics in data science? An integrative approach based on microethics and virtues,” AI Soc., vol. 36, no. 3, pp. 939–953, 2021.   
[15] J. Borenstein and A. Howard, “Emerging challenges in AI and the need for AI ethics education,” AI Ethics, vol. 1, pp. 61–65, 2021.   
[16] D. Long and B. Magerko, “What is AI literacy? Competencies and design considerations,” in Proc. CHI Conf. Human Factors Comput. Syst., Apr. 2020, pp. 1–16.   
[17] H. Furey and F. Martin, “AI education matters: A modular approach to AI ethics education,” AI Matters, vol. 4, no. 4, pp. 13–15, 2019.   
[18] G. N. Vilaza and P. Bækgaard, “Teaching user experience design ethics to engineering students: Lessons learned,” Front. Comput. Sci., vol. 4, 2022, Art. no. 793879.   
[19] G. Taylor and D. Deb, “Teaching AI ethics in a flipped classroom,” J. Comput. Sci. Coll., vol. 36, no. 5, pp. 67–76, 2021.   
[20] D. Raji, M. K. Scheuerman, and R. Amironesei, “You can’t sit with us: Exclusionary pedagogy in AI ethics education,” in Proc. ACM Conf. Fairness, Accountability, Transparency, Mar. 2021, pp. 515–525.   
[21] J. Morley, A. Elhalal, F. Garcia, L. Kinsey, J. Mökander, and L. Floridi, “Ethics as a service: A pragmatic operationalisation of AI ethics,” Minds Mach., vol. 31, no. 2, pp. 239–256, 2021.   
[22] R. Adams, “Can artificial intelligence be decolonized?,” Interdiscipl. Sci. Rev., vol. 46, no. 1-2, pp. 176–197, 2021.   
[23] M. Zembylas, “Encouraging moral outrage in education: A pedagogical goal for social justice or not?,” Ethics Educ., vol. 16, no. 4, pp. 424–439, 2021.   
[24] P. K. Shih, C. H. Lin, L. Y. Wu, and C. C. Yu, “Learning ethics in AI—Teaching non-engineering undergraduates through situated learning,” Sustainability, vol. 13, no. 7, 2021, Art. no. 3718.   
[25] A. Hingle, H. Rangwala, A. Johri, and A. Monea, “Using role-plays to improve ethical understanding of algorithms among computing students,” in Proc. IEEE Frontiers Educ. Conf., Oct. 2021, pp. 1–7.   
[26] D. A. Martin, A. Johri, A. Hingle, and T. Lennerfors, “Role-playing hypothetical stakeholder scenarios,” in Proc. 49th SEFI Annu. Conf. 2021: Blended Learn. Eng. Educ.: Challenging, Enlightening– Lasting?. Eur. Soc. Eng. Educ., 2021, pp. 1580–1583.   
[27] I. Skinner, S. Brown, and R. Evans, “Unplugged game-play motivates the study of engineering ethics,” in Proc. IEEE Int. Conf. Teach., Assessment, Learn. Eng., Dec. 2018, pp. 794–797.   
[28] E. Burton, J. Goldsmith, S. Koenig, B. Kuipers, N. Mattei, and T. Walsh, “Ethical considerations in artificial intelligence courses,” AI Mag., vol. 38, no. 2, pp. 22–34, 2017.   
[29] R. Hishiyama and T. Shao, “Educational effects of the case method in teaching AI ethics,” in Proc. World Conf. Inf. Syst. Technologies. Apr. 2022, pp. 226–236.   
[30] B. Hoffman, “Designing critical thinking experiences in online courses during a global pandemic: A narrative research study exploring community college instructors’ approach to course design and promoting critical thinking skills,” Ph.D. dissertation, School Educ., Northeastern University, Boston, MA, USA, 2021.   
[31] M. A. Knowles, “Five motivating concerns for AI ethics instruction,” Proc. Assoc. Inf. Sci. Technol., vol. 58, no. 1, pp. 472–476, 2021.   
[32] D. Garingan and A. J. Pickard, “Artificial intelligence in legal practice: Exploring theoretical frameworks for algorithmic literacy in the legal information prof.,” Legal Inf. Manage., vol. 21, no. 2, pp. 97–117, 2021.   
[33] V. Dean and I. Nourbakhsh, “Teaching ethics by teaching ethics pedagogy: A proposal for structural ethics intervention,” in Proc. 53rd ACM Tech. Symp. Comput. Sci. Educ., Feb. 2022, pp. 272–278.   
[34] M. Skirpan, N. Beard, S. Bhaduri, C. Fiesler, and T. Yeh, “Ethics education in context: A case study of novel ethics activities for the CS classroom,” in Proc. 49th ACM Tech. Symp. Comput. Sci. Educ., Feb. 2018, pp. 940–945.   
[35] K. M. Getchell et al., “Artificial intelligence in business communication: The changing landscape of research and teaching,” Bus. Prof. Commun. Quart., vol. 85, no. 1, pp. 7–33, 2022.   
[36] A. Eaton, “Technology-supported pedagogy in business, technical, and professional communication,” Bus. Commun. Quart., vol. 66, no. 3, pp. 113–117, 2003.   
[37] P. Cardon, C. Fleischmann, J. Aritz, M. Logemann, and J. Heidewald, “The challenges and opportunities of AI-assisted writing: Developing AI literacy for the AI age,” Bus. Prof. Commun. Quart., vol. 86, no. 3, pp. 257–295, 2023.   
[38] N. N. Jones, “Narrative inquiry in human-centered design: Examining silence and voice to promote social justice in design scenarios,” J. Tech. Writing Commun., vol. 46, no. 4, pp. 471–492, 2016.   
[39] M. Daskalaki, “Alternative organizing in times of crisis: Resistance assemblages and socio-spatial solidarity,” Eur. Urban Regional Studies, vol. 25, no. 2, pp. 155–170, 2018.   
[40] C. Spinuzzi, “Losing by expanding: Corralling the runaway object,” J. Bus. Tech. Commun., vol. 25, no. 4, pp. 449–486, 2011.   
[41] A. M. Haas and M. F. Eble, Eds., Key Theoretical Frameworks: Teaching Technical Communication in the Twenty-First Century. Logan, UT, USA: Utah State Univ., 2018.   
[42] J. M. Dubinsky, “Service-learning and civic engagement: Bridging school and community through professional writing projects,” presented at the 5th Annual Meeting of the Warwick Writing Programme, Coventry, UK, Mar. 26–27, 2001.   
[43] T. Bridgeford and K. S. Amant, Academy-Industry Relationships and Partnerships: Perspectives for Technical Communicators. New York, NY, USA: Taylor & Francis, 2017.   
[44] B. J. Grosz et al., “Embedded EthiCS: Integrating ethics across CS education,” Commun. ACM, vol. 62, no. 8, pp. 54–61, 2019.   
[45] T. A. Carnegie and K. Crane, “Responsive curriculum change: Going beyond occupation demands,” Commun. Design Quart. Rev., vol. 6, no. 3, pp. 25–31, 2019.   
[46] M. E. Exter and I. Ashby, “Preparing today’s educational software developers: Voices from the field,” J. Comput. Higher Educ., vol. 31, pp. 472–494, 2019.   
[47] J. Southworth et al., “Developing a model for AI Across the curriculum: Transforming the higher education landscape via innovation in AI literacy,” Comput. Educ.: Artif. Intell., vol. 4, 2023, Art. no. 100127.   
[48] G. L. Mehaffy, “Challenge and change,” Educause Rev., vol. 47, no. 5, pp. 25–42, 2012.   
[49] R. M. Curnalia and D. Mermer, “Renewing our commitment to tenure, academic freedom, and shared governance to navigate challenges in higher education,” Rev. Commun., vol. 18, no. 2, pp. 129–139, 2018.   
[50] V. D. Robles and J. Frith, “Developing a content strategy course and interdisciplinary skills: A teaching case,” in Proc. 36th ACM Int. Conf. Design Commun., Aug. 2018, pp. 1–6.   
[51] A. Melde et al., “Tackling key challenges of AI development–insights from an industry-academia collaboration,” in Proc. Upper-Rhine Artif. Intell. Symp. UR-AI 2022: AI Appl. Med. Manuf., Villingen-Schwenningen, Germany, Oct. 2022, pp. 112–121.

Nupoor Ranade is an assistant professor of Rhetoric and Technical Communication with Carnegie Mellon University, Pittsburgh, PA, USA. Through her teaching, she tries to build a bridge between academia and industry and help students develop professional networks while they also contribute to the community that they are part of. She has authored or coauthored papers published in journals including Technical Communication, AI & Society, Communication Design Quarterly, and IEEE TRANSACTIONS ON PROFESSIONAL COMMUNICATION. Her research interests include technical communication practice and pedagogy, professional writing and editing, inclusive design, and ethics of AI. Prof. Ranade is the recipient of multiple awards for her research.

Marly Saravia is a psychology graduate with George Mason University, Fairfax, VA, USA. Her research interests include technical communication, emerging technologies, and their influence on postsecondary education.