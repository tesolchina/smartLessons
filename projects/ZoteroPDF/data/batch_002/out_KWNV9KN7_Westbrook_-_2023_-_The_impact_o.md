# The impact of input format on written performance in a listening-into-writing assessment

Carolyn Westbrook a,b, \*

a Assessment Research Group, British Council, 1 Redman Place, Stratford, London, E20 1JQ, UK ' CRELLA, University of Bedfordshire, Putteridge Bury, Hitchin Road, Luton, Bedfordshire, LU2 8LE, UK

# ARTICLEINFO

# ABSTRACT

Keywords:   
Integrated assessment   
Listening-into-writing   
EAP   
Testing

Over the last five decades, research in teaching and testing (academic) listening has investigated different foci. Initially, teaching listening involved bottom-up approaches (Dirven and OakeshottTaylor, 1984) then both higher- and lower-level processes were integrated (Voss, 1984). In the early 2000s, different input formats (Read, 2002) and discourse features of lectures (Thompson, 2003) were the subjects of academic listening research. More recently, EAP tests have increasingly taken an integrated approach to reflect real-world tasks, yet few studies have looked at integrated listening-into-writing tasks (Cubilo and Winke, 2013).

This counter-balanced measures design study investigates how test taker performance differs on an integrated EAP listening-into-writing task when lecture input is presented as audio only in one half and video in the other half of the input. Two groups of test takers took part in the current study.

A Hotelling's $T ^ { 2 }$ test revealed a statistically significant effect on scores when test takers were presented with the audio only input first but there was no significant effect on scores when the video input was presented first. Data on test taker preferences revealed that more people preferred the video input to audio only.

# 1. Introduction

Many university courses around the world are offered in English, which, among ther kills requires the ability to listen to lectures and write academic papers. Therefore, universties and testing organisations measure students' English proficiency to ensure their suitability for study. This has typically been done using both discrete and integrated tasks.

Both the ELTS test and later, the IELTS test, were designed to reflect some features of academic language' (IELTS, 2019). The former included tasks with an integrated skills fus. Unfortunately, these were replaced by discrete sils sub-tests in the Es test. Yet, in recent decades, researchers have come to recognize that integrated tass reflect the target language use domain (TLU) much more closely because in an academic context there is necessrily some input for any writing task that has to be carred out (Weir, 1983, p. 376). Thus, many tests of English for Academic Purposes (EAP) now include integrated skills tass (Plakans & Geril, 2012, p. 217).

While integrated academic reading-into-writing tass have received a good deal of attention in the literature, integrated EAP listening-into-writing tass have received comparatively litl. Given the huge strides made by developments in technology and the increased possibilities to teach and test academic listening-into-writing that these have ledto, it i perhaps surprising that relatively little research has been done in this area, partcularl with regard to the different options for teaching and testing integrated EAP listening.

<html><body><table><tr><td colspan="2">Abbreviations</td></tr><tr><td>TLU</td><td>Target Language Use</td></tr><tr><td>CEFR</td><td>Common European Framework of Reference for Languages</td></tr></table></body></html>

Traditionally, lectures are delivered live by the lecturer and students assessments - whether formative or summative -focus on tasks which require them to demonstrate their understanding of the content, for example, as part of a group discsion, a presentation, a report or an essy. More recently, however, due to the influence of technology and changes in pedagogical practices, not to mention the impact of Coronavirus, flpped and online learning have been widely adopted in the sector. Therefore, it i important to consider how best to present online input both for teaching and for asessment purposes. A good deal of research has investigated the impact of audio and video input in discrete listening tes but very ittle work has examined the impact of different input formats on integrated listening-into-writing tasks.

This paper wil give brief outline of the reearch and developments in the testing of listening and, specifically, academic listening practices over the lat five decades since the emergence of ALEAP formerly SLMOUs] and will then present the results of one pat of a larger PhD study which focused on how listening input provided in the form of a podcast (audio-only) versus a vodcast (video with PowerPoint) impacted on written performance in an integrated EAP listening-into-writing test.

# 2. Literature review

# 2.1.  Overview of listening research

In JEAP specificll, with the exception of the 2011 Special Issue on academic listening, which includes four state-of-the-art ar. ticles, there appears to be relatively littl research into academic istening assessment over the 20 years of the journal's existence. Lynch (2011 attributed this to the inherent complexity of listening and listening reearch' due to the numerous intenal and external factors tht can imct o istng abiit as w as the diffiuty f ching istng efctivly (p. 0). He ta thttis s not a criticism of the journal's editorial policy but a reflection of 'a wider neglect of istening' (p. 80). Indeed, his review of the research published in JEAP up to that point reveals that, out f ust nine listening-focussed articles, only one, astudy by Read (2002), focussed on EAP listening assessment.

Nine years later, in their review of 416 JEAP articles between 2002 and 2019, Riazi et al. (2020) found that only six articles (just over $1 \%$ ) focussed on academic listening whereas there were 276 (approximately $6 6 \%$ ) articles on academic writing. Only 38 studies $( 9 \% )$ reported on more than one modality, e.g. reading and writing or listening and speaking.

Early pedagogy and research focussed largely on bottom-up approaches to listening comprehension with the emphasis on phoneme, syllable and word level processing (Dirven & Oakeshot-Taylor, 1984, p. 326). By the 1970s and 1980s, the emphasis was on the integration of both lower- and higher-level inguistic proceses (Voss 1984) and the difficulties that leaners encounter with listening. These include discourse structure (Godfrey, 1979), internal and extraneous dificulties (Zimmerman, 1980, in Dirven & Oakeshott-Taylor, 1985 p.7) and the efect of memory on listening comprehension (Richards, 1983). In the 1990s and 200s, with the developments that new technology had brought, researchers started to investigate the impact of different input formats (Brett 1995; Coniam, 2001; Gruba, 1997; Ockey, 2007) and were proposing ways fteaching (Field, 2008) and asssing listening comprehension (Coniam, 2001) based on the findings.

Around the same time, research in English for Academic Purposes was gaining momentum. Research into academic lstening in the 1980s and beyond examined features of listening comprehension and lecture comprehension (Dunkel & Davis, 1994; Millr, 2009; Young, 194). Rchard (1983) prets alist of microsills required when listeng to ctures, noing, among ther aspects, the need to identify relationships among units within discourse, the abilit to identify the role of discourse markers i signaling structure of a lecture', the ability to follow different modes of lecturing: spoken, audio, audio-visual', the ability to follow lecture (sic) despite differences in accent and speed' and 'to recognize irrelevant matter' (p. 229-230).

Although Richards (1983) list of micro-skill for academic English has been criticised for being limited to just academic lectures, research has investigated some of these skils over the last three decades. For example, areas of focus have included note-taking (Carrel, 2007; Chaudron et al, 1994; Dunkel, 1988; Siegel, 2018; 2020) and speech rate (Griffiths, 1990; Revesz & Brunfaut

# 2013; Robinson et al., 1997).

The importance of understanding discourse structure (Camiciotoli, 2004; Dudley-Evans, 1994; Zare & Keivanlo0-Shahrestanaki) 2017) and the use of discourse markers (Chaudron & Richards, 1986; DeCarrico & Nattinger, 1988; Thompson, 2003) have also received a good deal of attntion. Several studies have found that clearly signposted discourse can benefit both L1 and L2 learners (DeCarrico & Nattinger 1988; Rickards, Fajen, Sllivan, & Gillespie, 1997). More recently, Zare and Keivanloo-Shahrestanaki (2017) found that an understanding of how importance is marked in academic lectures can improve comprehension of the main points. Other areas that have been investigated in relation to EAP listening include factors affcting performance including vocabulary acquisition (Paribakht & Webb, 2016; Vidal, 2003) and text length (Carrell et al., 2004; Locke, 1977).

The impact of lecture length in both live and asynchronous lectures has been investigated over the years. Locke (1977) found that there was a $1 7 \%$ drop on average between the quantity of lecture notes taken in the first $2 0 \mathrm { { m i n } }$ of a lecture and those taken in the last $1 0 { - } 3 0 \mathrm { m i n }$ of 50-70 min lectures. More recently, Inman and Myers (2018) cite several authors who recommend that lectures should be broken down into 10-15 min sections (p. 3). In an asynchronous environment, studies have found that students atention span may be even shorter. Guo et al. (2014) found a significant drop in engagement when students were presented with videos which were longer than $9 { - } 1 2 \mathrm { m i n }$ and the median engagement time was 6 min (p. 44).

# 2.2. Input formats in listening tests

One aspect of listening which has received a good deal of attention in both general English and English for Academic Purposes i the impact of different input formats (audio, vide0 and multimedia) (Batty, 2015; Coniam, 2001; Pardo-Ballester, 2016; Sueyoshi & Hardison, 2005; Suvorov, 2013; Wagner, 2007), as wl as the use of context versus content stlls (Ginther, 2002), and captions (Leveridge & Yang, 2013; Montero Perez et a., 2014; Sydorenko, 2010). However, these studies have provided mixed findings. Some researchers found no statistically significant differences across input formats (Coniam, 2001; Cubilo & Winke, 2013) while others found that test takers perform bettr on a listening test containing video input (Batty, 2015; Sueyoshi & Hardison, 2005; Wagner, 2010); in contrast, Suvorov's (2008) study revealed that test takers performed significantly worse on a video-mediated lecture compared to an audio-only lecture or a listening text presented with a single photograph. However, his findings suggest that video might, in fact, be beneficial to test takers if the input is in the form of a dialogue.

It should be noted here that the visuals in Suvorov's (2008) study were context visuals; if content visuals had been used, the results may have been different. Indeed, in her 2002 study, Ginther found that content visuals were more helpful than context visuals. Building on his earlier work, Suvorov (2013) investigated test takers' interaction with context and content visuals in audio versus video-based input in multiple choice academic listening tets. Although there was no impact on score relating to the type of visual, the use of eye-tracking software revealed differences in viewing behaviour with the mean fixation rate being statisticall significantly higher for content videos than context videos. In addition, $9 7 \%$ of Suvorov's participants reported that content visuals aided comprehension of the lecture.

With regard to multimedia input, Aldera (2015) investigated the impact over several classes of multimedia input (audio with visual animation) compared to audio only. The group exposed to multimedia input performed beter in both a post-test and a delayed post-test. Although this suggests that the input helped the students' listening skill, it should be noted that students may have performed better purely as a result of the visual input, and not necessrily because the multimedia input helped their listening skil. Nonetheless, these findings concur with Brett (1997) who also found that students presented with multimedia input outperformed those with audio and video input.

In terms of test taker preferences for the input formats, several studies have revealed that test takers prefer video input even f their scores are not always in line with this preference (Pardo-Ballster, 2016; Progosh, 1996). Other study findings have been mixed, with some test takers expressing a preference for video and others considering it a distraction (Chen et al, 2014; Coniam, 2001; Cubilo & Winke, 2013). This may be due to a number of factors including the type of visuals (whether these are context/content visuals) or the cognitive load imposed when the input is too fast.

Research examining the use of captions has also produced mixed findings. Montero Perez et al. (2014) found that learners who are exposed to fully-captioned input perform better on global comprehension questions than those with only keywords or no captions but not on detal questions; other studies have revealed differences based on proficiency level. Pujola (2002) found that lower-proficiency learners may focus on reading the captions because they consider them a'necessary tool in their understanding of the authentic aural input (p. 254). Similarly, Leveridge and Yang (2013) found that lower-proficiency learners benefitted from the use of captions yet they caused interference for more proficient learners. In contrast, Aldukhayel's (2021) study revealed that lower-proficiency students struggled to process all the inputs (audio, visual images and captions) simultaneously when watching a vlog.

# 2.3. Integrated tasks

What is striking about the studies above is that the vast majority are based on discrete listening tass so, despite the fact that listening to lectures and taking notes is afrequently cited istening task, and responding to lecture input both in spoken and written responses are tasks which students are often required to complete (Westbrook & Howell, 2011), very few studies have investigated integrated listening-into-writing task types.

Table 1 Background information of the test takers.   

<html><body><table><tr><td rowspan="2"></td><td rowspan="2">Total no. of test takerse</td><td colspan="3"> Nationality</td><td colspan="3">Gender</td><td colspan="3">Age</td><td colspan="6"> Self-assessed English language level</td><td colspan="3">Year of study</td></tr><tr><td>UA</td><td></td><td>Other</td><td>No info</td><td>M</td><td></td><td>No info</td><td>18-21</td><td>22-25</td><td>No info</td><td>A1 A2</td><td>B1</td><td></td><td>B2</td><td>C1</td><td>No info</td><td>2</td><td>No info</td></tr><tr><td>RFl uni</td><td>74</td><td>56</td><td></td><td>1 (Tatar)</td><td>17</td><td>22</td><td>50 2</td><td></td><td>1</td><td>9</td><td>17</td><td>16</td><td>20</td><td>3.</td><td>1</td><td>19</td><td></td><td>28 17.</td><td>29</td></tr><tr><td>UA2 uni</td><td>42</td><td>0</td><td>0</td><td></td><td></td><td>4</td><td>38</td><td></td><td>4</td><td>0</td><td>0</td><td></td><td>9</td><td>23</td><td>8</td><td></td><td></td><td>18</td><td>20</td></tr><tr><td>Total</td><td>116</td><td>56</td><td>42</td><td></td><td>17</td><td>26</td><td>88</td><td></td><td>102 5</td><td>9</td><td>17</td><td>16</td><td>29</td><td>26</td><td></td><td>19</td><td></td><td>35</td><td> 49</td></tr></table></body></html>

1 RF uni $=$ participants from Russian Federation university. 2 UA uni $=$ participants from Ukrainian university.

Knoch and Sitajalabhorn (2013) explore the integrated task type and propose a 6-part definition for such tasks:

...test takers are presented with one or more language-rich source texts and are required to produce written compositions that require (1) mining the source texts for ideas, (2) selecting ideas, (3) synthesising ideas from one or more source texts, (4) transforming the language used in the input, (5) organizing ideas and (6) using stylistic conventions such as connecting ideas and acknowledging sources (p. 306).

The types of tasks used most frequently in integrated tass are those which combine reading-into-writing, ften requiring students to produce a summary of the input (Baba, 2009; Li, 2014; Yu, 2009) or essay response tasks (Ascencion Delaney, 2008)

Studies have compared performance on independent writing tasks versus integrated writing tasks (Cumming et al., 2005; Gebril) 2009; Guo et al., 2013; Lee & Kantor, 2007), investigated rater decision making (Gebril & Plakans, 2014), and considered the role of reading strategies (Plakans, 2009). In addition, a large amount of the research has focussed on source text use. Studies have inves. tigated how test takers interact with source texts i both reading-into-writing tasks (umming et al., 2016; Kyle, 2020; Neuman et al., 2019) and in reading- and listening-into-writing tasks (Cumming et al., 205; Plakans & Gebril, 2013). In line with Cumming et al. (2005), Plakans and Gebril (2013) found that lower level leaners depended heavily on the reading texs for content and direct copying of word .. (p. 217). Thir study also revealed that listening ability sigificantly impacted on score, more so than other feature .. more commonly associated with integrated writing, such as verbatim source text use' (p. 227).

The few studies on listening-into-writing have investigated istening proceses and strategies (Rukhthong & Brunfaut, 2020), task authenticity (Rukhthong, 2015), note-taking strategies (Carrll, 2007) and input formats (Cubilo & Winke, 2013). Carrll (2007) examined the correlation between students' notes on a listening comprehension lecture and their performance on an integrated listening-into-writing task. She found a significant correlation between the number f content words in the notes and performance on the writing task. Cubilo and Winke (2013) studied the impact f ifferent input formats in an integrated listening-into-writing task In a counter-balanced design, participants wrote two essays - one based on audio input and one based on video input. She did not find any significant differences between input formats for overall cores or for the rating criteria content, organisation', vocabulary and mechanics'. However, she did find a significant difference for the criterion, language use' In this case, test takers received a significantly higher score for essays supported by the video input.

The study by Cubilo and Winke (2013) is the closest study that the author has found to the current study but their study involved audio inputs with stil pictures vs video with context-only visuals. The test takers saw the speaker so they could pay attention to non-verbal information but there were no content visuals. As such, the impact of different input formats (audio vs video containing content visuals) appears to represent a gap in the literature which this current study seeks to address.

# 3. Research questions, participants, materials and methods

# 3.1. Research questions

Onthe basis of the literature review, this paper wil present the results of investigations designed to answer the following research questions:

1. How do input order and format (audio vs video) affect written performance on an integrated listening-into-writing EAP task?   
2. With regard to test takers perctions of their performance, what reasons do test takers give for why they felt they performed better when presented with one input format rather than the other?   
3. With regard to test takers perceptions of thr performance, what reasons do test takers give for why they flt they peformed worse when presented with one input format rather than the other?

# 3.2. Participants

The data for this study was collected from participants at two universities: one located in the Russian Federation $( \mathbf { n } = 7 4 )$ and another in Ukraine $( \mathtt { n } = 4 2 )$ . In total, data was collected from 131 participants. However, five participants did not sign the consent form While three did not write anything in the main EAP task so these students were removed from the analysis. For a further seven students, the data collection was carried out incorrectl so they were also excluded thus resulting n a total f 116 test taker. Demographic data for the participants can be found in Table 1 below.

University students were selected because the main task was designed to investigate academic language use and required students to listen to a lecture as part of an integrated EAP listening-into-writing test. The two universities in the study were selected because they both have a post-Soviet educational culture and a similar linguistic background. The two universties also have a strong inter. nationalisation agenda so students need to be able to follow lectures in English.

All participants were informed about the study by way of an information sheet and ethical consent was collected from allpar. ticipants. A copy of the information sheet and ethical consent can be found in Appendix 1. Ethical clearance was obtained from the University of Bedfordshire and the two universities involved in the study.

# 3.3. Materials and methods

Further to an exploratory study during which the materials and methodology were refined, the main study comprised three main tasks:

1. Lexico-grammatical placement test: Quick Placement Test (QPT) (Oxford University Press, 2001)   
2. Integrated EAP listening-into-writing task a. Listening to, and taking notes on, a lecture on the topic of Culture shock which was split in hal, with one half being provided as audio only and one half as a video including PowerPoint. b. Writing a summary of the lecture content

3. Post-task feedback questionnaire

# 3.3.1. Task 1 - Quick Placement Test (QPT)

In the first instance, est takers took a pen-and-paper version of the QPT (Oxford Universt Press 2001). This 30-min test comprises 60 multiple-choice items. The rationale for selecting this est was fourfold. Firs, as a published test, it had already bee trialled and alidated externall. econd, it had ben used for placement purposes at the author's instittion over many years. Third, lexis has been shown to play an important role i istening (Bonk, 2000; Stahr, 2008, 2009; Van Zeeand & Schmitt, 2013) and writing (Laufer & Nation, 1995; Stehr, 2008). Finall, the QPT provides a swift yt reliable estimate of students' proficiency level so participants could be split into two groups of equal number and balanced levels of language proficiency. This was done to ensure that any group dif ferences that were revealed in the EAP test performance were the result of the EAP test rather than the result of having two groups of very different abilit ranges. An independent samples t-tt revealed that there was no statisticall sigficant iffence between the two groups $( \mathtt { p } = . 3 7 2 )$ (see Results below).

# 3.3.2. Task 2 - integrated EAP listening-into-writing test

The main instrument for the study was the integrated EAP listening-into-writing test. The test comprised two tasks: a) watching and listening to a lecture and taking notes on the content b) writing a 350-word summary of the main and supporting points from the lecture.

The research methodology for the first task (the input part) employed an AB-BA' counterbalanced measures design (Mackey & Gass, 2005, p. 353) in which test takers istened to a lecture which was divided into two halves. The first group (audio first') was presented with the first half of the lecture as audio input and the second half as video input while the second group (video first) watched a video of the first part and listened to an audio recording of the second half (see Table 2 below).

In line with the findings from Guo et al. (2014) (se Literature Review above) and the M00C platform provider, Edx, which recommends 6 minutes as the maximum length for a video lecture (Inman & Myers, 2018, p. 3), the whole lecture lasted 12:42 min. This was divided as follows:

. Introduction and outline: 0:33   
. First half of the lecture: 6:14   
: Second half of the lecture: 5:46   
: Close of the lecture: O:09

Following initial trials, the instrument was refined to ensure that both groups had a similar experience. Apart from the firs slide at the beginning of the lecture, which showed the outline, each video included three sides: one with one sentence, one with five bullet points and one with a diagram which included five keywords. The reason for the thre types of input on the slides was to nsure that the two halves were as comparable as possible while also providing variation in the way the visual information was presented.

The two halves of the input were designed to be of approximately equal playback length and were analysed using Text Inspector (Text Inspector, 2019) to ensure that they were approximately equal in terms of the linguistic features including word count and textual complexty. To measure this, the main body of each half of the transcript (having removed the inroduction and the close of the lecture, and having cleaned the transcript to remove false starts and hesitations) was analysed using Text Inspector (Text Inspector, 2019). Text Inspector is an online, automated text analysis software which performs many of the same analyses as other similar products on the market. Like other software programmes, Text Inspector provides the usual descriptive statistics such as word and sentence count, and lexical diversity measures such as type/token ratio and $\mathrm { { M T L D } ^ { 7 } }$ ; however, it also analyses input for occurrences of Academic Word List words (Coxhead, 2000) and provides CEFR levels for the words in the text based on the English Vocabulary Profile (Cambridge Universty Press 2015). The contents of the slides in each half f the lecture were also analysed using Text Inspector. The results of both of these analyses can be found in Appendix 2 and demonstrate that the spoken input was very similar across the two halves of the input although there was more variation in the results for the language on the slides.

Table 2 Input order.   

<html><body><table><tr><td>Group</td><td> Input order</td></tr><tr><td>&quot;Audio first&#x27; group</td><td>Audio only</td></tr><tr><td>&#x27;Video first&#x27; group</td><td>Audio and video with PowerPoint</td></tr></table></body></html>

In terms of speed of delivery of the lecture, Brindley and Slayter (2002) note that normal' speed texts are delivered at a speed of 180 words per minute (wpm) whileGrffiths (1992) suggests that the average speech rate is 188 wpm. In an earlier study, Tauroza and Allison (1990) cited an average speech rate of 125-160 wpm. Camiciottol (2005) measured the speech rate in a lecture delivered in an L1 environment and one delivered in an L2 evironment. In line with Tauroza and Allison (1990), the spech rate in the L2 lecture was 125 wpm whil the lcture delivered in an L1 stting in the UK had a speech rate f 183 wpm, which is more in line with Brindey and Slayter (2002) and Griffths (1992). Investigating speech rates in the Cambridge Suit of exams, Field (2013, p. 119) found that the speech rate on the PET exam - a CEFR Level B1 exam - was 167.4 wpm on average whil the Cambridge FCE - a B2 level exam - had an average speech rate of 207.6 wpm. Therefore, the speed of delivery of the lecture was kept in line with the speed that would be epected for a B1/2 exam. The speech rate for the introduction was slightly slower than the main content at 167.09 wpm to allow test takers to become accustomed to the speaker's accent. The speech rate for the first half of the lecture was 177.75 wpm and for the second half of the lecture, it was 182.26.

Test takers heard the input twice and were allowed to take notes at any time.

After the second playback, test takers moved on to the second task in the test (the outut part). In this task, they had 45 min to write 1 350-word summary.

3.3.2.1. Rating of students' writte responses. To develop a model answer, an expert panel of three L1 English speaker EAP lecturers listened to the whole lecture as as audio input and noted down the salient point. Then they agreed on a consensus version, which could be used while rating to evaluate the extent of task achievement. The audio only verson was used for note-taking as they all had access to the PowerPoint slides while rating. Raters used the consensus version to asses the amount of content that test takers rproduced in relation to the CEFR descriptors in the verall Written Production scale (Council of Europe, 2001) (see elow). For example, if atest taker only reproduced  few isolated phrases, this would be anA1 performance ut f they wrote a clear, well-tructured text containing the vast majority of the points from the input, this would constitute a C1 performance.

Before being rated, the summaries were split into two halves, representing the two halves of the input. The three EAP lecturers underwent rater familiarisation training to develop a shared understanding of the criteria in line with (Trace et al., 2016, p.41) then used the CEFR OverllWrtten Production descriptors (Council of Europe, 2001) to rate the papers. Each paper was rated by between 1 and 3 raters whereby rater 1 rated 96 papers, rater 2 rated 74 papers and rater 3 rated 96 papers. This alowed sufficient overlap for a Rasch analysis to be carried out.

The CEFR OverallWriten Production cale (Council f Europe, 201) was used as this scale provides a clear rogression from simple isolated phrases (1) to clear, detailed texts (B1) up to clear, well-stuctured texts . (C1)(p. 23). This enabled raters to distinguish between those at the lower level who were only able to (re)produce odd words or phrases and the more detailed, well-written texts at higher levels.

3.3.2.2. Sttisicl analysis. The score allocated to test takers were analysed quantitively using Many Facet Rasch Analysis (Linare. 1989) to calculate test takers' Fair Average scores on each half of the summary writig task and to measure rater harshness/leniency and Infit. The Fair Average scores were then used as the basis for a Hotelling's $T ^ { 2 }$ test, which was carried out using SPss Version 22 IBM Corp, 2013). In contrat o est, which is use to tes for iffernes betwegroups when there is only one deendent variable, Hotelling's $T ^ { 2 }$ can be used when there are several dependent variables. This test is similar to a Multivariate Analysis of Variance (MANOVA) but a MANOVA is usually run when there are three or more groups in the independent variable whereas Hotlling's $T ^ { 2 }$ can be used with two groups for the independent variable (Laerd, 2015), which was the case in this study.

# 3.3.3. Task 3 - feedback questionnaire

After participants had completed the integrated listening-into-writing task, they were asked to complete a pen-and-paper feedback questionnaire. This was designed to collect demographic data but also to investigate their perceptions of the task. All test takers were asked to complete the questionnaire but, in some cases, they did not answer all the questions.

# 4. Results

# 4.1. Quick Placement Test

Table 3 below shows the QPT results. As can be seen, the mean score in the 'audio first group was 1.98 points higher than that of the 'video first' group $( M = 3 6 . 3 8 $ $S D = 1 0 . 3 4 9$ compared to $M = 3 4 . 4 0$ $S D = 1 0 . 7 1 9 $

For the independent sample t-test, tests of normality were carried out and the istributions for both groups were normal. The t-es results revealed that there was no statistically significant difference between the two groups $( \mathbf { p } = . 3 7 2 )$

Table 3 QPT results.   

<html><body><table><tr><td>Group</td><td>Mean</td><td>Standard deviation</td><td>Min</td><td>Max (out of 60)</td><td>Median</td></tr><tr><td>Audio first</td><td>36.38</td><td>10.349</td><td>18</td><td>58</td><td>37</td></tr><tr><td>Video first</td><td>34.40</td><td>10.719</td><td>16</td><td>55</td><td>32.50</td></tr></table></body></html>

# 4.2. Integrated EAP listening-into-writing test

To answer RQ1, Fair Average scores and Rater Infit and Outfit were calculated using Facets. The Fair Average scores were used for the Hotelling's $T ^ { 2 }$ test to investigate whether there were any statistically significant differences in performance across the two groups when each group was presented with the two types of input but in a different input order.

For scoring, the summaries were divided into two halves, representing the audio input in one half and the video input in the other half. Each half of the summary was allocated a CEFR level score and this was converted to a number format as follows:

: ${ \mathsf { A } } { \mathsf { 0 } } ^ { \mathrm { 8 } }$ : 1   
: A1: 2   
: A2: 3   
: B1: 4   
: B2: 5   
: C1: 6

# 4.2.1. Facets analysis

The Facets analysis revealed that the threeraters were consistent within themselves see Table 4below) with the Infit Mn Sq all falling within the 0.5 to 1.5 range that Linacre (2012) considers productive for measurement (p. 11). Similarl, the Outfit MnSq values were also within an acceptable range.

Finally, the number of exact agreements was 147 $5 0 \% )$ compared to an expected number of agreements of 151.2 $( 5 1 . 4 \% )$ , which suggests that raters were acting as independent experts, whereby rater 2 was the most lenient (Fair Average: 4.35) and rater 1 was the harshest (Fair Average: 4.04).

# 4.2.2. Hotelling's $T ^ { 2 }$ analysis

Preliminary assumption checking revealed that the data for each group were not normall distributed as asssed by the Shapiro Wilk's test $( p < . 0 5 )$ . However, it should be noted that a MAnovA is 'relatively robust to violations of the assumptions in many circumstances (Bray & Maxwell, 1985, p.33); inspection of the boxplots showed that there were four univariat outliers in the scores for the first half f the lecture audo inut) for the audi firt group ut there were o outiers in the vide first group; Mahalanobis distance revealed that there were no multivariate outliers in the data $( p > . 0 0 1 )$ ; there were linear relationships, as assessed by scatterplot, and no multicollinearity $( | \mathbf { r } | < 0 . 9 )$ ; finally, there was homogeneity of variance-covariance matrices, as assessed by Box's test of equality of covariance matrices $\left( p = . 0 5 5 \right)$

The results of the Hotelling's $T ^ { 2 }$ analysis demonstrate that, despite the fact that there were no significant differences between the two groups on the QPT scores, the 'audio first group scored more highly for both input formats (see Table 5 below).

Fig. 1 below shows these results.

There was a statistically significant difference between the groups on the combined dependent variables, $F \left( 2 , 1 1 3 \right) = 1 7 . 8 3 2 , p <$ .0005; Wilks' $\Lambda = 0 . 7 6 0$ ; partial $\eta 2 = 0 . 2 4 0$ , using a Bonferroni adjusted $\alpha$ level of 0.025 with a simultaneous 95 per cent confidence level. Since the scores were not normally distributed, a Mann-Whitney $U$ test (CI 97.5 per cent) was run to compare the scores between test takers in the 'audio first' group and 'video first' group. For the writing scores relating to the audio and video inputs, the distributions were not similar as assessed by visual inspection. Scores based on the audio input for the 'audio first' group (mean rank $=$ 72.17) were statistically significantly higher than for the 'video first' group (mean rank $= 4 4 . 8 3 $ $U = 8 8 9$ $z = - 4 . 3 8 9$ $p < . 0 0 0 5$ However, scores based on the video input for the 'audio first' group (mean rank $= 6 0 . 7 7 $ were not statistically significantly higher than those of the 'video first' group (mean rank $= 5 6 . 2 3 $ $U = 1 5 5 0 . 5 0 0$ $\pmb { z = - 0 . 7 2 7 }$ $p = . 4 6 7$

Fig. 2 shows these results.

Table 6 shows the performance breakdown by group and the two halves of the lecture. The findings revealed that, across both groups, approximately $4 0 \%$ of the participants $\left( \mathtt { n } = 4 6 \right)$ performed equally well in both halves of the summary irrespective of input order and input format while approximately half $\left( \mathtt { n } = 5 7 \right)$ ) performed better in the summary relating to the first half of the lecture but performance dropped off in the second half of the lecture. The remaining $1 1 \%$ ${ \bf \tilde { n } } = 1 3$ ) performed better on the summary relating to the second half of the lecture. Looking at each of the two groups in turn, 25 test takers (approximately $4 3 \%$ ) in the 'audio first' group scored equally well in both halves of the summary, another 25 (approximately $4 3 \%$ ) scored better in the summary relating to the first half of the input (audio input) and the remaining $1 4 \%$ (approximately) $( \mathbf { n } = 8 )$ performed better in the summary relating to the second half of the input (video input). In the 'video first' group, only approximately $3 6 \%$ $\mathbf { \tilde { n } } = 2 1$ ) scored equally well on both halves of the summary whereas $5 5 \%$ ${ \bf ( n = 3 2 ) }$ performed better on the summary relating to the first half of the input (video input). Only approximately $9 \%$ $( \mathtt { n } = 5 )$ performed better on the summary relating to the second half of the input (audio input).

Table 4 Rater fit statistics.   

<html><body><table><tr><td>Rater</td><td>Infit MnSq</td><td>Outfit MnSq</td></tr><tr><td>Rater 1</td><td>.85</td><td>.86</td></tr><tr><td>Rater 2</td><td>1.08</td><td>.96</td></tr><tr><td>Rater 3</td><td>1.05</td><td>.78</td></tr></table></body></html>

Table 5 Mean scores for each group and input format.   

<html><body><table><tr><td>Group</td><td>First half of the lecture</td><td>Second half of the lecture</td></tr><tr><td>&#x27;Audio first group</td><td>Audio input: M = 4.006, SD = 1.246</td><td>Video input: M = 3.571, SD = 1.340</td></tr><tr><td>&#x27;Video first&#x27; group</td><td>Video input: M = 3.452, SD = 1.212</td><td>Audio input: M = 2.886, SD = 1.444</td></tr></table></body></html>

![](img/62f079e459a0a22add78574a9e9a08f426c6ff582b1cb20b607f5243e4158d65.jpg)  
Fig. 1. Performance by group.

![](img/a3fbb81ae9f9f74f10fb3b873a569ba5817b10205a717480897efa1bf5919ce7.jpg)  
Fig. 2. Performance by input format.

Table 6 Performance breakdown by group and summary half.   

<html><body><table><tr><td>Group</td><td>Number performing equally well on both halves of the lecture</td><td>No. of test takers performing better on the first half of the lecture</td><td>No. of test takers performing better on the second half of the lecture</td></tr><tr><td>Both groups combined</td><td>46</td><td>57</td><td>13</td></tr><tr><td>Audio first</td><td>25</td><td>25</td><td>8</td></tr><tr><td>Video first</td><td>21</td><td> 32</td><td>5</td></tr></table></body></html>

# 4.3. Feedback questionnaire

Participants were asked to give reasons for why they thought they had performed bettr on the summary relating to one half of the lecture input than the other. Table 7 below shows the responses for this question.

As can be seen, $3 2 . 8 \%$ ${ \bf \tilde { n } } = 3 8$ ) of respondents felt that they had been assisted by having access to the text/visual. An additional $7 . 8 \%$ ${ \bf \langle n = 9 \rangle }$ felt that the video was more understandable. Conversely, $1 5 . 5 \%$ ${ \bf \tilde { n } } = 1 8$ ) felt that listening only was easier. 26 test takers did not respond to this question.

Some test takers felt the video helped them because they could:

. 'see slides in the presentation' (2SA3)   
: both listen and read information' (sV10) Test taker, 2sv8, explained the usefulness of the visuals clearly:   
there were slides that improved the understanding and because visual perception helped to focus'. On the other hand, one of the test takers who expressed a preference for audio only input stated:   
. 'I was focused only on listening' (KA6) while another one felt they performed better when presented with the audio input:   
. 'because there was not any distraction' (5SA2).

When asked for the reasons why they felt they performed worse on one part of the task than the other (Q.8) (see Table 8 below), again 26 test takers did not respond. However, $2 0 . 7 \%$ ${ \bf ( n = 2 4 }$ ) felt that listening only was more difficult. Conversely, $1 3 . 8 \%$ $( \mathbf { n } = 1 6 )$ felt that both watching and listening were difficult and/or they felt distracted by the video while $1 7 . 2 \%$ $\left( \mathbf { n } = 2 0 \right)$ ) said they did not understand the content.

In contrast to the comment from test taker KA6 above, one test taker felt they performed worse on the audio half of the inpul because:

. 'it don't concentration (sic) my attention' (2SA4).

Despite the fact that the input was almost exactly the same in terms of dificulty, one test taker who was presented with the video first felt that, when it came to the audio:

. 'the audio information is much more difficult' (SV9).

# 4.4. Summary of results

This study attempted to shed light on three research questions:

1. How do input order and format (audio vs video) affect written performance on an integrated listening-into-writing EAP task?

Table 7 Perceived reasons for better performance.   

<html><body><table><tr><td>Perceived reasons for better performance</td><td>Percentage of respondents</td></tr><tr><td>Text/visual helped me</td><td>33</td></tr><tr><td>No response</td><td>22</td></tr><tr><td>Listening only was easier</td><td>15</td></tr><tr><td>Video was more understandable</td><td>8</td></tr><tr><td>I understood the content better (second half of the lecture)</td><td>6</td></tr><tr><td> Incomprehensible/miscellaneous response</td><td>6</td></tr><tr><td>I don&#x27;t know</td><td>4</td></tr><tr><td>I understood the content better (first half of the lecture)</td><td>3</td></tr><tr><td> Interesting topic</td><td>2</td></tr><tr><td>Clear presentation structure</td><td>1</td></tr></table></body></html>

Table 8 Perceived reasons for worse performance.   

<html><body><table><tr><td>Perceived reasons for worse performance</td><td>Percentage of respondents</td></tr><tr><td>No response</td><td>22</td></tr><tr><td>Listening only was more difficult.</td><td>21</td></tr><tr><td>Don&#x27;t understand.</td><td>17</td></tr><tr><td>Watching and listening is difficult/distracted by video</td><td>14</td></tr><tr><td>Sleep/lack of concentration/difficult to concentrate</td><td>7</td></tr><tr><td>Speech rate too quick.</td><td>4</td></tr><tr><td> Incomprehensible/miscellaneous response</td><td>3</td></tr><tr><td>Too much information.</td><td>3</td></tr><tr><td>Video was more understandable</td><td>2</td></tr><tr><td>I don&#x27;t know</td><td>2</td></tr><tr><td>Lack of time</td><td>2</td></tr><tr><td>Listening only is easier.</td><td>1</td></tr><tr><td>Bad acoustics</td><td>1</td></tr><tr><td>Performed same on both</td><td>1</td></tr></table></body></html>

2. With regard to test takers perctions of their performance, what reasons do test takers give for why they felt they performed better when presented with one input format rather than the other?   
3. With regard to test takers perceptions of thir performance, what reasons do test takers give for why they felt they performed worse when presented with one input format rather than the other?

The Hotelling's $T ^ { 2 }$ analysis revealed that the mean scores in both groups were lower for the second half of the input than for the first half of the input and that the mean scores for video first group were lower than for the audio first group on both halves of the input. This resulted in a statistically ignificant difference between the two groups on the combined variables. Similarly, there was astatistically significant difference tween the twogroups in peformance by input format when tes takers were preented with the audio input, yet there was no statistically significant difference when test takers were presented with the video input.

In terms of test taker preferences, $4 0 . 6 \%$ of test takers in total $\left( \mathtt { n } = 4 9 \right)$ felt that they had been assisted by access to the text/visual and that the video was more understandable whereas only $^ { 1 5 \% }$ $\mathbf { \tilde { n } } = 1 8$ felt that the audio only input was better.

# 5. Discussion

This study has built on previous studies relating to input formats on discrete listening tests by investigating the impact of input formats and input order on an integrated listening-into-writing task.

First of al, with regard to the alidit of the scoring, the results of the Facets analysis demonstrate that al three raters were within 0.5 logits of each other according to the Fair Average scores. This was most likely due to the fact that the threerters involved in the study had worked together at the same institution over many years and had used a rating scale based on the CEFR in their daily work The fact that they underwent specific rater training for this particular task would have also contributed to their shared understanding of the performance levels required for a given CEFR level and thus the close agreement achieved. Nonetheles, t is important to note that, although they were very close, they were still different enough to be acting as independent raters.

The Hotelling's $T ^ { 2 }$ analysis revealed that, when presented with input in two different formats (audio vs video), it appears that test takers perform beter on a follow-up writing task when the first input format that they are exposed to is audio rather than video. As pointed out by sometet takers, acces to the video may have caused them to watch the video rather than focussing on taking notes so this may have been a distraction, thus resulting in fewer notes and less to write about.

When the 'audio frst group was exposed to the second half of the input (video), the mean score was half a CEFR level lower than the score for the first half of the input (audio) $( M = 4 . 0 0 6$ in the summary for the first half compared to $M = 3 . 5 7 1$ in the summary for the second half. This could have been due to test takers also being distracted by the video or due to fatigue among some test takers. However, what is interesting is that the mean scores on the video input were similar across both groups $( M = 3 . 4 5 2$ for the 'video first' group and $M = 3 . 5 7 1$ for the 'audio first' group) such that there was no statisticall significant difference between the groups. This suggests that tes takers perform similarly when exposed to video input irrespective of whether this is the first type f input they are exposed to or not.

On the other hand, the 'video first group performed worse on the audio only input - their second input format - with the mean score falling by .7 of a CEFR level (from $M = 3 . 4 5 2$ for the summary relating to the first half of the input to $M = 2 . 8 6 6$ for the summary relating to the second half). This was 1.14 CEFR levels lower than the mean score for the 'audio first' group $( M = 4 . 0 0 6 )$ and was statisticall signficant. One possble explanation for ths could be that the language in the two hales of the lecture varied in difficulty, however, care was taken to ensure that both halves of the lecture were as close as possible in terms of the word length, text complexity and duration. In fact, the second half of the input was sightly shorter see Appendix 2) but was of almost exactly equal dfficulty the Flesch-Kincaid Grade Level, a assessed by Text Inspector, for the firs hlf f the input was 59.61 compared to 59.43 for the second half of the input while lexical diversty (MLD) for the first half was 39.76 compared to 40.25 for the second half. As such, itis unlikely that the text itself was the cause of the differing results for the audio-only input.

Another possible reason could be that test takers who were exposed to the video input first relied on the visual support (text.

diagram and visual organiser) as well as the speaker's body language in the frst half f the input, which, when removed, may have led to difficulties in decoding. This would be in line with findings from Locke (1977) and Guo et al. (2014), which revealed that engagement and note-taking dropped off over the course of alecture (see Literature Review above). Locke (1977) also found that, on average, $8 8 \%$ of the material lecturers wrote on the board during the lecture would appear in the students' notes while students only wrote down $5 1 . 6 \%$ of the spoken input that was not written on the board. Therefore, when the 'video first' group was not exposed to the video input (in the second half of the lecture), it may be that they simply did not write down as much as they had when they had been exposed to the video (and therefore the visual support) in the firt half of the lecture whil the audio first group may have been more focused on writing down as much as possible when listning to the first half of the input because they did not have any visual support.

Chang et al. (2011) found an inverse relationship between listening comprehension and cognitive load. Their students performed better when exposed to sound plus text (double mode') compared to sound only (single mode') but they found that accessto visual input did not benefit schema construction in the longer term. This may account for the significant difference in performance between the two groups in the current study: if the test takers i the video first group had ben relying on the scaffolding provided by the visual input in the first half of the input, they may not have built up the schema to enable them to deal with the audio-only input. This would not have been an issue for the audi first group as they had not had that scaffolding when they were exposed to the audio only input so were not reliant on it.

Furthermore, potential difficulties in decoding may have led to fatigue. McGarrigle et al. (2017, p. 95) point out that effortful listening' can lead to stres and fatigue. Consequently, students concentration may have decreased as the test went on such that they took fewer notes, resulting in having lessto write about relating to the second half of the input. The finding that a considerable percentage of both groups reived higher scores in their firs input than in the second irespective of input format may lend weight to this assumption. On the other hand, although almost $5 0 \%$ $\mathbf { \bar { n } } = 5 7$ ) performed worse on the summary relating to the second half of the lecture irrespective of input format, just over $5 0 \%$ $( \mathtt { n } = 5 9 )$ performed equally well or better in the second half so this may be a person-spific trat.. rther than  enealizd faige" efft (Dee & Janssen, 2013, p.17). In any case, this isue needs to e borne in mind when presenting input so, in line with findings from Guo et al. (2014), input should perhaps be kept short.

Given these findings, it may have been beneficial to have another two groups: one that listened to the whole lecture as audio only input and one that watched the whole lecture as a video. This would allow a better insight into the effect of the second half of the ecture, for example, to understandwhether performance droped off due to fatigue caused by the change in input formats, or whether this would be the case irespective of input format in line with previous research (Guo et al., 2014; Locke, 1977. Another reason for some of the weaker performances in the second half ould be that test takers ran out of time. Allowing more time may have allowed students to write more; however, this was not possible due to the length of time that was available for test takers to complet the tasks. A small number of test takers $( \mathtt { n } = 9 )$ did comment that they would have liked more time, yet feedback did not suggest that this was a major issue in this study.

The findings of the current study are, to some extent, in line with Suvorov's (2008) findings because his test takers performed significantly worse with video compared to audio only and audio with a single photograph. However, other research into input formats has yielded mixed findings. Gruba (1993) did not find any signficant ifference between audio and video in his study. imilarly, Batty (2015) found no significant interaction between delivery format and text type, nor between proficiency level and delivery format. Other studies have found that higher proficiency learners perform better on discrete istening tests when they have aes to video while the lower level learners perform better with audio (Pardo-Ballster, 2016; Chen et al., 2014). It should be noted that previous research was generally based on listening test rather than integrated listening-into-writing test, and in some cases, the video input included only context visuals rather than content visuals so this may account for the differences in the findings to some extent.

Irrespective of performance, there appears to be a greater preference among test takers for the use of video than for audio-only input with over $4 0 \%$ stating a preference for video since they could use the visual stimulus to aid comprehension and concentratin. The greater prefrence for video concurs with ther studies (Pardo-Ballester, 2016; Progosh, 1996; Suvoro, 2008; Wagner, 2010) and the comments in support of the use of textual input are in line with findings from Chang et al. (2011) and Montero Perez et al (2014). In contrast, only around $^ { 1 5 \% }$ preferred audio, with some test takers stating that the video was distracting. This appears to be in line with other research which has compared the two formats (Coniam, 2001; Gruba, 1994; Suvorov, 2013).

As educators, we need to consider what the implications of these findings are for teaching and testing academic istening-intowriting. Vandergrift (2004) argues that 'students need to learn to rely on the acoustic signal and relevant contextual factors to develop listening strategies (pp. 10-11). While this may be true, many lectures include written support in the form of a PowerPoint presentation. Moreover, many online materials include captioned video (Winke e al., 2010). Similarly, many online lectures (whether pre-recorded or recorded live then uploaded) willalso often have aces to an accompanying transcript in addition to any visual support included in the lecture.

Referring to Mayer's (2001) Cognitive Theory of Multimedia Learning, Leveridge and Yang (2013) state that, as audio input becomes to difficult, the L2 listener turns to the visual input mode, asthis may be more easily understod. Thus, L2 listeners who do not have the istening ability required for the task may resort t reading rather than listening, as may have ben the cas inthe current study. There are, of course, construct implications to this- the listening construct may change to a reading construct (at least, partially)

- but ths reflects th domain, n which lers do have aes to texual ndor visul suppor as wl as the trancript. Theefore this additional support can help lower-level learners to understand the input and, consequently, one hopes, perform better on their written assessments. Baty (2015) recognises not only the authenticit but aso the increased face validity that audiovisual input affords and therefore argues in favour of the use of video.

In addition to helping linguisticaly weaker L2 learners, there are other equality and accessbility advantages of using video Learners who may be hard-of-hearing can also use the textual input and read the speaker's lips to aid comprehension.

# 6. Conclusions and implications

This study has implications for both teaching and testing integrated listening-into-writing in an EAP environment which we ned to consider when deciding whether to make content available for remote, blended or flipped learning.

As EAP lecturers, I would argue, our aims are twofold: one i to develop students' listening skill so that they are able to integrate into the academic environment, both in and outside of clas; the other is to prepare them for the real-world academic environment Where they may often have aces to audiovisual input. Therefore, the way we present information to our students and asss them should serve both of these aims.

Video-mediated input can provide valuable scaffolding in lectures to assist learners in understanding the content of the input; however, for some, this may also lead to cognitive overload so we need to bear this in mind. To aid automaticity of processing and reduce the cognitive load, we can raise awarenes of the discourse fatures used to structure ifferent types f input. We can also help students to relate the spoken input to thevisual input by encouraging them to compare and contrast the content of the audio and visual input. This can be done by encouraging students to notice how what is written on the PowerPoint slide differ from what the speaker actually says. To asst with decoding, students can consider how the graphological form of a word which may appear on screen compares to its pronunciation.

However, we must also be aware of the potential negative impact that audiovisual input may have on listening skils over the longer term if learners become acustomed to being able to focus solely, or primaril, on the written word. Test taker questionnaire data revealed that some test takers felt that the audio only input was too fast, when, in actual fact, the peech rate was almost exactl the same in both input formats. This is possibly due to the aditional ffort of having to processthe input in real-tme without the support of the visual. The findings of the current study also suggest that losing the visual support has a greater impact on performance than when test takers are accustomed to audio only input and are then provided with the aditional upport offered by the visual stimul. Therefore, we should also provide targeted exercis to develop students istening/decoding skils as this will also id automaticity of processing and decrease cognitive load. This can be done by raising awareness f how pronunciation changes in connected speech and when vowels are stressed or unstressed. Thus, providing audio-only input, which can be used explicitly for such purposes and to teach general listening comprehension skill that leaners can use in their interactions outside of a lecture situation, is also vitally important.

The impact of fatigue should not be underestimated. It is recognised that a video or audio text which serves as content input for a flipped or blended leaning leson can be watched as often as necessary and at different times s earners are not limited to listening/ watching everything in one siting. Nonetheles teaching input should not be too long - 6 min is recommended by Ed for an online lesson (Inman & Myers, 2018). Guo et al. (2014) observed a drop-off in engagement between 9 and $1 2 \mathrm { m i n }$ and this study appears to support those findings as attention appears to have dropped off when exposed to the second half of the lectre, that is, between 6 and $1 2 \mathrm { m i n }$ in both groups. In a testing environment, of course, the issue of fatigue is an important consideration as tes takers may or may not have control over the input. In this case, fatigue appears to have been greater when test takers had become accustomed' to the visual input in the first half of the lecture and were then exposed to audio only in the second half. Of course, this may have ben exacerbated by the change of format and, clearly, one would not change the format of the input mid-test; however, the efect may wel be the same if we use audiovisual input in our teaching and audio only in a test. Therefore, our students need to be exposed to and comfortable with both input formats.

Although several researchers have claimed that $1 0 { - } 2 0 \mathrm { m i n }$ is a rule of thumb for lecture input (Bradbury, 2016), it would be useful to know whether age and L2 proficiency levels affect concentration levels, particularly in an EAP environment. Similarly, further research could investigate whether there is a diffrence in concentration levels between recorded and live lectures since individual lecturer traits and personalitis are also likely to affect engagement level, perhaps more than lecture length (Bradbury, 2016). This would be particularly timely given the changes brought about by the global pandemic and the move to more online or blended teaching. One important point to consider here is that recorded input enables isteners /viewers to replay or rewind as often as they wish. They can also stop the recording at any time to take a break. Therefore,research into the impact of individual control over pre-recorded lecture input and how this might afect performance in a time-constrained asessment would also be valuable. However, we should bear in mind that, if input is provided asa video, this provides scafflding and may help to maintain concentration therey possibly reducing the need for repetition or pauses.

To conclude then, this study has attempted to address a gap in the research by bringing together research on input formats in (academic) listening and integrated listening-into-writing asessment. The findings revealed that there is lessof a drop-f in per formance when a video is used and there ems to be more of a preference for video-based input than audio only input. On the basis of these findings, i seems wise to suggest that video-mediated input is an appropriate way to provide input both for teaching and testing. This also reflects the TLU domain and is therefore more authentic. Conversely, since some test takers may be distracted by the video and bearing in mind the impact of visual input on the construct of academic listening, it could be argued that audio only should be used. I would argue that a combination of input types should be used since the video can provide support for important content while audio can be useful in training students listning skill. However, I should stress the need for further research to help us fully understand the role of input formats and the extent to which they can benefit students in understanding input which they need for a follow-up integrated task.

# Funding

The author acknowledges the role of the British Council in making ths study possble: The British Council provided the research grant which enabled me to conduct the study as part of the ARAGs 2017 programme. I would lik to expresses my deep gratitude for this support.

Any opinions, indings, conclusions or recommendations expressed in this material are those of the author and do not necessrily reflect the views of the British Council, its related bodies or its partners.

# Author statement

Carolyn Westbrook: conceptualisation, methodology, investigation, analysis, writing, reviewing and editing, Kevin Westbrook: rating, Alexandra Brown: rating, Leander Johnson: coding, Viktoriya Levchenko and staff: data collction, Olga Kvasova: data collection, Tony Green: supervision.

# Declaration of competing interest

None.

# Acknowledgement

I would like to thank the editors, Sarah Brewer and Olwyn Alexander, the anonymous reviewers, and Dr Karen Dunn and Professor Barry O'Sullivan OBE for their advice in preparing this paper and for their invaluable feedback on earlier drafts.

Appendix 1. Main study - Information sheet and consent form

Introduction to the research

This doctoral research will investigate the relationship between input task characteristics (video vs audio input) of listening comprehension texts, and performance on written output tasks.

The objectives are:

to investigate how test takers perform when input is presented in audio format only compared to video format; to investigate the extent to which test takers are influenced by the written word in an EAP lecture compared to the spoken

# Methodology

The research questions are as follows:

. Do test takers perform better when presented with video input for a lecture? . To what extent do test takers rely on the written word compared to the spoken word?

The aim of the study is to find out how test takers performance on an integrated EAP test varies when the input (i.e. the lecture content) is presented in audio and video formats.

To assess the differences in performance, the data will be assessed qualitatively and quantitatively if numbers allow.

1l data will be anonymised and informed consent will be sought from all participants.

The study comprises three steps:

quick lexico-grammatical placement test (approx. 30 mins)   
language test comprising an academic lecture and a follow-up writing task (approx. 80 mins); brief post-task questionnaire (approx. 5 mins);

# Test format

A specifically developed integrated EAP istening and writing task. Tet-takers will watch/listen to a short EAP lecture (on a general academic topic) presented in audio only and video formats and produce a thematically-linked written summary. The same auditory input will be provided in each case $( 9 0 ~ \mathrm { m i n } )$

The research will be conducted as follows: one $\mathrm { ~ x ~ } 3 0 \ \mathrm { m i n }$ followed by one $\mathrm { ~ x ~ } 1 . 5 \mathrm { ~ h ~ }$ session.

Information sheet for participants - main study

First of all thank you for showing an interest in participating inthis study, which willbe the basis of the researcher's PhD thesis. Participation is completely voluntary and you may withdraw at any time.

Please see the information sheet provided for information about the specific tasks.

The data you provide (your testresults, post-test questionnaire and, whereapplicable, the interview data) wil be analysed to see if he type of input has an effect on your performance.

However, please note that the performance on these tasks does not affect your academic course in any way.

You are more than welcome to find out your test result. If you wish to do that, please send me an e-mail: xxxxxxx.

The initial findings from this research were presented at the xxxx. It is intended that the finished research will be published in papers and journal artice as well asthrough the rearcher's PhD theis. If you wish to have a copy of the results of the study, please send me an e-mail at the above address, too.

If you are willing to participate, please complete and sign the consent form overleaf and return it to the tutor/researcher.

Consent form for participants

First of all, thank you for agreeing to participate in this study, which willbe the basis of the researcher's PhD thesis. Please read the consent information below and tick the boxes to confirm your agreement. Then please sign your name below and write your name clearly.

I confirm that:

I have been given clear and detailed information about the study I will be involved in.   
I understand that participation is completely voluntary and I may withdraw at any time.   
I agree to my data being used for the purposes of this study.   
I am aware that all data will be anonymised and any personal data will be treated as confidential.   
I am aware of how the results of this study will be disseminated $( =$ passed on to other people) and I agree to this.   
I understand that I may request a copy of my results and of the results of the study by sending an e-mail to the researcher and that I have been given the researcher's e-mail address.   
Signed:   
Name: (please print)   
THANK YOU FOR YOUR PARTICIPATION AND YOUR HELP. THEY ARE GREATLY APPRECIATED!

Appendix 2. Text Inspector analysis of lecture language and slides   

<html><body><table><tr><td>Operation</td><td>Data</td><td>Lecture First half</td><td>Lecture Second half</td><td>Lecture Slides First half</td><td>Lecture Slides Second half</td></tr><tr><td>Statistics</td><td>Sentence count</td><td>34</td><td> 31</td><td>2</td><td>3</td></tr><tr><td>Statistics</td><td>Token count</td><td>1108</td><td>1048</td><td>54</td><td>61</td></tr><tr><td>Statistics</td><td>Type count</td><td>290</td><td>277.</td><td>42</td><td>44</td></tr><tr><td>Statistics</td><td>Type/token ratio</td><td>0.26</td><td>0.26</td><td>0.78</td><td>0.72</td></tr><tr><td>Statistics</td><td>Avge syllables per sentence</td><td>43.97</td><td>45.19</td><td>54.5</td><td>36.67</td></tr><tr><td>Statistics</td><td>Avge syllables per word</td><td>1.35</td><td>1.34</td><td>2.02</td><td>1.8</td></tr><tr><td>Statistics</td><td> Flesch Reading Ease</td><td>59.61</td><td>59.43</td><td>8.66</td><td>33.64</td></tr><tr><td>Statistics</td><td>Flesch-Kincaid Grade</td><td>13.04</td><td>13.37</td><td>18.76</td><td>13.62</td></tr><tr><td>Statistics</td><td>Average Sentence Length</td><td>32.59</td><td>33.81</td><td>27</td><td>20.33</td></tr><tr><td>Lexical Diversity</td><td> Lexical diversity (VOCD)</td><td>71.86</td><td>62.8</td><td>71.16</td><td>54.36</td></tr><tr><td> Lexical Diversity</td><td>Lexical diversity (MTLD)</td><td>39.76</td><td>40.25</td><td>44.27</td><td>59.14</td></tr><tr><td>Lexis: EVP</td><td>A1 type %</td><td>45.97</td><td>52.45</td><td>28.57</td><td>51.16</td></tr><tr><td>Lexis: EVP</td><td>A2 type %</td><td>20.47</td><td>16.43</td><td>9.52</td><td>2.33</td></tr><tr><td>Lexis: EVP</td><td>B1 type %</td><td>10.07</td><td>13.99</td><td>19.05</td><td>25.58</td></tr><tr><td>Lexis: EVP</td><td>B2 type %</td><td>8.72</td><td>8.74</td><td>16.67</td><td>0</td></tr><tr><td>Lexis: EVP</td><td>C1 type %</td><td>2.01</td><td>1.4</td><td>4.76</td><td>11.63</td></tr><tr><td>Lexis: EVP</td><td>C2 type %</td><td>0.67</td><td>0</td><td>2.38</td><td>0</td></tr><tr><td>Lexis: EVP</td><td>Known Words type %</td><td>0.67</td><td>0.7</td><td>4.76</td><td>4.65</td></tr><tr><td>Lexis: EVP</td><td>Unlisted type %</td><td>11.41</td><td>6.29</td><td>14.29</td><td>4.65</td></tr><tr><td>Lexis: EVP</td><td>A1 token %</td><td>64.09</td><td>67.71</td><td>28.3</td><td>48.28</td></tr><tr><td>Lexis: EVP</td><td>A2 token %</td><td>13.76</td><td>11.54</td><td>15.09</td><td>1.72</td></tr><tr><td>Lexis: EVP</td><td>B1 token %</td><td>4.71</td><td>5.06</td><td>15.09</td><td>18.97</td></tr><tr><td>Lexis: EVP</td><td>B2 token %</td><td>3.68</td><td>3.44</td><td>13.21</td><td>0</td></tr><tr><td>Lexis: EVP Lexis: EVP</td><td>C1 token %</td><td>0.85</td><td>0.91</td><td>3.77</td><td>8.62</td></tr><tr><td></td><td>C2 token %</td><td>0.19</td><td>0</td><td>1.89</td><td>0</td></tr><tr><td>Lexis: EVP Lexis: EVP</td><td>Known Words token % Unlisted token %</td><td>3.3 9.43</td><td>6.07 5.26</td><td>11.32 11.32</td><td>18.97 3.45</td></tr></table></body></html>

(continued)   

<html><body><table><tr><td>Operation</td><td>Data</td><td>Lecture First half.</td><td>Lecture Second half.</td><td>Lecture Slides First half</td><td>Lecture Slides Second half</td></tr><tr><td>Lexis: AWL</td><td>AWL All Types %</td><td>5.83</td><td>7.48</td><td>11.9</td><td>15.56</td></tr><tr><td>Lexis: AWL</td><td>AWL All Tokens %</td><td>4.98</td><td>8.2</td><td>12.96</td><td>18.03</td></tr></table></body></html>

# References

Alera, . 015.tii mim s   isg mprio in m Th d Ptic i  e, (10, 1983-1988. https://doi.org/10.17507/tpls.0510.02   
Akl .021)   r i .    , 2 78-191.  / scholarspace.manoa.hawaii.edu/bitstream/10125/73439/1/25_02_10125-73439.pdf Accessed: 22 December 2021   
Ascencion ae,  008). It the -te ort. Jo of ish for c , 7, 140150. /i.0.1016/. jeap.2008.04.001   
aba,   ii   f 81/.106/. jslw.2009.05.003   
Batty, .15i   it  tg Testing, 32(1), 3-20. https://doi.org/10.1177/0265532214531254   
Bonk, . . 0 d n lex  ad istn mpehi. iol J f Lisg 11) 431.h//.g/10.1080/ 10904018.2000.10499033   
raury, 016)   n   10, or  in o, 0, 50953 //10152 advan.00109.2016   
Bray, J. H., & Maxwell, S. E. (1985). Multivariate analysis of variance. Newbury Park, CA: Sage Publications, Inc.   
Bret . ( iri 3.. org/10.1016/0346-251X(94)00054-A   
Bret . (19 ti t t  t i iset1 3953. /..0136-251X (96)00059-0   
Brindey, , & Slayter, H. (2002). Exploring tas diffiuly in EL istng asment. Lnge ting, 19(4), 369-394 http:/oi.rg/10.191/ 0265532202lt236oa   
ambrde t . 205). ish Poile theR fr gish aaet h://gisleg/ss e: 2 oer 2019   
ici . 0 tin   e  ti f sh Purposes, 3(1), 39-54. https://doi.org/10.1016/S1475-1585(03)00044-4 j.esp.2004.05.002 Series. MS-35. Available at https://www.ets.org/Media/Research/pdf/RR-07-01.pdf. (Accessed 29 October 2019). Lguge g 141),3105.ait ht://t.u/101471.994r88Aeed 17 December 2021.   
hng, . e  . 1    i  d i  q t ef or f of   /ad 942/218 Accessed: 12 October 2019.   
Chad  ky,   .19 s i d . perspectives (pp. 75-92). Cambridge: Cambridge University Press   
Chad  . 1   13..1093 applin/7.2.113   
hn,      014  f vif oh s .     3-58./i.g 10.3968/4348   
ni 01h          s2 (1), 1-14. https://doi.org/10.1016/S0346-251x(00)00057-9   
ncf o01).      a /80 Accessed: 27 August 2020.   
Coxhead, A. (2000). A new academic word list. Tesol Quarterly, 34(2), 213-238. https:/doi.org/10.2307/3587951   
ui . e  1n  n n taking. Language Assessment Quarterly, 10(4), 371-397. https://doi.org/10.1080/15434303.2013.824972   
ay  0f next generation T0EFL. Assessing Writing, 10, 5-43. https://doi.org/10.1016/j.asw.2005.02.001   
g      o       f s  e 23, 47-58. https://doi.org/10.1016/j.jeap.2016.06.002   
Debeer,   Jae  (2013) deing item-ionfts wthin an R frmwrk Jl of tiol Mem, 502), 164185.hs/oi.org. 10.1111/jedm.12009   
earrio,  er  18  for t f c  for i ,  10. /i. 10.1016/0889-4906(88)90027-0   
Dre, R t-ao, . (1984. of te  aice ng ci ( ) e chng 7(4, 6-3././10.1017 S026144480001082X   
Dien,  at-or, J 15. tf te t arie  ein P   g, 1, 220. /g/10.1017/ S0261444800011241   
udy- . (199)o in     f  a r  ct.  ., listening - research perspectives. Cambridge: Cambridge University Press.   
unkel, P. 18.          t ein  t   el, 2, 291./.0.2307 3586936   
kel  is    t   a iir e language. In J. Flowerdew (Ed.), Academic listening: Research perspectives. Cambridge: Cambridge University Press.   
uran,   , R  e  004  t  t. dsc 2, 20-2/./0.1093 applin/25.2.220 utg upp. 1, University Press   
Gebril,  (209. core isait f admic witing tss  one t mtd fit l? g ting 26(4), 124. h/o.g/10.1177 0265532209340188 doi.org/10.10169/j.asw.2014.03.002   
Gnther,  (202). t   vis a e isg  st.  g, 92, 13-167. ././0.191/ 0265532202lt225oa   
Goey7n r . 71 112/./.146- 1770.1977.tb00295.   
Grif, 1 n  imei .  g ( 311././0.11 j.1467-1770.1990.tb00666.x   
Grifts,  (9. ch rat d istnng mehther ift etionsh l r, 62 8539.ree fr /ww. jstor.org/stable/3587015 Accessed: 8 September 2020.   
Guea P 13   i      h/ticle jj-15.1-art7.pdf Accessed: 16 October 2018.   
Guba P194) o d   ii.  61)5  -icati. org/files/pdf-article/jj-16.1-art2.pdf Accessed: 27 October 2019.   
Gruba, P. (1997). The role of video media in istening asessment. System, 25(3),335-345. tps://doi.org/10.1016/50346-251x(97)00026-2   
Gu, L   3. t   qt comparison study. Assessing Writing, 18, 218-238. https://doi.org/10.1016/j.asw.2013.05.002   
Guo, P.J,  J bi . (2014). w idction afs stt me: An empricl st f vi.  Prgs o he rst AC Conference on Learning. https://doi.org/10.1145/2556325.2566239   
IBM Co 13). IBM SPSS windows, version 22.0. Armonk, NY: IBM Corp.   
IELTS. (2019). IELrs. Available at: https://www.ielts.org/about-the-test/two-types-of-ielts-test Accessed: 19 October 2019.   
Inman, . yr, . 018 stg  t  vi -  ape 68. ed fr /ri/lex ED588350.pdf Accessed: 31 October 2021.   
ch,   13   g s r n r  in 18 300-308. https://doi.org/10.1016/j.asw.2013.09.003   
yle,  (2020h lionh tw fre f se tet use and ind win qu.  in, 45,12. h/.g/0.10167/. w.2020.100467   
Laerd. (2015). Statisical tutorials and software guides. Available at: https://statistics.laerd.com/ Accessed: 05 October 2019.   
Laer , o 15.a i s  ri   ic, 6(, 0-2./10.1093 applin/16.3.307   
Le,  r  00.t    tive  h r   t tt.   of sing 7 (4), 353-385. https://doi.org/10.1080/15305050701632247   
Leeridge  .13)    c s  , 25 (2), 199-214. https://doi.org/10.1017/S0958344013000074   
Li, J 2014). E f t  s w  n25-9. /.10101408.03   
Linacre, J. M. (1989). Many-facet Rasch measurement. Chicago, IL: MESA Press   
Linare, J2012). Myt Rchem t rial ailaleat ht.//istes.o/a/i.f Ad: 28 Fary 2019.   
Locke,  (197.r  f lt ak  l te. he   oc, (, 3-9. /.10.1080 00220671.1977.10885044   
Lynch, T. (2011). Academic listening in the $2 1 ^ { \mathrm { s t } }$ century: Reviewing a decade of research. Journal of English for Academic Purposes, 10, 79-88. https://doi.org/ 10.1016/jjeap.2011.03.001   
Mackey, A , & Gass, S. M. (2005). Second Language research - methodology and design. Mahwah, New Jersey: Lawrence Erlbaum Associates, Inc.   
Mayer, R. (2001). Multimedia learning. New York: Cambridge University Press   
carthy,  Jis 0LD , d HD: altion sty f ssticad aphe t xlst st or eerch Methods, 42(2), 381-392. https:/doi.org/10.3758/BRM.42.2.381   
ar  i  ly Journal of Experimental Child Psychology, 161, 95-112. https://doi.org/10.1016/j.jecp.2017.04.006   
Miler    a f f    () 830. Retrieved from: https:/www.asian-efl-journal.com/June_2009_EBook.pdf#page-8 Accessed: 03 May 2021.   
onter P,  r  , . 014) s mtiv i sf d nd  co i   istenng comprehension. $R e C A L L ,$ 26(1), 21-42. https://doi.org/10.1017/S0958344013000256   
a   gh  019  wiers u i  a the ch  of s fr Ac  38, 106-120. https://doi.org/10.1016/j.jeap.2019.02.002   
Ockey, . (20. mpitio f g si m r vi  e- istg tst.  tin 24(4, 57-537 p/o.g 0.1177/026553220709077   
Oxford University Press. (2001). Quick placement test. Oxford: Oxford University Press.   
Pardatr . 01  -s .    91./..7206.7.17   
Parbakht, . 06)oh   ea o d is iciet  of ih for Academic Purposes, 21, 121-132. https://doi.org/10.1016/j.jeap.2015.05.009   
Plans  (209Te olf n r i ig s.  f Esh for d e, 8, 25226. /.g0.16/. jeap.2009.05.001   
Plans  il, 01. c titi  e   rat awtin .ng 7 83./o.g 10.1016/j.asw.2011.09.002 217-230. https://doi.org/10.1016/j.jslw.2013.02.003   
Prgsh i a l /. php/tesl/article/view/676/507 Accessed: 29 August 2020.   
Pu, 0   - 52.. org/10.1017/S0958344002000423   
Red . 200   i    f s    1011er  .   
e 35, 31-65. https://doi.org/10.1017/S0272263112000678   
Rz     i  t. Jounal of English for Academic Purposes. Journal of English for Academic Purposes, 48, 1-17. htps://doi.org/10.1016/jeap.2020.100925   
Richards, J.C. (1983). Listning comprehensio: Approach, deign, procedure. Teol Quartrly, 172), 219-240. htps://doi.org/10.2307/3586651   
R of Educational Psychology, 89(3), 508-517. https://doi.org/10.1037/0022-0663.89.3.508   
Roinon,  g,      (1997ff e ra t    of  rt. Contemporary Educational Psychology, 22, 260-277. https://doi.org/10.1006/ceps.1997.0929   
Rukhthong, . (2015). Investiging the isteng costrct underlyig listeing-urize tasks. Laaster Univrst. Unublished PhD thesis.   
k   0   i  ng 37 (1), 31-53. https://doi.org/10.1177/0265532219871470   
Siege, . 208  ak    en   .  of gis   5852. / doi.org/10.1016/j.jeap.2018.07.001   
Siee, . 0   a ih q-.  of h r dc Purposes, 46, 1-10. https://doi.org/10.1016/j.jeap.2020.100868   
Sthr,  . (208. Vy siedthe kill of istg, rg an wtg.  n Jo, 362, 139-153. /i.g/10.1080/ 09571730802389975   
Sthr, . 00  d  is mi n gish   aa    qsio 4) 577-607. Available at: https://www.jstor.org/stable/pdf/44485886 Accessed: 05 September 2020.   
eyshi  o005       i   ) 1-669. / doi.org/10.1111/j.0023-8333.2005.00320.x 180813-16671. Master's thesis.   
o, 3   t 881067   
ydreo  0ty  t y sti.  g   2 07a t h/mm2 sydorenko.pdf Accessed: 16 October 2019.   
Tauroza, ., & Allison, D. (1990. Spch rat in British English. Aplid Linuistcs, 1(1), 90-105. http:/oi.rg/10.1093/applin/11.1.90   
Text Inspector. (2019). Text Inspector.com. Available at textinspector.com. (Accessed 15 September 2019).   
Tmpn3 r      , 5-20. https://doi.org/10.1016/S1475-1585(02)00036-X   
ra .,   016  i c  23. https://doi.org/10.1016/j.asw.2016.08.001 34(4), 457-479. https://doi.org/10.1093/applin/ams074   
andgit  004) st  g ist  f Ap nsi 24 -25./.017/02671905040007   
Vidal, K. (2003). Ademic listeng sore f vocabular cquisition Aplied Lnusics 24(1), 5689. ps:/i.og/10.1093/alin/24.1.56   
Voss B.(1984). Slips of the Ear: Investigations into the speech perception behaviour of German speakers of English. Tubingen: Narr.   
ager 00) t  v  t  , 11 66.aea https:/scholarspace.manoa.hawaii.edu/bitstream/10125/44089/11_01_wagner.pdf Accessed: 09 August 2020.   
ager, 010 eff f th u f id x n  ist t-ar   in 7(), 93513. /./10.1177 0265532209355668   
Wer . uk/id/eprint/10019535/1/WEIR,%20C.J.Vol_1.pdf Accessed 01 Feb 2021.   
Werook  11     t     e Siena, Italy: Universita di Stranieri, 5-8 May 2011.   
e,   f     i  , 4(1) 65-86. Retried from: htps:/chlarsace.manoa.hawaiid/bistream/10125/42031401 winkeassyoreno.df Aced 21 Deemer 2021.   
Yong, 19t  .  ii.e University Press.   
Yu, G. 009  ng  t e f   ait   n  6-7. /.106. asw.2009.04.002   
Zare Jhki. 017  t     . Academic Purposes, 27, 31-41. https://doi.org/10.1016/j.jeap.2017.03.001