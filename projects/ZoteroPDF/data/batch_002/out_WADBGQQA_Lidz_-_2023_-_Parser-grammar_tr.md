# Parser-grammar transparency and the development of syntactic dependencies

Jeffrey Lidz

To cite this article: Jeffrey Lidz (2023) Parser-grammar transparency and the development of syntactic dependencies, Language Acquisition, 30:3-4, 311-322, DOI: 10.1080/10489223.2022.2147840

To link to this article: https://doi.org/10.1080/10489223.2022.2147840

# Parser-grammar transparency and the development of syntactic dependencies

Jeffrey Lidz

University of Maryland

# ABSTRACT

A fundamental question in psycholinguistics concerns how grammatical structure contributes to real-time sentence parsing and understanding. While many argue that grammatical structure is only loosely related to online parsing, others hold the view that the two are tightly linked. Here, I use the incremental growth of grammatical structure in developmental time to demonstrate that as new grammatical knowledge becomes available to children, they use that knowledge in their incremental parsing decisions. Given the tight link between the acquisition of new knowledge and the use of that knowledge in recognizing sentence structure, I argue in favor of a tight link between grammatical structure and parsing mechanics.

# ARTICLE HISTORY

Received 14 January 2022   
Accepted 15 October 2022

# 1. Introduction

One of the oldest ideas in psycholinguistics holds that the real time perception of syntactic structure reflects grammatical representations transparently (Miller & Chomsky 1963; Mehler 1963; Mehler & Carey 1967; Berwick & Weinberg 1984; Bresnan & Kaplan 1982; Phillips 1996; Steedman 2000, inter alia). When first introduced, this idea was couched as the Derivational Theory of Complexity (DTC), that is, sentences whose grammatical analysis require more transformational steps also require more computational steps in parsing and hence should take more time to process (Miller & Chomsky 1963). For example, in the theory of the day, declarative sentences like (1a) would require no transformations, polar questions like (1b) would require one transformation (subject-aux-inversion), and wh-questions like (1c) would require two transformations (subject-aux-inversion and wh-movement). As a result, (1c) was predicted to be recognized more slowly than (1b), which in turn would be recognized more slowly than (1a).

(1) a. The dog will chase the cat b. Will the dog chase the cat? c. Who will the dog chase?

While some initial results supported this idea, the DTC could not be maintained, as the number of transformations did not seem to be a reliable predictor of sentence processing time across a wider range of phenomena (Slobin 1966; Fodor et al. 1967; Walker 1968). While there were many reasons that the DTC might have failed, including having the wrong grammatical theory, the wrong theory of transparency, or the wrong complexity measure (Berwick & Weinberg 1984), one prominent response to these failures was to give up on the idea of transparency altogether (Chomsky 1968; Bever 1970). Bever, for example, suggested that the “perceptual and grammatical systems for relating internal and external structures of sentences . . . can manifest themselves as independent in the adult and are learned at least partially independently in the young child.” (Bever 1970: 281). While this move made it harder to martial psycholinguistic evidence in favor of any particular linguistic analysis, one virtue was the attempt to bring into alignment certain aspects of child and adult psycholinguistics. For example, Bever suggested that the same parsing heuristic, treating sentences containing the sequence N-V-N as indicating subject-verb-object, could explain both adult garden path phenomena (2a) and children’s difficulties with passive sentences (2b):

(2) a. The horse raced past the barn fell b. The cat was chased by the dog

In adult psycholinguistics, this idea has persisted and morphed into ideas like “good enough parsing” (Ferreira et al. 2002) and “shallow parsing” (Frank et al. 2012). Such two-systems approaches treat the perception of sentence structure as driven in part by mechanisms that are largely independent of the representations implied by the grammatical theory.

In developmental psycholinguistics, the question of the fit between grammar and parser has not been a primary topic of investigation since Bever’s (1970) initial forays. Rather, to the extent that researchers have examined children’s parsing, it was with an eye towards questions of incrementality (e.g., Borovsky et al. 2012; Mani & Huettig 2012; Lew-Williams & Fernald 2007; Omaki et al. 2014; Love 2007; Trueswell et al. 2012), on-line prediction (e.g., Omaki et al. 2014; Lassota et al. 2016; Huang et al. 2017) and the integration of multiple sources of information in ambiguity resolution (e.g., Trueswell et al. 1999; Choi & Trueswell 2010; Thothathiri & Snedeker 2008; Kidd et al. 2011; Rabagliati et al. 2013; Huang & Ovans 2021). However, such research characterizing children’s parsing is generally orthogonal to the question of the degree to which parsing transparently respects grammatical structure.

In the current paper, I would like to return to the question of the fit between parsing mechanics and grammatical knowledge, using children’s performance as a probe. I will argue against a two-systems approach in which the perception of sentence structure is independent of the data structures that characterize grammatical knowledge, and in favor of transparency between parser and grammar throughout development. The transparency I have in mind is that children use their grammatical knowledge fully and incrementally in the process of sentence understanding. Whatever grammatical knowledge children have at a given stage of development is directly engaged by predictive and incremental processes of structure building and interpretation. This is not to say that children never make errors, but only that such errors do not reflect a lack of transparency between their current state of knowledge and the parsing mechanisms that drive sentence understanding. Typically, such errors reflect the extralinguistic systems that are engaged in sentence understanding (Novick et al. 2005; Clackson et al. 2011; Syrett & Lidz 2011; Omaki et al. 2014).

In order to make this argument, I will review a range of evidence concerning children’s grammars and parsers in the period between 15- and 20-months of age, focusing specifically on how children represent and parse grammatical dependencies. To foreshadow, we will see that as new knowledge comes on-line developmentally, it has immediate effects on incremental structure building procedures, suggesting that there is no chasm between the mechanisms of sentence recognition and the data structures defined by the grammar. Rather, the perceptual mechanisms involved in sentence recognition make optimal use of grammatical knowledge, even if that knowledge is incomplete relative to the ultimate target of acquisition. On this view, we maintain the unity of child and adult psycholinguistics and the transparency between grammatical structure and psycholinguistic processes.

In order to see the argument in favor of transparency clearly, we must first examine the development of syntactic dependencies. Having established a timeline of development for both local and nonlocal dependencies, we will be able to probe the degree to which grammatical knowledge drives children’s on-line parsing throughout development.

# 2. Dependencies in syntactic development

Syntax concerns itself with dependencies between words and phrases. These dependencies sometimes hold locally, as in the case of a verb selecting its direct object. In (1), for example, we see that the English verb bring requires a Noun Phrase immediately to its right. If that NP is missing, or if an adverb intervenes, ungrammaticality results. Other dependencies hold at a distance, as for example when that same verb-object relation is realized by a wh-phrase at the upper edge of a clause (2). In (2), we see that the direct object of a verb like bring can be missing just in case there is a wh-phrase at the left edge of the clause. And, when there is a wh-phrase at the left edge of the clause, then the direct object position cannot be filled. This complementarity reflects the fact that what in (2a) and the toy in (1a) both bear the same relation to the verb, despite differences in their local syntactic environments.

(1) a. April is bringing the toy b. \* April is bringing c. \* April is bringing quicky the toy   
(2) a. What is April bringing b. \* What is April bringing the toy

In the next two sections we examine children’s discovery of local and long-distance dependencies.

# 2.1 Local Dependencies

Our understanding of what children know about local argument-structure dependencies mostly comes from studies of verb learning. Numerous studies have shown that infants can use the syntactic structure of a sentence as evidence about what event it describes, and consequently what the verb in that sentence means. For example, Naigles (1990) famously presented 25-month-olds with a novel verb in the context of a complex scene with two parts: a causal part in which a duck pushes a bunny over, and a noncausal part in which the duck and bunny each wheel their arms independently. While they watched this scene, the children heard a novel verb used either transitively, as in (3a), or intransitively, as in (3b).

(3) a. The duck is gorping the bunny. b. The duck and the bunny are gorping.

Naigles (1990) then separated these two parts of the scene into two different videos each showing only one of the two events. She measured infants’ looking preferences when they were asked to “find gorping” as a function of whether they were initially familiarized to the novel verb in a transitive or an intransitive clause. Infants who had heard the transitive looked longer at the pushing scene, and infants who heard the intransitive looked longer at the arm-wheeling scene. Infants were thus sensitive to the syntactic frame of the novel verb, inferring that gorp in a transitive frame was more likely to label the causal event, whereas gorp in an intransitive frame was more likely to label the noncausal event.

This basic finding has been reproduced in various ways, confirming that infants as young as 22 months are sensitive to transitivity, and reliably infer that transitive clause containing a novel verb labels a causal event (Arunachalam & Waxman 2010; Arunachalam & Dennis 2018; Brandone et al. 2006; Fisher et al. 2010; Noble et al. 2011; Pozzan et al. 2015; Yuan & Fisher 2009; Yuan et al. 2012).

Moreover, children are able to draw this inference on the basis of distributional information alone. Yuan & Fisher (2009) familiarized 28-month-olds with short dialogues containing novel transitive or intransitive verbs, without any informative visual context. At test, infants were then asked to identify the referent of the novel verb (e.g., Find blicking!) while viewing two candidate events, one causative and one noncausative. Infants who had heard the transitive dialogues looked longer at the causative event than infants who had heard the intransitive dialogue. This indicates that they had tracked the syntactic properties of the novel verb and used those properties to draw inferences about its possible meanings, even without the support of referential context.

However, beyond Naigles’ (1990) seminal study, further work has found inconsistent behavior with intransitive clauses. Infants who hear novel verbs in intransitive frames do not show a reliable preference for events intended to be viewed with one participant as opposed to two (e.g., Arunachalam & Waxman 2010; Noble et al. 2011; Yuan et al. 2012). Several methodological explanations have been proposed to account for these variable results with intransitive clauses. First, many studies use intransitive sentences with conjoined subjects (e.g., The duck and the bunny are gorping) in order to control the number of nouns across conditions. It is possible that infants may not reliably perceive these sentences as intransitive: if they mistake the conjoined subject for two separate arguments, this might lead them to infer a causative meaning for the verb (Gertner & Fisher 2012; Yuan et al. 2012). This view recalls, though is not identical to, Bever’s (1970) idea of heuristic sentence understanding mechanisms, as the child’s perception of the clause is driven by the number of NPs rather than by their structural positions. An alternative view would be that infants do not reliably perceive the presented scenes under the event concept intended by the experimenters. If infants conceptualize a scene of one actor pushing another as an event of two actors playing, then they might consider the intended “two-participant” scene a good referent for a novel intransitive verb labeling that event (Brandone et al. 2006; Pozzan et al., 2015; Arunachalam et al. 2016). Thus, without clear independent support for either the sentence percept or the scene percept, it is difficult to diagnose children’s difficulties.

Nonetheless, prior work shows a clear asymmetry in the interpretation of transitive and intransitive clauses containing novel verbs. But these asymmetries raise the question of how infants use the syntactic contexts that verbs appear in to draw inferences about their meanings. One influential view. already alluded to, holds that infants take the noun phrases in a clause to be arguments, and expect the number of arguments in a clause to match one-to-one the number of participants in the event the clause describes (Fisher 1996; Gleitman 1990; Naigles 1990; Lidz et al. 2003; Fisher et al. 2010). Thus, a transitive clause with two arguments should label an event perceived with two participants, whereas an intransitive clause with only one argument should label an event perceived with one participant. This learning strategy has the advantage of requiring little syntactic knowledge of the learner, but also comes with a cost—it is based on a heuristic that does not hold generally across the verb lexicon and which is not consistent with the range of variability found across the world’s languages (Williams 2015; Perkins 2019; Perkins et al. 2022). Thus, a learner using this one-to-one matching heuristic will ultimately need to abandon it, presumably when their knowledge of the grammar becomes richer.

An alternative explanation of the effects of transitivity on verb learning, which would be more continuous with adult grammars cross-linguistically, might rely on children’s expectations about the ways that local syntactic dependencies are related to clause meaning (Perkins 2019; cf. Dowty 1979; Jackendoff 1983; Pinker 1984; Grimshaw 1990; Baker 1996; Williams 2015). On this view, infants expect the subjects of transitive clauses to name agents, and they expect objects of transitive clauses to name patients. Therefore, if infants could identify local grammatical relations like subject and object, then they could infer that the clause labels an event in which the subject refers to the agent and the object refers to the patient. Having identified these roles, the learner would be in a good position to identify the event labeled by the sentence and, in turn, the verb (Gertner et al. 2006).

To test this latter hypothesis, Lidz et al. (2017) asked about the first step of this chain of inference, namely whether 16- and 19-month-old children know about correspondences between the syntactic position of a Noun Phrase and its thematic relation.

They presented events in which an agent used an instrument to affect an object. For example, they saw events in which a hand used a ruler to tap a traffic cone. While they saw these events, they heard either a simple transitive clause containing a novel noun in the direct object position, (4a), or an intransitive clause containing a novel noun inside a Prepositional Phrase headed by with (4b).

(4) a. She’s hitting the tam b. She’s hitting with the tam

After several exposures to these sentences containing the novel noun, they were then shown the two objects (i.e., the ruler and the cone) and were asked “which one is the tam?”. Sixteen- month-olds looked more at the cone in the transitive condition and they looked more at the ruler in the Prepositional Phrase condition. These results indicate that by 16- months, infants know how to identify the thematic role of a NP based on its syntactic position. Because infants drew different conclusions about the referent of the novel NP (and arguably the meaning of the novel noun) as a function of its syntactic position, we can conclude that they build syntactic representations that contain more information than simply the number of nouns in the clause. In turn, this conclusion suggests that effects of clause structure in verb learning experiments might be driven by a richer representation of subject and object and the thematic consequences of these representations (see Perkins et al. (2022) for converging evidence).

While these results indicate that by 16-month-olds children are aware of mappings between syntactic position and thematic relation, a closer examination of the data also reveals the incremental nature of the parser in the 2nd year of life. In this dataset, the effect of syntactic position is negatively related to children’s verb vocabulary. As verb vocabulary goes up, children’s ability to use the syntactic position as evidence of the thematic relation goes down. Lidz et al. (2017) argue that this effect derives from an independent contribution of the verb’s statistical distribution to parsing and understanding. Because the verbs used in this study occurred in transitive clauses in child-directed speech roughly $8 0 \%$ of the time, this statistical information overpowered the bottom-up information derived from the syntax. This interpretation is further supported by the data of the 19-month-olds who, like the larger vocabulary 16-month-olds, were more likely to treat the novel noun as referring to the patient, independent of its syntactic position.

A natural interpretation of this statistical effect is that it is a reflection of the predictive nature of (infant) parsers. Regarding this viewpoint, when children hear a verb that they know, they project the most likely syntactic structure in advance of getting bottom-up evidence for that structure (Altmann & Kamide 1999; Gordon & Chafetz 1990; MacDonald et al. 1994; Trueswell et al. 1993). When these predictions conflict with bottom-up information from the sentence itself, they have difficulty revising this conflict (Trueswell et al. 1999) and rely instead on their initial commitments (cf. Sherman & TurkBrowne 2020).

This interpretation is supported by two additional results. First, if the verb’s prediction for a direct object is satisfied, then 19-month-olds show the expected sensitivity to the contribution of the preposition. Lidz et al. (2017) tested 19-month-olds with sentences like (5).

(5) a. She’s hitting that thing with the tam b. She’s hitting the tam with that thing

In this situation, 19-month-olds successfully interpreted the novel noun phrase as referring to the instrument in (5a) and to the patient in (5b). Thus, when the predictions of the verb are satisfied, then the contribution of the bottom-up information in the preposition is revealed.

Additionally, White & Lidz (2021) tested 19-month-olds’ interpretations of these same structures but with a novel verb in addition to the novel noun:

(6) a. She’s gorping with the tam b. She’s gorping the tam

Because the verb is novel in these sentences, it has no distributional profile to drive a syntactic prediction. As a result, children here were predicted to rely on the bottom-up cues to structure and correctly interpret the novel noun phrase as an instrument in (6a) and a patient in (6b). This is precisely what White & Lidz (2021) found. Strikingly, the sentences with both a novel verb and a novel noun reveal children’s knowledge of the link between syntactic position and thematic relation better than those with a known verb and a novel noun. In turn, the fact that the contribution of the syntactic structure interacts with the contribution of the lexical distribution demonstrates that children’s parsing and interpretation is fed by knowledge of both, even at the earliest stages of syntactic development. To the extent that children make parsing errors, these arise not from a lack of knowledge, but from the interaction of structural and lexical contributions to on-line structure-building processes.

To summarize so far, we have seen that by 16-months of age, infants can use the syntactic position of a novel noun phrase to determine its thematic relation to the event labeled by the verb and, in concert with a scene, determine the referent of this noun phrase. This implies that by this age infants have knowledge of the mapping between syntactic positions and thematic relations. However, we have also seen that this ability is impacted by new knowledge of verbsubcategorization frequencies as these are acquired. Knowledge of subcategorization frequencies can lead to syntactic predictions. And in some cases, these predictions conflict with the bottom-up information in the signal and lead to parsing errors. These parsing errors, in turn, lead to errors of interpretation. In children younger than two years of age, the parser is incremental, predictive and statistical, just as it is in adults (Frazier & Rayner 1982; Frazier & Flores D’Arcais 1989; Trueswell, Tanenhaus & Garnsey 1994; Altmann 1998; Wagers & Phillips 2009). Moreover, the statistically driven predictions of the infant parser change as children identify the distributional signatures of particular verbs, suggesting that as lexical knowledge grows, the parser incorporates that knowledge immediately. We will return to this point below.

# 2.2 Nonlocal dependencies

Turning now to nonlocal dependencies, some studies have found evidence that English-learning children might develop the ability to detect movement dependencies in English sentences between the ages of 15 and 20 months (Gagliardi et al. 2016; Seidl et al. 2003; Perkins & Lidz 2020, 2021). Seidl et al. (2003) investigated 13-, 15-, and 20-month-old infants’ understanding of wh-questions using a preferential looking technique. Infants saw an event of, for example, an apple hitting some keys, and then saw still images of the apple and the keys while being asked one of the three questions in (7).

(7) a. Where are the keys? b. What hit the keys? c. What did the apple hit?

They found that 13-month-olds were unable to respond correctly to any of the questions, that 15- month-olds looked at the correct image for the “where” question (7a) and the subject question (7b), but not the object question (7c), and that 20-month-olds looked at the correct image for all 3 question types.

Gagliardi et al. (2016) followed up on this research, testing comprehension of wh-questions and relative clauses like those in (8).

(8) a. Which dog did the cat feed? (object Q) b. Which dog fed the cat? (subject Q) c. Find the dog that the cat fed (object relative) d. Find the dog that fed the cat (subject relative)

These prompts occurred after the infants watched a scene in which one dog fed a cat, and then the cat fed a second dog, making both the questions and relatives felicitous. Unlike Seidl et al. (2003), these authors did not find a subject-object asymmetry, but they did find an interesting discontinuity in performance. 15-month-olds appeared to arrive at the correct interpretation for both wh-questions and relative clauses. In an object question/relative they looked more at the dog that got fed, rather than the dog that had done the feeding. The 20-month-olds, however, only appeared to comprehend whquestions and relative clauses in which the relative pronoun was who, but not those with that. These authors argued that 20-month-olds’ surprising failure with certain relative clauses might demonstrate the development of syntactic knowledge. These infants have learned to represent the full movement dependencies in these sentences, but have difficulty detecting when relative clauses with that contain these dependencies. The word that is ambiguous in English—it occurs in many contexts other than in relative clauses—so words like who or which are much clearer cues to movement dependencies. By this logic, then, 15-month-olds might arrive at the right answer without parsing the full movement dependency, thereby avoiding these difficulties with relative clauses.

On the view that 15-month-olds’ success with wh-questions and relative clauses is not based in their knowledge of wh-movement, this success would be explained by their knowledge of argument structure. Specifically, 15-month-olds knowledge of the transitivity of certain verbs could drive their ability to find the missing argument in a wh-question. For example, after hearing a sentence like (8a), a child who knows that feed is a transitive verb would successfully identify the cat as the subject and hence the agent of feeding and further generate the expectation for an object NP to fill the role of the entity being fed. When this NP does not arrive, she could nonetheless look for the referent of the missing argument relation.

As previously shown, vocabulary size is a predictor of when children expect a direct object NP to occur with a particular verb. Therefore, under the hypothesis that 15-month-olds’ success at interpreting wh-questions is due to their argument structure representations, and not to their knowledge of the grammatical dependency between the wh-phrase and the verb, we can predict that 15-month-olds’ should succeed at identifying the patient argument in an object wh-question only to the degree that they know the transitivity of the verb.

Perkins & Lidz (2019) tested this prediction by using total vocabulary size as an index of 15-montholds’ likely verb argument-structure knowledge, asking whether their success on interpreting object wh-questions was predicted by the size of their vocabularies. In this task, participants were presented with two videos on opposite sides of a television screen. In one video a brown monkey was feeding a frog. In the other, the frog was feeding a black monkey. Participants then heard one of the sentences in (9), and their eye-gaze was measured.

(9) a. Which monkey is feeding the frog? b. Which monkey is the frog feeding? c. Find the monkey that is feeding the frog. d. Find the monkey that the frog is feeding.

As predicted, for both subject and object wh-questions and for both subject and object relative clauses, children’s vocabulary was the best predictor of their success at looking at the right event. Note that vocabulary size was a predictor of successful interpretation here for precisely the same reason that it was a predictor of unsuccessful interpretation among 16-month-olds in Lidz et al (2017)—namely that knowledge of specific verb-argument structures allows for prediction of a direct object and the thematic interpretation of that predicted argument.

Of course, while the effect of vocabulary was predicted by the account that 15-month-olds’ apparent understanding of wh-questions is driven by their knowledge of argument structure, vocabulary effects are pervasive in all aspects of cognitive and linguistic development. It is possible, then, that vocabulary is not an index of argument structure knowledge in these kinds of tasks, but rather of knowledge of the dependency itself. Given the findings reported above showing that knowledge of argument structure begins to emerge in this same time period, it seems more plausible that the account offered by

Gagliardi et al. (2016) and Perkins & Lidz (2019) is correct. Nonetheless, a more direct test of the knowledge of the filler-gap dependency itself was required to be confident in these conclusions.

Perkins & Lidz (2021) set out to provide such a test. They probed knowledge of both the local argument-structure dependency and the filler-gap dependency in a task that was not based on the interpretive and referential consequences of that knowledge. To do so, these authors developed a listening time task (Maye et al. 2002; Shi, Werker & Cutler 2006) that tested children’s knowledge of the complementary distribution of fronted wh-phrases and NPs in direct object position.

This task asked whether infants in four age groups (14-, 15-, 17-, and 18-month-olds) were sensitive to missing arguments of transitive verbs by comparing sentences with post-verbal NPs and those without. The compared these in declarative contexts (10) and in wh-questions (11). In this design, the acceptability of having a post-verbal NP is flipped across the two pairs. The verb hug

(10) a. A dog! The cat should hug. b. A dog! The cat should hug him.   
(11) a. Which dog should the cat hug? b. Which dog should the cat hug him?

needs a direct object, making (10a), which lacks a direct object, less acceptable than (10b), which has one. But, the wh-phrase can serve as that argument across a distance, making (11a) more acceptable than (11b). Thus, to the degree that infants can represent both the local argument-structure dependency and the nonlocal wh-dependency, we should expect a different pattern of listening preference in the declaratives (10) as compared to the wh-questions (11). Conversely, if they only represent the local argument-structure dependency, then we should expect the same pattern in the declaratives and the wh-questions.

Consistent with the view that 15-month-olds do not represent the nonlocal dependency in a whquestion, only the 18-month-olds in this study showed a different pattern of responses in the declaratives and the wh-questions. These infants listened longer to the grammatical item in each pair (i.e., $1 0 \mathrm { b } > 1 0 \mathrm { a }$ , and $1 1 \mathsf { a } > 1 1 \mathsf { b }$ ). This suggests that it is not until 18-months that English-learning children have identified the nonlocal dependency in wh-questions. This conclusion, in turn, supports the view that younger children’s success with interpreting wh-questions was driven by their knowledge of argument structure and not the long-distance dependency involved in wh-movement.

# 3. Parser-grammar transparency revisited

We are now in a position to use our understanding of how children represent local and nonlocal dependencies, and when this knowledge develops, in order to probe the degree to which grammatical knowledge and the mechanisms involved in parsing and interpretation are transparent.

As we have seen, 19-month-olds in Lidz et al. (2017) use their knowledge of a verb’s likely subcategorization frame to drive initial parsing decisions. When they hear a verb that is highly likely to occur in transitive clauses, they project a direct a direct object position, to be filled by the next NP they encounter in the signal. This leads them to misparse sentences like (12a), where this prediction is inconsistent with the bottom-up input, but to correctly parse sentences like (12b), where it is consistent with the bottom-up input.

(12) a. She’s hitting with the tam b. She’s hitting that thing with the tam

Additionally, we have also seen that it is not until 18-months that children represent the long-distance dependency that underlies wh-questions.

As a result, Hirzel et al. (2020) set out to test the transparency of the parser and the grammar by putting these two observations together. If the parser is transparent to the grammar throughout development, then we expect that as a new piece of knowledge is added to a child’s grammar, that knowledge will be used in incremental structure building processes. Conversely, if learning to parse is somehow independent of learning the grammar (or, if parsing mechanisms do not fully respect grammatical knowledge), then we would expect a delay between the acquisition of new knowledge and its use in on-line parsing. More specifically, these authors asked whether knowledge of the longdistance dependency in wh-movement is used in incremental structure building by 19-month-olds.

To ask this question, they presented 19-month-olds with sentences like those in (13).

(13) a. She’s hitting with the tam b. What is she hitting with the tam

The declarative (13a) is a replication of Lidz et al. (2017). Given prior results, the expectation was that 19-month-olds would treat “the tam” as the direct object of the verb and, consequently, the patient of the hitting event, despite the presence of the preposition. This error results from the verb’s bias to take a direct object argument, leading children to parse (13a) as though it were a simple transitive clause. The wh-question in (13b), however, can determine whether children rapidly integrate the wh-phrase into the object position. If they do, then the wh-phrase will satisfy the verb’s expectation that it takes a direct object and so the PP can be integrated into the structure correctly, leading to the interpretation of “the tam” as the prepositional object, and hence the instrument of the hitting event. If, however, children’s parsers do not use their newly acquired knowledge of the long-distance dependency involved in wh-movement, then we would expect them to make the same parsing error they make in (13a), namely allowing the verb’s expectation for a direct object to overshadow the contribution of the preposition.

Hirzel et al. (2020) show that 19-month-olds treat “the tam” in as the patient of the hitting in (13a), but that they do not do so in (13b), where they are more likely to treat it as the instrument of the hitting. This suggests that just as children acquire the syntactic dependency in wh-movement, this knowledge is integrated into their parsing behavior. They treat the fronted wh-phrase as the direct object of the verb, despite the fact that it is displaced from the verb. This, in turn, suggests that there is a tight link between the acquisition of grammatical structure and its use in parsing. Not only do children recognize that fronted wh-phrases can function as direct objects, they use this information in their on-line parsing and interpretation decisions. This tight link further argues against views of parsing that separate the mechanics of sentence perception from the representation of grammatical knowledge (e.g., Bever 1970; Ferreira et al. 2002; and Frank et al. 2012). There is simply no developmental time between children’s learning some aspect of grammar and their ability to use that knowledge in incremental structure building. Rather, parsing makes transparent use of grammatical knowledge, essentially as soon as that knowledge is acquired and from the earliest stages of syntactic development. Thus, learning a grammar is sufficient for learning to parse.

# 4. Conclusions

In this paper we have explored the emergence of local and long-distance dependencies in children’s grammars and the consequences of this new knowledge for children’s on-line parsing behavior. As we have seen, knowledge of the link between syntactic position and thematic relation is in place by 16 months. As the verb vocabulary grows, children begin to use their knowledge of a verb’s distribution to predict upcoming structure. This knowledge leads them to misparse sentences that don’t match the statistically dominant form, but also provides the information they need to correctly interpret sentences with long-distance dependencies, even before acquiring their syntax. By 18-months, knowledge of wh-movement dependencies appears to be in place, and we have seen that by 19-months, children use this knowledge to guide their on-line parsing decisions, allowing a fronted wh-phrase to serve as the predicted argument of a known transitive verb. In sum, it appears that as children’s knowledge of grammar grows, new knowledge is immediately incorporated into mechanisms of sentence perception and understanding.

Because children’s parsing behavior is so tightly tied to their grammatical knowledge, we can conclude that children do not operate with two separate systems–one for grammatical analysis and another for on-line sentence perception–as originally proposed by Bever (1970). Rather, the mechanisms involved in sentence perception are directly informed by the data structures that underlie grammatical knowledge. We do not both learn a grammar and how to parse. Instead, parsing and grammar develop in tandem, pointing to a one-system view of parser-grammar relations. In other words, we learn a grammar, and parsing comes for free.

This paired development, in turn, suggests that there is no separate system of mind whose role is to parse sentences. Rather, parsing mechanics may reflect grammatical knowledge so transparently because sentence recognition procedures use the data structures defined by the grammar in concert with rest of cognitive psychology—systems such as working memory, cognitive control, inhibitory control, and so forth. A strong version of this hypothesis is that sentence recognition involves the optimal use of the data structures defined by the grammar, subject to the constraints imposed by extralinguistic cognitive systems (Frazier & Fodor 1978). Spelling out precisely how grammatical knowledge interacts with these extralinguistic cognitive resources constitutes an important goal for future research.

# Disclosure statement

No potential conflict of interest was reported by the author(s).

# ORCID

Jeffrey Lidz $\textcircled{1}$ http://orcid.org/0000-0001-8829-1495

# References

Altman, Gerry T.M. 1998. Ambiguity in Sentence Processing. Trends in Cognitive Science 2.146–152.   
Altmann, Gerry T. & Yuki Kamide. 1999. Incremental interpretation at verbs: restricting the domain of subsequent reference. Cognition 73(3). 247–264   
Seidl, Amanda, George Hollich & Peter W. Jusczyk. 2003. Early understanding of subject and object wh-questions. Infancy 4. 423–436.   
Borovsky, Ariel, Jeffrey L. Elman & Anne Fernald. 2012. Knowing a lot for one’s age: Vocabulary skill and not age is associated with anticipatory incremental sentence interpretation in children and adults. Journal of Experimental Child Psychology 112. 417–436.   
Arunachalam, Sudha & Shaun Dennis. 2018. Semantic detail in the developing verb lexicon: An extension of Naigles and Kako (1993). Developmental Science 22. e12697.   
Arunachalam, Sudha. & Sandra R. Waxman. 2010. Meaning from syntax: Evidence from 2-year-olds. Cognition 114. 442–446.   
Arunachalam, Sudha, Kristen Syrett & YongXiang Chen. 2016. Lexical disambiguation in verb learning: Evidence from the conjoined-subject intransitive frame in English and Mandarin Chinese. Frontiers in Psychology 7. 138. doi: 10. 3389/fpsyg.2016.00138   
Baker, Mark C. 1996. Thematic roles and syntactic structure. In L. Haegeman (ed.), Elements of grammar, 73–137. Dordrecht: Kluwer.   
Berwick, Robert & Amy Weinberg. 1984. The grammatical basis of linguistic performance. Cambridge: MIT Press.   
Bever, Thomas G. 1970. The cognitive basis for linguistic structures. In J. R. Hayes (ed.), Cognition and the development of language, 279–362. New York: John Wiley.   
Brandone, Amanda, Dede Addy, Rachel Pulverman, Roberta Golinkoff & Kathy Hirsh-Pasek. 2006. One-for-one and two-for-two: anticipating parallel structure between events and language. In Proceedings of BUCLD 30. Boston: Cascadilla Press.   
Bresnan, Joan & Ronald Kaplan. 1982. Introduction: Grammars as mental representations of language. In J. Bresnan (ed.), The mental representation of grammatical relations. Cambridge: MIT Press.   
Choi, Youngon & John C. Trueswell. 2010. Children’s (in)ability to recover from garden paths in a verb-final language: Evidence for developing control in sentence processing. Journal of Experimental Child Psychology 106(1). 41–61. doi: 10.1016/j.jecp.2010.01.003   
Chomsky, Noam. 1968. Language and mind. New York: Harcourt, Brace, Jovanovich.   
Clackson, Kaili, Claudia Felser & Harald Clahsen. 2011. Children’s processing of reflexives and pronouns in English: Evidence from eye-movements during listening. Journal of Memory and Language 65. 128–144.   
Fisher, Cynthia, Yael Gertner, Rose M. Scott & Sylvia Yuan. 2010. Syntactic bootstrapping. Wiley Interdisciplinary Reviews: Cognitive Science 1(2). 143–149.   
Dowty, David. 1979. Word meaning and Montague grammar. Dordrecht: Reidel.   
Kidd, Evan, Andrew J. Stewart & Ludovica Serratrice. 2011. Children do not overcome lexical biases where adults do: The role of the referential scene in garden-path recovery. Journal of Child Language, 38. 222–234.   
Ferreira, Fernanda, Vittoria Ferraro & Karl G.D. Bailey. 2002. Good-enough representations in language comprehension. Current Directions in Psychological Science 11. 11–15.   
Fisher, Cynthia. 1996. Structural limits on verb mapping: The role of analogy in children’s interpretations of sentences. Cognitive Psychology 31. 41–81.   
Fodor, Jerry A., Thomas Bever & Merill Garrett. 1967. Language structure and verbal behavior. unpublished manuscript. Cambridge, MA: MIT Press.   
Frank, Stefan L., Rens Bod & Morten H. Christiansen. 2012. How hierarchical is language use? Proceedings of the Royal Society B: Biological Sciences 279. 4522–4531.   
Frazier, Lyn & Giovanni B. Flores D’Arcais. 1989. Filler driven parsing: A study of gap filling in Dutch. Journal of Memory and Language 28(3). 331–344.   
Frazier, Lyn & Janet D. Fodor. 1978. The sausage machine: A new two-stage parsing model. Cognition 6, 229–247.   
Frazier, Lyn & Keith Rayner. 1982. Making and correcting errors during sentence comprehension: Eye movements in the analysis of structurally ambiguous sentences. Cognitive Psychology 14. 178–210.   
Gagliardi, Annie, Tara Mease & Jeffrey Lidz. 2016. Discontinuous development in the acquisition of filler-gap dependencies: Evidence from 15- and 20-month-olds. Language Acquisition 23(3). 1–27.   
Gertner, Yael & Cynthia Fisher. 2012. Predicted errors in children’s early sentence comprehension. Cognition 124(1). 85–94.   
Gertner, Yael, Cynthia Fisher & Julie Eisengart. 2006. Learning words and rules: Abstract knowledge of word order in early sentence comprehension. Psychological science 17(8). 684–691.   
Gleitman, Lila R. 1990. The structural sources of verb meanings. Language Acquisition 1(1). 3–55.   
Gordon, Peter & Jill Chafetz. 1990. Verb-based versus class-based accounts of actionality effects in children’s comprehension of passives. Cognition 36(3). 227–254.   
Grimshaw, Jane. 1990. Argument structure. Cambridge, MA: MIT Press.   
Hirzel, Mina R., Laurel Perkins & Jeffrey Lidz. 2020. 19-month-olds parse wh-quetsions incrementally. Paper presented at 45th Boston University Conference on Language Development, Boston.   
Huang, Yi Ting, Kathryn Leech & Meredith L. Rowe. 2017. Exploring socioeconomic differences in syntactic development through the lens of real-time processing. Cognition 159. 61–75.   
Huang, Yi Ting & Zoe Ovans. 2021. Who “it” is influences what “it” does: Discourse effects on children’s syntactic parsing. Cognitive Science 46. e13076.   
Jackendoff, Ray. 1983. Semantics and cognition. Cambridge, MA: MIT Press.   
Novick, Jared, Sharon Thompson-Schill & John C. Trueswell. 2005. Cognitive control and parsing: Reexamining the role of Broca’s area in sentence comprehension. Cognitive, Affective & Behavioral Neuroscience 5. 263–281.   
Lidz, Jeffrey, Henry Gleitman & Lila R. Gleitman. 2003. “Understanding how input matters: The footprint of universal grammar on verb learning,” Cognition 87. 151–178   
Lassota, Romy, Akira Omaki & Julie Franck. 2016. Developmental changes in misinterpretation of garden-path wh-questions in French. Quarterly Journal of Experimental Psychology 69. 829–854.   
Lew-Williams, Casey & Anne Fernald. 2007. Young children learning Spanish make rapid use of grammatical gender in spoken word recognition. Psychological Science 18. 193–198.   
Lidz, Jeffrey, Aaron Steven White & Rebecca Baier. 2017. The role of incremental parsing in syntactically conditioned word learning. Cognitive Psychology 97. 62–78.   
Love, Tracy. 2007. The processing of non-canonically ordered constituents in long-distance dependencies by pre-school children: A real-time investigation. Journal of Psycholinguistic Research 36. 191–206.   
MacDonald, Maryellen C., Neal J. Pearlmutter & Mark S. Seidenberg. 1994. The lexical nature of syntactic ambiguity resolution. Psychological Review 101(4). 676–703.   
Mani, Nivedita & Falk Huettig. 2012. Prediction during language processing is a piece of cake – but only for skilled producers. Journal of Experimental Psychology, Human Perception and Performance 38. 843–847.   
Maye, J., Janet F. Werker & LouAnn Gerken. 2002. Infant sensitivity to distributional information can affect phonetic discrimination. Cognition 82(3). B101–B111.   
Mehler, Jacques. 1963. Some effects of grammatical transformations on the recall of English sentences. Journal of Verbal Learning and Verbal Behavior 2. 346–351.   
Mehler, Jacques & Peter Carey. 1967. The role of surface and base structure in the perception of sentences. Journal of Verbal Learning and Verbal Behavior 6. 335–338.   
Miller, George A. Noam homsky. 1963. Finitary models of language users. in D. Luce (ed.), Handbook of mathematical psychology. New York: John Wiley & Sons.   
Naigles, Letitia R. 1990. Children use syntax to learn verb meanings. Journal of Child Language 17(2). 357–374.   
Noble, Claire H., Caroline F. Rowland & Julian M. Pine. 2011. Comprehension of argument structure and semantic roles: Evidence from English-learning children and the forced-choice pointing paradigm. Cognitive Science 35(5). 963–982.   
Omaki, Akira, Imogen Davidson-White, Takuya Goro, Jeffrey Lidz & Colin Phillips. 2014. No fear of commitment: Children’s incremental interpretation in English and Japanese wh-questions. Language Learning and Development 10. 206–233.   
Perkins, Laurel. 2019. How Grammars Grow: Argument structure and the acquisition of non-basic syntax. PhD Dissertation, University of Maryland.   
Perkins, Laurel & Jeffrey Lidz. 2020. Filler-gap dependency comprehension at 15-months: The role of vocabulary. Language Acquisition 27. 98–115.   
Perkins, Laurel & Jeffrey Lidz. 2021. Eighteen-month-old infants represent nonlocal syntactic dependencies. Proceedings of the National Academy of Sciences 118(41). e2026469118 .   
Perkins, Laurel, Tyler Z. Knowlton, Alexander Williams & Jeffrey Lidz. 2022. Structure vs. content in syntactic bootstrapping. Article under review.   
Phillips, Colin. 1996. Order and structure PhD dissertation, Massachusetts Institute of Technology.   
Pinker, Steven. 1984. Language learnability and language development. Cambridge, MA: Harvard University Press.   
Pozzan, Lucia, Lila R. Gleitman & John C. Trueswell. 2015. Semantic ambiguity and syntactic bootstrapping: The case of conjoined-subject intransitive sentences. Language Learning and Development 12(1). 14–41.   
Rabagliati, Hugh, Liina Pylkkanen & Gary Marcus. 2013. Top-down influence in young children’s linguistic ambiguity resolution. Developmental Psychology 49. 1076–1089.   
Rushen, Shi, Janet F. Werker, & Anne Cutler. 2006. Recognition and representation of function words in englishlearning infants. Infancy 10(2). 187–198.   
Sherman, Brynn & Nicholas B. Turk-Browne. 2020. Statitical prediction of the future impairs episodic encoding of the present. Proceedings of the National Academy of Sciences 117(37). 22760–22770.   
Slobin, Dan I. 1966. Grammatical transformations and sentence comprehension in childhood and adulthood. Journal of Verbal Memory and Verbal Behavior 5. 219–227.   
Steedman, Mark 2000. The syntactic process. Cambridge, MA: MIT Press.   
Syrett, Kristen & Jeffrey Lidz. 2011. Competence, performance and the locality of quantifier raising: Evidence from 4-year-old children. Linguistic Inquiry 42. 305–337.   
Thothathiri, Malathi & Jesse Snedeker. 2008. Syntactic priming during language comprehension in three- and four-yearold children. Journal of Memory and Language 47. 69–90.   
Trueswell, John C., Daniel Kaufman, Alon Hafri & Jeffrey Lidz. 2012. Development of parsing abilities interacts with grammar learning: Evidence from Tagalog and Kannada. Proceedings of BUCLD 36. 620–632.   
Trueswell, John C., Irina Sekerina, Nicole M. Hill, Marian L. Logrip. 1999. The kindergarten-path effect: Studying online sentence processing in young children. Cognition 73(2). 89–134. doi: 10.1016/S0010-0277(99)00032-3   
Trueswell, John C., Michael K. Tanenhaus & Susan M. Garnsey. 1994. Semantic influences on parsing: Use of thematic role information in syntactic ambiguity resolution. Journal of Memory and Language 33(3). 285–318.   
Trueswell, John C., Michael K. Tanenhaus, & Christopher Kello. 1993. Verb-specific constraints in sentence processing: separating effects of lexical preference from garden-paths. Journal of Experimental psychology: Learning, Memory, and Cognition 19(3). 528.   
Wagers, Matthew W., & Colin Phillips. 2009. Multiple dependencies and the role of the grammar in real-time comprehension. Journal of Linguistics 45(2). 395–433.   
Walker, Edward, Paul Gough & Robert Wall. 1968. Grammatical relations and the search of sentences in immediate memory. Presentation at the annual meeting of the Midwestern Psychological Association.   
White, Aaron Steven & Jeffrey Lidz. 2021. Lexicalization in the developing parser. Glossa: Psycholinguistics 1(1). doi: 10. 5070/G601148   
Williams, Alexander. 2015. Arguments in syntax and semantics. Cambridge: Cambridge University Press.   
Yuan, Sylvia & Cynthia Fisher. 2009. Really? She blocked the baby?: Two-year-olds learn combinatorial facts about verbs by listening. Psychological Science 20(5). 619–626.   
Yuan, Sylvia, Cynthia Fisher & Jesse Snedeker. 2012. Counting the nouns: Simple structural cues to verb meaning. Child Development 83(4). 1382–1399.