# Examining teacher's evaluative language in written, audio and screencast feedback on EFL learners' writing from the appraisal framework: A linguistic perspective

Murad Abdu Saeed a,\*,1, Atef AbuSa'aleekb, Mohammed Abdullah Alharbi c,2

a Department of English, Faculty of Languages & Linguistics, University of Malaya, Malaysia b Department of English, College of Education, Majmaah University, Majmaah, Saudi Arabia. c Department of English, College of Education, Majmaah University, Majmaah, Saudi Arabia

# ARTICLEINFO

# ABSTRACT

Keywords:   
E-feedback   
Mode   
EFL writing   
Text revisions   
Writing improvement

Technology facilitates teacher corrective feedback on students' writing, but there is a need to examine how written, audio and screencast modes affect teacher's evaluative language of electronic (e-) feedback from linguistic approaches. By using the engagement resources of the appraisal framework within Systemic Functional Linguistics, this study examined the effect of written, audio and screencast modes on the instructor's evaluative language in his e-feedback on writing and the text revisions of 15 pairs of Saudi EFL learners. The linguistic analysis of the efeedback revealed that the instructor's engagement resources differed across the three e-feedback modes. Specifically, the screencast and audio e-feedback modes were dominated by expanding resources (resources expanding the space for dialogue) as opposed to the prevalence of contracting resources (resources limiting/shutting down the space for dialogue) in the written feedback mode. Moreover, the audio and screencast feedback modes contained more statements and suggestions whereas the written feedback mode was dominated by commands/orders and suggested corrections. The content analysis revealed that the screencast e-feedback mode addressed a higher number of global issues in writing; however, the audio and written e-feedback modes addressed a higher number of local issues in writing. Despite the higher overall rate of successful text revisions resulting from the screencast and audio e-feedback modes, no significant differences were found except in relation to students' global text revisions. The study offers useful pedagogical implications for instructors in effectively responding to students' writing.

# 1. Introduction

Teacher correctie feedback on students writing is defined as evaluative and corrective information provided by teachers on students' strengths and weaknesss in writing (AbuSeileek, 2013; Bahari, 2021; Chong, 2019). It enables students to know ther strengths, notice their weaknesses and improve their writing accordingly (Zheng, Zhong, Yu, & Li, 2020). Despite the importance ot teacher feedback on writing, writig teachers may find it challenging to give students efective feedback (Cavanaugh & Song, 2014;

Ryan, Henderson, & Phillips, 2019). Although teachers' feedback in oral face-to-face (FTF) and handwriten comments on students paper-based writing are recognized to be effctive modes of feedback for English as second/foreign language (ESL/EFL) learners, teachers may find such feedack modes challenging, laborious and time-consuming especiall in writing clases with a large number of students (Cavanaugh & Song, 2014; Hung, 2016; Ryan et al., 2019). Moreover, oral TF feedback may not be understood by some students due to their limited proficiency in English (Bush, 2020). Therefore, teachers have multipl options to give students electronc (e-) feedback on their anguage lening in gneral (Mathieson, 2012; Teng & Yeh, 2019) and in particular, on writing courses (Chang, Kelly, Satar, & Strobl, 2017). E-fedback is defined as edback provided by teachers to students online using educational technology (Ene & Upton, 2014). It can be provided in a writen mode via text Microsoft word comments, Google Docs comments or Blackboard forum comment, in an audio mode through voice record or in a screencast mode through screencast capture technology (Chang et al. 2017; Ene & Upton, 2014; Godwin-Jones, 2018; Soden, 2016). Yet, responding to students' writing through e-written comments may appear a daunting task for teachers and it may hinder them from providing elaborative and detailed feedback on students' writing (Ryan et al., 2019).

Due to the above-mentioned challenges, writing teachers and intructors are highly recommended to use audio/voice record and screencast (a capture technology that combines both auditory and visual elements) in reponding to writing (Ryan et al., 2019). Unlike webcam or video displaying the teacher as a talking head', screencast technology captures students' writen texts and teacher's oral/voice comments on writing (Bush, 2021). Although this later e-feedback has been increasingly described in the iterature as multimodal fedback which combines both verbal (voice/audio) and non-verbal/visual elements (Chang et al., 2017; Thomas, West, & Borup, 2017), teachers should choose the modes that facilitate theire-feedack on writin (Cunningham, 2019; lola & Oskoz, 2016). Recent research comparing e-written and audio feedack modes (Cavanaugh & Song, 2014; Chalmers MacCallum, Mowat, & Fulton, 2014) and writen and screencast modes (Cunningham, 2019a; Elola & Oskoz, 2016) has shown that screencast technology enables teachers to respond to students' writing elaborately whilst simultaneously highlighting the specific parts of students written texts using visual clues such as a mouse cursor (Bush, 2021). Some studies have described e-screencast feedback as conversational despite the lack of indicators of its conversational nature from actual screencast data (Bush, 2021; Edwards, Dujardin, & Williams, 2012; Mahoney, Macfarlane, & Ajjawi, 2019) In order to examine the influence of writen, audio and screencast modes on the evaluative language (the inguistic choices or resources used by tachers) in formulating their e-feedback n student writig, studies need to use linguisti frameworks such as Martin's and White's (2005) appraisal framework in analyzing teachers feedack (Cunningham, 2019a; Hung, 2016). This framework, which was developed within Systemic Functional Linguistics (SFL) (Hllday & Mathiesen, 2014), can move feedback research from a traditional content analysis to a fine-grained inguistic analysis of feedack that focuses on the linguistic choices in teachers evaluative languag f fdback (Bastola & Hu, 2021; Cunningham, 2019). Yet, ittl is known about ow teachers' evaluative language of feedback i shaped by different modes (Bastola & Hu, 2021; Cunningham, 2019a; Gardner, 2004)

Although studies suggest that teachers' evaluative language can affect students' use of feedback in revising and enhancing writing (Bastola & Hu, 2021; Cunningham, 2019a; Gardner, 2004; Hyland & Hyland, 201; Shrestha, 2022), no study has examined this topic especially when researching teachers'-fdback in different modes. Teacher's-fedack on writing may become fruitles if learners do not use it effctively in improving their writing (Alharbi, 2022). In other words, will students sucesfully use the feedback information in enhancing their writing? And which feedback mode willbe more effective in enhancing their writing? These important questions need to be addressed by investigating students' uptake of teacher feedack, which is known as the extent to which learners successflly use fdack in revising their writen texts. Successful uptake is an important indicator of thefectiveness of teacher's feedback on writing (Ene & Upton, 2014, 2018) and in particular, e-feedback modes (Bakla, 2020; Cunningham, 2019b). Investigation of student uptake of e-fedback is necessary for understanding the affordances and limitations of each e-feedback mode in teacher corrective feedback on writig (Bakla, 2020; Chang et al., 2017; Cunningham, 2019a, 2019b, Ryan, Henderson, & Phillips, 2016; Silva 2012). Despite recent investigations f tudents uptake of teacher e-feback provided through writte, audio and screencast modes. the findings remain inconclusive (Bakla, 2020; Cunningham, 2019b; Elola & Oskoz, 2016). Therefore, based on the above ssues, the present study attempted to address the following specific research questions:

1. How do the written, audio and screencast modes afect the teacher's evaluative language in responding to EFL students writing?   
2. How do he writen, ao and scst modes ffet th xto whch techr's e-feack addres differen suesrrors n students' writing?   
3. Are there statistically significant differences in students uptake of the e-fedack provided through written, audio and screencast modes in revising their texts?

# 2. Literature review

# 2.1. The appraisal framework as a feedback analytical tool

Since most of the existing frameworks for fedback are concerned with a content analysis and of the written feedback mode (e.g, Elola & Oskoz, 2016), a few recent studies have adopted a inguisic framework that can advance our understanding of the evaluatie language of teachers' feedback in different modes (e.g., Cunningham, 2017, 2019a). These studies used a linguistc framework grounded within SFL (Halliday and Mahiesen, 2014), which is known as the appraisalframework (Martin & White, 2005; White, 2015). The framework focuses on the evaluative language or the linguistic choices and resources employed by teachers in making meanings, establishing interpersonal relationships and managing relational positioning when giving feedback to students (Bastola & Hu, 2021; Cunningham, 2017, 2019a; Gardner, 2004; Martin & White, 2005; Shrestha, 2022; White, 2015).

The framework consists of three main dimensions: (1) attitude (evaluators feelings, behaviors, etc), (2) engagement (linguistic resources enabling evaluators to take value positions and inroduce other voices and perspectives) and (3) gradation concerned with the gradability of meanings conveyed by evaluators through language) (Martin & White, 2005). However, due to the space limitation, the linguistic analysis of the e-feedack modes in the preset study was exclusive to explicit engagement resources within the appraisal framework, specifically the heteroglossic engagement resources as shown in Fig. 1.

The appraisal framework provides useful insights into teachers' heteroglossic engagement resources as linguistic resources that help evaluators/feedback providers either expand or contract the space for dialog. Expanding resources expand the space for students to have control over their texts, express their perspectives and make their own decisions on what and how to revise their own texts (Cunningham, 2017, 2019a; Marti & White, 2005; Shrestha, 202 Starfield et al., 2015; White, 2015). These expanding resources are of two sub-categories: entertains and atributes. Expanding entertains are these resources that usually leave opportunities for text authors/students to expres their voices and opinions and take a stance. They can be manifested in these linguistic choices: modal verbs (e.g, can, could, y, ght, e as wl asidial markrs , sm parely, sugs, ) d istec ver  pobaly, possibly, ikel, etc) (Martin & White, 2005). Expanding attributes are these resources that provide a neutral report of another and can serve as t acknowledge g, use of rorting vers such as say, reort stte, dee, anounce, believe and think) and r to istancethe authorial voice from the atributed material (e,g,to claim and by certain uses of scare quotes Martin & White, 2005). In the feedack context, feedback provided in the form of suggestions using lower modals such as could or might is an example of entertains and feedback employing verbs such as said, stated and mentioned as a reference to the student's text is an example of atributes

![](img/81097ce0e3387424c2a48045def17535022351845faa6aff7ad119da9280b80d.jpg)  
Fig. 1. The engagement resources within the appraisal framework (Martin & White, 2005, p.134).

# (Cunningham, 2017, 2019a).

On the other hand, contracting resources contract and shut down the space for students to express their own voices and make decisions on their revisions (Cunningham, 2017, 2019a; Shrestha, 2022; Starfield et al., 2015). They are further clustered into two sub-types: proclaims and disclaims. Contracting isclams are these resources by which some dialogic alternative is directly rejected, supplanted, r i represented as not applying" (Marti & White, 2005, p.117). They areused to reect (e.g., use of negations such asno, not, never, nothing, etc) and or to counter (e.g, use of conjunctions and connectives such as but, however, yet, though, although, depite and even though as well as use of comment adjuncts/adverbials such as surprisngly, only, just, even and till thealternative positive position into the dialog (Martin & White, 2005). Contracting proclaims are these resources by which \*some dialogic altenatives are confronted, challenged, overwhelmed or otherwise excluded (Martin & White 205 p.117-118). They are used to concur (e.g., use of locution shs se, f ore, n isigy, nl, ery  t,  ded,  tr f ft nend the truth is that, etc) and or endorse (e.g., use of verbs such as find, prove, demonstrate, show and point out) the altenative postion. In brief, contracting disclaims serve as mechanisms to directly reject the alternative position whereas contracting proclaims serve as mechanisms to limit the cope of dialogistic alternatives (Martin & White, 2005). For example, in the context of feedback, contracting resources are realized through teachers use of direct evaluations, direct statements, direct commands and or error corrections (Cunningham, 2017, 2019a; Martin & White, 2005; White, 2015).

Since this framework is applicable to teachers evaluative language in both written (e.g., Smith, J.,  Adendorf, 2014; Bastola & Hu, 2021; Gardner, 2004; Liu & Jiang, 2023; Macken-Horarik, 2003; Martin, 2004; Martin, 2007; Pounds, 2011; Shrestha, 2022; White, 2015) and spoken mode (., Caldwell, 209; Ferguson, 2010; Gadner, 2004), it ffers interesting insights into the ealuative language used in different e-feedback modes (Cunningham, 2017, 2019a).

# 2.2. Studies on the evaluative language of feedback modes from linguistic perspectives

Several studies have focused on corrective feedback from linguistic perspectives (Bastola & Hu, 2021; Hyland & Hyland, 2001; Liu & Jiang, 2023; Shrestha, 2022; Starfield et al., 2015; Starfield et al., 2017). Some of these studies have focused on theattitude system within the appraisal framework, which is not the scope of the present study (Bastola & Hu, 2021; Liu & Jiang, 2023; Shrestha, 2022; Starfield et al., 2015, 2017). What is relevant to this study is the use of modality varied among PhD thesis examiners from high (e., must & need to) to median (e.g., should) and low (e.g., may, might, can & could). Whereas high modality vers leave littl room for negotiations, low modality verbs alow more room for negotiations (Starfield et al., 2015, Starfield et al., 2017). In Hyland's and Hyland's (2001) study, the two teachers employed hedges to soften their criticisms and suggestions and minimize the threat of their critical udgment f students writing. The authors concluded that social relationships are important in constructing effctive feedback

In addition, al the above studies on the evaluative languag from a linguistic perspective have focused on the written mode except for Bastola's and Hu's (2021) study focusing on oral and writen modes. Yet, this study examined the atitudinal stances but not the engagement reources in supervisors feedback. Teachers linguistc onstructio of fdack in different modes is an interesting topic for the current feedback research trend. In this regard, Gardner (2004) examined the evaluative language of taped oral and written feedback provided by two tutors on research methodology papers. The tutors used a greater range of strategies such as giving explicit detailed suggestions or advice, indicating the reader's reaction, praising, indicating the significance and expressing expectations of improvement when giving feedback in the taped-oral mode compare to the written mode. Moreover, the taped-oral feedback tended to be elaborative, more intricat, and les lexically dense than the writte fedack. Wheras the tutors ssered their authority and distanced the students by using high obligations such as commands and high modality verbs such as \*must, they used a mixture of high, median and low obligations in the taped-oral feedback mode.

Moving to the e-feedback modes, due to the increasing advancement of educational technologies that support fedback-giving, it is becoming easier for teachers to diversfy the way they provide e-fdback on students assignments in general (e., Mathieson, 2012; Tseng & Yeh, 2019) in particular, on writing (e.g., Chang et al., 2017; Cunningham, 2019a, 2019b; Elola & Oskoz, 2016; God win-Jones, 2018). They can provide writtene-eedback using inserted comments of Google Docs and chat messages, audio e-feedback using audio mesaes and mobile records and screencast e-fedack using screencast capture technology (Alharbi, 2022; unningham 2019a, 2019b; Elola & OSskoz, 2016; Filius, de Kleijn, Uil, Prins, van Rijen, & Grobbee, 2019). Some studies provided evidence on the influence of these modes on the evaluative language in teachers e-fedback (Cunningham, 2019b; Elola & Oskoz, 2016).Starting with studies on writen and audio modes, some studies have looked at the discourse/pragmatic features of e-feedback (e.g., Cavanaugh & Song, 2014; Chalmers et al., 2014; Nemec & Dintzner, 2016). Results indicate that teacher's audio e-feedback contained a higher number of discourse functions (eg, suggestions, questions, evaluation, ec) than the written e-feedack except for the e-feedback serving as direct corrctions (Chalmers e al., 2014 Nemec & Dintner, 2016). Moreover, audio and screencast e-feedback tended to e more elaborative than the written e-feedback (Chalmers et al., 2014; Cunningham, 2019a; Hennessy & Forrster, 2014; Nemec & Dintzner, 2016).

Some studies have compared teachers' written and screencast e-feedback modes. For instance, Elola and Oskoz (2016) reported no clear differences between the two modes in the linguistic features of e-feedback as both modes contained e-feedback functioning as suggestions, clarifications, statements, praises and commands. Yet, the findings of these studies on e-feedback modes were obtained through a content analysis of the e-feedback rather than a more rigorous linguistic framework that captures detaled differences in relation to teachers' evaluative language of e-feedack. Interestingly, two other studies (Cunningham, 2017, 2019a) have analyzed teachers evaluative language in written and screencast e-feedback modes from a linguistic perspective by using the appraisal framework. While Cunningham (2017) focused on the attitude language of -feedback within the appraisal framework, Cunningham (2019a) focused on the engagement resources of e-feedback within the appraisal framework. Cunningham (2017) reported that teachers screencast e-feedback contained a higher proportion of positive appreciation and a lower proportion of negative evaluations of students texs. The researcher attributed this finding to the mode used by the teachers in responding to writing. I other words, the teachers seemed more comfortable with the screencas technology for providing e-fedback and therefore, they employed more linguistic resources that established tex-reader back-channelig. However, due to the limited visual space in the written e-feedback mode, the teachers seemed to prioritize composing critical or negative comments on students' writing. According to Cunningham (2019a), the mode was found to inluence the evaluative language i e-feedback. Specifically, the screencast e-feedback inguisically consisted of more expanding resources such as advice, suggestions, casting future changes and praises, which positioned the teachers as collaborator and mitigated the neatie aspects of their e-fedack. On the othr hand, most of the writtene-fedack lingisically consisted of contracting resources that postioned the teachers as the authority and projected the critical aspect of theire-feedback.

# 2.3. Studies on the content of e-feedback modes

Studies have also examined the content of e-feedback modes in order to find the aspects of writing addressed by teachers when providing e-feedback in different modes. For instance, Elola and Oskoz (2016) found that the screencast e-feedback mode contained detailed feedback on global aspects of text: content, structure and organization, whereas the written e-fedback mode ffered explicit feedback on local aspects, such as form or grammar. Moreover, Cavanaugh's and Song's (2014) study compared audio and written e-feedback modes and revealed that the audio feedack addressed more global issues whereas the written e-fedback addressed more local issues in students assignment. Although Alharbi's (2022) study analyzed the content of teacher's feedback into global and local in four modes: oral, written, audio and screencast modes, this analysis was performed for the purpose of examining students uptake of global and local feedback in the four modes. Nevertheles, t can be inferred from the numbers of gloal and local feedback identified in the four modes that the oral and screencast feedback modes addressed more global ssues in writing than the audio and written feedback modes. However, the oral and audio feedback modes addressd more local issues in writing than the screencast and written feedback modes.

Results of previous research also support the superiority of audio and screencast e-feedback modes in giving more elaborate (Cunningham, 2019a, 2019b; Hennessy & Forrester, 2014), supportive (Ryan et al., 2016), personalized (Edwards et al., 2012; Ryan et al., 2019) and converational fedback (Bush, 2020; Edwards et al., 2012; Orlando, 2016). Yet, these studies excet Cunningham's (2019a, 2019b) did not provide any evidence on the superiority of audio and screencast e-feedback modes from actual feedack data but rather the reults werelicited by means of interviews and surveys from students mee persectives as fback receiver. Another gap in previous research on e-feedback modes is that only few studies have examined e-feedback in thre different modes (Alharbi, 2022; Bakla, 2020; Orlando, 2016; Ryan et al., 2019). Yet, two of these studies have explored this topic from students' uptake of e-feedback and persective (Orlando, 2016; Ryan et al, 2019) and one study has examined theffect of-fedback in the three modes on students' writing performance and perception (Bakla, 2020). Although Alharbi's (2022) study included teacher's actual feedback data, it was limited to analys of the pragmatic functions (e.g, suggestions and questions) acrossthe three modes or the purpose of determining whether these pragmatic features of teacher's feedback would affect students' uptake of feedback.

# 2.4. The effect of e-feedback modes on students' writing improvement

Since students successul uptake f teachers fedback is recognzed as a partial indicatio of the efficiency of teacher fedback, its investigation continues to be important in feedback reearch. Reent rearch, therefore, has looked at the effc f -fedback modes on students' uptake of feedback. For instance, Ozkul and Ortactepe (2017), the screencast e-feedback mode was more effective than the writtene-feedback mode in resulting into ahigher number of students subsequent tex rvisions. In contrast, Cunningham (2019) found that bothscreencast and writtene-edback modes were equall effctive in promoting students' sucessul micro-level/local text revisions. Yet, the screencas e-feedback mode led to more successful global textrevisions than the written e-feedack. Moreover, Elola and Oskoz (2016) reported that students sucessully revised their texts at the global level regardes of the written and screencast e-feedback modes.

In addition, Bakla (2020) found that teacher's written and audio e-feedback modes resulted into more local tex revisions than the screencas -fedback mode. However, these differences were found non-significant, which suggets that none f the thre e-feedback modes is more eficient than the others in promoting students global text revisions. On the other hand, Alharbi (2022) revealed that While the highest rate of stdents seessul uptake f edback was associated with teacher's screencast and audio e-fedack modes, the lowest rate of successful uptake was related to teacher's written e-feedback mode.

In conclusio all the above studies on teachers e-feedback modes and it effect on students writig focused on feedback provided on students texts written individually except Alharbi's(2022) study that focused on feedback provided on texts written collaboratively or in pairs. The current study also focused on teacher's e-feback modes on collaborative writing as per support enables students to better understand teachers' e-feedback and consequently, revise their texts efectively (Alharbi, 2022 Storch, 2021). Moreover although the above studies on the efect of e-feedback modes on students text revisions have been conducted on different ESL and EL contexts using different methods varying from qualitatie (e.., Cunningham, 2019a) to quantitative (.., Chalmers t l., 2014; Cunningham, 2017, 2019b) and mixed methods (Bakla, 2020), most of these studies serve s a go0d reference for the method of the current study, incudig the study proedure, data collection and analys of the manner and content e-feedback and it effect on students' writing improvement.

# 3. The study

# 3.1. Study design

The study used a purposeful sampling technique that suits selection of this writing course as an information-rich case for study in depth. It was conducted in an undergraduate writing course over an academic semester of the academic year of 2020 in a Saudi university. Due to universty segregation of males and females in the study context, the writing course, as a typical malecourse of the Saudi university context, consisted of a maleassistant professor in English with a four-year experience in EFL universt teaching and whose PhD major was feedback in EFL writing and 30 male students. The students had already taken one semester English language intensive courses and passed the English language intensivetest that determines their oral and written proficiency. Based on their performance in this test, they were admitted to the universty English undergraduate program. The writing course itroduces students to paragraph writing of different genres: descriptive, narratie, process and argumentative. Students joining the course are usually assessed through continuous asessments (writing tasks) in addition to mid-term and final exams. The thre paragraph writing tass on three topics in thesame genre of narrative paragraph writing examined in the current study were graded out of 15 marks as part of students' continuous assessment in the course. While the first drafts were graded, the final drafts were voluntary. So most of these students were highly motivated to improve their writing skills in English through teacher's different e-feedback modes.

# 3.2. The writing tasks and feedback activities

Prior to the start of the peer writing and teacher e-feedback on writing, the instructor informed the students of the writing activities and that only their first drafts would be graded, while their participation in the revisions of their first drafts would be voluntary and were meant to encourage them to notice their errs in writing and for the purpose of research. The students signed a consent on ther participation in the study. Prior to the study procedure, the students were grouped in 15 pairs based on their choice and comfort. Then, these pairs were assigned to numbers (P1-P15).

The students engaged in collaborative writing of three narrative paragraph tass on three diferent topics. The pairs had to choose one topic from the list f topics on narrative writing provided by the teacher and they were fre to write on a topic of their own choice. Table 1 shows he mber of frst drafts and final drafts writen by the students across th thre tass and different feedack modes. In each writing task covering three weeks, each pair of students engaged in three tages: (1) pre-writing (planning or brainstorming), (2) writing the first draft (constructing thir geerated points in sentnces and paragraph forms) and (3) receiving e-fedack on the frst draft and accordingly revising it. During the first two stages, no prompts were used except some instructions and examples (e., instruction on pre-writing outlines and developing thee outines into first drafts. The pairs engaged in the first two stage f writing in the FTF clasroom during the one-hour clss and they collaboratively planned their texts, brainstormed ideas, discusse, wrote their first drafts in papers, scanned them and uploaded them in the Blackboard Forum of the course.

For the third stage, the focus of this study, the instructor read the first drafts at home and responded to these first drafs via efeedack. For the first writing task, the teacher provided audio e-feedback via the mobile recorder. For the second writing task, the teacher provided screencast e-feedack using the laptop's Bandicam recorder which recorded his voice comments and visual activities on students' first drafts displayed in the screen. For the third writing task, the teacher composed his written e-feedback in the form of written comments in the Blackboard Discussion.

Moreover, the audio and screencast record files of e-feedback were shared to the WhatsApp group of the course. Each file was preceded with a written message in the WhatsApp group notifying the pair of sharing the recordto their private WhatsApp group. For the written e-fedback mode, the teacher's written comments on each pair's irt draft in the Blackboard Discussion of the course were accessible to the pairs joining the course. During this third week of each writing task, the pairs were asked to revise their frt drafts based on teacher's e-feedback on writing and submit the final drafts to the course system.

# 3.3. Data collection

The data was collected from two sources: tacher e-feedack in the three ifferent modes and students first and final writtendrafts The audio and screencast rcords were collected earlier during the activities by downloading and saving them immediately in folders according to the numbers f pairs (P1-P15) assigned to students at the start of the writing activities. However, the written feedback data was copied as text comments from the Blackboard Discussion and organized in Microsoft word files accordingly. I adition, the first (N.45) and final drafts (N.45) of the three writing tass were organized into thre separate folders, each folder containing15 first drafts and 15 final drafts with the teacher's e-feedback mode to be compared for analyzing students' text revisions based on the identified e-feedback.

Table 1 The writing tasks and feedback and revision activities.   

<html><body><table><tr><td>Topic</td><td>Number of pairs</td><td>Number of first drafts</td><td>Feedback modes</td><td>Tools for feedback-giving</td><td>Number of final drafts</td></tr><tr><td>Topic 1</td><td>15</td><td>15</td><td>Audio</td><td>WhatsApp</td><td>15</td></tr><tr><td>Topic 2</td><td>15</td><td>15</td><td> Screencast</td><td>Bandicam</td><td>15</td></tr><tr><td>Topic 3</td><td>15</td><td>15</td><td>Written</td><td>Blackboarde</td><td>15</td></tr></table></body></html>

# 3.4. Data analysis

The data analysis was performed in four stages: data preparing, coding, categorizing and category counting. During the preparation stage, the researcher listened to the audio records and watched the screencast records. Afer that, the records were transcribed and checked against the audio and screencast rcords. This made it esier to import the transcripts of the e-feedack modes in the form of plain text file into the UAM corpus tool, which comprises set of tols for linguistictext nnotations, while rerring to the original files for consultation. The UAM corpus tol provides numerous functionalitie which enable reearchersto annotate texts manually and semi-automatically.

# 3.5. Linguistic analysis of the evaluative language in the three e-feedback modes

In addresing the first research question, the second stage was initiated by coding thee-feback data in the thre modes i relation to the engagement resources of the appraisal framework. This coding was based on the operational definitions of the engagement resources categories and sub-categories in previous studies (Cunningham, 2017, 2019a; Martin & White, 2005). Accordingly as shown in Table 2, each main clause in the data was assgned to one and sometimes to two of these labels: expanding entertains, expanding attributes, contracting disclaims and contracting proclaims.

In addition to the engagement resource analysis, the evaluate language in the e-feedack modes was analyzed in relation to its discourse functions. This analysis provides useful insights into the teacher's manner of feedback or his linguistic construction of efeedback across the different modes (Elola & Oskoz, 2016). Based on the definitions of the various discourse functions of teacher e-eedback on writing in previous studie (e.g. Alharbi, 2022; Chalmers et al., 2014; Elola & Oskoz, 2016), each feedback containing a complete and meaningful idea was coded accordingly (e.g., Change this adjective- was coded as an order or a command). Then, these functions were clustered into five main categories (Appendix A).

# 3.6. Analysis of the content of the three e-feedback modes

In addressing the second research question, another round of coding the e-fedback data in relation to its content was performed. For instance, the feedack (e, I suggest you re-writ his sentence clely) was coded as cler ida expresion, while this fback (e. g, Can you add one more sentence to elaborate the previous one?) was coded as an idea elaboration. This coding stage was ended with categorization of the aspects f texts addressed by the teacher's e-feedback modes into global and local aspects. While the global feedback refersto feedback addressing content and idea development, unity and organization,structure and genre, the ocal feedack refers to fedback adressing grammar, vocabulary and mechanics such as spelling and punctuations (Alharbi, 2022; Cunningham, 2019a; Elola & Oskoz, 2016). Examples of teacher's global and local feedback are provided in Appendix B.

# 3.7. Analysis of students' text revisions and writing improvemeni

In order to answer the third research question, students first (15) and final drafts (15) in each writing task were read and compared. Identification of the global and local errors (E) made by students in the first drafts as well as the global and local text revisions (T) in the final drafts began using the codes used above for the content f teacher's fdback. Each E in the irt draft of each pair, which was aso addressed by the instructor's feedback, was labeled accordingly. Simultaneousl, the final draft of the same pair was checked to verify whether this  was corrected by the pair. From this intial text analysis, i was noticed that each E could be either successully revised (SR), or unsuccessfull revised (UR) or not revised at al (NRA). Based on this ientification f students text revisions continued and these revisions were tabulated accordingly using three excel file, each of which was exclusive to the draft of each writig task or teachers feedack mode. This was followed by assigning eachTR to one of these cores: either "1 if the TR was SR, or $" 0 "$ if it was UR and NRA.

Table 2 Sample coded e-feedback in relation to the engagement resources..   

<html><body><table><tr><td>Engagement resources types</td><td> Sup-types</td><td>Feedback examples</td></tr><tr><td rowspan="3">Expanding entertains: Resources expanding the space for an alternative into the dialog</td><td>Evidential: Mitigated, personalized and hedged Suggestions</td><td>You may say this in a better way.</td></tr><tr><td>Questions: Rhetorical and faux questions</td><td>Anything that you can add to elaborate this sentence?</td></tr><tr><td>Directives: Obligations, options and suggestions</td><td>You should finish/change this sentence.</td></tr><tr><td>Expanding attributes: Resources acknowledging and or distancing the authorial voice from the attributed material</td><td>Acknowledge: Neutral reporting Distance: Reporting with the aim of distancing by using</td><td>You mentioned/said/stated that. Not found in the feedback data</td></tr><tr><td>Contacting disclaims: Resources directly rejecting and or countering the positive position into the dialog</td><td>the verb claim Deny/reject: Use of negations and deletions of text</td><td>You cannot use this introductory</td></tr><tr><td></td><td>Counter: Countering a statement through conjunctions and or comment adjuncts/adverbials</td><td>sentence in witting.e Not all over the world but &quot;from. distance&quot;.</td></tr><tr><td>Contacting proclaims: Resources limiting the scope of dialogistic alternatives by concurring, pronouncing and or</td><td>Pronounce: Making pronouncements, direct evaluative statements, direct commands, added emphasis,</td><td>Sure, a great concluding remark. /Change this phrase by *help me to</td></tr><tr><td>endorsing the other position.</td><td>additions of text Concur: Affirming/agreeing with statements/ideas</td><td>keep&quot;. The body has good ideas. This shows that you enjoyed the</td></tr><tr><td></td><td>Endorse: Endorsing ideas/statements in the text</td><td>experience.</td></tr><tr><td></td><td>Justify: Giving reasons</td><td>Change &quot;will&quot; into would because it is in the past..</td></tr></table></body></html>

The researcher and a research asstant had several discussions over a week via the WhatsApp prior to the actual proces of coding during which they discussed the codes prepared earlier. They also exchanged the data transcripts through Google Drive. The research assistant coded almost $1 0 \%$ of the feedback transcripts in each feedback mode for the purpose of inter-rater reliability. Then, the coded data of both was exchanged and compared carefuly. After this those segments of the coded data assigned to similar codes were calculated in order to determine the percentages of agreements. First, the percentages of agreements were $8 9 . 2 \%$ $9 2 . 1 ~ \%$ $9 0 . 7 \%$ and $9 1 . 5 \%$ for coding engagement resources, discourse functions and content of feedback and students' E and TR, respectively. However, after several discussions, the percentages of agreements reached $9 7 \%$ $9 8 . 3 ~ \%$ $9 6 . 5 ~ \%$ and $9 8 . 6 \%$ respectively.

The last stage of data analysis was counting the numbers and percentages of the above categories of engagement resources, discourse functions and content of feedback overal and across the three modes as wellas the errors and text revisions made by the pairs. For students global and local errors and textrevisions, the percentages of the TR-SR that were previously assigned to the score "1" were calculated for each type of E as: $\mathrm { E } \% = \mathrm { N }$ $\mathrm { S R } \times 1 0 0 \div \mathrm { N }$ of E in each mode (See Appendix C). This stage ended by using a oneway analysis of variance (Aov) to compare students text revisions across the thee e-feeback modes. Speificll, the Friedman's k test was used to determine if there are significant differences in students overall text revisions, gloal revisions and local revisions while the Wilcoxon signed-ranks test was performed to see whiche-feedback mode was more efective in relation to students overall text revisions, global revisions and local revisions.

# 4. Findings

The findings are presented according to the three research questions.

# 4.1. The evaluative language in the three e-feedback modes

To answer the first research question, the findings relevant to the engagement resources and discourse functions are presented in these two sub-sections:

# 4.2. Engagement resources in the three e-feedback modes

In this study, the writing instructor used four types of engagement resources in constructing his e-feedback in the three modes: expanding entertains (resources expanding the space for dialogue), expanding atributes (resources acknowledging and or distancing the authorial voice from the atributed material), contracting disclaims (resources directly rejecting and or countering the positive position into the dialog) and contracting proclaims (resources limiting the scope of dialogistic alternatives). Table 3 provides sample feedback on the writing of pair 1 acros the three modes. This example shows that the evaluative language of each feedback mode differed in relation to the teacher's use f engagement resource. The teacher's evaluative language in the audio e-feedback mode was dominated by his use of expanding atriute resources (e.g, you said/mentioned, this fourth sentence, before this phrase, etc). The evaluative language in the screencast e-feedback mode was full of expanding entertain resources including the use of mitigated suggestions (e.g., this idea can be elaborated & they could be moved up) and questions (e.g., I could easily shopping? Or easily shop?)

Table 3 Sample feedback showing teacher's use of engagement resources across the three modes.   

<html><body><table><tr><td>Audio feedback</td><td>Screencast feedback</td><td>Written feedback</td></tr><tr><td>A missing verb before the phrase &quot;by him&quot;.. You may use this phrase: &quot;was attributed to him&quot; instead of &quot;by him&quot;. Are you sure about the structure of this fourth sentence? Is it appropriate to use &quot;comfortable&quot; in this fifth sentence? Change this adjective. Why countries? Can you revise the structure of the fifth sentence? What&#x27;s missing here before the phrase good friend?. You said it was enjoyable in this sentence. Yet, the sentence following it says something opposite. In this sentence, you mentioned these tiny details. Are they relevant? You can add two sentences to the conclusion of your paragraph: one about your feeling and one sentence about the lesson learnt.</td><td>The introductory sentence is great. You may re-phrase your topic sentence by including the phrase &quot;an exciting day&quot;. I could easily shopping? Or easily shop? Or easily do shopping? You should say *the city night life was full of fun&quot;. This idea can be elaborated to understand. your reaction to the situation. How can you connect the fifth and sixth sentences? The two sentences after this are good but they could be moved up. You probably wanted to talk about your reaction here. must mention the lesson learnt.</td><td>You cannot say *we are going to talk about&#x27; in writing. Be careful. This is not an effective the topic sentence. Re-write it. Change &quot;can&#x27; into could because you are narrating a story. What does this phrase after crying mean? Not clear I did not get this sentence. Revise it. You need to add &quot;the&quot; before growing up&quot;. This idea is good, but you need to elaborate it. The concluding sentence is good but you</td></tr></table></body></html>

Italic $=$ entertains; Underlined italic $=$ attributes; Bold $=$ disclaims; Bold underlined = proclaims.

On the other hand, the evaluative language in the written e-feedback mode was characterized by the prevalent use of contracting disclaim resource (e., negations such as no/not & conjunctions such as but, yet, etc) as well s contracting proclaim resources (e., direct negative evaluations and unhedged commands). Moreover, while the screencast e-feedback contained hedged directives as demonstrated by the teacher's use of modal verbs (e.g., can, may, should and could), the e-written feedback contained unhedged commands (eg, change, be, revise & re-write). This suggests that whereas the evaluative language in both audio and screencast efeedback modes seemed to expand the space for dialogue, it appeared to shut down this space for dialogue in the written e-feedback mode.

In calculating the frequency of occurrence of these four engagement resources, Table 4 shows that the instructor more prevalently used expanding entertain resources in his evaluative language of the screencast e-feedback mode (N. $5 0 3 / 2 1 \% )$ I, whereas his evaluative language in the audio feedback mode was dominated by the use of expanding attribute resources (I $\Vdash . 3 6 0 / 1 5 \%$ . The prevalent use of theseattribute, such as referencing language (e.g.This second sentence states/talks about") in the audio fdback mode could be used as an alteative to the lacking visul aids by which the instrctor attempted to direc students atention to specific part of the written tex. On the other hand, visualization of the screencast e-feedback mode semed to play a role i lowering the instructor's use of attributes in responding to students' writing.

Secondly, the teacher's e-fedback mode tended to be dominated by more contracting resources, specifically with a prevalent use of disclaim resources $( 1 7 \% )$ . This includes the use of more negative statements such as "This is not clear" and sentences carrying contradicting words such as "but, however, although and though" in providing written e-feedback on students' writing.

# 4.3. Discourse functions of the three e-feedback modes

Our second round of the e-feedback data analysis identified five categories of the discourse functions of the teacher e-feedback across the three modes. Table 5 shows varying distriutions of these discourse unctions as the creencast and audio modes contained a higher number of discourse functions than the written mode. This could be due to the easiness involved in producing the feedback through speaking in the audio and screencast modes where the teacher seemed to easily and quickly shft from one function (e.g., command) to other functions (.g, question and suggestion) in addressing one issue in writing. On contrary, this shif of functions of feedack in addresig one issue might be time-consuming in the written mode so he mostly addressed each issue via a short-written comment often carrying one function.

Moreover, there is a striking contrast in the use of discourse functions across the three modes. While combined comments (e.g, question $^ +$ suggestion $^ +$ statement), statements and suggestions made up most of the engagement resources in the screencast and audio modes, combined comments (error identification $^ +$ correction), commands and suggested corrections made up most of the engagement resources in the witten mode. Hedged suggestions (e.g.,"You can/could/may change this") contrast unhedged commands (e.g., "Change this"). Similarly, combined comments provide explanations, clarifications and evaluations whereas sugested corrections are desired changes imposed by the instructor on student' writing. Thus, it appears that the screencast and audio modes con. tained feedback that mostly directed students through sugestions in revising their writing. On the other hand, the written mode contained feedback that mostly dictated students what to do and imposed on them certain changes to be made to their writing.

From the above results, responding to writing in the form of questioning is exceptional because it was identified in the three modes and there are no much difference i the numbers and percentages of this category I seems that the yes/no and wh-questions asked by the instructor in the three modes were intended to engage students i revising their writing through seeking clarifications (e.g., What do you mean by this?), requesting (Can you replace this word), confirmation checks (e.g., Do you know the hook?), certainty checks (e. 8., Are you sure about this?) and seeking correct responses (e.g., come or comes?).

# 4.4. Issues/errors addressed by the teacher e-feedback in the three modes

In addressing the second research question, the analysi of the feedback content revealed the extent to which the global and local issues were addressd in the threee-feack modes differed. able6 shows that the tehr addresed more ssues via the scrncast feedback $( 2 8 6 / 3 7 \% )$ and audio feedback $( 2 7 4 / 3 5 \%$ than the issues he addressed via the written feedback $( 2 2 1 / 2 8 ~ \% )$ . Moreover, while most of the global issues were addressed via the screencast feedback $1 6 8 / 2 2 \% )$ , most of the local issues were addressed via the audio $( 1 8 4 / 2 3 . 4 \% )$ and written feedback $( 1 4 5 / 1 8 . 2 \% )$

In addition, the mode appeared to affect how the instructor addresed global isues in students writing. The sample transcription of the e-feedack in Table7 illustrates that the audio and screncast records semed to allow the intructor to give lengthier, expansive and detailed comments on the global aspects related to ideas, organization and coherence. This could be due to the easines involved in speaking the audio and screncast feedback as opposed to typing the written feedback. The audio and screncast records alowed the teacher to give lengthy verbal explanations easily.

Table 4 Distributions of the engagement resource types across the three e-feedback modes.   

<html><body><table><tr><td>Feedback mode</td><td colspan="2">Expanding resources</td><td colspan="2">Contracting resources</td></tr><tr><td></td><td>Entertain</td><td>Attribute</td><td>Disclaim</td><td>Proclaim</td></tr><tr><td>Audio</td><td>210 (9 %)</td><td>360 (15 %)</td><td>98 (4 %)</td><td>82 (3 %)</td></tr><tr><td>Screencast</td><td>503 (21 %)</td><td>292 (12 %)</td><td>71 (3 %)</td><td>42 (2 %)</td></tr><tr><td>Written</td><td>22 (1 %)</td><td>19 (1 %)</td><td>391 (17 %)</td><td>277 (12 %)</td></tr><tr><td>Total</td><td>735 (31 %)</td><td>671 (28 %)</td><td>560 (24 %)</td><td>401 (17 %)</td></tr></table></body></html>

Table 5 Distributions of the discourse functions across the three e-feedback modes.   

<html><body><table><tr><td>Feedback discourse functions</td><td colspan="2">Audio</td><td colspan="2">Screencast</td><td colspan="2">Written</td></tr><tr><td></td><td>N</td><td>%</td><td>N</td><td>%</td><td>N</td><td>%</td></tr><tr><td>Suggestions</td><td>52</td><td>19 %</td><td>62</td><td>21.7 %</td><td>1</td><td>.5 %</td></tr><tr><td>Questioning</td><td>43</td><td>15.7 %</td><td>14</td><td>4.8 %</td><td>14</td><td>6.4 %</td></tr><tr><td>Statements</td><td>23</td><td>8.4 %</td><td>27</td><td>10 %</td><td>11</td><td>5 %</td></tr><tr><td>Commands</td><td>45</td><td>16.4 %</td><td>38</td><td>13 %</td><td>60</td><td>27 %</td></tr><tr><td>Correctionse</td><td>13</td><td>4.7 %</td><td>29</td><td>10 %</td><td>61</td><td>27.6 %</td></tr><tr><td>Combined</td><td>98</td><td>35.8 %</td><td>116</td><td>40.5 %</td><td>74</td><td>33.5 %</td></tr><tr><td>Total</td><td>274</td><td>100 %</td><td>286</td><td>100 %</td><td>221</td><td>100 %</td></tr></table></body></html>

Table 6 Distributions of issues addressed by the instructor across the three modes.   

<html><body><table><tr><td>Issues addressed</td><td colspan="2">Audio</td><td colspan="2">Screencast</td><td colspan="2">Written</td></tr><tr><td></td><td>N</td><td>%</td><td>N</td><td>%</td><td>N</td><td>%</td></tr><tr><td>Global issues</td><td>90</td><td>11.6 %</td><td>168</td><td>22 %</td><td>76</td><td>9.8 %</td></tr><tr><td>Local issues</td><td>184</td><td>23.4 %</td><td>118</td><td>15 %</td><td>145</td><td>18.2 %</td></tr><tr><td>Total</td><td>274</td><td>35 %</td><td>286</td><td>37 %</td><td>221</td><td>28 %</td></tr></table></body></html>

Table 7 Sample teacher e-feedback modes varying in length.   

<html><body><table><tr><td></td><td>Before the conclusion, you have mised more detals on an important point that th reader expect from you. You know whati is? You could hae talked about your rectinto the sitation. hy should e lk aout this? impl, ese narrative writig is  only aout nrratig a at story/ event/sitation, but i is also about how one was feling and reacting to it that moment. You may say, for example, as aresult/therfore/</td></tr><tr><td>Audio</td><td>conseque,  e et s s yr felin , ar, art, t, sds s .t me now? hope so. This is not cler. What do you mean by it? an you change it? Maybe like mixing your ideas in one sentence. We should not ssume that the reader</td></tr><tr><td>Written</td><td>knows detail of our past story. You can always read your ideas from a reader&#x27;s perspective. So your sentence should be reader-friendly. Can you add one more sentence on what you learnt from this conversation or talking to him?</td></tr></table></body></html>

# 1.5. Effect of the e-feedback modes on students' text revisions and writing improvemen

To answer the second research question, a text revision score was calculated for each level as stated above and as shown in Appendix C. Table illustrates that teacher's screncast and audio fedback reulted into students higher overal text revision scores $( 8 1 . 1 1 \%$ & $7 2 . 2 \%$ ) than the written feedback $( 6 7 . 8 7 \% )$ . A non-parametric Friedman test of differences was conducted and resulted into a Chi-square value of 5.30, which was not significant,. $\chi 2 ( 2 ) = 5 . 3 0$ $\mathtt { p } = . 1 3$ . This result suggests that none of the three e-feedback nodes was more effective in improving students' overall text revisions.

Table 8 Students' text revision scores in responding to the three e-feedback modes.   

<html><body><table><tr><td>Mode</td><td colspan="3">Global revisions</td><td colspan="3"> Local revisions</td><td colspan="3">Overall</td></tr><tr><td></td><td></td><td>TR</td><td>TR%</td><td>E</td><td>TR</td><td>TR%</td><td>E</td><td>TR</td><td>TR%</td></tr><tr><td>Audio</td><td>90</td><td>69</td><td>76.6 %</td><td>184</td><td>129</td><td>70 %</td><td>274</td><td>198</td><td>72.26 %</td></tr><tr><td> Screencast</td><td>168</td><td>144</td><td>85.7 %</td><td>118</td><td>88</td><td>74.6 %</td><td>286</td><td>232</td><td>81.11 %</td></tr><tr><td>Written</td><td>76</td><td>45</td><td>59.2 %</td><td>145</td><td>105</td><td>72.42 %</td><td>221</td><td>150</td><td>67.87 %</td></tr></table></body></html>

The above descriptive statistics show that whereas the screencast and audio modes led to higher global text revision scores $( 8 5 . 7 \%$ & $7 6 . 6 \%$ respectively) than the written mode $( 5 9 . 2 \% )$ , the screencast and written modes led to higher local text revision scores $( 7 4 . 6 \%$ & $7 2 . 4 2 \ : \%$ than the audio mode $( 7 0 \% )$ . The same test was repeated to compare among the three modes in relation to students' global and local text revision scores. Resuls illsrated that while the difference in the global text revision scores was statistically significant, $\chi 2 ( 2 ) = 7 . 1 0 , p = 0 . 0 4 2$ , it was not significant for the local text revision scores, $\chi 2 ( 2 ) = 1 . 1 6$ $p = 0 . 5 9$ . Again, a post-hoc analysis with Wilcoxon signed-rank tests was performed in order to find out which feedback mode was more efective in enhancing students' global text revisions. This resulted into a significance level of $p < 0 . 0 1 5$ . Hence, there were significant differences between the screencast and written modes $\mathbf { \Delta } Z = - 1 . 4 5$ $\begin{array} { r } { p = 0 . 0 1 } \end{array}$ ), between the audio and written modes $( \mathsf { Z } = . 2 0 , p = 0 . 0 2 )$ , but no significant differences between the screencast and audio modes were found $\mathbf { Z } = - \ 2 . 2 0$ $p = 0 . 0 6 \mathrm { \ : }$ . This result suggests that both screencast and audio modes were morefficient in facilitating teacher's e-feedack on writing, which onsequently improved students global text revision scores.

# 5. Discussion

This study was conducted in responding to the challenges involved in giving oral FTF and handwritten feedback for EFL teachers especially those with overload work and large numbers of students joining writing courses (Cavanaugh & Song, 2014; Hung, 2016; Ryan et al., 2019. It als attempted to fl up important gaps in earlier research on teacher's fedack through e-feedback modes-the need for research comparing e-written, audio and screencast eedack modes (Alharbi, 202; Bakla, 2020) using analytical frameworks of actual feedback data from a linguistic perspective (Cunningham, 2017, 2019). To address the first research question, the study focused on the evaluative language in the three-feedback modes provided by one writing teacher from the engagement resources within the appraisal framework (Martin & White, 2005; White, 2015). The present study revealed that the teacher's evaluative language in the audio and screencast e-feedback modes contained more expanding resources compared to the wrtten e-feedback mode which highly consisted of contracting resources. The expanding resources served as linguistic choices which expanded the space for dialogue while the contracting resources acted as lingustic choices which limited the space for dialogue (Cunningham, 2019a; Martin & White, 2005). This finding is consistent with the finding of aprevious study using the same analytical framework (Cunningham, 2019a). This implies that audio and screencast modes enabled the teacher to assume a more collaborative model in his evaluative language, which consequently provided a space for EFL learners viewpoints and options in how to revise their writing. In other words, the audio and screencast technologies semed to help the teacher maximize his use of linguistic choices in constructing and providing e-feedback of a more formative nature, which consequentl, placed him as an advisor and a colleague (Cunningham, 2019a; Garder, 2004; Hyland & Hyland, 2001).

In contrary, in giving students writtene-fedback, the teacher used more contracting resources, which rendered him an authority over students that imposed certain text corrctions on them. However, this finding seems to counter-argue Cunningham's (2019a) claim that screencast capture technology is the only single choice for writing instructors to turn their feedback into conversational because the conversational nature of fedback was also observed in the audio fedback through the instructor's spoken words and tone of voice (Hennessy & Forrester, 2014) as well as the frequent ue of questioning when responding tostudents writing. I other words the audio mode appeared to afford teacher's linguistic choices that could open up multiple venues for students to revise their writing rather than dictating them what to do through commands and spoon-feeding them through directcorrctions of rrors. The finding of the present study also supports self-perception findings of previous studies on the conversational nature of audio and screencast e-feedback modes (Bush, 2020; Edwards e al., 2012; Hennessy & Forrester, 2014; Orlando, 2016; Ryan et al, 2016). Because seech is more social-oriented, the audio and screncast feedback tended to fee like a more personal and hedged language as illstrated by the teacher's prevalent use of more expanding resources, thus creating more interpersonal venues.

In addition, our findings obtained from the discourse function analysis of feedback supported the above finding on teacher's divergent evaluative language in constructing his e-feedback across the three modes. The audio and screencas feedback highly functioned as questions, suggestions and even a combination of both functions, while the written feedback highly served as commands and error corrections. This finding corroborates the varying existence of discourse functions in teachers' e-feback modes (Chalmers et al., 2014; Elola & OSskoz, 2016). This suggests that the technology used for giving each feedback mode may push writing teachers to more frequently use certain types of feedback over others. As the audio and screencast records facilitated teachers provision of feedback thatis spoken in nature, he highly constructed his feedback in the question and suggestion forms in both modes. Such hedged suggestions seemed to placestudents as agent and responsible for revising their writen texts because they could consider the teacher's advice in deciding on how to revise their texts (Cunningham, 2019a; Gardner, 2004; Hyland & Hyland, 2001). On the other hand, due to the slow pace of writing the feedback comments in the written mode, other types of feedback constructions such as unhedged commands and error corrections seemed more suitable as they are not wordy/lengthy and therefore, they are not time-consuming. Such unhedged feedback appeared to dictate students on how to revise their texts.

In answering the second research question, the current study demonstrated that the three modes afected the extent to which the teacher's efeedback addressed global and localissues in writing. Whilethe majority of global ssues in students' writing were addressed through the screencast fedback, the maorit of local issues were adressedthrough the audo and wrten feedback This is not new given that similar results were reported by Elola and OSskoz (2016) obtained from feedback analys and results of Bakla (2020) obtained from students perspectives. The current study supports the efficacy of screencastechnology in facilitating teachers e-feedback on global isues through his elaborate oral comments and visual highlightsas wellas flexible movement acos the ections of students texts lola & Oskoz, 2016). In contrary, giving written feeback restricted the teacher's frdom to do so possibly because of his effort in composing or typing comments on students writing in the Blackboard Discussion. The current study finding also supports Cunningham's (2019a) and Soden's (2016) studies that screencast technology provides a space for writing instructors to give detailed and explanatory feedback. Moreover, theaudio feeback appeared more detailed than the writtene-feedack mode. Although this feature was observed in the fedack transcripts, it confirms the results f few previous studies Chalmers et al., 2014; Nemec & Dintzner, 2016).

Concerning the third research question, the study findings showed that the screencast and audio e-fedback modes led to a higher overall rat of students' successfl text revisions than the written mode. This decriptive reult supports the reults reported by Ozkul and Ortactepe (2017). Yet, no significant differences were found among the three modes, which corroorates Bakla's (2020) result. In relation to the global tet revisions, the screencast and audio modes reulted into higher perentags of seul global tex revisions than the written mode. This result confirming Cunningham's (2019b) result and contradicting result of Elola's and Oskoz, was also supported by the inferential sttistics of the preet study. It implies that both screncas and audio feedback semed morefftive in improving students' global text revisions. The result could be interpreted from the detailed and elaborative nature of teacher's screencast and audio feedback as opposed to the brief nature of writte feedback. Another reason could be the combined visual and auditory elements of the screencast mode, which rendered global isues easier for students to revise. In other words, students simultaneous hearing of the oral feedback and viewing of the erroneous parts f their texs on the creencas records seemed to play a role in facilitating their understanding of teacher's feedback and aiding their successful text revisions.

On the other hand, in relation to the local text revisions, the screencast and text modes led to a higher number of students suc. cessful text revisions than the audio mode, which contradicts Bakla's (2020) result that the audio and written modes resulted into higher numbers of micro level text revisions than the screencast mode. Yet, no significant differences were found among the three modes, which supports Bakla's (2020 result. This could be due to the nature of local erors that can easily be undersood and corrected by students without the need for teacher's detailed or elaborative feedback.

# 6. Conclusion and implications

The present study explored how the written, audio and screencast modes influence the way the teacher responds to EFL learners writing. The study revealed that the audio and screencast e-feedback modes contained more expanding resources, thus making such feedback more interpersonal as opposed to the written e-feedback mode containing more contracting resources that imited such interpersonal space and emphasized teacher's authority and the necessity for giving corrections of students' errors in writing. This result should not be interpreted from the mode itself alone but rather how these technological tools were used to produce the efeedback seemed to play an important role in the teacher's selection of engagement resources, which either promoted or contracted such interpersonal spaces. This could be also explained from the differences in spoken and written language. Morover although the teacher addressed global and local isues in writing across the thee modes, the extent to which thes issues were addresse differed with mor global issues being addressed by the screencast feedback as opposed to the audio and written feedback addressing more local issues. The screencast and audiofeedback addressing global isues was more elaborative than that of the written feedback.

The findings have implications for writing intructors as well as researchers. For instructors, the findings demonstrated how the screencast mode enhances teachers delivery of effectivee-feedback on writing. This is not to trivialize the importance of audio and written modes in EFL writing instruction because each mode has its own advantages: whil screencast records suit teacher's corrective feedback on writing that is meant to provide detailed and lengthy explanations of global issues, audo and written modes suit provision of less detaled feedback addressing specific local errors relevant to vocabulary, grammar and punctuations. However, this is to encourage transformation of uni-modal practicesto multi-modal feedback practices in responding to students writing as suggested by Chang et al. (2017) and Hung (2016). Feedback transformation is very crucial for EFL instructors, especiall in the EFL context where learners need teachers support in writing (Alharbi, 2020). EFL teachers can improve the effectiveness of e-feedback modes (Bakla, 2020). In ddition, they should think of how tocarefully select the fedack mode that catersthe type of isues and erors i students writing. Based on the findings, due to the dfficult involved in revising global aspects of texts teachers can address global isues through audio-visualfedback that combines their oral voices and visual highlights f the texts. This audio-visual feedback will aid students' undersanding of teachers' global feedback and their successful global revisions. However, teachers may find the audio and written modes more effctive to respond to students local errors as these types of errors do not require detailed information and therefore, they can be easily fixed by EFL learners.

Despite the contributions of the present study to earlier research on e-feedack modes using the appraisal framework, thestudy has several limitations to be addressed for future research. First, the study focused on the e-feedback modes provided by one teacher. Future research, therefore, should compare the three modes among different instructors to se if there are differences in their efeedback on writing. In addition in ths stud, each -feedback mod focused on a different topic of writing, which may have affected the findings. Therefore, future research can explore whether teacher's e-feedback modes on the same topic of writing will lead to different findings. Another limitation is the relatively short feedback cycle and the fact that the feedback was confined to one EFL writing course in the Saud context. Therefore, the findings should be interpreted carefully when used in different context. In order to provide a comprehensive picture of the e-fedback modes in writing courses, future studies should take into account the views of teachers and students on the three modes. This can be achieved by using a mixed method approach that combines both survey and follow-up interview. Finlly, in this study, the writing course was a typical course taught to a class of male students only in the Saudi university context, so the study findings may not be generalized to classes with a mixture of male and female students. Future studies might focus o e-feedback modes in mixed clase of male and female students as both geders might usee-feeback modes ifferently in revising their writing (Hung, 2016).

# CRediT authorship contribution statement

Murad Abdu Saeed: Writing - review & editing, Validation, Methodology. Mohammed Abdullah Alharbi: Funding acquisition, Validation, Writing - review & editing. Atef Odeh Abusa'aleek: Writing - original draft, Investigation, Conceptualization.

# Disclosure statement

The author of this paper has no potential conflict of interest.

# Data availability

The data that has been used is confidential.

# Acknowledgements

The authors extend the appreciation to the Deanship of Postgraduate Studies and Scientific Research at Majmaah University for funding this research work through the project number: R-2024-1180.

Appendix A. Sample coded e-feedback in relation to its discourse functions   

<html><body><table><tr><td>Discourse functions</td><td> Samples</td></tr><tr><td rowspan="3">Suggestions</td><td>You can change this phrase.</td></tr><tr><td>You should add one sentence here..</td></tr><tr><td>I would suggest adding one more sentence to elaborate this idea.</td></tr><tr><td rowspan="2">Questioning</td><td>Yes/no question: Are you sure this is true? Can you please check this word?</td></tr><tr><td>Wh-question: What do you mean by this sentence?</td></tr><tr><td rowspan="2">Statements</td><td>We usually try to set up the scene to make it easy for readers to imagine the place and time.</td></tr><tr><td>This is a very good idea..</td></tr><tr><td rowspan="2">Corrections commands</td><td>The only thing occurring to my mind was.</td></tr><tr><td>Change this verb by another one that accurately expresses the intended meaning.</td></tr><tr><td></td><td>Don&#x27;t leave this space after the sentence. Start the next sentence here</td></tr><tr><td>Combined</td><td>What do you mean by this &quot;shopping in the whole world&quot;? I suggest you change it. You can say &quot;from distance&quot; or online.</td></tr></table></body></html>

Appendix B. Sample teacher e-feedback in relation to its content   

<html><body><table><tr><td>Global issues</td><td>Samples</td></tr><tr><td>Lacking/inappropriate title</td><td>You should put your title here..</td></tr><tr><td>Lacking/inappropriate background</td><td>Can you add an introductory sentence to give background about your event?</td></tr><tr><td>Background-topic sentence connection</td><td>How can you do to relate your background to the main idea?</td></tr><tr><td>Lacking/ineffective topic sentence</td><td>The topic sentence should be your main idea and not attached to the supporting sentence.</td></tr><tr><td>Awkward idea expressions</td><td>Change this sentence: &quot;the only thing occurring to my mind was&quot;.</td></tr><tr><td>Idea elaboration</td><td>You should elaborate this idea.</td></tr><tr><td>Irrelevant ideas</td><td>Are you sure this sentence is relevant to your main idea?</td></tr><tr><td>Lacking coherence</td><td>You need to connect or link these sentences using &quot;Moreover, In addition, et&quot;</td></tr><tr><td>Flow of ideas</td><td>I think this sentence should be the first one in this paragraph. It carries the main idea.</td></tr><tr><td>Idea repetition</td><td>Remove that sentence from &quot;because ...without injuries&quot; because it looks repetitive.</td></tr><tr><td>Lacking/inappropriate conclusions</td><td>You should give a concluding sentence summing up your experience.</td></tr><tr><td>Local issues</td><td>Sample feedback</td></tr><tr><td>Erroneous tense use</td><td>Why the past tense here?</td></tr><tr><td>Inaccurate sentence structure</td><td>They are better what? Fix the structure.</td></tr><tr><td>Inappropriate vocabulary choice</td><td>Change &quot;went to take him&quot; by picked him up</td></tr><tr><td>Inaccurate active-passive voice use</td><td>&quot;when suddenly my car hit by another car&quot;. This should be in the passive.</td></tr><tr><td>Erroneous word forms</td><td>You mean silently as this should be an adverb.</td></tr><tr><td>Word order</td><td>Why are the adjectives big and scary after the noun &quot;wolf?</td></tr><tr><td>Article use</td><td>This word is definite so it should be preceded by the not a.</td></tr><tr><td> Preposition use</td><td>To or for? Check.</td></tr><tr><td>Subject-verb disagreement</td><td>There is places? Why? Check and revise it.</td></tr><tr><td>Incorrect plural/singular use</td><td>It should be singular here.</td></tr><tr><td>Missing words</td><td>No missing &quot;is&quot;?</td></tr><tr><td>Lacking/wrong punctuations</td><td>There is a missing comma here.</td></tr><tr><td> Misspellings</td><td>Check the spelling of this word.</td></tr><tr><td>Capital-small letter use</td><td>Why is it small here?</td></tr><tr><td>Indenting</td><td>Don&#x27;t you need to indent it here?</td></tr></table></body></html>

ppendix C. Students' text revision scores in the three e-feedback modes   

<html><body><table><tr><td></td><td colspan="3">Voice</td><td colspan="3">Screencast</td><td colspan="3">Text</td></tr><tr><td></td><td>E</td><td>TR</td><td>TR%</td><td>E</td><td>TR</td><td>TR%</td><td>E</td><td>TR</td><td>TR%</td></tr><tr><td colspan="10">Global issues</td></tr><tr><td> Lacking/inappropriate title</td><td>7</td><td>6</td><td>85.7%</td><td>6</td><td>5</td><td>83%</td><td>7</td><td>6</td><td>85.7%</td></tr><tr><td> Lacking/inappropriate background</td><td>5</td><td>3</td><td>60%</td><td>6</td><td>5</td><td>83%</td><td>7</td><td>4</td><td>57%</td></tr><tr><td>Background-topic sentence connection</td><td>2</td><td>1</td><td>50%</td><td>5</td><td>4</td><td>80%</td><td>4</td><td>1</td><td>25%</td></tr><tr><td>Lacking/ineffective topic sentence</td><td>7</td><td>4</td><td>57%</td><td>8</td><td>6</td><td>75%</td><td>5</td><td>2</td><td>40%</td></tr><tr><td>Awkward idea expressions</td><td>17</td><td>12</td><td>70.5%</td><td>30</td><td>26</td><td>86.6%</td><td>21</td><td>11</td><td>52%</td></tr><tr><td>Idea elaboration</td><td>14</td><td>12</td><td>85.7%</td><td>34</td><td>29</td><td>85%</td><td>12</td><td>6</td><td>50%</td></tr><tr><td>Irrelevant ideas.</td><td>5</td><td>4</td><td>80%</td><td>15</td><td>13</td><td>86.6%</td><td>5</td><td>5</td><td>100%</td></tr><tr><td>Lacking coherence</td><td>18</td><td>14</td><td>77.7%</td><td>30</td><td>27</td><td>90%</td><td>8</td><td>5</td><td>62.5%</td></tr><tr><td>Flow of ideas</td><td>4</td><td>3</td><td>75%</td><td>20</td><td>16</td><td>80%</td><td>3</td><td>1</td><td>33%</td></tr><tr><td>Idea repetition</td><td>5</td><td>5</td><td>100%</td><td>5</td><td>5</td><td>100%</td><td>3</td><td>3</td><td>100%</td></tr><tr><td> Lacking/inappropriate conclusions</td><td>6</td><td>5</td><td>83%</td><td>9</td><td>8</td><td>88.8%</td><td>1</td><td>1</td><td>100%</td></tr><tr><td>Total</td><td>90</td><td>69</td><td>76.6%</td><td>168</td><td>144</td><td>85.7%</td><td>76</td><td>45</td><td>59.2%</td></tr><tr><td colspan="10">Local errors</td></tr><tr><td>Erroneous tense use</td><td>3</td><td>2</td><td>66.6%</td><td>6</td><td>3</td><td>50%</td><td>16</td><td>13</td><td>81.25%</td></tr><tr><td>Inaccurate sentence structure</td><td>28</td><td>16</td><td>57%</td><td>27</td><td>17</td><td>62.9%</td><td>16</td><td>12</td><td>75%</td></tr><tr><td> Inappropriate vocabulary choice</td><td>29</td><td>20</td><td>69%</td><td>11</td><td>6</td><td>54.5%</td><td>22</td><td>16</td><td>80%</td></tr><tr><td>Inaccurate active-passive voice use</td><td>0</td><td>0</td><td>0%</td><td>2</td><td>2</td><td>100%</td><td>8</td><td>6</td><td>75%</td></tr><tr><td>Erroneous word forms</td><td>12</td><td>8</td><td>66.7%</td><td>9</td><td>6</td><td>66.7%</td><td>10</td><td>7</td><td>70%</td></tr><tr><td>Word order</td><td>0</td><td>0</td><td> 0%</td><td>4</td><td>3</td><td>75%</td><td>1</td><td>1</td><td>100%</td></tr><tr><td>Article use</td><td>10</td><td>7</td><td>70%</td><td>8</td><td>5</td><td>62.5%</td><td>1</td><td>1</td><td>100%</td></tr><tr><td> Preposition use</td><td>6</td><td>3</td><td>50%</td><td>1</td><td>1</td><td>100%</td><td>1</td><td>0</td><td>0%</td></tr><tr><td>Subject-verb disagreement</td><td>2</td><td>2</td><td>100%</td><td>6</td><td>4</td><td>66.7%</td><td>1</td><td>1</td><td>100%</td></tr><tr><td>Incorrect plural/singular use</td><td>7</td><td>5</td><td>71%</td><td>7</td><td>6</td><td>85.7%</td><td>3</td><td>1</td><td>33.3%</td></tr><tr><td>Missing words</td><td>11</td><td>10</td><td>90%</td><td>9</td><td>5</td><td>55.5%</td><td>15</td><td>9</td><td>60%</td></tr><tr><td>Lacking/wrong punctuations</td><td>54</td><td>36</td><td>66.6%</td><td>20</td><td>14</td><td>7%</td><td>30</td><td>23</td><td>76.7%</td></tr><tr><td>Misspellings</td><td>7</td><td>6</td><td>85.7%</td><td>12</td><td>10</td><td>83%</td><td>9</td><td>6</td><td>76.7%</td></tr><tr><td>Capital-small letter use</td><td>13</td><td>12</td><td>92%</td><td>5</td><td>4</td><td>80%</td><td>12</td><td>9</td><td>75%</td></tr><tr><td> Indenting</td><td>2</td><td>2</td><td>100%</td><td>3</td><td>2</td><td>66.7%</td><td>0</td><td>0</td><td>%</td></tr><tr><td>Total</td><td>184</td><td>129</td><td>70%</td><td>118</td><td>88</td><td>74.6%</td><td>145</td><td>105</td><td>72.41%</td></tr></table></body></html>

ote: An rl t ra  t  ti th in f th   r t rii l mb r. \*\*\* $\mathbf { E } =$ Errors, TR $=$ Text Revision.

# References

AbSeie 013 k  iie  ti f sn 294, 319-333.   
abi, th   ti  i Learning and Teaching, 14(3), 227-242.   
Aharbi, M 202). Exploing the mpact f teher feack modes and feres on studnts tt reisios in writingAsring 52,13.   
Bahari, A. (2021). omputer-mediated feedack for 2 leaners: Challenges vers affordance. oudl of Cmpute Assited Leng, 371), 24-38.   
Bakla, A. (2020). A mixed-methods study of feedback modes in EFL writing. Language Learning & Technology, 24(1), 107-128.   
Bastola,  H, . 2021). nting on yr work is stf time y!: n apalad study f alative lanag in superisry feack Studies in Educational Evaluation, 68, 1-11.   
Bush, J. C. (2021). Using screencasting to give feedback for academic writing. Innovation in Language Learning and Teaching, 15(5), 473-486.   
Caldwell D. (2009). Working your words' Appraisal i the AFL post-match interview. Austaian review of pplied lingustics 32(2), 13-14.   
Caanagh   014     i.     101) 122.   
Chamers C, Maclm, J., Mat   Fun, . (2014)  ack Rchr lngg t nmrabl ct on stden pence. Prctti Research in Higher Education, 8(1), 64-73.   
ag,    tit & Pedagogy.   
Chong, .. 019. d tif k d t i  g ,  100-10.   
g.017   fak in ESL writing. Writing & Pedagogy, 9(3).   
Cigh,  J.019). w h  feack h wh te t int an cst eak n  wtin mputers Education, 135, 91-99.   
ughm J.019). de ti ad use f -md t ad ct feak in  wrg trs d ion 52 222-241.   
a, i12 kr   to  f Writing, 2(1), 95-126.   
Elola, I, & Oskoz, A. (2016). Supporting second language writing using multimodal feedback. Foreign Language Annals, 49(1), 58-74.   
Ene, E., & Upton, T. A. (2014). Learner uptake of teacher electronic fedback in ESL composition. System, 46, 80-95.   
Ene  01.s  s t k  ak tio.   g 41, 1-13.   
Fso0 t gsti    , 5 215-229   
Fi        019    n Journal of Computer Assisted Learning, 35(5), 607-619.   
Gardner, S. (2004). Knock-on effects of mode change on academic discourse. Journal of English for Academic Purposes, 3(1), 23-38.   
Godwin-Jones, R. (2018). Second language writing online: An update. Language Learning & Technology, 22(1), 1-15.   
Halliday, M. A. K., & Matthiessen, C. M. (2014). Halliday's introduction to functional grammar. Routledge.   
Hes, r.1 i 9   
Hung, S.-T. A. (2016). Enhancing feedback provision through multimodal video technology. Computers & Education, 98, 90-101.   
Hyland, F., & Hyland, K (2001). Sugaring the pill Praise and criticism in witte fedack. Jourl of Second Language Writin, 10(3), 185-212.   
Li a (pp. 375-392). Cham: Springer International Publishing.   
Macken-Horarik, M. (2003). Appraisal and the special instructiveness of narrative. Text & Talk, 23(2), 285-312.   
Mahoey, P, e,    2019)  qlie s f viack in hg tio g  gio 242) 157-179   
Martin, J., & White, P. R. R. (2005). The Language of Evaluation: Appraisal in English. Palgrave MacMillan.   
Martin, J. R. (2004). Contextualising Appraisal: origins and challenges. Sydney: University of Sydney.   
Martin, J. R. (2007). Working with Discourse: Meaning beyond the Clause. London: Continuum.   
athieson 012).g tt tins f l fack ia stig i r. r  f  o, 63, 143-156.   
me,E r,016.if w n . P , 155-59   
Orlando, J. (2016). A cmpariso f tex, voce, and scrcasting feack to onin tdnts. Amrican Joual f Distce ctio, 303), 156-16.   
Ryan  o Pili 016t fknt k  nt f si . enc.   
Ozkul, S., & Ortactepe, D. (2017). The use of video feedback in teaching process-approach EFL writing. TES0L Joumal, 8(4), 862-877. British Journal of Educational Technology, 50(3), 1507-1523.   
Shrestha, P.N. (2022).n altive langag used in asmet fedack n usi studnts aai writing.si wring 54, 1-16.   
Sia,  2.i te c ie  pr r vr  ns rin t in p. Computers and Composition, 29(1), 1-22.   
Smith J f  014  o a i  rr. es, 452) 276-288.   
Sden,.016st  a th in f ght rs sd   f ped Linguistics and TEFL, 5(1), 213-236. on doctoral theses. Linguistics and Education, 31, 130-144.   
Stald, .  , ie o at , Kie,    2017)  nin n D  s ow grammatical choices construe examiner roles. Linguistics and Education, 42, 53-64.   
Stoch, .2021).il ti o wig d    ctiewtin d thoti inf w tie feedback. In The Routledge handbook of second language acquisition and writing (pp. 22-34). Routledge,.   
Tmas,  t   p, .017 s    p x d sck .  nd Higher Education, 33, 61-73.   
, .  . 019    , 32) 145-158.   
White, P. R. (2015). Appraisal theory. The international encyclopedia of language and social interaction, 3, 1-7.   
eg,    20  t  r    th ti f stt n. SAGE Open, 10(2), 1-10.

urad A  t  s,   stic rti  n ag Educational Technology in Writing and Peer and Teacher Feedback, Feedback Dialog and EFL collaborative writing.

At ai   stc  s  t  9 His research interests are applied linguistics, CALL, internet linguistics, electronic feedback, and EFL writing.