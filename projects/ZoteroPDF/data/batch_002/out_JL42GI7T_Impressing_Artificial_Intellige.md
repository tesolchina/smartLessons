# Impressing Artificial Intelligence: Automated Job Interview Training in Professional English Subjects

# Andrew Jarvis

Centre for Applied English Studies, The University of Hong Kong, Hong Kong

# Anna Ho

English Language Centre, The Hong Kong Polytechnic University, Hong Kong

# Grace Lim

English Language Centre, The Hong Kong Polytechnic University, Hong Kong

# Abstract

More organizations are using automated job interview platforms to screen candidates at the early stages of the recruitment process. These platforms enable job candidates to take automated video interviews remotely using their personal devices. The interviews are analysed by artificial intelligence (AI) powered algorithms to produce analytics which inform hiring decisions. In this article, we explore the use of automated job interviewing within professional English subjects delivered to undergraduate students in Hong Kong. The innovation was introduced to help students to keep up with recruitment practices, provide speaking practice and explore AI-powered evaluation as a form of feedback. As well as outlining how automated interviewing was integrated into our teaching practice, we discuss student feedback on the experience and offer suggestions for future teaching practice with this technology. We also highlight considerations for practitioners such as the acceptance and adoption of AI technologies into language learning provision and the development of AI literacy skills. AI technologies have much potential for language teaching and this article offers a practical exploration into one such technology: automated job interviewing.

# Keywords

English for specific purposes, artificial intelligence (AI) in language learning, professional English, AI interviewing, AI literacy

# Introduction

Artificial intelligence (AI) technologies are transforming recruitment practices with more organizations adopting automated video interviewing to facilitate the recruitment process (Chou et al., 2022). To take an AI-based interview, candidates enter an online interview platform and answer set questions within a set time. The video interviews are automated, meaning that no human is required to ask the questions and interview answers are digitally recorded. The interviews are analysed by AI algorithms to produce insights about the candidate, which employers use to aid recruitment decisions. Benefits of automated interviewing for organizations include: (a) reducing hiring costs (Suen et al., 2019); (b) enabling flexibility in scheduling and candidate review (Langer et al., 2017); (c) offering convenience for candidates (Kim and Heo, 2022); and (d) standardizing the interviews for procedural fairness (Kim and Heo, 2022).

One of the aims of English for Specific Purposes (ESP) is to help students use language to achieve their professional goals (Feak, 2012), and one initial goal for undergraduates is to attain employment. Many of our professional ESP subjects have a focus on accessing the workplace which includes interview skills. Advancements in digital communication technologies have led to the emergence of new digital genres in professional contexts (Hafner and Pun, 2020), prompting us to explore automated job interviewing. Although there is much overlap between live and automated interviews in terms of the language and communication skills required, automated interviewing is its own genre, with its own challenges and opportunities for language learning. In this article, we report our experience of conducting an automated job interview exercise with students taking professional English subjects.

# The Teaching Context

This innovation was implemented at The Hong Kong Polytechnic University between January and April 2023. English is the medium of instruction at this university, where undergraduates take a four-year curriculum. During the latter years of their studies, students take a credit-bearing ESP subject provided by the university’s English Language Centre. Participants of our AI interview innovation were taking one of these subjects in the disciplines of: (a) business; (b) construction and environment; or (c) hotel and tourism management. These subjects take a scenario-based approach in which students produce communicative outputs relevant to their fields. In each of these subjects, one module is dedicated to job applications where students need to ‘apply’ for an internship or graduate position related to their fields of study and participate in a live job interview. The innovation presented in this article aimed to provide the supplementary speaking opportunity of an AI-powered job interview as part of the learning process. As this was the first-time conducting AI interviews with students, we made the interviews voluntary, and they were not assessed as part of the subject grade. 51 students from eight classes (approximately 20 per class) opted to take the AI interviews and 14 participants joined focus groups (FGs). Students taking the ESP subjects ranged in their English proficiency levels but were expected to have a B2 level on the European Common Framework of Languages.

# Reasons for the Innovation

Feedback from our graduate network confirmed that personnel selection practices are changing, with applicants often needing to be screened by AI during the early stages of recruitment. A major impetus for this AI interview innovation was therefore to ensure that our teaching of job application skills was meeting the current demands of graduate recruitment. This includes being able to communicate effectively in AI-powered environments and understanding how AI algorithms can evaluate them. AI literacy (e.g., as conceptualized by $\mathrm { N g }$ et al., 2021) is becoming a fundamental skill in professional settings and through this AI intervention, we envisioned that students would not only gain more understanding and practice with an AI technology, but also evaluate its practical and ethical qualities.

A second reason for this innovation was to provide out-of-class speaking practice. Despite the English-medium instruction environment, students have limited English speaking opportunities outside class. This is problematic because graduate job interviews in Hong Kong are often conducted in English (Mahboob, 2014). Additionally, students from the focal institution may be less competitive in securing employment due to lower overall English proficiency levels than students of higher-ranked institutions (Mahboob, 2014). Technology-assisted speaking opportunities may be seen by some learners as low anxiety environments (Chen, 2022), which we considered to be useful for developing speaking confidence.

Exploring AI analytics to complement self, peer and teacher evaluation was also a catalyst for this innovation. Research (e.g., Gu et al., 2021) suggests that automated systems can provide useful feedback on spoken output including holistic scores and personalized comments. Automatic speech recognition technology can process spoken speech into a written format which we deemed as useful for learners and teachers to analyse aspects such as organization, rhetorical moves and language use. Automated interviewing platforms can also be used as coaching tools (Suen et al., 2020), fitting in to our pedagogy which values a process approach.

# Description of the Innovation

# The Project

This innovation uses an AI-powered job interview platform to provide job interview practice for undergraduate students taking professional ESP subjects. The project also aims to explore the value of AI-powered feedback. The project started in January 2023 and we report here on the first round of AI interviews.

# The Platform

We used a platform developed by Neufast, a local company specializing in AI-powered recruitment. The advantages of using this paid service are that the platform is set up and easy to customize, the database has thousands of interviews which can add more predicative reliability and the platform gives the students an authentic experience. We found that free online interview tools do not have the features and depth of analytics that paid versions have but we predict that in the coming years this technology will become more accessible. An example of a free tool is Google’s Interview Warmup which enables users to answer industry specific questions. Answers are transcribed so that users can review their responses. Though useful for practice and brief insights, the tool does not give much depth of evaluation, especially on communication skills.

The Neufast platform enables employers to set up automated interviews and invite candidates to complete them in their own time and on their own devices. The recorded video interviews are analysed from a dashboard of competencies selected by the employer and relevant to the post. The platform produces holistic scores and individualized reports to inform employers when reviewing candidates. Different job interview platforms use different constructs to measure interview performances and have different data sets and machine learning algorithms to make predictions on candidates (Tippins et al., 2021). This needs to be pointed out to students in developing their AI literacy as, like a language rubric, which uses constructs (e.g., pronunciation and grammar) for teachers to infer a holistic grade on a language performance, AI-generated reports only give clues to an interview performance based on pre-determined criteria. In another area of consideration, Hockly (2023) points out that capturing learner data through AI tools raises ethical concerns such as privacy of information, anonymity and ownership of information. We had such concerns which required much discussion with Neufast and our information technology unit to ensure that student data were protected.

# The Interviews

Students took one interview which asked five questions set by the subject coordinators. Each question allowed 30 seconds preparation time and two minutes answer time. Students could opt to take one practice question which was not scored. In the given scenario, learners were applying for an internship or graduate position in their field.

The following are some examples of our automated interview questions:

1) Please tell us about yourself.   
2) What are the most important qualities of a fresh graduate working in your field?   
3) Tell us about a time you worked in a team. What challenges did you encounter   
and how did you overcome them?   
4) What type of work environment do you thrive in?   
5) What are your goals for the next five years?

# The Task

We produced presentation slides which teachers used to elicit and introduce AI interviewing. Points covered included:

1) What is AI-powered interviewing?   
2) How does automated interviewing fit into the recruitment process?   
3) Why do companies use AI interview platforms?   
4) How will I be rated?   
5) What good practices can I employ in automated interviewing?

Students were sent a link to access the platform and given two weeks to complete the interview. The interviews were conducted while students were developing job application skills as part of their professional English subjects. Participating students were sent AI-powered reports which they discussed with teachers.

The reports included guidance on the competencies, a dashboard of overall scores, individual competency scores and development needs. One limitation of the reports is that they are written for employers, not language learners. Though this gave students a unique insight into the employer perspective, a platform designed for language learners could be more effective.

The extracts in Figure 1 were taken from the dashboard of a student’s interview report. The student’s overall impression score, which captures confidence, enthusiasm and composure, was 6.2 (7.0 is considered ‘high’). The second extract shows the student’s performance on specific competencies preselected by the subject coordinator. Later in the report, there was more explanation of these ratings for each competence.

Students were especially interested to know more about the reports. Our aim in discussing the reports with students was not only to help them interpret the results but also to guide them in evaluating the value of the AI-powered feedback. This fits into our goal of developing critical and ethical awareness of AI technology.

# Reflection

Through this innovation, we aimed to give our students experience and insight into AI interviewing. We also wanted to explore an AI technology and its possibilities for enhancing language teaching provision.

Students who took the AI job interviews were positive about the experience. Comments from the FGs revolved around the themes of opportunity, awareness and skills.

# Opportunity

In all FGs, students reported valuing the opportunity to take the AI interview. Students saw that this type of technology would be used in graduate hiring and viewed the practice AI interviews as a rare opportunity:

![](img/6a9687ea2ce4583daae387a63ef8a2dbd33480a4fabab9d87aa86a3b7a4b52dd.jpg)  
Figure 1. Extracts of artificial intelligence-generated analytics featured in a report.

‘This practice is useful to the student because I think AI interview may be a big trend for the future … It is really good practice and I’m so glad that I took this.’ (S1 – Business)

‘I think you can’t get this kind of opportunity until you actually do it, like in real life.’ (S2 – Business)

# Awareness

Students valued the practice interview because it raised their awareness about the automated interview process, including how they were rated by the AI algorithms. In addition, students reported enhancing their critical awareness of AI interviewing such as the differences between automated and live interviewing:

‘It can let the student to experience how the AI interview runs, and how they can prepare before the interview.’ (S3 – Construction and Environment)

‘Our gesture, our pronunciation, our fluency, because I’ve read the report and basically it’s judging our fluency, our starting point, our confidence.’ (S4 – Business)

‘The biggest difference is not being able to see the interviewer’s face and obviously emotions and reactions, and that could affect a lot with your demeanour and your answers and the way you just… pace yourself.’ (S5 – Hotel and Tourism Management)

# Skills

Some students highlighted that this experience was useful for building their speaking fluency as they needed to speak for two minutes for each interview answer. A few students also reported that they needed to consider their body language, camera positioning and background, suggesting that digital literacy skills and communicating to AI were skills that they developed:

‘I think the motivation would be that I want to do more practice and try to train myself to react more fast and fluent.’ (S6 – Hotel and Tourism Management)

‘I need to use computer to record. I have to make sure that my eye content is parallel to the camera. And I have to make sure the background is clean and tidy.’ (S7 – Business)

A few considerations arose from the teaching and learning perspective.

# Practice V. Assessment

The students valued the AI interviews as a practice exercise but preferred live interviews as the main assessment task. Reasons for this included not being used to automated platforms, and lack of clarity about how they would be graded. Our students prioritized face-to-face speaking experiences because these opportunities are scarce in their daily lives. We found that the value of the interview platform lies in enabling independent speaking practice in which students can receive feedback without the immediate need of a teacher.

# Grade Credits and Task Integration

Many of the FG participants suggested that to encourage more students to take the interviews, students should receive a small grade percentage. This was because competing demands and deadlines on students led them to prioritize graded work. Participating teachers suggested that these micro grade credits could be based on task completion, with the interviews being integrated into the assessment task scenario. Allocating class time for reflection activities could further help to embed the interviews into the learning sequence.

# Teacher Investment

This type of innovation requires teacher buy-in. Teachers not only need to use class time to introduce the interviews but also to familiarize themselves with the platform and grapple with new practices such as AI feedback. According to the Technology Acceptance Model, technology uptake is a cost/benefit decision (Davis et al., 1989). Our teachers needed to decide if the investment in exploring the AI technology would reap adequate benefits for their students and teaching practice. In implementing this type of innovation, it is important to have a clear justification, provide professional development opportunities and ensure that the logistics (e.g., accessing student reports) are as streamlined as possible.

# Future Pedagogical Directions

After running the AI interviews with students on a voluntary basis and receiving positive reviews, the next step is to embed the practice interviews further into our learning modules and assessment task sequence. This fits into our blended learning approach which is based around constructivist notions of learning (see Stokes and Jarvis, 2024) where students learn on task while utilizing relevant resources and platforms, and teacher instruction is centred around facilitation, consultation and feedback. In practical terms, we aim to employ the following measures:

1) Embed the AI task into our learning modules to better reflect a process-oriented genre approach to multimodality and digital literacies as described by Hafner and Miller (2018).   
2) Offer microcredits for taking the practice interview as part of a process grade.   
3) Integrate the AI interviews into the assessment scenario in building up to the live assessment task.   
4) Prioritize more class time for reflection activities to facilitate language and communication development and AI literacy.   
5) Provide opportunities for teachers to better understand AI interviewing; for example, we have run a professional development session in which the platform provider gave a talk.

In this article, we have outlined our exploration of using AI interview technology in professional English subjects. Automated speaking platforms offer much potential for speaking practice and detailed AI-powered feedback. These technologies need to be thoughtfully integrated into blended learning provision and practitioners should enable critical reflection to develop students’ AI literacy skills.

# Conflict of Interests

The authors have no conflict of interests to declare.

# Ethical Approval

The project received ethical clearance from the Human Subjects Ethics Application Review System, The Hong Kong Polytechnic University.

# Funding

The authors disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was supported by the University Grants Commitee Teaching Development Grant (grant number VTL-27).

# ORCID iD

Andrew Jarvis

$\textcircled{1}$ https://orcid.org/0000-0002-0882-0762

# References

Chen YC (2022) Effects of technology-enhanced language learning on reducing EFL learners’ public speaking anxiety. Computer Assisted Language Learning: 1–25. DOI: 10.1080/ 09588221.2022.2055083.   
Chou YC, Wongso FR, Chao CY, et al. (2022) An AI mock-interview platform for interview performance analysis. In: 2022 10th International Conference on Information and Education Technology (ICIET). Piscataway, NJ: Institute of Electrical and Electronics Engineers, 37–41.   
Davis FD, Bagozzi P and Warshaw PR (1989) User acceptance of computer technology: a comparison of two theoretical models. Management Science 35(8): 982–1003..   
Feak CB (2012) ESP And speaking. In: Paltridge B and Starfield S (eds) The Handbook of English for Specific Purposes. Malden, Ma: John Wiley & Sons, Ltd, 35–53.   
Gu L, Davis L, Tao J, et al. (2021) Using spoken language technology for generating feedback to prepare for the TOEFL iBT $^ \mathrm { \textregistered }$ test: a user perception study. Assessment in Education: Principles, Policy & Practice 28(1): 58–76..   
Hafner CA and Miller L (2018) English in the Disciplines: A Multidimensional Model for ESP Course Design. Abingdon, Oxon; New York, NY: Routledge.   
Hafner CA and Pun J (2020) Introduction to this special issue: English for academic and professional purposes in the digital Era. RELC Journal 51(1): 3–13..   
Hockly N (2023) Artificial intelligence in English language teaching: the good, the bad and the ugly. RELC Journal 54: 445–451..   
Kim JY and Heo W (2022) Artificial intelligence video interviewing for employment: perspectives from applicants, companies, developer and academicians. Information Technology & People 35(3): 861–878..   
Langer M, König CJ and Krause K (2017) Examining digital interviews for personnel selection: applicant reactions and interviewer ratings. International Journal of Selection and Assessment 25(4): 371–382..   
Mahboob A (2014) Meeting the challenges of English-medium higher education in Hong Kong. International Review of Applied Linguistics in Language Teaching 52(2): 183–203..   
Ng DTK, Leung JKL, SKW C, et al. (2021) Conceptualizing AI literacy: an exploratory review. Computers and Education: Artificial Intelligence 2(1): 100041..   
Stokes J and Jarvis A (2024) Integrating blended learning into large-scale English for academic purposes courses. In: Wong LLC (ed) Best Practices in English Teaching and Learning in Higher Education Lessons from Hong Kong for Global practice. Abingdon, Oxon; New York, NY: Routledge, 103–118.   
Suen HY, Chen MYC and Lu SH (2019) Does the use of synchrony and artificial intelligence in video interviews affect interview ratings and applicant attitudes? Computers in Human Behavior 98(1): 93–101..   
Suen HY, Hung KE and Lin CL (2020) Intelligent video interview agent used to predict communication skill and perceived personality traits. Human-centric Computing and Information Sciences 10(1): 1–12..   
Tippins NT, Oswald FL and McPhail SM (2021) Scientific, legal, and ethical concerns about AI-based personnel selection tools: a call to action. Personnel Assessment and Decisions 7(2): 1–22.