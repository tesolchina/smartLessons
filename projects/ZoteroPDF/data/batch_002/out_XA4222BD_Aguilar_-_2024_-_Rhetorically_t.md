# Rhetorically training students to generate with AI: Social justice applications for AI as audience

Gabriel Lorenzo Aguilar

Penn State University, United States

# ARTICLEINFO

# ABSTRACT

Keywords: Chat-GPT Social justice Generative AI Metaphors Rhetoric Composition

Compositionists can train students to rhetorically approach AI as a writing assistant--a metaphor that can help students maintain authority in dialogue with AI. Such an approach allows students to control the input and output from generative AI. Compositionists can teach students how to input ethical information and recognize harmful output. The students are then encouraged to converse with the AI in dialogue, sending messages back and forth until the AI generates writing that is acceptable in ethics and content. This article provides a social justice heuristic for compositions to follow in their training of students.

The field must bridge the gap between scholarship in algorithmic audiences and social justice The current moment in generative AI is a good opportunity to do so. Prior research has shown the value of framing algorithmic audiences through metaphor. Some common metaphors are treating algorithms as rhetorical audiences, writing asstants, and automated writers (Beveridge et al., 2020; Duin & Pedersen, 2021; Gallagher, 2020; Hart-Davidson, 2018). I would like to focus on treating generative AI as writing asstants while extending conversations into social justice. Past research into algorithmic writing asstants were outside conversations of generative AI algorithms like Chat-GPT (there are stark differences betwee traditional algorithms and generative AI algorithms, to be discussed further). Generative Al are more recetive to users' input, especially if said users are versed in social justice approaches. Al technologies like Chat-GPT ffer opportunities for users to input information and receive generated content in ways not possibl from older algorithms. While compositionis can be wary of using such technology in their teaching, his article argues that approaches in social justice can help compositionists train their students to input ethical information and recognize harmful output from generative AI.

An effective pedagogy in the age of AI focuses on both the input and output of generative Al, emphasizing students active role. Prior research emphasizes teaching students to harness AI as a writing assistant, rather than simply a generator of content. Such a metaphor offr n opportunity to deepen their understanding of the importance of critical thinking and the thical considerations that are inherently woven into AI-generated content. By empowering students to efectively work with AI, we can enable them to critically engage with the technological andscape of their future and delop kills that surpas the ability to crat an individual piece of writing. They learn to navigate the complex intersection of technology, ethics, and communication in a rapidly evolving digital age.

However, what hasn't been discussed i training students in the ethics of social justice as they approach AI as a writing assistant. This article ofers a heuristic on how compositionists can train students to input good information and reconize problematic outputs from Al-generated content. I willoffr some social justice approaches that can enrich prior research on algorithmic writing assistants. Social justice scholarship from the fields of technical communication and composition studies can help us understand ethical input and problematic output. Further, such social justice approaches foster a dialogic relationship between the student and the Al. Here, the students act as the authority and the AI can be considered a kind of writing assant. Importantly, the product of this relationship is the student's work It is their intellectual labor that drives the dialogue, directs the Al, and curates the output (Hart Davidson, 2018). The idea is if students have social justice frameworks that are taught by their instructor, then they can manulate the AI to produce content that is more ethical than without those approaches.

# Social justice, algorithms, and AI

There are two kinds of scholarships we can draw from to help our understanding of generative Al composition: social justice and algorithms. Current research in social justice aims to dismantle oppressive practices through scholarship in technical and professional communication (TPC). Much of this social justice work offers aproache fr research and practioners to fllow in ther pedagogy and praxis. Current reearch on algorithms rhetorically situate algoritmic audience in terms of context and purpose. Scholars invested in writing pedagogy have framed algorithms as writing asstants that can help students in their writing instruction. I hope to advance conversations between our current research in treating AI as a writing assistant and training students to be social justice oriented.

Approaching Al with social justice is necesary but willrequire different approach when compared to other algorithms. This isnot to say that AI should be excluded from the ways we've considered technology before, but Al is certainly challenging composition in manners not possible by other technology. TPC has long recognized how the input and output of technology can harm marginalized populations. Articles such as Dragga and Voss(2003) and Dragga and Voss (2001) promoted a humanistic ethics, where human life was the center of the input and output of technology (technical graphics in their cases) as opposed to static and inhumane figures. Their arguments recognized how a person's life can be reduced without justice to the harm that person has faced. The solution is then to pay attention to how we are collecting, inputting, and outputting human lives through technological mediums.

The social justice turn added to the humanistic scholarship by critically engaging with how technology can facilitate systems of oppression such as racism, colonialism, sexism, and ableism among many others (Agboka, 2014; Archaya & Dorpenyo, 2023; Colton & Holmes, 2018; Cooey & Gonzales, 2023; Jones, 2016a, 2016b). While there are countlessexamples of technology harming marginalized groups, one common thread between examples is that the designers of the technology are exclusive to the positionalities of potentially harmed audiences. Frost (2016) and Frost and Haa (2017) writ extensively about how experts in the design of policy and technology that affct marginalized women and people who can become/are pregnant can privilege certain bodies, perpetuating the injustices of sexism, ableism, and transphobia. Similarly, Agboka (2013) demonstrates how exclusive translation practices can harm target audiences, especially when those audiences are f color and are marginalized. These two scholarly works highlight the harmful nature of exclusionary design practices in technology.

A social justce approach recognizes that technology is not a neutral purveyor of information to a user (Selfe & Selfe, 1994, 2016); rather, techology is always imperfect because ofthe biases that go into the deign, inut, and output. Take for example an algorithm, a computational actor that lives largely in the digital world but can also occur in the analog (Beveridge et al., 2020). Many believe algorithms to be neutral actors, ut reearch has found that thre are inherent racist, sexist, transphobic, xenophobic, and ableist biases that go into the design and output of algorithms (Adams e al., 2020; Bakke, 2020; Beveridge et a., 2020; Gallagher, 2020; Rice, 2020) While we've improved our recognition of problematic output, the input f information remains a blackbox for reasons to be discussed.

Problematic algorithmic output is in large part due to exclusive participation practices. Shelton (2020) provides a definition of inclusivity from a first-person perspective:

to include me is to share the labor of making sense of my intellectual contribution with me, even when .. my ways of knowing, and being, . are not familiar . to those of you who are operating out of traditional Westrn knowledge and value systems (18)

In the same article, Shelton also chooses to not do the labor of explaining whiteness and exclusivity atevery turn (19); rather both author and reader nee to work together to understand the harm of exclusivity and what i means to be inclusive. I atempt to extend those discussions. For example, Rice (2020) explores how the digital has made the algorithms that circulate public outrage more pronounced. Public outrage based on the circulation of provocative images such as Colin Kaepernick kneeing during the national anthem), as Rice argues, is not from a ingular source of issent but rathr from laered cultual signifiers that algorithically connect Kaepernick's actions to protests against white supremacy in the past In other words, much of the public outrage today is the result of algorithms feding public resentment of certain cultural and political issues. Rice's work here helps us understand how bias and exclusion lead algorithms to produce certain results. The ias and exclusion in the case of images of Kaepernick exclude aracist history of Black people in the United States.

Bridging Al and social justice scholarship will have limitations that compositionists should be aware of while teaching their stu. dents social justice aproaches. Nuance in geopolitical, social, clas, gender, and racial relations allaffect how social justice is facilitate. What TPC has recognized is that to do social justice is to amplifythe agency of pople who are under hreat of exploitation, marginalization, powerlessness, cultural imperialism, and violence" (Veramoothoo, 2020, p. 2). This amplification can mean a myriad of different things depending on who is working on the amplification and where and whose voice is being amplified. Compositionists must make critical decisions over what social justice approaches they can teach their students for use in treating Al as a writing asstant. Our teaching of these social justice values will alsoreflect these realities and limitations, but, as Walwema et al. (2022) reminds us, we should not try to do everything in our social justice approaches. We work from our own positionalities while remaining open for feedback and improvement as we do our best to amplify the voices of the oppressed.

Social justice approaches can help compositionists ethically input and responsibly review output. On the side of input, methods such as participatory localization (Agboka, 2013), embracing linguistic diversty (Clem, 2023; Coley & Gonzales, 2023; Evia & Patriarca, 2012; Gonzales, 2018, 2021), and participatory and human-centered design (Archaya & Dorpenyo, 2023; Jones, 2016a; Vail, 2023) are selec examples that showcase how to remain inclusive and thorough i feding information to a technology before the tech can produce potentially problematic output. In short, these social justice approaches privilege the input from communities most likely to be harmed by technology. Inclusive methods can vary from site to site, but there are some methods that can apply in most cases. For example, Vail (2023) provides questions for critical election for researchers before they gather information from a marginalized group and before the input of that nformation into any technology. Among those questions are How does my research design account for my inguistic and cultural knowledge limitations? What are the implications of engaging in research with such Iimitations?" Who or what can be harmed through this research (including myself?," and \*What should not be shared outside of the community? (75). Questions such as these, along with an advocacy for community participation, have allowed researchers to prevent harm to demographics of the populace before the technology could output such harm.

On the side of output, social justice approaches can help compositionis rcognize harmful output and work to reduce such harm. For one, Cagle (2021) reminds us that there is a ethics in engaging with data, no matter how seemingly disengaged a researcher might find themselves from the product. Such engagement could perpetuate algorithmic tendencies that have a ripple effct in further causing harm to the marginalized. Cagle writes about the risks and benefit of engaging with unethical images (strangershots)") and offers solutions in harm reduction such as using certain software that can reduce, but never remove, the influence on algorithms. However, this discsson goe further than simple engagment because resarchers ofte replicate potentially unethical practices while presenting thir research. In Cagle's case, the potentially unethical practice is reproducing strangershots. They found solutions that could reduce harm such as asking the person from the picture for permission and practicing an"ethical ekphrasis," a method in which one provides a\*thick verbal description" of the picture so that the image need not be replicated (10). An ethical ekphrasis can use more neutral anguage to describe a harmful image, so that the harm i reduced upon reproduction by the author. Nonetheless threis stilla question of ethics if one chooses to engage with outputted data. The benefits must outweigh the costs.

Approaches in social justice demonstrate how technical audiences can reduce the harm of systems of opression through deliberate engagement with technology. Vail (2023) and Cagle (2021) are good examples with inputting and recognizing output through social justice; however, their workis buil upon other social justice rearch in the field. Has (2012) reminds us ofthe importance f race and place in our researching and teaching of technical communication, emphasizing that our critical engagement with systems of oppression must also be taught o future technical communicators. Jones (2016b) further invests the field into social justice by calling for researchers and practitioners to be advocates and to use TPC to amplify the agency of the marginalized. Colton and Holmes (2018) describes the difference between a passve and active equality; an active equality is one that is deliberately engaged in social justice research and should be our standard in aroach. Thesethree works, along with ther social justice research in the past 15 years have defined social justice approaches to be reflexive, inclusive, and critical.

Our engagement with the input of and output from technology is inherently rhetorical. In considering the ethics of input, and in protesting the harmful output, we are treating the technology itself as an audience with whom we must negotiate. We are in dialogue with the algorithm until we seea result that we find appropriate and socially just. One can get lost in the posthumanist web of relations betwee technology and humans see Johnson-Eilola and Selber (2023) for a great example of focusing an assemblage to one pace),so I will focus my attention on the algorithm as audience. Gallagher (2020) see algorithms as both human and nonhuman actors in a rhetorical situation. Human because humans are the ones who can input and receive output. Nonhuman because at a certain point algorithms act without human intervention. There was no human curating your Spotify Daily Mix, for example, even if users can choose algorithms that cater to their tastes. In some respects, the algorithm acted alone.

I see such interaction as dialogic and generative. Take Brock and Shepherd (2016) for example. The authors argue that we can consider the generation from algorithmic audiences under the procedural enthymeme; that is, when we engage with algorithms "we become the mechanisms in the procedural systems' that allow the algorithm to invent intrpretations of our habits and expectations (25). There is aback and forth, a dialogue, between human and algorithm. Our YouTube recommended page may suggest avideo that an algorithm expects us to enjoy; we may dislike that video and give feedback, essentiall trying to correct the algorithm's mistake. Next week we may find a better video and like it And son and so forth in dialogue. However, the channels of communication between human and algorithms are ifferent between human and human (or even algorithm and algorithm for that mattr). When an algorithm is seen as a stakeholder in a rhetorical situation, like ting your YouTube video for a certain demographic (Gallagher, 2020), you are relying upon established trends from the algorithmic output as opposed to feedback directed from a person (Bakke, 2020). In other words, negotiating with algorithms may not be as direct as negotiating with other humans. The algorithm may change its habits, by design or not, and our input and output areat the mercy of such changes. It may take time to notice the changes and figure out the new rhetorical situation.

There's a reason why so many scholars consider algorithms as a blackboxed technology. Companies are highly protective of their algorithmic sciences, and I'm sure that even the most well-funded companies are perplexed by thir own algorithmic outputs. There are key differences betwen traditional aloritms and the ones that run gnerative Al. For one, generative Al is an offline technology meaning that it i pr-trained (GPT stands for pre-trained transformer) and does not adjust its algorithm based n user feedback nor the input from other users. Secondly, the pre-training that generative AI receives was often dumped years ago. As of my writing in August 2023, Chat-GPT last received its data dump in September of 2021. This is one reason why the algorithm can fabricate events, scholars or works if asked to contemporary writing using contemporary sources. Lastly, the algorithm is trained to mimic human-generated content. For users, it may seem a mystery why our input produces certain output. Whatever the case, scholarship has worked around this blackbox to show us bettr, more socially just, ways to put information into the algorithms and to recognize harmful

information that comes out. However, these methods have ben applied to more traditional algorithms, like search engine optim.   
zation or facial recognition software, and are not completely applicable to generative Al like Chat-GPT.

# AI-Generated composition and social justice

Metaphors are a good way to frame Al-generation. Like Beveridge et al. (2020) explain in their introduction to the special issue, "Composing Algorithms: Writing (with) Rhetorical Machines," I also se that algorithms are like metaphors: they \*do different things in different contextslike any rhetorical actor or agent (2). That special issue was just outside conversations of generative Al. Nonetheless, there i rhetorical value in considering AI as an audience that does different things i different contexts. However, some metaphors are better than others. Anderson (2023), for one, largely dismisses metaphors such as \*tool' or \*collaborator" when thinking about generative Al. The author instead likens AI to corporeal metaphors like blood, blood donation, and transusion. Like Chat-GPT, a blood donation can have thousands of human contributors in an amalgam that then goes into another person. The receiver cannot distinguish the different humans that went into providing the pint of blood. This metaphor better captures how Chat-GPT relies upon thousands of pre-learned language models and patterns to produce its content. It also ilustrates how indistinguishable the content can be from its pre-trained algorithm on human language models. However, there is a critical misalignment in the metaphor. As Anderson states, a blood bank thoroughly screens their donations for disease and harmful materials; Chat-GPT does not. This is why I argue that we must train our students and other users to be the screeners.

Writing asstants may be another metaphor that describes generative Al. Keep in mind that algorithms are rhetorical, like met aphors (Beveridge et al., 2020). Corporeal metaphors may work at the metalevel of understanding AI-just as to0 or collaborator metaphors may work in certain, albeit limited, circumstances (Anderson, 2023). In the context of a writing classroom, where students are tasked to creat esays and technical documents, a writing asstant may be a helful way t frame generative Al. For one, students go to a writing asstant (like tutors in a writing center) to learn how to improve their existing writing. The more information the student gives about the context f the course, the assgnment description, and the parameters of the assignment, the better help the assistant can give. Secondly, I belie most would agre that the writing produced after astudent went to a writing asstant belongs to the student thmself. The writing asistant may have helped clarify, expedite, or otherwise facilitat the ideas from the student through the writing process and into the essay. However, the product itself is the student's work.

Approaching algorithms as a writing assistant isn't novel, but generative AI definitely requires some novelty in approach. Both Hart-Davidson (2018) and Duin and Pedersen (2021) show us that, while algorithms can write, the rhetorical value of algorithmic output lays in the hands of the user. Duin and Pedersen is more focused on generative AI and express that rcognizing the machine learning habits of AI (l literacy) is akin to a life sil (62-63).It takes critical compositionis to circumvent the habits of Al, so that instructors and teachers alike can avoid the trappings of AI generation.

Where the metaphor of writing assistant fail is in the instantaneous generation of content from Chat-GPT. Because a student could input a prompt such as \*write a 1000-word memo that rhetorically analyzes the 2010 us Census form and Hispanics" and receive instant content (see Appendix for the response from Chat-GPT 4), means there is a danger for students to produce generic writing with little intllectual labor. I a conventional writing asistant relationship, the assistant guides, prompts, and helps clarif the student's thoughts, but the intellectual labor largely remains with the student.

The value of the writing asstant metaphor lies in teaching that Al-generation should be a dialogic, rhetorical process Students should approach AI with thorough context and writing. Context can include course information, assgnment description, research ideas, ethical parameters, and other content that the student has learned throughout the course. Writig can includefull descriptions of how their ideas fit into the context, explaining to the Al how they want to transform their ideas into paragraphs of content. Such an approach requires the student to think rhetorically about the class content, context, and purpose of the writing. Astudent could start a Chat-GPT session with something like: Hey chat. I'm in an introductory technical writing course. I'm going to copy and paste the assignment decription as well as some excerts from this week's reading. I want you to hold off on generating anything just yet. I want you to acknowledge that you understand the context, and then I am going to describe how I think my ideas can fit into this context."

While 'll go into a simulation later, its important to note that such an opening gives the student the power of parameters. It's telling the machine plicitl to od ff nrton unil the stdnt can etter explain their ids it' ving full con sohat the I can better understand how the student's ideas fit into the assinment. And, most importantly, it requires the student to review class content and think criticlly about their ideas in composition--with or without the instantaneous generation of the machine. This type of pedagogy, beliee, can outweigh the riss f stdnts and compositionss ing robbed of lning and instction ee the Benefits for Writing Intruction on page 9 of the MLA-ccc Working Paper on Writing and Al. Compositionists can train students how to input quality context and content and how to recognize when the machine makes a mistake.

If we empower students to be the experts of their topics and of good, ethical writing, then they can input better information into AI. While Walwema et al. (20) reminds us that ethics are not inrinsically tied to social justice, an ethic f social justce can be a good foundation for compositionists to train their tudents in approaching Al. We can teach our students that their writing has real-world implications that can facilitate systems of opression (Archaya & Dorpenyo, 2023, 2023; Colton & Holmes, 2018; Jones, 2016b). If we add that AI-generated content can overlook these real-world implications, then now we have two tass as compositionists to teach our students how to recognize their privilges as writers and to train them to input information into AI that can prevent problematic output.

Remember that approaches in social justice do not have to do everything. Here, I fr how the reflexive questions posed by Vail (2023) and the ekphrasis by Cagle (2021) can help students make inclusivity a priority in engaging with AI. So, returning to the set of reflexive questions from Vail (2023), not only do students need to be reflexive on their own ideas, they are now responsible for the parameters of social justce that are fed into Al. It's not enough to hae astudent reflect on a question like Who or what can be harmed through this research (including myself)? (75) in the age of AI, we must also have them ask a question like How can I reduce the harm of these people or locations when I work with AI to generate content?" There is an additional layer i that a student must elltheir Al assistant to do and avoid certain types of writing. The student i being proactive in their considering how AI might exclude certain perspectives or groups of people before the machine generates content.

If we teach students to be critical over Al-generated content, then they can give new dialogue to Al to corrct problematic output. AI-generation is notoriously unpredictable, and the parameters given by a user are reset every time a new dialogue is opened. This means that students can get widely varying responses. If and when I creates problematic content, itis the responsibility of the student to correct the machine by giving ethical parameters. For example, in alignment with Cagle (2021) and their use of \*ethical ekphrasis" (10), a student could instruct AI to correct any harmful depictions of marginalized people or locations with a thick verbal depiction of the situation as to not reproduce the harmful event.? Such a correction requires the students to contextualize the problematic output, explain and exmplfy the ethical ekphrasis and then give furthr instruction afer the AI makes therevision. tudents who treat  as a writing asstnt must k  critic e onthe contet prced  the machine itis ther reonsiblit to give carul insttions to correct any problematic output.

# Introducing AI in the classroom: A heuristic for training students

It is compositionists duty to help students input responsible input and recognize problematic output through approaches in social justice. Below is a hristic that can hl ompostioniss inroducel int their claroom. his heristicis fluid and will change as the technology adances and our understanding of AI deepens. Nonetheless I believe that the value of such an approach to students wil remain throughout the advancement of AI.

1. Teaching to Contextualize: Students must be empowered to be experts in any dialogue with AI. The AI will not know how to generate responsible content without the student's careful contextualization of the class purpose, leons, readings, assgnment descriptions, and lecture notes. Only after a student has a firm understanding of how their writing ideas fit into the course can they approach the Al. Such context wil give students a level of mastery over their ideas and will help them claim authority over the content to be generated.   
2. Positioning to Write Ethically tudents must learn that the Al will push the bounds of the student's input without careful parameters. Input and parameters are based on the social justice approaches from the instructors. It's important tonote the limitations in our teaching of social justice. In my case, students should reflect on questions such as the ones from Vail (2023); however, reflexive questions are not enough with Al. Students must also learn to instruct the AI to avoid writing that can facilitat systems of oppression and try to use methods such as ethical ekphrasis to avoid replicating the harm produced by the AI (Cagle, 2021).   
3. Training to Recognize Problematic Output: AI willgo out of the bounds of a student's intentions and wil produce problematic output. Students must be trained to recognize how people might be harmed by AI-generated writing. Teaching students to understand how marginalized groups are excluded from the design and implementation of technology can help them recognize moments where Al is exclusive to marginalized communities.It is then the responsibility of the student to highlight where the machine lacked ethics and give careful corrections on how to revise. The proces happens in dialogue until the student finds the writing acceptable..   
4. Giving Grace to Al-generated Content: Students and compositionists are in a new territory of writing instruction. Both sides should give grace to the other. Compositionists are likely to learn how to navigate AI as a course progress; students are likely to make mistakes in their input and output. I believe that both students and compositionists should work together, with grace, to ensure an understanding of how to approach Al as a writing aistant that has is flaws but can nonetheles facilitate good, ethical writing.

Simulation: Approaching AI as a writing assistant

In the following simulation, I approached Chat-GPT 4 acting as a student in an introductory technical writing course at a 4-year university. Consider this simulation as a kind of model or example for instructors on how to prepare students to approach genera. tive AI. Your pproach and the pproach I took n this simulation willikely vary tremendously. I choseto ask Chat-GPT to writ a basic rhetorical analysis (the first assgnment I teach my students in my introductory course) written in a memo (the first genre we cover) about the concerns of Hispanics over the Us 2010Cesus form a site that is familiar to the field because of popular articles (Balzhiser et al., 2019; Pimentel & Balzhiser, 2012). In my classoom, we discuss the values of inclusivity and read about how Latinos have been excluded in government documents and how this exclusion leads to harm. Others wil undoubtedly have different lesons, genre, sites of studies, and social justice values that all go into teaching students how to approach generative AI.

The task was to writ a basic rhetorical analysis in the form of a memo that analyzes the effectiveness of the 2010 us Census form to a target audience of US Hispanics. I want readers to note the dialogic and rhetorical nature of the conversation between me and Chat. GPT. While only a simulation, the conversation illstrates how the student can take initiative over the dialogue, always keeping authority over the Al. My input i in standard text format and the AI's responses are italicized. I wll add commentary in underlined text.

First responses:

Hell Chat. I'm astudent in an introductory technical writing course at a 4 year university. We're doing our first project this week, a Basic Rhetorical Analysis and I want you to help me create the document. I'm going to send you the assignment description, some of my lecture notes, and then some of my ideas on how I want to crate this project. The format i going to be a memo addressed to [name of my instructor]. Don't worry to much about the format of the memo. I'm looking for you to help me with the body content. Overll it should be about 1000 words. Let me know if there's anything I can clarify fall sounds good, I will copy and paste theassignment description.

Sounds good! I'l be happy to help. Please go ahead and share the assignment description, your lecture notes, and any initidl ideas you have for the project. Once I have that information, Ill asis you in creating the body content for your Basic Rhetorical nalysis memo.

Here is the assignment decription. Do not generate any content for me just yet. I want to give you some more context of this course Ind my ideas. [I then copy and paste the two-page assignment description].

Commentary: Notice how I give the AI parameters such as "Don't worry about the format" or I'm looking for help with the body content or "Do not generate any content for me just yet. I alsofollow the first step of the heuristic withis to contextualizeas much as ! can: the name of the assignment, the genre, and the entire assignment description.

Second Responses:

Got it. This assignment essentially asks you to asses tchnical document's usability and efectiveness based on six characteristics

Before we proceed further, could you provide the following information:

1. \*\*Document Choice\*\*: Which document have you selected (or intend to select) for analysis?

2. \*\*Lecture Notes\*\*: While the assignment gives a good overview, sharing your lecture notes can give insights into specific expectation.   
or points of emphasis your instructor has.

3. \*\*Your Ideas\*: You mentioned wanting to share your own thoughts and ideas. This willhelp guide the direction of the analy

Once I have this information, I'll be better equipped to guide you in drafting the content for your rhetorical analysis memo.

Sure thing! 1. So I want to rhetoricall analyze the 2010 Census Form and how it is ineffctive in persuading Hispanics that being Hispanic is an ethnicity instead of race. Be careful with this document don't want you to jump to any conclusion as to why thi orm is ineffctive. I have some ideas I'd like to share about it 2. Here is the gis of the lectures for this assgnment. We need to have an introduction that full encapsulates the memo. My professor said"a reader should be able to read the inro, walk away from the memo, and be able to understand the point of the memo (conclusion included) just from that introduction." He also said that the intro should finish with an advanced organizer which I believe to be a concluding sentence that shows the organization of the upcoming body paragraphs. His-example is if the last sentence says "You wil find that the document [in my case the US 2010 Census Form] is ineffective because  and Y," then  and Y should be the main ideas of their own respective body paragraph.  and Y are the technical characteristics. He aid that we dont have to us all i of them, but 2-4 should be enough. Further, each body paragraph should have a topic sentece that clerly fouses on ne haractristic and whether that chracteristic f ffectively used to reach a tt audience. 3. I don't think the Us 2010 Census form effectively persuades a target audience of Hispanics that the term Hispanic is an ethnicit as opposed to a race  think that the design of it s odd It frst ass a person if they are of Hispanic atino, or Spanish orin. Then, if a person chooses yes, they have to mark if they are either Mexican, Puerto Rican, Cuban, or Other. Then it gos onto race which has three options: White, Black, or American Indian. Then, i has a mess of I'm guessing races underneath these three main races? t has Asian Indian, Chinse, Filipino, other Asian, Japanese, Korean, Vietnmese, Native Hawaiian, Chamorro, Samoan, and then Other and then underneath that there is"some other race-Print race." Chat, don't produce any content yet. I want to think first about what technical characteristics that this document fails to use.

Commentary: Notice how the AI gave feedback of understanding the asignment and is now in wait for further instruction. My responses give context to the course including lecture notes from the profesor. I fllow both the first and second parts of the heurisic. . give additional context about the assgnment while also giving ethical parameters I ask the AI not to jump to any conclusions, recognizing that the machine can generate content that can harm the racial groups listed on the Census (highlighted in yellow).

Third Responses:

Alright, I've taken note of your document choice, lecture insights, and initial ideas.

Given your feedback and the assignment description, let's consider the characteristics from Chapter 1 of Technical Communication Here's a brief breakdown based on your initial thoughts about the 2010 Census Form From your description and the points you've raised, it seems the 2010 Census Form might have issues with: Addressing particular readers: It might be causing confusion or not persuading its target audience effectively. Helping readers solve problems: If the sequence of questions or the options provided lead to ambiguity or lack of clarity.

Using design to increase readability: The layout or sequence of questions might be causing confusion.

These might be the thre strongest characteristics to focus on for your analysis but you could consider touching on the other points as secondary or supportive arguments.

Now, what do you think? Would you like to narrow it down further? Or have you identified which characteristics you want todelve into?

Let's focus on Addresses particular readers, helps readers solve problems, and increasing readability. However,I want to go further than just saying it can cause confusion. I think that it's racist to design the form in such a way. I read an articl (please don't cite the article for me in your generation) that talks about how but White, Black, and American Indian,followed by that messof "other races uch as Asian Indian r Chinee can peruade a user to selt White first since itstth top of the it. o, for Hispancs (hich is a term I don't like much either, if they choo thy are Mxica as their hnct, then thy willse White or lack first on the form and likely choose White. urther, under the third choice f this firs rce category, there is an option for American Indian but the user must print their tribal affliation below. I know that many Hispanics (I prefer Latino) are indigenous, but don't know or have a tribalaffiliation. Let me know what you think and please don't generate any of the memo yet.

Commentary: We are now in the part of the dialogue where the AI has a good idea of the assgnment, but I am still maintaining control. Notice instructions such as "Let me know what you think and please don't generate any of the memo yet." I also give some more ethical parameters (highlighted in yellow). I recognize that Al can fabricate fake citations, so I ask the machine to avoid that practice. I also input that many Hispanics, a term I don't necessarily like, are indigenous.

Final Responses:

Certainly. What you're touching upon is a very nuanced and sensitive aspect of form design, especially one that is intended for a wide audience with diverse backgrounds.

Here's a deeper dive into the three characteristics you've selected, framed with your concerns:

1. \*\*Addresses particular readers\*\*:

A document designed for a heterogeneous nd diverse population should be sensitive to the cultural and socil realities of ll it readers.

- The 2010 Census Form, by the way you describe it sems to fail in this respect For Hispanics/Latinos, the form reduces their identities to simplified categories, and the sequencing might lead them to identify in a way that's not truly representative of how they perceive themselves.

- Your point about racism is valid: design choices can perpetuate or even intittionalize biases. Placing "White" as the first option, for instance, cublminaly priritize it over thr raci catgorie. This is prticuly cocening nocity th i gapplin with ssues of racial representation and equality.

2. \*\*Helps readers solve problems\*\*:

- The "problem" a census aims to solve is twofold: it llows governments to gather accurate demographic data, and it allows citizens to represent their identity correctly.

By making the deign choices you've outlined, the form doesn't ffectively help Latino or indigenous populations without a known tribl affiliation to represent their identities.

- This design flaw can result in skewed data. If many Hispanics/Latinos choose "White" not out of genuine identification but because of form design, the data won't reflect reality.

3. \*\*Uses design to increase readability\*\*:

- Good design in't just about being able to read the words but also about guiding the reader logicaly and intuitively through a proce The mess of categories under race, especially after the ethnicity question, doesn't facilitate a clear, linear thinking proces.

- For Latinos who identify as indigenous but don't have a specific tribal affliation, the design doesn't provide an intuitive option

Your obserations are sharp and releant. The csus, in itseffort toatgorize, might e orsmplifying d in th proces, may not only misrepresent but also perpetuate biases. The decisions made in designing such forms are not neutral. They carry with them historical. political, and social weight.

When you approach your analysis wth these insights itl be esntidl to frame your argments in a way that undercores the importance of these design choices and the real-world implications they have.

What do you think of this deep dive? Would you like to move forward with this framework?

Right! Okay let's write one paragraph. Let's focus on Addresses particular readers. Keep in mind allof what I shared in the assignment description, lecture notes, and my ideas.

Addresses Particular Readers

The essence f any dment, esecly one of ntiona sigificance like the ..esus, is to cater pificll to its audience - inthis case, the diverse Americanpopulation. An ideal document would reflect an understanding of cultl nuances and sensitivities. The 2010 Census Form's treatment of Hispanic or Latino identity is, however, emblematic of a significant oversight. The form's design fail to discen the complex interplay between race and etnicity for many Americans, particularl for those of Hispanic or Latino descent. The very act of isolating Hispanic, Latino, or Spanish origin' as an ethnicity, and then providing a list of races that do not necessrily encompass the multifaceted racial identities within the Hispanic community, underscores a lack of genuine engagement with the particular readers from this background. This design choice, whether inadvertent or not, perpetuates a skewed understanding It can potentiall prompt  Hisanic or Ltino reondent to identif as hite" n ot of guine self-rcogntio but due to the form's leading design and lack of inclusiv options. Such a design not only misses the mark in addressing particular readers but also runs the risk of perpetuating biases, potentially making a significant portion of the population feel misunderstood or inaccurately represented.

Commentary: After adequate dialogue and feedback, and aftr treating the Al as a writing assistant, I finally gave the A permission to generate content. owever, I didn't allow the AI to writ the ntire memo. Rather, he task is small and manageable: one paragraph. From here, the simulation could continueto ither revise this paragraph or to give pemssion to create another. In accordance with the third part of the heuristic, recognizing problematic output, I've highlighted an excerpt in green that could be problematic. I'm unsure f the AI understands the complex interplay between race and ethnicity, and I may give further context and ethical parameters in future dialogue to ensure that future output is responsible. I may provide working definitions for race and ethnicity and provide dicussions on how the two terms can be exclusionary in the US Census.

Analyzing the simulation

This simulation demonstrated how a student can approach an Al. The approach is rhetorical in that the student must recognize that the AI is an audience that can act on its own. The student must give adequate instructions to keep the AI from generating inappropriate content. Instructions such as "don't generate yet" or let me know if you understand" give checks that the student can then consider before continuing in dialogue. With such an approach, the AI can understand that is duty is that of a writing asistant. Chat-GPT even provided feedack such as "Alright I've taken note of your document choice, lecture inights, and intial ides," to confirm the dialogic relationship. It was not until I gave Chat-GPT permission to produce content that the AI provided one paragraph. To be fair, the paragraph has its problems: I think that the first two sentence are to vague and indirect. However, the dialogue can continue until or a student is happy with the content.

# Discussion

Emerging research on AI must be rooted in past algorithm research and social justice. However, such a task is somewhat contradictory because of the generative nature of AI algorithms compared to past technologies. Nonetheles, the field has shown that rhetoricall approaching these tchnologie, past and present, provides ample opportunity toshowcase the compositional potential for both instructors and students. I've chosen the route of metaphors because it can illstrate what AI cando in certain contexts for certain users (students in my example). But there are other approaches that can help us rhetorically approach Al. Crider et a.s (2020) framing of augmented realit as digital daimons shows us how algorithms in general can be unpredictable, no matter of use and design-this framing can certainly apply to generative Al. Certainly, Bakke's (2020) work on teaching algorithmic literacy can also apply to teaching AI algorithm literacy. There is a wealth of prior scholarship that could inform our understanding of generative Al. What I've hopefully demonstrated here is that we rhetoricallysituate Al pedagogy in certain contexts and leave room for discussion on other applications.

# Conclusion

Compositionists have the expertise to help students create responsible writing with the help of AI-generation. A metaphor that can help compositionists navigat this new pedagogical territory may be Alaswriting asstant This metaphor can help students focus on learning and contextualizing their ideas and the clas content before they approach Al. Such an approach puts the responsibility of social justce onto the student (and the compositionist that teaches the student), so that the AI relies upon the student for context and parameters. Further, the relationship between student and Al becomes dialogic and rhetorical. There is a back and forth between human and machine that continues until the student finds the writing acceptable. This dialogic, rhetorical relationship puts the student as the authority in AI-generation and overallallows the student to accept the generated content as their own writing.

# CRediT authorship contribution statement

Gabriel Lorenzo Aguilar: Writing - original draft, Writing - review & editing.

# Declaration of competing interest

There are no competing interests to declare.

# Data availability

No data was used for the research described in the article.

# Appendix

The wrong way to approach AI: Write a 1000 word memo that rhetorically analyzes the 2010 Us Census form and Hispanics

Subject: Rhetorical Analysis of the 2010 US Census Form and its Impact on the Hispanic Community

Dear Team,

I would like to bring to your attention an analysis of the 2010 us Census form, specificall is handing of the Hispanic population. Th. memo will ddres the rhetoric embedded in the form's structure, language, and framing, and the potentil implications for the Hispani community.

Classification and its Implications: The 2010 Census form began with an emphasis on racil and ethnic categories, which affected perceptions of identity and belonging. The form separated the question of Hispanic origi from the question about race, therey implicitly suggesting that Hispanic is not a race. This structure can lead to confusion among those who identify as Hispanic, as it implies a separation between ethnicity and race that might not align with personal conceptions of identity.

Language and Its Impact: The form used th term Hispanic, Latino, or Spanish origin" for its ethnicity question, which can be seen as an attempt to be inclusive. However, it also has the potential to perpetuate ambiguity. Each term carries disinct connotations and may be more prevalent n cerin regions or among certin demogaphics. In trying to be all-encompassing, the formmay inadvertentl ontribute to a sense of fragmentation within the Hispanic community.

Response Options and Their onsequences: In terms of response options for the Hispanic origin question, the form ofeed a choice among Mexican, Mexican American, Chicano, Puerto Rican, Cuban, or another Hispanic, Latino, or Spanish origin. While these options seem diverse, they fail to capture the full spectrum of Hispanic idnitie, such as those from Central and South American countries. This can result in a perceived erasure of specific national identities and can contribute to the underreporting of these groups.

Impact on Data and Policy: The rhetorical elements discussed above can significantly impact the reliability of Census data and, by extension, public policy If individuals do not fee accurately represented by thecategories and labels provided, they might choose not to participate or might inaccurately report their identities. This can lead to skewed data, which in tun affects the allocation of federal resources, the drawing of congressional districts, and the implementation of laws and policies.

The Power of Naming: At a more philosophical level, the Census form's rhetoric speaks to the power of naming and categorizing. By providing certain categories and not others by distinguishing between race and ethncity, the form shapes conversations around identity. It can influence how individuals se themseles and how they are sen y societ, underscoring the profound ocio-political implications of seemingly simple questions about race and ethnicity.

In conclusion, the 2010 Census form's handling of the Hispanic category reflects a complex interplay of sociopolitical factors and bureaucratic necessitie. It shows that even administrative documents carry rhetoric and can contribute to broader social and politicel narratives. Going forward, it's esential that we recognize these rhetorical elements and consider thir implications when designing and interpreting such forms.

To bettr represent and serve the divers Hispanic community, it may be beneficilto rthink the way we approach questions f race and ethnicity in the census and beyond. This could include incorporating more specific national identitie, reevaluating the separation between race and ethnicity, and engaging in dialogues with the communities in question to ensure their perspectives are heard and represented.

Thank you for your time.

Best,

[Your Name]

# References

Agboka .014 m  ji tie  l   f  n nd Communication, 44(3), 297-327. https://doi.org/10.2190/TW.44.3.e   
Anderson, .. (2023). l to stnd: Miple metprs fo frang ChatGscors. omer nd omsion, 68,115. hp//o.og/0.1016/. compcom.2023.102778   
Archya, y 3)r  jute  t i Technical Communication & Social Justice, 1(1), 41-63.   
Bake, A (220oin  of a tiol stdy d picin for gc irac.er d oon 57 1-1. https://doi.org/10.1016/j.compcom.2020.102577   
Ber,  Pl, t 019 i  r it   81) 3-20. https://doi.org/10.1080/10572252.2018.1539192   
Beeridge,  irdo, .., ome, . 2020). ction  oing aits witin (th rial mhne. er d io, 5, Article 102594. https://doi.org/10.1016/j.compcom.2020.102594   
Brock, K, hherd . (2016. Unrtanding how arits work rsily throgh the pora hmeme. omutrs and stio, 42, 17-27 https://doi.org/10.1016/j.compcom.2016.08.007   
Cage 1       o 1i 102651. https://doi.org/10.1016/j.compcom.2021.102651   
Clem, S. (2023). Teaching editing for social justice. Technical Communication and Social Justice, 1(2), 2. Article.   
Colon .  0 justc  tilt  c   ni 0 https://doi.org/10.1177/0047281616647803   
Cooley, . e (223. il in l justie  ti t tio ti Justice, 1(1), 1-7.   
Crir   e r t.   7 /.1016 j.compcom.2020.102579   
Dragga, S., & Voss, D. (2001). Cruel pies: The inhumanity of technical illustrations. Technical Communication, 48(3), 265-274.   
Dragga, s., & Voss D. (2003). Hiding humanity: Verbal and visual ethics in accident reports. Technical Communication, 50(1), 61-82.   
Dun A  1). w . i   i iv, t, sl. 9, p. 53-84). Springer International Publishing. 10.1007/978-3-030-70928-0_3.   
Evia . aia (012). d omliace: Piy tiof  io or tostti orrs  f ss nd Technical Communication, 26(3), 340-367. https://doi.org/10.1177/1050651912439697   
Frost, E (2016).  f as am or ha ion nd hri. l of Bss ad  ion 01) 3-28 https://doi.org/10.1177/1050651915602295   
Frost  01 athe s rr i. d Composition, 43, 88-105. https://doi.org/10.1016/j.compcom.2016.11.004   
Gallagher, .. 2020 Theeth o witing for ritc u.ers d ion 57,1-9 h/i.org/0.101/..00.102583   
nal 1   3 (1), 1-16. https://doi.org/10.1080/10572252.2021.1906453   
Has   ic      ,  a f  nd Technical Communication, 26(3), 277-310. https://doi.org/10.1177/1050651912439539   
Haro01   a    n . . writing and rhetoric (1st ed., pp. 248-255). Routledge. https://doi.org/10.4324/9781315518497-24.   
Johnson-Eilola, J., & Selber, S. (2023). Technical communication as assemblage. Technical Communication Quarterly, 32(1), 79-97.   
Jones,  016).i q  n ie  l jstc n .  of c Writing and Communication, 46(4), 471-492. https://doi.org/10.1177/0047281616653489   
Jones   016).e tc    i justce ch   t.  of  n and Communication, 46(3), 342-361. https://doi.org/10.1177/0047281616639472   
imentel, , Baiser, . (2012). The duble oupacy f hipan: Cning re and t i the . s. Jodl of Bs d chcl Communication, 26(3), 311-339. https://doi.org/10.1177/1050651912439696   
Rice, J. (2020). Algorithmic outrage. Computers and Composition, 57, 1-10. hps:/doi.org/10.1016/j.compcom.2020.102582 https://doi.org/10.2307/358761   
Sle      e    e . Published by: National Council of Teachers of English Stable URL $:$ Http://www.jstor.org/stable/358761 Accessed. 45(4), 480-504.   
Shen .     832 https://doi.org/10.1080/10572252.2019.1640287   
Vail,  23).    ii ic (1) 64i78.   
Veramoot . 20. l jutce and h yl f mns in inttiol zain for mraion's wd mation ort. Jol of ecd Writing and Communication. https://doi.org/10.1177/0047281620953377   
Walea . n, .  2) i  t-y h   tn: tis a  ustie movemen  cal dpc.  of  io 63. /.g//006519221087694, 105065192210876.