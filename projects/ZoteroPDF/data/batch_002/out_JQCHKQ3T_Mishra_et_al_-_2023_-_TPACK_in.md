# TPACK in the age of ChatGPT and Generative AI

Punya Mishra, Melissa Warr & Rezwana Islam

To cite this article: Punya Mishra, Melissa Warr & Rezwana Islam (2023) TPACK in the age of ChatGPT and Generative AI, Journal of Digital Learning in Teacher Education, 39:4, 235-251, DOI: 10.1080/21532974.2023.2247480

To link to this article: https://doi.org/10.1080/21532974.2023.2247480

# EDITOR’S INVITED PAPER

# TPACK in the age of ChatGPT and Generative AI

Punya Mishraa $\textcircled{1} ,$ , Melissa Warrb iD and Rezwana Islama

a Mary Lou Fulton Teachers College, Arizona State University, Tempe, AZ, USA; bCollege of Health, Education, and Social Transformation, New Mexico State University, Las Cruces, NM, USA

# ABSTRACT

The educational impact of Generative AI (GenAI) technologies, such as ChatGPT, has received significant attention. We use the TPACK framework to discuss the types of knowledge teachers require to effectively use GenAI tools. We highlight the qualities of GenAI that make it like other digital technologies (they are protean, opaque, and unstable) as well as qualities that make it revolutionary (namely, they are generative and social). We describe how these traits affect specific knowledge domains (TK, TPK, TCK, XK, and TPACK) and explore implications for educators. Finally, we argue for a more expansive description of Contextual Knowledge (XK), going beyond the immediate context to include considerations of how GenAI will change individuals, society and, through that, the broader educational context.

ARTICLE HISTORY Received 9 August 2023 Accepted 9 August 2023

# KEYWORDS

TPACK; generative AI; chatGPT; teacher education; ChatGPT in education; TPACK and ChatGPT

# Introduction

Generative AI (GenAI) has taken the world by storm. Over the past year, GenAI (including tools such as ChatGPT, MidJourney, Stable Diffusion, Bard, Dalle-E, and Bing Chat) have become part of everyday discourse (Angwin, 2023; Cardona et  al., 2023). There has been much hand-wringing— and some celebration—about the impact these tools will have on education (see, for example, Cardona et  al., 2023; Heaven, 2023; van Rijmenam, 2023; Murgia & Staton, 2023). Educators have been receiving mixed messages, and, not suprisingly, there is a great deal of uncertainty about what these technologies mean for teacher practice, teacher education, and student learning.

It is broadly within this context that we situate this article. Our goal is to develop a better understanding of the nature of GenAI technologies and provide guidance to teachers and teacher educators on their productive use for learning. As described in the Technological Pedagogical Content Knowledge (TPACK) framework (Mishra & Koehler, 2006), teachers need specific types of knowledge to use technology creatively and effectively in their teaching. The TPACK framework argues that knowledge for the successful integration of technology not only includes knolwedge of specific content, pedagogical approaches or technology but also requires a dynamic amalgam of all three. These knowledge bases exist in a “creative tension” with each other where changes in one affect the other two. The advent of GenAI presents new challenges to educational systems and poses significant questions about what learning means and what today’s teachers need to know to be successful. Thus, in this article we use TPACK as a framework to explore what teachers need to know to best integrate GenAI tools in their teaching.

There are two reasons we are centering our discussion of GenAI and education around TPACK. First, the TPACK framework has been one of the most generative, foundational ideas in the field of educational technology, having substantial impact on research. Research in this area has been supported by a thriving international community of scholars and practitioners from across content areas including, but not limited to, mathematics, science, social studies, music, history, and physical education. Moreover, this research has been conducted in multiple educational contexts and spaces, including K12, higher education, online, hybrid and in-person (Herring et  al., 2016; Niess et  al., 2018). The pace of research in this area has also been constantly expanding. Publications that used TPACK as a core framework for research rose from just 29 published pieces in 2008 to a total of 2,941 publications (1,984 articles, 29 books, 354 book chapters, and 574 dissertations) as of June 2023 (Judi Harris, personal communication, June 30, 2023).

Second, the TPACK framework has had a significant impact on the actual work that teachers do day after day. Both Shulman’s (1986) conceptualization of Pedagogical Content Knowledge (PCK) and its extension into TPACK emphasize the importance of knowledge in practice. Knowledge in this context is seen as a pragmatic, active form of knowing, consistent with how the construct is discussed by scholars such as Dewey (1934/1969), Dewey and Bentley (1949), Schön (1983, 1987) and Perkins (1986). In these conceptualizations, knowledge is similar to a tool that has been designed and adapted for a purpose—a form of “usable knowledge.” This makes it amenable for practitioners to apply in their specific contexts. As a result, the framework has become a staple component of teacher education courses and teacher professional development programs.

That said, it could be argued that TPACK is old news and that its wide use has led to the framework becoming essentialized and rendered somewhat meaningless. In other words, TPACK is now part of the canon, one more framework, and one more set of acronyms that teacher education students are expected to memorize and regurgitate. This is most evident when we see that students can purchase course assignment “reflection” papers about the framework from online paper-mills (for a fee of course), suggesting that the core ideas of the framework are fossilized rather than something we engage with intellectually, conceptually, and practically. And more crucially, rapid changes in technology (such as the rise of GenAI) raise questions about the relevance and the value of the framework itself. What does TPACK look like and mean in the age of GenAI? This article seeks to answer this question.

The structure of the article is as follows. After this introduction, we discuss the rise of GenAI technologies, offer key definitions of the concepts that underlie GenAI and review some of the current educational discourse around these tools. Next, we unpack the similarities and differences between these new technologies and other digital technologies, identifying key properties of GenAI technologies. This, we believe, is key to understanding how these tools will influence teacher knowledge, i.e., TPACK. More specifically, the next sections explore how GenAI changes both specific aspects of the TPACK framework as well as the framework overall. We conclude with an argument for a more expansive description of Contextual Knowledge (XK), going beyond the immediate context to include a consideration of how GenAI will change individuals, society, and the broader educational context as well as what GenAI means for teacher knowledge and practice.

# Introducing GenAI

GenAI refers to artificial intelligence (AI) applications which are designed to use a variety of machine learning algorithms to create new content (text, images, video, music, artwork, synthetic data, etc.). Although this content is produced in response to user input, these applications are not explicitly programmed to produce specific content. Rather, these programs learn and analyze rules and statistical structures from a large dataset and generate new content with similar structures (Bhatia, 2023; Ray, 2023). These outputs can be either in the same medium as the user input or a different one, for example text-to-text, text-to-image, image-to-video, etc. Examples of GenAI include ChatGPT, Bard, DALL-E, Midjourney and DeepMind.

A large language model (LLM) is a type of GenAI which focuses on text generation. These models are trained on enormous datasets consisting of billions of sentences (Bhatia, 2023; Ray, 2023). LLM’s can perform various natural language processing (NLP) tasks such as summarizing, translating, analyzing data, and making predictions. GPT-3 (Generative Pretrained Transformer 3) and GPT-4 are LLM’s developed by the company Open AI, an AI research and deployment company. These models are popular for their capability of creating realistic and contextual responses (Roose, 2022).

We believe that much of the current discussion of GenAI tools (in education and beyond) has been built on a fundamental misunderstanding of these technologies. GPT-4 and other forms of GenAI are often misconstrued as a replacement for search engines like Google, with the added benefit of being more conversational. However, these tools do not create an extensive archive of the texts used during their training, nor do they refer back to those texts when presented with a question. Instead, they operate as a concise and refined amalgamation of the information learned from those texts, formulating responses based on its recollection and patterns interwoven within the training data (Bhatia, 2023). This is what makes it generative and incredibly powerful.

# Current discussions about GenAI and education

Since ChatGPT3 was introduced in November 2022, the responses from educators have run the gamut, from consternation to excitement. For many educators, initial exposure to GenAI tools provoked fears of rampant cheating and plagiarism. A few educational institutions entered into a panic mode, worrying about how these tools would fundamentally undermine academic integrity and thus negatively impact student learning (Mills, 2023; Murgia & Staton, 2023). There were calls to block access to these technologies or even to ban them completely (Rosenblatt, 2023). However, given the wide array of developing GenAI tools, including their ongoing integration into standard productivity tools (such as Microsoft Office and Google Suite), a ban appears unlikely to work. Another defensive strategy has been to fight AI with more AI, i.e., create AI-based systems that check for use of AI, similar to popular tools like TurnItIn. However, these tools have been shown to have a low success rate, generating many false positives, which can result in students being falsely accused of violating academic integrity (Chaka, 2023; Mitchell, 2023). There are also numerous news stories of faculty who have failed to catch plagiarism or have falsely accused students of the same (e.g., Lonas, 2023).

Another major concern with GenAI technologies is that they have a propensity to make up stuff or “hallucinate” (Alkaissi & McFarlane, 2023), raising questions and concerns about the spread of misinformation (Cardona et  al., 2023; D’Agostino, 2023; Heikkilä, 2022b). The fact that this is not a bug that can be fixed, but rather an emergent feature steeming from the way these tools are designed, adds to the concern. Because GenAI tools are recreating patterns seen in the data they are trained on, they have no comprehension of truth (Weise & Metz, 2023). They will very confidently spit out fake information, including incorrect facts and made-up references. Furthermore, because of the black-box nature of these tools, it is difficult to identify when they are hallucinating and when they are reporting true facts (Chan & Hu, 2023).

Another important challenge regarding GenAI in education is that of equity in its accessibility, usage skills, and training data. For example, learners with access to these tools will likely have an advantage over those who don’t, exacerbating the digital divide (Gunkel, 2003) and leading to disparities in achievement (Chan & Hu, 2023). Perhaps more significantly, learners who develop proficiency in using the tools effectively will outpace their peers who have received no instruction or guidance in their use, a challenge often labeled as the “second-level digital divide” (Scheerder et  al., 2017).

Also of concern are biases built into the tools themselves. Because GenAI tools are trained on human-created discourse, they become a mirror of the biased views in our discourse (Ray, 2023). For example, experiments have demonstrated ChatGPT3’s tendencies to reproduce gender and racial bias (e.g., Snyder, 2023), raising questions about how GenAI technologies might perpetuate these biases. An additional ethical concern considers the ownership of the content the models were trained on and intellectual property rights of creators (Ethical guidelines on the use of artificial intelligence (AI) and data in teaching and learning for educators, 2022; Foltynek et  al., 2023; Moya et  al., 2023). For instance, these tools have been trained on human generated information (websites, blog posts, Reddit forums and more) with little or no attribution and acknowledgement given to the original authors and creators (Heikkilä, 2022a).

Despite these challenges, many have argued for the potential benefits of GenAI in education. Advocates of AI’s capabilities and its educational applications highlight its potential for personalized and differentiated learning, of offering real-time feedback and assistance as a non-human tutor and an aid to human teachers (e.g., Arthur, 2023; Herft, 2023). For example, there is some initial evidence that GenAI can help reduce teacher workload (Chan & Hu, 2023). In addition, it has the potential to improve accessibility for diverse students, create new avenues for creative expression, and help establish immersive and interactive learning environments (Baidoo-Anu & Owusu Ansah, 2023; Chheang et  al., 2023; Kadaruddin, 2023).

GenAI tools can also assist in the research and writing processes for learners, teachers, and researchers. For example, there are specialized tools that can assist in developing research questions, identifying related literature, and summarizing and evaluating research papers (FAQ, 2023). GenAI tools can also aid in tasks such as identifying research topics, generating hypotheses, and summarizing literature (Martin, 2023). Perhaps one of the most immediately visible benefits of GenAI tools are their ability to produce and revise text, allowing learners to focus on the development and expression of ideas rather than the mechanics of writing.

# Ameliorating the dissonance

The juxtaposition of the fears and potential benefits of GenAI can create a type of cognitive dissonance, leading us to a range of false dichotomies. The current discourse can result in psychological whiplash as opinions and perspectives see-saw between opposite points of view: these tools are horrible/amazing, we should ban/embrace them, they will transform our world for the better/worse, and so on. Clearly, what is lost in the debate is nuance. If anything, the history of technological change has taught us to be wary of such dichotomous thinking. Instead, we must go beyond the either/or options to more sophisticated and nuanced ways of thinking that both recognize the capabilities of particular technologies and how their impact can be mitigated by a complex array of systemic or cultural factors. Moreover, these tools are here to stay, and, as educators, we must recognize the role that GenAI will play in the future—a future for which we are responsible and committed to prepare our students for. We need to recognize that GenAI has unique strengths and weaknesses and is embedded with particular ways of thinking. These characteristics are inherent in the nature of the media itself and, thus, often invisible to the users. Thus, it is important for educators to understand the technology and the kinds of understanding and knowing that are best supported by it.

# TPACK and GenAI

The TPACK framework can provide a scaffold for considering what teachers need to know to use any technology effectively. It is important to note that the TPACK framework is not focused on any particular technology. What TPACK is about is the relationship between technology, pedagogy, and content. Thus, although the framework emerged out of a need to address challenges with digital technologies, the TPACK framework applies just as well to what we now consider simpler, analog technologies such as paper and pencil, traditional whiteboards and more. For example, Herring et. al. (2016) described Quintilian’s (35–100 AD) use of a novel approach to teach writing. Quintilian cut out letters on a board in beautiful script, and learners could practice writing by moving a writing tool along the grooves, minimizing errors (cited in Illich, 1996, p. 9). This example highlights the significance of a particular technology’s (the letter board) unique abilities to support learning. Different tools offer distinct affordances, influencing their suitability for specific activities, and the letter board offers a tight integration of content (writing) and tool (a tablet with groves), exemplifying the interconnectedness of technology, pedagogy, and content. This integration is the foundation of the TPACK framework. This raises an important question: if TPACK applies to teaching writing in 100 A.D., wouldn’t it also apply to the new tools of today—of interest here, GenAI?

In other words, the fact that TPACK is technology agnostic, focused on the integration of tools with content and pedagogy, not on the specific tools themselves, makes it an amenable framework for considering how GenAI can be used to support teaching and learning. It is also important to recognize, however, that different technologies provide different affordances and constraints when it comes to their integration with content and pedagogy, offering distinct “zones of possibility” (Dirkin & Mishra, 2010). Changes in technology push us to reconsider how we think about the content to be taught as well as the pedagogical approach that is most appropriate. In this new context, it is critical that we recognize how new GenAI tools are fundamentally different than the technologies that have come before (analog or digital). Much of the discussion around these technologies, we believe, is based on an incomplete understanding of the nature of GenAI technologies and how they are different from other digital tools. It is for this reason that much of the discourse around GenAI has focused on issues such as the perceived increase in plagiarism and cheating and assessing the quality of generated content, while larger questions about the shifts in the very nature of teaching and learning have received less attention.

To address this issue, we frame the next few sections around the TPACK framework, particularly focusing our attention on the knowledge domains that are potentially most impacted by GenAI. In the canonical version of the TPACK diagram (Figure 1) there are four main areas (or forms of knowledge) related to technology. They are Technological Knowledge (TK) as well as in the overlapping spaces that constitute Technological Content Knowledge (TCK), Technological Pedagogical Knowledge (TPK) and, of course, Technological Pedagogical Content Knowledge (TPACK). Additionally, though not explicitly mentioned, technology can have a significant impact on Contextual Knowledge (XK). The next few sections take each of these in turn, starting with Technological Knowledge (TK).

![](img/8df92fdc7dcbffe8625a4ff889a2ae0c7c1ba8041910817dc72ed1f4b1c5e72f.jpg)  
Figure 1. T he Canonical TPAC K diagram (Mishra, 2019).

# Technological knowledge (TK): understanding the nature of GenAI

Because GenAI is a form of digital technology we begin by identifying what is common to all digital technologies. Then we will consider what makes GenAI different from other digital media. Koehler and Mishra (2008) identified three key properties that digital technologies share: digital technologies are protean, opaque and unstable. Digitality’s protean nature enables it to dynamically simulate many different media formats (e.g., image, sound, text, numbers), even those that cannot exist physically, making it a meta-medium with vast potential for representation and expression. Digital technology’s unique ability to store, deliver, and manipulate various symbol systems empowers humans, granting them new abilities and greater efficiency in performing tasks. Digital technologies are also functionally opaque. That is, their inner workings are largely concealed from users, turning computer interactions into symbolic and arbitrary experiences with potential real-world implications. This makes the process of working and learning with digital tools challenging, similar to learning a new language or culture. Finally, digital technologies are unstable in that they are prone to error (both human and software generated) which add to the challenge of using them in educational contexts.

As digital technologies, GenAI technologies also exhibit these characteristics, albeit in a more complex and magnified manner. First, the protean nature of GenAI technologies is seen in their versatility and transformative abilities, from their interaction with diverse digital content to the wide range of applications they support. However, the protean nature is magnified because of its ability to interact with this range of digital content—text, data, image, video, and more— through a natural language interface that is extremely accessible and intuitive to use. This is a far cry from the command line and graphical user interfaces that we have used in the past. The ease of interaction with various types of content enables new forms of knowledge synthesis, discovery, and creative expression. Additionally, this versatility supports a wide range of applications including creative writing, text summarization and synthesis, language translation, data analysis and computer programming. The ease of interaction combined with the variety of media GenAI tools can interact with also mean that costs of creating seemingly sophisticated, realistic, high-quality content have dropped significantly. Finally, these tools can generalize from learned patterns, responding to queries, or generating content on topics they were not explicitly trained on. This showcases a form of inductive reasoning, something no easily accessible technology has been able to do.

Second, the instability of GenAI extends beyond human and system errors. GenAI’s iterative generation process can lead to unexpected results. For example, while capable of innovative genre mashups and unique content generation, these models may also “hallucinate” or produce outputs that are not grounded in their training data, a characteristic that can be both advantageous in creative contexts and problematic when accuracy is paramount. The quality of their output often reflects the quality of the input provided; poor, ambiguous, or misleading input can lead to suboptimal or inaccurate output. Moreover, many of these models have an illusory sense of confidence in their output even when making predictions or generating content that is completely incorrect.

Finally, GenAI is opaque to users and even their own creators. Despite their practical utility, the range of functions these tools can execute—including the complexity of the inputs they accept, the extensive processing they perform, and the variety of outputs they can generate— make them one of the most complex digital artifacts ever created. They become a “black box” where comprehending or predicting why a particular output was generated or how the model operates (and the costs of doing so) are essentially impossible to understand, even by the very designers of these tools (Voosen, 2017; Zewe, 2023). Another aspect of this opacity stems from the hidden costs of their creation, as highlighted by Timnit Gebru (described in Hao, 2020). Training GenAI models requires substantial computational and human resources. This has significant environmental and social implications at a time of increased environmental and economic precarity.

In addition to being protean, unstable, and opaque, GenAI tools have two other unique characteristics that no technology has ever exhibited before. GenAI tools are generative and social. We describe each in greater detail below.

First, GenAI is generative. Though it may seem a bit of a tautology—after all, the word “generative” is in its name—it is often difficult to grasp the extent of its generative properties. Every response to a prompt is unique, created in real time. The ability of GenAI to generate conclusions on the fly, by “seeing” patterns and building on them, is why they often surprise us with unexpected responses. Thus, one can create interesting genre mash-ups (such as writing epic poetry about mathematical ideas) or explore the meaning of a novel through multiple perspectives. Their generative nature can be best understood by seeing that even the same, identical prompts generate different results each time.

Evidence of generativity can also be seen in the surprising and unanticipated capabilities GenAI has developed, often surprising its creators. For example, GenAI developers were surprised that GenAI tools learned to translate between languages and write sophisticated code without any direct training (Al-Sibai, 2023; Hutson, 2022; Metz, 2021). Some of these systems have even learned to deceive and lie, misrepresenting themselves to humans (e.g., Humphries, 2022; Kan, 2023). And though current models have been “constrained” using ad-hoc software guardrails, they still have the capacity to surprise by the sheer ease with which they can create absolutely unique and novel output, over and over again. Incidentally, these guardrails can (and have been) subverted, which only expands the range of outputs that they generate (see Metz, 2023).

Second, GenAI is social; one of the most unique properties of GenAI is its “psychological reality.” This social aspect is as much a property of the medium as it is our response to the medium. GenAI offers a new, more literal form of “social media.” In contrast to traditional social media that offers tools to support person-to-person connection, GenAI encourages social interaction through the tool itself. This ability to engage as if it was human is a unique development in the history of technology. Our interactions with GenAI occur through language (a uniquely human capability), and these tools have the ability to understand and respond based on the context and history of the interaction. Thus, just like conversations with other humans, each interaction with GenAI is unique, different, and emergent. This means that the most productive ways of engaging with these tools is conversational in nature.

Because of their true social nature, many people anthropomorphize GenAI tools, describing them as having human-like qualities such as personality and agency. Although other forms of interactive media also can provoke a human-like response (Mishra, 2006, 2022; Mishra & Hershey, 2004; Mishra et  al., 2001; Reeves & Nass, 1996), GenAI models have attributes (such as using conversational language and engaging in unrestricted, open-ended dialogue) that make anthropomorphizing these technologies much easier and almost automatic.

It is not difficult to understand why this happens. Humans are social beings, with a significant proportion of our cognitive activity based on inferring the social norms, beliefs, and desires of other people. Moreover, we are cognitive misers, and we will take psychological short-cuts to minimize cognitive effort. As Kahneman (2011) argued in his book “Thinking, Fast and Slow,” inferences are forms of “fast thinking” that operate automatically and are made with little voluntary control, driven by instinct and emotion. What this means is that it is easier to believe and act as if LLM’s are psychological beings than to consider them machines. Disbelief takes cognitive effort while engaging with these GenAI models and interpreting their actions through a social/psychological lens is effortless. Our social brains, honed through millions of years of evolution, are not trained or prepared to deal with these boundary objects. For these reasons, we will anthropomorphize GenAI technologies despite knowing better. In other words, we will often attribute psychological states such as beliefs, intentions, and desires to these technologies even though we know that they lack personal experiences, emotions, or consciousness and that their outputs are purely the product of learned patterns, devoid of personal insight or emotional depth. We find them to be psychologically real in ways that other technologies are not and never have been. Just to be clear, the point here is not that these systems are sentient or have internal psychological states, but rather, as humans and social beings, we will react to them as if they were a psychological other.

In conclusion, it is more accurate to consider GenAI as creative, generative, reasoning, social “psychological others” than tools that writes term papers and summarizes information in a conversational tone. Their true potential manifests when utilized as an expert collaborator, one who often gets things wrong but who can help with a range of complex tasks such as comparing concepts, constructing counterarguments, generating analogies, analyzing data, or evaluating symbolic logic. GenAI’s vast knowledge base and its ability to work, tirelessly, with complex concepts in sophisticated ways, combined with its propensity to hallucinate have led some to suggest that the best way of thinking of these technologies is as if it were a “smart, drunk intern” (Mishra, 2023).

# Reimagining TPK (technological pedagogical knowledge)

To use GenAI tools effectively in educational contexts, teachers need to have knowledge about the technology itself. However, this is not enough—they also must integrate this knowledge with pedagogy (TPK) and content knowledge (TCK). TPK describes understanding how GenAI technologies can support general pedagogical processes, including how they can be used to address the common challenges or pitfalls students might have with the technology and enabling new approaches to creative expression and assessment. For example, GenAI can become a study partner or tutor for teachers and learners, creating tests and providing feedback on responses. Additionally, the wide array of media that can be easily produced with GenAI—and the relative ease of developing creative media representations—enables new tools for focusing on conceptual representation, communication, and expression of knowledge. The fact that these tools can generate complex and unique responses suggests that educators may need to reimagine their assessments of learning to focus on deeper, meta-level ideas. For instance, in a writing assignment the teacher may ask a student to use GenAI to create a first draft then annotate the draft to identify the strengths and weaknesses of GenAI’s response. This allows learners to think more about the deeper ideas of composition, meaning making, rhetoric, argumentation, and flow. As this example indicates, to be effective users of this technology teachers need to be thoughtful, intentional, and strategic about understanding how the technology can support deeper learning.

Although rich with possibility, teachers also need to understand how to support learners in understanding the problems and challenges associated with GenAI. For example, developing a basic understanding of how these tools are developed (i.e., trained to reproduce the vast amounts of internet-stored language they are trained on) can help teachers and learners be more aware of their tendencies to reproduce inequities, generate false information, and take on human-like personas. Teachers might support students in exploring the nascent field of “prompt engineering,” a set of strategies for inferring the manner in which these GenAI tools “think” and function.

Ultimately, teachers need to understand the strengths of GenAI and see them as they truly are: generative psychological agents that are now part of the classroom. But educators also need to recognize that these are alien intelligences (Warr et  al., 2023), dissimilar from human intelligence. The urge to anthropomorphize will be strong, which requires bringing our critical facilities to bear and learning to think “slow.” Slow thinking, as Kahneman (2011) described it, involves complex, analytical thought processes that require conscious effort. Slow thinking can include tasks such as problem-solving or evaluating choices (or in this case, recognizing the true nature of GenAI models). Part of TPK is to know appropriate and inappropriate uses of the tools and support learners in developing this knowledge.

# Reimagining TCK (technological content knowledge)

Where TPK focuses on the relationship between technology and pedagogy, TCK moves the attention to how technology is used in specific content areas. It has been suggested that every domain of human activity, every profession that depends on abstract knowledge, will be affected by GenAI (Li & Liu, 2020). This means everything from journalism to education, from coding to filmmaking, from law to physics, from marketing to music will be transformed, in some shape or form, by the rise of AI. Over time, AI is likely to reduce employment for college-educated workers by automating tasks previously considered high-skill. This could displace workers in various industries as companies seek to cut costs through automation. Relatively unaffected will be the blue-collar professions that are deeply connected to the physical world, such as those who maintain and repair mechanical devices; those who engage in live performances such as theater and sports; and those who take care of the most in need, such as the elderly and the very young. The result is an inversion of the standard hierarchy where, in pure economic terms, the white-collar professions were valued more than the more blue-collar professions. How this will impact the broader economy is difficult to predict but this is something that educators and policy makers need to consider as they prepare students for the future.

The impact of AI on future careers has two implications. First, it may mean a renewed appreciation of disciplines such as physical making (for example, through maker-spaces or vocational programs) and the arts, arenas where GenAI will have the least impact. Second, it will mean cognitively oriented professionals will be most valuable if they can use GenAI for critical thinking and creativity. For example, when AI can comb through hundreds of precedents to find the right support to write a law brief, the role of the lawyer shifts from researching case law to effectively framing arguments and counterarguments. Similarly, GenAI’s prose will likely take the place of some basic journalism (efficiently reporting the facts) and journalists will need to pivot to developing and communicating new forms of knowledge connected to current issues. Data analysts can, using GenAI tools, more easily create visualizations of large sets of data without coding skills, perhaps opening space for searching for new ways to represent and make decisions with data. Ultimately, because of GenAI’s ability to produce many types of media—prose, poetry, images, audio, video, code, data visualizations (and perhaps more that are yet to be discovered)—it will become embedded into the practices of disciplinary work and industry. Given these changes, it is crucial that educational systems reconsider curricular goals and learning approaches. What learners need is to develop types of knowledge necessary for today’s (and tomorrow’s) workforce, reflecting new forms of content knowledge that are transformed due to advances in GenAI.

# Reimagining XK (contextual knowledge)

A recent and significant shift in the research on TPACK has been an emphasis on understanding Contextual Knowledge (XK)—a recognition of the fact that context matters—and impacts—what educators can and cannot do. Mishra and Warr (2021) considered the relationship between contextual knowledge and a teacher experimenting with a new technology for assessment:

This lesson (and assessment) does not exist in isolation, merely shaped by the teacher’s TPACK. They exist within broader systemic and cultural contexts and discourses, which may include (but surely are not limited to) teacher performance evaluation systems, school rankings, current budgetary constraints, state-level policies and standards, and more. A teacher who understands how these systemic factors work can utilize them intelligently to set herself and her students for success. We do not mean that teachers need to become expert administrators or policy makers. Rather, if teachers are cognizant of these issues, sensitive to constraints, and open to possibilities, they can leverage apparent constraints into recipes for success.

Mishra and Warr (2020, 2021) and Warr et  al. (2020) provide a framework (the five spaces for design in education framework) to urge educators to consider the broader systems and cultural contexts within which education functions. They argue that the TPACK framework, by focusing mainly on teachers’ knowledge within the classroom (artifacts, processes, and experiences), has prevented teachers from being as successful as they could be. When teachers design learning materials, they work within constraints of larger educational systems over which they have limited control. Understanding these factors is key to their success.

As educational landscapes shift and new technologies such as GenAI emerge, teachers need to not only update their knowledge and skills but also seek to understand the broader systemic factors that empower or constrain what they can and want to do. It is not only crucial for them to understand how GenAI works, and how to repurpose it for their specific pedagogical needs; they need to understand that their actions are grounded within and circumscribed by external factors. These include but are not limited to broader discussions around student autonomy, plagiarism, school, and district policies. A thoughtful, creative teacher with a sophisticated understanding of how they can use GenAI in their classroom, whether to teach Newton’s laws or literary analysis, may find their attempts stymied by district level policies that prohibit the use of these tools in classroom contexts. Contextual Knowledge (XK) may then be the key difference to the successful implementation of any innovation or its failure. This is particularly important in the context of new technologies, such as GenAI, which have significant potential to disrupt existing systems and practices.

# Reimagining TPACK in the age of GenAI: bringing it all together

Technological Pedagogical Content Knowledge, has for the past two decades, been the defining framework for teacher knowledge for intelligent and intentional technology integration in teaching. It recognizes that the teacher plays a pivotal role in the educational context. Teachers are the conduit for taking disciplinary knowledge of a given domain and transforming it (using the right technology) for the benefit of learners and their educational development. The advent of GenAI and their ability to offer deep expertise of a wide array of content, their generative protean abilities, as well as their ability to communicate in language and behave as a psychological real “other,” call into question many of the traditional roles played by teachers.

There are some direct implications of the inclusion of GenAI in education that emerge from our discussion above. In keeping with the TPACK framework, we start with how the nature of TPK changes in this new ecosystem, i.e., the use of tools for pedagogy across content areas. Most of the controversy around the use of these tools in education has been in the arena of assessment. Technology (whether it be print or multimedia) has influenced the kinds of assessments we have created, but we have never had a technology that could be generative in nature, giving us the power to create new prose, write poetry, solve mathematical problems and more, just using everyday language. In some ways, this brings immense challenges to how we assess student learning and yet at the same time it forces us to acknowledge that many of our assessments do not truly measure student understanding and knowledge. This is a significant challenge for educators across the board with clear implications for equity; these technologies will not be equitably available to all. GenAI will require educators to develop new pedagogies and recognize that there will be other social agents in the learning space, a space that has been primarily inhabited by humans. These social agents will be better than humans in many—though not all—aspects. Teachers need to experiment and play with these tools, seeking new pedagog ical techniques in response to ongoing technological advancement and change.

Technological Content Knowledge (TCK) will need to be reimagined as well. Essentially, educators will have to reconsider what they teach, similar to how math educators had to shift when calculators became cheap and available. We must continually ask ourselves what is truly important for our students to know so that they are prepared for an unpredictable and emerging future, one in which AI technologies will lead to job transformation and economic change. Furthermore, as these tools improve, they will continue to build increasingly complex understandings of content, perhaps even rivaling the content knowledge of expert educators. This has implications for the kinds of educational standards we design as well as the curricular content we want our teachers to cover. Teacher education programs will need to consider these factors as we prepare the next generation of teachers, educational professionals, and educational leaders.

Despite all we have discussed, the most important insight concerning TPACK in an age of GenAI is philosophical in nature. These technologies require a shift in perspective from a mere utilitarian technological approach to a relational one. Traditional dichotomies—machine versus tool, tool versus object—blur and lose their relevance when we speak of GenAI. At some level, a relational perspective to technology is not a new idea. Scholars such as Latour and Venn (2002), Ihde (1998), and Verbeek (2015) have all argued that technologies are more than mere tools. They are not neutral, but rather they actively influence our interaction with the world. In that sense they have agency, shaping our actions, modifying the ecosystem within which we co-exist through these interactions. That said, in the past these ideas have been theoretical, insightful metaphors for how we would think of the broader ecosystem of people, societies, and technology. GenAI technologies are almost embarrassingly literal manifestations of these abstract philosophical ideas.

Thus, GenAI doesn’t just operate in isolation, but it interacts, learns, and grows through dialogue with humans. This collaborative dance of information exchange collapses the old boundaries that once defined our relationship with tools and technology. The meaning of these entities is not fixed or pre-determined, rather, how we make sense of these new tools is emergent based on multiple rounds of dialogue and interactions with them, akin to how we engage, interact and learn from and with human correspondents. Thus, we’re not just users or operators, we’re co-creators, shaping and being shaped by these technologies in a continuous and dynamic process of co-constitution. This is a critical shift in understanding that educators need to embrace as we navigate the wicked problem of technology integration in teaching.

Moreover, the learning space, which until today was inhabited by humans (learners and educators) as active meaning-making agents, will change due to the advent of these generative, social technologies. Even at this moment, tools such as KhanMigo (the Khan Academy’s version of a tutor built on top of OpenAI’s ChatGPT 4) can play the role of an educator as a guide on the side, a role typically described as a uniquely human. The presence of an “alien” intelligence in a space that has previously been only inhabited by humans will be disruptive in unpredictable ways. For instance, future versions of these tutoring technologies will most definitely have TPACK knowledge built into their very design. They will have knowledge of content and the current state of student understanding combined with an ability to work across a range of representational media (text, images, video and more). This will make them incredibly powerful tools for educators. Thus, the kinds of knowledge teachers need to have will evolve and change. For example, teacher knowledge may need to focus more on the social and psychological aspects of growth and development and less on content expertise. And of course, what this means for the education professions remains to be seen.

# Stepping back from TPACK: the bigger picture

Thomas Edison, speaking of education and the value of educational film, famously said:

I should say that on the average we get about two percent of efficiency out of schoolbooks … The future of education, as I see it, will be conducted through the medium of the motion picture … where it will be possible to obtain one hundred percent efficiency (quoted in Cuban, 1986, p. 9).

Edison further argued that these efficiencies will dramatically change education, predicting that “Our school system will be completely changed in ten years” (quoted in Saettler, 1990, p. 98).

Quotes such as these are often used to argue for two opposing perspectives. One, on the hubris of technologists, who see every new tool (film, computers, the internet, social media, etc.) as having a transformative effect on education; and the other, on the intransigence and resistance of educators and educational systems to change.

Both these perspectives, we suggest, miss the point, one by overhyping the impact of technology and the other by overemphasizing the inertia of educational systems. The truth is more complicated. Technology has entered education in the form of books and computers and pencils and microscopes. But expecting technology to transform education is to give technological tools far more agency than they actually have. It ignores the fact that these tools operate within, and gain their meaning from, broader social structures and systems of education, which have not changed.

That said, technologies have changed education profoundly by changing the world education functions in. Even if Edison was profoundly incorrect about the impact of film on schooling, film has changed the world. As Mishra et  al. (2023) write:

… it would also be shortsighted of us to ignore the impact of cinema on the world at large. From Birth of a Nation to Leni Riefenstahl’s propaganda films, to the rise of the Hollywood blockbuster, to the spread of popular cinema across the world, the technology of the motion picture has changed the world at large, a world within which education functions. It has changed the social/cultural context, the broader socio-political knowledge ecology within which schools exist and where learning and teaching happen.

This more nuanced view of the impact of technology on learning applies to GenAI. When we think about educational technologies, we often consider the classroom or the school as the unit of analysis, ignoring both the contextual as well as the more long-term effects of technology that change the classroom in unpredictable ways.

We believe the inordinate amount of discussion and handwringing about GenAI-supported cheating and plagiarism is over-wrought. We have faith that educators, with their creativity, will find ways to evaluate student learning even in the age of GenAI. Moreover, we are certain that educators will engage thoughtfully, intentionally, and productively with these new tools to benefit the intellectual development of their students. The true challenge, and one we don’t often pay attention to, will come in how GenAI will change the broad context within which educational systems function. This will require educators, educational leaders, and policy makers to think more long-term than we are used to doing.

For example, consider the introduction of social media. Around a decade ago, educators were both excited and troubled by the advent of social media. We wondered how we could use Twitter or YouTube in our classrooms, or how we could leverage the power of social media tools for learning content. These were genuine and important questions. However, while we were focusing on the classroom applications of these tools, we did not think about their broader social impact. We were not prepared for how social media would disrupt the body politic at large through the spread of misinformation and fake news. We did not consider how these technologies of connection might disrupt our world at a global scale. Yet, there is increasing evidence that the use of social media reduces trust in government, news media, and institutions by increasing polarization and the spread of misinformation (Stubenvoll et  al., 2021; Turcotte et  al., 2015). The design of these tools pushes people toward more extreme positions, to dishonest performative acts that are driven by mob dynamics rather than cooperation. Addtionally, the U.S. Surgeon General’s Advisory (2023) recently issued a warning that widespread use of social media among kids and teens poses a significant mental health risk. Longitudinal data reveal a concerning surge in teen depression and suicide attempts during the last fifteen years, leading to its recognition as a “national state of emergency” by the American Academy of Pediatrics (2021). According to the latest trend report from the CDC, the proportion of high-school students reporting “persistent feelings of sadness or hopelessness” has risen dramatically from $2 8 \%$ in 2011 to a troubling $4 2 \%$ in 2021. Alarmingly, the figures for girls and LGBTQ students are even more distressing, standing at $5 7 \%$ and $6 9 \%$ , respectively, in 2021 (Youth risk behavior survey: Data summary and trends report, 2011-2021, n.d.).

These were changes we were not thinking about when we were working on developing teachers TPACK around the use of social media. And these broader cultural shifts have educational impact. These kids and teens are in our classrooms and schools. They are our students. And whether we like it or not, the consequences of widespread social media use, including its impact on mental health, is now an educational issue. It is something that educators have to contend with.

As we focus on helping teachers develop TPACK in the age of GenAI, we need to take a long-term view if we are to truly empower them to do the best by the students in their care. For example, we must consider questions such as the following: What does it mean to teach in in an era where GenAI becomes part of our everyday life? In a time when it will be increasingly difficult to distinguish between AI-generated and human-generated content? As the boundary between AI- and human-generated content fades, how will it impact trust in information sources, institutions, and widely held social beliefs? Will GenAI technologies strengthen or erode these beliefs? Will they fuel confusion, skepticism, and anxiety, further exacerbating societal divisions, similar—or perhaps beyond—what we see happening with social media? And, it must be made clear, trust in this space goes beyond just the erosion of trust in information. How will our tendency to anthropomorphize, or attribute human traits to non-human entities, complicate matters further? Will these generative technologies, with their creativity, language-using, and seemingly social characteristics, heighten this confusion, creating a deceptive illusion of real, human-like interaction? What will this mean for children and youth who are still developing their sense of self and identity? How will the ripple effects of these developments affect educational systems that are already over-burdened and over-extended? What are the implications of people losing trust in the truthfulness of information and reliability of institutions on educational systems? Is there a risk of these institutions being perceived as ineffective or complicit in spreading misleading content? Moreover, how will they cope with the mental health consequences that may emerge, and how will they provide support to students navigating a world where truth is elusive and social and emotional confusion prevails? These are questions we should have asked of social media over a decade ago, and these are questions we need to ask of GenAI today! That said, a thoughtful reader may point out a fundamental limitation in our thinking, namely that all the questions we pose above are driven by experiences in our recent past with social media. We are constrained, it must be acknowledged, in our prognostications, by what has gone in the past. GenAI, given its unique attributes, will have its own emergent, unexpected, long-term consequences that are difficult to predict. We see no easy way through this conundrum. The broader impact of technologies on the world are difficult to predict. That said, as educators we can learn from this history to be better prepared as the unique consequences of these new technologies become more apparent.

It is also important to recognize that the consequences of the decisions of corporations and governments often become problems educators are expected to address. This is what we have seen with social media use, and we worry that a similar dynamic will play out with GenAI. Specifically, given the arms race currently underway in the world of GenAI as corporations jostle to gain first-mover advantage with little regard for broader social consequences (Grant & Weise, 2023; Hao, 2020), it will be teachers once again who will be left to clean up the messes left behind.

Our goal is not to be pessimistic about the possibilities of these technologies. These are powerful tools, and they have the potential to truly transform classrooms and the world within which classrooms exist. We have always known that humanity has a Faustian bargain with technology, that we take the good with the bad. What we would like to see is that educators, as they develop TPACK, look not just at their immediate context but cast a long-range perspective, considering not only how GenAI impacts them today but also how it will possibly impact the personal and professional lives of their learners going forward. GenAI (protean, opaque, unstable, generative and social) is here to stay and our job as educators is to prepare for this emerging future. TPACK will be useful as a framework, but only if we view it from a wider perspective than we have so far.

# Disclosure statement

No potential conflict of interest was reported by the author(s).

# Notes on contributors

Punya Mishra juggles being associate dean, professor, researcher, author, and designer at the Mary Lou Fulton Teachers College at Arizona State University. He claims to be interested in life, the universe, and everything; and loves shoehorning Douglas Adams’ book titles into his bio statement. You can find him at punyamishra.com.

Melissa Warr is an Assistant Professor of Education Design and Learning Technologies at New Mexico State University. Her research blends teacher education, design, creativity, and technology. Her scholarship is available at http://melissa-warr.com.

Rezwana Islam is a doctoral student at the Mary Lou Fulton Teachers College at Arizona State University. She is interested in designing and evaluating learning experiences and the future of teacher education in the areas related to artificial intelligence, virtual/augmented reality.

# ORCID

Punya Mishra $\textcircled{1}$ http://orcid.org/0000-0002-9300-4996   
Melissa Warr $\textcircled{1}$ http://orcid.org/0000-0002-0985-4067   
Rezwana Islam $\textcircled{1}$ http://orcid.org/0000-0001-6749-2837

# References

American Academy of Pediatrics. (2021). AAP-AACAP-CHA Declaration of a National Emergency in Child and Adolescent Mental Health. https://www.aap.org/en/advocacy/child-and-adolescent-healthy-mental-development/ aap-aacap-cha-declaration-of-a-national-emergency-in-child-and-adolescent-mental-health/   
Alkaissi, H., & McFarlane, S. I. (2023). Artificial hallucinations in ChatGPT: Implications in scientific writing. Cureus, 15(2), e35179. https://doi.org/10.7759/cureus.35179   
Al-Sibai, N. (2023). Google surprised when experimental AI learns language it was never trained on. The Byte. https://futurism.com/the-byte/google-ai-bengali   
Angwin, J. (2023). Decoding the hype about AI. The Markup. https://themarkup.org/hello-world/2023/01/28/ decoding-the-hype-about-ai   
Arthur, R. (2023). AI tools for teachers. Rachel Arthur Writes. https://rachelarthurwrites.com/2023/04/24/ai-toolsfor-teachers/   
Baidoo-Anu, D., & Owusu Ansah, L. (2023). Education in the era of generative artificial intelligence (AI): Understanding the potential benefits of ChatGPT in promoting teaching and learning. Available at SSRN 4337484.   
Bhatia, A. (2023). Let us show you how GPT works  —  Using Jane Austen. The New York Times. https://www. nytimes.com/interactive/2023/04/26/upshot/gpt-from-scratch.html   
Cardona, M. A., Rodríguez, R. J., & Ishmael, K. (2023). Artificial intelligence and the future of teaching and learning. Office of Educational Technology. https://tech.ed.gov/files/2023/05/ai-future-of-teaching-and-learning-report.pdf   
Chaka, C. (2023). Detecting AI content in responses generated by ChatGPT, YouChat, and Chatsonic: The case of five AI content detection tools. Journal of Applied Learning and Teaching, 6(2), 1–11. https://doi.org/10.37074/jalt. 2023.6.2.12   
Chan, C. K. Y., & Hu, W. (2023). Students’ voices on generative AI: Perceptions, benefits, and challenges in higher education. In arXiv [cs.CY]. arXiv. http://arxiv.org/abs/2305.00290   
Chheang, V., Marquez-Hernandez, R., Patel, M., Rajasekaran, D., Sharmin, S., Caulfield, G., … Barmaki, R. L. (2023). Towards anatomy education with generative AI-based virtual assistants in immersive virtual reality environments. arXiv Preprint arXiv:2306.17278.   
Cuban, L. (1986). Teachers and machines: Classroom use of technology since 1920. Columbia University Press.   
D’Agostino, S. (2023). How AI tools both help and hinder equity. Inside Higher Education. https://www.insidehighered. com/news/tech-innovation/artificial-intelligence/2023/06/05/how-ai-tools-both-help-and-hinder-equity 9). IntaLex Corporation.   
Dewey, J., & Bentley, A. J. (1949). Knowing and the known. Beacon Press.   
Dirkin, K., & Mishra, P. (2010). Values, beliefs, and perspectives: Teaching online within the zone of possibility created by technology. Society for Information Technology & Teacher Education International Conference, 3811– 3817.   
Ethical guidelines on the use of artificial intelligence (AI) and data in teaching and learning for educators. (2022). The European Commission. https://doi.org/10.2766/127030   
FAQ. (2023). Elicit. https://elicit.org/faq   
Foltynek, T., Bjelobaba, S., Glendinning, I., Khan, Z. R., Santos, R., Pavletic, P., & Kravjar, J. (2023). ENAI recommendations on the ethical use of artificial intelligence in education. International Journal for Educational Integrity, 19(1), 1–4. https://doi.org/10.1007/s40979-023-00133-4   
Grant, N., & Weise, K. (2023). In A.I. Race, Microsoft and Google Choose Speed Over Caution. The New York Times. https://www.nytimes.com/2023/04/07/technology/ai-chatbots-google-microsoft.html   
Gunkel, D. J. (2003). Second thoughts: Toward a critique of the digital divide. New Media & Society, 5(4), 499–522. https://doi.org/10.1177/146144480354003   
Hao, K. (2020). We read the paper that forced Timnit Gebru out of Google. Here’s what it says. MIT Technology Review. https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnitgebru/   
Heaven, W. D. (2023). ChatGPT is going to change education, not destroy it. MIT Technology Review. https://www. technologyreview.com/2023/04/06/1071059/chatgpt-change-not-destroy-education-openai/   
Heikkilä, M. (2022a). The algorithm: AI-generated art raises tricky questions about ethics, copyright, and security. https://www.technologyreview.com/2022/09/20/1059792/the-algorithm-ai-generated-art-raises-tricky-quest ions-about-ethics-copyright-and-security/   
Heikkilä, M. (2022b). How AI-generated text is poisoning the internet. MIT Technology Review. https://www. technologyreview.com/2022/12/20/1065667/how-ai-generated-text-is-poisoning-the-internet/   
Herft, A. (2023). A teacher’s prompt guide to ChatGPT aligned with “what works best.” https://www.canva.com/ design/DAFW8z-D60c/ikjg6jQju5IRaseV6Izzcw/view?utm_conten $\varXi$ DAFW8z-D60c&utm_campaign $\equiv$ designshare &utm_medium=link&utm_source=publishsharelink   
Herring, M. C., Koehler, M. J., & Mishra, P. (2016). Handbook of technological pedagogical content knowledge (TPACK) for educators (2nd ed.). In Mary C. Herring, M. J. Koehler, & P. Mishra (Eds.). Routledge. https://doi. org/10.4324/9781315771328   
Humphries, M. (2022). Meta’s latest AI can play diplomacy better than most humans. PC Magazine. https://www. pcmag.com/news/metas-latest-ai-can-play-diplomacy-better-than-most-humans   
Hutson, M. (2022). AI learns to write computer code in “stunning” advance. Science. https://www.science.org/content/ article/ai-learns-write-computer-code-stunning-advance   
Ihde, D. (1998). Philosophy of technology. Paragon House.   
Illich, I. (1996). In the Vineyard of the text: A commentary to Hugh’s Didascalicon. University of Chicago Press.   
Kadaruddin, K. (2023). Empowering education through generative AI: Innovative instructional strategies for tomorrow’s learners. International Journal of Business, Law, and Education, 4(2), 618–625. https://doi.org/10.56442/ijble. v4i2.215   
Kahneman, D. (2011). Thinking, fast and slow. Macmillan.   
Kan, M. (2023). GPT-4 was able to hire and deceive a human worker into completing a task. https://www.pcmag. com/news/gpt-4-was-able-to-hire-and-deceive-a-human-worker-into-completing-a-task   
Koehler, M. J., & Mishra, P. (2008). Introducing TPCK. In AACTE Committee on Innovation and Technology. (Ed.), Handbook of technological pedagogical content knowledge (TPCK) for educators (pp. 3–29). Routledge.   
Latour, B., & Venn, C. (2002). Morality and technology. Theory, Culture, & Society, 19(5–6), 247–260. https://doi. org/10.1177/026327602761899246   
Li, R., & Liu, C. (2020). Artificial intelligence revolution: How AI will change our society, economy, and culture. Skyhorse.   
Lonas, L. (2023). Professor attempts to fail students after falsely accusing them of using ChatGPT to cheat. https:// thehill.com/homenews/education/4010647-professor-attempts-to-fail-students-after-falsely-accusing-them-of-usingchatgpt-to-cheat/   
Martin, A. J. (2023). Educational psychology meets generative AI. Psychology Today. https://www.psychologytoday. com/us/blog/psyched/202305/educational-psychology-meets-generative-ai   
Metz, C. (2021). A.I. can now write its own computer code. That’s good news for humans. The New York Times. https://www.nytimes.com/2021/09/09/technology/codex-artificial-intelligence-coding.html   
Metz, C. (2023). Researchers poke holes in safety controls of ChatGPT and other chatbots. The New York Times. https://www.nytimes.com/2023/07/27/business/ai-chatgpt-safety-research.html   
Mills, A. R. (2023). ChatGPT just got better. What does that mean for our writing assignments? The Chronicle of Higher Education. https://www.chronicle.com/article/chatgpt-just-got-better-what-does-that-mean-for-our-writing-assignments   
Mishra, P. (2006). Affective feedback from computers and its effect on perceived ability and affect: A test of the computers as social actor hypothesis. Journal of Educational Multimedia and Hypermedia, 15(1), 107–131.   
Mishra, P. (2019). Considering contextual knowledge: The TPACK diagram gets an upgrade. Journal of Digital Learning in Teacher Education, 35(2), 76–78. https://doi.org/10.1080/21532974.2019.1588611   
Mishra, P. (2022). Can a computer program be sentient? Insights from Rodolphe Topffer, the father of comic books. https://punyamishra.com/2022/07/06/can-a-computer-program-be-sentient-or-is-it-all-in-our-heads/   
Mishra, P. (2023). ChatGPT is a smart drunk intern: 3 examples. https://punyamishra.com/2023/07/26/chatgpt-i s-a-smart-drunk-intern-3-examples/   
Mishra, P., Henriksen, D., & Richardson, C. (2023). From crayons to AI: Widening the lens on educational technology and creativity. TechTrends, 67(2), 207–212. https://doi.org/10.1007/s11528-023-00839-9   
Mishra, P., & Hershey, K. A. (2004). Etiquette and the design of educational technology. Communications of the ACM, 47(4), 45–49. https://doi.org/10.1145/975817.975843   
Mishra, P., & Koehler, M. J. (2006). Technological pedagogical content knowledge: A framework for teacher knowledge. Teachers College Record: The Voice of Scholarship in Education, 108(6), 1017–1054. https://doi.org/10.1111/ j.1467-9620.2006.00684.x   
Mishra, P., Nicholson, M., & Wojcikiewicz, S. (2001). Does my wordprocessor have a personality? Topffer’s law and educational technology. Journal of Adolescent & Adult Literacy: A Journal from the International Reading Association, 44(7), 634–641.   
Mishra, P., & Warr, M. (2020). Foreward: A systems view of technology infusion. In A. C. Borthwick, T. S. Foulger, & K. J. Graziano (Eds.), Championing technology infusion in teacher preparation: A framework for supporting future educators. International Society for Technology in Education.   
Mishra, P., & Warr, M. (2021). Contextualizing TPACK within systems and cultures of practice. Computers in Human Behavior, 117(April 2021), 106673. https://www.sciencedirect.com/science/article/pii/S0747563220304209 https://doi.org/10.1016/j.chb.2020.106673   
Mitchell, A. (2023). AI thinks the constitution was written by bots  —  but there’s a bigger issue. New York Post. https://nypost.com/2023/07/25/why-its-a-problem-that-ai-thinks-the-constitution-was-made-by-ai/   
Moya, B., Eaton, S. E., Pethrick, H. A., Hayden, K., Brennan, R., Wiens, J., McDermott, B., & Lesage, J. (2023). Academic integrity and artificial intelligence in higher education contexts: A rapid scoping review protocol. Canadian Perspectives on Academic Integrity, 5(2), 59–75.   
Murgia, M., & Staton, B. (2023). The AI revolution is already transforming education. Financial Times. https://www. ft.com/content/47fd20c6-240d-4ffa-a0de-70717712ed1c   
Niess, M. L., Gillow-Wiles, H., & Angeli, C. (Eds.) (2018). Handbook of research on TPACK in the digital age. IGI Global.   
Perkins, D. N. (1986). Knowledge as design. Lawrence Erlbaum Associates.   
Ray, P. P. (2023). ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope. Internet of Things and Cyber-Physical Systems, 3, 121–154. https://doi.org/10.1016/j. iotcps.2023.04.003   
Reeves, B., & Nass, C. (1996). The media equation: How people treat computers, television, and new media like real people (Vol. 10). Cambridge University Press.   
Roose, K. (2022). The brilliance and weirdness of ChatGPT. The New York Times. https://www.nytimes. com/2022/12/05/technology/chatgpt-ai-twitter.html   
Rosenblatt, K. (2023). ChatGPT banned from New York City public schools’ devices and networks. NBC News. https:// www.nbcnews.com/tech/tech-news/new-york-city-public-schools-ban-chatgpt-devices-networks-rcna64446   
Scheerder, A., van Deursen, A., & van Dijk, J. (2017). Determinants of Internet skills, uses and outcomes. A systematic review of the second- and third-level digital divide. Telematics and Informatics, 34(8), 1607–1624. https:// doi.org/10.1016/j.tele.2017.07.007   
Schön, D. A. (1983). The reflective practitioner: How professionals think in action. Basic Books.   
Schön, D. A. (1987). Educating the reflective practitioner. Jossey-Bass Publishers.   
Shulman, L. S. (1986). Those who understand: Knowledge growth in teaching. Educational Researcher, 15(2), 4–14. https://doi.org/10.3102/0013189X015002004   
Snyder, K. (2023). We asked ChatGPT to write performance reviews and they are wildly sexist (and racist). Fast Company. https://www.fastcompany.com/90844066/chatgpt-write-performance-reviews-sexist-and-racist   
Saettler, P. (1990). The evolution of American educational technology. Libraries Unlimited.   
Stubenvoll, M., Heiss, R., & Matthes, J. (2021). Media trust under threat: Antecedents and consequences of misinformation perceptions on social media. International Journal of Communication Systems, 15, 22.   
The U.S. Surgeon General’s Advisory. (2023). Social media and youth mental health. Department of Health and Human Services. https://www.hhs.gov/sites/default/files/sg-youth-mental-health-social-media-advisory.pdf   
Turcotte, J., York, C., Irving, J., Scholl, R. M., & Pingree, R. J. (2015). News recommendations from social media opinion leaders: Effects on media trust and information seeking. Journal of Computer-Mediated Communication, 20(5), 520–535. https://doi.org/10.1111/jcc4.12127   
van Rijmenam, M. (2023). ChatGPT is a paradigm shift; why we should embrace it. The Digital Speaker. https:// www.thedigitalspeaker.com/chatgpt-paradigm-shift-why-education-should-embrace-it/   
Verbeek, P. P. (2015). Beyond interaction: A short introduction to mediation theory. Interactions, 22(3), 26–31. https://doi.org/10.1145/2751314   
Voosen, P. (2017). How AI detectives are cracking open the black box of deep learning. Science. https://www.science. org/content/article/how-ai-detectives-are-cracking-open-black-box-deep-learning   
Warr, M., Mishra, P., Henriksen, D., & Woo, L. J. (2023). A chat about GPT3 (and other forms of alien intelligence) with Chris Dede. TechTrends, 67(3), 396–401. https://doi.org/10.1007/s11528-023-00843-z   
Warr, M., Mishra, P., & Scragg, B. (2020). Designing theory. Educational Technology Research and Development, 68(2), 601–632. https://doi.org/10.1007/s11423-020-09746-9   
Weise, K., & Metz, C. (2023). When A.I. chatbots hallucinate. The New York Times. https://www.nytimes. com/2023/05/01/business/ai-chatbots-hallucination.html   
Youth risk behavior survey: Data summary & trends report, 2011-2021. (n.d.). Center for disease control and prevention. https://www.cdc.gov/healthyyouth/data/yrbs/pdf/YRBS_Data-Summary-Trends_Report2023_508.pdf   
Zewe, A. (2023). Unpacking the “black box” to build better AI models. MIT News. https://news.mit.edu/2023/ stefanie-jegelka-machine-learning-0108