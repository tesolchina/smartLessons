# Thirty years of writing assessment: A bibliometric analysis of research trends and future directions

Jihua Dong a,\*,1,2, Yanan Zhao a,1,3, Louisa Buckinghamb,4,5

a Applied Linguistics of the School of Foreign Languages and Literature at Shandong University, China b School of Culture, Languages and Linguistics, University of Auckland, Private Bag 92019, Auckland, New Zealand

# ARTICLEINFO

# ABSTRACT

Keywords:   
Writing assessment   
Bibliometric analysis   
Research trends   
CiteSpace

This study employs a bibliometric analysis to identify the research trends in the field of writing assessment over the last 30 years (1993-2022). Employing a dataset of 1,712 articles and 52,092 unique references, keyword co-occurrence analyses were used to identify prominent research topics, co-citation analyses were conducted to identify influential publications and journals, and a structural variation analysis was employed to identify transformative research in recent years. The results revealed the growing popularity of the writing assessment field, and the increasing diversity of research topics in the field. The research trends have become more associated with technology and cognitive and metacognitive processes. The influential publications indicate changes in research interest towards cross-disciplinary publications. The journals identified as key venues for writing assessment research also changed across the three decades. The latest transformative research points out possible future directions, including the integration of computational methods in writing assessment, and investigations into relationships between writing quality and various factors. This study contributes to our understanding of the development and future directions of writing assessment research, and has implications for researchers and practitioners.

# 1. Introduction

Writing is a complex and dynamic process consisting of challenging cognitive activities, and which can be asssed from multi faceted perspectives (Hamp-Lyons, 2019; Hartwell & ull, 2023). Driven by th increasing demand for asessing writing in diverse and dynamic situations (Hamp-Lyons, 2002), the field of writing assessment has undergone remarkable growth in the past decades. As noted by lomp (2012) ths fild has bee shifting from \*assessig writing as a product to asesing the deloment f writing ability" (p. 90), which is indicative of the field's expanded scope and depth. However, this rases new conceptual considerations, construct issues, and methodological challenges (Bazerman, 2016; White, 1994; Zheng & Yu, 2019), and thus call for a systematic and crtical examination of the current research trends and future directions in writing assessment. In this study, we provide a holistic and diachronic overview of the evolving trends in writing asessment interms of prominent research topics, influential publications, main research venues and future research directions from a bibliometric perspective.

Writing asessment plays a pivotal role in monitoring students' progress, identifying problems in student writing, providing feedback and guidance, and measuring the effectiveness of writing instruction. The analysis of writing assessment can contribute to shaping the design and implementation of curriculum and pedagogy, and the establishment and maintenance of writing standards and quality (ONeill t al., 2009). Writing asessment can take various forms and concerns different stages of the writing proces (Cooper, 1984). These include theoretical concerns and pre-assessment procedures (such as needs analyses), methodological challenges of writing asessment (including the creation and implementation of writig asessment), and the validity of certain writig assesment types. To understand the evolution of the field of writing assessment, this study seeks to address the following questions:

(1) What are the prominent research topics in the field of writing assessment between 1993 and 2022? How have they changed?   
(2) What are the most influential publications in writing assessment between 1993 and 2022?   
(3) What are the most influential journals in writing assessment between 1993 and 2022?   
(4) What has been the most transformative research in writing assessment in the latest 5 years?

# 2. Literature review

# 2.1. Reviews in writing assessment

There have been a number of research reviews and syntheses throughout the development of the field of writing assessment. For instance, Yancey (1999) outlined four overlapping waves in the evolution of writing asessment: the first wave (1950-1970) focused on objective tests; the second wave (1970-1986) concerned holistically scored essays; the third wave (1986-199) emphasized portfolio and programmatic asessments and the fourth wave (beginning in 199) involved a broader focus on assessing various genres of writing (e.g., email, hypertext) and writers individual dfferences. Hamp-Lyons (2001) provided a retrospective review of the first three generations of the writing asessment field and predicted the qualities of the fourth generation. The firs three generations focused on the direct testing of timed essays, multiple-choice testig, and portfolio-based practice respectiely. The fourth generation integrated both humanistic and technological aproaches, utilizing advancements in computer applications. Behizadeh and Engelhard (2011) conducted a historical analysis to scrutinize the interplay betwen the two research traditions, namely measurement theories and writing theories, and their influence on writing asessments in the United States. The tracing of the adancement of writing assessment revealed that the iterature was predominantly influenced by measurement theory, whereas the impact of writing theory was relatively low. Graham et al. (2015) conducted a meta-analysis to examine the efect f formative writing ssessment on enhancing students writing performance among elementary students. Result found that fdack from adults has a particularly signficant effect (displaying the greates effect size), which supports the use of formative asessment for student writing. Lam (2017) provided a comprehensive review of portfolo assessment by introducing the ationale, development and implementation of portolo assessment. Hammond (2018) conducted a historiographical analysis of the presentation of racial injustice in writing assessment by analyzing articles published in The English Journal from 1912 to 1935. The analysis showed that language use associated with assessment was informed by racial and national biases, and classroom writing assessments servedto reinforce and perpetuat these biased language norms. Poe and Elliot (2019 focused on the ssue of fairness i writing asessment in their analysis ofarticles over the past 25 years, and they emphasized the importance of the theoretical conceptualization of assessment. Hammond (2019a) reviewed controversies related to automated essay scoring (AES), comparing articles published in The English Jounal and Phi Delt Kappan. His study found an ongoing controversy over AES, and he proceeded to callfor more extensive analyses of these technologies. Similarly, Hammond (2019b) inestigated racial iues presented in Asessing writig from 1994 to 2018, and identified four prevalent trends of race tall, namely erction talk (.., discussin of race based on percetions of examiner and examinee), performance tlk' (ie. patterns in assessment pformane), content talk (i., rac ak in tst mtril), and csttial tlk (ie., mtion of rac n literatue reviews). Building on the aforementioned insights into the field of writing asessment, this bibliometric study proposes a more fine-grained, comprehensive analysis f research in the feld to identify key topics, publications, and journals from a chronological perspective, and to identify future research directions.

# 2.2. Bibliometrics

Bibliometrics refers to the application of mathematical and statistical techniques to measure and evaluate various aspects of scholarly publications (Pritchard, 1969). By collecting and analying bibliometric data from scientific databases such as the Web of Science (Wos) and Scopus, researchers can gain insights into the research trends, productivity, impact, collaboration and citation patterns of publicatios, jourls, authors, instittions and countries in a speifi field r discipline (Lei & Liu, 2019). In the field f 2 writing, Arik and Arik (2017) provided an overview of second language writing (SLW) research by collcting bibliometric data from the WoS and extracting frequent keywords using AntConc. Sun and Lan (2021) used AntConc and Python script to identify the most highly cited authors, articles and the most frequently used concepts of trans- studies of writing. Crosthwaite et al. (2022) compild a corpus of publications to discover the popular research topics, jounals, researchers and countries related to L2 writen corrective feedback, and used VOSviewer to generate data visualization. Hyland and Jiang (2022) traced the development of writtn interaction and mapped the field by compiling, annotating and analyzing a corpus of related articles to identify the most prevalent authors,

journals, publications and regions.

# 3. Method

# 3.1. Bibliometric data

The bibliometric data analyzed in this study consisted of 1,712 articles and 52,092 unique rferences downloaded from the WoS SSCI core collction in December 2022. WoS was chosen as the data source because it provides comprehensive and reliable bibliometric information such as publication tite, authors, keywords, journals, astracts and reference ists. The search criteria included terms related to writing assessment such as "writing asess\*, Writ test", \*Writ\* evaluation\*", Writ\* measure\*", \*Assess\* L2 student writing", Assess\*L2 writing", Assess\*student writing", Diagnos\* writ\*","writing quality, "writ\*scor\*",sesment\* of essays", \*"analytic rating", and various combinations conveying similar meanings in topics (titles, keywords or abstracts), for wider coverage of literature. Following Liu and Hu (2021), we excluded document types other than journal article'. Search results were also refined to those published in English, as it is the most widely used language for academic communication and dissemination in lin guistics and educational reearch, and keeping the same language ensures a consistent and rigorous analysis of bibliometric data. We also limited our search from 1993 to 2022, as only very few articles $( \mathbf { n } = 8 9 $ ) were published before 1993.

Afer the initial query and refinement of the search results, the retrieved bibliometric data, including titles, abstracts, author keywords, author information, journals, and reference iss, were downloaded as plain text files. Before importing into CiteSpace a close examination of the ite, keywords, and abstracts of the articles was conducted to check their rlevance to writing assessment Articles that were not pertinent to writing assesment were excluded. For example, one of the retrieved studies tled Do Children with Reading Difficutie perience Writing Dfficulties?A Met-Anlysis was excluded beause, deite mentioning writing assesment in its abstract, it primary fous did not pertain to writing assment. Consequently, theultimate dataset comprised a total of1,679 articles. The accuracy and consistency of rferences were also checked by correcting spelling errors and inconsistencies in the referencing style. This pre-analysis check helps to ensure the reliability and consistency of the analysis (Liu & Hu, 2021; Zhao & Strotmann, 2015).

The 30-year period was divided into three equal sub-periods of 10 years to chart the diachronic development of the field, following Crosthwaite et al. (2022), Lei and Liu (2019), and Park and Nam (2017): (1) 1993-2002: 144 articles and 4,493 cited references; (2) 2003-2012: 292 articles and 9,996 cited references 3) 2013-2022: 1,179 articles and 37,603 references. This division allows for the identification of publications that received fewer citations in the erly stage of the development of the field, as those rly publications tend to be less cited (Shneider, 2009).

# 3.2. Data analysis

In this study, CiteSpace was used for analyzing and visualizing research trends based on the bibliometric data (Chen, 2016) CiteSpace i softwareenabling multifaceted visual analytics of rearch patterns and diachronic hift, such as detecting citation bursts with increasing impact, identifying co-occurring keywords, decomposing a network of keywords into different clustrs, and tracing author collaborations geographically (Chen, 206; Chen et al., 2012). This software has been extensively used for mapping trends and changes within different feld related to lingustics, such as corpus liguisics (Park & Nam, 2017), data-driven learning (Dong et al., 2023c), and English for Specific Purposes (Liu & Hu, 2021).

The identification of prominent research topics (Research Question 1) was achieved by the keyword co-occurrnce analysis in CiteSpace. Keywords utilized in this study concern the terms selected by authors and presented in the Keywords section of research papers to summarize the core content of their articles (Li et al., 2009; Lu et al., 2020). As previously suggested, keywords have been identified as useful in representing main research topics and signaling the intended disciplinary audience of the study (Crosthwaite et al., 2022; Xia et al., 2021).

Previous research (e.g., Dryer, 2019; Scott & Tribble, 2006) has aso used keywords, which were mainly identified and selected by comparing different corpora of the whole reearch artices in the corpus analysis. For example, Dryer (2019) analyzed the polysemy of certain keywords in twelve major journals in writing studies. Based on the comparison of the self-built corpus of research articles of writing studies and cocA, he employed frequency and collocational strength as metrcs in identifying keywords (e.g, rhetoric, audience) and analyzing their different uses in each journal. The keyword analyses in these studies, along with collocational analyes, are advantageous as they can reveal the distinctive features and topics of acorpus, as well as the polysemy and variation of word meanings across ifferent contexts. However, i i necessary to point out that their analysis focused on words that are sigificantly more frequent in the research articles, instead of the carefuly selected keywords in the Keywords section of research articles.

As previously suggested, keywords of articles were valuable indexing tools for databases and search engines, which are charac. terized by minimizing polysemies from surrounding contexts (Lu et al., 2020). Thus, keywords have been widely utilized in biblio metric analyses, including quantifying the frequency of certain keywords and conducting co-occurrence analyses, to analyze the evolution of the field and identify prominent reearch topics (Lu et al., 2020). Co-occurring keywords are those apearing in at least two different documents within a time period (Chen et a., 2012). The prominence of reearch topics was measured by the frequency of keyword co-occurrence based on the embedded keyword co-occurrence matrix in CiteSpace (Chen, 2006). The rationale is that keywords with high co-occurrin frequencies in the network can be considered esential elements of knowledge i certain fields (Shi & Liu, 2019), whil keywords that received les atention from the field can indicate marginal subject areas (De Belis, 2009). Keyword co-occurrence analysis has been attested to be useful in revealing research trends and changes in research topics in a certain field (Bornmann et al., 2018; Zhang et al., 2020).

In the detailed analytical procedures, keyword co-occurrence analyses were run for every 10 years of the dataset. In each analysis, the node type was set to keyword, and the default setting of one year per time slce was used, with the top 50 included for each slice, following the general practice (Chen, 2016). Ingenerating the cluster labels, the Log Likelihood Ratio (LLR) algorithm was applied, following Chen et al. (2010), as this has been previously atested as of high validity and reliability (Liu & Hu, 2021).

The identification of influential publications (Research Question 2) was addressed through document co-citation analysis. Influ. ential publications are those introducing novel and impacful knowledge that bridges the old and the new (Swales & Leeder, 2012, p. 145). According to Swales and Leeder (2012), co-citation analysis is efective in identifying influential publications, as it avoids the bias of individual authors opinions. Co-citation occurs when two or more publications are cited together in a later article, indicating some thematic or methodological similritie (Chen et al., 2010). Identifying influential publications based on cocitations can reveal how ideas in the research field were disseminated (Dong et al., 2023a). The influence of publications was measured by two metrics: co-citation frequency and citation burst The first metric, co-citation frequency, indicates how frequently two or more publications are cited together in other publications (Aryadoust et al., 2020), which further suggests the degree of impact and relevance of those co-cited publications within a field. The second metric,citation burst, measures the sudden surge in co-citations of a specific publ. cation within a defined time period, reflecting its rising popularity and influence in a field (Chen, 2016). Publications with a citation burst can be automatically identified by CiteSpace, indicated by sigma values $( \geq 1 )$ . The higher the sigma value, the more influential the publication (Liu & Hu, 2021). These metrics are esential for identifing influential publications that have attracted significant attention from scholars, thereby revealing how those publications shape the evolution of a research field (Chen, 2006). To address Research Question 3, a journal co-citation analysis was conducted. The higher the co-citation frequency of a journal, the higher its impact and relevance in the field. Separate document co-citation analyses and journal co-citation analyses were conducted for every 10 years of the dataset. The node type was set to rference for document co-citation analyses, and the node type was set tocited jounal for journal co-citation analyses. For both types f analyses, we retained the default setigs, using one year asa time lice and selecting the top 50 references or journals, in alignment with the common practice (Chen, 2006). The Cosine algorithm was employed to calculate the network connection strength, following the methodology outlined in Chen (2014, 2016).

We employed structural variation analysis to identify the latest transformative research from 2018 to 2022 (Research Question 4) Transformative research is generally defined as studies with the potential to usher in sigificant advancements in the field, and which are typically characterized by their incorporation of intricate and innovative ideas and approaches (Trevors et al., 2012). Previous explorations have atested that structural variation analysis is efective in quantifying the transformative potential of publications (Sebastian & Chen, 2021). In the analysis, Centrality Divergence $( \mathrm { C } _ { \mathrm { K L } } )$ was used to determine the transformative potential of recent publications. $\mathrm { C } _ { \mathrm { K L } }$ is a structural variation metric that examines the changes a paper induces in the distribution of centrality (i.e., the degreeto which a node connect other nodes) (Chen, 2016) It has been verified as efective in detecting publications transformative potential, especiall in identifying that of Nobel-Prize winning papers (Sebastian & Chen, 2021). The higher the $\mathrm { C } _ { \mathrm { K L } }$ value, the greater the transformative potential of one publication. The harmonic mean (H), which summarizesdifferent aspects of structural variations, was used as a suplementary parameter for predicting publications' potential impact. In the specific analysis, look back years' (the span between the citer publication date and the cited publication date) and link retining factor (the maximum links llowed for each node) were both set to - 1, and the window of analysis (measured from the start of the publication year) was set to 2 in the network generation. The $\mathrm { C } _ { \mathrm { K L } }$ and H thresholds were set to be 0.05 and 0.10 respectively, in line with previous practice (e.g., Chen, 2014, 2016).

# 4. Results and discussion

In this section, we present findings revealed in the analysis. Prominent research topics are presented in Section 4.1, and influential publications are presented and elaborated in Section 4.2. Section 4.3 focuses on highly co-cited journals in three time periods, and

Table 1 Top keywords with co-occurrence frequencies (full list in Appendix A).   

<html><body><table><tr><td></td><td colspan="2">1993-2002</td><td colspan="2">2003-2012</td><td colspan="2"> 2013-2022</td></tr><tr><td>Rank</td><td>Count</td><td>Keywords</td><td>Count</td><td>Keywords</td><td>Count</td><td>Keywords</td></tr><tr><td>1</td><td>12</td><td>instruction</td><td>46</td><td>student</td><td>201</td><td>student</td></tr><tr><td>2</td><td>8</td><td>student</td><td>28</td><td>instruction</td><td>122</td><td> language</td></tr><tr><td>3</td><td>7</td><td> knowledge/performance</td><td>25</td><td>knowledge</td><td>117</td><td>writing assessment</td></tr><tr><td>4</td><td>5</td><td>education/children/disability/skill</td><td>21</td><td>performance</td><td>113</td><td>instruction</td></tr><tr><td>5</td><td>4</td><td>error/gender difference/validity/program/ model/ language/learning disabled. student/classroom</td><td>20</td><td>writing</td><td>96</td><td>performance/</td></tr><tr><td>6</td><td>3</td><td>information/achievement/ science/higher education/acquisition</td><td>17</td><td>assessment children</td><td>85</td><td>English knowledge</td></tr><tr><td>7</td><td>2</td><td>teaching college composition/learning disability/text/working memory/ attitude/reading disability/teacher/ kindergarten/mathematics/ESL student/ adult/analogy/ age/developmental skill/belief/discourse/computer/ strategy/</td><td>15</td><td> language</td><td>74</td><td>skill</td></tr><tr><td>8</td><td></td><td>efficacy/composing process/literacy/ cohesion</td><td>13</td><td></td><td></td><td></td></tr><tr><td>9</td><td></td><td></td><td>11</td><td>skill classroom</td><td>66 62</td><td>quality children</td></tr><tr><td>10</td><td></td><td></td><td>10</td><td>achievement</td><td>59</td><td>feedback/meta- analysis</td></tr></table></body></html>

Section 4.4 illustrates recent articles that have the potential of being highly cited in the future.

# 4.1. Trends in research topics

Prominent research topics were represented by top keywords identified by keyword co-occurrence analyses as isted in Table 1 (ranked by co-occurrence frequency). The timeline views of co-occurring keywords were also generated to provide a clear chrono. logical view of the temporal changes in the research topic, as shown in Figs. 1, 2 and 3. The time span of each main cluster containing no less than 10 keywords) is presented by separate horizontal lines of time. The activenessof one cluster is determined by the published time of cited references in the cluster. The clusters are arranged vertically according to ther sie, with the largest at the top. Keywords are represented by nodes of tre rings. The size of the tre ing corresponds to the frequency of co-occurrences. The colored lines depict the links between co-occurring keywords. In each ten-year period, the research topics were identified by grouping clusters f related keywords, and each topic had sub-topics represented by keywords in each cluster.

The keyword co-occurrence analysis of writing asssment reearch in the last three decades reveals several shifts in the focus and scope of the field.Six main cluster of co-occurring keywords were identified in the decade 1993-2002 as shown in Fig 1. The largest cluster $\# 0$ (disabilities) was active in the whole decade 1993-2002. Cluster $\# 3$ (reading disability) presents similar research topics to Cluster $\# 0$ which consist of 17 keywords. This indicates that the assessment of writing produced by disabled students was a widelyresearched topic in the decade 1993-2002. Achievement and validity' also received scholars attention, as represented by Cluster $\# 2$ and $\# 4$ , respectively.

The analysis of the data in the decade 2003-2012 revealed nine main clusters (see Fig. 2). Cluster $\# 0$ , the largest and most prominent cluster, had the label 'students', similar to Cluster $\# 1$ in the previous decade 1993-2002. The other clusters differed significantl from those identified in the previous decade, which were labelled with keywords such as academic writing (Cluster #1) 'active learning' (Cluster $\# 2$ , 'working memory' (Cluster $\# 3$ , performance' (Cluster $\# 5$ , handwriting' (Cluster $\# 6$ , gender' (Cluster $\# 7$ ) and 'beliefs' (Cluster $\# 8$

Based on the articles published in the decade 2013-2022, nine main clusters were identified. The most prevalent cluster was Cluster $\# 0$ which focused on syntactic complexity'. Other significant research topics represented by cluster labels included strategy instruction' (Cluster $\# 2$ ), 'working memory' (Cluster #3), 'automated writing evaluation' (Cluster $\# 4 ]$ , 'evidence-based practice' (Cluster $\# 6$ ), and 'methods and materials' (Cluster $\# 7$ ). Of note, working memory remained a popular research topic in the two decades 2003-2012 and 2013-2022. The labels of Cluster $\# 5$ and Cluster $\# 8$ , namely L2 writing' and 'second language writing assessment', reflected the increasing interest in writing assessment in ESL and EFL contexts.

A few terms frequently co-occurred across the three time periods, yet they did not reflect research topics but rather the intrinsic characteristics of writing asesment. For instance, student, instuction, language and skill arekeywords that frequenly co-occur in all three decades, indicating that the field of writing asessment inherently relates to teaching language kills. Specificlly, the generic mention of language skills most commonly referred to writing skill. In addition, the keyword writing asessment' did not appear among the top keywords in the decade 1993-2002, but became highly co-occurrent in the subsequent two decades 2003-2012 and 2013-2022. This may indicate that writing assessment developed and consolidated as a distinct area of inquiry in the early 21st century.

The keyword co-occurrence analysis reveals more nuanced shifts in research topics acros three time periods. Generally speaking the overall co-occurrence of keywords increased over the three decades, reflcting the growing interest of scholars in the field of writing assessment. For example, the most frequent term co-occurred 12, 45, and 217 times in each time period respectively.

The analysis also uncovered a more diverse and comprehensive range of research topics in writing assessment research over time

![](img/af580c334fc8888bd970996a83ad699d56f61cc87b9c8bf8d2c9097f92f271ab.jpg)  
Fig. 1. Timeline view of the period of 1993-2002

![](img/73cf58c30bba8aa3822ba7ba2132cb1d21b64034135cde215b07d9dddc762d74.jpg)  
Fig. 2. Timeline view of the period of 2003-2012

![](img/1d5f9bec142d0adc0095aaecbbcfbe83a165b8a54b3166ec2b8ac0d5075a9cf8.jpg)  
Fig. 3. Timeline view of the period of 2013-2022.

According to the strengths of the co-occurrence rlationships, 125 keywords were allocated to six main clusters i the first time period (1993-2002); 177 keywords were divided into nine main clusters in the second time period (2003-2012); 370 keywords were divided into nine main clusters in the third time period (2013-2022). This trend can be attributed to the introduction of new research topics, which were represented by new keywords that appeared in later time periods.

The data revealed that new research topics emerged in the decade 2003-2012 and they maintained their relevance in the decade 2013-2022. Curriculum-based measurement was a new topic in the decade 2003-2012, with 5 co-occurrences; and it remained productive in the decade 2013-2022, with 16 co-occurrences. For example, Puranik and Alotaiba (2012) investigated how spelling and handwriting affect writing skils among kindergarten children. Adams and Simmons (2019) examined gender differences in early writing skill in kindergarten currculums. Another notable development was the rise of feedback' research, which emerged as a key concept in the field of writing assessment in the decade 2003-2012 with 4 co-occurrences, and its frequency increased to 59 co-occurrences in the decade 2013-2022, indicating its high popularit and importance within the field of writing assessment. The scope of feedback research was expanded by reearchers use of various cllocational expressions in the decade 2013-2022, including written correctiv fedback (co-occurrence of 21), corrective feback' (14), teacher feedack (8), er fedback (6), and so on. The expansion of the scope refected the diversity and specificity of feedback reearch. One representative study of tacher fdback is Link et al. (2022), who compared the effctivenes of teacher fedack and teacher feedback plus automatd writing evaluation (AWE) on lower-level and higher-level writing skills. This finding corroborates Hamp-Lyons (2019), who identified feedback as a core research element in the crrent field of writing asessment. As previously ugested, feedback entails a means of empowering students to take an active role in their earning and writing improvement (Crosthwaite l. 2022). The growing attention to feedback' in writing asessment aligns with contemporary educational theories and practices on student-centered education (Hamp-Lyons, 2019; Lee, 2017; Scot, 2014). The recent proliferation of digital tols and online platforms may have also streamlined the provision and reception of feedback on students' writing, contributing to the increasing scholarly interest in this topic (Hyland, 2010).

Similarly, 'meta-analysis was a new topic in the second time period, with 2 co-occurrences, subsequently increasing to 59 co occurrences in the third time period, which indicated increasing interes in synthesizing and reviewing previous research. For instance, Romig et al. (2021) conducted a meta-analysis of 24 articles to compare the criterion validit of dfferent prompt types and durations for curriculum-based measurement of written expression. According to Shneider (2009), the frequent publication of comprehensive reviews often signifies that a field has reached a stable and mature tage of development. The identified frequent emergence of 'meta-analysis' in writing assessment thus may indicate that the field has evolved into a mature stage, in which re searchers endeavor to synthesize knowledge of previous work, re-evaluate ongoing developments, and provide recommendations for practitioners and researchers.

Assessment criteria' and rating cale were two new topics that appeared in the later two time periods, and which focused on more fine-grained aspects of writing assessment. Another emerging research topic was the cognitive dimension of writing, especially the role of elf-regulation in the writing proces. The co-occurrence frequency of self-rgulation increased from 2 in the decade 203-2012 to 15 in the decade 2013-2022. Another aspect that rceived more atention was the assessment of proficiency. The co-occurrence frequency of proficiency' increased from 2 in the decade 2003-2012 to 47 in the decade 2013-2022. Moreover, quality' as the research object became more prominent in the recent decade, with its co-occurrence frequency of 2 in the decade 2003-2012 increasing to 66 in the decade 2013-2022. Writing quality' as a keyword also obtained a high frequency of 32 in the decade 2013-2022. The increased popularit of quality' and writing quality reflects the field's adaptive response to the evolving landscape of writing assessment by prompting in-depth inquiry into the evaluation and enhancement of writing quality. This shift may also be facilitated by the recent innovations in computational methods, which have provided practical ways for both human and automatic judgments of writing quality (Crossley, 2020).

Several research topics first emerged in the decade 2013-2022 and had relatively high cooccurrence frequency. Among them, several research topics showed a close relation to technology, including automated writing evaluation' (32), technology' (14), automated esay scoring (11), and automated feedback (9). For example, Bridgeman and Ramineni (2017) compared two models of AWE that predict the real-world writing performance of graduate students using different feature weights, and examined their impact on different subgroups of international students. Corpus-based writing asessment also developed in this decade, as evidenced by the co-citation frequency of terms like syntactic complexity' (44), lexical sophistication' (13), collocation' (8), lexical diversity (8), corpus lingusics (6) and lexical bundle (5). One representative study of syntactic complexity is Lu and Ai (2015), which compares the syntactic complexity of college-level English writing among writers with diffrent L1 backgrounds. Another recent trend was towards more detailed research on certain aspects of writing quality, such as accuracy' (58) and fluency' (27). Some research topics also focused on learners themselves, such as 'motivation (33), individual difference' (13), identity (8), and student engage. ment/engagement' (6). Additionall, genre (16) first appeared in the decade 2013-2022 indicating the importance of genre-based writing instruction and assessment. Another research topic revision (14) was identified, reflecting the increasing interest in the in. vestigations of students' revision proces and revised writing quality. Of note, the cognitive process of writing was also included in writing assessment reearch, as indicated by the keywords 'cognitive load' and cognitive load theory', which both appeared twice, indicating a sustained attention on the assessment of writing processes.

Some research topics became less prominent or disappeared acros the three time periods. To compare the changes in prominence, the ranks of keyword co-occurrence frequencies were used as indicators f changes. Research topicsrlated to disability showed a higher prominence in the decade 1993-2002, where disability' ranked 4th, disabled students ranked 5th, and learning disability' and reading disability ranked 6th and 7th, respectively. However, disability dropped to 11th and learning disability' to 12th in the decade 2003-2012; and disability' to 34th in the decade 2013-2022. The observed decrease i ranks for disability' research may be due to the emergence and increasing attention towards other topics in writing asessment, rflecting the evolving reearch landscae and shifting priorities in this field.

Interest in error research also declined, dropping from the rank of 5th in the decade 1993-2002 to the rank of 16th in the decade 2003-2012, and to the rank of 38th in the decade 2013-2022. One possible reason is that recent research tends to focus on feedback on error correction instead of solely identifying errors in student writing.

# 4.2. Influential publications

The co-citation analysis identified 97 burst publications across the three decades. No burst publication was detected in the decade

1993-2002; 3 burst publications were identified in the decade 2003-2012; while 94 burst publications were identified in the decade 2013-2022. This sugests that the field of writing assessment has become more mature and impactful over time, with a significant increase in the number of burst publications in the most recent decade.

Table 2 lists publications that were highlyco-cited by articles in the decade 1993-2002, with the threshold of co-citation frequency of 3. It should be noted that, as aforementioned, no burst publications (sigma value $\geq 1 \AA$ ) were identified in this time period, which might be due to the low level of popularity and immature research status of the writing assessment field. The immaturity can also be reflected through the co-citation frequencies of publications in the decade 1993-2002, with the highest frequency of only 4. In contrast, publications that were most highly co-cited in the decade 2003-2012 obtained a frequency of 19, while the most highly co. cited publications in the decade 2013-2022 obtained 41. A possble interpretation is that citing articles published in the decade 1993-2002 drew on diverse sources from other disciplines, as writing assessment lacked specific canonical' or influential' publications, which leads to an unfocused range of references. This low citation count in the early development of a scientific field corresponds to the characteristic cribed by Shneider (2009), that is arhers tnd to fae multifceted challengs and uncranties in establishing a new domain of inquiry in the early stage. One possble reason for such low count might be that the theoretical frameworks guiding their investigations were imprecise and even somewhat inaccurate" (Shneider, 2009, p. 218), due to having not been suficintly teste and refined. Additionally, researchers may have lacked the specialized methods and tols needed to address specific questions arising in a new field.

The most highly co-cited publication in the decade 1993-2002 was a book by Wittock and the American Educational Research Association (1986, Handbook of Research on Teaching (see Table 2). The high level of popularity ofthis book suggest that writing assesment is inherently related to teaching. This could be explained that writing asessment could serve as a valuable resource in supporting pedagogical research, and that writing assessment i not an isolated practice but rather an integral part of understanding and improving writing instruction. Other highly co-cited publications i this decade include Applebee (1990) and Applebee (1994), both of which conducted large-scale writing asessments among different grades of students, assgning writing tasks and conducting national surveys. Abbott and Berninger (1993) was also frequently co-cited, which constructed a model that showed the relationship between writing sills and other developmental skills. White's (1994) book, Teaching and Assesing Writing: Recent Advances in Understanding, Evaluating, and Improving Student Performance,is another highly co-cited book that summarized the variety of writing assessments inside and outside the curriculum. These publications with relatively high co-citation frequencies indicated the primary development of the field of writing assessment.

The development of writing assessment as afield of research was evident from the increased number of frequently co-cited burst publications in the decade 2003-2012 (see Table 3). One of the most representative publications is Weigle's (2002) book, Assessing Writng, which summarizd different type of writing asessment. This publication obtained the highest sigma value and experienced a citation burs from 2009 to 2010. Another strand of influential publications alls under the research theme of writing intruction. For example, Graham and Perin (2007a) analyzed the effectiveness of eleven types of interventions for writing instruction. Graham and Perin (2007b) discused specific teaching techniques in writing instruction for adolescent students. Hayes (1996) proposed a new framework for cognition and affect in writing, adapting to a larger diversty of writing activities, with a citation burst from 2004 to 2006. Another line of influential research examined more refined aspect f writing asessment For example, Eckes (2008) maintained a high co-citation frequency in the lattr two time periods, exploring rater efects in writing asssment. Likewise, Lumley (2002) investigated how raters used analytic rating scales to score writing. McMaster and Espin (2007) evaluated the technical features of curriculum-based measurements, including wring tasks, sample durations and scoring procedures, and it retained its high impact in the decade 2013-2022 (see Table 4). Moreover, Cohen t l. (003) is the second most influential publication with a citation burst from 2003 to 2006. A cloe examination of citing articles of this publication sugests that this book was frequently referenced as avaluable source of guidance for conducting statistical analyses. For example, Amato and Watkins (2011)cited Cohen et al. (2003) when stating the use fregression analysis t xamine the preditabilit f everal measures (.g. lency) in curriculum-based measurement (CBM) to determine learners writing ability. Furthermore, the high impact of this book may signal a prevalence of quantitative analysis in writing assessment,consistent with findings in Hinkel (2013). According to Shneider (2009), after a specific academic field is established, typically a reertoire of methods is then developed to facilitate the investigation ofeld-specific topics and phenomena.

The field of writing asessment witnessed rapid growth in the decade 2013-2022, as evidenced by the numerous burst publications (see Table 4). A representative line of research in this period was informed by sococultural theories that account for the complex and dynamic nature of writing as a communicative activity. Graham (2018), the second most influential publication with a co-citation frequency of 30, proposed a revised writer(s)-within-community model of writing, which incorporated the sociocultural theory of writing community. Notably, this publication remained in the citation burst in 2022, reflecting its significant impact.

Table 2 Influential publications co-cited by articles in the decade 1993-2002.   

<html><body><table><tr><td>Publications</td><td>Co-citation</td><td>Sigma</td></tr><tr><td>Handbook of research on teaching.. Wittrock, M. C., &amp; American Educational Research Association (Eds.). (1986).</td><td>4</td><td>1</td></tr><tr><td>Learning to write in our nation&#x27;s schools: Instruction and achievement in 1988 at grades 4, 8 and 12. Applebee, A. N. (Ed.). (1990).</td><td>3</td><td>1</td></tr><tr><td>Structural equation modeling of relationshps among developmental skill and writing skill in primary- and intermediate-grade writers. Abbott, R. D., &amp; Berninger, V. W. (1993).</td><td>3</td><td>1</td></tr><tr><td>Teaching and assesing writing: Recent advances in understanding, evaluating, and improving student performance. White, E. M. (1994).</td><td>3</td><td>1</td></tr><tr><td>NAEP 1992 Writing Report Card. U.S. Applebee, A. N. (1994).</td><td>3</td><td>1</td></tr></table></body></html>

Table 3 Top 10 publications most highly co-cited by articles in the decade 2003-2012.   

<html><body><table><tr><td>Publications</td><td>Co- citation</td><td>Sigma</td><td>Burst</td></tr><tr><td>Assessing writing. Weigle, S. C. (2002).</td><td>19</td><td>1.7</td><td> 2009-</td></tr><tr><td>A meta-analysis of writing instruction for adolescent students..</td><td>19</td><td>1</td><td>2010</td></tr><tr><td>Graham, S., &amp; Perin, D. (2007a). Writing Next Effctive Strategies to Improve Writing of Adolescents in Middle and High Schools-A Report to the Carnegie</td><td>13</td><td>1</td><td></td></tr><tr><td>Corporation of New York.. Graham, S., &amp; Perin, D. (2007b). Applied multiple regression/correlation analysis for the behavioral sciences (3rd ed.).</td><td>11</td><td></td><td></td></tr><tr><td>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003)..</td><td></td><td>1.41</td><td>2003- 2006</td></tr><tr><td>Assessment criteria in a large-scale writing test: What do they really mean to the raters? Lumley, T. (2002).</td><td>9</td><td>1</td><td></td></tr><tr><td>Technical Features of Curriculum-Based Measurement in Writing: A Literature Review.. McMaster, K., &amp; Espin, C. (2007).</td><td>9</td><td>1</td><td></td></tr><tr><td>Strategy instruction and the teaching of writing. Graham, S., &amp; Harris, K. R. (2006).</td><td>8</td><td>1</td><td></td></tr><tr><td>A New Framework for Understanding Cognition and Affect in Writing.. Hayes, J. R. (1996).</td><td>7</td><td>1.25</td><td>2004- 2006</td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td>National Commission on Writing for America&#x27;s Families, Schools, and Colleges. (2003).</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td>The neglected R: The need for a writing revolution..</td><td>7</td><td></td><td></td></tr><tr><td></td><td></td><td>1</td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td>7</td><td></td><td></td></tr><tr><td>Rater types in writing performance assessments: A classification approach to rater variability.</td><td></td><td>1</td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td>Eckes, T. (2008).</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td></tr></table></body></html>

Another strand of influential publications that has gained prominence in recent years involves the use of computational methods that combine computational linguistics and corpus inguistics,reflecting the interdisciplinary nature of the writing assssment field. Wilson and Czik (2016) compared the effctiveness f teacher feedback with and without automated essay evaluation systems on student writig, and explored teachers perceptions of using AWE systems. Ranall (2018) investigated factors influencing automated written corrective fedback for student writing. Li et al. (2015) re-tested the pedagogical and asssment value of an AWE system for the enhancement of student writing. These three publications experienced a citation burst in 2022, signalingstrong interest in AE. In the same line of corpus-based writing ssessment research, complexity is one of the most explored research topics. For instance, orris and Ortega (2009 discused current concens about the construct complexity, accuracy and flency, as well as isues concerning the interpretation of complexity measures. Lu (2011) analyzed the syntactic complexity of ESL writing, and explored the relationship between students' developmental levels and different syntactic complexity measures. Lu and Ai (2015) investigated the syntactic complexity f collee student argumenttie writing of different 1 backgrounds, and found significant differences betweenglish L1 writers and English-L2 writers. This finding corroborates recent literature that considers complexity as an important construct in determining learners' writing proficiency (e.g., Dong et al., 2023b). Studies that undertook corpus-based analyses of syntactic complexity were still highly co-cited in 2022, as seen in the case of Lu (2011) and Lu and Ai (2015).

# 4.3. Influential journals

Table 5 displays the top 10 most co-cited journals across three time periods from 1993 to 2022. As can be seen, some journals consistently appeared in the top 10 journals acrossall thre time periods: the high rank of Jounal of Educational Pychology was stable in the past thre decades, ranking 3rd in the decade 1993-2002 co-cited 26 times), 1st in the decade 2003-2012 (co-cited 83 times) and 3rd in the decade 2013-2022 (co-cited 351 times) The impact of Writen Communication increased strongly,from being co-cited16 times in the decade 1993-2002 (8th), 49 times in the decade 2003-2012 (5th) to 293 times in the decade 2013-2022 (6th). Review of Education Research featured writing assessment research regularly from 1993to 2012, ranking 2nd in the first two decades (co-citation frequency: 34 and 62, respectively). However, this journal dropped to 10th from 2013-2022, with 242 co-citations, possibly due to the growing prominence of other journals.

Several journals first appeared in the top 10 of highly co-cited journals in the decade 2003-2012. TEs0L Quarterly was highly co. cited in the decade 2003-2012, ranking 4th (co-citation frequency: 53); and retained 4th in the decade 2013-2022 (co-citation fre quency: 327). Similarly, Language Testing was co-cited 41 times in the decade 2003-2012 (7th) and 326 times in the decade 2013-2022 (5th). f note Assessng Writing peared 10th in the decade 2003-2012 cocited 37 times, and roseto 1st with a co-citation frequency of 429 in the decade 2013-2022, indicating its growing influence in the feld. This might be atributed to several factors, such as the increasing maturity and specilization of the field of writig assessment, which neesstated a dedicated journal that addrees various aspects of asssing writing. Another fctor is the high quality and relevance of the articles published i this journal, which made it a more authoritative and frequently cited source of information and knowledge in the field.

Several journals entered the top 10 influential journals list for the first time in the decade 2013 to 2022. Journal of Second Language

Table 4 Publications most highly co-cited in the decade 2013-2022.   

<html><body><table><tr><td>Publications</td><td>Co- citation</td><td>Sigma</td><td>Burst</td></tr><tr><td>A meta-analysis of writing instruction for adolescent students. Graham, S., &amp; Perin, D. (2007a).</td><td>41</td><td>1.46</td><td>2013-</td></tr><tr><td>A Revised Writer(s)-Within-Community Model of Writing. Graham, S. (2018).</td><td>30</td><td>1.31</td><td>2017 2020-</td></tr><tr><td>Writing Next Efective Strategies to Improve Writing of Adolescents in Middle and High Schools--A Report to the Carnegie Corporation of New York..</td><td>24</td><td>1.14</td><td>2022 2013- 2017</td></tr><tr><td>Graham, S., &amp; Perin, D. (2007b). Automated essay evaluation software in English Language Arts classooms: Efect on teacher feedback, student motivation, and</td><td>26</td><td>1.48</td><td>2020-</td></tr><tr><td>writing quality. Wilson, J., &amp; Czik, A. (2016).</td><td></td><td></td><td>2022</td></tr><tr><td>Primary grade writing instruction: A national survey. Cutler, L., &amp; Graham, S. (2008).</td><td>21</td><td>1.06</td><td>2015- 2018</td></tr><tr><td>Towards an Organic Approach to Investigating CAF in Instructed SLA: The Case of Complexity. Norris, J. M., &amp; Ortega, L. (2009).</td><td>30</td><td>1.72</td><td>2018- 2019</td></tr><tr><td>A Corpus-Based Evaluation of Syntactic Complexity Measures as Indices of Collge-Level ESL Writers Language Development. Lu, X. (2011).</td><td>26</td><td>1.09</td><td>2018- 2022</td></tr><tr><td>Modeling the development of written language. Wagner, R. K., Puranik, C. S., Foorman, B., Foster, E., Wilson, L. G., Tschinkel, E., &amp; Kantor, P. T. (2011).</td><td>28</td><td>1.12</td><td>2013- 2018</td></tr><tr><td>S. Graham, C. A. MacArthur, and J. Fitzgerald (eds.): Best Practice in Writing Instruction: Guilford Pres, New York, NY, 2007. Johnson, M. (2009).</td><td>11</td><td>1.03</td><td>2013-</td></tr><tr><td>Technical Features of Curriculum-Based Measurement in Writing: A Literature Review. McMaster, K., &amp; Espin, C. (2007).</td><td>13</td><td>1.08</td><td>2015 2015- 2017</td></tr><tr><td>Automated written corrective feedback: How well can students make use of it? Ranalli, J. (2018).</td><td>19</td><td>1.07</td><td>2020- 2022</td></tr><tr><td>Rethinking the role of automated writing evaluation (AWE) feedback in ESL writing instruction. Li, J., Link, S., &amp; Hegelheimer, V. (2015).</td><td>26</td><td>1.07</td><td>2020-</td></tr><tr><td>Conceptualizing and measuring short-term changes in L2 writing complexity. Bulte , B., &amp; Housen, A. (2014).</td><td>25</td><td>1.14</td><td>2022 2019-</td></tr><tr><td>The Nation&#x27;s report Card: Writing. National Center for Education Statistics. (2012).</td><td>12</td><td>1.02</td><td>2022 2015-</td></tr><tr><td>Throw &#x27;em out or make &#x27;em better? State and district high-stakes writing assessments.</td><td>12</td><td>1.03</td><td>2017 2015-</td></tr><tr><td>Graham, S., Hebert, M.A., &amp; Harris, K.R. (2011). Teaching Writing to Elementary Students in Grades 4 6: A National Survey.</td><td>22</td><td>1.24</td><td>2017 2015-</td></tr><tr><td>Gilbert, J., &amp; Graham, S. (2010). Rater types in writing performance assessments: A classification approach to rater variability.</td><td>12</td><td>1.01</td><td>2018 2013-</td></tr><tr><td>Eckes, T. (2008). Examining the contribution of handwriting and spelling to written expression in kindergarten children.</td><td>10</td><td>1.02</td><td>2016 2017-</td></tr><tr><td>Puranik, C. S., &amp; Alotaiba, S. (2012). Syntactic complexity in college-level English writing: Differences among writers with diverse L1 backgrounds.</td><td>11</td><td>1.02</td><td>2018 2020-</td></tr><tr><td>Lu, X., &amp; Ai, H. (2015). Large-scale assessment, locally-developed measures, and automated scoring of essays: Fishing for red herrings?</td><td></td><td></td><td>2022 2013-</td></tr></table></body></html>

Table 5 Influential journals across three time periods.   

<html><body><table><tr><td></td><td colspan="2"> 1993-2002</td><td colspan="2"> 2003-2012</td><td colspan="2">2013-2022</td></tr><tr><td>Rank</td><td>Co- citation</td><td> Journal</td><td>Co- citation</td><td>Journal</td><td>Co- citation</td><td> Journal</td></tr><tr><td>1</td><td>36</td><td>Research in the Teaching of English</td><td>83</td><td>Journal of Educational Psychology</td><td>429</td><td>Assessing Writing</td></tr><tr><td>2</td><td>34</td><td> Review of Educational Research</td><td>62</td><td>Review of Educational Research</td><td>370</td><td>Journal of Second Language Writing</td></tr><tr><td>3</td><td>26</td><td> Journal of Educational Psychology</td><td>54</td><td>Research in the Teaching of English.</td><td>351</td><td> Journal of Educational</td></tr><tr><td>4</td><td>25</td><td>College Composition and</td><td>53</td><td>TESOL Quarterly</td><td>327</td><td>Psychology TESOL Quarterly</td></tr><tr><td>5</td><td>22</td><td>Communication Journal of Educational Measurement</td><td>49</td><td>Written communication</td><td>326</td><td>Language Testing</td></tr><tr><td>6</td><td>20</td><td>American Educational Research</td><td>41</td><td>College Composition and</td><td>293</td><td>Written communication</td></tr><tr><td>7</td><td>18</td><td>Journal American Psychologist</td><td>41</td><td>Communication Language Testing</td><td></td><td></td></tr><tr><td>:</td><td>16</td><td>Written communication</td><td>40</td><td>Exceptional Children</td><td>291 268</td><td>Reading and Writing</td></tr><tr><td>9.</td><td>12</td><td>Language Arts</td><td>37</td><td>Learning Disability Quarterly</td><td>250</td><td>System Applied Linguistics</td></tr><tr><td>10</td><td>10</td><td>The Journal of Educational Research</td><td>37</td><td>Assessing Writing</td><td>242</td><td> Review of Educational Research</td></tr></table></body></html>

Writing was ranked 2nd, with a co-citation frequency of 370. Reading and Writing, System, and Appied Lingusic also featured writing assessment research in the decade 2013-2022, with a co-citation frequency of 291 (7th), 268 (8th), and 250 (9th), respectively.

Several journals ranked highly in the decade 1993-2002 and fell out of the top 10 in the last decade. For example, Collge Composition and Communication, which was ranked 4th in the decade 1993-2002 and 6th in the decade 2003-2012, dropped out of the top 10 in the decade 2013-2022. Similar patterns can be found in Journal of Educational Measurement, American Educational Research Journal, American Psychologist, etc. This phenomenon may be atributed to various factors, such as the emergence of new journals that compete for atention and citations over time. Other possble explanations can be changes i research paradigms that graduall shift from quantitative to qualitative (Rahman, 2016), and changes in publication preferences such as cross-disciplinary research.

# 4.4. Latest transformative research

The structural variation analysis identified 11 recent publications with transformative potential (2018-2022), using a $\mathbf { C } _ { \mathrm { K L } }$ value threshold of 0.05 (listed in Table 6). Among those publications, 7 were published in 2022, 1 each in 2018 and 2021, and 2 in 2019.

A close examination of transformative publications revealed that one of the most prominent future directions is the continuous integration of computational methods in writing asessment to analyze and proces natural language data. This line of research was mainly presented in detailed investigations focusing on the effects of AWE systems in various types of writing instruction (e.g, collaborative writing) on the enhancement of students' writing performances. The AWE systems can evaluate writing quality and proficiency based on large corpora and ingustic models (Shermis & Burstein, 2013). For example, the second most transformative study $( \mathrm { C } _ { \mathrm { K L } } ; 0 . 3 4 )$ , Sun and Fan (2022) investigated the efect of AWE-aided assessments versus instructor-provided assessments on students' writing performances and writing anxiety. They also explored the role of writing anxiety as a moderating variable in influencing students' writing performance. In another transformative study $( \mathrm { C } _ { \mathrm { K L } } ; 0 . 2 )$ , Chen and Cui (2022) examined the effectiveness of AWE feedback and peer fedback on the improvement of coherence and cohesion in student writing. The findings reported greater enhancement of tudents' use f cohesive devices and cohesive chain formation in the group receving per feedack. Zhang and Chen (2022), with $\mathrm { C } _ { \mathrm { K L } }$ of 0.19, discovered the effects of different assessment approaches (process- and product-based) in computer-mediated collaborative writing classes. This direction was in line with Hamp-Lyons (2019), who found greater use of technology in writig assessment.

In the same line of research, trategy use and acquisition in the context of AWE systems were identified as another dominant future direction. Butterfuss et al. (2022) used an AWE-aided tutoring system to enhance students' persuasive writing strategies $( \mathrm { C } _ { \mathrm { K L } } ; 0 . 2 4 )$ The findings revealed students' improvements in persuasive essay writing between pre- and post- training sessions. Zhang and Zhang (2022), with $\mathrm { C } _ { \mathrm { K L } }$ of 0.2, focused on how students' use of metacognitive strategies in L2 writing was influenced by AWE and non-AWE feedback. The analysis found that automated feedback had a unique impact on students' monitoring strategies. Palermo and Thomson (2018), with $\mathrm { C } _ { \mathrm { K L } }$ of 0.15, implemented AWE systems into self-regulated strategy development (SRsD) instruction and traditional instruction. The findings confirmed the positive effcts of the combination of SRD instruction and AWE systems on students writing quality. These transformative studies demonstrated the close relationship between writing assessment practices and computational methods, which is possibly due to their common interest in understanding and analyzing the linguistic and discoursal features of writing. Computational methods can provide valuable insights and tools for writing asessment, such as enhancing the validity and reliability of scoring methods and the quality of feedback to writers. The prominence of this line of research can be explained by the digital revolution that has transformed the field of applied linguistics (Zhang & Chen, 2022).

Table 6 Latest transformative publications (2018-2022).   

<html><body><table><tr><td>Publications</td><td>CKL</td><td>H</td></tr><tr><td>Perspective taking and language features in secondary students&#x27; text-based analytical writing. Cho, M., Kim, Y.-S. G., &amp; Wang, J. (2022).</td><td>0.38</td><td>1.14</td></tr><tr><td>The effects f an AWE-aided asessment aproach on usines English writingperformance and writing anxiety A contextual onsideration. Sun, B., &amp; Fan, T. (2022).</td><td>0.34</td><td>1.02</td></tr><tr><td>Writing motivation in Chinese children with developmental dyslexia. Yeung, P. (2022).</td><td>0.25</td><td>0.74</td></tr><tr><td>Strategy Uptake in Writing Pal: Adaptive Feedback and Instruction. Butterfuss, R., Roscoe, R. D., Allen, L. K., McCarthy, K. S., &amp; McNamara, D. S. (2022).</td><td>0.24</td><td>0.71</td></tr><tr><td>The effect of feedback on metacognitive strategy use in EFL writing. Zhang, J., &amp; Zhang, L. J. (2022).</td><td>0.2</td><td>0.6</td></tr><tr><td>The effects of AWE and peer feedback on cohesion and coherence in continuation writing. Chen, M., &amp; Cui, Y. (2022).</td><td>0.2</td><td>0.59</td></tr><tr><td>Assessing collaborative writing in the digital age: An exploratory study. Zhang, M., &amp; Chen, W. (2022).</td><td>0.19</td><td>0.59</td></tr><tr><td>Which linuistic ftres predict qualit of agumenttive writig for collee basic witer, and how do those fetres change with insruction? MacArthur, C. A., Jennings, A., &amp; Philippakos, Z. A. (2019).</td><td>0.15</td><td>0.46</td></tr><tr><td>Teacher implementatin of elf-Rulate y Deloment with n uomated wriig aation syst ffets on the amenttive writing performance of middle school students.</td><td>0.15</td><td>0.44</td></tr><tr><td>Palermo, C., &amp; Thomson, M. M. (2018). Writing flexibility in argumentative essays: A multidimensional analysis. Allen, L. K., Likens, A. D., &amp; McNamara, D. S. (2019).</td><td>0.11</td><td>0.34</td></tr><tr><td>The role of L2 writing self-efficacy in integrated writing strategy use and performance. Golparvar, S. E., &amp; Khafi, A. (2021).</td><td>0.06</td><td>0.17</td></tr></table></body></html>

Recent transformative research has also focused on the relationships between L2 writing quality and language, cognitive and affective factors (e., inguistic featres, self-eficy and strategies, perspective taking, and writing motivation). For instance, MaArthur et al. (2019) $( \mathrm { C } _ { \mathrm { K L } } ; \ 0 . 1 5 )$ found the predictability of certain linguistic features, such as referential cohesion and lexical complexit, on writing qualit among collee student, and this contributed to establishing the criteria for valid formative asesments. Similarly, Golparvar and Khafi (2021), with $\mathrm { C } _ { \mathrm { K L } }$ of 0.06, uncovered a positive relationship between writing self-efficacy and the quality of summary writing, extending the knowledge of the role of selfefficacy in writing performance. The most transformative study. $\mathrm { C } _ { \mathrm { K L } }$ 0.38), Cho et al. (2022) added another layer to this line of transformative studies by examining how adopting dual perspectives enhanced writing qualit, shedding light on the integral role of cognitive processes in writing enhancement. This line of researchis further complemented by Yeung (2022) $( \mathrm { C } _ { \mathrm { K L } } ; 0 . 2 5 )$ , who highlighted the role of writing motivation in enhancing writing quality among children with developmental dyslexia. These transformative studies revealed the need for a more interconnected aproach as opposed to the traditional isolated approach of analyzing components in writing, as noted in previous literature (Golparvar & Khaf, 2021). These findings can help not only better understand writing quality and development but also improve the teaching and learning of writing kill and strategies (Crossley, 2020. This corroborates the views of Hartwell and Aull(2023) that writing i a complex and dynamic proces, influenced by individual, social, and cultural factors, which signals the likely importance of relational analyses in future research.

To conclude, the past five years of transformative reearch have witnessed a shift towards more fine-grained reearch topics, such as the relationships between writing qualit and various factors. The cross-disciplinary integration of writing asessment with computational linguistics is also evident, as presented by investigations into the implementation of AWE systems to support L2 writing development. The expansion of the writing assessment field by integrating approaches and methodologies from other fields was also described in Hamp-Lyons (2001, 2002) and Riazi et al. (2018).

# 5. Conclusion

The present study adopted an extensive bibliometric approach to analyze the trends in research topics, publications, and journals over the past three decades, and the most recent transformative publications in writing asessment. The keyword co-occurrence analysis (Research Question 1) showed two trends in the writing asessment field: a rise in the overall occurrence frequencies indicating the increasing popularity of the field and an expansion of research topics, evidenced by the larger number of topics identified in the later periods. The changes in the research topics indicated the gradual integration into writing asessment of technology-based methods (e.g., AwE), corpus-based techniques (e.g., syntactic complexity), more specific aspects of writing assesment ., accuracy; fluency), and lner-relatd factors (e, moivation individualdifference). The analys aso showed that research on disabilities and errors in writing has become less prominent. The identification of influential publications (Research Question 2) confirmed the increasing popularit of the field of writing assessment, as suggested by the number of burs publications in each of three time periods. The most influential publication that was co-cited by articles in the decade 2003-2012 is Weigle (2002), Assesin writing, and the most influential publication that was co-cited by articles in the decade 2013-2022 is the meta-analysis by Graham and Perin (2o007a). Recent influential publications were crossdisciplinary, and associated with sociocultural theories computational methods and corpus-based methods. The crossdisciplinary features of research disciplines were echoed in Park and Nam (2017) and Crosthwaite et al. (2022), in which the development of scientific knowledge is "a product of active and dynamic interactions in all walks of academia" (Park & Nam, 2017 p. 428). Our results regarding influential journals (Research Question 3) showed a variety of changes in top journals in the past three decades. Asssing Writing and Journl of Second Language Writing rose to become the first and second most influential journals in the decade 2013-2022.

The findings regarding the influential publications (Research Question 2) and the latest transformative research (Research Question 4) can help shed light on the potential directions of future research. This was identified as including: writing assessment research informed by sociocultural theories, the integration of computational methods into assessng writing quality, and explorations of relationships between L2 writing quality and various factors. These research topics represent the forefront of writing assessment resech nd poss the caacit to shap th re dtions of this field  iht of the constey in thejectives  cope f the two prominent journals identfied in this study, Asessing Writing and the Journal of Second Language Writing, we posit that these journals will retain their position as the primary plaform for disseminating writing assessment research in the future.

This study provided a comprehensive overview of writing assessment research by identifying prominent research topics, influential publications, influential journals and the latest transformative research. Our findings demonstrated that bibliometric analysis is valuable for understanding trends in writing asessment, a it can analye large quantitie of quantitatie data to reveal developmental trends. The co-citation analyses revealed papers and journals that are currentl high-impact in writing assessment, and which were expected to maintain their influential role in the near future. The structural variation analysis has proved to be advantageous in uncovering inovative research that holds the promise of potential future mainstream of writing assessment research (Bornmann & Daniel, 2008). By charting the development of writing assessment and identifying possible future research directions, the study can provide practical orientation to both established and novice researchers in the field.

However, it is necessary to point out several limitations of the present study. Firstly, ths study adopted keyword co-occurrence analyses in bibliometrics to identify the main research topics of the articles in the dataset. Although keywords have been widely used in bibliometric analysis, drawing on Dryer's (2019) suggestion, future bibliometric analysis may need to consider a broader context to acount for potential factors that could impact the interpretation of keywords, i order to enhance precision and specificity of keyword analyses. Second, the interpretation of results related to the impact of research topics needs caution, and potential complexities and nuances need to be considered when reaching more accurate and well-founded conclusions. Third, only publications from the WoS platorm were included in the analysis to represent the writing asessment field. Future bibliometric studies could include publications from additional platforms such as Scopus. Fourth, the Matthew effect should be acknowledged here, whereby studies by well-known academics are more likely to be cited than less well-known academics. While some citation issues such as self-citation have been excluded from the co-citation analysis, ctation bias could not be full adresed. Future bibliometric analysis involving citations or co-citations may take other citation-related issues into consideration.

# Data Availability

Data will be made available on request.

# Acknowledgments

We would like to acknowledge our appreciation for the support received from the National Social Science Foundation of China (No. 21FYYB052) and the Shandong Province Education Reform Project (No. Z2022151).

# Appendix A. Extended list of Table 1

<html><body><table><tr><td></td><td></td><td></td><td></td><td></td></tr><tr><td>11</td><td>9</td><td>working memory/school/model/disability/acquisition/literacy</td><td>58</td><td>accuracy</td></tr><tr><td>12</td><td>7</td><td>learning disability/academic writing/belief</td><td>57</td><td>learner</td></tr><tr><td>13</td><td>6</td><td>strategy</td><td>53</td><td>writer</td></tr><tr><td>14</td><td>5</td><td>curriculum based measurement/ criterion validity/ English/ comprehension</td><td>51</td><td>impact</td></tr><tr><td>15</td><td>4</td><td>written/education/2nd language/developmental skill/ intervention/feedback</td><td>47</td><td>education/proficiency</td></tr><tr><td>16</td><td>3</td><td>error/attitude/conception/age/tool/computer/written expression/adoloscent literacy/beginner writer/technical.</td><td>44</td><td>syntactic complexity/literacy</td></tr><tr><td>17</td><td>2</td><td>feature behavior/assessment criteria/childrens&#x27; knowledge/deficit/. attention/writing proficiency/care/self regulation/boy/ autism/cell/student writing/awareness/science education/ memory/rating scale/connection/success/writing</td><td>40</td><td>text/acquisition/L2 writing</td></tr></table></body></html>

35 task/strategy   
33 motivation/achievement   
32 writing quality/model/automated writing evaluation   
29 teacher/formative assessment   
28 working memory/academic writing/reading comprehension/   
comprehension   
27 fluency/perception/belief   
26 writing instruction   
25 intervention   
24 adolescent   
23 validity/written expression   
22 L1/vocabulary/complexity   
21 grade/2nd language/written corrective feedback   
20 school/classroom   
19 level   
18 efl writing   
17 higher education/second language writing/efficacy   
16 feature/learning disability/curriculum-based measurement/   
genre/index   
15 self regulation/cohesion   
14 professional development/corrective feedback/construction/.   
technology/revision/self-efficacy

46

13 ability/individual difference/lexical sophiscation   
12 error/gender difference/written language   
11 automated essay scoring/discourse   
10 design/academic/academic achievement/attitude/corpus/ academic language/essay   
9 foreign language/regulated strategy development/automated feedback   
8 perspective/identity/collocation/kindergarten/reliability/ generalizability theory/score/1st grade/teacher feedback/ lexical diversity/science/linguistic feature/technical feature judgment/strategy instruction/automated writing evaluation (awe)/primary grade/chinese/writing evaluation/validation/ outcm/assessing writing/peer assessment/gender behavior/l2/context/connection/pattern/peer feedback/ executive function/academic performance/student engagement/engagement/competence/effect size/computer/ argumentative writing/transcription/error correction/corpus linguistics/learn/critical thinking of the art/test/lexical bundle/construct/standard/writing development/diversity/medical education/formulaic language/ language impairment oral language   
4 literacy skill/emotion/attention/experience/goal/performance assessment/difficulty/autism spectrum disorder/curriculum/ disciplinary literacy/form/linguistic complexity/assessment literacy/integrated writing assessment/pair/national survey/ early adolesence/middle school/elementary student/disability/ english language learner/high school student/developmental skill/natural language processing/syntactic complexity measure/classroom assessment/explicit/college student/ collaborative writing/handwriting problem/assessment for learning/implementation/pedegogy/fit index/artificial intelligence word/analytic rubric/classification accuracy/disorder/written/ self/caf/writing skill/challenge/rater-mediated assessment/ predictor/confirmatory factor analysis/classification/richness/ performance feedback/many-facet rasch measurement/high school/African American english/sophistication/reflection/ implicit/grammatical complexity/cognitive load/efl writing assessment/hand/rating quality/mode/esl/collaboration/ writing disability/wiki/frequency/argument/goal orientation/ language learning disability handwriting readiness/anxiety/inquiry/physics/high functioning autism/state writing assessment/contract grading/ community/listening comprehension/osce/argumentation/ instructional strategy/early writing/2nd language performance/methods and material/coherence/writing strategy/faculty/middle/information/peer/awareness/ dysgraphia/grammar/intervention study/analytic rating/ collaborative prewriting/generation 15/composition skill/ capacity/cognition hypothesis/issue/primary school/executive control/speaker/pedagogical issue/comparative judgement/ language testing/flipped classroom/covariance structure analysis/english for academic purpose/bias/preschool/ agreement/united states/intelligent tutoring system/university admission/prompt/medicine/improving classroom teaching/ digital literacy/automated writing assessment/esl student/ lexical complexity/coh metrix/early grade writing assessment/ expert/program/assessment/impairment/automated written corrective feedback/writing assessment/esl writing/common core state standard/secondary education/marking/l2 writing quality/elementary education/consequence/multiple choice/ creativity/elementary/environment/writing quality/age/ capacity theory/communication/many-facet rasch model/ linguistics/support/language acquisition/efl learner/human rater/first-year writing/integrated writing/academic purpose/ curriculum based measure/cognitive load theory/adhd/higher education/organization/peer response/collaborative learning/ interactive learning environment/awe feedback/academic literacy/speed/rater variability/grammar correction/first-year composition/ielts preparation/theoretical perspective/ developmental dyslexia/follow up/rater effect/scientific (continued on next page)

argumentation/and material/selection/comparability/ prevalence/spoken/assessment as learning/plagiarism/ adolescent l2 student/middle school student/research methodology/goal setting/scenario-based assessment/growth/ eap/item response theory/criteria/chemical education research/noun phrase complexity/1st language/beginning writer/integrated writing task/persuasive writing/elementary school/attention-deficit/hyperactivity disorder/object/first grade/chemistry/lexical complexity/sla

# References

Adams, A M & immons, FR (2019) Exporing indvial and gender differenes i erly writig peromance. Reding and Witing 32, 235263   
mato, J , . 01.  tivt  tin  o gh. h  ofi 44, 195-204 https://doi.org/10.1177/0022466909333516   
Ari, ., rik  (017. od anag wing ubicatins i e of scie ibiomerc anlyis. blition, 1), 4 p/o.g/10.3390/ publications5010004   
Arydost , aia,    h . 200. n xie  mpn  f mn  t a n LA research. Frontiers in Psychology, 11, 1-29. https://doi.org/10.3389/fpsyg.2020.01941 research (pp. 11-23). The Guilford Press.   
Bde 11 ft    win h ot i   i the nted States. Assessing Writing, 16, 189-211. https://doi.org/10.1016/j.asw.2011.03.001   
a , 08       .  of  1), 45. /. 10.1108/00220410810844150   
an hd  018 the     r sd     o occurrence analysis. Scientometrics, 114(2), 427-437. https://doi.org/10.1007/s11192-017-2591-8   
Bridn 1 d    sg Writing, 34, 62-71.   
Che . .        e i Science and Technology, 57(3), 359-377. https://doi.org/10.1002/asi.20317   
Chen, C. (2014). The CiteSpace manual. College of Computing and Informatics, 1(1), 1-84.   
Chen, C. (2016). CiteSpace: A practical guide for mapping scientific literature. Hauppauge, NY: Nova Science Publishers.   
Che 2 , 1 (5), 593-608.   
Che      ti.   heicn Society for Information Science and Technology, 61(7), 1386-1409. https://doi.org/10.1002/asi.21309   
Cooper, P. L. (1984). The assessment of writing ability: A review of research. ETS Research Report Series, 1984(1). i-46.   
Crossey, S. A.(2020). Linguistic features in writing quality and development: An overview. Jounal of Writing Research, 11(3), 415-443. on L2 wCF. Journal of Second Language Writing, 58, Article 100934. htps://doi.org/10.1016/j.jslw.2022.100934   
De Bellis, N. (2009). Bibliometrics and citation analysis: From the science citation index to cybermetrics. Scarecrow pres..   
Dong    ckn 203.   oc    rc i  e ic. (45),, 163-189. https://doi.org/10.17398/2340-2784.45.163   
Dong, J., Wang,  & ukL 2023)ap  th dcliion f yic coxt n s  wi 113, 102974 https://doi.org/10.1016/j.system.2022.102974   
og,    23th i ic ./ 10.1017/S0958344022000222   
Dryer, D. B. (2019). Divided by primes: Competing meanings among writing studies' keywords. Collge English, 81(3), 214-255.   
Graham, S., ert, M., & Hars, K R. (2015). Formative asesment and writig: A met-analysis. The Elementary Schol Jonal,11(4, 523-547. the advancement of opportunity (pp. 41-70). Fort Collins, CO: WAC Clearinghouse.   
Hammond, J.W. (2019a). Deinitive programs: Rhetoric, computtio, and the (prehistory of controery over automated essy scoring, 1954-1965. n J.Jkw, .el,  oh, J., .hr,  J.r .. d .),  mh wg, o  oi . 91-112). University Alabama Press.   
Hd 019   vi sg 9408ng 4210425. . org/10.1016/j.asw.2019.100425   
Ham-Lys  201). Fh wtin st . ia .), n nd  win . 11728)w aene Erlbaum.   
Hamp-Lyons, L. (2002). The scope of writin sessment. Asessing Writing 8(1), 5-16. http:/doi.org/10.1016/1075-2935(02)00029-6   
Hamp-Lyns, L (2019. Rfltg n th ast, mrcng th fr s Wig, 42, icle 10423. p/i./10.1016/..2019.100423   
Hae,   . 10.1016/j.asw.2023.100769   
Hinkel, E. (2013). Handbook of research in second language teaching and learning (Ed.). Routledge.   
Hd 0          7182.   
Hyland,  Ji,  (2022.ction in wie te  bibmric td f ulisd h.   d   n chig.   
Lam  07 t 317.016.0.00   
Lee, I. (2017). Classroom writing assessment and feedback in l2 school contexts. Springer Berlin Heidelberg.   
Le   209  np sti r 0206ri i  ts i stcs,  540561. https://doi.org/10.1093/applin/amy003   
Li,      . 20 st   ri i   p  r199 to 2006. Scientometrics, 80(1), 39-58.   
Link ., Mad,  & Rh, (202). mct f  witing tion n ther fack, stdet risio, d witin ioeme. Computer Assisted Language Learning, 35(4), 605-634. org/10.1016/j.esp.2020.10.003   
Lu, .        0    ki . Informetrics, 14(4), Article 101066. https:/doi.org/10.1016/j.joi.2020.101066   
O'Neill, P., Moore, C., & Huot, B. (2009). Guide to college writing assessment. University Press of Colorado.   
Park   017. st   9720 n . c  33 2757./o. 10.17250/KHISLI.34.3.201712.008 asw.2019.100418   
Pritchard, A. (1969). Statistical bibliography or bibliometrics? Journal of Documentation, 25(4), 348-349.   
Rahman, .016) The a ad d  using qlittie d qttiveaphe nd mt i ge ig an sment research: A literature review. Journal of Education and Learning, 6(1), 102. https:/doi.org/10.5539/jel.v6n1p102   
Rzi  h8t    906 Language Writing, 41, 41-54. https://doi.org/10.1016/j.jslw.2018.07.002   
Romig, ., le,  Tre, . J od, J.W. 2021 aasi f prot anatin for crri-a mme f wen angag. Exceptionality, 29(2), 133-149.   
Scott, M., & Tribble, C. (2006). extual pattems: Key words and corpus analysis in language education (Vol. 2). Jon Benjamins Publishing.   
Scot, . 14 i  fi 9(./0.100 13562517.2013.827639   
Seastia, ,  h. (2021). - mms of bel Pri w r.  e, 168, e 0254. h/./10.1371/ journal.pone.0254744   
Shermis, M. D., & Burstein, J. (2013). Handbook on automated esa evaluation: Current appications and new directions. Routledge..   
Shi  019 th    ai i00201i, 11(13), 3716.   
Sheider, 009. r sto a c i   f st. d n c ci, 35, 217-23. h/g/.106/. tibs.2009.02.002   
omp .2.  t  ngt   11. 10.1016/j.asw.2012.02.001   
Sun,Y., & Lan,. (2021). Rrh trens i ns stdes on wriig  bibliomeric alys yst, 103, Aicle 102640. htp:/do.org/10.1016/. system.2021.102640   
al,   . 01       919r  31 137-146.   
rors,  c   s 012ive  io    cie, 13, 117-123.   
White, EM. (194). sue and problems in writing sesmet Assin Wriig, 11) 11-27. htp:/doi.org/10.1016/1075-2935(94)90003-5   
ia D       021  o9901rcs Research, 8(1), 5. https://doi.org/10.1186/s40779-021-00300-z   
Yancey, K B.(199). Looking ack as we lo forward: Historicizing writing aesment. Colle Comosition and Commnicatin, 50(3),483-503.   
hng,      0e     ri study using CiteSpace I. Journal of Traditional Chinese Medical Scince, 7(2), 189-198. https://doi.org/10.1016/jtcms.2020.05.006   
Zha, . 015.is   cr s  o t, ie,  e (, 1-20. https://doi.org/10.1016/j.asw.2019.100421

J, ,  t    tr t,    r        , ReCALL and System, among others.