# Effectiveness and inclusiveness of locally adapted human-delivered synchronous written corrective feedback for English referential articles

Taichi Yamashita

To cite this article: Taichi Yamashita (2024) Effectiveness and inclusiveness of locally adapted human-delivered synchronous written corrective feedback for English referential articles, Computer Assisted Language Learning, 37:5-6, 1074-1107, DOI: 10.1080/09588221.2022.2068612

To link to this article: https://doi.org/10.1080/09588221.2022.2068612

# Effectiveness and inclusiveness of locally adapted human-delivered synchronous written corrective feedback for English referential articles

Taichi Yamashita $\textcircled{1}$

The Department of World Languages & Cultures, The University of Toledo, Toledo, OH, US A

# ABSTRACT

The present paper reports on the effectiveness and inclusiveness of human-delivered synchronous written corrective feedback (SWCF) in paired writing tasks. Replicating Yamashita, Study 2 and Study 3 each conducted a classroom-based quasi-experimental study in an English-as-a-Second-Language (ESL) writing program at an American university. In Study 2, 50 learners were assigned to either of the two experimental groups (direct, indirect) or the control group based on their language analytical ability (LAA). All the three groups worked on two in-class computer-mediated animation description tasks in pairs for 50minutes. The two experimental groups received either direct or indirect SWCF on their uses of the referential articles during the tasks, while the control group did not. Learners’ article use was assessed with an animation description test and a sentence rewriting test on a pretest (one week prior to the treatment), posttest (a few days after), and delayed posttest (two weeks after). Inclusiveness of SWCF was explored by examining changes in performance of high LAA and low LAA learners separately. Study 3 recruited another cohort of 51 learners from the same writing program and replicated Study 2 with a modified test in place of the sentence rewriting test. Findings suggested that only the direct group improved to a greater extent than the control group, and this finding was found only in Study 2, potentially questioning the effectiveness of SWCF in this context. However, SWCF improved low LAA learners’ article use to a comparable extent to high LAA learners, contributing to inclusive classroom teaching.

# KEYWORDS

Human-delivered synchronous corrective feedback; evaluation; practicality; grammar; aptitude-treatment interaction; replication

# Introduction

One of the practical challenges in making feedback on writing tasks effective is returning it to students in a timely fashion. After submitting a paper, students typically wait for teachers’ feedback for days (Liu & Brown, 2015). This is partly because students’ moment-by-moment writing is usually covert and thus not easily accessible to teachers. Although unavoidable, delayed feedback may cause errors that could have been avoided if feedback had been provided as learners wrote and prevent students from modifying their knowledge about the target language in a single class hour (Shintani & Aubrey, 2016). Furthermore, students may perceive considerably delayed feedback as a lack of teaching skills, potentially evaluating the instructor negatively (Lee & Du, 2021). In short, teachers’ real-time feedback has potential to facilitate learners’ language use, expedite their learning, and to maintain their positive perception of the instructor. This paper uses the term synchronous written corrective feedback (SWCF) to refer to textual responses to incorrect language use that are provided reactively as learners work on a writing task.

Human-delivered SWCF is advantageous over automated SWCF in two significant ways. First, as comments are provided by the instructor, human-delivered SWCF may be perceived as trustable, which is said to increase revision engagement (Ranalli, 2021), by learners. Second, while many automated SWCF tools are available only for English, human-delivered SWCF is applicable to other languages, including those less commonly taught, for which resources are typically limited. However, human-delivered SWCF raises an essential concern among front-line teachers, practicality. The present study is thus meaningful as it examines the effectiveness of SWCF and its contribution to inclusive classroom teaching in an environment where SWCF is more conveniently delivered.

# Background

# Considering practicality of human-delivered SWCF in ESL writing programs at American universities and its local adaptations

Practicality has been one of the core qualities in computer-assisted language learning (CALL) as the field centers around pragmatism (Chapelle, 2001). When a CALL task is deemed impractical, whether theoretically or empirically, some adaptations need to be considered. Human-delivered SWCF requires one instructor to monitor multiple texts being written, and thus the instructor’s capability to provide SWCF will vary depending on the class size. Shintani and Aubrey (2016) expressed their opinion that SWCF is feasible for 20 to 25 students when a teacher forms groups of four to five. In an ESL writing program in U.S. universities, the context in which the current study was conducted, one class is recommended to have 20 students at maximum (CCCC Executive Committee, 2015). Also, Lee and Du (2021) surveyed

506 ESL writing courses from 2015 to 2018 at an American university, finding that class sizes ranged from 10 to 21 with the average of 18 students. Such class sizes may decrease perceived feasibility of SWCF that is provided to each individual. Accordingly, while practicality remains empirical inquiry, some adaptations of SWCF need to be considered if SWCF is to be put into practice beyond research contexts.

Another concern is writing fluency as one teacher needs to keep abreast of learners’ ongoing text construction. Shintani and Aubrey (2016) study recruited learners who had scored 460 to 500 in the paper-based TOEFL, which can be deemed approximately as the B1 level (intermediate) on the Common European Framework of Reference for Languages (CEFR) (Lim et  al., 2013). This proficiency level may have enabled their ideal operationalization of SWCF, where ‘SCF was targeted at a problematic sentence before students started the next sentence’ (p. 303). Meanwhile, ESL writing programs for fully matriculated students (i.e. non-conditional admission) at U.S. universities typically include students who possess the B2 level (upper-intermediate) at minimum (Papageorgiou et  al., 2015). While heterogeneity in proficiency is readily acknowledged, incoming international students are usually expected to have a higher level of academic writing fluency than participants in Shintani and Aubrey (2016). Therefore, practicality of SWCF argued in Shintani and Aubrey (2016) context cannot be presupposed in this particular context. Through this judgmental evaluation (Chapelle, 2001), additional considerations need to be given so that SWCF is conveniently executed in typical classroom environments.

# Unique effectiveness of SWCF for grammar learning from a metaanalytic perspective

SWCF is not only innovative but distinctively effective for grammar learning. Shintani and Aubrey (2016) pioneering study compared the effects of asynchronous written corrective feedback (AWCF) and SWCF on the accuracy of English hypothetical conditional structures. One group of learners received SWCF via Google Docs while they were describing their own hypothetical events in the past, while another group of learners received AWCF 10 minutes after their task completion. The other group worked on the same writing tasks without any feedback. Their uses of hypothetical conditional structures were assessed with a text reconstruction task immediately before (pretest), immediately after (posttest), and two weeks after the posttest. Shintani and Aubrey (2016) found that SWCF resulted in a Cohen’s $d$ of 1.48 on the posttest and of 1.20 on the delayed posttest (compared with a group that did not receive any feedback), suggesting that learners who received SWCF were able to use hypothetical conditional structures more accurately than learners who did not receive SWCF with the mean differences of 1.48 and 1.20 in standard deviation units. These large effect sizes were clearly contrasted with a Cohen’s $d$ of .83 on the posttest and .57 on the delayed posttest for AWCF. These effect sizes for SWCF seem to be in stark contrast with effect sizes of SWCF reported over the past three to four decades. Kang and Han (2015) analyzed 20 primary studies published from 1980 to 2013 that employed a pretest-posttest design with a group of learners who received AWCF and another group of learners who did not (please see their Appendix C on p. 18 for meta-analyzed primary studies). They aggregated effect sizes to estimate the effectiveness of AWCF, finding that AWCF is associated with a median effect size of .48 $\left( Q _ { 1 } = . 3 2 \right.$ , $Q _ { 3 } = . 6 2 )$ ). Adopting Kang and Han (2015) methodology, Lim and Renandya (2020) analyzed 35 primary studies from 2001 to 2019, and found a median effect size of .50 for AWCF $\mathrm { \Delta } Q _ { 1 } = . 2 9$ , $Q _ { 3 } =$ 1.08) (please see their references on pp. 17-23 for meta-analyzed primary studies). These medium effect sizes are close to those for AWCF in Shintani and Aubrey (2016) (i.e. $g _ { \mathrm { p o s t t e s t } } \ : = \ : . 8 1$ , $g _ { \mathrm { d e l a y e d } } = . 5 6 )$ , whereas the effect sizes for SWCF exceed the third quartile in both meta-analyses1 (i.e. $g _ { \mathrm { p o s t t e s t } } = 1 . 4 6 $ , $g _ { \mathrm { d e l a y e d } } = 1 . 1 8 )$ . This meta-analytic perspective seems to suggest that SWCF could be twice as effective as AWCF.

It should be noted that meta-analyses are not flawless and need to be interpreted with caution (see Boers et  al., 2021; Ellis, 2018; Truscott, 2020). Boers et al. (2021) and Truscott (2020), for example, argued that meta-analytic findings are not stable due to meta-analysts’ subjective decision-making while designing their study. Despite such limitations, the reported unique effect sizes for SWCF in Shintani and Aubrey (2016) suggest its great potential. However, teachers may feel that these results pertain only to small-sized classrooms where one instructor can conveniently provide SWCF to every student at once. It is thus worthwhile examining whether these results can be generalized to more practical contexts, such as those where the number of to-be-monitored documents is halved by forming student dyads.

# Follow-up studies of Shintani and Aubrey (2016)

To my knowledge, there have been two studies that investigated SWCF. Yamashita (2021), Study 1, investigated if Shintani and Aubrey (2016) findings are generalizable to task settings where a Google Docs document is shared by two students who collaborate on a writing task. Study 1 recruited 52 English-as-a-Second-Language (ESL) learners in a writing program at a large research university in the United States. Individual learners were randomly assigned to either an experimental group or a control group. Invited to a computer classroom, both groups worked on two animation description tasks in pairs. During the tasks, only the experimental group was provided with indirect SWCF, which informed learners of the error occurrence related to referential definite and indefinite articles and prompted their revision. Changes in learners’ uses of the definite and indefinite articles were examined with an animation description test, which they worked on individually a few days after the treatment (posttest) and two weeks later (delayed posttest). Study 1 found that the experimental group increased their accuracy score from the pretest to the posttests, whereas the control group did not improve. The group difference was accompanied with small effect sizes on the posttest and the delayed posttest. This finding suggested that SWCF has potential to improve learners’ grammatical accuracy even when used in task environments that are more practical in classroom settings.

At the same time, the small effect sizes found in Study 1 contrast with Shintani and Aubrey (2016) large effect sizes. This discrepancy was potentially caused by the fact that Shintani and Aubrey (2016) provided the correct form in response to learners’ errors, which is referred to as direct CF, whereas Study 1 simply indicated the error occurrence, which is referred to as indirect CF (Ellis, 2009). Meta-analyses in fact suggest that direct and indirect AWCF are equally effective, direct AWCF being 1.22 to 1.67 times as effective as indirect AWCF (Kang & Han, 2015; Lim & Renandya, 2020). To my knowledge, Kim et  al. (2020) is the only study that investigated direct and indirect SWCF, though they were handwritten (i.e. not computer-mediated). In their study, one group received the correct form in response to their error commitment (i.e. direct SWCF group), while another group had their errors circled (i.e. indirect SWCF group), and the other group did not receive any SWCF (i.e. control group). Learners underwent six tasks that addressed 12 grammatical features collaborating with a partner. The two experimental groups achieved significantly higher accuracy than the control group on the posttests, but the two groups did not differ to a significant extent. Effect sizes for direct SWCF ranged from small to medium, whereas those for indirect SWCF ranged from small to large. These findings provide support for SWCF, whether direct or indirect, especially in terms of external validity, as its effectiveness was found for 12 linguistic features and tasks that were carried out in pair work. Due to the scarcity of studies that investigated direct and indirect SWCF at once, replicating Yamashita (2021) with direct SWCF was expected to increase external validity.

# Biased effectiveness of SWCF towards a subgroup of learners

Although Shintani and Aubrey (2016), Kim et  al. (2020), and Study 1 provided some support for SWCF, they did not provide any evidence regarding whether SWCF is effective across learners with different characteristics, such as aptitude and learning style. This biased effectiveness, traditionally referred to as aptitude-treatment interaction (ATI) (Cronbach & Snow, 1977), has been widely investigated in CALL (Chapelle & Heift, 2009; Kam et  al., 2020; Mizumoto & Chujo, 2016; Payne & Whitney, 2002; Varol & Erçetin, 2021). For example, Mizumoto and Chujo (2016) found that data-driven learning, which was conventionally deemed beneficial for inductive learners, was effective for both inductive and deductive learners. If SWCF is found to marginalize some learners, such evidence may guard against stakeholders’ hasty decision to incorporate SWCF. If such bias is not confirmed, SWCF can be enjoyed by a larger number of learners, who would not be reached out if stakeholders were too cautious. As CALL evaluation stresses stakeholders’ decision-making regarding the CALL task, taking into account individual characteristics is critical as ‘a thorny question’ (Chapelle, 2001, p. 82).

One of the major learner variables known to moderate the effectiveness of AWCF is language analytical ability (LAA), ‘the capacity to infer rules of language and make linguistic generalizations or extrapolations’ (Skehan, 1998, p. 204). When exposed to AWCF on a linguistic feature, some learners are more capable than others of applying the learning experience to another encounter with the feature (Benson & DeKeyser, 2019; Sheen, 2007; Shintani & Ellis, 2015; Stefanou & Révész, 2015). To my knowledge, only Arroyo and Yilmaz (2017) have investigated the effectiveness of SWCF for different LAA levels. Forty-five L2 Spanish learners worked on a 30-minute information gap task in Skype. One group received the correct form immediately after their nontargetlike language use of noun-adjective agreement, while another group was exposed to the correct form after they completed the entire task. Learners were assessed with an oral production test and a grammaticality judgment test before and after the information gap task. The control group did not receive any feedback. Their results suggested that the effectiveness of SWCF was not moderated by LAA, providing some support for SWCF in view of inclusive teaching. Perhaps, because SWCF draws learners’ attention to form during, not after, a task, their engagement with rule identification may diminish (Sato & McDonough, 2020). Clearly, more studies are needed.

# Research questions

The present paper reports on two classroom-based studies, Study 2 and Study 3, which serve as an approximate replication of Study 1, Yamashita (2021). It is argued that replication is critical to any scientific endeavors (Porte, 2012), and CALL is not an exception (Bikowski & Schulze, 2015;

Chun, 2012; Smith & Schulze, 2013). Study 2 and Study 3 are explicitly labelled as replication of Study 1 in order to facilitate readers’ ‘evaluation of the extent of changes to previous research procedures and materials’ and to ‘improve the quality of syntheses and meta-analyses’ (Marsden et  al., 2018, p. 366). Such explicit labelling increases retrievability of the initial study and replication, a critical component of replication (McManus, 2021). Study 2 and Study 3 are also characterized as approximate replication, which ‘involves repeating the original study exactly in most respects, but changing nonmajor variables (in a way that allows for comparability between the original and replication studies)’ (Porte, 2012. p. 8). The three studies can be compared much more reasonably than studies that differ greatly in their study design. Study 2 and Study 3 were guided by the following research questions:

RQ1: To what extent are direct and indirect SWCF effective for improving individuals’ grammatical accuracy of the English referential indefinite and definite articles?

RQ2: Is there any effectiveness of direct and indirect SWCF biased towards a certain level of LAA?

Study 2 and Study 3 are similar to Study 1 in that they investigated the effectiveness of SWCF, but they differ from Study 1 as these two replication studies investigated the moderating effects of LAA on the effectiveness of SWCF. Study 2 and Study 3 kept many study design features identical, including the instructional context and the target features to enhance comparability across the three studies. Study 3 was motivated due to concerns about learners’ low engagement with peer interactions (please see Treatment instruments) and insufficient time and participants’ fatigue in the sentence rewriting test (please see Error correction test – Study 3) in Study 2. This change was to contribute to more precise evaluation of SWCF as its claimed effectiveness assumes precise measurement of learners’ grammatical knowledge regarding the referential articles.

# Methods

# Instructional context and participants in Study 2 and Study 3

The present study recruited learners from five classes of an ESL writing course at a large-sized Midwestern research university in the U.S. Learners registered for this course because they had failed the writing section of an in-house placement test, which was designed to measure arriving international students’ academic writing ability. The curriculum aimed to improve their ability to write academic papers by teaching them how to write a thesis statement and present evidence backing their main ideas, for example. However, because many students still faced linguistic challenges, such as grammar and vocabulary, the curriculum also focused on these aspects with a supplementary textbook solely dedicated to grammar.

Under the approval of the Institutional Review Board, learners’ informed consent was collected after the data collection as all the research activities had been completed as a part of the regular classroom instruction. For Study 2, five classrooms were reached out, and 50 learners agreed to participate in the research project as part of their classroom activities. Each learner was assigned to either a direct $\left( n = 2 2 \right)$ , indirect $( n = 1 6 )$ , or control group $( n = 1 2 )$ ) based on their language analytical ability score to minimize the pre-existing differences among the three groups $( M _ { \mathrm { d i r e c t } } = 8 . 3 6 .$ , $S D _ { \mathrm { d i r e c t } } = 3 . 3 0$ ; $M _ { \mathrm { { i n d i r e c t } } } = 7 . 3 8$ $S D _ { \mathrm { i n d i r e c t } } =$ 2.53; $M _ { \mathrm { c o n t r o l } } = 7 . 5 8$ , $S D _ { \mathrm { c o n t r o l } } = 3 . 4 8 )$ . The direct group had 11 pairs, the indirect group consisted of eight pairs, and the control group had six pairs. Only 45 of the 50 learners completed a demographic survey. There were 20 females and 25 males among the survey respondents, aged from 18 to 29. The sample was primarily comprised of L1 Chinese speakers $( n = 2 6 )$ , while others spoke 14 languages as their L1s, such as Arabic and Korean. Many of them were undergraduate students who had not been in the U.S. for more than six months. Their proficiency was estimated based on 35 self-reported scores on TOEFL iBT and IELTS as not all the participants responded to this survey item. Twenty-five students reported their TOEFL scores ( $M = 7 6 . 2 8$ , $S D = 9 . 4 1 $ ) and 10 reported their IELTS scores $\stackrel { \prime } { M } = 6 . 2 5$ , $S D ~ = ~ . 3 5 )$ . Consulting previous standard-setting studies (Lim et  al., 2013; Papageorgiou et  al., 2015), the present study estimated their proficiency as intermediate to upper-intermediate or the B1 to B2 level on the CEFR for all the three groups.

In order to increase sample size, Study 3 needed to recruit participants from both the high-level and low-level ESL courses and recruited a completely different sample of 51 learners in five classrooms. Participants in Study 3 shared many characteristics with the sample in Study 2. More details are available in Supplementary File A, including gender, age, and proficiency levels.

# Treatment instruments

Given the concerns on practicality of SWCF in this particular context due to students’ writing fluency and class size, the present study situated SWCF in writing tasks that are enacted by student dyads to halve the number of documents to be monitored simultaneously. The treatment was delivered via Google Docs, where learners worked on animation description tasks in pairs during their regular class hours. Google Docs was often used in each class, and thus learners were adequately familiar with the platform. During the treatment, each document was shared by the researcher and two learners. They visited their document with their own institutional account.

For Study 2, they were given 20 minutes to describe a Tom and Jerry animation clip of approximately three minutes with a partner. The addressee was their friend who had not watched the video clip yet, and learners were instructed to describe the clip in as much detail as possible. They could watch the clip as many times as they wanted. Learners were shown two video clips of Tom and Jerry, and the order of the two animation clips was counterbalanced for each group (Table 1). The link to the second clip was pasted in the same Google Docs document only after the first 20 minutes passed. Each learner worked on both video clips with the same partner. Their computer screens were captured during the treatment with QuickTime.

Unlike Study 2, Study 3 employed a sequential writing task as the treatment task, where student dyads take turns in contributing one sentence to the passage. This task was expected to increase their engagement with interactions with their partner and their partner’s text.

# Computer classroom configuration

For both Study 2 and Study 3, the treatment session was conducted in a computer classroom of 552 square feet with a capacity of 19 people reserved for this research project. Figure 1 visualizes a sample seating chart of Study 2 and Study 3 in the computer classroom that follows the same physical configuration as in Study 1. This computer classroom is equipped with 18 Mac desktop computers for learners’ use. During the treatment, one Mac desktop computer was provided for each learner. Because these desktop computers are placed along the classroom wall, learners were seated with their back to the researcher. To facilitate their interaction, two paired learners were seated next to each other and were explicitly encouraged to talk to each other during the treatment. Uninformed of their group assignment, learners were clustered within the same group while distant from the other two groups. Except for one class where the researcher monitored only three documents, he was monitoring seven to nine documents on his own laptop computer (Microsoft Surface Pro 4, 12.3 inches). He sometimes circulated the classroom to guide learners as part of natural classroom management while yet spending most of the class hours monitoring shared documents at his seat. Circulating the classroom did not allow him to monitor documents all the time, but such classroom management happens in many classroom contexts. In order to raise learners’ awareness of the researcher’s presence, he monitored the control groups’ documents so that learners could see his cursor moving in their document, but he did not provide any comments for this group.

Table 1. Counterbalance of treatment video clips (per pair) in Study 2.   

<html><body><table><tr><td rowspan="2">Task</td><td colspan="2">Direct (11 pairs)</td><td colspan="2">Indirect (8 pairs)</td><td colspan="2">Control (6 pairs)</td></tr><tr><td>6</td><td>5</td><td>4</td><td>4</td><td>2</td><td>4</td></tr><tr><td>Task 1</td><td>Clip A</td><td>Clip B</td><td>Clip A</td><td>Clip B</td><td>Clip A</td><td>Clip B</td></tr><tr><td>Task 2</td><td>Clip B</td><td>Clip A</td><td>Clip B</td><td>Clip A</td><td>Clip B</td><td>Clip A</td></tr></table></body></html>

![](img/3c862cd0c2b1b63396de99fe471ab0d4c0925b49eced6e56860dfaadb62c75f3.jpg)  
Figure 1. P hysical configuration of the computer classroom during the treatment in Study 2.

# Definite and indefinite articles in English

In narrative writing, the ability to produce noun phrases (NPs) with the definite and indefinite articles is essential because these two articles indicate whether or not a certain item has been already mentioned in a storyline. Incorrect uses of these articles can thus impact comprehensibility of written texts. These functions are often called first mention and anaphoric mention, the choice of which is primarily determined by two semantic concepts of [±Specific Reference] and [±Hearer Knowledge] (Huebner, 1983). The indefinite article occurs under $[ + S$ pecific Referent, -Hearer Knowledge], whereas the definite article emerges under [ $\cdot +$ Specific Referent, $^ +$ Hearer Knowledge] contexts. The semantic component of [±Hearer Knowledge] is determined by multiple factors, such as identifiability (e.g. I saw a cat yesterday. I found the cat injured.) and lexical relations (e.g. He’s got a cat. The kitty turned out to be injured.) (Cho, 2017). Due to the opaque form-meaning association, even learners who are fully matriculated at a U.S. university still struggle with these features (Butler, 2002), potentially in need of further instructional support. The two coordinators of the ESL writing program, where this research was conducted, confirmed the potential appropriateness of these features in this context. These features were examined for Study 2 and Study 3. In short, these features were chosen because of their impact on comprehensibility of written texts, struggles with these features reported for a similar sample of learners, and experts’ opinions at the local institution.

# Feedback operationalization and provision

Study 2 and Study 3 operationalized direct SWCF as providing the correct form and indirect SWCF as indicating an error occurrence (Ellis, 2009). During the treatment, the researcher highlighted erroneous portions of the text as soon as errors were detected. This highlighting was accompanied by a comment box. The comment provided the correct form for the direct group (e.g. Error occurred. Correct this by using ‘a’ here.) and an indication of the error for the indirect group (e.g. Error occurred. Correct this.). For both groups, the researcher added a revision-prompting message to minimize the potential difference in the degree of output-prompting nature between direct and indirect SWCF. While the researcher was monitoring texts, he was using the editing mode in Google Docs. It should be noted that each classroom had a full enrollment capacity of 20 students and had all the direct, indirect, and control groups. Therefore, the researcher only needed to provide SWCF to seven pairs at most (i.e. 14 individuals assigned to the experimental groups, six others assigned to the control group).

If learners dismissed an instance of SWCF by clicking on Resolve without correcting the error, the researcher provided additional SWCF for the same error. During the treatment, there was no time solely dedicated to the revision as a whole class. Instead, learners were expected to respond privately to the researcher’s message as they wrote. The control group worked on the same animation description tasks without SWCF or comments on the content. Any explicit grammar instruction on the articles was not given until delayed posttests were completed, which helped to ascribe changes in the use of the two articles to this intervention.

# Language analytical ability (LAA) test

Study 2 and Study 3 used a LAA test which was originally developed by Ottó (2002) and has been often adopted in AWCF studies (Jiang & Xiao, 2014; Schmitt et  al., 2003; Sheen, 2007). The test gives a list of words and sentences in an artificial language along with their English translations (see Supplementary File B for test items). Based on these linguistic clues, test takers need to induce grammatical rules of the artificial language and apply the abstracted rules to identify an appropriate English translation for 14 sentences in the artificial language. One rationale for this test is that the current sample did not share the same L1, and thus only an English-mediated test was practical. Secondly, the test has been shown to have good internal consistency when used to assess LAA of ESL students (Schmitt et  al., 2003; Sheen, 2007) and L1 Chinese speakers (Jiang & Xiao, 2014) with its Cronbach’s alpha ranging from .78 to .92. The test was delivered in the pencil-paper format. The researcher firstly read aloud the instructions, and learners were then given 20 minutes to complete the test.

# Animation description test (ADT)

The ADT was intended to measure learners’ ability to use the target features accurately in a context where they needed to convey meaning. Learners were asked to watch an animation of approximately three minutes of Tom and Jerry and write a description in as much detail as possible using Microsoft Word for 20 minutes in a class hour without a partner (please see Supplementary File C for test prompts). Three video clips prepared for the ADT were all different in terms of content from the video clips presented in the treatment.

The researcher electronically distributed a prompt to each participant via a learning management system adopted across the classes. Once 20 minutes had passed, the participants submitted their work to the system. The researcher circulated the classroom during the test task to ensure that learners were following the instructions. This test was employed for both Study 2 and Study 3.

# Sentence rewriting test (SRT) – Study 2

The SRT was intended to measure learners’ sensitivity to bare NPs for first mention and bare NPs for anaphoric mention in a context where they did not have to convey meaning. Learners were told to read two related sentences about a made-up TV program, where one of the two was underlined (e.g. One summer, Bob and his friends visit historic seaside town. Bob’s friends start disappearing one by one.). For each underlined sentence, they were asked to rewrite the sentence, correcting a grammatical error for each item in 20 minutes (please see Supplementary File D for test items).

The SRT was administered in pen-and-paper format in order to allow learners various ways of correcting errors. Six items were related to an anaphoric bare NP, and another six were about a first mention bare NP. Four distractors were included to minimize the possibility that learners would figure out the focus of the SRT and thereby to better ascribe their learning to the treatment rather than to their excessive attention to bare NPs during the SRT. For both the ADT and SRT, three versions were created and presented in a counterbalanced order for each group to minimize test order effects as shown in Table 2.

# Error correction test – Study 3

To mitigate concerns about insufficient time and learners’ fatigue felt in the sentene rewriting test in Study 2, Study 3 employed an error correction test (see Supplementary File E for test items). Students only needed to fix an error without having to rewrite the whole sentence. Three versions were created, and each version had 20 test items (cf.,

Table 2. Counterbalance of three versions of the ADT and SRT (per individual) in Study 2.   

<html><body><table><tr><td></td><td colspan="3">Direct (n=22)</td><td colspan="3">Indirect (n=16)</td><td colspan="3">Control (n=12)</td></tr><tr><td>Test</td><td>7</td><td>7</td><td>8</td><td>4</td><td>5</td><td>7</td><td>5</td><td>5</td><td>2</td></tr><tr><td>Pretest</td><td>c</td><td>D</td><td>E</td><td>c</td><td>D</td><td></td><td>c</td><td>D</td><td></td></tr><tr><td>Posttest</td><td>E</td><td>c</td><td>D</td><td>E</td><td>c</td><td>D</td><td>E</td><td>c</td><td>D</td></tr><tr><td>Delayed posttest</td><td>D</td><td>E</td><td>c</td><td>D</td><td>E</td><td>c</td><td>D</td><td>E</td><td>c</td></tr></table></body></html>

Notes. Letters represent three test versions.

12 in the SRT). This format was to allow students to demonstrate their receptive knowledge to a fuller extent, not being tasked with handwriting an entire sentence. Two L1 speakers of English, who were PhD students in Applied Linguistics, reviewed test items and fixed some wording.

# Data collection procedures

Firstly, participants took the LAA test one week prior to the pretest session (20 minutes). The student who obtained the highest LAA score was assigned to the direct group, the one with the second highest score was assigned to the indirect group, and the one at the third place was assigned to the control group. This group assignment order was counterbalanced in order to minimize differences among the three groups on LAA (see Table 3 for a sample group assignment).

Then, learners were randomly paired up within the same group2. One week after the LAA test, they took a pretest consisting of the ADT and SRT (40 minutes). One week after the pretest, they worked on the two collaborative writing tasks (50 minutes) and took a posttest in the same week (40 minutes). Two weeks after the treatment, learners took a delayed posttest (40 minutes). Study 2 created three versions for each of the ADT and the SRT, and Study 3 created three versions for each of the ADT and the ECT. The three versions were counterbalanced for both Study 2 and Study 3 (please see Table 2). Table 4 illustrates the procedures that were followed in Study 2 and Study 3.

# Data analysis

# Instrument reliability of the language analytical ability test (LAA)

Each item was scored dichotomously, correct or incorrect. Rasch analysis (one-parameter logistic) was performed with the RM function in the eRm package (version 1.0-1; Mair & Hatzinger, 2007; Mair et  al., 2020). This analysis indicated that Item 14 notably deviated from the modeled relationship between item difficulty and person ability (infit mean-square $=$ $1 . 3 9 > 1 . 3 )$ ). The removal of this test item increased Kuder-Richardson 20 (KR20) from .77 $9 5 \%$ CI [.65, .84]) to .78 ( $9 5 \%$ CI [.66, .85]), whereas the removal of any of the other test items did not. Separation reliability was 0.8, indicating that the test without Item 14 adequately separated learners with high LAA from those with low LAA (Christensen et  al., 2017). Accordingly, Item 14 was removed, and the rest of the 13 items were submitted for analysis. Following the same analytical procedures, Study 3 removed Items 1 and 4 and submitted the remaining 12 items for analysis.

Table 3. S ample group assignment based on LAA scores.   

<html><body><table><tr><td>Group</td><td>LAA</td><td>Mean LAA</td></tr><tr><td>Direct</td><td>12</td><td>6.75</td></tr><tr><td>Direct</td><td>8</td><td rowspan="9"></td></tr><tr><td>Direct</td><td>4</td></tr><tr><td>3</td><td></td></tr><tr><td>Direct Indirect</td><td>11</td></tr><tr><td>Indirect</td><td>7</td></tr><tr><td>Indirect</td><td>6</td></tr><tr><td>Indirect</td><td>2</td></tr><tr><td>Control</td><td>10</td></tr><tr><td></td><td>9</td></tr><tr><td>Control Control</td><td>5</td><td></td></tr><tr><td>Control</td><td>1</td><td></td></tr></table></body></html>

<html><body><table><tr><td colspan="2">Week 1 Session 1</td><td colspan="2"></td><td colspan="3"></td></tr><tr><td>Week 2</td><td>20 Aptitude test</td><td colspan="2">Language analytical ability test</td><td colspan="2">Language analytical ability test Animation description test</td></tr><tr><td>Session 2 40 Pretest</td><td></td><td colspan="2">Animation description test Sentence rewriting test</td><td colspan="2">Error correction test</td></tr><tr><td>Week 3</td><td>Treatment Task 1 Animation</td><td></td><td></td><td></td><td></td></tr><tr><td>Session 3 50</td><td>SWCF</td><td>Task 1 Animation description with direct description with</td><td>Task 1. Animation</td><td>Task 1 Animation description with direct</td><td>Task 1 Animation Task 1. description with indirect</td></tr><tr><td></td><td></td><td>indirect SWCF Task 2 Animation</td><td>description Task 2.</td><td>SWCF SWCF</td><td>Animation description</td></tr><tr><td></td><td></td><td>Task 2 Animation description with direct description with</td><td> Animation</td><td>Task 2 Animation Task 2 Animation description with direct</td><td>Task 2.</td></tr><tr><td></td><td>SWCF</td><td>indirect SWCF</td><td>description SWCF</td><td>description with indirect SWCF</td><td>Animation description</td></tr><tr><td>Session 4 40 Posttest</td><td></td><td>Animation description test</td><td></td><td>Animation description test</td><td></td></tr><tr><td></td><td></td><td>Sentence rewriting test</td><td></td><td>Error correction test</td><td></td></tr><tr><td>Week 5</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td>Animation description test</td><td></td><td>Animation description test</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>Session 5 40 Delayed posttest</td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>Error correction test</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td>Sentence rewriting test</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr></table></body></html>

# Interrater reliability of rating article use in the animation description test (ADT)

Each instance of the referential definite and indefinite articles was coded in a dichotomous manner, correct or incorrect (see Supplementary File F for the coding scheme). The incorrect use included missing articles and overgeneralized uses. The overgeneralized uses involved the use of the indefinite article for referring to items that were assumed to be known to the reader and the use of the definite article for referring to items not assumed to be known to the reader. The researcher and an L1 speaker of English, who was majoring in MA TESOL, established interrater reliability. After a training session, the researcher and the second rater independently coded 45 texts (i.e. $2 5 \%$ of all the papers). Interrater reliability was calculated in the form of Krippendorf ’s alpha for the two raters’ decisions. The interrater reliability was .86 for the two articles altogether, suggesting an adequate level of agreement. The two raters then discussed and solved all the disagreements. The researcher coded the remaining papers by himself. Study 3 invited another L1 speaker of English and followed the same procedures, finding that interrater reliability was .85.

# Reliability of the sentence rewriting test (SRT)

The 12 critical items were coded dichotomously, depending on whether learners showed sensitivity to a bare NP. Incorrect responses included cases where learners corrected other language features, such as verb tense and preposition, or where they left the original sentence as it was. Correct responses included cases where learners provided the appropriate article and possessive pronoun. For an anaphoric bare NP, demonstrative before a bare NP was also deemed correct, while for a first-mention bare NP, pluralization of the NP was regarded as correct as well. For example, for a first mention bare NP, historic seaside town, learners’ responses were coded as correct if they wrote a historic seaside town or historic seaside towns. For an anaphoric mention bare NP, missing books, their responses were coded as correct if they wrote the missing books or those (or these) missing books, for example.

Multilevel Rasch analysis was performed with the glmer function in the lme4 package (Bates et  al., 2015). Fixed effects included time (i.e. pretest, posttest, delayed posttest), test version (i.e. C, D, E), group (i.e. direct, indirect, and comparison), and their interactions. Random effects included test item and person. Random effects for test item is equivalent to item difficulty, and random effects for person represents person ability (Doran et  al., 2007). Infit MSQ was calculated by dividing the sum of the squared residuals by the sum of the squared standard errors. The 36 test items did not notably deviate from the modeled relationship between item difficulty and person ability, adequately falling within the range of 0.7 to 1.3. This suggests that there is less than $3 0 \%$ of variance between the observed and predicted response patterns. Study 3 followed the same analytical procedures to analyze the 60 items in the three versions of the ECT. No items were flagged.

# Statistical analysis

Study 2 and Study 3 employed generalized linear mixed-effects modeling (GLMM) with the logit link. GLMM was conducted with the glmer function in the lme4 package (version 1.1.21; Bates et  al., 2015) in R 3.6.1 (R Core Team, 2020). The following statistical packages were used to diagnose models as recommended by scholars (Gries, 2021; Mateyard & Davies, 2020). Outliers, residuals, and model performance were examined with the influence function in the influence.ME package (version 0.9.9; Nieuwenhuis et  al., 2012), the simulateResiduals function in the DHARMa package (version 0.3.3.0; Hartig, 2020), and the binned_residuals function in the performance package (version 0.5.1; Lüdecke et  al., 2020), respectively. Multicollinearity was assessed by examining generalized variance inflation factor (Fox & Monette, 1992), using the vif function in the car package (version 3.0.10; Fox & Weisberg, 2019). All finalized models reported in this paper met these assumptions reasonably (please see Supplemenytary File G for all models). Models were fitted via maximum likelihood with the BOBYQA algorithm. Coefficients were tested with Wald’s test. $R ^ { 2 }$ with the delta method was computed with the r.squaredGLMM function in the MuMIn package 1.43.6 (Bárton, 2016). Due to the small sample size, models were specified in forward stepwise procedures to save statistical power. As our primary research purpose was to identify predictors that best account for variance in changes over time, we decided to start with a model with Time (i.e. pretest, posttest, delayed posttest) in our model specification.

GLMMs produce estimates in log odds ratio, which is less familiar to applied linguists. To increase the interpretability of our findings, log odds ratio was converted to Cohen’s $d$ , a popular effect size indicator among applied linguists (Plonsky $\&$ Oswald, 2014), with the conversion formula, $L o g O d d s R a t i o = d \frac { \pi } { \sqrt { 3 } }$ , in Borenstein et  al. (2009, p. 47). Plonsky and Oswald (2014) proposed that Cohen’s $d$ of 0.6, 1.0, and 1.4 are seen as small, medium, and large, respectively, for within-group comparisons and that Cohen’s $d$ of 0.4, 0.7, and 1.0 are deemed as small, medium, and large, respectively, for between-group comparisons. Following this suggestion, log odds ratios of 1.09, 1.81, and 2.54 were interpreted as small, medium, and large for within-group comparisons. Similarly, odds ratios of.73, 1.27, and 1.81 were interpreted as small, medium, and large for between-group comparisons.

# Results

# Preliminary analysis on the frequency and timing of SWCF during the writing tasks

In Study 2, the direct group received a total of 38 SWCF instances, while the indirect group was provided with 50 SWCF instances3 . The direct group received 3.45 instances of SWCF per pair on average $\mathrm { \Delta S D = }$ 2.46), while the indirect group received 6.25 $\mathrm { ( S D } = 2 . 7 6 )$ . When only SWCF instances for novel NPs are considered, the direct group received 3.27 instances $\mathrm { ( S D } = 2 . 4 1 \mathrm { ) }$ ), and the indirect group received 4.50 instances $\left( \mathrm { S D } = 1 . 8 5 \right)$ on average. The direct group produced a total of 34 successful revisions, whereas the indirect group produced a total of 18 successful revisions. This indicates that the greater number of SWCF for the indirect group resulted from their dismissals of SWCF and incorrect responses to SWCF and that the number of unique NPs that were addressed by SWCF was comparable across the two groups.

Among the 88 SWCF instances, synchronicity could be coded for 86 instances ( $9 8 \%$ retrieval rate). While 32 of the 86 SWCF instances were delivered before learners moved to the next sentence $( 3 7 \% )$ , 54 SWCF instances were also delivered after they moved to the next sentence $( 6 3 \% )$ . Many SWCF instances were delivered more than 60 seconds after learners’ error commitment (please see Supplementary File A for more details).

In Study 3, the direct group received 48 SWCF instances, while the indirect group received 49 SWCF instances. The direct group was given 4.8 SWCF instances on average per pair $\left( S D = 2 . 4 9 \right)$ , whereas the indirect group was provided with 4.9 SWCF instances on average per pair ( $\mathbf { \zeta } S D = 3 . 0 7 ,$ ). The direct group received 4.44 SWCF instances for novel

NPs on average, whereas the indirect SWCF received 4.60 instances for novel NPs. The direct group produced a total of 37 successful revisions, whereas the indirect group produced a total of 20 successful revisions. This suggests that the two groups received a comparable number of SWCF instances and that direct SWCF was more facilitative of successful revisions.

Eighty-four SWCF instances were retrieved from the screen capture data ( $8 9 \%$ of retrieval rate). Approximately, a half of the SWCF instances were delivered before learners moved to the next sentence for both the direct and indirect groups. The other half were provided after learners had moved to the next sentence (please see Supplementary File A for more details).

# Learners’ performance on the language analytical ability test

Learners’ performance on the LAA test was comparable across groups. The mean score for the direct group was 8.36 ( $\left. S D = 3 . 3 0 \right.$ ); the mean for the indirect group was 7.38 ( $\left. S D = 2 . 5 3 \right.$ ), and the mean for the control group was 7.58 $\mathrm { \Delta } S D = 3 . 4 8 { \it \Psi }$ . After checking assumptions, a one-way ANOVA was run. These three groups did not differ in LAA to a significant extent $\left( F ( 2 , \ 4 7 ) = \ . 5 2 7 \right.$ , $p = . 5 9 4 ^ { \cdot }$ ).

In Study 3, the direct group’s average LAA score was 6.55 $\left. S D = 3 . 3 0 \right.$ ), and the indirect group’s mean score was 5.44 $\left( S D = 2 . 9 6 \right)$ . The control group scored 5.92 on average $\left( S D = 3 . 0 9 \right)$ . After checking assumptions, one-way ANOVA was run, which suggested that the three groups were not significantly different in LAA $( F ( 2 , \ 4 8 ) \ = \ . 6 0$ , $\pounds = \ . 5 6 )$ .

# Changes in learners’ performance on the animation description test (ADT)

In Study 2, there were a total of 1927 observations. Table 5 shows descriptive statistics of correct responses, incorrect responses, and accuracy score (i.e. $\frac { c o r r e c t } { c o r r e c t + i n c o r r e c t } { \times 1 0 0 }$ ). The three groups started with approximately $5 0 \%$ of accuracy on the pretest, but only the experimental groups improved.

From all the models tested, the $T i m e ^ { * } G r o u p ^ { * } L A A$ model fitted the best and was associated with marginal and conditional R-squares of .05 and .13, respectively. The model specification procedures suggested that changes in learners’ performance differed among the three groups and that those changes were related to LAA. Individuals’ predicted accuracy is visualized in Figure 2. The direct group improved from the pretest to the posttests regardless of their LAA level. For the indirect and control groups, learners with high LAA improved to a greater extent than those with low LAA.

Table 5. D escriptive statistics of correct responses, incorrect responses, and accuracy score $\begin{array}{c} \underline { { \phantom { 1 0 0 } } } \mathrm { c o r r e c t } \qquad \\ { \qquad \mathrm { c o r r e c t } \qquad } \\ { \qquad \mathrm { c o r r e c t } \qquad } \end{array}$ ) on the ADT in Study 2. correct  incorrect   

<html><body><table><tr><td>Group</td><td> Response</td><td colspan="2">Pretest</td><td colspan="2">Posttest</td><td colspan="2">Delayed</td></tr><tr><td></td><td></td><td>Mean</td><td>SD</td><td> Mean</td><td>SD</td><td>Mean</td><td>SD</td></tr><tr><td>Direct</td><td>Correct</td><td>5.95</td><td>5.14</td><td>9.09</td><td>5.15</td><td>10.14</td><td>4.63</td></tr><tr><td></td><td>Incorrect</td><td>4.32</td><td>3.06</td><td>4.64</td><td>3.58</td><td>3.86</td><td>3.38</td></tr><tr><td></td><td>Accuracy score (%)</td><td>54.86</td><td>30.18</td><td>67.18</td><td>23.25</td><td>75.09</td><td>21.32</td></tr><tr><td>Indirect</td><td>Correct</td><td>5.53</td><td>5.32</td><td>10.69</td><td>6.91</td><td>9.38</td><td>5.51</td></tr><tr><td></td><td>Incorrect</td><td>3.07.</td><td>2.58</td><td>5.94</td><td>3.60</td><td>5.00</td><td>2.83</td></tr><tr><td></td><td>Accuracy score (%)</td><td>55.40</td><td>35.05</td><td>60.25</td><td>25.15</td><td>61.94</td><td>23.03</td></tr><tr><td>Control</td><td>Correct</td><td>4.58</td><td>3.78</td><td>7.83</td><td>5.73</td><td>6.58</td><td>3.87</td></tr><tr><td></td><td>Incorrect</td><td>5.33</td><td>3.85</td><td>7.17</td><td>3.81</td><td>7.33</td><td>3.89</td></tr><tr><td></td><td>Accuracy score (%)</td><td>45.42</td><td>27.89</td><td>45.25</td><td>25.83</td><td>47.17</td><td>18.81</td></tr></table></body></html>

![](img/1deeccc4817936ad780cbce5a51241e0050bccec8230f5b7b6b63d5775404d77.jpg)  
Figure 2. I ndividuals’ changes in accuracy on the ADT predicted by the Time\*Group\*LAA model separated by the direct (left), indirect (middle), and control (right) groups and separated by the high LAA (above average, top) and low LAA (below average, bottom) groups in Study 2.

Tukey’s Honest Significant Difference (HSD) (see Table 6) showed that only the direct group improved from the pretest to the posttest and from the pretest to the delayed posttest to a significant extent, and this significant within-group difference came with small effect size $( < 1 . 0 9 )$ .

The three groups did not differ to a significant extent on the pretest (see Table 7). The direct group outperformed the control group to a significant extent on the posttest and on the delayed posttest, and these significant between-group differences came with medium effect size.

Within-group pairwise comparisons with Tukey’s HSD (see Table 8) suggested that the indirect group’s change from the pretest to the delayed posttest was significantly moderated by LAA as well as the control group’s change from the pretest to the posttest. Both of these significant within-group differences came with a small effect size $( < 1 . 0 9 )$ .

Table 6. Within-group pairwise comparison for the ADT that indicates learners’ changes over time in Study 2.   

<html><body><table><tr><td>Group</td><td>Contrast (Time)</td><td colspan="2">Coef </td><td>SE</td><td colspan="2">95% CI</td><td>Effect size</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>Lower</td><td>Upper</td><td></td></tr><tr><td>Direct</td><td>Pretest- Posttest</td><td>.59</td><td>**</td><td>.20</td><td>.12</td><td>1.05</td><td>Small</td></tr><tr><td></td><td>Posttest - Delayed</td><td>.31</td><td></td><td>.19</td><td>-.13</td><td>.76</td><td></td></tr><tr><td></td><td>Pretest-- Delayed</td><td>.90</td><td>***</td><td>.21</td><td>.41</td><td>1.38</td><td>Small</td></tr><tr><td>Indirect</td><td>Pretest- Posttest</td><td>.02</td><td></td><td>.25</td><td>-.55</td><td>.60</td><td></td></tr><tr><td></td><td>Posttest- Delayed</td><td>.06</td><td></td><td>.20</td><td>-.41</td><td>.53</td><td></td></tr><tr><td></td><td>Pretest-- Delayed</td><td>.08</td><td></td><td>.25</td><td>-.50</td><td>.67</td><td></td></tr><tr><td>Control</td><td>Pretest- Posttest</td><td>.20</td><td></td><td>.26</td><td>-.41</td><td>.81</td><td></td></tr><tr><td></td><td>Posttest - Delayed</td><td>-.07</td><td></td><td>.23</td><td>-.61</td><td>.47</td><td></td></tr><tr><td></td><td>Pretest-- Delayed</td><td>.13</td><td></td><td>.26</td><td>-.49</td><td>.74</td><td></td></tr></table></body></html>

$^ { * * } p < . 0 1$ , $^ { \ast \ast \ast } p < . 0 0 1$ ; Coef $\mathop { \bf { \ : = } }$ Coefficient; $\mathsf { S E } =$ standard error; $9 5 \%$ $\mathsf { C l } = 9 5 \%$ confidence intervals.

Table 7. Between-group pairwise comparison for the ADT that indicates the effectiveness of SWCF in Study 2.   

<html><body><table><tr><td>Time</td><td>Contrast (Group)</td><td colspan="2">Coef </td><td>SE</td><td colspan="2">95% CI</td><td>Effect size</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>Lower</td><td> Upper</td><td></td></tr><tr><td>Pretest</td><td>Direct- Control</td><td>.46</td><td></td><td>.34</td><td>-.33</td><td>1.25</td><td></td></tr><tr><td></td><td>Indirect- Control</td><td>.76</td><td></td><td>.38</td><td>-.12</td><td>1.64</td><td></td></tr><tr><td></td><td>Direct - Indirect</td><td>-.30</td><td></td><td>.33</td><td>1.07</td><td>.48</td><td></td></tr><tr><td>Posttest</td><td>Direct-Control</td><td>.85</td><td>*</td><td>.31</td><td>.12</td><td>1.58</td><td>Medium</td></tr><tr><td></td><td>Indirect- Control</td><td>.58</td><td></td><td>.32</td><td>-.17</td><td>1.34</td><td></td></tr><tr><td></td><td>Direct- Indirect</td><td>.26</td><td></td><td>.29</td><td>-.40</td><td>.93</td><td></td></tr><tr><td>Delayed</td><td>Direct-Control</td><td>1.23</td><td>***</td><td>.32</td><td>.49</td><td>1.97</td><td>Medium</td></tr><tr><td></td><td>Indirect- Control</td><td>.71</td><td></td><td>.33</td><td>-.06</td><td>1.49</td><td></td></tr><tr><td></td><td>Direct- Indirect</td><td>.52</td><td></td><td>.29</td><td>-.17</td><td>1.21</td><td></td></tr></table></body></html>

$^ { * } p < . 0 5$ , $^ { \ast \ast \ast } p < . 0 0 1$ ; Coef $\dot { } = $ Coefficient; $\mathsf { S E } =$ standard error; $9 5 \%$ ${ \mathsf { C l } } = 9 5 \%$ confidence intervals.

Table 8. Within-group pairwise comparison summary for the ADT that indicates the moderating effects of LAA on learners’ changes over time in Study 2.   

<html><body><table><tr><td>Group</td><td>Contrast (Time)</td><td>Coef </td><td></td><td>SE</td><td colspan="2">95% CI</td><td>Effect size</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>Lower</td><td>Upper</td><td></td></tr><tr><td>Direct</td><td>Pretest-- Posttest</td><td>-.17</td><td></td><td>.19</td><td>-.62</td><td>.28</td><td></td></tr><tr><td></td><td>Posttest -- Delayed</td><td>-.17</td><td></td><td>.17</td><td>-.56</td><td>.23</td><td></td></tr><tr><td></td><td>Pretest -- Delayed</td><td>-.34</td><td></td><td>.19</td><td>-.80</td><td>.12</td><td></td></tr><tr><td>Indirect</td><td>Pretest - Posttest</td><td>.50</td><td></td><td>.30</td><td>-.20</td><td>1.19</td><td></td></tr><tr><td></td><td>Posttest-- Delayed</td><td>.25</td><td></td><td>.24</td><td>-.32</td><td>.81</td><td></td></tr><tr><td></td><td> Pretest -- Delayed</td><td>.74</td><td>*</td><td>.30</td><td>.04</td><td>1.45</td><td>Small</td></tr><tr><td>Control</td><td>Pretest-- Posttest</td><td>.61</td><td>*</td><td>.25</td><td>.04</td><td>1.19</td><td>Small</td></tr><tr><td></td><td>Posttest -- Delayed</td><td>-.14</td><td></td><td>.21</td><td>-.63</td><td>.36</td><td></td></tr><tr><td></td><td>Pretest -- Delayed</td><td>.47</td><td></td><td>.25</td><td>-.10</td><td>1.05</td><td></td></tr></table></body></html>

${ } ^ { * } p < . 0 5 { } _ { i }$ ; Coef $\stackrel { \cdot } { = }$ Coefficient; $\mathsf { S E = }$ standard error; $9 5 \%$ $\mathsf { C l } = 9 5 \%$ confidence intervals.

In Study 3, the ADT elicited a total of 1959 observations of referential NPs that were coded for accuracy (see Table 9). All three groups started with approximately $7 0 \%$ of accuracy, and none demonstrated a notable improvement on the posttest. For the delayed posttest, only the indirect group notably improved, ending up with $7 8 \%$ accuracy.

Table 9. Frequency of correct and incorrect responses with accuracy score correct $\mathrm { \langle \frac { \ c u n c e t { 1 } } { \Sigma } \times \mathrm { 1 0 0 \rangle } }$ ) on the ADT in Study 3. correct  incorrect   

<html><body><table><tr><td>Group</td><td> Response</td><td colspan="2">Pretest</td><td colspan="2">Posttest</td><td colspan="2"> Delayed</td></tr><tr><td></td><td></td><td> Mean</td><td>SD</td><td>Mean</td><td>SD</td><td>Mean</td><td>SD</td></tr><tr><td>Direct</td><td>Correct</td><td>8.00</td><td>5.11</td><td>12.17</td><td>9.24</td><td>10.12</td><td>5.96</td></tr><tr><td></td><td>Incorrect</td><td>4.29</td><td>2.59</td><td>4.83</td><td>3.45</td><td>5.40</td><td>4.78</td></tr><tr><td></td><td>Accuracy score (%)</td><td>64.58</td><td>24.82</td><td>67.72</td><td>21.39</td><td>67.47</td><td>25.67</td></tr><tr><td>Indirect</td><td>Correct</td><td>9.12</td><td>4.68</td><td>10.39</td><td>5.54</td><td>9.53</td><td>4.53</td></tr><tr><td></td><td>Incorrect</td><td>5.06</td><td>4.51</td><td>5.12</td><td>4.00</td><td>3.21</td><td>2.29</td></tr><tr><td></td><td>Accuracy score (%)</td><td>68.17</td><td>26.55</td><td>67.11</td><td>22.02</td><td>78.00</td><td>18.80</td></tr><tr><td>Control</td><td>Correct</td><td>9.15</td><td>7.55</td><td>9.23</td><td>7.20</td><td>8.91</td><td>5.61</td></tr><tr><td></td><td>Incorrect</td><td>5.60</td><td>5.06</td><td>3.73</td><td>2.80</td><td>2.67</td><td>1.58</td></tr><tr><td></td><td>Accuracy score (%)</td><td>70.92</td><td>29.73</td><td>73.15</td><td>25.09</td><td>70.58</td><td>30.19</td></tr></table></body></html>

Table 10. P airwise comparison results of the time-only model for the ADT in Study 3.   

<html><body><table><tr><td>Contrast</td><td colspan="2"></td><td>SE</td><td colspan="2">95% CI</td><td>Effect size</td></tr><tr><td></td><td></td><td></td><td></td><td>Lower</td><td>Upper</td><td></td></tr><tr><td>Pretest-- Posttest</td><td>0.22</td><td></td><td>0.13</td><td>-.09</td><td>.52</td><td></td></tr><tr><td>Posttest -- Delayed</td><td>0.40</td><td>*</td><td>0.14</td><td>.07</td><td>.73</td><td>Small</td></tr><tr><td>Pretest- Delayed</td><td>0.61</td><td>***</td><td>0.14</td><td>.28</td><td>.95</td><td>Small</td></tr></table></body></html>

Notes. ${ } ^ { * } p < . 0 5 ,$ , $^ { \ast \ast \ast } p < . 0 0 1$ .

The Time-only model fitted the best among all the models tested, indicating that the study failed to find significant effects of group and LAA on changes in learners’ performance. The Time-only model was accompanied by marginal and conditional R-squares of .01 and .19, respectively.

Within-group pairwise comparisons with Tukey’s HSD (Table 10) suggested that all the three groups improved from the posttest to the delayed posttest and the pretest to the delayed posttest to a significant extent. These significant changes were accompanied by small effect sizes.

Figure 3 visualizes changes in accuracy of individuals predicted by the Time-only model. It seems that LAA did not moderate changes in learners’ performance. Learners improved their accuracy of the articles on the ADT regardless of group assignment and LAA.

# Changes in learners’ performance on the sentence rewriting test (SRT) in Study 2 and on the error correction test (ECT) in Study 3

In Study 2, there were a total of 1788 observations from the SRT (see Table 11). The three groups began with a very small number of correct responses and that they only achieved around the correct rate of $4 0 \%$ .

The Time-only model fitted the best among all the models tested and was associated with marginal and conditional R-squares of .03 and .32, respectively. Changes in learners’ performance did not differ among the three groups, and their changes over time were not related to LAA. Individuals’ predicted accuracy on the SRT is visualized in Figure 4, which suggests that learners improved to a comparable extent regardless of their group assignment and LAA level.

![](img/e05f7f0b73570f69bb7813155bd9a85dc8b8a928e7923a2eee6a54e7ac6f999f.jpg)  
Figure 3. I ndividuals’ changes in accuracy on the ADT predicted by the Time-only model separated by the direct (left), indirect (middle), and control (right) groups and separated by the high LAA (above average, top) and low LAA (below average, bottom) groups in Study 3.

Table 11. D escriptive statistics of correct responses, incorrect responses, and accuracy score correct 100 ) on the SRT in Study 2. correct  incorrect   

<html><body><table><tr><td>Group</td><td> Response</td><td colspan="2">Pretest</td><td colspan="2">Posttest</td><td colspan="2">Delayed</td></tr><tr><td></td><td></td><td> Mean</td><td>SD</td><td> Mean</td><td>SD</td><td>Mean</td><td>SD</td></tr><tr><td>Direct</td><td>Correct</td><td>4.71</td><td>2.49</td><td>4.84</td><td>3.42</td><td>6.17</td><td>3.09</td></tr><tr><td></td><td>Incorrect</td><td>8.36</td><td>2.97</td><td>7.82</td><td>3.59</td><td>6.95</td><td>3.70</td></tr><tr><td></td><td>Accuracy score (%)</td><td>30.36</td><td>24.80</td><td>34.77</td><td>30.09</td><td>42.05</td><td>30.83</td></tr><tr><td>Indirect</td><td>Correct</td><td>3.40</td><td>2.76</td><td>4.71</td><td>3.65</td><td>6.07</td><td>3.75</td></tr><tr><td></td><td>Incorrect</td><td>9.73</td><td>2.76</td><td>8.40</td><td>3.22</td><td>6.69</td><td>4.06</td></tr><tr><td></td><td> Accuracy score (%)</td><td>18.87</td><td>23.12</td><td>34.25</td><td>31.27</td><td>44.19</td><td>33.86</td></tr><tr><td>Control</td><td>Correct</td><td>3.10</td><td>1.60</td><td>4.33</td><td>4.09</td><td>4.67</td><td>3.14</td></tr><tr><td></td><td>Incorrect</td><td>9.42</td><td>1.88</td><td>8.75</td><td>4.00</td><td>7.33</td><td>3.14</td></tr><tr><td></td><td>Accuracy score (%)</td><td>21.58</td><td>15.66</td><td>27.00</td><td>33.41</td><td>38.83</td><td>26.19</td></tr></table></body></html>

Pairwise comparisons were made with Tukey’s HSD (see Table 12). All the three groups improved from the pretest to the posttests to a significant extent, and these significant within-group differences came with small effect sizes.

In Study 3, 3000 observations of referential NPs were obtained from the ECT (see Table 13). The three groups seem to have improved their article use from the pretest to the posttests, but their attainment reached $5 0 \%$ accuracy at best.

![](img/e4a94d846aef886bf8ffeaef7d240cc28638ddc73dfa6128f34c54e426693bf2.jpg)  
Figure 4. I ndividuals’ changes in accuracy on the SRT predicted by the Time-only model separated by the direct (left), indirect (middle), and control (right) groups and separated by the high LAA (above average, top) and the low LAA (below average, bottom) groups in Study 2.

Table 12. Within-group pairwise comparison summary for the SRT that indicates learners’ changes over time in Study 2.   

<html><body><table><tr><td>Contrast (Time)</td><td colspan="2">Coef </td><td>SE</td><td colspan="2">95% CI</td><td>Effect size</td></tr><tr><td></td><td></td><td></td><td></td><td>Lower</td><td> Upper</td><td></td></tr><tr><td>Pretest- Posttest</td><td>.51</td><td>**</td><td>.15</td><td>.17</td><td>.86</td><td>Small</td></tr><tr><td>Posttest -- Delayed</td><td>.54</td><td>***</td><td>.14</td><td>.21</td><td>.87</td><td>Small</td></tr><tr><td>Pretest-- Delayed</td><td>1.06</td><td>***</td><td>.15</td><td>.71</td><td>1.41</td><td>Small</td></tr></table></body></html>

$^ { * * } p \ < \ . 0 1$ , $^ { * * * } p \ < \ . 0 0 1$ ; Coef $\stackrel {  } { = }$ Coefficient; $\mathsf { S E = }$ standard error; $9 5 \%$ $\mathsf { C l } = 9 5 \%$ confidence intervals.

Table 13. Frequency of correct and incorrect responses with accuracy score correct $\times 1 0 0$ ) on the ECT in Study 3. correct  incorrect   

<html><body><table><tr><td>Group</td><td>Response</td><td colspan="2">Pretest</td><td colspan="2">Posttest</td><td colspan="2">Delayed</td></tr><tr><td></td><td></td><td>Mean</td><td>SD</td><td>Mean</td><td>SD</td><td>Mean</td><td>SD</td></tr><tr><td>Direct</td><td>Correct</td><td>5.94</td><td>4.51</td><td>8.35</td><td>4.76</td><td>8.25</td><td>4.27</td></tr><tr><td rowspan="3"></td><td>Incorrect</td><td>14.95</td><td>4.67</td><td>12.53</td><td>5.20</td><td>13.40</td><td>5.08</td></tr><tr><td>Accuracy score (%)</td><td>25.25</td><td>23.37</td><td>37.37</td><td>26.00</td><td>33.00</td><td>25.41</td></tr><tr><td>Correct</td><td>7.88</td><td>4.90</td><td>11.29</td><td>5.42</td><td>10.60</td><td>6.13</td></tr><tr><td rowspan="4">Indirect Control</td><td>Incorrect</td><td>12.56</td><td>5.10</td><td>9.88</td><td>5.58</td><td>10.65</td><td>6.73</td></tr><tr><td>Accuracy score (%)</td><td>37.22</td><td>25.51</td><td>53.33</td><td>29.46</td><td>46.76</td><td>33.63</td></tr><tr><td>Correct</td><td>6.00</td><td>5.25</td><td>8.27</td><td>5.85</td><td>10.78</td><td>7.10</td></tr><tr><td>Incorrect</td><td>15.38</td><td>5.25</td><td>13.00</td><td>6.18</td><td>13.00</td><td>7.14</td></tr><tr><td></td><td>Accuracy score (%)</td><td>23.08</td><td>26.26</td><td>35.00</td><td>30.89</td><td>40.42</td><td>38.87</td></tr></table></body></html>

The Time\*LAA\*Group model fitted the best among all the models tested. The model comparisons suggested that the three groups changed their performance over the course of time in a comparable way and that the impact of LAA on their ECT performance was significantly different among the three groups. The Time\*LAA\*Group model was associated with marginal and condition R-squares of .07 and .37, respectively.

![](img/be622d9240063f6933f4ee2169a1eb64ca13b872cc94b33d092c1017e1844da8.jpg)  
Figure 5. I ndividuals’ changes in accuracy on the ECT predicted by the Time\*LAA\*Group model separated by the direct (left), indirect (middle), and control (right) groups and separated by the high LAA (above average, top) and low LAA (below average, bottom) groups in Study 3.

Given that the model comparisons suggested that group assignment did not significantly influence performance, the $T i m e ^ { * } L A A ^ { * } G r o u p$ model was examined with primary focus on how the relationship between LAA and performance differed among the three groups. Figure 5 visualizes the relationship extracted from the $T i m e ^ { * } L A A ^ { * } G r o u p$ model. The role of LAA appears to be minimal for the direct group, whereas LAA moderated changes in the indirect and especially control groups’ performances. The moderating effects seem delayed for the indirect group, whereas such effects appeared both on the posttest and the delayed posttest for the control group.

Pairwise comparisons were made with Tukey’s HSD for the three groups separately (see Table 14). The impact of LAA was not confirmed for the direct group. LAA significantly moderated the indirect group’s changes from the posttest to the delayed posttest and from the pretest to the delayed posttest, though the effect sizes were small. LAA also moderated the control group’s changes from the pretest to the posttest and to the delayed posttest to a significant extent. Such effects were small from the pretest to the delayed posttest and medium from the pretest to posttest for the control group.

Table 14. Within-group pairwise comparison results of the Time\*LAA\*Group model for the ECT in Study 3.   

<html><body><table><tr><td>Group</td><td>Contrast (Time)</td><td></td><td></td><td>SE</td><td colspan="2">95% CI</td><td>Effect size</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>Lower</td><td>Upper</td><td></td></tr><tr><td rowspan="3">Direct</td><td>Pretest - Posttest</td><td>-.16</td><td></td><td>.17</td><td>-.57</td><td>.25</td><td></td></tr><tr><td>Posttest-- Delayed</td><td>.29</td><td></td><td>.17</td><td>-.10</td><td>.69</td><td></td></tr><tr><td>Pretest -- Delayed</td><td>.13</td><td></td><td>.17</td><td>-.28</td><td>.53</td><td></td></tr><tr><td rowspan="3">Indirect</td><td>Pretest - Posttest</td><td>.00</td><td></td><td>.19</td><td>-.44</td><td>.44</td><td></td></tr><tr><td>Posttest-- Delayed</td><td>.62</td><td>**</td><td>.19</td><td>.19</td><td>1.06</td><td>Small</td></tr><tr><td>Pretest -- Delayed</td><td>.62</td><td>**</td><td>.20</td><td>.16</td><td>1.08</td><td>Small</td></tr><tr><td rowspan="3">Control</td><td>Pretest - Posttest</td><td>1.11</td><td>***</td><td>.25</td><td>.54</td><td>1.69</td><td>Medium</td></tr><tr><td>Posttest-- Delayed</td><td>-.14</td><td></td><td>.24</td><td>-.70</td><td>.43</td><td></td></tr><tr><td>Pretest - Delayed</td><td>.98</td><td>***</td><td>.24</td><td>.41</td><td>1.54</td><td>Small</td></tr></table></body></html>

Notes. $\ast \ast _ { p } < . 0 1$ , $^ { \ast \ast \ast } p < . 0 0 1$

# Discussion

The first research question dealt with the effectiveness of SWCF on productive and receptive knowledge of the referential articles. Study 2 found that only direct SWCF is effective for improving learners’ productive knowledge with medium effect size, whereas Study 3 did not find significant effects for direct and indirect SWCF. These medium and non-significant effects should not be necessarily discouraging. Lim and Renandya’s study (2020) suggested that AWCF typically results in small $( k = 1 4 )$ to medium $( k = 1 0 )$ effect sizes (Figure 6). Large effect sizes are typically above the third quartile $( k = 1 4 )$ . Given this treatment-specific effect size distributions, the observed medium effect size is positive, and the non-significant effects might be unsurprising, especially given the small sample size in Study 2 and Study 3.

Nevertheless, the several non-significant effects greatly contrast with Shintani and Aubrey (2016) reported large effect sizes. This disagreement would be attributable to the fact that their study provided SWCF to each individual, and thus individual learners had more opportunities to engage with SWCF. In contrast, Study 2 and Study 3 asked two learners to collaborate on the same task. Unlike paper-based tasks, the editing mode, the default setting of Google Docs, automatically removes the teacher’s comments once the highlighted part is deleted. Accordingly, once one dyad member has revised an error, the other dyad member may lose a chance to engage with SWCF (Yamashita, 2021). It is recalled that learners were paired due to concerns on practicality of SWCF. As the ideal teaching environment in a laboratory setting may not always be practical in classroom settings, classroom studies typically find smaller effect sizes (e.g. Li, 2010; Plonsky, 2011). Second, Shintani and Aubrey (2016) examined the hypothetical conditional structure, which involves higher saliency than the referential articles. In many cases, learners simply need to read a single sentence to assess the grammaticality of the hypothetical conditional, whereas they typically need to read multiple sentences to determine the grammaticality of the referential articles. For example, Shintani et  al. (2014) and Suzuki et  al. (2019) both reported that AWCF was more effective for the hypothetical conditional structure than for the indefinite article. Kim et  al.’s study (2020) also suggested that the effects of SWCF can range from small to large, depending on linguistic features. In short, the participatory structure and linguistic features in Study 2 and Study 3 may have contributed to the non-significant effects altogether. That said, determining its effectiveness only on inferential statistics is risky given the small sample size and the short instructional time in Study 2 and Study 3. The effectiveness might have been salient had more participants been recruited and had SWCF been provided to several more tasks over a prolonged period of time. Indeed, for example, the average accuracy score of the ECT in Study 3 increased by more than $1 0 \%$ from the pretest to the posttest for all the three groups. It should also be noted that standard deviation was large, which indicates great variations in changes in learners’ performance. Furthermore, the inconsistent findings between Study 2 and Study 3 could be attributed to differences in learners’ prior knowledge. For instance, the descriptive statistics on the ADT indicate that the learners in Study 2 started with approximately $5 0 \%$ of accuracy, whereas those in Study 3 began with more than $6 0 \%$ of accuracy. It is likely that the effectiveness of SWCF was not observed in Study 3 due to the small room for improvement at the onset of the study.

![](img/9554b2bd1009e13d853476ffd4faf596345359bc62899421f8eeec90d26736c5.jpg)  
Figure 6. M eta-analyzed effect sizes in Lim and Renandya (2020) compared with Plonsky and Oswald (2014) benchmark of small (.40; blue), medium (.70; green), and large (1.00; red).

The second research question addressed the potential moderating effects of LAA on the effectiveness of SWCF. Study 2 and Study 3 consistently found that direct SWCF was not related to any LAA level and that indirect SWCF shows a stronger effect for high LAA learners. Interestingly, such effects appeared in a delayed manner both in Study 2 for the ADT and in Study 3 for the ECT. This indicates that both low and high LAA learners may benefit from indirect SWCF immediately, but high LAA learners may retain their gains to a greater extent over two weeks. These findings well align with the trend that when learners need to figure out grammatical rules by themselves (e.g. inductive learning), learners with higher LAA benefit more from the class hour (Erlam, 2005; Hwu et  al., 2014). At the same time, however, the present findings contrast with previous studies that had found the moderating effects of LAA for direct AWCF (Benson & DeKeyser, 2019; Sheen, 2007; Shintani & Ellis, 2015; Stefanou & Révész, 2015). This discrepancy in findings could be attributed to learners’ proofreading-like engagement with direct SWCF. When SWCF includes the correct form and a revision-prompting message, they may focus merely on eliminating errors, minimally engaging with figuring out the grammatical rules behind the linguistic manifestations (Li & Roshan, 2019), especially because they need to respond to SWCF while constructing their passage. In addition, Study 2 and Study 3 did not tell learners at the beginning of the class hour that they would receive SWCF, leaving learners uninformed of the way they were expected to act upon SWCF. In contrast, when AWCF is provided, learners can focus on forms without having to create a passage at the same time. Furthermore, previous studies on AWCF explicitly instructed learners to engage with AWCF (Benson & DeKeyser, 2019; Sheen, 2007; Shintani & Ellis, 2015; Stefanou & Révész, 2015). For example, Stefanou and Révész (2015) provided learners with ‘the advice to attend to the feedback carefully because, as they were told, they would later have to complete a similar task’ (p. 268). Such an explicit follow-up instruction possibly created a learning-oriented classroom environment. In short, it is likely that the absence of a clear instruction on SWCF and the relatively meaning-focused task environment in Study 2 and Study 3 minimized learners’ engagement with the referential articles.

More importantly, changes in the control group were greatly moderated by LAA. Unlike the indirect condition, the moderating effects appeared immediately both in Study 2 for the ADT and in Study 3 for the ECT. For example, the control group increased the number of correct uses from pretest to posttests for the ADT in Study 2 (Table 5). This group-level gain could be attributed to gains of a sub-group of high LAA learners (Figure 2), who improved even in this least form-focused learning environment (i.e. no feedback). Unlike such high LAA learners, low LAA learners may need additional assistance to analyze their own language and improve their grammatical knowledge. Similarly, the increased correct responses of the control group for the ECT in Study 3 (Table 13) could be attributed to gains of a high LAA sub-group (Figure 4). Study 2 and Study 3 are somewhat inconsistent in that they found the moderating effects of LAA in the control condition for different tests. At the same time, Study 2 and Study 3 are consistent in that LAA played a more important role for the control group than for the experimental groups, suggesting that meaning-focused tasks may require learners to engage with formal aspects by themselves to improve their grammatical knowledge. These findings are unique as previous studies did not report the relationship between changes from a pretest to posttests and LAA for a control group (Benson & DeKeyser, 2019; Sheen, 2007; Shintani & Ellis, 2015; Stefanou & Révész, 2015). It is possible that form-focused feedback, which may not be immediately effective for grammar learning, can level out differences among individuals, revealing another form of its educational value in terms of inclusive classroom teaching. Study 2 and Study 3 suggested that direct SWCF may serve learners with different LAA relatively evenly, at the cost of tempting them not to analyze their language use while processing of SWCF. Meanwhile, indirect SWCF and a meaning-focused writing activity without SWCF may prompt learners to examine their own language use at the expense of potentially differentiating the rate of growth among individuals with different LAA. These pros and cons should be considered in practice.

# Conclusion

The present study investigated the effectiveness of human-delivered SWCF in animation description tasks which two paired learners collaborated on in Google Docs for college-level ESL writing courses. The study focused on human-delivered SWCF to empower teachers of languages other than English and examined its potential in paired writing tasks to reexamine the effectiveness of SWCF in a classroom environment where human-delivered SWCF is deemed more practical. Overall, the study provided moderate support for human-delivered SWCF in this context. SWCF can be as effective as AWCF while contributing to inclusive teaching and decreased teachers’ out-of-class workload.

The present study has three major limitations. First, Study 2 and Study 3 only investigated English articles as the target feature. Such a narrow focus may be tangential to stakeholders’ aim to improve many other aspects of L2 ability of their students. Second, while this study investigated SWCF in a practical environment, practicality remains an empirical inquiry. Teachers may not feel that SWCF is practical even when tasks are performed by student dyads. Qualitative data, such as classroom observations and interviews, are essential to delve into their implementation and perception of SWCF. The present study does not provide any evidence that helps conclude whether SWCF is practical. As a reviewer rightly pointed out, practicality becomes more concerning when the teacher provides SWCF for a range of errors, unlike the present study where only the referential articles were targeted at. In fact, it is recalled that the researcher needed to circulate the classroom as part of his natural classroom management, which did not allow him to monitor Google Docs all the time. In this view, hand-written SWCF may be advantageous as teachers can provide feedback and circulate the classroom at the same time (see Kim et  al., 2020 for such an implementation). Third, the statistical conclusion validity is low as the present study had small sample sizes. Non-significant effects and relationship in the present paper may not necessarily suggest the absence of such effects and relationship in population. This weak statistical conclusion validity may have also caused inconsistent findings between Study 2 and Study 3, including the effectiveness of SWCF and the moderating role of LAA. The present study has pedagogical implications to strike a balance between the effectiveness and practicality. Instructors who are not used to SWCF may need to design tasks carefully in order not to be overwhelmed by its limited practicality at first sight. As suggested by Shintani and Aubrey (2016), forming a group of four to five students may make SWCF adequately practical for a class of 20 students, for example. Linguistic features should also be carefully selected. Selective SWCF may prevent the teacher from being distracted by other errors, increasing perceived practicality. Other measures may be taken in their own context, and such evaluation of learning outcomes and practicality, whether formally or informally, needs to continue. In this view, researchers’ explicit efforts to bring practicality at the forefront may be favorably perceived by practitioners, facilitating bidirectional conversation between the two. I humbly hope that this paper has provided a small snapshot of such endeavor.

# Notes

1. Effect sizes reported in Shintani and Aubrey (2016) were converted into Hedge’s $g$ for the sake of comparisons with effect sizes reported in meta-analyses.   
2. Due to the small sample sizes, it was not possible to create all the possible pairing patterns regarding LAA (i.e. high-high pair, high-low pair, low-low pair). As the pairing was done randomly, it can be argued that any arbitrariness was minimized. That said, it is possible that pairing did influence the results, which is out of the scope of this paper.

3. A reviewer rightly pointed out the possibility that the effectiveness of SWCF varied depending on whose error of the two paired individuals was addressed by SWCF. This possibility was explored by examining the relationship between the number of each learner’s errors that were addressed by SWCF and their learning gains. Any clear pattern was not found.

# Disclosure statement

No potential conflict of interest was reported by the author.

# Funding

This work was supported by the Small Research Grants in the TESL/ALT program at Iowa State University.

# Notes on contributor

Taichi Yamashita is a Visiting Assistant Professor in the Department of World Languages and Cultures at The University of Toledo. He earned a PhD in Applied Linguistics and Technology from Iowa State University. His research interests address the intersection of CALL and instructed SLA with specializations in feedback on writing and collaborative learning. His articles appear in Foreign Language Annals, Computer Assisted Language Learning, and Language Learning & Technology.

# ORCID

Taichi Yamashita $\textcircled{1}$ http://orcid.org/0000-0001-8531-7266

# References

Arroyo, D. C., & Yilmaz, Y. (2017). The role of language analytic ability in the effectiveness of different feedback timing conditions. In L. Gurzynski-Weiss (Ed.), Expanding individual difference research in the interaction approach: Investigating learners, instructors, and other interlocutors (pp. 72–97) John Benjamins.   
Bárton, K. (2016). MuMIn: Multi-model inference. R package version 1.43-6. https:// CRAN.R-project.org/package MuMIn   
Bates, D., Maechler, M., Bolker, B., & Walker, S. (2015). Fitting linear mixed-effects models using lme4. Journal of Statistical Software, 67(1), 1–48. https://doi.org/10.18637/ jss.v067.i01   
Benson, S., & DeKeyser, R. (2019). Effects of written corrective feedback and language aptitude on verb tense accuracy. Language Teaching Research, 23(6), 702–726. https:// doi.org/10.1177/1362168818770921   
Bikowski, D., & Schulze, M. (2015). Replication and evaluation in CALL. CALICO Journal, 32(2), i–v. https://doi.org/10.1558/cj.v32i2.26981   
Boers, F., Bryfonski, L., Faez, F., & McKay, T. (2021). A call for cautious interpretation of meta-analytic reviews. Studies in Second Language Acquisition, 43(1), 2–24. https:// doi.org/10.1017/S0272263120000327   
Borenstein, M., Hedges, L. V., Higgins, J. P. T., & Rothstein, H. R. (2009). Introduction to meta-analysis. Wiley.   
Butler, Y. (2002). Second language learners’ theories on the use of English articles. Studies in Second Language Acquisition, 24, 451–480. https://doi.org/10.1017/ S0272263102003042   
CCCC Executive Committee. (2015, March 31). Statement of principles and standards for the postsecondary teaching of writing. Position statements. www.ncte.org/cccc/ resources/positions/postsecondarywriting   
Chapelle, C. A. (2001). Computer applications in second language acquisition. Cambridge University Press.   
Chapelle, C. A., & Heift, T. (2009). Individual learner differences in CALL: The field independence/dependence (FID) construct. CALICO Journal, 26(2), 246–266. https:// doi.org/10.1558/cj.v26i2.246-266   
Cho, J. (2017). The acquisition of different types of definite noun phrases in L2-English. International Journal of Bilingualism, 21(3), 367–382. https://doi.org/10.1177/1367 006916629577   
Christensen, K. B., Makransky, G., & Horton, M. (2017). Critical values for Yen’s Q 3: Identification of local dependence in the Rasch model using residual correlations. Applied Psychological Measurement, 41(3), 178–194. https://doi.org/10.1177/0146621616677520   
Chun, D. M. (2012). Replication studies in CALL research. CALICO Journal, 29(4), 591–600. https://doi.org/10.11139/cj.29.4.591-600   
Cronbach, L. J., & Snow, R. E. (1977). Aptitudes and instructional methods: A handbook for research on interactions. Irvington.   
Doran, H., Bates, D., Bliese, P., & Dowling, M. (2007). Estimating the multilevel Rasch model: With the lme4 package. Journal of Statistical Software, 20(2), 1–18. https:// doi.org/10.18637/jss.v020.i02   
Ellis, R. (2009). A typology of written corrective feedback types. ELT Journal, 63(2), 97–107. https://doi.org/10.1093/elt/ccn023   
Ellis, R. (2018). Meta-analysis in second language acquisition research: A critical appraisal. Journal of Second Language Studies, 1(2), 231–253. https://doi.org/10.1075/ jsls.00002.ell   
Erlam, R. (2005). Language aptitude and its relationship to instructional effectiveness in second language acquisition. Language Teaching Research, 9(2), 147–171. https:// doi.org/10.1191/1362168805lr161oa   
Fox, J., & Monette, G. (1992). Generalized collinearity diagnostics. Journal of the American Statistical Association, 87(417), 178–183. https://doi.org/10.1080/01621459 .1992.10475190   
Fox, J., & Weisberg, S. (2019). An R companion to applied regression (2nd ed.). SAGE Publications.   
Gries, S. T. (2021). (Generalized linear) Mixed‐effects modeling: A learner corpus example. Language Learning, 71(3), 757–798. https://doi.org/10.1111/lang.12448   
Hartig, F. (2020). DHARMa: Residual diagnostics for hierarchical (multi-level/mixed) regression models. R package version 0.3.3.0. https://CRAN.R-project.org/package DHARMa   
Huebner, T. (1983). A longitudinal analysis of acquisition of English. Korama Press.   
Hwu, F., Pan, W., & Sun, S. (2014). Aptitude-treatment interaction effects on explicit rule learning: A latent growth curve analysis. Language Teaching Research, 18(3), 294–319. https://doi.org/10.1177/1362168813510381   
Jiang, L., & Xiao, H. (2014). The efficacy of written corrective feedback and language analytic ability on Chinese learners’ explicit and implicit knowledge of English articles. English Language Teaching, 7(10), 22–34. https://doi.org/10.5539/elt.v7n10p22   
Kam, E. F., Liu, Y. T., & Tseng, W. T. (2020). Effects of modality preference and working memory capacity on captioned videos in enhancing L2 listening outcomes. ReCALL, 32(2), 213–230. https://doi.org/10.1017/S0958344020000014 https://doi.org/10.1111/modl.12189   
Kim, Y., Choi, B., Kang, S., Kim, B., & Yun, H. (2020). Comparing the effects of direct and indirect synchronous written corrective feedback: Learning outcomes and students’ perceptions. Foreign Language Annals, 53, 176–199. https://doi.org/10.1111/flan.12443   
Lee, S., & Du, Q. (2021). Quantifying native speakerism in second language (L2) writing: A study of student evaluations of teaching. Applied Linguistics, 42(3), 541– 568. https://doi.org/10.1093/applin/amaa033   
Li, S. (2010). The effectiveness of corrective feedback in SLA: A meta‐analysis. Language Learning, 60(2), 309–365. https://doi.org/10.1111/j.1467-9922.2010.00561.x   
Li, S., & Roshan, S. (2019). The associations between working memory and the effects of four different types of written corrective feedback. Journal of Second Language Writing, 45, 1–15. https://doi.org/10.1016/j.jslw.2019.03.003   
Lim, G. S., Geranpayeh, A., Khalifa, H., & Buckendahl, C. W. (2013). Standard setting to an international reference framework: Implications for theory and practice. International Journal of Testing, 13(1), 32–49. https://doi.org/10.1080/15305058.2012 .678526   
Lim, S. C., & Renandya, W. A. (2020). Efficacy of written corrective feedback in writing instruction: A meta-analysis. TESL-EJ, 24(3), 1–26.   
Liu, Q., & Brown, D. (2015). Methodological synthesis of research on the effectiveness of corrective feedback in L2 writing. Journal of Second Language Writing, 30, 66–81. https://doi.org/10.1016/j.jslw.2015.08.011   
Lüdecke, D., Makowski, D., Waggoner, P., Patil, I. (2020). Assessment of regression models performance. CRAN. https://easystats.github.io/performance/   
Mair, P., & Hatzinger, R. (2007). Extended Rasch modeling: The eRm package for the application of IRT models in R. Journal of Statistical Software, 20(9), 1–20. http:// www.jstatsoft.org/v20/i09 https://doi.org/10.18637/jss.v020.i09   
Mair, P., Hatzinger, R., Maier, M. J. (2020). eRm: Extended Rasch modeling. 1.0-1. https://cran.r-project.org/package=eRm   
Marsden, E., Morgan‐Short, K., Thompson, S., & Abugaber, D. (2018). Replication in second language research: Narrative and systematic reviews and recommendations for the field. Language Learning, 68(2), 321–391. https://doi.org/10.1111/lang.12286   
Meteyard, L., & Davies, R. A. (2020). Best practice guidance for linear mixed-effects models in psychological science. Journal of Memory and Language, 112, 104092.   
McManus, K. (2021). Are replication studies infrequent because of negative attitudes?: Insights from a survey of attitudes and practices in second language research. Studies in Second Language Acquisition, 1–14. https://doi.org/10.1017/S0272263121000838   
Mizumoto, A., & Chujo, K. (2016). Who is data-driven learning for? Challenging the monolithic view of its relationship with learning styles. System, 61, 55–64. https:// doi.org/10.1016/j.system.2016.07.010   
Nieuwenhuis, R., Te Grotenhuis, M., & Pelzer, B. (2012). Influence.ME: Tools for detecting influential data in mixed effects models. R Journal, 4(2), 38–47. https://doi. org/10.32614/RJ-2012-011   
Ottó, I. (2002). Magyar Egységes Nyelvérzékmérő Teszt. Unpublished material.   
Papageorgiou, S., Tannenbaum, R. J., Bridgeman, B., & Cho, Y. (2015). The association between TOEFL $i B T ^ { \infty }$ test scores and the Common European Framework of Reference (CEFR) levels (Research Memorandum No. RM-15-06). Educational Testing Service.   
Payne, J. S., & Whitney, P. J. (2002). Developing L2 oral proficiency through synchronous CMC: Output, working memory, and interlanguage development. CALICO Journal, 20, 7–32. https://doi.org/10.1558/cj.v20i1.7-32   
Plonsky, L. (2011). The effectiveness of second language strategy instruction: A meta‐analysis. Language Learning, 61(4), 993–1038. https://doi.org/10.1111/j.1467-9922.2011.00663.x   
Plonsky, L., & Oswald, F. L. (2014). How big is “big”? Interpreting effect sizes in L2 research. Language Learning, 64(4), 878–912. https://doi.org/10.1111/lang.12079   
Porte, G. (2012). Replication research in applied linguistics. Cambridge University Press.   
R Core Team. (2020). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/   
Ranalli, J. (2021). L2 student engagement with automated feedback on writing: Potential for learning and issues of trust. Journal of Second Language Writing, 52, 100816. https://doi.org/10.1016/j.jslw.2021.100816   
Sato, M., & McDonough, K. (2020). Predicting L2 learners’ noticing of L2 errors: Proficiency, language analytical ability, and interaction mindset. System, 93, 102301. https://doi.org/10.1016/j.system.2020.102301   
Schmitt, N., Dörnyei, Z., Adolphs, S., & Durow, V. (2003). Knowledge and acquisition of formulaic sequences: A longitudinal study. In N. Schmitt (Ed.), The acquisition, processing, and use of formulaic sequences (pp. 55–86) John Benjamins.   
Sheen, Y. (2007). The effect of focused written corrective feedback and language aptitude on ESL learners’ acquisition of articles. TESOL Quarterly, 41(2), 255–283. https:// doi.org/10.1002/j.1545-7249.2007.tb00059.x   
Shintani, N., & Aubrey, S. (2016). The effectiveness of synchronous and asynchronous written corrective feedback on grammatical accuracy in a computer‐mediated environment. The Modern Language Journal, 100(1), 296–319. https://doi.org/10.1111/ modl.12317   
Shintani, N., & Ellis, R. (2015). Does language analytical ability mediate the effect of written feedback on grammatical accuracy in second language writing? System, 49, 110–119. https://doi.org/10.1016/j.system.2015.01.006   
Shintani, N., Ellis, R., & Suzuki, W. (2014). Effects of written feedback and revision on learners’ accuracy in using two English grammatical structures. Language Learning, 64(1), 103–131. https://doi.org/10.1111/lang.12029   
Skehan, P. (1998). A cognitive approach to language learning. Oxford University Press.   
Smith, B., & Schulze, M. (2013). Thirty years of the CALICO Journal – Replicate, replicate, replicate. CALICO Journal, 30(1), i–iv. https://doi.org/10.11139/cj.30.1.i-iv   
Stefanou, C., & Révész, A. (2015). Direct written corrective feedback, learner differences, and the acquisition of second language article use for generic and specific plural reference. The Modern Language Journal, 99(2), 263–282. https://doi.org/10.1111/ modl.12212   
Suzuki, W., Nassaji, H., & Sato, K. (2019). The effects of feedback explicitness and type of target structure on accuracy in revision and new pieces of writing. System, 81, 135–145. https://doi.org/10.1016/j.system.2018.12.017   
Truscott, J. (2020). The efficacy of written corrective feedback: A critique of a meta-analysis. Unpublished manuscript, National Tsing Hua University, Hsinchu, Taiwan.   
Varol, B., & Erçetin, G. (2021). Effects of gloss type, gloss position, and working memory capacity on second language comprehension in electronic reading. Computer Assisted Language Learning,  34(7), 820–844.   
Yamashita, T. (2021). Corrective feedback in computer-mediated collaborative writing and revision contributions. Language Learning & Technology, 25(2), 75–93.