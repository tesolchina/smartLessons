# A study of vocabulary learning using annotated $3 6 0 ^ { \circ }$ pictures

Kevin Papin & Regina Kaplan-Rakowski

To cite this article: Kevin Papin & Regina Kaplan-Rakowski (2024) A study of vocabulary learning using annotated $3 6 0 ^ { \circ }$ pictures, Computer Assisted Language Learning, 37:5-6, 1108-1135, DOI: 10.1080/09588221.2022.2068613

To link to this article: https://doi.org/10.1080/09588221.2022.2068613

# A study of vocabulary learning using annotated $3 6 0 ^ { \circ }$ pictures

Kevin Papina $\textcircled{1}$ and Regina Kaplan-Rakowskib

a Département de didactique des langues, Université du Québec à Montréal, Montréal, Québec, Canada; bDepartment of Learning Technologies, College of Information, University of North Texas, Denton, TX, US A

# ABSTRACT

Second language (L2) learning research suggests that virtual reality (VR) has the potential to enhance the development of language skills due to its immersive nature and its situated learning oppor tunities. This quantitative, between-subjects study compared the effectiveness of three learning conditions. University students $( N = 6 3 )$ studied vocabulary annotated on: (1) $3 6 0 ^ { \circ }$ pictures viewed using a VR headset, (2) $3 6 0 ^ { \circ }$ pictures viewed on a desktop monitor, and (3) standard two-dimensional (2D) pictures viewed on a desktop monitor (control condition). After the experiment, the students completed productive and receptive posttests measuring vocabulary recall. Through multiple analyses of variance (MANOVA), the study revealed that learning new vocabulary with annotated $3 6 0 ^ { \circ }$ pictures viewed on a desktop monitor is associated with significantly higher posttests scores, compared with learning using a VR headset or standard 2D pictures. Kruskal-Wallis H tests showed vocabulary learning with $3 6 0 ^ { \circ }$ to be engaging, but effective only when studied on the 2D monitor. This study has practical implications for VR-assisted language learning and for the design of teaching materials to enhance L2 vocabulary learning.

# KEYWORDS

$3 6 0 ^ { \circ }$ pictures; immersive learning; virtual reality; vocabulary learning; annotated vocabulary

# Introduction

Mastering vocabulary is an essential step in language development (Nation, 2001). While many strategies have been identified to enhance vocabulary learning (Schmitt, 2010), language learners have commonly relied on the use of multimedia (e.g. pictures, videos) for vocabulary learning (Chun & Plass, 1996). As technology advances, novel approaches to learning vocabulary become available. For example, in addition to standard two-dimensional (2D) pictures, teachers can now use pictures that show an omnidirectional, $3 6 0 ^ { \circ }$ view, allowing students to freely explore a whole environment. Such pictures can be viewed using a high-immersion virtual reality (HiVR) headset or presented in low-immersion virtual reality (LiVR) on a 2D desktop monitor. In both cases, teachers can annotate $3 6 0 ^ { \circ }$ pictures with text (such as target vocabulary, as in the case of our study).

While research has explored vocabulary learning using 2D images (e.g. Yoshii & Flaitz, 2002) and stereoscopic 3D images (Kaplan-Rakowski, 2019; Kaplan-Rakowski, Lin, & Wojdynski, 2022), vocabulary learning with annotated $3 6 0 ^ { \circ }$ pictures in HiVR or LiVR has not received any attention even though they have instructional potential. Studies testing the method of loci indicate that learning can be stimulated through the use of spatial cues in a $3 6 0 ^ { \circ }$ environment, viewed in HiVR (Huttner & Robra-Bissantz, 2017; Krokos, Plaisant, & Varshney, 2019) or in LiVR (Reggente, Essoe, Baek, & Rissman, 2019). Moreover, research on LiVR has shown that digital environments annotated with words help learners to recall vocabulary (Lan, Fang, Legault, & Li, 2015).

Virtual reality (VR) for language learning has been rapidly gaining popularity. While various definitions exist, Kaplan-Rakowski and Gruber (2019) distinguish between different types of VR, based on the level of immersion that is provided. They define HiVR as ‘a computer-generated $3 6 0 ^ { \circ }$ virtual space that can be perceived as being spatially realistic, due to the high immersion afforded by a head-mounted device’ and LiVR as ‘a computer-generated three-dimensional virtual space experienced through standard audio-visual equipment, such as a desktop computer with a two-dimensional monitor’ (p. 552). Both HiVR and LiVR rely on omnidirectional viewing environments, allowing the content to be explored through the observer’s perspectives on three axes (Rai, Gutiérrez, & Le Callet, 2017).

In the context of this study, $3 6 0 ^ { \circ }$ pictures were annotated to serve as a visual aid, a vocabulary learning strategy that has been shown to improve second language (L2) proficiency (Smith, 1993). We define a $3 6 0 ^ { \circ }$ picture as a spherical photograph that allows ‘omnidirectional viewing and active exploration of the surrounding area, similar to real life’ (Papin & Kaplan-Rakowski, 2020, p. 266). Thanks to $3 6 0 ^ { \circ }$ pictures, language learners can see not only the photographed scene, but also the larger situational context provided by the surroundings. Such context is likely to foster increased immersion and offer a meaningful learning experience to students (Cárdenas-Robledo & Peña-Ayala, 2018). $3 6 0 ^ { \circ }$ pictures make it possible to explore all directions (up, down, left, right, etc.), while 2D pictures are limited to a smaller field of view, depicting only a fraction of the broader context. Table 1 shows a comparison of affordances between HiVR, LiVR, and 2D pictures. While some studies have investigated vocabulary learning in HiVR and LiVR, some conflicting results have emerged, especially with regard to the effect of the level of immersion on L2 vocabulary learning. Moreover, no research has investigated the effect of annotated vocabulary on $3 6 0 ^ { \circ }$ pictures. Investigating the effect of annotation in $3 6 0 ^ { \circ }$ pictures on vocabulary learning could shed a new light on previous inconsistent results, while opening the door to new research on material design for vocabulary learning.

Table 1. Comparison of affordances of high-immersion virtual reality (HiVR), low-immersion virtual reality (LiVR), and two-dimensional (2D) pictures.   

<html><body><table><tr><td colspan="2">Characteristics</td><td colspan="2">Learning conditions</td></tr><tr><td>Name</td><td>HiVR</td><td>LiVR</td><td>2D</td></tr><tr><td>Viewing method</td><td>Virtual reality headset</td><td>Desktop monitor</td><td>Desktop monitor</td></tr><tr><td>Immersion level</td><td>High</td><td>Low</td><td>None</td></tr><tr><td>Picture type</td><td>360 picture</td><td>360 picture</td><td>Standard 2D picture</td></tr><tr><td>Interactivity</td><td>Head movement tracking</td><td>Mouse scrolling, panning, zooming</td><td>No interactivity</td></tr><tr><td colspan="2">Examples</td><td colspan="2"></td></tr></table></body></html>

# Theoretical framework

This section presents the theoretical framework of our study, which adopts a cognitive approach to vocabulary learning and teaching, including dual coding theory, multimedia learning, and embodied cognition. Next, we present a literature review on the effectiveness of vocabulary learning using LiVR, HiVR, and the combination of LiVR and HiVR.

# L2 vocabulary learning and teaching

Word knowledge consists of three aspects, which are form, meaning, and use (Webb & Nation, 2017). The two main approaches to L2 vocabulary learning and teaching are implicit and explicit (Schmitt, 2008). Implicit vocabulary learning occurs incidentally, when language learners are exposed to new words in naturalistic contexts (Nation, 2001). The drawback of the implicit approach is that the amount of L2 output that learners receive is limited (Laufer, 2003). To complement the implicit approach, researchers have also called for explicit vocabulary teaching, which relies on direct instruction to teach learners word form, meaning, and use (Ellis, 2005). Theories, such as dual coding and cognitive multimedia learning, have been applied to CALL research to identify effective practices for explicit vocabulary instruction using technology.

# Dual coding theory and multimedia learning

Creating an association between a mental image and a concept has been used as a memory aid for millennia (Yates, 1992). From a cognitive view, the dual coding theory (Paivio, 1971) formulates a rationale for learning vocabulary with pictures. Paivio’s theory posits the existence of two subsystems influencing vocabulary memorization. A verbal system is related to the linguistic aspect of vocabulary learning (e.g. word structure, spelling), and a nonverbal system (imagery) refers to nonlinguistic aspects (e.g. pictures, events).

Word-image association supports L2 vocabulary learning (Cohen, 1987; Peters, 2019). Plass, Chun, Mayer, and Leutner (1998) also found that vocabulary learning aided with both verbal (translation) and visual (picture or video) annotations was effective. The Plass et  al. findings were integrated into the Mayer (1997) generative theory of multimedia learning, which goes beyond Paivio’s dual-coding theory and considers the limited capacity of working memory, active processing, and information transfer to account for learning.

The method of loci is another common technique for vocabulary memorization that relies on mental imagery, spatial mnemonics, and word-picture associations (Godwin-Jones, 2010). The method of loci corresponds to a mental representation in which the physical space is embedded with information (e.g. words, faces), facilitating recall (Yates, 1992). This approach aligns with cognitive psychology theories that consider spatial intelligence as the ability to visualize objects, recognize faces, or notice details to solve spatial navigation problems (Gardner, 2011). Existing apps such as ThingLink offer the possibility to annotate $3 6 0 ^ { \circ }$ pictures with multimedia that allow viewers to access visual or auditory information (Scrivner, Madewell, Buckley, & Perez, 2019). Annotating real-life objects has the potential to effectively create memory links with L2 vocabulary, as shown in a study by Ibrahim et  al. (2018).

# Embodied cognition theory and immersive learning environments

One key feature of immersive virtual environments is the sense of presence—the feeling of ‘being there’ that a user experiences in a computer-generated environment (Barfield, Zeltzer, Sheridan, & Slater, 1995). As Slater and Wilbur (1997) explain, presence is a state of consciousness felt by the user in a virtual environment, and immersion is an objective description of the technology and its capacity to create an illusion of reality. Vocabulary annotated on $3 6 0 ^ { \circ }$ pictures, viewed in HiVR, thus can be considered as more immersive than $3 6 0 ^ { \circ }$ pictures displayed on a desktop monitor (LiVR) or than traditional 2D pictures.

Research on embodied cognition suggests that the level of immersion might impact learning. Embodied cognition theories posit that an interaction exists between the body (verbal, visual, tactile, sonic, and kinesthetic elements based on the individual’s experience) and the environment during learning (Barsalou, 2008). According to embodied theories, the environment facilitates the development of cognitive representation (Borghi & Cimatti, 2010). Because $3 6 0 ^ { \circ }$ pictures require movement to be fully viewed – e.g., moving the mouse to explore a $3 6 0 ^ { \circ }$ scene displayed on a desktop monitor (LiVR) or moving one’s head to explore a $3 6 0 ^ { \circ }$ scene displayed through a head-mounted display (HiVR) – they provide more sensory-motor stimulus than regular 2D pictures. In other words, $3 6 0 ^ { \circ }$ pictures, especially if viewed in HiVR, provide more opportunities for embodied cognition than 2D pictures.

This is particularly relevant for L2 learning because embodiment and memory are closely related (Buzsáki & Moser, 2013) and that context-based learning helps learners associate words with their context (Kroll & Curley, 1988). Repetto et  al. (2021) argue that using $3 6 0 ^ { \circ }$ environments can support L2 learning by providing a sensorimotor experience (e.g. visual and motor stimuli), which helps L2 learners develop embodied representations through word-movement associations. Legault et  al. (2019) go further and explain that some of the differences in vocabulary learning observed between L1 and L2 learners could be explained by the fact that in their classroom, L2 learners do not have access to as many embodied opportunities (e.g. manipulating objects, being placed in different physical environments) as their L1 counterparts.

Moreover, due to its highly immersive aspect, HiVR provides excellent opportunities for embodied learning (Serino & Repetto, 2018; Vázquez, Xia, Aikawa, & Maes, 2018). By providing physical and visual cues, the combination of $3 6 0 ^ { \circ }$ pictures and HiVR therefore appears as an ideal configuration for embodied vocabulary learning, based on research showing that people tend to associate body and perception with words (Zwaan, Madden, Yaxley, & Aveyard, 2004).

# Literature review

When studying annotated vocabulary, language learners typically create mental associations between the target words and their corresponding 2D pictures (Plass et  al., 1998). Nowadays, the technology advancements, more specifically HiVR and LiVR, provide new embodied learning opportunities that have the potential to strengthen these mental associations and enhance vocabulary learning.

Virtual reality evokes realistic sensory experiences, activating learners’ visual coding (Xie, Chen, & Ryder, 2021). VR can also offer relevant and immersive situated learning spaces, which can activate language learners’ visual and kinesthetic channels, and lead to high-order thinking skills development (Xie et  al., 2021). Moreover, with its strong sense of presence, HiVR provides new affordances to help develop L2 communicative competence (Kaplan-Rakowski & Gruber, 2021; Ou Yang, Lo, Hsieh, Wu, & W.-C, 2020) and can also be a safe platform for practicing speaking while reducing foreign language anxiety (Gruber & Kaplan-Rakowski, 2020; 2022; Thrasher, 2022).

Language learning in both HiVR (Kaplan-Rakowski & Wojdynski, 2018; Lai $\&$ Chen, 2021) and LiVR (Papin, 2020; Wehner, Gump, & Downey, 2011) evoke students’ positive attitudes. Research also shows that LiVR, using $3 6 0 ^ { \circ }$ videos, has the potential to increase L2 willingness to communicate when placing students in virtual simulations reproducing real-life interactions (Papin, 2018; 2022).

In other words, both types of VR, LiVR and HiVR, have shown advantageous for language learning. Despite the potential of VR, no study thus far explored the effect of vocabulary learning using $3 6 0 ^ { \circ }$ pictures vocabulary viewed in HiVR or in LiVR; neither is there any study comparing the effectiveness of HiVR versus LiVR for any language aspect, including vocabulary learning. The sections below provide an overview of the most relevant existing research on vocabulary learning in HiVR and LiVR, as well as comparisons between HiVR and LiVR.

With regard to HiVR, a few studies have compared the effectiveness of learning L2 vocabulary in HiVR with more traditional methods (e.g. 2D flashcards). Legault et  al. (2019) compared L2 vocabulary learning using either HiVR (words displayed in a VR headset) or 2D flashcards. In both cases, participants $( N { = } 6 4 )$ had to click on target learning items to hear the corresponding L2 word, and they could see the English translation in a written form. The HiVR condition was associated with better results in terms of vocabulary accuracy, although the findings mostly applied to the lower-achieving participants. In a study conducted among 64 EFL Saudi learners, Alfadil (2020) also showed that explicit vocabulary teaching in an HiVR game yields significantly better vocabulary learning than traditional methods relying on books, worksheets, and lectures.

In a study with 24 learners of Swedish, Ebert, Gupta, and Makedon (2016) found that learning vocabulary in HiVR was significantly more effective than learning with flashcards. Participants $\scriptstyle { \left( N = 1 0 4 \right) }$ in Repetto, Di Natale, Villani, Triberti, Germagnoli, and Riva (2021) studied vocabulary situated in HiVR $3 6 0 ^ { \circ }$ videos against 2D videos. The HiVR group attained significantly higher vocabulary scores than the 2D group, confirming Ebert et  al. (2016) and Legault et  al. (2019) that a higher level of immersion helps recall.

Tai, Chen, and Todd (2020) also compared vocabulary learning in HiVR versus 2D videos. In their study, 49 EFL learners learned new vocabulary by performing a simulation on the Mondly VR app, using a VR headset (experimental group), or by watching a walkthrough 2D video of the same simulation (control group). HiVR group significantly outperformed the control group at the vocabulary posttests. Researchers explain this finding by the fact that the 2D video offers less interactivity and stimuli than an HiVR simulation.

Contrary to Legault et  al. (2019), Ebert et  al. (2016), and Repetto et  al. (2021), Hartfill et  al. (2020) found a negative impact of learning vocabulary in HiVR. Participants $\left( N = 2 9 \right)$ ) learned vocabulary in two conditions: (1) playing a dynamic HiVR game called Word Saber, and (2) using 2D flashcards. While the participants found the HiVR vocabulary game more entertaining and engaging than studying with 2D flashcards, their vocabulary scores were associated with significantly lower scores compared to 2D condition due to cognitive overload.

Moving to a less immersive context, researchers comparing vocabulary learning in LiVR and 2D have found fewer conflicting results, with the results being mostly positive toward learning in LiVR. For example, Lan et  al. (2015) used a similar research design as Legault et  al. (2019), but they compared vocabulary learning between LiVR and 2D among L2 Chinese learners $\left( N { = } 3 6 \right)$ . For both conditions of LiVR and 2D pictures, each clickable learning item revealed the written L2 word and its L1 translation. Results showed that LiVR aided short-term L2 vocabulary learning more than 2D picture-word associations. This finding aligns with other studies on the effectiveness of using virtual environments for L2 vocabulary learning (Hsiao, Lan, Kao, & Li, 2017; Lan, 2015; Rankin, Gold, & Gooch, 2006; Tseng, Liou, & Chu, 2020).

As for comparing the effectiveness between learning in HiVR versus LiVR, to date, no research testing annotated L2 vocabulary learning exists. The closest study that compared the effectiveness of using HiVR versus LiVR is a study by Krokos et  al. (2019). The researchers tested word recall, following the use of the method of loci under HiVR and LiVR conditions. Participants $( N { = } 4 0 )$ explored two $3 6 0 ^ { \circ }$ virtual environments displaying annotated pictures. The results indicate that HiVR viewing yielded significantly better recall than LiVR viewing, consistent with the hypothesis that a higher level of immersion helps learning.

While the study by Lai and Chen (2021) focused on incidental vocabulary learning, it also compared vocabulary gains in HiVR versus LiVR.

Participants $\left( N = 3 0 \right)$ played a visual novel game, either using a VR headset (HiVR) or personal computer (LiVR). Results indicate that although both groups saw vocabulary gains, the HiVR group performed significantly better at vocabulary delayed posttest. Participants declared that the sense of presence and the embodiment contributed to a better understanding of new words, pointing again to the importance of immersion to support vocabulary learning.

Teachers today have various options of technologies to facilitate vocabulary teaching, ranging from traditional word-picture associations to more immersive visualizations (e.g. $3 6 0 ^ { \circ }$ pictures). While more immersive learning environments tend to be more engaging, their effectiveness for vocabulary learning is unknown. The rationale of our study is to test the differences in effectiveness among three annotation formats in terms of vocabulary learning.

# Research questions

In sum, some evidence supports the potentially beneficial impact of HiVR over 2D conditions for vocabulary learning (Repetto et  al., 2021; Ebert et  al., 2016; Legault et  al., 2019). Meanwhile, Hartfill et  al. (2020) contradicted the additive value of HiVR for vocabulary learning, especially when learners are not used to VR technology (Dhimolea, Kaplan-Rakowski, & Lin, 2022). Moreover, while research in cognitive psychology indicates that HiVR is superior to LiVR for text recall (Krokos et  al., 2019), studies in language learning specific contexts did not yet confirm such a finding. Only one study investigated the effect of LiVR compared with 2D and found LiVR to be more effective for L2 vocabulary learning (Lan et  al., 2015).

Given the conflicting empirical results regarding the effectiveness of learning vocabulary annotated in HiVR, the scarce research on vocabulary learning using LiVR versus 2D pictures, and the fact that no study compared L2 vocabulary learning with annotated $3 6 0 ^ { \circ }$ pictures between these three conditions, this study addresses the following research question:

‘Is there a significant difference in the effectiveness of learning vocabulary annotated on:

1. $3 6 0 ^ { \circ }$ pictures viewed using a VR headset (HiVR),   
2. $3 6 0 ^ { \circ }$ pictures viewed on a desktop monitor (LiVR), or   
3. standard two-dimensional (2D) pictures?’

In addition to studying the learning outcomes through our main research question, we explore learners’ perceptions of the three types of annotations for vocabulary learning. Consequently, our exploratory research question is:

What differences are there in participants’ perceived engagement, effectiveness, and ease of use among the three conditions?

# Methods

# Research design

To answer the research questions, the design of the study encompassed three learning conditions: (1) vocabulary annotated on $3 6 0 ^ { \circ }$ pictures, viewed in HiVR using a VR headset, (2) vocabulary annotated on $3 6 0 ^ { \circ }$ pictures, viewed in LiVR on a desktop monitor, and (3) vocabulary annotated on standard 2D pictures, viewed on a desktop monitor (control condition). This between-subjects study followed a quantitative paradigm.

# The participants

University students $\left( N = 6 3 \right)$ ) learning L2 French volunteered to participate in the study. All the participants resided in a large, French-speaking Canadian city. Therefore, they were immersed in the Western culture and intensively exposed to the alphabetic language system. Due to the between-subject design of this study, we ensured that all participants had a comparable level of proficiency in French. This was verified with their institutional French placement test results and a pre-experiment screening test. The placement test consisted of multiple, comprehensive assessments of students’ proficiency. The assessment tasks included an oral interview, a writing task, and grammatical judgment tasks. A vocabulary screening test measured differences in the preexisting vocabulary knowledge of the participants. The analysis of ANOVA revealed insignificant differences at the $\textstyle p < 0 . 0 5$ for the target vocabulary knowledge between the three groups of students $[ F ( 2 , 5 9 ) ~ = ~ 0 . 5 5$ , $\hbar = 0 . 5 8 ]$ , confirming that the participants’ initial French vocabulary knowledge was comparable and limited, regardless of their L1.

The participants’ average length of French studies was 1–2 years, and the most prevalent mother tongues were Chinese $( 4 3 \% )$ and English $( 4 0 \% )$ . The mean age of the participants was 19.7. Table 2 provides further demographic characteristics of the sample.

All participants were proficient speakers of English. As required by the university regulations, students must demonstrate proficiency in English verified by standardized English test results, such as the Cambridge C2 Proficiency Exam (highest level of certification, with a score of at least 200 out of 230). The distribution of non-native speakers of English was comparable across the three groups.

Table 2. D emographic information about the participants.   

<html><body><table><tr><td rowspan="2"></td><td rowspan="2"></td><td colspan="2">Gender</td><td colspan="3">L1</td><td colspan="2">Years of French education</td></tr><tr><td>N F</td><td>M</td><td>English</td><td>Chinese</td><td>Others</td><td> 0-2 years</td><td>3+ years</td></tr><tr><td>Total</td><td>63</td><td>43</td><td>20</td><td>25</td><td>27</td><td>11</td><td>53</td><td>10</td></tr><tr><td>Percentage</td><td></td><td>68</td><td>32</td><td>40</td><td>43</td><td>17</td><td>84</td><td>16</td></tr></table></body></html>

Note. $\lfloor 1 =$ first language.

This study was approved by Research Ethics Board-1 at McGill University, and all participants gave prior written informed consent. The students did not receive any incentives to participate in the study. To avoid the Hawthorne effect, the research objectives were concealed from participants and the experiment was incorporated into the existing class.

# Content of the experiment

To assess the potential of VR for vocabulary learning, we used the ThingLink 360 online platform to annotate $3 6 0 ^ { \circ }$ pictures with L2 French words. Using a vocabulary corpus database ensured that the 15 selected target words were low-frequency words, consequently minimizing participants’ previous exposure to them. The selection of the target words needed to meet several criteria. All the target words were required (1) to be concrete nouns, (2) to be beyond beginner French level, (3) to be absent in the word pool in the students’ textbook, (4) to denote the meaning of an object, and (5) to not be cognates of English (to reduce the risk of students guessing the meaning). Applying the criteria resulted in a set of 15 words easily representable with visuals.

The final 15-word selection (see Appendix A) was determined by limitations of cognitive processing (Miller, 1956), by recommendations of short exposure to HiVR (Bailenson, 2018), and by established research (e.g. Tai et  al., 2020). We also consulted the French course instructor who helped determine the categories (i.e. restaurant, sport, nature) of our target vocabulary. We provided the translations to ensure that the participants were explicitly informed what each target word represented, in case of any confusion.

The target words were annotated in three different $3 6 0 ^ { \circ }$ pictures. The first picture depicted a street in Havana showing several pedestrians outside of a restaurant and a small city park. The second picture displayed the interior of a restaurant, which featured tables, chairs, a salad bar, and a large wine rack. The third picture showed the interior of a race car. Viewers could see a race car driver on a racetrack. The three pictures were linked and looped, allowing the participants to navigate efficiently.

# Instruments

The instruments of the study were a screening test, productive and receptive posttests, a demographic questionnaire, and a voluntary post-experimental survey. Our instrument sequencing was similar to what was done in other VR vocabulary learning studies (e.g. Repetto et  al., 2021). The participants completed all the instruments on an individual basis, in a digital format.

# Vocabulary screening test

The screening test served to verify that the participants had no substantial knowledge of the target vocabulary before the intervention, and to test the homogeneity of variances among the three groups. On the screening test, the participants saw a list of the 15 target French words and two words acting as distractors. As done in Tai et  al. (2020), the screening test consisted of a definition-supply test (word meaning). The participants were prompted to indicate which French words they knew and to provide evidence of it by writing the English translation or a definition of these words. If they did not know the meaning of a French word, participants had to check an I don’t know box.

# Posttest

The posttest consisted of two parts: one productive and one receptive, each lasting 5 minutes. Both parts covered all the 15 target French words and two distractors. As Nation (2001) suggested, including all the target vocabulary items in the test increases test reliability. The intention of the productive part (see Appendix B) was to measure the participants’ ability to recall and produce the target vocabulary (Schmitt, 2000). On the productive part, the participants saw the English translations together with the screenshots from the experiment, representing the objects that were annotated with the target vocabulary (the words were not visible on the screenshots). The participants’ task was to provide French translations of the words.

The goal of the receptive part of the posttest (see Appendix C) was to measure the participants’ ability to recognize the meaning of the L2 words and then select their correct French translation (Schmitt, 2000). On the receptive part of the posttest, the participants saw the screenshots from the experiment, representing the target French words. The participants’ task was to select the correct word from a multiple-choice list. The list contained all 15 target words, two distractors, and an $I$ don’t know option. This option intended to lessen the chance that some participants would randomly choose any item if they did not know the correct answer. The list of questions was randomized for both receptive and productive posttests to increase validity (Webb, Sasao, & Ballance, 2017).

The scoring scale for the receptive and productive parts of the posttest ranged from a minimal score of zero (0) to the maximum score of one (1) per item. For the receptive posttest (multiple-choice questions), the participants either received zero (0) or one (1) point per item. For the productive posttest, perfect answers received full credit of one (1) point. Answers with one minor issue (e.g. lack of diacritical marks or a missing letter) received 0.75 points, for example, ‘égout’ spelled as ‘egout’. Answers with more than one issue (e.g. a missing diacritical mark and an unnecessary letter) received 0.5 point, for example, ‘egoute’ instead of ‘égout’. Words that were more problematic, when only a partial word was provided, received a score of 0.25, for example, ‘égneu’ instead of ‘égout’. Finally, missing words or completely wrong answers, which included words that did not resemble the target words, received no points.

The scoring was performed independently by two raters who were experts in L2 teaching and research. In case of disagreement, a third rater was available to determine the final score; however, such a need did not arise because the inter-rater reliability reached $1 0 0 \%$ , as ratings depended on objective, pre-established scoring criteria.

# Demographic questionnaire and post experimental survey

The goal of the demographic questionnaire was to elicit the participants’ age, gender, native language, number of languages spoken fluently, and the length of French studies. The voluntary post-experimental survey contained Likert-scale questions eliciting the differences in participants’ perceptions on the level of engagement, effectiveness, and ease of use of the vocabulary learning conditions. The participants could also share comments on their learning experience.

# Procedure

# Pre-experiment practice activity

Participants completed a 5-minute pre-experiment practice activity (see Figure 1 for the screenshot) to become acquainted with the format of the experiment. This activity was also to reduce the novelty effect of HiVR and LiVR pictures. Next, the participants proceeded with the main experiment.

![](img/ec215a8812d8b4add9219d7e7dcc9423b52ecc5785a447cab76f02f9fe297b96.jpg)  
Figure 1. P re-experiment practice picture.Note. A screenshot of the sample pre-experiment practice picture. Number 3 displays the target word with its translation.

# Experiment

The main experiment consisted of three pictures—each annotated with five French target words numbered from 1 to 5. Participants hovered over each number to see the target French word with its translation in English, which was the participants’ lingua franca. Students were to follow the order of the numbers to ensure that they did not skip any words.

We ensured that our three learning conditions looked identical and presented the same pictures and the same vocabulary, with the only difference being the way the pictures were viewed. The first condition was in HiVR, using a VR headset (Google Cardboard). The second condition was in LiVR, using a $2 2 ^ { \prime \prime }$ desktop monitor. The third condition was in 2D, also on a $2 2 ^ { \prime \prime }$ desktop monitor. The 2D pictures (our control group) were screenshots of the $3 6 0 ^ { \circ }$ pictures, so the format of the annotated objects in all three conditions was nearly identical. The 2D pictures were presented on PowerPoint slides containing the French word and its English translation (see Figure 2). In all three conditions, participants had the same amount of time allotted for studying the vocabulary (5 minutes), but we allowed one additional minute to the HiVR group, accounting for possible technical issues. The reason for the duration of this intervention was driven by recommendations of HiVR experts who encourage only short exposures to HiVR technology (Bailenson, 2018).

# Post-experiment data collection

Following the experiment, the participants were given 10 minutes to complete the demographic questionnaire, which served as a distractive task before the posttests. We employed the strategy used in cognitive research (e.g. Krokos et  al., 2019) to ensure that information was no longer stored in the short-term memory as the mind was occupied with a different task after the experiment. Next, all participants had $2 0 \mathrm { { m i n } \mathrm { { - } } }$ utes to complete both the receptive and productive vocabulary posttests. Last, participants in the LiVR and HiVR were given the opportunity to fill out the voluntary post-experimental survey.

![](img/a39e29c7e9d14d69680ed39f2aa64aaab117797575dbd66d3accd0065950a224.jpg)  
Figure 2. E xperimental $3 6 0 ^ { \circ }$ picture.Note. Screenshots of the experimental $3 6 0 ^ { \circ }$ picture depicting the race car. The red numbers indicate the items annotated with the target vocabulary. The vocabulary is displayed when a user hovers over a number. Taken from the passenger’s seat, the two screenshots show what can be seen to the left and the right.

# Data analysis

Based on the recommendation by Howell (2012), we employed a multivariate analysis of variance (MANOVA) to determine whether there exist any differences between independent groups on more than one continuous dependent variable (posttest scores). The independent variable was the type of vocabulary learning method with three categories: (1) vocabulary annotated in HiVR, (2) vocabulary annotated in LiVR, and (3) vocabulary annotated on standard 2D pictures (control condition). For the non-parametric data, we conducted Kruskal-Wallis H tests to determine differences in participants’ engagement, perceived effectiveness, and ease of use when learning vocabulary in the experimental learning conditions. All the initial tests were followed with post hoc analyses.

# Results

# MANOVA assumptions

Prior to running the MANOVA, we verified that our study met the required assumptions. That is, our data had two dependent variables, each with continuous data. Our independent variable had three levels representing three learning conditions with three independent groups participating in the intervention. The participants completed only tasks in their assigned learning conditions, without being involved in other learning conditions, which satisfies the MANOVA assumption of independence of observations.

We further confirmed that our sample met the required conditions for multivariate normality with a visual examination of Q-Q plots, as suggested by Oppong and Agbedra (2016). The Q-Q plots also visually confirmed that our sample does not suffer from concerns about multivariate outliers. Moreover, we proceeded with more rigorous tests of multivariate skewness (Mardia, 1974), multivariate kurtosis (Mardia, 1974), and the chi-squared test of Mahalanobis distance (Henze & Zirkler, 1990).

The chi-squared Q-Q plot illustrated no concerns about a departure from multivariate normality (Oppong & Agbedra, 2016) or multivariate outliers. The test statistic for the Mardia multivariate skewness test was 4.34 ${ \it p } = 0 . 3 6 )$ , the Mardia multivariate kurtosis test value was −1.16 $( p = 0 . 2 8 )$ , and the Henze-Zirkler test value for Mahalanobis distance was 0.53 $\left( p = 0 . 4 3 \right)$ . Therefore, we cannot reject the null of multivariate normality for our sample by any of these measures and our data fulfill the necessary criteria for the MANOVA procedure (Oppong & Agbedra, 2016) with regards to multivariate normality.

To verify the homogeneity of the participants in terms of their previous French vocabulary knowledge, we conducted Levene’s test on the scores of the screening test. The results of Levene’s test indicated that the assumption of equality of variances was not violated $F ( 2 , 6 0 ) = 0 . 5 5$ , $p \ = . 5 8 > 0 . 0 5$ , confirming that the participants’ vocabulary knowledge before the experiment was comparable.

# MANOVA results

Table 3 summarizes the results of the MANOVA. We did not reject the null hypothesis that the productive measure was equal across conditions $[ F ( 2 , 6 0 ) = 1 . 7 5$ , $\hbar = 0 . 1 8 ]$ , which indicated that there were no significant mean differences across the conditions. As a result, for the productive measure, we did not follow up with post hoc tests.

In the receptive measure, the differences in sample means were statistically significant $[ F ( 2 , 6 0 ) = 6 . 3 7$ , $\hbar { < } 0 . 0 1 ]$ . To detect which pair of conditions was different, we conducted post hoc pairwise comparisons using Tukey-Kramer honestly significant difference (HSD) test.

Table 4 reports the mean $( M )$ , standard deviation $( S D )$ , standard error, and confidence interval for each learning condition and measure. For the receptive measure, the condition in which vocabulary was annotated in LiVR had the highest mean $\left( M = 1 1 . 6 5 \right)$ ). The control condition of vocabulary annotated on 2D pictures had the lowest mean $\langle M = 8 . 6 5 \rangle$ ). The control condition showed the largest variation in both measures $( S D / = 4 . 5 1 $ ). Vocabulary displayed in HiVR showed the smallest variation $\mathrm { \prime } S D = 3 . 3 4 \mathrm { \rangle }$ .

Table 3. R esults of vocabulary learning in screening test (ANO VA) and productive and receptive posttests (MANO VA).   

<html><body><table><tr><td></td><td>Ss</td><td>df</td><td>MS</td><td>F</td><td>Sig</td></tr><tr><td>Screening test between</td><td>1.10</td><td>2</td><td>0.55</td><td>0.55</td><td>0.58</td></tr><tr><td>Within</td><td>59.09</td><td>59</td><td>1.00</td><td></td><td></td></tr><tr><td>Total</td><td>60.19</td><td>61</td><td></td><td></td><td></td></tr><tr><td>Productive posttest between</td><td>39.10</td><td>2</td><td>19.55</td><td>1.75</td><td>0.18</td></tr><tr><td>Within</td><td>671.05</td><td>60</td><td>11.18</td><td></td><td></td></tr><tr><td>Total</td><td>710.15</td><td>62</td><td></td><td></td><td></td></tr><tr><td>Receptive posttest Between</td><td>173.69</td><td>2</td><td>86.85</td><td>6.37</td><td>0.003</td></tr><tr><td>Within</td><td>818.06</td><td>60</td><td>13.63</td><td></td><td></td></tr><tr><td>Total</td><td>991.75</td><td>62</td><td></td><td></td><td></td></tr></table></body></html>

Table 4. D escriptive statistics on receptive vocabulary recall.   

<html><body><table><tr><td colspan="4"></td><td rowspan="2"></td><td colspan="2">95% confidence interval for mean</td></tr><tr><td>Learning condition</td><td>N</td><td>M</td><td>SD</td><td>Standard error Lower bound</td><td>Upper bound</td></tr><tr><td>Receptive posttest</td><td>23</td><td>7.96</td><td>3.34</td><td>0.70</td><td>6.51</td><td>9.40</td></tr><tr><td>HiVR LiVR</td><td>23</td><td>11.65</td><td>3.35</td><td>0.70</td><td>10.20</td><td>13.10</td></tr><tr><td>2D (control)</td><td>17</td><td>8.65</td><td>4.51</td><td>1.09</td><td>6.33</td><td>10.97</td></tr><tr><td>Total</td><td>63</td><td>9.49</td><td>4.00</td><td>0.50</td><td>8.48</td><td>10.50</td></tr></table></body></html>

Note. HiVR $=$ high-immersion virtual reality; LiVR $=$ low-immersion vir tual reality; $2 \mathsf { D } =$ two-dimensional.

In sum, the scores associated with learning vocabulary annotated on $3 6 0 ^ { \circ }$ pictures in LiVR learning were significantly better on receptive measures, as compared with when vocabulary was studied using 2D pictures or HiVR. The effect size using Cohen’s $d$ indicated the value of 1.1 on the receptive comparison between HiVR and LiVR. Such a value represents a large effect size. The effect size values for the remaining pair comparisons are in Table 5.

# Post-experimental survey

Participants answered three questions: (1) ‘How engaging did you find the images that you saw?’, (2) ‘How effective did you find the images that you saw?’, (3) ‘How easy to use did you find the images that you saw?’. The perception levels were expressed with a 5-item Likert scale, ranging from 1 (not at all) to 5 (extremely). Overall, the HiVR and LiVR groups expressed being equally engaged, but the 2D group was significantly less engaging. The LiVR group found their condition significantly more effective than HiVR or 2D conditions. Learning with LiVR was perceived as significantly easier compared to HiVR.

Table 5. P airwise comparisons on vocabulary learning in receptive posttests.   

<html><body><table><tr><td rowspan="2">Learning condition</td><td rowspan="2">Mean difference</td><td rowspan="2">Standard error</td><td rowspan="2"></td><td colspan="2">95% confidence interval for mean</td><td rowspan="2">Cohen&#x27;s de</td></tr><tr><td>Sig Lower bounde</td><td>Upper bound</td></tr><tr><td>Receptive posttest</td><td>0.69</td><td>1.18</td><td>0.83</td><td>2.15</td><td>3.53</td><td>0.1</td></tr><tr><td>2DHiVR 2DLiVR</td><td>3.01</td><td>1.18</td><td>0.04</td><td>5.84</td><td>0.17</td><td>0.4</td></tr><tr><td>LiVR-HiVR</td><td>3.70</td><td>1.09</td><td>0.00</td><td>1.08</td><td>6.31</td><td>1.1</td></tr></table></body></html>

Note: $2 \mathsf { D } =$ two-dimensional; HiVR $=$ high-immersion virtual reality; LiVR $=$ low-immersion virtual reality.

# Perceived-engagement levels

We ran a Kruskal-Wallis $_ \mathrm { H }$ test to determine whether the levels of learners’ engagement differed between HiVR, LiVR, and 2D groups. Median scores were statistically significantly different between groups, $H ( 2 ) = 7 . 8 9$ , $p = . 0 1 9$ . Using Dunn’s (1964) procedure with a Bonferroni correction for multiple comparisons, we conducted post hoc pairwise comparisons between the groups. This analysis revealed statistically significant $( p \ : = \ : . 0 4 6 )$ differences in levels of engagement between the HiVR $\displaystyle M d n = 4$ ) and 2D $\left( M d n = 3 \right)$ ) groups, and between the LiVR $( M d n = 4 )$ ) $\left( p \ = \ . 0 0 6 \right)$ and 2D groups, but not between the HiVR and LiVR groups.

# Perceived-effectiveness levels

We also ran a Kruskal-Wallis $_ \mathrm { H }$ test to calculate differences in the levels of learners’ perceived effectiveness of HiVR, LiVR, and 2D conditions for vocabulary learning. Median scores were statistically significantly different between the groups, $H ( 2 ) = 6 . 1 9$ , $ { p ^ { \mathrm { ~ = ~ } } } . 0 4 5$ . Post hoc pairwise comparisons between the groups with a Bonferroni correction for multiple comparisons indicated statistically significant differences in levels of perceived effectiveness between the LiVR $( M d n = 4 )$ ) and 2D $( M d n = 4 )$ ) $( p \ : = \ : . 0 1 9 )$ groups, but not between the remaining comparisons.

# Perceived ease of use

Our last question was about ease of use and it did not apply to the 2D group. Kruskal-Wallis H test for differences between the HiVR and LiVR groups were statistically significant $\left( { p = 0 . 0 0 2 } \right)$ , indicating that the LiVR group found the technology easier to use.

# Discussion

The main goal of this study was to examine whether there is a difference in the effectiveness of learning vocabulary annotated on: (1) $3 6 0 ^ { \circ }$ pictures viewed using a VR headset (HiVR), (2) $3 6 0 ^ { \circ }$ pictures viewed on a desktop monitor (LiVR), or (3) standard 2D pictures. The study also aimed at exploring the participants’ perceptions of the three conditions. The results of the MANOVA for the receptive posttest showed that the LiVR group obtained significantly higher results, compared with both the HiVR group and the 2D pictures group. The most informative aspect of our findings is that we do not observe a monotonic progression of learning effectiveness as students go from 2D to HiVR. LiVR seems to offer an ideal balance of immersion and effectiveness for vocabulary learning. We observe a pattern in which learning is least effective for the two extremes of 2D and HiVR and is the most effective for the middle condition of LiVR (see Figure 3). Our results, therefore, are inconsistent with most existing studies that were limited to two conditions that could be classified as higher and lower immersion settings.

# Higher immersion does not necessarily lead to better vocabulary learning

Our findings differ from several studies comparing HiVR and LiVR for vocabulary learning in a $3 6 0 ^ { \circ }$ environment. Repetto et  al. (2021), Ebert et  al. (2016), and Legault et  al. (2019) found that vocabulary learning in HiVR was more effective than learning with flashcards and standard word associations. Krokos et  al. (2019), as well as Lai and Chen (2021), found that HiVR yielded better information recall than LiVR. Our results thus suggest that conclusions concerning VR for language learning are dependent on the precise type of VR condition, the learning environment, and the testing procedure.

One explanation for the discrepancy between our findings and past research may be that our study used $3 6 0 ^ { \circ }$ pictures instead of $3 6 0 ^ { \circ }$ videos as in Madini and Alshaikhi (2017) and Repetto et  al. (2021). Videos are typically more immersive and likely to have more learning context. Videos also often include an audio channel, possibly aiding information encoding (Mayer, 1997; Paivio, 1971). Furthermore, the studies by Madini and Alshaikhi (2017), as well as by Repetto et  al. (2021), were longitudinal, lasting 14 and 4 weeks, respectively. Participants in these studies may have had a chance to review the learning content on multiple occasions, thus promoting better learning with HiVR, as suggested in a systematic review of research on VR-assisted language learning (Dhimolea et  al., 2022). Our study evaluated a one-time intervention to reduce the confounding variables that are present with repeated exposures to the learning content over time.

![](img/c3104e609f17ba7580a7db839ca20c0afef951434c2fd6323e7490accc491c57.jpg)  
Figure 3. Learning effectiveness when studying annotated vocabulary in different levels of immersion.

The Legault et  al. (2019) results supporting the superiority of learning in HiVR could be explained by the fact that their experiment included tactile learning through the inclusion of haptic controls. Legault et  al. (2019), along with Jia and Liu (2019), also used both visual and auditory channels. Their participants could click to display the picture of the item and its translation, as well as listen to its pronunciation. Our study used only a visual channel, which might have made our word-picture associations weaker, according to the Paivio (1971) dual-coding theory. We purposely limited our experiment to testing solely the visual channel to avoid extraneous variables.

One more explanation for differences in our results is that several participants reported discomfort (e.g. dizziness) when studying in HiVR. We intentionally included a pre-experiment practice for our experimental groups to allow for adjustment to the technology. Nevertheless, in the post-experimental survey, several HiVR participants reported encountering minor technical difficulties, which might have affected their learning experience.

Moreover, Vázquez et  al. (2018) noticed that when their participants were first exposed to the HiVR environment, their level of distraction was high. Our participants reported no previous experience with HiVR which might have contributed to a distraction due to the novelty effect for the HiVR condition. Novelty and lack of experience with immersive technology may decrease its effectiveness (Kaplan-Rakowski, 2019). This negative effect might not have been as strong for the LiVR condition because the medium of display (a desktop monitor) was more familiar to the participants than a VR headset.

# Cognitive load as a possible limitation to L2 vocabulary learning in HiVR

Our receptive measures revealed a significant difference in effectiveness between LiVR and 2D pictures. Such an outcome is in line with Lan et  al. (2015), although their study used Second Life, a virtual world, which displays computer-generated content instead of $3 6 0 ^ { \circ }$ pictures used in our study. Our results could be explained by the fact that LiVR is perceived as easier to use than HiVR. Some participants reported discomfort using HiVR, as seen in these comments: ‘The lack of something to keep the headset still on my head without the use of my hands was annoying and made me a little motion sick’, or ‘I felt dizzy discovering those words’. This type of discomfort (referred to as ‘cybersickness’) is caused by stereoscopic viewing and is sometimes associated with the use of HiVR (Kaplan-Rakowski, 2019; Kaplan-Rakowski et  al., 2022; Kaplan-Rakowski & Wojdynski, 2018). LiVR may not have led to cognitive overload, but it still provided a certain level of immersion that, based on contextual learning and embodied cognitive theories, can help recall (Buzsáki & Moser, 2013; Kroll & Curley, 1988).

On the receptive tests, we also found that LiVR was more effective than HiVR. These results contradict some previous studies (Huttner & Robra-Bissantz, 2017; Krokos et  al., 2019). The conflicting outcomes may have been caused by differing research designs. In Krokos et  al. (2019), the participants were first shown word-picture associations and then had to use the method of loci in a virtual space to recall these associations. In our case, HiVR may have provided extensive stimuli and may have led to cognitive overload (Sweller, 1988), which limited the participants’ short-term memory capacity. The increased level of immersion might therefore have acted as a distractor for the HiVR group. In addition, students reported in the post-experimental survey that HiVR was harder to navigate than LiVR.

# Conclusions

This paper described a quantitative, experimental investigation of the effect of annotating vocabulary on $3 6 0 ^ { \circ }$ pictures viewed in HiVR, $3 6 0 ^ { \circ }$ pictures viewed in LiVR, and 2D pictures. The receptive tests results revealed that learning vocabulary with annotated $3 6 0 ^ { \circ }$ pictures is associated with significantly higher posttests scores, compared with learning with standard 2D pictures, provided that viewing is on a desktop monitor and not with a VR headset. On productive posttests, learners recalled vocabulary equally well across the three learning conditions.

While these results contradict previous research suggesting that a higher level of immersion helps recall (Huttner & Robra-Bissantz, 2017; Krokos et  al., 2019), our post-experimental survey revealed that HiVR may lead to cognitive overload due to the rich stimuli of the environment, which consequently could have impeded vocabulary learning. LiVR seems to provide L2 learners with the right amount of immersion and embodied learning, making it more effective than HiVR or traditional 2D pictures.

As any study, ours has several limitations. First, our participants reported Chinese or English being their L1 ( $4 3 \%$ and $4 0 \%$ , respectively), which made the sample unbalanced. While the significant differences observed in the receptive posttests came with a strong size effect, the sample size for this study was not large enough for stronger tests considering other variables. Future studies could benefit from a larger sample size and from exploring how the participants’ L1 could affect their learning in HiVR and LiVR. Testing the differences in L1 between the learners seems particularly interesting; Papin and Kaplan-Rakowski (2020) have already iniciated such research. As literature shows (Siok, Perfetti, Jin, & Tan, 2004), native speakers of languages that use pictographs have different spatial awareness than learners whose native language uses the alphabetic system. Also, some students learn better using visual cues, while others do not (Armstrong, 2009). Further exploration of these factors could explain variation in our results across participants.

Unlike other VR and vocabulary studies (Repetto et  al., 2021; Madini & Alshaikhi, 2017), ours focused on a single in-class intervention. Future studies should also focus on vocabulary retention. Because annotated LiVR pictures are easy to navigate and do not seem to create a cognitive overload for learners, investigating how to best take advantage of LiVR pictures in language classrooms would be useful. Some examples of lesson design to be calibrated include the number of words to annotate per picture, visualization time, exposure frequency, and manipulating various multimedia within $3 6 0 ^ { \circ }$ pictures (e.g., audio, video, text) . Studies could also observe learning gains when annotated $3 6 0 ^ { \circ }$ pictures are integrated into a larger teaching scenario to reinforce ecological validity.

This study was the first to compare vocabulary learning between HiVR and LiVR. It has important pedagogical implications in the field of L2 vocabulary learning and CALL. According to our data, LiVR significantly aids vocabulary recall and is easy to navigate. Online annotated $3 6 0 ^ { \circ }$ pictures are also easy to share (Scrivner et  al., 2019) with students, which makes them useful tools for context-aware, ubiquitous learning (Cárdenas-Robledo & Peña-Ayala, 2018). Teachers could also use online annotation platforms (e.g. ThingLink) to ask students to create their own annotated pictures and connect them (i.e. a virtual tour or a digital story). Besides supporting L2 vocabulary learning, such activities would bring more contextual learning as students could choose to annotate pictures captured in their daily-life environment. Even though our study focused on L2 vocabulary learning, strategies of word annotation in VR could be equally implemented in other subjects (e.g. medicine, biology).

# Disclosure statement

No potential conflict of interest was reported by the authors.

# Funding

This work was not supported by any funding.

# Notes on contributor

Kevin Papin is an Assistant Professor in the Faculty of Education at Université du Québec à Montréal (UQAM). His research focuses on the pedagogical use of technology (e.g., virtual reality, speech technologies) for L2 learning, in relation to willingness to communicate, vocabulary and pronunciation.

Dr. Kaplan-Rakowski’s key research interests lie at the intersection of three areas: immersive learning technologies (e.g., virtual reality, augmented reality, mixed reality), computer-assisted language learning (CALL), and emotional responses to learning technologies. Within CALL, Kaplan-Rakowski studies how practicing various language skills can be facilitated using high-immersion virtual reality, immersive stereoscopic 3D pictures, $3 6 0 ^ { \circ }$ degree pictures, and other immersive technologies.

# ORCID

Kevin Papin $\textcircled{1}$ http://orcid.org/0000-0001-7547-4524   
Regina Kaplan-Rakowski $\textcircled{1}$ http://orcid.org/0000-0002-6769-7784

# References

Alfadil, M. (2020). Effectiveness of virtual reality game in foreign language vocabulary acquisition. Computers & Education, 153, 103893. https://doi.org/10.1016/j.compedu.2020.103893   
Armstrong, T. (2009). Multiple intelligences in the classroom (3rd ed.). Alexandria, VA: ASCD.   
Bailenson, J. (2018). Experience on demand: What virtual reality is, how it works, and what it can do. New York, NY: WW Norton & Company.   
Barfield, W., Zeltzer, D., Sheridan, T., & Slater, M. (1995). Presence and performance within virtual environments. In W. B. T. A. Furness (Ed.), Virtual environments and advanced interface design (pp. 473–513). Oxford: Oxford University Press on Demand.   
Barsalou, L. W. (2008). Grounded cognition. Annual Review of Psychology, 59, 617–645. https://doi.org/10.1146/annurev.psych.59.103006.093639   
Borghi, A. M., & Cimatti, F. (2010). Embodied cognition and beyond: Acting and sensing the body. Neuropsychologia, 48(3), 763–773. https://doi.org/10.1016/j.neuropsychologia.2009.10.029   
Buzsáki, G., & Moser, E. I. (2013). Memory, navigation and theta rhythm in the hippocampal-entorhinal system. Nature Neuroscience, 16(2), 130–138. https://doi. org/10.1038/nn.3304   
Cárdenas-Robledo, L. A., & Peña-Ayala, A. (2018). Ubiquitous learning: A systematic review. Telematics and Informatics, 35(5), 1097–1132. https://doi.org/10.1016/j. tele.2018.01.009   
Chun, D. M., & Plass, J. L. (1996). Effects of multimedia annotation on vocabulary acquisition. The Modern Language Journal, 80(2), 183–198. https://doi.org/10.2307/328635   
Cohen, A. D. (1987). The use of verbal and imagery mnemonics in second language vocabulary learning. Studies in Second Language Acquisition, 9(1), 43–61. https://doi. org/10.1017/S0272263100006501   
Dhimolea, T. K., Kaplan-Rakowski, R., & Lin, L. (2022). A systematic review of research on high-immersion virtual reality for language learning.  TechTrends, 6. https://doi. org/10.1007/s11528-022-00717-w.   
Dunn, O. J. (1964). Multiple comparisons using rank sums. Technometrics, 6, 241–252. https://doi.org/10.1080/00401706.1964.10490181   
Ebert, D., Gupta, S., & Makedon, F. (2016). Ogma: A virtual reality language acquisition system [Paper presentation]. Proceedings of the 9th ACM International Conference on Pervasive Technologies Related to Assistive Environments, PETRA’16, June, pp. 1–5. Association for Computing Machinery. https://doi.org/10.1145/2910674.2910681   
Ellis, N. C. (2005). At the interface: Dynamic interactions of explicit and implicit language knowledge. Studies in Second Language Acquisition, 27(2), 305–352. https:// doi.org/10.1017/S027226310505014X   
Gardner, H. (2011). Frames of mind: The theory of multiple intelligences. New York, NY: Basic Books.   
Godwin-Jones, R. (2010). Emerging technologies. Language Learning & Technology, 2(14), 4–11.   
Gruber, A., & Kaplan-Rakowski, R. (2020). User experience of public speaking practice in virtual reality. In R. Z. Zheng (Ed.), Cognitive and affective perspectives on immersive technology in education (pp. 235–249). Rochester, NY: IGI Global. https:// doi.org/10.4018/978-1-7998-3250-8.ch012   
Gruber, A., & Kaplan-Rakowski, R. (2022).  The impact of high-immersion virtual reality on foreign language anxiety. Boston, MA: SSRN. https://dx.doi.org/10.2139/ ssrn.3882215   
Hartfill, J., Gabel, J., Neves-Coelho, D., Vogel, D., Räthel, F., Tiede, S., Ariza, O., Steinicke, F. (2020). Word saber: An effective and fun VR vocabulary learning game. In B. Preim, A. Nürnberger, & C. Hansen (Eds.), MuC ‘20: Proceedings of the Conference on Mensch und Computer (pp. 145–154). New York, NY: Association for Computing Machinery. https://doi.org/10.1145/3404983.3405517   
Henze, N., & Zirkler, B. (1990). A class of invariant consistent tests for multivariate normality. Communications in Statistics – Theory and Methods, 19(10), 3595–3617. https://doi.org/10.1080/03610929008830400   
Howell, D. C. (2012). Statistical methods for psychology. Boston, MA: Cengage Learning.   
Hsiao, I. Y., Lan, Y. J., Kao, C. L., & Li, P. (2017). Visualization analytics for second language vocabulary learning in virtual worlds. Journal of Educational Technology & Society, 20(2), 161–175.   
Huttner, J. P., & Robra-Bissantz, S. (2017). An immersive memory palace: Supporting the method of loci with virtual reality. Twenty-third Americas Conference on Information Systems.   
Ibrahim, A., Huynh, B., Downey, J., Höllerer, T., Chun, D., & O’Donovan, J. (2018). Arbis pictus: A study of vocabulary learning with augmented reality. IEEE Transactions on Visualization and Computer Graphics, 24(11), 2867–2874. https://doi.org/10.1109/ TVCG.2018.2868568   
Jia, T., & Liu, Y. (2019 Words in kitchen: An instance of leveraging virtual reality technology to learn vocabulary [Paper presentation].2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct), (October, pp. 150–155). Institute of Electrical and Electronics Engineers. https://doi.org/10.1109/ ISMAR-Adjunct.2019.00-59   
Kaplan-Rakowski, R. (2019). The effect of stereoscopic three-dimensional images on vocabulary learning. Contemporary Educational Technology, 10(4), 324–337. https:// doi.org/10.30935/cet.634172   
Kaplan-Rakowski, R., & Gruber, A. (2021). One-on-one foreign language speaking practice in high-immersion virtual reality. In Y. J. Lan, & S. Grant (Eds.), Contextual language learning – Real language learning on the continuum from virtuality to reality (pp. 187–202). Springer. https://doi.org/10.1007/978-981-16-3416-1   
Kaplan-Rakowski, R., & Gruber, A. (2019). Low-immersion versus high-immersion virtual reality: Definitions, classification, and examples with a foreign language focus. Proceedings of the Innovation in Language Learning International Conference 2019 (pp. 552–555). New York, NY: Pixel.   
Kaplan-Rakowski, R., Lin, L., & Wojdynski, T. (2022). Learning vocabulary using 2D pictures is more effective than using immersive 3D stereoscopic pictures. International Journal of Human–Computer Interaction, 38(4), 1–10. https://doi.org/10.1080/104473 18.2021.1938394   
Kaplan-Rakowski, R., & Wojdynski, T. (2018). Students’ attitudes toward high-immersion virtual reality assisted language learning. In P. Taalas, J. Jalkanen, L. Bradley, & S. Thouësny (Eds.), Future-proof CALL: Language learning as exploration and encounters—short papers from EUROCALL 2018 (pp. 124–129). Voillans, France: Research-publishing.net. https://doi.org/10.14705/rpnet.2018.26.824   
Krokos, E., Plaisant, C., & Varshney, A. (2019). Virtual memory palaces: immersion aids recall. Virtual Reality, 23(1), 1–15. https://doi.org/10.1007/s10055-018-0346-3   
Kroll, J. F., & Curley, J. (1988). Lexical memory in novice bilinguals: The role of concepts in retrieving second language words. In M. Gruneberg, P. Morris, & R. Sykes (Eds.), Practical aspects of memory (Vol. 2, pp. 389–395). Cambridge, MA: Academic Press.   
Lai, K. W. K., & Chen, H. J. H. (2021). A comparative study on the effects of a VR and PC visual novel game on vocabulary learning. Computer Assisted Language Learning, 1–34. Ahead-of-print. https://doi.org/10.1080/09588221.2021.1928226   
Lan, Y. J. (2015). Contextual EFL learning in a 3D virtual environment. Language Learning & Technology, 19(2), 16–31.   
Lan, Y. J., Fang, S. Y., Legault, J., & Li, P. (2015). Second language acquisition of Mandarin Chinese vocabulary: Context of learning effects. Educational Technology Research and Development, 63(5), 671–690. https://doi.org/10.1007/s11423-015-9380-y   
Laufer, B. (2003). Vocabulary acquisition in a second language: Do learners really acquire most vocabulary by reading? Some empirical evidence. Canadian Modern Language Review, 59(4), 567–587. https://doi.org/10.3138/cmlr.59.4.567   
Legault, J., Zhao, J., Chi, Y. A., Chen, W., Klippel, A., & Li, P. (2019). Immersive virtual reality as an effective tool for second language vocabulary learning. Languages, 4(1), 13–44. https://doi.org/10.3390/languages4010013   
Madini, A. A., & Alshaikhi, D. (2017). Virtual reality for teaching ESP vocabulary: A myth or a possibility. International Journal of English Language Education, 5(2), 111–126. https://doi.org/10.5296/ijele.v5i2.11993   
Mardia, K. V. (1974). Applications of some measures of multivariate skewness and kurtosis in testing normality and robustness studies. Sankhyā: The Indian Journal of Statistics, Series B, 36(2), 115–128.   
Mayer, R. E. (1997). Multimedia learning: Are we asking the right questions? Educational Psychologist, 32(1), 1–19. https://doi.org/10.1207/s15326985ep3201_1   
Miller, G. A. (1956). The magical number seven, plus or minus two: Some limits on our capacity for processing information. Psychological Review, 63(2), 81–97. https:// doi.org/10.1037/h0043158   
Nation, I. S. P. (2001). Learning vocabulary in another language. Cambridge, UK: Cambridge University Press. https://doi.org/10.1017/CBO9781139524759   
Oppong, F. B., & Agbedra, S. Y. (2016). Assessing univariate and multivariate normality. a guide for non-statisticians. Mathematical Theory Modeling, 6(2), 26–33.   
Ou Yang, F.-C., Lo, F.-Y R., Hsieh, C., Wu, J., & W.-C, V. (2020). Facilitating communicative ability of EFL learners via high-immersion virtual reality. Educational Technology & Society, 23(1), 30–49.   
Paivio, A. (1971). Imagery and verbal processes. New York, NY: Holt, Rinehart & Winston. https://doi.org/10.1126/science.176.4035.628-b   
Papin, K. (2018). Can 360 virtual reality tasks impact L2 willingness to communicate? In P. Taalas, J. Jalkanen, L. Bradley, & S. Thouësny (Eds.), Future-proof CALL: Language learning as exploration and encounters–short papers from EUROCALL 2018 (pp. 243–248). Voillans, France: Research-publishing.net. https://doi.org/10.14705/ rpnet.2018.26.844   
Papin, K. (2022). L’impact de tâches communicatives de réalité virtuelle sur la volonté de communiquer à l’extérieur de la classe: Perceptions d’apprenants de FLS à Montréal. The Canadian Modern Language Review, 78(1), 52–74. https://doi.org/10.3138/ cmlr-2020-0117   
Papin, K., & Kaplan-Rakowski, R. (2020). An exploratory analysis of the impact of learners’ first language on vocabulary recall using immersive technologies. In K.-M. Frederiksen, S. Larsen, L. Bradley & S. Thouësny (Eds), CALL for widening participation: short papers from EUROCALL 2020 (pp. 266–271). Voillans, France: Research-publishing.net. https://doi.org/10.14705/rpnet.2020.48.1199   
Papin, K. (2020). [La contribution des tâches de réalité virtuelle au désir de communiquer en français langue seconde à l’extérieur de la salle de classe à Montréal]. [Doctoral dissertation]. Université de Montréal, Papyrus. https://hdl.handle.net/1866/23558   
Peters, E. (2019). The effect of imagery and on‐screen text on foreign language vocabulary learning from audiovisual input. TESOL Quarterly, 53(4), 1008–1032. https:// doi.org/10.1002/tesq.531   
Plass, J. L., Chun, D. M., Mayer, R. E., & Leutner, D. (1998). Supporting visual and verbal learning preferences in a second language multimedia learning environment. Journal of Educational Psychology, 90(1), 25–36. https://doi.org/10.1037/0022-0663.90.1.25   
Rai, Y., Gutiérrez, J., & Le Callet, P. (2017 A dataset of head and eye movements for 360-degree images [Paper presentation]. Proceedings of the 8th ACM on Multimedia Systems Conference, (June, pp. 205–210). Association for Computing Machinery. https://doi.org/10.1145/3083187.3083218   
Rankin, Y., Gold, R., & Gooch, B. (2006). 3D role-playing games as language learning tools. Eurographics, 25(3), 33–38. https://doi.org/10.4236/jss.2015.310015   
Reggente, N., Essoe, J. K., Baek, H. Y., & Rissman, J. (2019). The method of loci in virtual reality: Explicit binding of objects to spatial contexts enhances subsequent memory recall. Journal of Cognitive Enhancement, 4(1), 12–30. https://doi.org/10.1007/ s41465-019-00141-8   
Repetto, C., Di Natale, A. F., Villani, D., Triberti, S., Germagnoli, S., & Riva, G. (2020). The use of immersive $3 6 0 ^ { \circ }$ videos for foreign language learning: A study on usage and efficacy among high-school students. Interactive Learning Environments, 1–16. https://doi.org/10.31234/osf.io/5b7y2   
Repetto, C., Di Natale, A. F., Villani, D., Triberti, S., Germagnoli, S., & Riva, G. (2021). The use of immersive $3 6 0 ^ { \circ }$ videos for foreign language learning: a study on usage and efficacy among high-school students. Interactive Learning Environments, 1–16. Ahead-of-print. https://doi.org/10.1080/10494820.2020.1863234   
Schmitt, N. (2008). Instructed second language vocabulary learning. Language Teaching Research, 12(3), 329–363. https://doi.org/10.1177/1362168808089921 Schmitt, N. (2010). Researching vocabulary: A vocabulary research manual. London, UK: Palgrave Macmillan. https://doi.org/10.1057/9780230293977 Schmitt, N. (2000). Vocabulary in Language Teaching. Cambridge, UK: Cambridge University Press. Scrivner, O., Madewell, J., Buckley, C., & Perez, N. (2019). Best practices in the use of augmented and virtual reality technologies for SLA: Design, implementation, and feedback. In M. L. Carrió-Pastor (Ed.), Teaching language and teaching literature in virtual environments (pp. 55–72). New York, NY: Springer. https://doi.org/10.1007/978-   
981-13-1358-5_4 Serino, S., & Repetto, C. (2018). New trends in episodic memory assessment: Immersive   
360 ecological videos. Frontiers in psychology, 9, 1878. https://doi.org/10.3389/ fpsyg.2018.01878 Siok, W. T., Perfetti, C. A., Jin, Z., & Tan, L. H. (2004). Biological abnormality of impaired reading is constrained by culture. Nature, 431(7004), 71–76. Slater, M., & Wilbur, S. (1997). A framework for immersive virtual environments (FIVE): Speculations on the role of presence in virtual environments. Presence: Teleoperators & Virtual Environments, 6(6), 603–616. https://doi.org/10.1162/ pres.1997.6.6.603 Smith, M. S. (1993). Input enhancement in instructed SLA: Theoretical bases. Studies in Second Language Acquisition, 15(2), 165–179. https://doi.org/10.1017/ S0272263100011943 Sweller, J. (1988). Cognitive load during problem solving: Effects on learning. Cognitive Science, 12(2), 257–285. https://doi.org/10.1207/s15516709cog1202_4 Tai, T. Y., Chen, H. H. J., & Todd, G. (2020). The impact of a virtual reality app on adolescent EFL learners’ vocabulary learning. Computer Assisted Language Learning,   
1–26. Ahead-of-print. https://doi.org/10.1080/09588221.2020.1752735 Thrasher, T. (2022). The impact of virtual reality on L2 French learners’ language anxiety and oral comprehensibility: An exploratory study. CALICO Journal, 39(2) https://doi.org/10.1558/cj.42198 Tseng, W. T., Liou, H. J., & Chu, H. C. (2020). Vocabulary learning in virtual environments: Learner autonomy and collaboration. System, 88, 102190. https://doi. org/10.1016/j.system.2019.102190 Vázquez, C., Xia, L., Aikawa, T., & Maes, P. (2018 Words in motion: Kinesthetic language learning in virtual reality [Paper presentation]. 2018 IEEE 18th International Conference on Advanced Learning Technologies (ICALT), (July, pp. 272–276). Institute of Electrical and Electronics Engineers. https://doi.org/10.1109/ICALT.2018.00069 Webb, S. A., & Nation, I. S. P. (2017). How vocabulary is learned. Oxford, UK: Oxford University Press. https://doi.org/10.25170/ijelt.v12i1.1458 Webb, S., Sasao, Y., & Ballance, O. (2017). The updated Vocabulary Levels Test: Developing and validating two new forms of the VLT. ITL-International Journal of Applied Linguistics, 168(1), 33–69. https://doi.org/10.1075/itl.168.1.02web Wehner, A. K., Gump, A. W., & Downey, S. (2011). The effects of Second Life on the motivation of undergraduate students learning a foreign language. Computer Assisted Language Learning, 24(3), 277–289. https://doi.org/10.1080/09588221.2010.551757 Xie, Y., Chen, Y., & Lan Ryder, H. (2021). Effects of using mobile-based virtual reality on Chinese L2 students’ oral proficiency. Computer Assisted Language Learning,   
34(3), 225–245. https://doi.org/10.1080/09588221.2019.1604551 Yates, F. A. (1992). The art of memory. (Vol. 64). London, UK: Random House.   
Yoshii, M., & Flaitz, J. (2002). Second language incidental vocabulary retention: The effect of text and picture annotation types. CALICO Journal, 20(1), 33–58. https:// doi.org/10.1558/cj.v20i1.33-58   
Zwaan, R. A., Madden, C. J., Yaxley, R. H., & Aveyard, M. E. (2004). Moving words: Dynamic representations in language comprehension. Cognitive Science, 28(4), 611– 619. https://doi.org/10.1016/j.cogsci.2004.03.004

Appendix A. The 15 target French vocabulary words with English translations   

<html><body><table><tr><td>Picture number</td><td>Annotation number</td><td>Target word</td><td>English translation</td></tr><tr><td rowspan="5">picture 1</td><td>1</td><td> pancarte</td><td>sign</td></tr><tr><td>2</td><td> grillage</td><td>bars</td></tr><tr><td>3</td><td>buisson</td><td>bush</td></tr><tr><td>4</td><td>egout</td><td>sewage</td></tr><tr><td>5</td><td>pupitre</td><td>menu stand</td></tr><tr><td rowspan="5">picture 2</td><td>1</td><td>nappe</td><td>tablecloth</td></tr><tr><td>2</td><td>poutre</td><td>beam</td></tr><tr><td>3</td><td>lustre</td><td>chandelier</td></tr><tr><td>4</td><td> paillasson</td><td> door mat</td></tr><tr><td>5</td><td>carrelage</td><td>tiles</td></tr><tr><td rowspan="5">picture 3</td><td>1</td><td>cadran</td><td>speedometer</td></tr><tr><td>2</td><td>retroviseur</td><td>rear-view mirror</td></tr><tr><td>3</td><td>volant</td><td>steering wheel</td></tr><tr><td>4</td><td>casque</td><td>helmet</td></tr><tr><td>5</td><td>pneu</td><td>tire</td></tr></table></body></html>

Appendix B. Screenshot of one productive posttest item. Students saw the L1 word ‘sign’ and the screenshot of the picture representing it. The task was to type the translation of the target word in the provided space

![](img/c6156ea5916cb3f3da5fbb51c42926344d3b65fe9b0516d9bd84717557a6a382.jpg)

Appendix C. Screenshot of one of the items of the receptive posttest. Students saw the picture representing one of the target words. They were to choose the correct translation from the given options

![](img/df3c4b2043d0ce11fae4909036cf93aa275241231b2b5ee9ec4f99b6601d371f.jpg)

What's the French word for the numbered object in the picture? \*