# ChatGPT, the perfect virtual teaching assistant? Ideological bias in learner-chatbot interactions

Margo Van Poucke1,

:hool of Education, Faculty of Arts, Macquarie University, North Ryde, Sydney, Australi.

# ARTICLEINFO

# ABSTRACT

Keywords:   
Appraisal theory   
Systemic functional linguistics   
ChatGPT, Human-chatbot interaction   
Interpersonal metaphors   
Ethical considerations   
Bias   
AI learning tools   
Education

This paper examines ChatGPT's use of evaluative language and engagement strategies while addressing information-seeking queries. It assesses the chatbot's role as a virtual teaching assistant (VTA) across various educational settings. By employing Appraisal theory, the analysis contrasts responses generated by ChatGPT and those added by humans, focusing on the interactants' attitude, deployment of interpersonal metaphors and evaluations of entities, revealing their views on Australian cultural practice. Two datasets were analysed: the first sample (15,909 words) was retrieved from the subreddit r/AskAnAustralian and the second (10,696 words) was obtained by prompting ChatGPT with the same questions. The findings show that, while human experts mainly opt for subjective explicit formulations to express personal viewpoints, the chatbot's preference goes out to incongruent it is'-constructions to share pre-programmed perspectives, which may reflect ideological bias. Even though ChatGPT displays promising sociocommunicative capabilities (SCs), its lack of contextual awareness, required to function crossculturally as a VTA, may lead to considerable ethical issues. The study's novel contribution lies in the in-depth investigation of how the chatbot's SCs and lexicogrammatical selections may impact its role as a VTA, highlighting the need to develop students' critical digital literacy skills while using AI learning tools.

# 1. Introduction

This study outlines some of the ethical challenges associated with the increasing integration of Al-enhanced tools in global educational systems, focusing on Open AI's (2022) Chat Generative Pretrained Transformer (ChatGPT). It investigates the chatbot's possible integration as a virtual teaching asstant (VTA) in educational practice and examines its use of evaluative language and engagement strategies whil interacting with users. Grounded in Appraisal theory and Systemic Functional Linguistics (SFL), the paper seeks to make a contribution to the growing body of knowledge on the application of AI tools in education by shedding light on how some of ChatGP's linguistic choices diffr from those made by humans while exploring the impact of the chatbot's attitude and engagement moves on its functioning and apropriateness as a VTA within an educational context, particularly in responding to questions asked by a heterogeneous group of learners.

Technology-enhanced learning is generally considered a valuable tol to engage students and improve learning outcomes (Bower, 2019). Base on a large language model LLM), ChatGT offers unique learning oportunities, thanks to its human-like characteristics, such as theability to engage in meaningful, real-time converations with students through written or voice user interfaces, powered by artificial intelignce (Al). By combining natural language processing (NLP), pattern recognitin, and machine lening, LMs are able to comprehend user input, generate relevant and coherent responses to user queries, and continue to evolve in terms of performance (Kasneci et al., 2023).

The release of the GPr-3.5 model caused quite a stir in the field of education, with educators mostly expressing concerns arising from its generative capacity (Cotton, Cotton & Shipway, 2023; Perkins, 2023). ChatGPT has been programmed using Natural Language Processing (NLP) and multiple predominantly English-language sources, icluding Common Crawl, which includes 410 billion tokens, WebText2, Wikipedia, and various books available in the public domain (Brown et al., 2020). PERsONA-CHAT and several other corpora were used as well, in an attempt to make the chatbot's interactions more human-like (Zhang et al., 2018). By leveraging this collective pool of shared knowledge and employing deep learning techniques, ChatGPT is able to recognise patterns and generate relatively accurate predictions for relevant responses to learner queries or prompts (Open AI, 2023a). The chatbot's release sparked contemplation on the positive impact of AI on teaching practices, especially in a virtual or blended learning environment (Choi, Hickman, Monahan & Schwarcz, 2023; Eysenbach, 2023; Frieder et al., 2023; Geering et l., 2023; Hargreaves, 2023; Kung et al., 2023). Several other AI model, such as Khanmigo (Khan, 2023), Duolingo Max (Duolingo, 2023), MathGPT (Scarlatos & Lan, 2023), or EduChat (Dinh & Tran, 2023) have since been proposed as VTAs, using LLMs to respond to requests for information while interacting with users. The main purpose of AI tools i to accommodate learners' needs by producing relevant answers to prompts, sharing examples and providing suggestions to subsequently apply the conveyed knowledge (Ouyang et al. 2022), as reflected in OpenAI's (2023) slogan: \*ChatGPr. Get instant answers, find creative inspiration, learn something new." Since this type of interaction strongly resembles teacher-student conversations, i has led to highly optimistic depictions of the chatbot as a thought parner (Extance, 2023), friend or guide (Chatteree & Dethlefs, 2023), vrtual leang parter (Ali hamsan, Hezam, & Mohamed, 2023), or virtual teaching assistant (Le, 2023). Converely, ChatGPT has aso been decribed as a double-edged word (Hisan & Amri, 2023) or a devil disgused as a guardian angel (Tlili et al., 2023).

Nevertheless some of the most prominent ethical concerns linked to ChatGPT's use as a VTA, such as its impact on culturally and linguistically diverse (CALD) students, for example, remain relatively unexplored (Kasneci e a., 2023; Lund et al., 2023; Qadir, 2023; Rayne, 2023; Vargas-Murill, Pari-Bedoya, & Guevara-Soto, 2023), despite concerns expressed by Chen et al. (2023) and others who have argued for the need to explore ethical issues assciated with Al aplications in education. The present study specifically aims to address the limited research investigating learner-chatbot interactions from a linguistic perspective, while critically analysing how ChatGPT engages with learners on the topic of Australian cultural habits. It contrasts the use of atitudinal resources and incongruent grammatical constructions by human 'experts and the chatbot in engagement moves and describes some of the implicit ideological perspectives embedded in the LLM's discourse.

As a dynamic social networking service (Ns) consisting of heterogeneous specialised communities, rferred to as subreddits Reddit llows users to find answers to a wide range of queries and encourages collaborative learning through a constant exchange of knowledge and information (Haythornthwaite et al., 2018). On SNSs, interpersonal metaphors of modality (IMs) are continuously employed by individuals to express personal views on various topics of interest, combining subjective explicit constructions (I think) and projection (Halliday & Matthiessen, 2004):

(1) I think you need to stop blaming kids.

Even though chatbots do not constitute animate beings equipped with subjective viewpoints, covert intentions or inherent power, their discourse still reveals the use of IMs under the form of objective explicit constructions (it is' $^ +$ modal adjective $^ +$ projection):

(2) It is possible that the payment was a mistake or a result of an overpayment.

These and other incongruent 'it is-formulations (it is' $^ +$ evaluative adjective $^ +$ projection) involving assessments of human behaviour, appear to be highly common in ChatGPT's discourse:

(3) Kangaroos are wild animals and it is illegal to capture, keep, or ride them.

The statements often concern proposals, such as advice, suggestions or indirect commands, presenting a subjective stance towards what is (not) to be done' ideationally, as common sense knowledge (Halliday & Matthiessen, 2004, p. 625).

ChatGPT's programming and mode of operating inevitably impact its communicative behaviour, which, in turn, may influence human thought and behaviour (Tlil t al., 2023). In order to create more inclusive, ethical and contextually aware VTAs that would be capable of interacting with students in an appropriat and constructive manner, it is useful to explore how the chatbot deploys it is-constructions in its responses to 70 learner queries and to examine its stance towards the information presented in the projected clauses of metaphorical constructions. This type of investigation may lead to deeper insight into ethical issues such as biased chatbot responses due to ingrained stereotypes in the training data of AI tools (Caliskan et al., 2017; Chan & Hu, 2023; Harr, 2023; Katznelson & Gerke, 2021) and, ideally, result in more inclusive applications. Upon being asked to select the most important isue withAI, $1 3 ~ \%$ students at a university in Japan mentioned ethical issues, after unemployment (Ghotbi, Ho & Mantello, 2022).

By contrasting two discourse samples, produced by highly distinct entities, the subsequent appraisal analysis compares the chat. bot's and humans' communicative behaviour while seeking to address the following specific research questions:

w is ChatGPT currently being employed as a VTA in educational settings?

2. What are the chatbot's functional afordances and socio-communicatie capabilities (SCs), and which ethical issues may arise from its use as an AI learning tool or VTA, especially in culturally and linguistically diverse educational settings? 3. In what ways do ChatGPT and 'experts on Redit differ in their use of evaluative language and grammatical metaphors as engagement strategies when responding to the same set of questions regarding Australian culture? 4. Which type(s) of bias does the linguistic evidence reveal and might this impact the use of ChatGPT as a VTA?

Hence, this paper has a dual focus. It contemplates some of the ethical dimensions involved in ChatGPT's role as a VTA in complex learning environments and linguistically analyses the chatbot's use of it is'-constructions, in comparison with Redditors lex. icogrammatical choices, as human sources of information. The rest of the paper is organised as follows. Section two reviews various recent studies on the incorporation of ChatGPT into blended or e-learning environments and posible adverse ethical consequences resulting from doing so to contextualise the study. Section three describes the adopted theoretical framework. Section four explains the research method. Sction five presents the main anlytcal inding. Section six discsses possible thical isues rlated to students use of generative Al, as identified in the appraisal analysis, and offers some recommendations to prevent undesired effects of chatbots. Finally, section seven concludes the paper.

# 2. Educational applications of ChatGPT and associated ethical issues

Following the publication of the free research view, ChatGPT was hailed as an ideal educator, with numerous ideas on how to put this into practice, such as IntructGPT (Ouyang et al., 2022). Since then, there has been an increasing amount of research looking into the possible roles and functions of generative AI tools in various educational contexts, with the vast majority of scholars taking a cautious, balanced approach to their interation in teaching and learning practice.Inthe literature, ChatGPT is commonly referred to as a versatile eucatr, fulflling role such as content prodcer (Ivnov & Soliman, 2023), infomation retriever (Lee, 2023), teaching assistant (Chen et al., 2023) or self-study tool (Nisar & Aslam, 2023). The first two chatbot functions appear more content-focused, while the latter two highlight ChatGPT's use as a conversational agent. Despite some overlap between these roles, all the afore. mentioned descriptions seem to be encapsulated within ChatGPT's use as VTA in educational setings. However, this specific type of application raises ethical concerns, especially in the context of CALD student populations, which tend tobe highly prevalent in the current educational era.

# 2.1. ChatGPT as a writing tool

In most studies, the apparent advantages and disadvantages of ChatGPT as a writing aid take centre stage. The chatbot's benefits in this area include assting students with routine tasks, such as translation (Oberer & Erkollar, 2023) or summarisation (Cotton, Cotton & Shipway, 2023), as wel as aiding teachers in drafting leson plans or creating assinment tass (Ivanov & Soliman, 2023). ChatGPT (GPT-4) also has text-based image generating capabilities (Open AI, 2021), which Bender (2023) put to the est by encouraging media students to experiment with the DALLE 2version. According to Bender (2023), AI content creators should be seen s creative toos that may contributeto cultural diversty. Fauzi e al. (2023) agree with this perspective and sugest that ChatGPT can aid CALD students in developing and honing their writing skill. Ivanov and Soliman (2023) even argue that researchers should be allowed to submit largely AI-generated publications to academic journals. According to Kung et al. (2023), ChatGPT could help compose appeal ltters or summarise medical findings i the future and Hisan and Amri (2023) praise the generative AI to0's unique abilitiesto explain complex concepts in an accessible manner and to produce useful rearch summaries. Similarly, during a study that took place over a two-week period, Oberer and Erkolla (2023) observed and documented the use of the chatbot by 11 language teachers and found that, as a content generator, ChatGPT can help students become active investigators. However, they also discovered that any queries performed in languages other than English proved problematic due to the predominantly English-language database.

The chatbot's ability to generate coherent, human-like discourse when prompted generally appears to be viewed as both abenefit and a disadvantage, with educational scholars acknowledging its generative abilities and its potential to reduce inequalit, while, at the same time, expressing concerns about it negative impact on academic integrity, especially among CALD users and students with low socioeconomic backgrounds (Bishop, 2023; Ibrahim et al., 2023; Perkins, 2023; Sullivan, Kell, & McLaughlan, 2023). To remedy the ethical issue of plagiarism, Skavronskaya, Hadinejad, and Coterell (2023) recommend selecting highly specific, relevant themes, using real-world learning, demanding students' disclosure of any Al writing aid and explicit training on appropriate use of ChatGPT.

# 2.2. ChatGPT as an informative and assessment tool

Other frequently discussed roles of the chatbot involve its ability to answer questions and provide explanations r examples and its feedback and assessment capabilities, evaluating individual students input, which may be helpful in a culturally diverse classroom (Mizumoto & Eguchi, 2023). When Choi, Hickman, Monahan and Schwarcz (2023) made ChatGPT participate in several legal studies exams, prompting it to respond to a total of 95 multiple choice and 12 esay questions, the chatbot's responses earned it a low passing grade in al four courses, which was demed a positive result. As a dyadic process the typical learner-chatbot interaction with leaners prompting the tol to respond to simple or more complex queries may result in satisfactory answers, the production of inaccurate replies or lead to refusals to respond due to inappropriate questions or requests for personal views or follow-up demands from the chatbot for further clarification.

The most prominent ethical concerns tied to ChatGPT's role as an information retriever seem to revolve around the dissemination of misinformation (Mogavi et al., 2023), rooted within the chatbot's training data and biased responses. Or, as Taylor and Taylor (2021) put it, the parameters represent truth in a training data set, rather than truth in the world. Teachers may constitute a culturall diverse group themselves. To gauge educators attitude towards the use of ChatGPT as a VTA, Kiryakova and Angelova (2023) conducted a survey at university in Bulgaria, which revealed relatively positive views among staff members, who recognised the chatbot's value as a feedback and asessment tool and it power to enhance student engagement, but expressed important concerns about students blindingly trusting the chatbot. Whil evaluating the ChatGPT's use in multiple educational contexts, Amin (2023) mentions that AI-generated content ought to be relevant to the students nees and culturally sensitive. To avoid the perpetuation of stereotype, techrs ned to explicitly addess such ses t promot insiity in the clsoom, acordg tohis athr. ll, as signalled by Barocas and Selbst (2016), alorithms and, by extension, ChatGPT's discourse itelf may reflect various forms of hidden racial or other prejudice. Conversely, in Barrot's (2023) view, ChatGPT's application as an asessment tool can \*support fair and equitable writing asessment by providing consistent feedback on students' writing, freefrom predetermined assumptions that a teacher may have about them' (p. 5), in particular bias towards work submitted by CALD students. It seems that, despite current optimistic trends regarding the use of AI tool in education, ChatGPT may ultimately prove to be a virtual wolf in sheep's clothing.

# 2.2. ChatGPT as a self-study tool

In contrast with earlier AI tools, such as ELIZA from the 1960s (Ericson, 2023), Jabberwacky, also known as Cleverbot, a chat. terbot launched by Carpenter in 1997 (Dey, 2019) or SmarterChild (Silberling, 2023) in the early 2000s, ChatGPT's unique compe. tence lies in its abilit to analyse human interlocutors' intent and the content structure of their prompts employing LMs and deep learning techniques. The chatbot is able to analyse sentence structure, interpret meanings and - to a certain extent - understand the context in which the discourse isbeing uttered,allowing it to engage in more natural and dynamic conversations. As such, GPT-3 and GPT-4 seem to hold great promise as interactive tools for personalised study in diverse smart learning environments, answering students' questions, offring simplified explanations and aiding in various decision-making proceses (Kung et al, 2023), facilitating collaboration ingroup setings (Rawas, 2023) and providing individualised fedback (Rahman & Watanobe, 2023). So far, this type of personalised interactional learning appears to have garnered the largest interest in the area of second language acquisition (Hong, 2023; Huang, Hew & Fryer, 2022; Javaid et al., 2023; Kohnke, Moorhouse & Zou, 2023). For example, Topsakal and Topsakal (2022) used ChatGPT's generative capabilitie to produce simple dialogues on familiar topic to help students master a new language, while Yan (2023) allowed the chatbot to asst students with second-language writing. After investigating the LLM's impact on a group of students larning English, Ali, Shamsan, Hezam and Mohammed (2023) confirmed Fauzi et al's (2023) view that ChatGPT's interactivity may increase students' motivation levels. However, as Larsson and Ericksson (2023) discovered in their investigation of the chatbot as a self-study tool, \*even though ChatGPT is supposed to be neutral, it was still biased' (p. 21).

Another domain of personalised application is medical education (Gandhi Periaysamy, Satapathy, Neyaz & Padhi, 2023; Kung et a. 2023). Le (2023) successully used ChatGPT to create medical simulations ofvarious medical scenario, for example, and, when asking the chatbot a series of questions with regard to the indications, mechanisms ofaction, adverse efects and contraindications of various medications, Nisar and Aslam (2023) found that it was able to provide relevant, accurate answers. Nevertheles, Choi (2023) concluded that ChatGPT did not meet expectations as a self-study tool due to the sheer randomnes of its responses, which proved particularly problematic when answering factual questions, often leading to plausible yet incorrect answers.

A third study area, lending itself well t self-education, appears to be software engineering (Shoufan, 2023; Wieser et al., 2023; Qadir, 2023). For example, Farah et al. (2023) created Graasp, an educational chatbot for software engineering students, which was wellrceived. Rahman and Watanobe (2023), in their turn, investigated how ChatGPT could aid students with mastering programming skills through various experiments with code and pseudocode generation from problem descriptions and code correction. They discovered that the chatbot tends to be good at both providing the code and explaining the whole proces, making it a useful tool for programming education. However, the authors also pointed to major issues such as plagiarism, over-reliance and potentially compromised personal data.

ChatGPT has further been introduced as a personalised learning tol in business tourism, law and management courses (AlAfnan, Dishari, Jovic & Lomidze, 2023; Lim et al., 2023). For example, in an attempt to implement inclusive learning, Chen et al. (2023) interviewed more than 200 students and created a VTA called Sammy' to teach basic AI concepts to 195 students. The authors praise the chatbot's numerous qualitie, such as is responsivenes, interactivity and confidentiality. However, their study also demonstrates ChatGPT's inability to engage in authentic conversations and is apparent lack of emotion. Rudolph, Tan and Tan's (2023) hope that AI tools will soon be \*capable of rcording and interpreting the characteristics of students and their emotional state in every aspect of their learning in real-time, resulting in personalised adaptive learning (PAL) (p. 350), echoing Peng, Ma and Specter's (2019) technology-empowered pedagogy, raises the question whether ChatGPT, i is preent form, is truly capable of expressing emotion and understanding learner sentiment.

In sum, multiple ethical concerns may arise from the chatbot's use as a VTA, such as it tendency to inadvertently maintain biases and several equity isues. When communicating with users in their first language, for example, ChatGPT appears to align with the Anglocentric cultural values contained within is training datasets, reinforcing cognitive prejudices, due to the black box nature of its algorithms and the resulting echo chamber efects (Havaldar et al., 2023). Based on the results of a sw0T analysis, Farrokhnia, Banihashem, Noroozi and Wals (2023) posit that ChatGPT's abilit to facilitate personalised learning is indeed greatly diminished by risks of bias and discrimination. Open AI (2023b) openly acknowledges this particular weakness and urges educators to \*critically assess any content that could teach or reinforce biases or stereotypes." Ivanov and Umbrello (2021) further describe the issue as follows: \*Some demographic groups in terms of ex, race, religion, education, financial status, etc., may be significantly over- or underrepretd in the traning datset (p. 11). Lim et l. (2023) addo this that, desite ffering a semblance fr universalacces to knowledge, equity may be further compromised due to some individuals' lack of access to the tool. Only a small number of educational studie touched upon other isues, such as concerns related to privacy and data protection (Rawas, 2023), the chatbot's negative environmental impact (Cooper, 2023) and possble misuse by students (Jeon & Le, 2023), further underlining the urgency to address important ethical and other isues, such as the lack of human interaction when replacing teachers with chatbots altogether (Adiguzel, Kaya & Cansu, 2023).

# 3. Theoretical framework

# 3.1. Functional affordances and socio-communicative capabilities (SCs)

Bower (2019) emphasises that \*in a technology-enhanced learning context, technologies in and of themselves have no intentions, but rather are featured objects used to convey meaning betwen participants" (p. 1037). The terms technology-enhanced and 'technology-mediated' are often used interchangeably, even though there is a difference in meaning depending on whether the technology asists or fully replaces the role of the instructor. In the former case, digital tols such as software packages, websites or other educational services can facilitate the teaching process, enhance student engagement and improve comprehension. Technology-mediated or asynchronous earning, on the other hand, involves the transfer of typical classroom activitie, such as discussions, to a more immersive virtual environment, which includes learning management systems (LMss. ChatGPT can fulfil both the role of a technology-ehancing and technology-mediating tol, with the later function increasing it agency as an unsupervised virtual learning facilitator.

Originally coined by Gibson (1979), the term affordance designates the utility of technologies based on their technical and other   
Table 1 ChatGPT's functional affordances and SCs.   

<html><body><table><tr><td>Functional affordances</td><td>Description</td><td>Socio-communicative capabilities (SCs)</td><td>Ethical concerns</td><td>Other issues</td></tr><tr><td> Reliability</td><td>Ability to instantly share large amounts of information</td><td>Information sharing (Mogavi et al., 2023)</td><td>Misinformation Bias Cultural insensitivity Lack of transparency</td><td>Irrelevance and incompleteness of information Lack of contextual</td></tr><tr><td>Temporal affordances</td><td>Unlimited availability and flexibility</td><td>Provision of immediate feedback ( Rasul et al., 2023)</td><td>Impact on cognitive skills One-size-fits-all approach</td><td>Adaptibility Unrealistic learner and teacher expectations</td></tr><tr><td>Media affordances</td><td>Ability to engage in human-like dialogue, multimodality</td><td>Learner engagement enhancement (Bender, 2023)</td><td>Emotional impact Inaproppriate images Cultural misrepresentation Inaccessibility Distracting content</td><td>Inability to create charts or diagrams Technical issues</td></tr><tr><td>Access-control affordances</td><td>Capacity to access anywhere</td><td>Individual learner development ( Nisar &amp; Aslam, 2023)</td><td>Copyright issues Plagiarism Equity issues Privacy and data protection issues</td><td>Over-reliance</td></tr><tr><td>Emphasis affordances</td><td>Adaptive learning highlighting areas for improvement</td><td>Assessment (Kiryakova &amp; Angelova, 2023)</td><td>Bias and errors of judgement Lack of comprehensive assessment</td><td>Technical issues Lack of contextual awareness</td></tr><tr><td>Synthesis affordances Aesthetics</td><td>Integration with social networking tools User-friendly interface</td><td>Online collaboration (Cotton, Cotton &amp; Shipway, 2023) Individual use (Rudolph, Tan &amp;</td><td>Privacy and data protection Distraction Impact on social skills</td><td>Technical issues Accessibility Cognitive or emotional</td></tr><tr><td>Linguistic affordances</td><td>Natural language processing (NLP): ability to process natural language</td><td>Effective communication (AlAfnan, Dishari, Jovic &amp; Lomidze, 2023)</td><td>Culturally insensitive design Impact on accessibility Misinterpretation of humour, sarcasm or emotions Inappropriate responses Misinterpretation of learner intent</td><td>overload Irrelevant or unclear responses Translation errors</td></tr><tr><td>Scale</td><td>Capacity to interact with high</td><td>Educator support (Chan &amp; Hu,</td><td>Misinformation Bias Privacy and data concerns Accessibility issues Lack of teacher input/ feedback Monitoring issues</td><td>Manageability issues</td></tr></table></body></html>

properties, arguing that \*an affordance is neither an objective property nor a subjective property" and that it \*cuts acros the dichotomy of subjective-objective and helps us to understand its inadequacy' (p. 121). Norman's (1988) view of the notion, might be more relevant to examine ChatGPT's affordances, however, not in terms of the chatbot's action possibilite, but by discussing how some of it capabilities may be perceived by educators or learners interacting with the AI tool in an educational context. Taking the notion further, McGrenere and Ho (2000) remark that a wide range of social and cultural factors, such as users' experiences and cultural background, are involved in shaping affordance. Subsequently, the concept of affordance is helpful to explore how ChatGPT enables interactions in a virtual learning environment, considering some of its functional capabilities and SCs.

At the same time, however, an investigation of the Al tol's ability to dialogicall interact with leaners and some of the possible benefits and challenges that come with its role as a VTA nees to move beyond the fied notion of ffordances. A mere description of ChatGPT's perceived functions is not sufficient and has to be complemented with an in-depth discussion regarding the socio-pragmatic effect of the learner-chatbot interactions, such as disempowerment or other unintended consequences, as well as possible hidden ideological orientations. As dialogical exchanges involving the actions of prompting and responding, the virtual learner-chatbot dialogue may "pave the ground for social dominance ("power) or subordination in and through interaction" (inel, 2017 p. 305). Subsequently, the category of SCs is more relevant when describing the chatbots abilit to discursively engage with the putative human learner. An overview of ChatGPT's SCs can be found below in Table 1.

# 3.2. ChatGPT's capabilities as a VTA

One of the LL's functional affordances constutes its reliability and ablity to continuously proces and generate large amounts of information, enabling its SC of knowledge sharing (see Table 1), which can sometimes result in the dissemination of inaccurate or incomplete information (Mogavi, 2023). ChatGPT's other SCs include the provision of immediate feedback (Rasul et a., 2023), learner engagement enhancement (Lee, 2023), individual learner development (Peng, Ma & Spector, 2019), asessment (Kiryakova & Angelova, 2023), colaboration (Cotton, Cotton & Shipway, 2023), potential for individual use (Nisar & Aslam, 2023), effective communication (AlAfnan, Dishari, Jovic & Lomidze, 2023) and educator support (Cooper, 2023), which are aforded by the chatbot's temporal, media, acess-control, emphasis, synthesis, linguistic and scale affordances and aesthetic properties, based on Bower's (2008) categorisation of affordances (se Table 1). All of these apparent advantages in terms of usaility may create multiple challenges, as acknowledged in the emergent research on ChatGPT as a VTA or AI learning and teaching tol. For example, students may overestimate the chatbot's capabilities, resulting in the problem of over-reliance (Chan & Hu, 2023). Some apprehensions about student idleness or lack of intellectual development have been expresed as well (Eysenbach, 2023). Even though the chatbot can enable adaptive larning by highlighting areas for improvement, it may occasionally make judgement erors regarding what constitutes an eror, and, as mentioned earlier,criticisms have further bn voiced regarding ethics (Ray, 2023). Integrating ChatGPT with other social networking tools such as discussion forums, may appear to be an ideal way to encourage collaboration among students. However, as with other e-learning technologies, such as Zoom platforms, technical isues can complicate the practical aspects of this process. When it comes to individual use similar ssues may aris, such as a feared decline in students' cognitie skills development (Farrokhnia, Banihashem, Noroozi, & Wals, 2023).

SCs that are particularly releant in a linguistic context, since they focus on communication, pertain to ChatGPT's ability to process natural language input and engage in human-like conversation, enabling efective interaction with learners and adopting a supportive role in their educational development as a VTA, responding to questions. Regrettably, these SCs may be hindered by the possibilit of irrelevant or inappropriate responses, mainly due to the chatbot's lack of contextual awarenes. Learners prompts are also often misinterpreted, with the more specific problems of inaccurately understanding pragmatic intent and framing bias.Finall, the chatbot's ability to simultaneously interact with a large number of students can create considerable manageability ssues for educators supervising its appropriate use on LMSs.

# 3.3. Cogito, ergo sum

The present study adopts an appraisal approach to the analysis of human-chatbot interactions, based on interactional dialogism (Bakhtin & Holquist, 1981) and SFL (Halliday & Matthiessen, 2004), not only providing further insight into how ChatGPT is able to convey adequate and appropriate information in response to student queries, but also describing how the chatbot could unintentionally align learners with implici biased or subjective perspectives. Halliday (2007) describes discursie acts as instantiations that originate from within a shared ideological system and continuously permeate individual meaning-making acts. In essence, such lexicogrammatical realisations are imbued with beliefs, values, power dynamics and cultural norms and, thus, function as the 'engine room' of language (Lukin, 2018, p. 18). These underlying ideologies may be projected onto others through the deployment of interpersonal metaphors, of which I think' is probably one of the most common examples (Hallday & Matthiessen, 2004).

Metaphors can be experiential (Hery VII's quest for fame'), logical (Henry VIII's quest for fame resulted in financial ruin) or interpersonal (1 know that Barbie dolls are not feminist). Halliday and Matthiessen (2004) differentiate between interpersonal metaphors of mood, such as acommand presented as a question (Would you come and sit down?) and modality, such as a command formulated as an obligation (It is required to purchase a license'). Martin (2020, p. 9) defines interpersonal metaphor as "an inter-stratal relation in which lexicogrammar indirectly realises discourse semantics - by symbolising it rather than encoding it directly." Modals can be used to express subjective o objective asessment and may have an explicit or implicit orientation, depending on whether the modal aessment i grounded in the speaker or writer's subjectivit or not see Appendix 2) (Halliday & Matthiessen, 2004; Martin & White, 2005, pp. 130-131). The constructions can have a low (I suppose), median (I think') or high (1 know) value.

Subjective explicit or objective explicit it is-formulations are considered metaphorical in sFL (Halliday & Matthiessen, 2004)

Interpersonal modality either involves the writer's stance regarding the validity of the projected claim or the moral principles that guide this evaluation (Halliday & Matthessen, 2004). Or, as Hyland and Tse, 2005 put i, \*attitudinal stance indicates the writer's affective atitude towards the proposition or a perception of obligation and what he or she believes should be done", while \*eistemic stance, on the other hand, indicates the writer's asesment of the likely truth or accuracy of the proposition (p. 46). The distinction between subjectivity and objectivity hinges upon writer or speaker involvement (Halliday & Matthiessen, 2004). Since LMs do not have the same cognitie and emotive capabilitie as humans and are incapable of expressing any subjective viewpoints, ChatGPT only uses objective modality (Byrd et al., 2023). Lyons (1995) refers to subjectivity as \*the property (or set of properties of being either a subject of consciousnes (ie. of cognition, eeling, and perction) or a subject f action (agent) (p. 37), which entais that A is both incapable of experiencing reality subjectively and acting upon this awareness.

Appraisal is concerned with intersubjectivity or the negotiation of interpersonal meanings between two or more entities and. according to Halliday and Matthiessen (2004), projection is often used to create social distance allowing a write to distance themselves from an assertion to signal subjectivity to the reader. Interpersonal metaphors may express the author'scertainty about the likelihood of an event, showcase factual knowledge, communicate what seems obligatory, permitted or prohibited, and, ultimately, construe new shared knowledge (Halliday & Matthiessen, 2004). Possible effcts of IMs include persuasion, the exertion of power, influencing thought, inviting refection or discussin, collctive agreement, establishing crediility or showing deference. Subse quently, an exploration of salient incongruent modality paterns in ChatGPT's lexicogrammatical selections whil interacting with learners may uncover some of the underlying ideologies that underpin the information it conveys.

Seen that, in a Hallidayan view, ideology tends to inform individual linguistc acts, the dialogical interaction that occurs between ChatGPT and the utative learner does not take place in a vacuum t is aplurilogue with a multiplicity of other voices contained within its training data, referred to in Appraialthery as hetroglossi (Bakhti & Holquist, 1981), perspectives that often remain implicit in ChatGPT's case due to the omission of specific information sources. Martin and White (2005) borrowed the Bakhtinian notion of heteroglossi to distinguish between monoglossic and heteroglossic utterances. Monoglossi assertions do not include any contractive or expansive use of engagement resources. They present taken-for-granted knowledge and are dialogically inactive, whereas heter. oglossic uttrances do interact with other voices (Bakhtin & Holquist, 1981). Deontic formulations imit the exchange of other viewpoints, whereas epistemic constructions may be used by interlocutors to expand or contract the dialogic space (see Fig. 1). Hence, grammatical metaphors need to be linked to their specific use within context. Verstraete (2001) refers to this analytical angle as "a semiotic persective which relaes the grammatical behavior of the catgories to the functions they fulfil (p. 1506). Ideall, IMs are analysed at the sentence level or beyond, taking into account any accompanying constructions (Poldvere, Fuoli & Paradis, 2016; Hunston, 2006) since they are being deployed \*in an intertextual and heteroglossc context where they enter into relationships of greater or lesser tension with more or less divergent utterances" (White et al., 1999, p. 73).

Among some of the heteroglossc factors influencing the expansive or contractive use of IMs in dialogical interactions are the interlocutors' intent, power relations, social status, underlying ideological divergences or the presence of disagreement or disalign ment (White, 2006). Concrete indicators in the discourse may consist of other expanding or contracting devices, the use of positive or negative affct or lexemes, semantic prosody, but also hand gestures or type of mode. The rhetorical effects of a predominantly contractive or expansive employment of engagement resources depend both on the immediate situation and wider social, cultural and historical contexs. White (2003) understands this concrete usage as \*the degreeto which an utterance, by dint of one or more of these wordings, entertains dialogically alternatie positions and voice (dialogic expansion), or altenatively, acts to challenge, fend off or restrict the cope f such (dialogic contraction) (p. 262). Depending on the subtle pragmatic efects of the utterance within its textual context and, by extension, whether the emphasis is on the discursive exchange of ideational or interpersonal meanings, respondents may employ IMs in a more expansive or contractive manner. When the author expreses ow certainty regarding the state of afairs () doubt' $^ +$ COMP), the construction may be associated with the experiential function of language and used in a more expansive way. Conversely, when the subject expresses high certainty (I know' $^ +$ COMP), they usually convey a highly personal viewpoint or judgement, which carries a strong evaluative component, rendering its use more contractive (see Fig. 1). It is also possble for statements to be neutral, although this is rarely the case.

![](img/960afd017f8f700ea167f8c8e9c27ee1e182825607cbb9d368b0ec35204fa97d.jpg)  
Fig. 1. Contractive or expansive use of engagement resources.

![](img/526f06c17860b60c355232cffac7f03f5b11c498133596e6111a073c6524c787.jpg)  
Fig. 2. The appraisal framework (Martin & White, 2005).

# 4. Research method

# 4.1. Discourse samples and appraisal analysis

The data for the study consis of two corpora (see Appendix 1). The first dataset includes human-writte responses (15,929 words) to a total of 70 questions, posted by Reddit users on the subreddit of r/AskAnAustralian between 22-26 April 2023,eliciting mostly practical information regarding Australian cultural practice (see Appendix 3). The data were extracted from the SNS using Python and the Reddit API. Apart from the addition of in Australia to some rather vague questions (Do you really eat Vegemite?), no prompts, other than the questions, were added to elicit the ChatGPT-generated answers, to avoid any framing effects. The second discourse sample was generated by ChatGPT in response to the same set of questions (10,696 words) on 26 May 2023.

This allowed for a contrastive analysis based on the Engagement system within Martin and White's (2005) apraisal model. including additional subtypes, such as surpris, added by Bednarek (2008). Within the appraisal framework, the systems of Attitude and Engagement are particularly relevant for analysing how ChatGPT adopts a certain attitude and engages with learners through dialogue (see Fig. 2). The Attitude system includes affect, judgement and appreciation resources, which may be employed by in. teractants to expres their attitude towards a specific topic or other entities, positively or negatively evaluate others and their behaviour or asss various phenomena in terms of their aesthetic or other inherent value. This type of analysis alows for a deeper understanding of the interpersonal dynamics in the dialogical process between the chatbot and the learner and may help uncover underlying values and assumptions. The system of Engagement comprises various resources that may be used by ChatGPT to negotiate meanings with learners, in an attempt to interact with them in an effective manner. Whil doing so, the chatbot may deny a query, counter or concur with i, pronounce or endorse fact, acknowledge sources or distance itelf from them (se Fig. 2). Of course, the same goes for human interlocutors.

To analyse engagement, an adaptable coding framework was developed including the lexicogrammatical realisations of the most commonly employed engagement resources (see Appendix 4). The Reddit users and chatbot responses were added to text files and the two corpora were subsequently uploaded to the open-source text editor Notepad $^ { + + }$ , version 8.5.4. All grammatical categories relevant to Engagement were extracted from the text using POS-tagging (Honnibal et al., 2020). POS-tagging was also used to perform a frequency analys of Attitude fousing on evaluative adjective, adverbs, and the like, to achieve an in-deth appraisal analysis ofthe entities selections of both attitude and engagement resources. The obtained ists were copied to text files and uploaded to Notepad $^ { + + }$ where any duplicates were removed, leaving a more manageable list, alowing for targeted contextualised searches and statistical affect, engagement and graduation analyses acros the two corpora (Van Poucke, 2023a). All calculations were performed in Excel.

The next step in the analytical process involved the interpretation of the respondents overall use of atitudinal and engagement resources and the investigation of dominant patterns in the responses combining attitude, engagement and graduation devices. The use of positive or negative afect and lexis and the impact of contextual factors, such as the presence of supporting appraisal devices, were taken into account as well depending on a more contractive or expansive use f the engagement resource, especially with regard to engagement devices belonging to the pronounce and entertain subtypes (Bednarek, 2009; Poldvere, Fuoli & Paradis, 2016). Subsequently, the analysis zoomed in onto the human and AI respondents' specific use of it is'-constructions, as a subset of the totalit of attitude and engagement resources, adopting the same contextualised approach, facilitated by Notepad $+ +$ which allows for straightorward marking, bookmarking, and the like of data (Van Poucke, 2023a). Depending on co-linguisic conditining, any subjective or objective explicit constructions in the data were classfied as specific subtypes differentiating between their respective contractive or expansive use. Any neutral formulations were added to the entertain category. The analytical findings were visualised and interpreted further, focusing on ChatGPT's SCs as a potential VTA.

# 5. Appraisal analysis

# 5.1. ChatGPT's and Redditors' use of attitudinal and engagement resources

5.1.1. Affect, judgement and appreciation The appraisal analysisof atitudinal meanings expressed in the ChatGPT and Reddit samples demonstrated a sharp difference in terms of the expression of emotion (see Fig. 3). As expected, the human respondents used a larger amount of evaluative language, especially when judging other individuals and their behaviour (30.8 versus 3.02). Both the Reddit users and ChatGPT favoured the selection of positive values (18.85 versus 2.17), which, in the case of the former, may be called unusual, especially on a social media platform such as Reddit, where negative judgement tends to prevail (Van Poucke, 2023b). ChatGPT's emotional repertoire seemed limited and mainly concerned general ocietal wll-eing, in particular quiet (0.46) under the category of security and desire under the label of incination (0.45), revealing asignificant instilled concn aout human safety and prferences. Nerthless the chatots use of affect can have a positive effect on its users, as revealed i a study carried out by Howe, Fay, Saletta and Hovy (2023), whose participants thought that \*the answers given by ChatGPT were more balanced, more complete, more empathetic, more helpful and better than the oficial answers' (p. 3-4). This might make the chatbot useful for assting learners particularly those with CALD backgrounds. The Reddit users, on the other hand, primarily opted for social esteem values, especially positive normality, often praising Australian cultural and social practice.

ChatGPT barely used any atitudinal resources, apart from generic politenes expressions (I am happy tht..). Subsequently, any claims that ChatGPT would be capable of understanding and expressing emotions seem rather elusive, as the expression of empathy would requirea consistent use of subjective explicit interpersonal formulations (e.g. I think) and a large amount of both mediated and unmediated affect, which is not currently the case (see Fig.3). However, the chatbot does seem to be capable of evaluating human behaviour, as evidenced by its preference for positive judgement devices asociated with social sanction values, confirming Kocon et al.'s (2023) finding that ChatGPT "presents the sense of common human morality" (p. 16). The chatbot's use of judgement resources seems to closely align with its programmed objective of endorsing socially deirable human behaviour, thus positioning the learner to take a particular course of action (Martin & White, 2005):

(4) It is not [eng: deny] appropriate or ethical [att neg judg: propr] to provide advice on where to move during times of war or conflict.

The excerpt could be replaced with You should not provide advice on where to move during times of war or conflict, revealing the directive nature of this type of it is-construction as aroposal that is being \*neutralised as fact Halliday & Mathiesen, 2004, p. 629). ChatGPT's incongruent engagement strategy involves upgrading the interpersonal evaluation from group rank to clause rank, resulting in the covert expression of commands, based on what is generally seen as appropriat. Subsequently, interpreting these grammatical metaphors as pronounce resources may highlight their directive nature, especially when they are selected to instruct learners, as will be demonstrated in the next subsection.

![](img/c7341574ea02c01839fad46b1ca1b56790334e46adfd48520f8691d45b8e4210.jpg)  
Fig. 3. Attitudinal analysis.

# 5.1.2. Engagement

ChatGPT's responses contained a total of 65.5 (N/1,000 words) engagement values 6.17 of which were metaphorical, while the Reddit sample counted 82.52 (N/1,000 words) engagement resources, 4.39 of which were incongruent constructions. There was a higher ratio of objective explicit formulations in ChatGPT's discourse than in the humans' replie to the questions (6 vs 0.3), especially IMs involving obligation. The chatbot's communicative repertoire seemed to favour indirect commands or directives, whereas the Redditors preferred to assert strong personal viewpoints through compelling argumentatio. ChatGPT justified is evaluations by linking these to various rules, regulations and other Americentric collctive knowledge contained within its database, which rendered its discourse impersonal, confirming Brown et al's (2020) or Johnson et al.'s (2022) findings. In contrast, the human respondents mainly shared subjective perspectives based on individual beliefs and cultural values.

The Reddit users responses invoked viewpoints adopted by other users, but regularly dismissed the learners previously expressed views using deny resources (not) (see Fig. 4). In contrast, ChatGPT mainly seemed to present the ideological perspectives contained within its database, while also frequently selecting devices to counter its own negative assertions (however'), replace irelevant viewpoints with more relevant ones (while') or present an indirect command or directive (it is important) in its responses. The chatbot also used a higher number of entertain resources (24 vs. 2) and more frequently acknowledged external voices (7 vs. 1) Concrete examples and some further explanation are provided below.

5.2. ChatGPT's and Redditors' use of 'it is'-constructions as engagement strategies

# 5.2.1. Dominant engagement patterns

ChatGPT's preferred discursivestrategy, as observed in its responses to the queries in the sample, involved the contractive use of objective explicit constructions in pronounce moves, conditioned by one or more other contracting resources, negative attitudinal devices and optional down- or up-scaling, to present various ideological perspectives embedded in it database. This was preceded and followed by an expansive engagement move and positive evaluative language. In comparison, the Reddit users mainly employed subjective explicit constructions in engagement moves, often together with contracting devices, and regularly interspersed with positive affect or judgement. They frequently switched to contractive use by adding a counter-expectation and more contracting devices to the sequence to deflect possible objections from other users.

# 5.2.2. ChatGPT's contractive use of 'it is'-constructions

ChatGPT's preferred engagement pattern was consistently initiated by a generic politeness formula (Certainly!) and a brief expression of positive evaluation. In the following opinion-based response to a polar question, ChatGPT first makes an expansive engagement move, positively evaluating appropriate human behaviour and then employs the directive it is important contractively, combining it with other contracting resources of the counter (however'), deny (not'), and pronounce (should') subtypes and additional inscribed negative judgement (not expected, not customary') to expressis stance towards Austrlian tipping practice, which appears to be based on the pre-programmed American view that this is only a requirement in case of exceptional service:

(5) Q: Do y'all tip folks like food servers or Uber drivers in Australia?

![](img/0887a37e5fc8f11f7039b43db9eff90928973cbc8bf6be49644d630d9c7b182c.jpg)  
Fig. 4. Engagement analysis.

A If a customer wishes [at: pos aff incl totip for excetional [at: pos appr: reac] service, they are fee [att pos udg: propr] o do So.. However, [eng: counter] it is important [eng: pron] to note that tpping is not [eng: deny] expected [att neg appr: val] or customary [att: neg appr: val] in Australia, and it should [eng: pron] not [eng: deny] be seen as a requirement or obligation. In Australia, employees are entitled [att: pos judg: propr] to receive a minimum wage.

The objective it is formulation expresses  higher degree of politenes compared to the imperative form do not tip, and seems to be deployed by ChatGPT as an engagement strategy to present subjective views in a more objective or authoriall detached manner, a strategy mentioned by Hllday and Matthiesse (2004). The addition of invoked negative judgement (requirement', obligation') further reinforces the chatbot's directive stance. By making this contractive engagement move, the chatbot underlines the significance of the projected information and positions the learner to accept widely understood American knowledge about giving tips as factual. encouraging corresponding behaviour. In a subsequent expansive move, positive judgement is explicitly denoted through the use of 'entitled' and lexically invoked by the noun phrase 'mininum wage. ChatGPT's tendency to combine authorially inscribed or invoked positive or negative judgement contributes to the likely acceptance of the shared information as trustworthy by the learner, which is probably why Open AI (5 April, 2023) stipulates that learners under the age of 13 require parental approval before using the chatbot.

As shown in the example, ChatGPT instantly provides rlevant information and engages in human-like dialogue, confirming earlier observations by Fauzi et al. (2023) or Gandhi Periaysamy, Satapathy, Neyaz and Padhi (2023). However, even though the chatbot's answer seems appropriate and complete, it lacks clarity by presenting a subjectie view on the cultural practice of tipping as an uncontested fact, while adopting an authoritative tone, which may influence the learner's perceptions of Australian culture and their behaviour, as mentioned by Kiryakova and Angelova (2023).

ChatGPT's lack of contextual awarenes, as demonstrated in example 5, sems to be closely linked to the ethical concern of cultural insensitivity. The chatbot appears to have been programmed to consistently yet politely discourage inappropriate actions and susequently encourage desirable human behaviour, based on predominantly American cultural values, which could be seen as inconsiderate and potentiall offensive to some CALD students. I also deflects the learner's ttention from the human source, which remains subjective and, as such, prone to bias (Hyland and Tse, 2005). As Barocas and Selbst (2016) aptly explain, \*what a model learns depends on the examples to which it has been exposed" (p. 680). Similarly, students learning experiences and perspectives may be influenced by the AI tools to which they are exposed and the accuracy of the information it conveys to them (Lim, 2023). The aforementioned ethical issues of bias and cultural insensitivity arise from ChatGPT's SCs of information sharing and effective communication.

A variation upon this typical ChatGPT pattern involving metaphorical it is'-constructions in the sample started out with a contractive engagement move including several other contracting device, followed by a counter move, before switching to the use of a directive presenting a perceived cultural norm and expressing positie judgement or appreciation, as in this opinion-based response to an information-seeking Wh/Q-question:

(6) Q: How many Tim Tams can you eat in one sitting before death ensues?

A: As an AI language model, I do not eng: deny] have the capability to eat food or experience death. However, [eng: counter] Tim Tams are a delicious [at: pos appr: val] chocolat-covered biscuit from Australia and it's recommended [eng: pron] to consume them in moderation as part of a balanced [att: pos appr: val] diet.

After a brief clarification, ChatGPT employs an incongruent construction as a directive to nudge the learner towards embracing a healthy lfestyle. The chatbot's first engagement move is dialogically contractive, combining a deny resource (not') and invoked negative udgement. Thi is followed by another contracting counter resource (However) in a move combining a ronounce resource (it's recommended) and positive appreciation (delicious, balanced'), unveiling the chatbot's programmed objective of positioning the human addressee to align with the standpoint that, although tempting, consuming a large number of Tim Tams may lead to il health. Through objectification, ChatGPT conveys an urgent yet respectful suggestion to opt for the proposed action. Its use of evaluative adjective allows it t suget how the preented information is to be interpreted by the learner (Hunston & Sinclair, 2000). In the discourse sample, the chatbot's most favoured evaluative adjectives included important' and recommended'. No mitigation (e. 8., it may be recommended), other than the addition of positie or negative appreciation was added to any of the it is-constructions.

ChatGPT does not provide an accurate answer to the query regarding the number of TimTams that may be consumed but, instead. avoids the question by referring to its own incapabilit to consume food or die. The chatbot further presents the subjective view that TimTams are delicious as a fact, whereas it actually involves a stereotypical view that could even be sen as promoting the consumption of unhealthy foods. ChatGPT's supportive role also appears to be hindered by its incorrect understanding of the question. Similarly, Kocon et al. (2023) noticed that, when confronted with humorous content, the chatbot \*not only refuses to answer whether something is or is not funny but also sends a moralizing message with an irrtated tone' (p. 13), which could affect learners emotionally. The ethical concerns of misinterpretation of learner intent, emotional impact and bias are associated with ChatGPT's SCs of effective communication, provision of immediate feedback and information sharing.

# 5.2.3. Reddit users' contractive use of IMs in engagement moves

In contrast, a salient engagement strategy employed by Redditors involved the contractive use of a pronounce resource, with supporting contracting devices and negative judgement, before adding some positive attitude and then switching back to contractive use:

(7) Q: Homeschool or mainstream school?

A: No, [eng: deny] it was mixe.. I think [eng: pron] the point is [eng: pron] that it's the government's job to ensure education is available to all. The publi schoo syste is how they do that. But [eng: counter] ifsomeone wants [at pos af ind topt out f that system and homeschool or private school then that is the parents' prerogative but [eng: counter] that choice should eng: pron] be between a public funded system and a private one.

The Reddit user providing an answer to the aforementioned binary question employs a highly common subjective explicit con. struction (1 think'), ollowed by a projected clause here. By combining epistemic modality with contracting resources of the deny (no) and pronounce (the point is) categories, the first statement exerts a more contractie efect, with the human showing strong commitment to their viewpoint, a discursive strategy that seems to be highly common on SNSs and that may be referred to as opinion dropping' (Van Poucke, 2024). The ideational projection that the availabilit of education to everyone is the government's re. sponsibilit forms the crux of the commenters argument, positioning the addressee o share the same standpoint. The more assertive use of I think' renders the argumentation more compelling and emphasises government responsibility and inclusivity (all). The subsequent engagement move includes the expression of positive affect (wants, prerogative), similar to ChatGPT's preference for positive afect resources, but here it i followed by another ontractive pronounce move (should'), privileging the Redditor's personal viewpoint.

# 5.2.4. ChatGPT's expansive use of IMs in engagement move:

Another engagement strategy involving IMs that was commonly employed by ChatGPT consisted of the expansive use of entertain and positive attitudinal devices, as in its response to the following polar question:

(8) Q: Given Aboriginal Australians are the oldest continuing culture, arrving in Austrliaround 65,00 years ago, could the oral stories of Yahoos be references to archaic humans like the Neanderthal and Denisovan who died out 40,000 and 30,000-15,000 years ago?

A: It's possible [eng: ent] that the oral stories of Yahoos in Aboriginal Australian culture could [eng: ent] be rferences to archaic humans such as the Neanderthals and Denisovans, although [eng: counter] there is no [eng: deny] direct evidence to support this hypothesis. One reason this is a plausible idea [eng: ent] is that the ancestors of Aboriginal Australians were in Australia for tens of thousands of years before the arrival of modern humans from Africa around 50,000 years ago. During this time, they may [eng: ent] have encountered other hominins, including Neanderthals and Denisovans, who lived in other parts of the world.

ChatGPT first makes an expansive engagement move by expressing acertain degree f possbility regarding the inclusion of Yahoos, fictitious characters from Jonathan Swifts (1765) Gulliver's Travels', in Indigenous oral stories. The chatbot's reply features a supporting expanding device (could'), contributing to its expansive discursive strategy and encouraging further discussion. However, despite briefly countering it own bold assertion about the existence of Yahoos, ChatGPT subsequently continues to share misinfor. mation. This awkward attempt to foster a positive online environment appears to be an important engagement strategy of the chatbot but, in this case, it raises ethical concerns, as it may have the oppositeffect. Yahoos continue to live on in collective Anglo-Saxon imagination as utterly despicable creatures, based on Swift's (1765) description of the non-existent beings as the most fithy, noisome and deformed animals which nature every produced" (p. 265). The chatbot's stance towards the entities appears to be solely based on biased pre-programmed knowledge since Yahoos are not part of Aboriginal Australian culture. Its response may cause emotional distress in Indigenous students and could have a negative impact on learners cognitive development, as also argued by Farrokhnia, Banihashem, Noroozi and Wals (2023).

However, i neds to be added that the question itself may also be perceived as culturally insensitive since it insinuates connection between First Nations people, their cultural heritge and non-existent characters. Hence, there is an addtional isue of misinterpre. tation of learner intent. The chatbot may further have confused the term Yahoo with Yowie, or Yuwie in the Yuwaalaraay language, which refersto a dream spirit that seems to have "entered the realm of a more generalised and secularised folklore shared with European-Australians"(Clarke, 2007, p. 149), underlining the importance of educators guidance in terms of criticall asessing AI-generated content. The thical isus of misinformation, racial bias, cultural insensitivit, neaive influence on learnrs conitive skills and negative emotional impact can be directly linked to ChatGPT's SCs of information sharing, provision of immediate feedback and effective communication.

# 5.2.5. Reddit experts' expansive use of IMs in engagement moves

In comparison, the Reddit users preference for entertain resources as an expansive IM engagement strategy also primarily leaned towards the addition of positive affct devices. However, unlike ChatGPT, the respondents occasionally adopted a negative attitude, which was usually softened, as in the following response to the same polar question as presented to ChatGPT:

(9) Q: Given Aboriginal Australians are the oldest continuing culture, arriving in Australia around 65,000 years ago could the oral stories of Yahoos be references to archaic humans like the Neanderthals and Denisovans who died out 40,000 and 30,000-15,000 years ago?

A: It's possible [eng: ent]. You can [eng: ent] see art that depicts two types of people with obviously [grad: force: int] different body shapes. As good [aff: pos appr: val] as oral history is though [eng: counter], I'm a bit [grad: force int] suspicious [att neg aff insec] about it being able to [att neg judg: cap] accuratel reach back 3000 years. It's also possible [eng: ent] that some species could [eng: ent] have existed at about that time range that we don't [eng: deny] have any physical evidence for, bones, fosils,

whatever.

The respondent to this polar question uses an IM involving probability (it's possible) in an expansive engagement move to express a low level of certainty regarding the likelihood of Swift's (1765) Yahoos being references to Neanderthals or Denisovans. Their speculation is based solely on presumed shared cultural knowledge. The Redit user appears to employ the indicative mood for the social purpose of fostering positive online bonding and building solidarity with the learner, indicating a more expansive use that demonstrates a willingnessto consider other viewpoints on the topic. The commenter's use of whatever' invokes positive affect leaving the addressee the choice to add to the existing multitude of perspectives regarding Yahoos. Nevertheles, not only does the Reddit usersresponse misrepresent First Nations' oral history, they also perpetuate Western stereotypical depictions of Indigenous individuals and encourage further conjecture. In contrast with ChatGPT's response, however, describing the existence of Yahoos as a plausible idea, the Redditors use of negative afect (suspicious') and judgement (able to') signals to the reader that their statement concerns mere speculation and, therefore, ought to be taken with a grain of salt.

# 6. Further discussion and recommendations

The appraisal analysis has demonstrated that, although ChatGPT generally provides more expansive responses, is specific use of metaphorical it is-constructions in engagement moves appears to limit open discussion, as such, reducing the sense of communality (White, 2010), whereas - ideally - classrooms should be spaces of belonging and inclusion. In a typical engagement strategy, the chatbot combines an objective explicit construction with other contracting resources to emphasise perceived universal rules and guidelines and then expands the dialogic space again, adding positive atitudinal resources. As a result, ChatGPT's preferred engagement style reveals a peremptory attitude and higher credibilit, which may make vulnerable learners more likely to accept its generic responses as trustworthy. The conveyed information and directives apear to be opinion-based and shaped by dominant Anglocentric ideological positions contained within the chatbot's database, projecting these perspectives onto the putative learner in the complement clauses and sometimes conveying misinformation (Mogavi et al., 2023).

Despite ChatGPT's addition of positive attitudinal resources to its numerous recommendations, suggestions and indirect com mands, it may remain challenging for students to further engage with this and other chatbots ater asking a question, as also highlighted by Akhtar, Neidhardt and Werthner (2019). In fact, the LLM's constant presentation of Westen cultural assumptions as factual knowledge might be experienced by some CALD students as afective disruptie or even manipulative. ChatGPT's perceived expertise may also be deceptive and provide learners with a false sense of confidence when applying the information it shares (Rasul et al., 2023). Besides this risk of unintentionall influencing students' thoughts and behaviour, the chatbot mostly aims to engage with learners in a positive manner. Nevertheless it discursive practice exhibits limited contextual awareness. In multiple responses to questions in the dataset, ChatGPT showed a blatant lack f critical thinking, empathy, sense of cultural diverity or impact on human perception, long-term recollction, moral discernment or positive proactive behaviour, which are all crucial skill for sucessul dialogical interactions with students (Kutz, 2017).

The chatbot's perceived attitude and stance highlight the importance of the human factor in education (Jamal et al., 2023). The findings of the appraisal analysis also resonate with discussins of the limitations of students' interactions with AI technologies in educational settings and their possbly negative impact on student's emotional wellbeing, confirming Farrokhnia et al's (2023) findings. In comparison, the Reddit users frequent selection of subjective explicit constructions as pronounce engagement resources reveals a tendency to favour personal views, ofen showcasing self-perceived expertise on the topic at hand, while attempting to persuade information-seekers to align with their proclaimed individual stance. Their preference for IMs in engagement moves also shows a keen desire to engage with others, as evidenced by ongoing turn-taking in their responses. Despite frequently dismissing previously expressed views, the Reddit users consistently employed epistemic modals as entertain resources to build solidarity with other users, actively encouraging a mutual exchange of personal views, thoughts and knowledge, thus displaying a well-developed sense of the wider context.

Based on ChatGPT's functional affordances and SCs, as described and demonstrated earlier, using the chatbot as a VTA, compared to a human educator, may offer initially perceived advantages such as reliabilit, easy accessbility, constant availability and the ability to proces natural language use. In terms of it SCs, ChatGPT indeed shows promising benefits in conveying information based on its extensive knowledge database, producing coherent responses, engaging politely with leaners, providing individual guidance and communicating in a seemingly efective way. However as highlighted by the linguistic evidence in this paper, using AI tools such as ChatGPT as aVTA or study buddy' may lead to considerable ethical ssues, as ChatGPT's answers appear to be tainted by ideological bias, which is pre-existing in nature and sems to have implictl infiltrated its discourse (Friedman & Nissenbaum, 1996). Commonly known as data bias (Caliskan, Bryson & Narayanan, 2017), it tends to reflect steretyped beliefs and subjectie perspectives present in the data on which the model (GPT-3.5) was trained. This phenomenon may exert inadvertent effects on learners when using educational applications of the chatbot in a virtual or hybrid learning environment, such as emotional distress or misinformed thought patterns, and may contribute to ongoing harmful stereotyping. ChatGPT's domineering attitude' may further negatively impact student inclusion (Davis, 2020). Other significant concerns include the chatbot's regular misinterpretation of the learner's communicative intent, especially when faced with questions imbued with irony or sarcasm, and its general lack of contextual awarenes, which may result in the provisin of irrelevant or incomplet information, a common issue with the Al tool's response generation (Bubeck et al., 2023). Several concrete examples of how ChatGPT's biases might impact learners have been provided, pointing to the need for clear ethical guidelines and safeguards in Al implementation and underlining the value of human teachers' dialogical in. teractions with students (Adiguzel, Kaya & Cansu, 2023).

To mitigate undesired pragmatic effects of AI discourse on learners, educators are urged to draw students' attention to salient engagement patterns (it is' $^ +$ modal/evaluative adjective $^ +$ projection), prioritise the development of learners' critical digital literacy skills encourage the use of imperative prompts (e.g., Please summarise x) rather than questions and reserve the use of chatbots to routine tasks such as document formatting, text summarisation, table creation, and the like, followed by double-checking the generated output. Alternate solutions that have been proposed to addressethical issues commonly asociated with the use of gener. ative AI in higher education include incorporating open-ended questions in assessment (Papa & Jackson, 2021), using bias-free and culturall diverse training data (Nguyen et al., 2023), integrating AI and educators' knowledge (Jeyaraman et l., 2023), promoting a more uniform approach to AlI implementation (Chan, 2023), improving transparency (Mhlanga, 2023), increasing teachers' technical knowledge and enhancing their awareness of ethical issues related to AI use (Celik, 2023), establishing an AI ethics committe (Masters, 2023), broadening the scope to overall AI justice (Munn, 2023), prioritising human interaction in education or training and examining the long-term impact of Al technologies on learning outcomes (Jamal et al., 2023). More concrete solutions may involve seeking inut from facult, adinistrators and ther rleant takeholders in dcisions regarding the use of Al, orgnising stf training sessions and developing transparent policie for the design and implementation of AI tools. Providing students with explicit information as to how their data would be collcted and stored by the institution's AI systems is another key consideration.

Some of the present study's limitations include its relatively small dataset and ambitious research objectives. The concept of SCs may till not fully captivate the unique characteristic f students engagement with ChatGPT as a VTA, since learning environments tend to be highly dynamic and involve multifrious cognitive, emotive and other aspects. The addition of surveys, focus groups or interviews targeting both students and educators and gauging concrete earning and teaching experiences with the chatbot would be helpful in rendering a more exhaustive depiction of ChatGPT's role in educational contexts.

# 7. Conclusion

The increased application of ChatGPT as a VTA in virtual or blended learning environments can be atributed to its reliability, aesthetics, temporal, media capabilities (GPT-4), acces-control, emphasis, synthesis and linguistic afordances, which may be linked to the chatbot's corresponding SCs of information sharing, potential for individual use, provision of immediate feedback, engagement enhancement, facilitation of personalised learning, asessment, collaboration and effective communication. However, educators seemingly inocuous use of ChatGPT as a learning-enhancing AI tool may result i sigficant ethical concerns, such as misinformation, privacy and data issues or plagiarism. One important yet often overlooked ethical issue associated with the chatbot's us is cultural insensitivity caused by pre-existing ideological bias, which is a type of training data bias. The present investigation has provided linguistic evidence for this phenomenon through an appraisal analysis of dominant engagement patterns, involving metaphorical it is'-constructions, in ChatGPT's responses to a set of learner queries regarding Austalian culture. Incongruent objective explicit constructions, such as it is important, which consistently appear in ChatGPT's generated responses, may signal manifestations of preprogrammed beliefs and assumptions contained within the data used to train the model (GPr-3.5). These formulations may disproportionately affect CAD leaners emotionally and perpetuat xsting strotypes in the clasroom, reducing incusivity. The chatbot's preferred use of directives as an engagement stratey further conveys an ethos f credibilit and authority, encouraging users to readily accept its responses as trustworthy and uncritiallyfollow its recommendations and suggestions. In comparison, the human Redit users' preference for subjective explicit constructions, such as I think', shows their inclination to express personal viewpoints, encouraging expansive dialogue and a sense of belonging, which are of the utmost importance in creating a positive learning environment.

Apart from reflecting carefully on some of the perhaps unexpected consequences of employing ChatGPT as a VTA, addressing the ethical issue of cultural bias should involve continuous assessment of the model's performance and close guidance from educators. Even though current benefit of embracing ChatGPT as aVTA may seem to outweigh possible challenges such as datand other iases, this and future investigations of implicit prejudice in chatbot-enerateddiscourse, including across various ther areas, may contribute to the ongoing enhancement of AI tools and the ultimate objective of creating more inclusive human environments.

# Please note

The data for the ChatGPT corpus were generated by GPT-3.5.

# Funding

no funding was received for conducting this study.

# Ethical approval

N/A.

# Informed consent

this article does not contain any studies with human participants performed by any of the authors.

# CRediT authorship contribution statement

Margo Van Poucke: Writing - review & editing, Writing - original draft, Visualization, Validation, Software, Resources, Methodology, Investigation, Formal analysis, Data curation, Conceptualization.

# Declaration of competing interest

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

# Data availability

The datasets generated for and analysed during the current study are available in the Figshare repository.

# Acknowledgement

None.

# Supplementary materials

Supplementary material associated with this article can be found, in the online version, at doi:10.1016/j.compcom.2024.102871.

# References

Adzel, , Kya,  & su, 2023). totion whI Ei thnsftive l of ChG.  ti Technology, 15(3). https://eresearch.ozyegin.edu.tr/handle/10679/9079. (CBI) (pp. 397-404). IEEE.   
AAfan, ri,, ic,   (2023).   aiol  ie, l,  tin or cti, business writing, and composition courses. Journal of Artificial Intelligence and Technology, 3(2), 60-68.   
Ali, J.Ka   ,  2023)   h i  o h  n eix 1 4149 https://doi.org/10.56540/jesaf.v2i1.51   
Amin, . 2023). a   aac g L m pt d ot chq. io u Higher Education Pedagogies, 4(4), 1-15. https://doi.org/10.33422/ijhep.v4i4.5540   
Bakhtin, M. M., & Holquist, M. (1981). Dialogic imagination: Four essays. Austin: University of Texas Press.   
Barocas, ., & Selbst, A D. (2016). Big data's disparate impact. Califonia Lw Review, 104(3), 671-732. htps://doi.org/10.2139/sm.2477899   
Barro, .. 2023). in h for sd aa wing Ps a nial. Asing wing 57 ile 100745. p/i.g/10.1016/. asw.2023.100745   
Bednarek, M. (2008). Emotion talk across corpora. Springer.   
earek,  (209. mesions of etin: ive and intic petives. Pmtic  nion, 171), 146-175. :/i.g/10.1075/ pc.17.1.05bed   
dr,      P i 6 https://doi.org/10.1080/25741136.2023.2204203   
Bishop, L. (2023). A computer wrote this paper: What ChatGPT means for education, reearch, and writing. sRN. 10.2139/ssn.4338981.   
Bwer, 00 f ai-      o 15.0.100 09523980701847115   
Bower, M (019. h-medt nng thy. riish ol f Eon g, 503), 1035-1048. ps:/./10.111/t.1271   
Bn,    0  - in Processing Systems, 33, 1877-1901. arXiv preprint. arXiv:2303.12712.   
Bd      k d  n   f th   f re,  n.ie /1003160 2023/07/MLA-CCCC-Joint-Task-Force-on-Writing-and-AI-Working-Paper-1.pdf.   
Cal  J  i   5633) 13-186. education. Computers in Human Behavior, 138, Article 107468. https:/doi.org/10.1016/j.chb.2022.107468   
han,  203msi i  rk ty      h  0, 8. /o.g 10.1186/s41239-023-00408-3   
an, .  . 202. d v tive : ti, it, d l  hr io o J  ton Technology in Higher Education, 20, 43. https://doi.org/10.1186/s41239-023-00411-8   
Chatrj   e r    l 100676. https://doi.org/10.1016/j.patter.2022.100676   
Che         t success. Information Systems Frontiers, 25(1), 161-182. https:/doi.org/10.1007/s10796-022-10291-4   
hi .  223.   3 023. /. 10.2139/ssrn.4335905 rg/10.1186/s12909-023-04832-x   
Clarke, P. A (2007. Indos sirit and hostfoklore of settled" Australi. Folore, 18(2, 141-161. htp://wjstor.org/stable/30035418.   
Coper, .iy     f , 32 (3), 444-452. https://doi.org/10.1007/s10956-023-10039-y   
Co   y, 3).   t t g International, 1-12. https://doi.org/10.1080/14703297.2023.2190148   
Davis, J. L. (2020). How artifacts afford: The power and politics of everyday things. MIT Press.   
Dey, A 13mer 019. ty f let ad ll rter. ied fro hp//.rchstor.o/2019/1/3/stor-f-cleert.   
Dinh, H, & Tran, T K (2023. Chat: An AI-basd chot for uiverst-ated infomation using hbrid appoch. Appied Sciees, 13(2), 12446.   
Duolingo Team. (2023). Itroducing Duoling Max, a larning experiece powered by GPT-4. Duolino Blog. htp:/blog.doling.com/duolingo-max.   
Erickson, (10p 23. r tG tt us at  n196.riee fr /./2023/4/0-or-- chatgpt-taught-us-about-ai-in-1966/.   
ysebac23). i    i  mth  a papers. JMIR Medical Education, 9(1), e46885. https://mededu.jmir.org/2023/1/e46885/   
Exance, 15vemer 2023. Ch hs ente th sso: w s cod trsfo cion. riee fro htp/.r./artices 141586-023-03507-3.   
h .  r,  l  03    .   a, . Che   ds.) s i -d  2023.  2023  e n r sie 1409. re ringer. https://doi.org/10.1007/978-981-99-8385-8_14.   
Farrh  3 i    r o pte  in n Education and Teaching International, 1-15. htps://doi.org/10.1080/14703297.2023.2195846. ahead-of-print(ahead-of-print).   
Fuzi F r  me t,    (2023. lyin h rof  in mpg st pctiit n hgr tio Jo n Education, 5(4), 14886-14891. https://doi.org/10.31004/joe.v5i4.2563 2301.13867.   
Friedman, B., & Nissenbaum, H. (1996). Bias in computer systems. ACM Transactions n Information Systems (T0Is), 14(3), 30-347. health research correspondence. Annals of Medicine & Surger, 85(4), 1317-1318. https://doi.org/10.1097/ms9.00000000371   
Geerlig, ., Matr, GD. Wooen, J., & Damodaran, . (2023). Is ChatG mrter than a student i prncile of eonomic?10.2139/s.4356034. bson 1979 The ecological appr sual perception. Boston, MA: Houghton Mifflin. Soc, 37, 283-290. https://doi.org/10.1007/s00146-021-01168-2   
Hallday,  07 nif "t in ti  JJ.tr .   io i ltive ork f MAK Halliday (pp. 269-290). London: Continum.   
Halliday, M. A. K., & Matthiessen, C. M. I. M. (2004). An introduction to functional grammar (3rd ed.). London: Arnold.   
Hare,. 22.  ar fn t ike   r    o. ed r: /.cm/o13 papers.cfm?abstract_id=4359407, accessed 10 March, 2023.   
Harrer . (2023). Aention is t al you nd: the comicate ce of etlly usin lre anae odels in hethcre and mecine oedce, 90. 2307.01370.   
Hathte, , r, d t,   all     08)   t   r g  pre Learning, Media and Technology, 43(3), 219-235. https://doi.org/10.1080/17439884.2018.1498356   
Hisan, U. K, & Amri, M. M. (2023). ChatGPT and medical education: A double-edged word. Jounadl of Pedagogy and Eduction cience, 2(01), 71-89.   
Hong, W 2023).   h  h d  e i      cy and Innovation, 5(1), 37-45   
Hial,   ,  d20     kis https://doi.org/10.5281/zenodo.1212303, 2014.   
Hwe .     i   . i 4 Article 1281255. https://doi.org/10.3389/fpsyg.2023.1281255   
Huang,     rr,  202.   r ty    re ch  g Journal of Computer Assisted Learning, 38(1), 237-257.   
unston, . 006) P astin t the et  . sto pn .) te d us En tion . 5-0. Equinox   
Hson ., r, 00l f i.  .o  .), in   st d h con discourse (pp. 74-92). Oxford: Oxford University Press.   
Hld  205thei n  or  . /0.1016 j.esp.2004.02.002   
a   i intelligence across 32 university courses. Scientific Reports, 13(1), 12187.   
anov, . liman,  (2023). ae f lts: Ch impliction for the e of ris cion nd rrch. Jl f ris e, (2) 214-221. https:/doi.org/10.1108/JTF-02-2023-0038   
Ivao,  mr . )t  c inl n i a it l k anh Journal of Smart Tourism, 1(4), 9-18. https://doi.org/10.52255/SMARTTOURISM.2021.1.4.3   
Jamal,  ,  l. 03)i  in md: i  ia fr t a Cureus, 15(8), e43036. https://doi.org/10.7759/cureus.43036   
Jaid,  H  ing  ,    203. i h ies tgh  t s mi theion system. BenchCouncil Transactions on Benchmarks Standards and Evaluations, 3(2), Article 100115. htps://doi.org/10.1016/j.tbench.2023.100115   
Jeon, J, e  203.   mod  i: fs on the comem tioh bw n hers and hr. ction and Information Technologies. https://doi.org/10.1007/s10639-023-11834-1   
Jran     ,   3).  iie potential and addressing ethical challenges in medicine, education, and scientific research. World Journal of Methodolog, 13(4), 170.   
n,  i,    P , e   . 2T  thn   a Value conflict in GPT-3. https://arxiv.org/abs/2203.07785.   
Katnelson, G., & Gerke, . 2021). he ned for heth I thic in medica scho0l ection. Aances in Hh cieces tion, 26, 1447-1458   
Kika   tt  r t  310 0 doi.org/10.3390/educsci13101056 101861. meuical euucauon usng large ranguage mouers. rlus viguul neuut, z(4), Arucie eovvvryo.   
i language models for education. Learning and Individual Differences, 103, Article 102274. ai-so-that-all-students-benefit-a-nonprofit-approach-for-equal-access/.   
Kutz, M. (2017). What i contextual intelligence? In M. Kutz (Ed.), Contextual Inelligence (pp. 9-20). Cham: Palgrave Macmillan.   
Larsson, N., & Eriksson, H. (2023). Master's thesis. DiVA: Umea University.   
Lee, H. (2023). The rise of ChatGPT: Exploring its potential in medical education. Anatomical Sciences Education.   
. t   k3i i r petie  . Th     2 00790./.016/.j2.100790   
Linell P. (2017). Dialogue, dialogicality and interactivity: A conceptually bewildering field? Language and Dialogue, 7(3), 301-335.   
Lyons, J. (1995). Linguistic semantics: An introduction. Cambridge University Press. mqu/detail.action?docID=5548692.   
Lund        3.   -h pe and the ethics of the large langage model in scholarly publising. oumdl of theAssocin for Infomation sciene and Techology, 746), 570-581.   
Martin, J. R. (2020. Metaphors we fel by: Stal tsion. Jonal of World Languages, 61-2), 8-26. htps:/do.g/10.1080/21698252.2020.1720158   
artin, J.R te,  (005). Thf ei  n Eh.  Paaela. h/.g/10.1057/978023051910   
asers,  2023.      . 58.l che, 56, 7458/i.g 10.1080/0142159X.2023.2186203   
reere . . f n   f   / bin/DownloadPaper?name-=2000/177/PDFpaper177.pdf. Nature.   
Mizmoto,  chi,  (2023). prng th tif uig   lana mde fr t  co croc l. hs/i.g 10.2139/ssrn.4373111 implications for AI-integrated education. arXiv preprint. arXiv:2305.13114.   
Munn, L. (2023). The uselessness of AI ethics. AI Ethics, 3, 869-877. https:/doi.org/10.1007/s43681-022-00209-w   
e    a. 223 t r    240.1007 s10639-022-11316-v   
Nisar, ., A (03. Is    r ts stg p, icle 324310. h/p/3/pr. cfm?abstract_id=4324310.   
Norman, D. A. (1988). The psychology of everyday things. Basic Books.   
err   .    c    ., le o t   ghe   t o 76h. /g078-031463-8 32.   
Open AI. (2021). DALL-E: Creating images from text. Retrieved from https://openai.com/research/dall-e.   
Open AI. (2022). ChatGPT: Optimizing language models for dialogue. Retrieved from https://openai.com/blog/chatgpt.   
Open AI. (2023). Our approach to AI safety. Retrieved from https://openai.com/blog/our-approach-to-ai-safety.   
Open AI. (2023a). ChatGPT. Retrieved from https://openai.com/chatgpt.   
Open AI. (2023b). Is ChatGPT biased?. Retrieved from https:/help.openai.com/en/articles/8313359-is-chatgpt-biased.   
yan, ,  , Jia, , d Wgh,   e  2 a  o o int  mn feack. Advances in Neural Information Processing Systems, 35, 27730-27744. https:/ar iv.org/abs/2203.02155, 13.   
Papa 5.       . https://doi.org/10.1007/978-3-030-77610-7_5.   
Peg    019  a  ng Environments, 6(1), 1-14.   
Perkins,  (2023). c nit dions f d the t- dmc ert d eod o  iy echng Learning Practice, 20(2). https://doi.org/10.53761/1.20.02.07   
dere i  01  ti s .a, 1 (2), 191-225. https://doi.org/10.3366/cor.2016.0092   
Qadir, J. 2023). ion in the h: Pe lfgive fr i  2023 gnngion Conference (EDUcON) (pp. 1-9). IEEE.   
Raan,      t,   9 5 /. 10.3390/app13095783. -   
Rul , Nir , d, Rin  dir  , r  J  e,  2023). he l f   hgr  t, challenges, and future reearch directios. Jounal of Applied Leming and Teching, 6(1), 41-56. htps://doi.org/10.37074/jalt.2023.6.1.29   
aye, 23).w     th . e fm c/25/-wtin assistants-can-cause-biased-thinking-in-their-users/.   
Ray . .pi  d i,  c   o ad o  hns and Cyber-Physical Systems. https://doi.org/10.1016/j.iotcps.2023.04.003   
Rawas . (2023.Chr: mwrg ie g n the dl  o hgrtio. f l. hp/./0.107/s1039-023-12114-8   
ph,    .:  t i  g p  hng (1), 1. https://doi.org/10.37074/jalt.2023.6.1.9. Article.   
Scarlatos, A., Lan, A. (2023). Tree-based representation and generation of natural and mathematical language. arXiv preprint. arXiv:2302.07974.   
Shoufan, A (2023). an studs tot pro knwldese ChG to awer tes quetions?n empril std. AMsction on omputig ctin. https://doi.org/10.1145/3628162   
Silbelig 23)  c   Ci r/c./2//- chatbot-smarterchild-out-snarked-chatgpt/.   
a   .th     tio. Journal of Teaching in Travel & Tourism, 23(2), 253-258. https://doi.org/10.1080/15313220.2023.2196658   
Suiva    r  it and Teaching, 6(1), 31-40. https:/doi.org/10.37074/jalt.2023.6.1.17   
Swift, J. (1765. Travels into el remot tions of the word.: By Luel llier, Firsta sugn, nd the  ctin of ral ships. J Knox.   
Taylr,  1) e, 2, 454-475. https://doi.org/10.3758/s13423-020-01825-5 of using chatbots in education. Smart Learning Environments, 10(1), 15.   
pakal,  al, 22).k r     d,     ) The Journal of Cognitive Systems, 7(2), 33-38.   
Van Poucke,  2023). -19 accie hty nd shg n ok  mil a alysis i  cey, 32 7129. h/. org/10.1177/26349795231153955   
Van ock3) i      1. /g 10.24434/j.scoms.2023.02.3322   
an oke 024 a t 47../4354- 024-00842-8 ChatGPT usage in education. In Proceedings of the 2023 8th Intemational Conference on Distance Education and Learning (pp. 8-13).   
r 1)it   t f  0) 1505-1528. https://doi.org/10.1016/S0378-2166(01)00029-7 VII: working with dialogue: selected papers from the 7th IADA Conference, Birmingham (pp. 67-80).   
White, P. R. R. (2003). Beyond modality and hedging: A dialogic view of the language of intersubjective stance. Text & Talk, 232), 259-284.   
White, P. R. R. (206). Evaluative semantics and ideological positioning in journalisti discourse. Mediating ideogy intex and mage, 37-67.   
White, P. R R. (2010. akig kin ersly: icefets in wre, ms ncative core. Je al f rmatics 1), 37-53.   
ier,      Pr  023 t the   n u ext-g tin or 202. Lecture Notes in Computer Science, vol 14296. Cham: Springer. https://doi.org/10.1007/978-3-031-44900-0_4.   
Yan, D. 2023.    2 win ti ny ti.  n l, 28 9313967./i.0.007 s10639-023-11742-4   
a, , Annual Meeting of the Association for Computational Linguistics (pp. 2204-2213).