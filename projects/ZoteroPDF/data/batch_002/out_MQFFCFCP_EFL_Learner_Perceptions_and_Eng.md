# EFL Learner Perceptions and Engagement of a Customized AI-led Class

Seungeun Lee Korea University, Republic of Korea

# Abstract

Technological advancement has enabled language educators to employ AI virtual humans as online instructors by customizing their characteristics, such as English varieties, to meet learners’ needs and preferences. As AI instructors become aviable option in classrooms, how they affect language learners’ learning warrants investigation. Building upon social presence theory regarding interpersonal relationships in an online environment, this study aimed to examine the role of social presence and AI instructors’ credibility in fostering learner engagement. Additionally, it examined the effects of variables within instructors on instructor credibility and learner engagement. In the study, a 2 (human or AI) $\times 2$ (native or non-native English-speaking teacher) between-subjects design was utilized in an online experiment with 120 English learners. Regression and mediation analyses revealed, in AI-led classes, social presence positively influenced learner engagement, with instructor credibility fully mediating this relationship. According to a two-way MANOVA analysis used to examine the effects of humanness and nativeness on credibility and engagement, no evidence was found to support a difference between AI instructors and their human counterparts when observing learners’ perceptions and engagement, regardless of whether the instructors were NESTs or NNESTs. The results show that AI instructors can be a viable alternative in language classes.

# Keywords

Educational technology, AI instructor, native English-speaking teacher, social presence theory, instructor credibility, learner engagement

# Introduction

As one of the prominent forms of language learning in the context of English as a foreign language (EFL), online classes provide convenience and flexibility. However, challenges in online classes in terms of learners feeling isolated and lacking a sense of belonging, which hinder learner engagement, have been identified (Li, 2022). Since engagement in online classes is directly linked to second language (L2) learners’ learning performance (Jiang and Peng, 2023), engagement is considered essential for successful online EFL learning (Sun et al., 2023).

In determining L2 learners’ engagement, the notion of social presence and instructor credibility needs to be considered (Rezvani and Miri, 2021; Zheng, 2021a). In online L2 classes that lack physical co-presence, social presence plays a key role, which Biocca et al. (2003: 456) defined as the “sense of being with another.” Two concepts, immediacy and intimacy, have been suggested to largely contribute to social presence by Short et al. (1976), whereby immediacy represents the psychological distance between communicators and intimacy can be displayed by eye contact and smiling. This psychological closeness helps L2 learners engage in online learning. As Zhong et al. (2022) reported, there is the predictive role of social presence in learning engagement during courses that support online classes. Additionally, L2 learners’ perceptions of instructor credibility influence learner engagement (Zheng, 2021a), since instructors are authoritative information sources in online classes. With reliable teachers, learners tend to value the class more, thus being more likely to show high engagement if communication is considered credible (Amerstorfer and Freiin von Münster-Kistner, 2021).

However, to better understand the impact of social presence and instructor credibility on learner engagement, their interrelationship should be also considered. Derakhshan (2021) reported a significant interrelationship between immediacy and instructor credibility, which are both crucial predictors of L2 learner engagement. Nevertheless, as there has been insufficient research on the role of these factors in learner engagement, the importance of their interplay in establishing learner engagement during online classes warrants attention.

Furthermore, with the advancement of AI, AI instructors are becoming viable in language classrooms, emphasizing the need for research on how these three key variables— social presence, instructor credibility, and learner engagement—interact in AI-led online classes. While it is crucial to compare human and AI instructors, it is also valuable to comprehend how learners respond to different types of AI instructors. Through customization, AI’s skin complexion and accent can be manipulated to reflect human variability, such as accentedness and nativeness, which represent the degree of having a native accent and being perceived as a native speaker, respectively. Despite the various types of AI virtual humans, most previous studies have not considered the variables associated with them, such as AI’s voice and appearance (e.g., Li et al., 2016). However, given the research demonstrating the nativeness of instructors impacts EFL learners’ perception (Walkinshaw and Oanh, 2014), it is likely that similar effects of nativeness will be observed in EFL classes conducted by AI instructors. Thus, as the first step in discussing the viability of AI instructors in EFL classrooms, it is essential to address the role of nativeness among instructors in EFL learners’ perceptions to find the optimal conditions for AI instructors. In this regard, it is valuable to consider instructor characteristics of humanness (AI vs human) and nativeness (NEST vs NNEST) simultaneously, as they are deemed to be crucial in determining instructor credibility and engagement, which may in turn affect EFL learners’ achievement.

# Literature Review

# Learner Engagement and Social Presence

Learner engagement is defined as “the amount (quantity) and type (quality) of learners’ active participation and involvement in a language learning task or activity” (Hiver et al., 2024: 202). In online language learning, learners are prone to disengagement because of various factors, for example, diminished sense of co-presence. Learner engagement is considered to consist of three components. According to Hiver et al. (2024: 204–205), behavioral engagement refers to “active participation” observed from learners’ voluntary involvement and effort; emotional engagement to “personal affective reactions” such as enjoyment and enthusiasm; and cognitive engagement to “mental effort and mental activity.” Cognitive engagement is demonstrated by self-regulation and the use of deep and shallow processing strategies (Greene, 2015). Research has indicated academic performance in online L2 learning can be enhanced by learner engagement (Jiang and Peng, 2023), making engagement essential for successful online EFL learning (Sun et al., 2023).

Social presence has been examined as a solution to address learners’ engagement during online classes, where physical co-presence cannot be established. Social presence theory aims to reveal how the sense of connectedness can be established during human–computer interactions (Biocca et al., 2003). Social presence can explain how learners establish social belonging in remote learning settings. Short et al. (1976) showed intimacy and immediacy significantly contribute to social presence, while the importance of instructor immediacy in engaging L2 learners has also been highlighted (Derakhshan, 2021; Zheng, 2021a). In particular, Teo et al. (2022) reported L2 instructors’ immediacy fosters learner engagement, further noting the adverse impact of non-immediacy on learners’ engagement.

While it has been established that social presence can boost L2 learner engagement in online classes, research has focused on human instructors. However, as social presence theory suggests individuals can feel a sense of connectedness even with an artificial human, it is possible that highly human-like AI instructors can also enhance social presence, thereby promoting learner engagement.

# Instructor Credibility

According to McCroskey and Teven (1999), instructor credibility is a composite encompassing competence, trustworthiness, and goodwill. While competence refers to being an expert in the field, trustworthiness involves being honest, and goodwill implies understanding. Instructor credibility is a crucial factor in shaping learners’ attitudes and perceptions of their teachers and the classes conducted by them, which has been reported to predict EFL learners’ engagement (Zheng, 2021b).

As a positive relationship was reported between instructor immediacy and instructor credibility (Santilli et al., 2011), their interplay has been considered in explaining L2 learner engagement (Derakhshan, 2021). However, to better understand the role of this interrelationship in engagement, a question arises as to whether instructor credibility can serve as a mediator linking social presence with learner engagement, as it does not seem to be a mere predictor of a positive learning experience. Instructor credibility has been examined as mediating learners’ learning experience and instructors’ interpersonal variables such as immediacy (Allard and Holmstrom, 2023; Schrodt et al., 2009). Schrodt et al. (2009) demonstrated instructor credibility fully mediates instructor immediacy and learners’ learning outcomes, by measuring learning outcomes in terms of learner empowerment (e.g., competence), affective learning (e.g., positive feelings about course content), and cognitive learning (e.g., use of learning strategies). The constructs of affective learning and cognitive learning in Schrodt et al. (2009) show overlap with the concept of emotional and cognitive engagement proposed by Hiver et al. (2024) and Greene (2015), as they refer to positive emotional reaction and mental activity often displayed through self-regulated learning strategies, respectively. Given the findings of Schrodt et al. (2009), it is postulated that learners’ level of engagement could be hindered when they perceive their instructors as lacking credibility, even if they experience a sense of co-presence with instructors. However, the mediating role of credibility in language classrooms has been underexplored, leaving this postulation insufficiently investigated. In addition, previous studies have centered on the role of instructor credibility with human teachers (e.g., Derakhshan, 2021), leaving the connection between L2 learners and AI teachers relatively unexplored.

# AI English Teachers

AI is gaining ground in language educational technology (An et al., 2023; Huang and Wang, 2021). AI chatbots can serve as conversational partners, to promote exposure to language learners (Lee and Jeon, 2024; Yang et al., 2022). AI virtual humans are even capable of delivering online foreign language lectures. Given the feasibility and potential of AI instructors, previous research has examined learners’ perceptions of AI instructors (Kim et al., 2022). Some research has revealed the superior influence of human instructors over AI, such as Li et al. (2016), which illustrated that learner attitudes were more favorable towards human instructors. Nonetheless, the study suggested that properly designed virtual or nonhuman instructors could be viable alternatives, posing the possibility that highly developed virtual instructors could successfully facilitate students’ learning.

It has been documented that high-quality non-human instructors can surpass human instructors in promoting learners’ learning. Pi et al. (2022) revealed AI instructors with likable appearances, such as those resembling popular singers, can induce higher attentional engagement in the learning materials than human instructors. This study suggested that properly designed virtual humans can increase learners’ dwell time on learning material because presenters’ attractive features may enable learners to concentrate more. Furthermore, the increased quality of AI technology and the degree of human-like characteristics in virtual humans can positively affect learners’ perception and learning. Comparing learner attitudes toward online lectures with different voices (i.e., human voice, classic AI voice, and modern AI voice), Craig and Schroeder (2017) found the modern AI voice was perceived as more effective in training learners than the human voice and resulted in better learning performance compared to the human and classic AI voice. Therefore, as AI technology continues to rapidly advance, further research is needed to investigate the influence of recent AI instructors on EFL learners’ perceptions and engagement, in comparison to those featured in previous research (e.g., Li et al., 2016).

# Native English-Speaking Teachers

In EFL contexts, learners’ perceptions of instructors and their L2 learning have been shown to be closely related to the instructors’ nativeness.1 Studies such as Walkinshaw and Oanh (2014) have reported Asian EFL learners’ preferences for native English-speaking teachers (NESTs) over non-native English-speaking teachers (NNESTs), which calls into question what effect the nativeness of AI instructors has if they are so real that they can barely be distinguished from humans.

Native speakers have been suggested to positively impact learner perceptions and engagement. Hanzlíková and Skarnitzl (2017) revealed EFL learners evaluated statements delivered by native English speakers to be more credible than those by non-native speakers. Instructors’ nativeness can also act as a strength for native teachers, enabling them to foster learner engagement by leveraging their authentic knowledge of the target culture, as the importance of indigenous knowledge and cultural competencies in promoting learner engagement is demonstrated in past studies (e.g., Suarta et al., 2022). Lasagabaster and Sierra (2002) reported EFL learners prefer NESTs in most linguistic areas, except for learning strategies and grammar which may require explicit teaching. Therefore, the nativeness of a teacher appears important in instructor credibility and learner engagement.

Nevertheless, the role of nativeness of AI instructors in educational contexts remains unclear. Existing studies exploring the impact of AI instructors’ nativeness on learners perception and learning have been conducted outside the field of language education (e.g., Do et al., 2022). Hence, with the growth of AI teachers in language education, it is essential to explore the influence of nativeness on EFL learners’ perceptions and engagement, which may contribute to identifying the optimal conditions for AI instructors in EFL classrooms and meeting the preferences of EFL learners. Specifically, this study aimed to examine how different types of instructors (i.e., human NEST, human NNEST, AI NEST, and AI NNEST) affect instructor credibility and learner engagement. Based on these grounds, this study poses the following research questions:

1) What is the role of social presence and instructor credibility in learner engagement when learners are instructed by AI instructors in an online English class?   
2) How do the humanness and nativeness of instructors influence EFL learners’ perceived instructor credibility and engagement in an online English class?

# Method

# Participants

The present study recruited 120 college students2 enrolled at a private university in the EFL context of South Korea. These participants responded to an advertisement and were selected based on their intermediate-level English proficiency through the university’s placement test. Participants were native Korean speakers and none had spent more than one year in an English-speaking country. They were diverse in terms of age $M = 2 2 . 1 1$ , $S D { = } 2 . 1 7 _ { . }$ ) and major fields of study. Approximately $5 9 \%$ were female $( n = 7 1 )$ ), $40 \%$ were male $( n = 4 8 )$ , and $1 \%$ preferred not to disclose their gender $( n = 1 )$ ). Thirty students were assigned to each experiment condition based on instructor type: human NEST, human NNEST, AI NEST, and AI NNEST.

# Manipulation of Humanness and Nativeness in Video Stimuli

In this study, lectures on English opaque idioms were created, using the same script for all instructors to ensure that their lectures covered the same content. The lecture videos were manipulated to vary in terms of the instructors’ humanness and nativeness.3 Humanness refers to the degree of human characteristics displayed by the instructor (AI vs Human), and nativeness is defined as the degree to which the instructor is perceived as a native speaker (NEST vs NNEST). Based on these two variables, four different types of videos were created for the four experimental conditions. The study had a human NEST condition with a native speaker of Standard North American English and a human NNEST condition with an ESL speaker from the Philippines. AI videos were generated using Synthesia (https://www.synthesia.io/), featuring virtual humans with characteristics that match variables of their human counterparts, including English varieties, gender, and age (Figure 1). Participants in the AI conditions were informed that the instructor was a virtual human.

# Instruments

Social Presence. Social presence was measured by participants’ mean rating of the degree to which they felt connected with others. This measurement was adapted from Li et al. (2016), which was originally based on the work of Lee et al. (2006). Social presence was assessed using five items (see Appendix for the complete questionnaire; $1 =$ strongly disagree; $5 =$ strongly agree). Reliability of the scale was high (Cronbach’s alpha $= . 8 1 5$ ).

Instructor Credibility. Instructor credibility was assessed by calculating the mean score of the 15-item4 Source Credibility Measure, adapted from McCroskey and Teven (1999) (see Appendix for the complete questionnaire). Competence, defined as expertness, was measured with six items. Trustworthiness, described as sagacity, was assessed using four items. Goodwill, defined as perceived caring, was measured using five items. Participants rated the instructor’s credibility using a bipolar adjective seven-point scale. Reliability of the scale was high (Cronbach’s alpha $= . 8 4 5$ ).

Learner Engagement. To measure participants’ quality and quantity of involvement, learner engagement was assessed by calculating the mean score of a 21-item engagement scale, adapted from $\mathrm { Y u }$ and Gao (2022), which was originally developed by Wang et al. (2016) (see Appendix for the complete questionnaire; $1 =$ strongly disagree; $5 =$ strongly agree). The measurement of behavioral engagement, conceptualized as active involvement, comprised five items. Emotional engagement, defined as positive emotional reactions to learning, was measured with 10 items. Cognitive engagement, conceptualized as self-regulated learning, was assessed using six items. Reliability of the scale was high (Cronbach’s alpha $= . 9 0 9 $ ).

Accentedness. To measure the degree to which the instructor is perceived as a native speaker, participants’ perceptions of instructors’ accents were examined using a single item adapted from Lee and Bailey (2023). Participants were asked to answer the question, “How did you feel about this person’s English accent?” on a five-point scale $1 = \mathrm { V e r y }$ strong non-native accent and difficult to understand; ${ 5 = \mathrm { A } }$ native speaker of English).

![](img/6819c630661ba5ce7cb1def4564e58074243a464961ec37f93caa3ee1038eac3.jpg)  
Figure 1. Screenshot images of (a) AI NEST and (b) AI NNEST.

# Procedures

The participants took part in the online experiment at their convenience for $3 0 \mathrm { { m i n } }$ . They were randomly assigned to one of four experimental conditions. Participants were informed about the study’s procedures and completed a consent form. They completed demographic questionnaires and were informed that they would be watching a $1 0 { \cdot } \mathrm { m i n }$ lecture on English idioms. After watching the lecture video, participants completed the questionnaires on social presence, instructor credibility, and learner engagement.

# Analysis

To assess whether there are perceived differences in instructors’ nativeness (NEST and NNEST), manipulation checks were performed as a preliminary test, using the Kruskal-Wallis test in SPSS, as the assumption of normality was violated. For the first research question on the role of social presence and instructor credibility in learner engagement, regression and mediation analyses were performed using R. For the second research question, investigating the impact of humanness and nativeness on credibility and engagement, a two-way MANOVA was conducted in SPSS. Measured variables fulfilled the assumptions for parametric analyses, except for social presence5 and accentedness.

# Results

# Manipulation Check

To validate the manipulation of instructors’ nativeness, the current study examined group differences in perceived levels of accentedness. The Kruskal-Wallis test revealed statistically significant differences among the four groups $( \mathrm { C h i } \mathrm { S q } = 3 3 . 3 6 , d f = 3 , p < . 0 5 )$ . Dunn’s post hoc test with Bonferroni correction did not reveal any significant differences among participants of the NEST and NNEST groups $( p > . 0 5 )$ , suggesting participants in both groups perceived their instructors similarly in terms of accentedness. However, significant differences were observed between the NEST groups and the NNEST groups $( p < . 0 5 )$ . NEST group participants perceived the instructors as having an accent close to native English speakers $\mathcal { M } { = } 4 . 6 3$ , $S D = . 6 1$ ), with ratings ranging between 4 (i.e., “Occasionally I detected a slight non-native accent, but still close to a native speaker of English”) and 5 (i.e., “Native speaker of English”). NNEST group participants perceived the instructors as having a somewhat non-native accent $( M = 3 . 7 7 , S D = . 8 9 )$ , with ratings ranging between 3 (i.e., “I detected a slight non-native accent, but it was understandable”) and 4 (i.e., “Occasionally I detected a slight non-native accent, but still close to a native speaker of English”). Therefore, the manipulations were deemed successful.

# Descriptive Statistics

Descriptive statistics for participants’ perceptions of social presence, instructor credibility, and learner engagement were examined. Table 1 summarizes the results (see Appendix for boxplots).

As Table 1 indicates, human NNEST achieved the highest score in enhancing social presence $\mathit { M } = 3 . 1 4$ , $S D = . 6 8$ . Human NEST received the highest rating on instructor

Table 1. Descriptive statistics of relevant variables.   

<html><body><table><tr><td rowspan="3"></td><td colspan="4">Humanness</td></tr><tr><td colspan="2">Human</td><td colspan="2">AI</td></tr><tr><td>M</td><td>SD</td><td>M</td><td>SD</td></tr><tr><td colspan="5">Social presence</td></tr><tr><td>NEST</td><td>3.09</td><td>.81</td><td>2.98</td><td>1.01</td></tr><tr><td>NNEST</td><td>3.14</td><td>.68</td><td>3.05</td><td>.89</td></tr><tr><td colspan="5">Instructor credibility</td></tr><tr><td>NEST</td><td>5.09</td><td>.83</td><td>4.94</td><td>.64</td></tr><tr><td>NNEST</td><td>4.93</td><td>.78</td><td>4.66</td><td>.77</td></tr><tr><td colspan="5">Learner engagement</td></tr><tr><td>NEST</td><td>3.59</td><td>.66</td><td>3.68</td><td>.65</td></tr><tr><td>NNEST</td><td>3.48</td><td>.65</td><td>3.58</td><td>.58</td></tr></table></body></html>

credibility $\mathit { M } = 5 . 0 9$ , $S D = . 8 3$ ), while AI NEST scored highest in learner engagement $M$ $= 3 . 6 8$ , $S D = . 6 5$ ).

# The Role of Social Presence and Instructor Credibility in Learner Engagement

To investigate the role of social presence and instructor credibility in establishing learner engagement, this study conducted linear and multiple regression analysis and causal mediation analysis using 10,000 bootstrap samples. Social presence served as the independent variable (IV), learner engagement as the dependent variable (DV), and instructor credibility as the mediator. The result was assessed based on a $9 5 \%$ confidence interval (CI) (see Table 2). As depicted in Figure 2, for AI instructors, a statistically significant relationship was observed between social presence and learner engagement (Total effect $= . 3 2$ , $p < . 0 5 )$ ) with the relationship mediated by the AI instructors’ credibility $( \mathrm { A C M E } = . 2 0 , p < . 0 5 )$ . The direct effect of social presence on learner engagement was not statically significant $( \mathrm { A D E } = 0 . 1 2$ , $p > . 0 5 ,$ ) after accounting for indirect effects, indicating a full mediation effect of AI instructors’ credibility.

Additionally, to compare AI instructors with human instructors, the mediation effect of instructor credibility in the human instructors’ groups was analyzed. As can be seen in Table 2, concerning human instructors, a statistically significant relationship was found between social presence and learner engagement (Total effect $= . 5 3$ , $p < . 0 5 ,$ ). Unlike AI instructors, this relationship was not mediated by instructor credibility $\begin{array} { r l } { \mathrm { ( A C M E = } } \end{array}$ . $1 0 , p > . 0 5 )$ , suggesting social presence has a direct effect on learner engagement.

# The Impact of Humanness and Nativeness on Instructor Credibility and Learner Engagement

This study examined how humanness and nativeness (IVs) can affect instructor credibility and learner engagement (DVs), using a $2 \times 2$ factorial design MANOVA. Table 3 summarizes the results of the two–way MANOVA analysis.

Regarding humanness, the results revealed no significant differences in instructor credibility and learner engagement between AI instructors and human instructors (Wilks’ $\lambda = . 9 5$ ,

Table 2. Mediation effect analysis of instructor credibility.   

<html><body><table><tr><td></td><td>ACME (95% CI)</td><td>ADE (95% CI)</td><td>Total effect (95% Cl)</td></tr><tr><td>Al</td><td>.20* (.06, .35)</td><td>.12 (.09, .35)</td><td>.32* (.16, .47)</td></tr><tr><td>Human</td><td>.10 (.03, .24)</td><td>.43* (.17, .71)</td><td>.53* (.30, .76)</td></tr></table></body></html>

Note. ACME stands for the average causal mediation effect; ADE measures the average direct effect. $\ast _ { \beta } < . 0 5$ .

![](img/33c42bc5ee74f7818ec45303d6283e2da3f777242ba6ec6d8263da31416ebae0.jpg)  
Figure 2. Simple mediation diagrams of (a) AI instructors and (b) human instructors. Note. a, b, c, and c’ are unstandardized regression coefficients. The estimate of c shows the total effect of social presence on learner engagement. The estimate of c-prime represents the direct effect of social presence on learner engagement. $\ast _ { \beta } < . 0 5$ .

$F ( 2 , 1 1 5 ) = 2 . 9 3 , p > . 0 5 , \eta _ { p } ^ { 2 } = . 0 4$ , observed power $= . 5 6$ ). For nativeness, significant differences were not found in credibility and engagement between NESTs and NNESTs (Wilks’ $\lambda = . 9 8 , F ( 2 , 1 1 5 ) = 1 . 2 3 , p > . 0 5 , \eta _ { p } ^ { 2 } = . 0 \mathrm { { \Omega } }$ , observed power $= . 2 6$ ). Furthermore, there was no interaction effect between humaneness and nativeness on credibility and engagement (Wilks’ $\lambda { = } . 9 9 8$ , $F ( 2 , 1 1 5 ) = . 1 4 $ , $p > . 0 5$ , $\eta _ { p } ^ { 2 } = . 0 0 2$ , observed power $= . 0 7$ ). In summary, the study did not find significant evidence for the influence of humanness and nativeness on instructor credibility and learner engagement.

As this study sought to investigate participants’ general perceptions and engagement of four different instructors, descriptive statistics were further analyzed to corroborate the initial results. Both AI instructors $( M { = } 4 . 8 0$ , $S D { = } . 7 1 $ ) and human instructors $( M = 5 . 0 1$ , $S D = . 8 0 $ ) were perceived to be credible, considering the midpoint of the scale is 4. Similarly, both AI instructors $( M = 3 . 6 3$ , $S D = . 6 1$ ) and human instructors $\mathrm { \Delta } M { = } 3 . 5 3$ , $S D = . 6 5$ ) were rated as engaging. Moreover, both NESTs $( M = 5 . 0 1$ , $S D = . 7 4 )$ and

Table 3. Two-way MANOVA analysis of humanness and nativeness.   

<html><body><table><tr><td>Source of variance</td><td>Wilks&#x27;l</td><td>df</td><td>F</td><td>p</td><td>np</td><td>Observed power</td></tr><tr><td>Humanness</td><td>.95</td><td>2</td><td>2.93</td><td>.06</td><td>.049</td><td>.56</td></tr><tr><td>Nativeness</td><td>.98</td><td>2</td><td>1.23</td><td>.30</td><td>.021</td><td>.26</td></tr><tr><td>Humanness  nativeness</td><td>.998</td><td>2</td><td>.14</td><td>.87</td><td>.002</td><td>.07</td></tr></table></body></html>

Table 4. Pairwise comparison.   

<html><body><table><tr><td></td><td colspan="3">Instructor credibility</td><td colspan="3">Learner engagement</td></tr><tr><td></td><td>Mean difference</td><td>Standard Error</td><td>95% CI</td><td>Mean difference</td><td>Standard Error</td><td>95% Cl</td></tr><tr><td>Human-Al</td><td>.21</td><td>.14</td><td>(.07, .48)</td><td>-.10</td><td>.12</td><td>(.33, .13)</td></tr><tr><td>NEST-NNEST</td><td>.22</td><td>.14</td><td>(.06, .49)</td><td>.11</td><td>.12</td><td>(-.13, .34)</td></tr></table></body></html>

NNESTs $( M { = } 4 . 8 0$ , $S D = . 7 8 )$ tended to be perceived as credible. Likewise, as for engagement, NESTs $\scriptstyle { M = 3 . 6 4 }$ , $S D = . 6 5 )$ and NNESTs $\mathrm { \Delta } M { = } 3 . 5 3$ , $S D = . 6 2 )$ were considered engaging.

As can be seen in Table 4, the results of pairwise comparisons indicated $9 5 \%$ CIs included the value of zero, which also suggests no differences in participants’ perception of credibility and engagement, whether they are taught by humans or AIs, as well as by NESTs or NNESTs.

# Discussion

This study investigated the impact of social presence and instructor credibility on learner engagement in online English classes with AI NEST, AI NNEST, human NEST, and human NNEST. The findings revealed the relationship between social presence and learner engagement was fully mediated by instructor credibility in the presence of AI instructors. Additionally, while the study examined the influence of humanness and nativeness on instructor credibility and learner engagement, no significant effects were found.

Regarding RQ1, as hypothesized, building on the reported mediating role of instructor credibility in Schrodt et al. (2009), the present study observed that instructor credibility mediates the relationship between social presence and learner engagement in AI-led classes. The present study provided insights into the distinct characteristics of AI instructors. Social presence positively influenced learner engagement during lectures delivered by both AIs and humans. However, social presence did not affect engagement after controlling for instructor credibility only in the case of AI. This highlights the significance of instructor credibility in facilitating learner engagement during AI-led classes. With human instructors, regardless of learners’ perception of credibility, learners can still engage in the class if they feel connected to the instructor. Conversely, the positive influence of social presence on engagement is evident only when learners perceive AI instructors as credible, emphasizing the need for further research on strategies to enhance learners’ perceived credibility of AI instructors.

As for RQ2, this study did not support previously reported positive effects of AIs and NESTs on instructor credibility and learner engagement in online English classes. EFL learners’ perceptions of instructor credibility and engagement did not differ between all four groups. Regarding humanness, the characteristics of the AI instructors employed in this study may explain the findings that AI instructors do not induce higher levels of credibility and engagement than human instructors. Compared to research such as Li et al. (2016), the present study employed relatively more human-like AI instructors. However, according to Cornelius et al. (2023), viewers tend to experience confusion or withdrawal when they are informed that a highly human-like virtual human is not a real human—a phenomenon commonly referred to as the uncanny valley. In other words, the mismatch between identity information (i.e., the instructor not being a real human) and its highly human-like visual representation may influence viewers’ perception of virtual humans. Considering this, in the present study, the mismatch could have prevented participants from perceiving the AI instructors as more credible and engaging compared to human instructors.

Alternatively, it can be argued no significant differences exist in instructor credibility and learner engagement between highly developed AI and human instructors. Confidence intervals in pairwise comparisons indicate both types of instructors elicit comparable levels of credibility and engagement, as suggested by Craig and Schroeder (2017). The study found a highly developed AI can be perceived as equally competent as a human, as demonstrated by learners who rated the credibility of the developed AI voice and human voice at similar levels. In the present study, both AI and human instructors are also considered credible, engaging, and possibly equal.

Regarding nativeness, both NESTs and NNESTs are perceived as credible, engaging, and potentially equal. This finding may offer meaningful insights into learners’ perceptions of teachers, who serve as primary and authoritative sources of information in language classrooms. Given that all four instructors’ speeches were perceived as understandable, as indicated by participants’ responses to a questionnaire item on accentedness, the findings suggest the importance of instructors’ comprehensibility over accentedness in learner perception. The high level of speech comprehensibility among NNESTs may have mitigated the potentially advantageous effects of NESTs on credibility and engagement. This postulation finds support in prior studies, although they were conducted in different contexts, necessitating further exploration. Podlipský et al. (2016) reported that the low comprehensibility among nonnative speakers adversely affects native speakers’ judgment on the credibility of non-native speakers’ statements. Isbell et al. (2024) also revealed that speakers with a high level of comprehensibility are likely to be perceived as acceptable in academic settings. Although these two studies focused on native speakers’ perceptions, unlike the present study, their findings partially support the proposition that comprehensibility is a robust factor in determining learners’ perception of non-native language instructors, warranting further research.

In addition to speech comprehensibility, the findings on nativeness can be further explained by considering the context of the present study. In the Korean EFL context, where learners have limited opportunities to encounter instructors from diverse linguistic backgrounds, students’ familiarity with a particular variety may have influenced the results. According to Ahn and Kang (2017), which was also conducted in the higher education setting in the Korean EFL context, English varieties that were found to be familiar to Korean students (e.g., inner circle varieties) tended to be perceived favorably, for instance sounding friendly and correct, further showing a high level of speech comprehensibility. In particular, the study reported that Philippine English is the next highest in familiarity after inner circle varieties, whilst Philippine English is perceived as friendlier and more correct than most of the outer/expanding circle varieties (e.g., Indian English and Italian English). In this light, the present study’s results support the findings of Ahn and Kang (2017) in that this study showed Philippine English-speaking teachers and North American English-speaking teachers elicited similar perceptions, especially in terms of credibility (e.g., the language teacher being competent or approachable). Given that familiarity with a language variety can function as an important variable in speech comprehensibility and learner perception, future studies can compare languages with varying degrees of familiarity in local contexts (e.g., in the Korean context, comparing North American English, Indian English, and Nigerian English). In particular, beyond the traditionally used model of the inner/outer/expanding circle proposed by Kachru (1985), it would be worth considering the familiarity with English varieties to provide a more contextualized understanding of the roles of instructors’ linguistic backgrounds in learner perceptions and engagement.

# Conclusion

This study aimed to investigate the mediating role of instructor credibility in linking social presence with learner engagement when instructed by AI as opposed to human instructors in an online EFL class. This study revealed the mediating role of AI instructors’ credibility between social presence and engagement as a distinct characteristic of AI-led lectures. These findings highlight the importance of instructor credibility in making AI-led lectures engaging. Furthermore, the influence of instructor types, considering the level of humanness and nativeness, on instructor credibility and learner engagement was examined. The findings suggest all four instructors are perceived as credible, engaging, and potentially equivalent.

The results of the present study should be considered with caveats and limitations. First, the participants were limited to Koreans. Thus, findings may not be generalizable to a broader population in other contexts. For example, English learners in an ESL context or multilingual societies may have different perceptions of the nativeness of a teacher. Furthermore, this study focused on comparing only two types of instructors from North America and the Philippines. Examining different English varieties with a varying degree of familiarity in local contexts could yield more fruitful insights. Lastly, the manipulation period might not have been long enough for learners to fully perceive social presence and learner engagement. Similarly, regarding instructor credibility, the goodwill dimension such as understanding may not have been fully perceived, since students had limited opportunity to be exposed to the instructors. Building upon this study, research comparing AI and humans in a real classroom setting (e.g., teaching hour-long lessons over several months) would provide a more comprehensive understanding of learner perceptions of AI-led lectures.

Nonetheless, this study provides implications for L2 educators and researchers investigating AI instructors, instructor credibility, and learner engagement. For future research, given the increasing feasibility of AI instructors, further investigation of credibility would offer new possibilities to enhance learner engagement. Additionally, when exploring instructor credibility and learner engagement, researchers should consider variables other than humanness and nativeness, such as instructors’ L2 comprehensibility. Moreover, leveraging AI instructors offers the benefits of convenience and cost-effectiveness, as AI-led lectures do not entail energy-consuming processes such as editing or reshooting. Meanwhile, it is hoped that the present study augments our understanding of AI instructors.

Ongoing research endeavors are expected to further elucidate the potential of AI instructors, which will open up new horizons in language education.

# Declaration of Generative AI and AI-assisted Technologies in the Writing Process

During the preparation of this work, the author used ChatGPT in order to edit the language and improve readability. After using the service, the author reviewed and edited the content as needed and takes full responsibility for the content of the publication.

# Author’s Note

Seungeun Lee is also affiliated with University of Hawaiʻi at Mā noa, United States.

# Funding

The author received no financial support for the research, authorship, and/or publication of this article.

# ORCID iD

Seungeun Lee $\textcircled{1}$ https://orcid.org/0009-0009-2110-4304

# Notes

1. Building upon the categorization by Kachru (1985), the present study associated native English varieties with “the inner circle” (e.g., the United States), while non-native English varieties are linked to “the outer circle” (e.g., the Philippines) and “the expanding circle” (e.g., South Korea).   
2. For the present study, the sample size $( n = 1 2 0 )$ ) was deemed appropriate based on a prior power analysis, which Plonsky (2013) suggested conducting to ensure sufficient observed power and identify a minimum sample size. As Nicklin and Vitta (2021), the priori power analysis was conducted using $\mathrm { G ^ { * } }$ Power (Faul et al., 2007), setting the Type I (α) error probability threshold at 0.05; and the power at 0.80. With the effect size set to medium, the results suggested that the minimum sample size of a $2 \mathbf { x } 2$ MANOVA analysis would be 98 participants. Exceeding the minimum sample size, given the central limit theorem, 30 participants for each group were recruited, resulting in a total of 120 participants for this study.   
3. The distinction between native and non-native speakers in English education can be a topic of contention. However, currently, there are no widely accepted alternatives to address this distinction. It is important to note the use of the native speaker label should be approached critically and with awareness of its limitations (Isaacs and Rose, 2022).   
4. While developing the three dimensions (i.e., competence, trustworthiness, and goodwill) of credibility, McCroskey and Teven (1999) combined the dimensions into a single measure to calculate an overall credibility score. This single composite measure showed high correlations with each dimension, with it having a high level of alpha reliability. Therefore, for this study, it was deemed reasonable to treat instructor credibility as one composite construct and use the overall credibility score, as in previous studies (e.g., Derakhshan, 2021).   
5. Although the social presence data did not pass the Shapiro-Wilk test for normality, the current study employed a parametric approach for the following reasons. Ernst and Albers (2017) recommended using graphical methods, such as Q-Q plots, to assess normality rather than relying solely on formal tests like the Shapiro-Wilk test. Also, the regression model is robust to violations of normality, as long as other assumptions such as homoscedasticity are

met (Williams et al., 2013). Considering the graphic normality and the robustness of regression, a parametric approach was deemed reasonable for analyzing social presence data.

References   
Ahn S-Y and Kang H-S (2017) South Korean University students’ perceptions of different English varieties and their contribution to the learning of English as a foreign language. Journal of Multilingual and Multicultural Development 38(8): 712–725.   
Allard A and Holmstrom AJ (2023) Students’ perception of an instructor: The effects of instructor accommodation to student swearing. Language Sciences 99: 101562.   
Amerstorfer CM and Freiin von Münster-Kistner C (2021) Student perceptions of academic engagement and student-teacher relationships in problem-based learning. Frontiers in Psychology 12: 713057.   
An X, Chai CS, Li Y, et al. (2023) Modeling students’ perceptions of artificial intelligence assisted language learning. Computer Assisted Language Learning. DOI: 10.1080/09588221.2023.2246519.   
Biocca F, Harms C and Burgoon JK (2003) Toward a more robust theory and measure of social presence: Review and suggested criteria. Presence: Teleoperators and Virtual Environments 12(5): 456–480.   
Cornelius S, Leidner D and E and Benbya H (2023) Credibility of virtual influencers: The role of design stimuli, knowledge cues, and user disposition. In: Proceedings of the 56th Hawaii International Conference on System Sciences (ed TX Bui), Honolulu, US, 3-6 January 2023, pp. 3401–3410. Honolulu: Hawaii International Conference on System Sciences.   
Craig SD and Schroeder NL (2017) Reconsidering the voice effect when learning from a virtual human. Computers and Education 114: 193–205.   
Derakhshan A (2021) The predictability of Turkman students’ academic engagement through Persian language teachers’ nonverbal immediacy and credibility. Journal of Teaching Persian to Speakers of Other Languages 10(21): 3–26.   
Do TD, Akter M, Choudhary Z, et al. (2022) The effects of an embodied pedagogical agent’s synthetic speech accent on learning outcomes. In: ICMI ’22: International conference on multimodal interaction (eds R Tumuluri et al.), Bengaluru, India, 7–11 November 2022, pp.198- 206. New York: Association for Computing Machinery.   
Ernst AF and Albers CJ (2017) Regression assumptions in clinical psychology research practice— A systematic review of common misconceptions. PeerJ 5(e3323): 1–16.   
Faul F, Erdfelder E, Lang A-G, et al. (2007) G\*Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences. Behavior Research Methods 39(2): 175–191.   
Greene BA (2015) Measuring cognitive engagement with self-report scales: Reflections from over 20 years of research. Educational Psychologist 50(1): 14–30.   
Hanzlíková D and Skarnitzl R (2017) Credibility of native and non-native speakers of English revisited: Do non-native listeners feel the same? Research in Language 15(3): 285–298.   
Hiver P, Al-Hoorie AH, Vitta JP, et al. (2024) Engagement in language learning: A systematic review of 20 years of research methods and definitions. Language Teaching Research 28(1): 201–230.   
Huang TH and Wang LZ (2021) Artificial intelligence learning approach through total physical response embodiment teaching on French vocabulary learning retention. Computer Assisted Language Learning 36(8): 1608–1632.   
Isaacs T and Rose H (2022) Redressing the balance in the native speaker debate: Assessment standards, standard language, and exposing double standards. TESOL Quarterly 56(1): 401–412.   
Isbell DR, Crowther D and Nishizawa H (2024) Speaking performances, stakeholder perceptions, and test scores: Extrapolating from the Duolingo English test to the university. Language Testing 41(2): 233–262.   
Jiang Y and Peng JE (2023) Exploring the relationships between learners’ engagement, autonomy, and academic performance in an English language MOOC. Computer Assisted Language Learning. DOI: 10.1080/09588221.2022.2164777.   
Kachru BB (1985) Standards, codification and sociolinguistic realism: The English language in the outer circle. In: Quirk R and Widdowson HG (eds) English in the World: Teaching and Learning the Language and Literatures. Cambridge: Cambridge University Press, pp.11–30.   
Kim J, Merrill K Jr , $\mathrm { X u K }$ , et al. (2022) Perceived credibility of an AI instructor in online education: The role of social presence and voice features. Computers in Human Behavior 136: 107383.   
Lasagabaster D and Sierra JM (2002) University students’ perceptions of native and non-native speaker teachers of English. Language Awareness 11(2): 132–142.   
Lee BJ and Bailey JL (2023) Assumptions of speaker ethnicity and the effect on ratings of accentedness, comprehensibility, and intelligibility. Language Awareness 32(2): 301–322.   
Lee KM, Peng W, Jin S-A, et al. (2006) Can robots manifest personality? An empirical test of personality recognition, social responses, and social presence in human–robot interaction. Journal of Communication 56(4): 754–772.   
Lee S and Jeon J (2024) Visualizing a disembodied agent: Young EFL learners’ perceptions of voice-controlled conversational agents as language partners. Computer Assisted Language Learning 37(5–6): 1048–1073.   
Li J, Kizilcec R, Bailenson J, et al. (2016) Social robots and virtual agents as lecturers for video instruction. Computers in Human Behavior 55: 1222–1230.   
Li L (2022) Students’ isolation challenges in blended EFL learning during COVID-19: How can social presence and interaction help develop sense of community? Psychology Research and Behavior Management 15: 3117–3131.   
McCroskey JC and Teven JJ (1999) Goodwill: A reexamination of the construct and its measurement. Communication Monographs 66(1): 90–103.   
Nicklin C and Vitta JP (2021) Effect-driven sample sizes in second language instructed vocabulary acquisition research. The Modern Language Journal 105(1): 218–236.   
Pi Z, Deng L, Wang X, et al. (2022) The influences of a virtual instructor’s voice and appearance on learning from video lectures. Journal of Computer Assisted Learning 38(6): 1703–1713.   
Plonsky L (2013) Study quality in SLA: An assessment of designs, analyses, and reporting practices in quantitative L2 research. Studies in Second Language Acquisition 35(4): 655–687.   
Podlipský VJ, Šimáč ková Š and Petráž D (2016) Is there an interlanguage speech credibility benefit? Topics in Linguistics 17(1): 30–44.   
Rezvani R and Miri P (2021) The impact of gender, nativeness, and subject matter on the English as a second language university students’ perception of instructor credibility and engagement: A qualitative study. Frontiers in Psychology 12: 702250.   
Santilli V, Miller AN and Katt J (2011) A comparison of the relationship between instructor nonverbal immediacy and teacher credibility in Brazilian and U.S. classrooms. Communication Research Reports 28(3): 266–274.   
Schrodt P, Witt PL, Turman PD, et al. (2009) Instructor credibility as a mediator of instructors’ prosocial communication behaviors and students’ learning outcomes. Communication Education 58(3): 350–371.   
Short J, Williams E and Christie B (1976) The Social Psychology of Telecommunications. London: Wiley.   
Suarta IM, Noortyani R, Yarsama K, et al. (2022) The role of teachers’ indigenous knowledge and cultural competencies in enhancing students’ engagement and learning outcomes. Journal of Ethnic and Cultural Studies 9(1): 244–264.   
Sun Y, Shi W and Fu L (2023) Improving Chinese EFL learners’ engagement in online classes: the role of teacher scaffolding and teacher respect. Journal of Multilingual and Multicultural Development. DOI: 10.1080/01434632.2023.2180009.   
Teo T, Khazaie S and Derakhshan A (2022) Exploring teacher immediacy-(non)dependency in the tutored augmented reality game-assisted flipped classrooms of English for medical purposes comprehension among the Asian students. Computers and Education 179: 104406.   
Walkinshaw I and Oanh DH (2014) Native and non-native English language teachers: Student perceptions in Vietnam and Japan. SAGE Open 4(2): 1–9.   
Wang MT, Fredricks JA, Ye F, et al. (2016) The math and science engagement scales: Scale development, validation, and psychometric properties. Learning and Instruction 43: 16–26.   
Williams MN, Grajales CAG and Kurkiewicz D (2013) Assumptions of multiple regression: Correcting two misconceptions. Practical Assessment, Research & Evaluation 18(11): 1–14.   
Yang H, Kim H, Lee JH, et al. (2022) Implementation of an AI chatbot as an English conversation partner in EFL speaking classes. ReCALL 34(3): 327–343.   
Yu Z and Gao M (2022) Effects of video length on a flipped English classroom. SAGE Open 12(1): 1–14.   
Zheng J (2021a) A functional review of research on clarity, immediacy, and credibility of teachers and their impacts on motivation and engagement of students. Frontiers in Psychology 12: 712419.   
Zheng J (2021b) The role of Chinese EMI teachers’ clarity and credibility in fostering students’ academic engagement and willingness to attend classes. Frontiers in Psychology 12: 756165.   
Zhong Q, Wang Y, Lv W, et al. (2022) Self-regulation, teaching presence, and social presence: Predictors of students’ learning engagement and persistence in blended synchronous learning. Sustainability 14(9): 5619.

# Appendix

A. Social presence measurement

<html><body><table><tr><td>Items</td></tr><tr><td>1. During the lecture, I felt as if I were interacting with an intelligent being.</td></tr><tr><td>2. During the lecture, I felt as if I were accompanied by an intelligent being.</td></tr><tr><td>3. During the lecture, I felt as if I were alone..</td></tr><tr><td>4. I paid attention to the instructor during the lecture..</td></tr><tr><td>5. During the lecture, I felt involved with the instructor.</td></tr></table></body></html>

B. Instructor credibility measurement

# Items

# Trustworthy (Cronbach's alph $\mathbf { \lambda } _ { \mathbf { \lambda } ^ { 1 } } = \mathbf { \lambda } _ { \mathbf { \lambda } _ { \mathbf { \lambda } } 6 9 6 }$

1. The instructor was phoney/genuine.   
2. The instructor was honest/dishonest.   
3. The instructor was unethical/ethical.   
4. The instructor was untrustworthy/trustworthy.

# Competence (Cronbach's alpha $\mathbf { \tau } = . 7 4 9$ )

1. The instructor was incompetent/competent.   
2. The instructor was informed/uninformed..   
3. The instructor was an inexpert/expert.   
4. The instructor was intelligent/unintelligent.   
5. The instructor was untrained/trained.   
6. The instructor was bright/stupid.

# Goodwill (Cronbach's alpha $\mathbf { \varepsilon } = . 7 8 \mathbf { 0 } _ { \perp }$

1. The instructor was insensitive/sensitive.   
2. The instructor was not understanding/understanding   
3. The instructor cared about me/didn't care about me   
4. The instructor had my interests at heart/didn't have my interests at heart.   
5. The instructor was concerned with me/unconcerned with me.

C. Learner engagement measurement

# Items

# Behavioral engagement (Cronbach's alpha $=$ .764)

1. When I couldn't understand in this English idiom lecture, I stayed focused until I did.   
2. I paid attention and listened carefully during this English lecture.   
3. If I didn't understand during the lecture, I gave up right away..   
4. I kept trying even if something was hard during the lecture..   
5. I put effort into learning English idioms.

# Cognitive engagement (Cronbach's alpha $= . 7 2 3$

1. During the lecture, I tried to understand my mistakes when my understanding was wrong.   
2. When work was hard during the lecture, I only studied the easy parts.   
3. I went through the work for this English lecture and made sure that it was right   
4. During the lecture, I tried to connect what I was learning to things I had learned before.   
5. I didn't think that hard when I was doing work for this lecture.   
6. I thought about different ways to memorize idioms that I just learned.

# Emotional engagement (Cronbach's alpha $\mathbf { \delta } = . 8 4 1 $ )

1. I thought that this English lecture was boring.   
2. I enjoyed learning new things about English during the lecture.   
3. I often felt down when I was in this English lecture.   
4. I didn't want to be in this English lecture.   
5. I looked forward to joining this English lecture.   
6. I wanted to understand what was learned in this English lecture.   
7. I felt good when I was in this English lecture.   
8. I didn't care about learning English during the lecture..   
9. I often felt frustrated in this English lecture.   
10. I got worried when I learned new things about English in the lecture.

D. Boxplots of (a) social presence, (b) instructor credibility, and (c) learner engagement

![](img/72b2178c6be52dce26c7d07accc5b8658a03f30fb6bba81e2d73fc87486e5eb5.jpg)![](img/141b58da3e7c7fe5547204d46a171369b32bbfa586c60f431873bbf7815caa7f.jpg)