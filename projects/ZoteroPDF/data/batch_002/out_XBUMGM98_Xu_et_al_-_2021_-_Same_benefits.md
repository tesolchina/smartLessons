# UC Irvine

# UC Irvine Previously Published Works

# Title

Same benefits, different communication patterns: Comparing Children's reading with a conversational agent vs. a human partner

Permalink https://escholarship.org/uc/item/7544r8x5

# Authors

Xu, Ying   
Wang, Dakuo   
Collins, Penelope et al.

Publication Date 2021-02-01

DOI 10.1016/j.compedu.2020.104059

Peer reviewed

# Same benefits, different communication patterns: Comparing Children's reading with a conversational agent vs. a human partner

Ying Xua,\*, Dakuo Wangb, Penelope Collinsa, Hyelim Lee a, Mark Warschauer?

a School of Education, University of California, Irvine, USA b IBM Research AI, Cambridge, USA

# ARTICLEINFO

# ABSTRACT

Keywords: Conversational agents Language development Storybook reading Communication Young children

Storybook reading accompanied by adult-guided conversation provides a stimulating context for children's language development. Conversational agents powered by artificial intelligence, such as smart speakers, are prevalent in children's homes and have the potential to engage children in storybook reading as language partners. However, little research has explored the effectiveness of using conversational agents to support children's language development. This study examined how an automated conversational agent can read stories to children via a smart speaker while asking questions and providing contingent feedback. Using a randomized experiment among 90 children aged three to six years, this study compared these children's story comprehension and verbal engagement in storybook reading with a conversational agent versus an adult. The conversational agent's guided conversation was found to be as supportive in improving children's story comprehension as that provided by an adult language partner. At the same time, this study uncovered a number of differences in children's verbal engagement when interacting with a conversational agent versus with an adult. Specifically, children who read with the conversational agent responded to questions with better intelligibility, whereas those who read with an adult responded to questions with higher productivity, lexical diversity, and topical relevance. And the two groups responded to questions with a similar level of accuracy. In addition, questions requiring high cognitive demand amplified the differences in of verbal engagement between the conversational agent and adult partner. The study offers important implications for developing and researching conversational agent systems to support children's language development.

Children's development of language skill in preschool years has a profound impact on their later iteracy proficiency and overal academic succes. Early language skils center on the ability to understand and convey meaning in oral language form (Kim, 2017; Kim, Park, & Wagner, 2014). Extensive research shows that children's development of language skill begins in homes long before children start formal intruction (Fan, Antle, Hoskyn, Neustaedter, & Cramer, 2017; Gest, Freman, Domitrovich, & Welsh, 2004; Roth, Speece, & Cooper, 2002; Whorrll & Cabell, 2016). Storybook reading by family members, typically parents, provides a comfortable environment for stimulating children's language skills. During storybook reading, parents sit together with and read to their children, ideally engaging the children in guided conversation where parents serve as children's language partner by posing questions and providing responsive fedback (Golinkoff, Hoff Rowe, Tamis-LeMonda, & Hirsh-Pasek, 2019; Lever & Senechal, 2011). This kind of guided conversation substantially amplifies the learning benefits associated with storybook reading for a review, see Mol, Bus, de Jong, & Smees, 2008). However, parents may not always have the language skill, time, or inclination to engage in such conversation-rich storybook reading with their children (Cooter, 2006; Manz, Hughes, Barnabas, Bracaliello, & Ginsburg-Block, 2010; Zevenbergen & Whitehurst, 2003).

In recent years, researchers believe intelligent systems with a conversational interface' can potentially provide children with additional language learning opportunities, as they have become increasingly powerful and are capable of simulating some interpersonal communications. A growing body of research has developed conversational inerfacesthat can engage children in a variety of conversations as part of the experience see Belpame, Knnedy, Ramachandran, casellti  Tanaka, 2018; Kenedy, Baxter, Senft, & Belpame, 2016, for review). Some intelligent systems developed in these studies can perform storybook reading tasks adaptable to a child's language level (e.g., Kory & Breazeal, 2014; Kory, Jeong, & Breazeal, 2013); others can employ game-like interactions for vocabulary and language learning (e.g., Freed, 2012; Movellan, Eckhardt, Virnes, & Rodriguez, 2009). Studies have demonstrated the feasibility and educational potential of intellgent systems as language partners (Gordon, Spaulding, Westlund, Le, Plummer, Mar. tinez et al., 2016; Kanero et al., 2018; Kory & Breazeal, 2014).

Most f the intelligent systems in existing studies have an embodied representation as a virtual avatar (Mack, Cummings, Rembert & Gilbert, 2019; Pauchet et al., 2017) or as a physical robotic body (Belpame et al., 2018; Free, 2012; Movellan et al., 2009; ory & Breazeal, 2014; Shamekhi, Lia0, Wang, Bellamy, & Erickson, 2018). These experimental systems are ften designed for narrowly specifi scenarios (e.g, robot to teach food related French vocabularies; Freed, 2012), and thus are rarely adopted by the general public (de Graf, Ben Allouch, & van Dij, 2017; Jacques, Folstad, Gerber, Grudin, Luger, Monroy- Hernandez, & Wang, 2019). On the contrary, conversational agents (CAs) in a smart speaker form, such as Google Home and Amazon Echo, are already used by many families as consumer-oriented voice asstants (Brush, Hazas, & Albrecht, 2018). According to areport, over 150 million households in the U.S. owned smart speakers in early 2020 (Kinsella, 2020). Studies have found that children enjoy their spontaneous interactions with CAs in their homes; children initiated questions (e.g., "Hey Google, does unicorn exist?"; Lovato, Piper, & Wartell, 2019) or commanded CAs to perform small tasks (e.g., Hey Alexa, play a Christmas song"; Sciuto, Saini, Forlizz, & Hong, 2018). Despite the popularity of these affordable and versatile smart speakers, litle research has been carred out to build CA systems based on smart speakers to support children's language development. Therefore, the ultimate objective of this research is to examine the potential of fully automated CAs in the form of a widely-adopted smart speaker that engages children in guided converstion i storybook reading (Blewitt, Rump, Shealy, & Cook, 2009; Chien, 2013; Zhou & Yadav, 2017).

# 1. Related work

# 1.1. Storybook reading with guided conversations for Children's language learning

Storybook reading is an effective way of fostering children's language development in their early years (Bus, 2001; Change & Huang, 2016; Yen, Y. Chen, Cheng, S. Chen, Y-Y. Chen, Ni, & Hiniker, 2018). For young children who are not able to decode text independently, storybook reading typicall involves them listening to thir parents reading out loud apicture book while loking at images. This activity cultivates young children's aility to comprehend oral narratives, thus laying the foundation for understanding the more complex text in higher grade levels. Storybook reading by parent, such as bedtime stories, is a highly routinized activity engaged in by families across cultures (Shanahan & Lonigan, 2010).

In its basic form, storybook reading involve children merely listning to their parents reading the text verbatim (Lenhart, Lenhard Vaahtoranta, & Suggate, 2018). But this form can be enriched with aditional interacive strategies. One efective interactive tratey is to engage children in guided conversation (Zevenbergen & Whitehurst, 2003), in which parents ask children prepared questions and provide responsive feedback with a goal of stimulating children's active participation in the reading process. Through back-and-forth conversation, children rflect on and vocally expres their understanding of the story. A meta-analysis that reviewed 16 studies has suggested an added value on children's language development resulting from incorporating guided conversation in storybook reading activities (Mol et al., 2008).

Specifically, researchers believe that guided conversation benefits both children's story comprehension as well as verbal engagement during the torybook reading activity (Vukelich, 1976). In these studies, sory comprehension is typicall asessed by a battery of questions developed specificall for a story. For example, Lever and Senechal found that children who had guided conversation with an experimenter performed significantl better in retelling tory elements than those who were not asked any questions during the storybook reading (Lever & Senechal, 2011). When analyzing children's verbal engagement in guided conversation, researchers commonly focus on the quality of children'sresponses to questions asked by parents along one or more of the five aspects, namely language prodctivity, lexical diversty, toical rlevane, accuracy, and intelligbility (Westrveld & Robert, 2017). A study, for example, suggested that children were more engaged in a guided conversation, as indicated by greater quantity and topical relevance in their responses, if they had higher language proficiency (Westerveld & Roberts, 2017). These prior studies have established useful metrics for evaluating the effctiveness of guided conversation, which guides the development of measures used in this study.

Some studies have investigated the types of questions parents asked in a storybook reading exercise (Birbili & Karagiorgou, 2009) In general, studies suggest that parents should ask questions at different cognitive demand levels (Blewitt et al., 2009). Low-cognitie-demand questions typicall revolve around a specific sory fact and high-cognitive-demand questions require children to make predictions and inferences based on information that is only implict in the text. The diffrent cognitive processes required to answer low- and high-demand questions lead to specific patterns in children's verbal engagement (Raphael, 1986). For example, a study found that the children's responses to low-cognitive-demand questions are more concise and simpler than those to a high-cognitive-demand question (Raphael, Highfield, & Au, 2006). This ifferential patten has sugested that rearchers should take questions' cognitive demand level into consideration when designing and evaluating CAs that engage children in story-related dialogues.

In summary, traditional research suggests that an effctive reading partner can increase children's language development through engaging children in guided conversation. Yet, this kind of guided conversation is not as common as may have been expected: Parents do not always pause the story, ask questions, and comment on their children's response. This could be due to parents either ssuming their child can learn well enough by simply listening to parent reading, or lacking the skils or time to incorporate such interactive opportunities (Golinkoff, Hoff, Rowe, Tamis-LeMonda, & Hirsh-Pasek, 2019). The recent development of intelligent systms with voice interfaces that can carry out natural conversation may provide an alternative approach to enrich children's in-home reading experiences.

# 1.2. Embodied intelligent systems as Children's language learning partners

Using embodied intelligent systems, both robots and virtual avatars, to enhance children's language learning through a voice interface has been a popular rearch topic n recent years (Papadopoulos et l., 2020). A number of intiatives have developed robotic intelligent systems to carry out structured language learning activities. For example, Kory and Breazeal (2014) developed a robotic learning companion for preschool children's oral language development. The robot was designed to tell children stories with different vocabulary complexities and teach children these words. The study found that children learned the vocabulary words that the robot had introduced in their conversation. Michaelis and Mutlu (2017) implemented a robot that was designed to make pre-programmed comments at particular points in a story as a child read aloud. Another group of researchers developed a robotic intelligent agent to support children's French language learning (Freed, 2012). The robot played a food-selection game with children and then talked about that food item with the children in French. The study found that this game-like conversation helped children learn these French words (Freed, 2012). Some other projects have developed intelligent agents embodied in avatars. Allen and colleagues utilized an avatar agent to speak with students in authentic situations, with a goal of improving students' comprehension, pronunciation, and vocabulary in a foreign language (Allen, Divekar, Drozdal, Balagyozyan, Zheng, Song et al., 2019). Authors incorporated an agent in a children's science animation series to teach children scientific vocabularies, and this agent was embodied in the series main character (Xu & Warschauer, 2020d).

In addition to this prior work contributing to system development, other studies have evaluated the efectivenessof embodied intelligent systems in children's learning context by comparing systems' performance with human learning partners. In terms of learning outcomes, for example, Westlund and cllagues found that children learn unfamiliar words equally well whether with a robot or with a human interlocutor (Westlund et al., 2017). Hong and colleagues also suggested that incorporating a robot teaching assistant in a classroom led to students' similar level of reading and writing improvement as compared to having a human assistnt (Hong, Huang, Hsu, & Shen, 2016). In terms of children's verbal engagement with intellgent systems, for example, Hyde and colleagues found that children produced a comparable amount of uttrances whether their on-screen conversation was with another human or with an avatar whose speech was operated by an experimenter (Hyde, Kiesler, Hodgins, & Carter, 2014). Tewari and Canny found in their study that children produced even more utterances that were relevant when playing a game with an animal character agent as compared to children playing a game with a familiar human (Tewari & Canny, 2014). They speculated that children's high-level language productions with this particular agent may stem from the more immersive experience of conversing directly with the game's character.

However, these aforementioned embodied systems relied heavily on non-verbal communication (e.g, eye gaze, body orientation) or anthropomorphism features (Tan, Wang, & Sabanovic, 2018) to engage children in learning activitie, and these features are not supported by CAs. Despite many studies suggesting that embodied systems' non-verbal cues help establish social relationships with learners and thus positively affect learning (e.g., Gordon et l., 2016; Kennedy et al., 2016) such non-veral behaviors may also place more cognitive load on the chldren, which may inhibit children's capacity to proces information related to the learning and concentrate on the conversation (Kenedy, Baxter, & Belpaeme, 2015). These two results lead to conflicting hypothese regarding how the effectiveness of disembodied CAs without non-verbal capacity may compare to that of embodied systems.

# 1.3. Disembodied conversational agents (CAs) and Child-CA interaction

The research on children's interaction with smart speakers has been growing due to these device increasing prevalence in many households over the past few years. These studies utilized various methodologies, including parent or child interviews, observations, diary instruments, or in-home audio recordings, and the majority of them focused on unstructured conversations initiated by children with general voiceassistant tools (., Amazon Alexa, Google Assistant, Apple Siri). In general, studies found that children commonly either command the voice asistant to perform specific tasks or ask questions to receive answers (Lovato & Piper, 2019). For example, through analyzing audio recordings of children talking with the smart speakers deployed in their home, Beneteau and colleagues categorized childen's intractions into thre themes, namely entertainment, astace, and information seeking (Bntau, Rchads, Zhang, Kientz, Yip, & Hiniker, 2020). This categorization scheme was echoed in Lovato's survey study (Lovato & Piper, 2015) and in Garg's study combining interviews with user log data (Garg & Sengupta, 2020a). Another study conducted by Lovato and colleagues specifically focused on children's information seeking behaviors with smart peakers and found that children turned to the CAs for information on a variety of topics, including language, culture, science, and math (Lovato et al., 2019). Although the CA studies reviewed above did not involve educational systems tailored for age-appropriate learning, they still indicated some learning opportunities for children as children initiated conversations with CAs (Garg & Sengupta, 2020b).

In addition to exploring how children readily use CAs, some studies also investigate how children perceive CAs. At least two studies have found that children generally perceive CAs as having cognitive ability; children in both studies indicated that the CAs they interacted with were "smart" and \*knowledgeable" (Xu & Warschauer, 2020c); Druga, Williams, Breazeal, & Resnick, 2017). Children in these two studies also perceived CAs as "friendly," truthful," and sociable companions (Xu & Warschauer, 2020c); Drug et al., 2017).

Nevertheless children were found to sometimes encounter challenges when they interact with CAs. Some children were not aware that smart speakers can not capture or interpret non-verbal expression; thus they attempted to use both verbal and non-verbal communication when responding to the CA. As CAs could not register the non-verbal responses, the conversation flow may have suffered. However, the CAs' reliance on speech may actually be positive, since this reliance once undersood by children- encourages children to practice verbal communication that is vital for their language development Xu & Warschauer, 2020b. Indeed, two studies found that preschool-aged children made eforts to have thir speech understod by CAs; they adjusted sentence structures, modified word choice, or spoke more articulately (Beneteau et al., 2019; Cheng, Yen, Y. Chen, S. Chen, & Hiniker, 2018)

Research on children's interactions with CAs shows that CAs are being seamlessly integrated into children's lives and into the family unit. This favorably positions CAs to be adapted to engage children in focused leaning experiences. Indeed, an emerging yet limited body of research develops smart speaker CAs to support specific language learning goals (Smutny & Schreiberova, 2020). Most of these studies leveraged CAs to teach adults foreign languages (Fryer, Ainley, Thompson, Gibson, & Sherlock, 2017; X. L. Pham, T. Pham, Q. M Nguyen, T H. Nguyen, & Cao, 2018), yet more research is needed to understand how young children respond to learning activities scaffolded by CA partners.

# 1.4. Research questions

This project focus on the design of a CA that can engage with children in a guided conversation in storybook reading and the evaluation of th effectivenes of ths stem. The evaluation is guided by two sets of questions that focus on childrens comprehension after reading and verbal engagement during reading:

![](img/05a0e455280964c98ab73f873767e1b9a57e31b45c43b283aad41c9686171b7a.jpg)  
Dialogue Flow Design of the CA's Guided Conversation Module   
Fig.1. Dialoue Flow Deign of th As Guided Converatio Module, Note. A pause at particuar points of the story, as a question,clasfies the child's reonse, and select  feback eponse for the child. We zoom i to the four intent catries only for Quetion 1. I tol here are nine questions.

Note. CA pauses at particular points of the story, asks a question, classifies the child's response, and selects a feedback response for the child. We zoom in to the four intent categories only for Question 1. In total there are nine questions.

RQ1: Does guided conversation with the CA improve children's story comprehension? If so, how does this improvement compare to that resulting from conversing with a human partner?   
RQ2a: Do children's verbal engagement behaviors with a human partner resemble or iffer from their behaviors with a CA partner? RQ2b: Does the similarity or diffrence in verbal engagement with a CA versus human partner apply to both low- and highcognitive-demand questions?

# 2. Development of the CA reading partner

The automated CA system was developed to simulate the dialogue flow of a human conversational partner. The system is built upon Dialogflow open source client library (Google Cloud, 2020). The CA's natural language understanding module was based on a generic pretrained model built in the Dialogflow engine, then retained with training utterances specific to the CAs conversation context (Le, 2018; Sabharwal & Agrawal, 2020, pp. 13-54). These training utterances were collcted from a pilot study of what children might say as a response to a particular question prompt. The CA was then able to learn from a small set of training utterances and naturally expand them to many more similar phrases so that the intent of children's verbal responses can be accurately captured and classified.

The CA engages children in a fantasy story Three Bears in a Boat authored by David Soman. This story was chosen because of the appropriate level of narrative complexity for the age group and potential story interest. To eliminate the confounding effects of the CA with the efects of voice quality (Cambre & Kulkarni, 2019; O'Neal et al., 2019), the CA used a female recorded voice instead of machine synthetic voice.

Nine open-ended questions were asked throughout the storytelling. Six of these were low-cognitive-demand questions, while the other three were high cognitive-demand questions. For example, the following is a paragraph from the story: \*One day, when their mother was out, the three bears did something they really shouldn't have, and with acrash, their mother's beautiful blue seashell lay scattered in pieces across the floor." A low-cognitive-demand question asked, \*What did the bears break?" And the answer to that question was seashell, which was found directly in the text. A high-cognitive-demand question asked children to make an inference based on the given information in the story or to summarize the information (e.g., "How did the bears search for the seashell?)

The CA performs end-to-end language processing that transcribes children's voice input into text uttrance, classfies the utter ance's intent, and selects a response to that intent. As indicated in Fig. 1, for each of the nine questions, four intent categories were defined toclassify a childs response uterances. These four categories were (1) a set of intents for correct answers, (2) a set f intents for incorrect answers, (3) an intent for when children explicitly expressthir inabilit to answer a question, and (4) an intent category for classfying all other intents (e.g., a child does not respond to the question at all or provides an off-topic response). For each intent within each question, there could be many variations of utterances that contained similar semantic meaning. After clasifying a child's responses as belonging to one of the intents, the agent then provided diffrential feedback that specifically addressed that response.

The CA's language model was optimized during a three-round field testing involving 20 children. These children's various responses to the CA's nine pre-defined questions were collcted. For example, the correct answers to the question \*What do you think is going to happen with the weather?" describe inclement weather. Possble answers to the question may be "Stormy", "Bad', "Windy" "Rainy", etc. and thus these intents were created in the initial CA However, during the pilo run, children were aso found to commonly refer to the inclement weather as being scary (e.g., It's kind of scary."; The bears are afraid of this weather."; \*The bears are too scared and they closed their eyes."). Thus, "Scary'" was added as another intent to capture this group of utterances. This iterative process asted three rounds, and the agent achied an inter-rater reliabilit with a human coder of 0.8, asesed by Cohen's Kappa A Cohen's Kappa above 0.80 has been considered as excellent agreement (McHugh, 2012).

# 3. Method

This section describes the experimental design, measures, and participants of the study.

# 3.1. Experimental design

This study used a three-condition between-subject experimental design, where participants were randomly assigned to one of the three conditions:

. Human-Story' where children were read a story by a human partner without any guided conversation; Human-Conversation' where children were read the same story, plus engaged in guided conversation with a human partner or "CA-Conversation' where children were read the same story, and engaged in the same guided conversation with the CA.

In all conditions, children met individually with a trained human experimenter in a designated quiet area at their school. Prior to the experiment sessin, the participant received an expressive vocabulary asessment (Expressive One Word Picture Vocabulary Test [Martin & Brownell, 2011], see Section 3.2.2 for more detail) as their baseline language proficiency.

At the beginning of the experiment session, the CA or a human experimenter had casual conversation with children about the child's age and favorite colors, following the same protocol. This activity aimed to build raport between the child and their reading partner (Human or CA).

During the storybook reading activity, children in Human-Story" group were only read the story by a human experimenter without being asked questions, whereas children in Human-Conversation" and CA-Conversation' groups were asked a same list of questions and received scripted fedback based on their answers. The smart speaker used in the A-Conversation ondition was aGoogle Home Mini device. There was a human experimenter present in the rom in the \*CA-Conversation condition to ensure the child's safety but not to interact with the child.

In all of the three conditions, a physical copy of the storybook was placed in front of the child as that the child could lok at the pages as they followed along the narration. Fig. 2 shows the experiment session setup of the "Human-Conversation' and the \*CAconversation' condition.

The reading activity took about $2 0 \ \mathrm { m i n }$ . Immediately after the reading activity, children's comprehension was assessed using an assessment battery developed by the research team (see Section 3.2.3 for more details. The whole experimental sesion was video recorded with consent from parents or legal guardians in order to conduct video coding to analyze children's verbal engagement patterns (see Section 3.2.4 for more details).

# 3.2. Experiment measurements

# 3.2.1. Background information

A parent survey was utilized to collect background information on children's date of birth (month and year) and home language (i. e., English only, English as second language, bilingual. These two factors have been traditionally shown to associate with children's learning and engagement instorybook reading (Cain, Oakhill & Bryant, 200; Farnia & Geva, 2013). This survey also asked for information about children's prior experience with CAs, since this fctor has been found to inluence children's interactions with the CA system (Bartneck, Suzuki, Kanda, & Nomura, 2007). A child was clasified as a heavy CA user ifparents indicated that the child used CAs more than a few days a week.

# 3.2.2. Baseline language proficiency

Children's baseline oral language skills were measured by the Expressive One Word Picture Vocabulary Test Fourth Edition (EOWPVT-4), which is an experimenter-administered, norm-referenced picture-naming asessment. Each child was asked to name objects, actions, and concepts that were depicted graphically, and the test lasted $1 5 { - } 2 0 ~ \mathrm { m i n }$ depending on the child's English proficiency. The internal reliability (Cronbach's coeficient alpha) of EOwPvr-4 for 3-to 6-year-olds is 0.95 (Martin & Brownell, 2011). Children's oral language skills are positively associated with children's performances in storybook reading activities (Kendeou, Van den Broek, White, & Lynch, 2009).

# 3.2.3. Story comprehension

Children's comprehension level of the story afer the storybook reading was measured as an indicator of a proximal learning outcome,similar to the research approach in Zhou and Yadav (2017). A questonnaire was developed, with a total of 10 items to measure how much a child understands the story. Together, these items aim toassesschildren's ability to 1) memorize main story events and make inferences, 2) sort narrative sequence, and 3) retell part of the story. There were eight items on memorization and inferences. Children were first asked to frely recall the answers. f they could not recall the answer corretly, the rearcher provided three multiple-choice options for children to select from. Two points were given to each item that was answered correctl through free recall and one point was given if answered correctly with multiple-choice options. There was one narrative sequence sorting item, Where children were aked to place images from the book in the order they occurred in the story. Children earned two points for completely correct order and one point for partially correct order. There was one item to prompt children to retell apart of the story, where children could earn one point for mentioning each key element in their answer up to four points.

An overall story comprehension score was calculated by summing the number of points acros allthe items and used this score as a dependent variable for the analysis. The range i from 0 to 2 points (16 points maximum for the 8 memorization and inference-making items, 2 points maximum for the single sequence sorting item, and 4 points maximum for the story-retelling item). Cronbach's co. efficient alpha is 0.87 for this story comprehension assessment.

# 3.2.4. Verbal engagement

Children's verbal engagement is a measure of how children responded to the CA's questions during storybook readings, which was coded from the video-taped interaction sessions. Only the Human-Conversation and CA-Conversation sessions have this measurement, because the Human-Story condition does not have guided conversation. Five sub-dimensions of verbal engagement were coded, based on the literature on parent-child storybook reading (Vukelich, 1976; Westerveld & Roberts, 2017), namely productivity, lexical diversity, topical relevance, accuracy, and intelligility. The unit of coding wa childs reonse to a single prompt, and each child had nine responses.

The reliability of the coding was established using two coders. These two coders, both native English peakers, were undergraduate research assistants. Neither of them were authors of this paper. Coder A coded allof the videos, while Coder B coded a subset of the videos $( 3 0 \% )$ . Coders met once every week to compare codes and discuss any discrepancies in coding. The operationalization and interrater reliability (i.e., Inter-class correlation) for each sub-dimension are detailed below.

Productivity. Children's language productivity was captured by the length of utterances in words. The total number of words was

![](img/ee53db560b5be59b16ea906606852fe6c2c5f027abad7df6af008d26edf30f69.jpg)

Note. A child participant in the Human-Conversation group (left); and another child participant in the CA

Conversation group, the smart speaker system is highlighted (right)

Fig. 2. Experiment Sesson Setup, Note. A child participant i the Human-Conversation group (left; and another child participant in the CA Conversation group, the smart speaker system is highlighted (right).

counted in each response, including repetitive words. The length of utterances is counted as 0 if the response does not contain verbal expressions. Meaningless speech input eg, filter words like Uhh, Umm, Ahha) was also excluded from the word count. Inter-class correlation $^ { \textrm { \scriptsize = 1 } }$

Lexical diversity. Children's lexical diversity was captured by the number of unique words in children's responses. The repetitive words in the utterance were removed, and only the unique words were counted. exical diversty was coded as 0 if no verbal expression was present, and meaningless speech input was excluded from the word count. Inter-class correlation $^ { \textrm { \scriptsize = 1 } }$

Topical relevance. The rlevance of children's response to a prompt will e coded using three categories, which indicate how wel children's responses maintain the semantic flow of conversation. Childish language, imperfect grammar, or answer correctness was not penalized within the rlevance code. A response that was directly addressed to the question received ascore of 2, response that was not directly adred to the qestion but aliged wth the overall theme of the story recived  core of 1, and response that was not related to the question or overall theme received a score of 0. Responses that did not contain verbal expressions was considered as irrelevant and received a score of O. Inter-class correlation $= 0 . 9 4$

Accuracy. The correctnessof children's response to a prompt was coded as a dichotomous variable, indicating whether a response is corrector incorret. pficll, correct answers reeivd a core f 1 and icorrect answers reeivd a core f eonses that did not contain verbal expressions were considered as incorrect and received a score of 0. Inter-class correlation $^ { \textrm { \scriptsize = 1 } }$

Intelligiility. he intelligility of childens uterances for each prompt was rated by a to 2 scale, following the method proposed by Flipsen (FlipsenJr, 202). A score of 0 indicated that a child's utterance was largely unintelligible, and the coders could understand less than $5 0 \%$ of the utterance; a score of 1 indicated that a child's utterance was mostly intelligible except for one or two words; a score of 2 indicated a child's utterance was articulate, and the coder could understand every single word. Responses that did not contain verbal expressions were excluded from this coding. Inter-class correlation $= 0 . 8 7$

In the analyses of this paper, these five sub-dimensions were analyzed separately, with each of them being a dependent variable.

# 3.3. Participants

The study targeted to include 90 children aged 3 to 6 to participate in the study. This sample size was pre-determined by a power analysis in order to detect a minimum effct size of 0.2 (Cohen, 2013). Upon approval by the Institutional Review Board, children were recruited from five local childcare programs affliated with or nearby a research university in the United States. These programs predominately enroll children of university students and faculty and include children from a wide range of economic, ethnic, cultural and linguistic backgrounds. The research team set up a recruitment booth at the school during pickup hours, explained the study procedure to the parents, and collected consent. There were 102 parents who provided consent for their child to participate 90 of these children actually participated and completed the experiment, and the remaining 12 children did not participate due to absence.

Background information of the 90 children who participated in the study is displayed in Table 1. Children's average age was 58 months (4.8 years old) with a standard deviation of 9 months. From the ful sample, 26 children were randomly assigned into the "Human-Story" group, 31 were in the "Human-Conversation'" group, and 33 were in the "CA-Conversation" group. The breakdown of background information of each of the three groups is displayed in Table 1. Randomization check using binomial regressions indicated that there were no significant differences in child baseline characteristics among the experimental condition assignments. After randomization had already occurred, during the study, children were asked if they had already read the book Three Bears in  Boat A total of 5 of the 90 children, spread out across the three conditions (1 in Human-Story, 2 in Human-Conversation, 2 in CA

Table 1 Participant background information by experimental condition.   

<html><body><table><tr><td></td><td>Full Sample</td><td>Human-Story</td><td>Human-Conversation</td><td>CA-Conversation</td></tr><tr><td>Age in months</td><td>58.1 (9.33)</td><td>56.9 (9.5)</td><td>58.3 (9.1)</td><td>59.5 (8.8)</td></tr><tr><td>Home language English only</td><td>67.4%</td><td>60.0%</td><td>71.0%</td><td>69.7%</td></tr><tr><td> Bilingual</td><td>10.1%</td><td>16.0%</td><td>9.7%</td><td>6.1%</td></tr><tr><td>ESL</td><td>22.5%</td><td>24.0%</td><td>19.3%</td><td>24.2%</td></tr><tr><td>Heavy CA use</td><td>36.2%</td><td>33.3%</td><td>34.2%</td><td>37.9%</td></tr><tr><td>EOWPVT</td><td>68.2 (17.5)</td><td>68.8 (17.1)</td><td>66.7 (17.1)</td><td>70.6 (17.4)</td></tr><tr><td>N</td><td>90</td><td>26</td><td>31</td><td>33</td></tr></table></body></html>

Note: Standard deviations in parentheses.

Conversation), indicated they had done so. The 5 were then asked to describe what the book was about; all 5said they couldn't remember the story.

# 4. Results

This section first presents the ful sample decriptive statistics of the outcomes measures. Findings were then reported regarding the CA's effcts on story comprehension (RQ1), verbal engagement behaviors with CA versus with human partner (RQ2a), and the interaction effects of questions' cognitive demand on verbal behaviors (RQ2b).

# 4.1. Descriptive statistics of outcome measures for full sample

The descriptive statistics for the full sample are presented in Table 2. Children's average score in story comprehension was 11.2, indicating that thee children i the sample correctly answered half of the comprehension items correctly. In terms of children's verbal engagement as they egaged in guided converation, the average legth of uterance (i.., productivity) was 4.4 words and the aerage number of unique words (i.., lexical diversity) was 3.7 words. The average score of topical relevance was 1.5 out of 2, indicating that most children were able to geerate answers that adressed the questions. Children in this study on average responded to half of the instory questions accurately, evidenced by an accuracy rate of 0.5. Also, these children generally articulated their nswers with good intelligibility, resulting in an intelligibility score of 1.9 out of 2.

The Pearson correlation coefficients between study variables and their ignificance levels are displayed in Table 2. Children's story comprehension was significantly positiely correlated with al verbal engagement measures. Among the verbal engagement variables, productivit, diverst, relevance, and accuracy were significantly correlated with each other, while intlligibility was only signifcantly correlated with relevance and accuracy but not productivity or diversity.

# 4.2. The effect of CAs on story comprehension

The first research question examined the extent to which having guided conversation with a learning partner during storybook reading may enhance children's story comprehension and whether the benefits of guided conversation differed depending on the nature of the learning partner (i.e., a CA or a human partner).

Descriptively, children who had guided conversation with either a CA or human language partner correctly answered story comprehension questions more frequently than did children in the group without guided conversation (see Table 3). When comparing the performance of the two groups with guided conversation, children in two groups answered approximately the same number of items correctly. The difference in score was only 0.13, which was much smaller than 1 (i.e., 1 item).

The regresson analyses first compared whether the two groups of children who had guided conversation performed better in story comprehension than their counterparts who did not engage in guided conversation (i.e, Human-Story group). This was considered as a baseline analysis to validate the benefits of guided converation with low- and high-cognitive-demand questions, regardless of the nature of language partners who carried out the conversation. The "Human-Story'" group was used as the reference group in our regression models (Model 1 in Table 4). The results indicated that both the CA-Conversation" $( \beta = 0 . 4 4$ $\begin{array} { r } { p = 0 . 0 3 , } \end{array}$ and the "HumanConversation" groups $( \beta = 0 . 6 4$ $p { = } 0 . 0 1$ ) scored significantly higher than the \*Human-Story" group. The higher comprehension score achieved by the two groups with guided conversation confirmed the advantage of incorporating guided conversation in storybook reading.

Table 2 Intercorrelations among study variables.   

<html><body><table><tr><td></td><td>Comp.</td><td>Pro.</td><td>Div.</td><td>Rel.</td><td>Acc.</td><td>Int.</td><td>Mean</td><td>SD</td><td>Range</td></tr><tr><td>Comprehension</td><td>1</td><td>0.28**</td><td>0.35**</td><td>0.59***</td><td>0.66***</td><td>0.32**</td><td>11.17</td><td>5.23</td><td>(0, 22.00)</td></tr><tr><td>Productivity</td><td></td><td>1</td><td>0.96***</td><td>0.52***</td><td>0.48***</td><td>0.03</td><td>4.38</td><td>2.55</td><td>(0, 13.78)</td></tr><tr><td>Diversity</td><td></td><td></td><td>1</td><td>0.55***</td><td>0.49***</td><td>0.02</td><td>3.73</td><td>1.89</td><td>(0, 11.33)</td></tr><tr><td> Relevance</td><td></td><td></td><td></td><td>1</td><td>0.87***</td><td>0.27*</td><td>1.47</td><td>0.53</td><td>(0, 2)</td></tr><tr><td>Accuracy</td><td></td><td></td><td></td><td></td><td>1</td><td>0.34*</td><td>0.54</td><td>2.19</td><td>(0, 1)</td></tr><tr><td>Intelligibility</td><td></td><td></td><td></td><td></td><td></td><td>1</td><td>1.90</td><td>1.65</td><td>(0, 2)</td></tr></table></body></html>

Note: Pearson correlation coefficients and significance levels reported. $p < 0 . 0 5$ denoted as \*, $p < 0 . 0 1$ denoted as \*\*, $p < 0 . 0 0 1$ denoted as $* * *$

Table 3 Descriptive statistics of story comprehension and verbal engagement variables by experimental condition.   

<html><body><table><tr><td></td><td colspan="2"> Human-Story</td><td colspan="2">Human-Conversation</td><td colspan="2">CA-Conversation</td></tr><tr><td>Comprehension</td><td></td><td>(4.62)</td><td>11.86</td><td>(5.78)</td><td>11.73</td><td>(5.03)</td></tr><tr><td>Productivity</td><td>Low cog.</td><td></td><td>3.24</td><td>(2.71)</td><td>3.10</td><td>(1.99)</td></tr><tr><td></td><td>High cog.</td><td></td><td>7.84</td><td>(4.67)</td><td>5.81</td><td>(4.05)</td></tr><tr><td></td><td>Combined</td><td></td><td>4.77</td><td>(2.53)</td><td>4.00</td><td>(2.56)</td></tr><tr><td>Diversity</td><td>Low cog.</td><td></td><td>2.89</td><td>(2.57)</td><td>2.62</td><td>(1.44)</td></tr><tr><td></td><td>High cog.</td><td></td><td>6.35</td><td>(3.32)</td><td>4.89</td><td>(2.57)</td></tr><tr><td></td><td>Combined</td><td></td><td>4.11</td><td>(1.99)</td><td>3.38</td><td>(1.75)</td></tr><tr><td> Relevance</td><td>Low cog.</td><td></td><td>1.56</td><td>(0.44)</td><td>1.40</td><td>(0.59)</td></tr><tr><td></td><td>High cog.</td><td></td><td>1.53</td><td>(0.63)</td><td>1.36</td><td>(0.68)</td></tr><tr><td></td><td>Combined</td><td></td><td>1.55</td><td>(0.46)</td><td>1.39</td><td>(0.59)</td></tr><tr><td>Accuracy</td><td>Low cog.</td><td></td><td>0.58</td><td>(0.25)</td><td>0.59</td><td>(0.28)</td></tr><tr><td></td><td>High cog.</td><td></td><td>0.46</td><td>(0.28)</td><td>0.44</td><td>(0.29)</td></tr><tr><td></td><td>Combined</td><td></td><td>0.52</td><td>(0.27)</td><td>0.51</td><td>(0.30)</td></tr><tr><td>Intelligibility</td><td>Low cog.</td><td></td><td>1.89</td><td>(0.17)</td><td>1.94</td><td>(0.12)</td></tr><tr><td></td><td>High cog.</td><td></td><td>1.82</td><td>(0.30)</td><td>1.89</td><td></td></tr><tr><td></td><td>Combined</td><td></td><td>1.87</td><td>(0.17)</td><td>1.93</td><td>(0.27) (0.15)</td></tr></table></body></html>

Note: Standard deviations in parentheses. Verbal engagement measures not applicable in Human-Story condition.

A post-hoc analysis was then conducted to compare the comprehension scores between children who had guided conversation with the CA and those who had guided conversation with a human partner, by using "Human-Conversation' as the reference group in the original regresson model. The result indicated that the comprehension scores of children in the CA-Conversation" group were not statistically different from those of children in the \*Human-Conversation' group $( \beta = - 0 . 2 0 , p = 0 . 2 9 )$ . These results suggested that the guided conversation carried out by CA could yield similarly effective learning as a human partner.

# 4.3. The effect of CAs on verbal engagement in guided conversation

The second set of research questions (RQ2a and RQ2b) focused on children's verbal engagement behaviors in guided conversation. RQ2a examined whether children convering with CA partners exhibited similar or different verbal engagement paterns as they would when talking with a human partner, and RQ2b examined whether any difference in verbal engagement varied based on the question's cognitive demand level. Table 3 presents descriptive statistics of children's verbal engagement between CA-Conversation and HumanConversation conditions, as wellas disaggregates the between-condition verbal engagement measures by low- and high-cognitivedemand questions. Descriptively, children produced longer, more lexically diverse, and more relevant responses when conversing with a human partner, yet children conversing with a CA language partner responded more intelligibly. The accuracy rate between the two conditions resembled each other. When the questions' cognitive demand level i taken into consideration, the difference in productivity and lexical diversity between the CA and Human groups became larger for high-cognitive-demand questions.

Table 4 Linear regression model on story comprehension measures.   

<html><body><table><tr><td></td><td>Comprehension</td></tr><tr><td>Human-Conv</td><td>0.64** (0.22)</td></tr><tr><td>CA-Conv</td><td>0.44** (0.22)</td></tr><tr><td>EOWPVT</td><td>0.62*** (0.11)</td></tr><tr><td>Age</td><td>0.27* (0.12)</td></tr><tr><td>English only</td><td>0.07 (0.30)</td></tr><tr><td>ESL</td><td>0.23 (0.31)</td></tr><tr><td>Heavy CA use</td><td>0.02 (0.19)</td></tr><tr><td>R2</td><td>0.62</td></tr></table></body></html>

Note: "Human-Story" is the reference group. Coefficients are standardized. Standard error in parentheses. $p < 0 . 0 5$ denoted as \*, $p < 0 . 0 1$ denoted as \*\*, $p < 0 . 0 0 1$ denoted as $* * *$ . Significant coefficients bolded.

Multilevel linear analyses were employed to formally test whether children conversing with a CA exhibited similar verbal engagement patterns as they would when talking with a human partner, and whether any diffrence in verbal engagement varied based on the question's cognitive demand. For each of the five engagement metrics, the analyse first focused on the ffets f language partner and questions' cognitive demand (Models 1, 3 5, 7, and 9 in Table 5). The analyses then focused on examining the interaction effects between the nature of language partner and questions' cognitive demand, by including an additional cros-level interaction term between the nature of language partner and questions' cognitive demand (i.e., CA-Conv $\times$ High cog; Models 2, 4, 6, 8, and 10 in Table 5). All models were controlled for chldren's age, expressive vocabulary core, home language, and prior CA experiences, given the documented relations between these variables and children's verbal responses.

# 4.3.1. Productivity

The multilevel model analysis suggested a significant effect of the nature of learning partners on language productivity. Specifically, reading with a human partner resulted in children responding in greater length $( \beta = - 0 . 2 8 , p = 0 . 0 4 )$ than they did to the CA partner (Model 1 in Table 5), sugesting some benefits of a human language partner in promoting language productivity over CAs. Questions that require high cognitive demand elicited responses that were significantly longer $( \beta = 0 . 7 8$ $p = 0 . 0 0$ ) than low-demand questions (Model 1 in Table 5).

Furthermore, the cross-level interaction between the nature of language partner and the questions' cognitive demand was sig. nificant (Model 2 in Table 5). The diffrence in language productivity between CA-Conversation" and Human-Conversation" conditions was significantly amplified when children were answering high-cognitive-demand questions $( \beta = - 0 . 4 4$ $p = 0 . 0 0 2$ ; Fig. 3-A). Specifically, children's response length did not differ significantly for questions that required low cognitive demand $( \beta = - 0 . 1 4 , p =$ 0.36). However, human partners' advantages in eliciting more language production became prominent when the conversation was cognitively challenging.

# 4.3.2. Lexical diversity

Regarding the efect of a CA versus human partner on lexical diversity (Model 3 in Table 5), children's responses contained more unique words when conversing with a human partner than with the CA $( \beta = - 0 . 3 5 , p = 0 . 0 1 )$ , indicating some advantages of a human partner in encouraging more lexically diverse utterances. In terms of the efect of questions' cognitive demand levels (Model 3 in Table 5), children were found to respond to high-cognitive-demand questions using more unique words $\mathcal { B } = 0 . 8 3$ $p = 0 . 0 0$

Furthermore, the model with the interaction effect (Model 4 in Table 5) indicated that the diffrence in lexical diversty between "CA-Conversation' and "Human-Conversation" was significantly larger among questions that require high cognitive demand $( \beta =$ $- 0 . 3 5$ $p = 0 . 0 1$ ; Fig. 3-B). Conversing with a human partner did not elicit more lexically diverse responses from children than did the CA if the questions required low cognitive demand $( \beta = - 0 . 2 4 , p = 0 . 1 1 )$ . Yet among the questions that were cognitively challenging, human partners were more likely to invite responses with higher lexical diversity than were CAs.

# 4.3.3. Topical relevance

In terms of the effect of a CA versus human partner on topical relevance (Model 5 in Table 5), children's responses were more topically relevant when they conversed with a human partner than with a CA partner $( \beta = - 0 . 3 0 , p = 0 . 0 4 )$ . However, when focusing on the efect of questions' cognitive demand (Model 5 in Table 5), a child's abilit to generate topicall relevant answers did not significantly differ by low- and high-cognitive-demand questions $( \beta = - 0 . 0 4$ $p = 0 . 6 0 \AA$

Table 5 Multilevel linear models on verbal engagement measures.   

<html><body><table><tr><td></td><td colspan="2"> Productivity</td><td colspan="2">Diversity</td><td colspan="2"> Relevance</td><td colspan="2">Accuracy</td><td colspan="2">Intelligibility</td></tr><tr><td></td><td>M1</td><td>M2</td><td>M3</td><td>M4</td><td>M5</td><td>M6</td><td>M7</td><td>M8</td><td>M9</td><td>M10</td></tr><tr><td>CA-Conv</td><td>0.28*</td><td>0.14</td><td>0.35*</td><td>0.24</td><td>0.30*</td><td>0.30*</td><td>0.08</td><td>0.07</td><td>0.23*</td><td>0.20</td></tr><tr><td rowspan="3">High cog</td><td>(0.14)</td><td>(0.15)</td><td>(0.14)</td><td>(0.15)</td><td>(0.15)</td><td>(0.15)</td><td>(0.11)</td><td>(0.12)</td><td>(0.11)</td><td>(0.13)</td></tr><tr><td>0.78***</td><td>0.58***</td><td>0.83***</td><td>0.67***</td><td>0.04</td><td>0.04</td><td>0.28***</td><td>0.30***</td><td>0.14</td><td>0.11</td></tr><tr><td>(0.07)</td><td>(0.1)</td><td>(0.07)</td><td>(0.1)</td><td>(0.07)</td><td>(0.1)</td><td>(0.08)</td><td>(0.11)</td><td>(0.09)</td><td>(0.12)</td></tr><tr><td>CA-Conv x</td><td></td><td>0.44**</td><td></td><td>0.35*</td><td></td><td>0.01</td><td></td><td>0.04</td><td></td><td>0.07</td></tr><tr><td>High</td><td></td><td>(0.14)</td><td></td><td>(0.14)</td><td></td><td>(0.15)</td><td></td><td>(0.16)</td><td></td><td>(0.17)</td></tr><tr><td>cog EOWPVT</td><td></td><td></td><td></td><td></td><td></td><td></td><td>0.30***</td><td></td><td></td><td></td></tr><tr><td></td><td>0.21*</td><td>0.21*</td><td>0.26*</td><td>0.26*</td><td>0.24*</td><td>0.24*</td><td></td><td>0.30***</td><td>0.13</td><td>0.13.</td></tr><tr><td>Age</td><td>(0.11)</td><td>(0.11)</td><td>(0.10)</td><td>(0.10)</td><td>(0.11)</td><td>(0.11)</td><td>(0.08)</td><td>(0.08)</td><td>(0.08)</td><td>(0.08) 0.02</td></tr><tr><td></td><td>0.05</td><td>0.05 (0.10)</td><td>0.04</td><td>0.04</td><td>0.19</td><td>0.19</td><td>0.10 (0.08)</td><td>0.10 (0.08)</td><td>0.02</td><td>(0.08)</td></tr><tr><td></td><td>(0.10)</td><td></td><td>(0.10)</td><td>(0.10)</td><td>(0.11)</td><td>(0.11)</td><td></td><td></td><td>(0.08)</td><td></td></tr><tr><td>English only</td><td>0.09</td><td>0.09</td><td>0.16</td><td>0.16</td><td>0.13</td><td>0.13</td><td>0.03 (0.23)</td><td>0.03 (0.23)</td><td>0.16</td><td>0.16</td></tr><tr><td>ESL</td><td>(0.31)</td><td>(0.31).</td><td>(0.30)</td><td>(0.30)</td><td>(0.32)</td><td>(0.32)</td><td></td><td></td><td>(0.26)</td><td>(0.26)</td></tr><tr><td></td><td>0.20</td><td>0.20 (0.32)</td><td>0.08</td><td>0.08</td><td>0.35</td><td>0.35</td><td>0.23 (0.24)</td><td>0.23 (0.24)</td><td>0.20</td><td>0.16</td></tr><tr><td></td><td>(0.32)</td><td></td><td>(0.32)</td><td>(0.32)</td><td>(0.33)</td><td>(0.33)</td><td></td><td></td><td>(0.27)</td><td>(0.26)</td></tr><tr><td>Heavy CA</td><td>0.09</td><td>0.09</td><td>0.05</td><td>0.05</td><td>0.02</td><td>0.02</td><td>0.10</td><td>0.10</td><td>0.01</td><td>0.01</td></tr><tr><td>use</td><td>(0.17)</td><td>(0.17)</td><td>(0.16)</td><td>(0.16)</td><td>(0.17)</td><td>(0.17)</td><td>(0.13)</td><td>(0.13)</td><td>(0.13)</td><td>(0.13)</td></tr></table></body></html>

Note: Each row i an indeendet variable, and each colum i a deendent variale. Fr each deendnt variale, two models were performed: the latter one has an interaction effect (CA-Conv $\times$ High cog). EOwpVT, Age, English only, ESL, and Heavy CA use are 5 control variables. Coefficients are standardized coefficient. Standard error in parentheses. $p < 0 . 0 5$ denoted as \* is considered statistically significant, $p < 0 . 0 1$ denoted as $^ { * * }$ $p < 0 . 0 0 1$ denoted as $\ast \ast \ast$ . Significant coefficients bolded.

![](img/3f7b74f7f8ed9dfa988657652da66885f49efeb239bdadcb6c652e2764671265.jpg)  
  
Fig. 3. Verbal engagement by the nature of language partner and questions' cognitive demand levels.

The cross-level interaction between questions cognitive demand and learning condition was not significant, as indicated in Model 6 in Table 5 $( \beta = - 0 . 0 1$ $\begin{array} { r } { p = 0 . 9 5 \mathrm { , } } \end{array}$ . Specifically, this non-significant interaction effect suggested that human learning partners, in general, were more likely to elicit relevant responses from children, and this pattern was consistent for both low- and high-cognitivedemand questions (Fig. 3-C).

# 4.3.4. Accuracy

In terms of the effect of a CA versus human partner on response accuracy (Model 7 in Table 5), there was no significant dfferences in response accuracy between children conversing with the CA and those conversing with a human partner $( \beta = - 0 . 0 8$ $\begin{array} { r } { p = 0 . 3 8 ) } \end{array}$ . In terms of the ffect of questions cogntive demand lel (Model 7 in Table 5), unsurprisingly, children were more likely to answer lower cognitive demand questions accurately compared to higher cognitive demand questions $( \beta = - 0 . 2 8$ $p = 0 . 0 0 \mathrm { \AA }$ . In terms of the interaction effect between questions cognitive demand and the nature of language partner (Model  in Table 5), our finding indicated that, when answering low-cognitive-demand and high-cognitive-demand questions, children had a comparable level of accuracy in the "CA-Conversation' and "Human-Conversation" conditions $( \beta = - 0 . 0 4$ $p = 0 . 7 9$ ; Fig. 3-D).

# 4.3.5. Intelligibility

In terms of the effects of a CA versus human partner on intellgibility of children's responses (Model 9 in Table 5), children's responses appeared to be more intelligible when conversing with a CA than with a human partner $( \beta = 0 . 2 3$ $p = 0 . 0 4 )$ . This suggested CAs' advantages in encouraging children to articulate their utterances. Questions' cognitive demand level did not significantly influence the intelligibility of children's responses $( \beta = - 0 . 1 4$ $p = 0 . 1 0$ ; Model 9 in Table 5). When including the interaction effect (Model 10 in Table 5), children showed a similar level of intelligility when conversing with the CA or a human partner, regardess of whether they answered low- or high-cognitive-demand questions $\mathscr { B } = 0 . 0 7$ $p = 0 . 6 7 $ Fig. 3-E).

# 4.4. Robustness check

We ran a robustness check excluding the 5 children who had indicated they had already read the story. Allresults remained consistent with the findings reported above.

# 5. Discussion

This section discusses the interpretation of the findings with regard to why children can learn from a CA partner and demonstrated certain verbal engagement behaviors in the guided conversations. As one of the first studies to design and evaluate a CA learning partner, the findings of this study provide novel design implications for further improving CAs in an affordable smart speaker format and deploying such systems to enrich young children's everyday literacy learning.

# 5.1. The learning benefits of conversing with disembodied CAs

This study demonstrated that the children who had guided conversation, whether with the CA or a human, comprehended the story better than the group who did not engage in guided conversation. This result was not surprising given that the vast education literature documenting the added value of guided conversation over non-interactive storybook reading where parents merely read the text (for reviews, see Arnold & Whithurst, 1994; Mol et l., 2008). However, the study's findings also extend this traditional line of research by demonstrating that A can potentilly facilitate children's language leaning as efectively as a human partner in this studys context. The positive effects of guided conversation in this study also validated the CA dialogue design strategy that incorporates high- and low-cognitive-demand questions (Raphael, 1986), proving the usefulness of developing intligent systems grounded in education theories (Callghan & Reich, 2018). One important factor enabling the CA in this study to replicate these benefits is its capacity to respond to children adaptively based on the children's answers. This kind of adaptive response helped identify and clarify children's misconceptions and reinforce an accurate understanding of the story (Aksan, Kochanska, & Ortmann, 2006; Funamoto & Rinaldi, 2015).

The fact that the CA, with only a voice interface, can benefit children's story comprehension as much as face-to-face human partners can reinforces the importance of verbal dialogue in promoting children's language skills. Yet, this result should not be interpreted as undermining the role non-verbal cues ordinarily play in boosting learning efectiveness (Dunn, Rodriguez, Miller, Gerhardt, Vannatta, Saylor et al., 2011; Kahlbaugh & Haviland, 1994; Negi, 2009). Instead, this result arises out of the storybook reading scenario in general. During storybook reading, young children typicall look at a picture book while listening to the story. Therefore, children's visual channel primarily concentrates on the illstrations (Paivio, 1991), which substantiall facilitates their understanding of the narration (Takacs & Bus, 2018), thus leaving limited oom for processing other non-verbal information provided by a human partner (Hanson, 1989). The minimal non-verbal information children do receive from human partners during storybook reading may not be sufficient to translate into the short-term lening benefit ths study asessed, such as immediate recallof story elements. Yet it is plausible that non-verbal cues may influence how children verbally engage with their reading partner, which is discussed below.

# 5.2. Verbal engagement behaviors with disembodied CAs

The findings of this study revealed nuances in how children verbally respond differently to a natural human and to a CA. Spe. cifically, children were found to generate longer and more lexically diverse responses when conversing with a human partner than with a CA. The human partner's ability to leerage social cues (e.g., loking at children as children formulat responses [Guo & Feng, 2013]) could contribute to this diffrence. Moreover, children were found to provide more relevant responses to a human partner. One speculation is that the social presence of a human partner may have encouraged children to make an efort to maintain the conversation flow (Groom, 2008; Kim et al., 2013; Zhou, Mark, Li, & Yang, 2019). Yet interestingly, despite the diferences in response relevance, children answered questions from the CA and the human partner with a similar level of accuracy, corroborating the finding on post-storybook reading comprehension that the CA benefits children's learning as wellas the human does. Taken together, this suggests that the lower relevance of childrens responses to CAs questions was not due to cognitive factors but may be related to social or behavioral factors. Lastly, CAs were found to enhance children's inteligibility. This may be dueto children's perceptions of the CAs istening ability tudies have suggested that people are likely to talk more clearly and slowly if hey peceive their parners as needing additional support in interpreting their utterances (Rooy, 2009). This pattern was also identified in childrens communication with CAs: Young chldren adjusted their speech style if they perceived CAs as encounterig dificultiesin understanding them (Beneteau et al., 2019; Cheng, Yen, Chen, Chen, & Hiniker, 2018).

There was evidence that the cognitive demand required to participate in the conversation, on top of the nature of the language partner, jointly shapes children's verbal engagement. Specifically, high-cognitive-demand questions amplified the efects of human partners on eliciting longer and more lexically diverse responses from children. This may also be attributed to the social presence of a human partner discussed before. An adult figure is oten perceived as more authoritative by children, which may encourage children to devote greater cognitive effort in attempting challenging questions (Davis, 2003).

Despite the nuances discussed above, the descriptive statistics suggest that children's responses to the CA were not fundamentll different from their responses to a human partner. Children in both conditions replied to the prompting with mult-word responses, kept their responses quite releant to the question, and uttered their responses intelligibly. This implie that children, regardess of Whether they are conversing with a CA or a human partner follow a shared convention during the conversation. This finding resonates with the prominent \*Computers as Social Actors (CASA)" paradigm (Nass, Moon, & Morkes, 1997; Nass, Steuer, & Tauber, 1994), which sugests that human users, especially children, tend totreat intelligent systems as human beings. Numerous studies on chil dren's interactions with embodied intellgent systems (e.g., robots and avatars) have supported this paradigm (Admoni & Scaselati. 2017; Fink, Lemaignan, Dillenbourg, Retornaz, Vaussard, Berthoud et al., 2014; Herink et al., 2012; Melson, Kahn, Friedman,

Roberts, Garrtt, & Gill, 209; Spolaor & Benitt, 2017; Tewari & Canny, 2014. The current study thus extends the application of the CASA paradigm to include disembodied CAs that do not have anthropomorphic figures and are restricted to verbal communication. This extension is also supported by other theorie that suggest an intelligent system's veral abilit i a central factor that shapes how users judge the system's sociability and intelligibility and thus how they interact with that system (Araujo, 2018).

# 5.3. Designing better CAs for early childhood language development

The current study sheds light on three implications for future design of CA language partners for young children.

First, it s important to design CAs with a clear theoretical rationale for meeting children's unique learning needs. In this study, the CA was tailored to a storybook reading context, incorporating evidence-based strategies that take into consideration the cognitive demand required by the conversation. The CA's ability to improve children's learning confirms the importance of a theoretically. driven design approach. Unfortunately, according to a recent review of over 500 voice-based apps on the market (Xu & War. schauer, 2020a), many of the apps purporting to benefit language learning were not grounded in research, thus limiting these apps abilities to fulfill their intended educational goal.

Second, it is important to fully leverage a CA's conversation capacity to compensate for its inabilit to utilize non-verbal expressions. In the current study, the CA did not fuly simulate a human partner in eliciting children's elaborat, complex, and relevant responses. As discused before, it is possible that the CA's disadvantages may arise from its disembodiment which prevents it from leveraging non-verbal cues. Developers can compensate for this lck by improving on such CAs' conversational expressiveness Lin, Ginns, Wang, & Zhang, 2020). For example, CAs may be designed to clearly explain to children how to best answer a question (e.g., "Listen to the question carefully and try to say as much as you can!") or provide follow-up prompts to encourage longer or more appropriate responses (e.g., "Great job! Can you say some more?" or \*That is a good idea! But how about what we've just talked about?"). CAs may also leverage natural acoustic features (i.., tone, prosody, pch speed), suchas asking a question with a tone of genuine curiosity, which may entice children to more thoroughly express their thoughts.

Third, it isalso important for developers to recognize the unique properties of CAs that make them especially useful learning tools regardles of whether they precisely mimic a human partner. Some researchers have proposed that CAs may be particularly valuable for providing children with opportunities to practice their language skill since CAs require children to communicate verbally (Vaquero, Saz, Lleida, Marcos, & Canalis 206). This supports the claim of Clark and colleagues (Clark, Munteanu, Wade, Cowan, Pantidi, Cooney et al. 2019), who suggest that developers need not and should not attempt to develop CAs that exactly emulate human-to-human interactions. Instead, CAs should be envisioned as a new form of language partner, one that could complement and enrich children's everyday conversational experiences.

# 5.4. Generalizability

The findings of this study are intended to be generalized to broader scenarios of using conversational interface to support young children's engagement and learning from storybook reading. irst storybook reading i one of the most important sources of language and literacy development during early childhood, and the activity simulated in this study followed a general reading format that children normally engage with in their everyday lives: istening to a story narrated by areading partner whil looking at a hard-copy book. Second, the conversation in this study took place via a smart speaker, which is a commercial product that is already widely available among children in the U.S. and other developed countries. Third, the participants of this study (i.e., 90 children aged 3-6) represented children from a variety of backgrounds, including approximately one third who are speakers of languages other than English and two thirds who had little prior experience with CAs.

However, there are also limitations to the generalizabilit including the fact that the experiment tok place in a single well educated community in one country and other issues of study design discussed below.

# 5.5. Limitations and future directions

This study was among the firs to utilize smart speakers as language partners, thus demonstrating the potential of this kind of CA. Future reearch wil want to build from what this study has shed light on by attending to some of the limitations of this nitia study

First, this study only focused on children's immediate learning outcomes-comprehension of the story they have just listened to. While this finding provides important evidence regarding the positive learning effcts of smart speaker CAs, it is unclear whether interacting with a CA reading partner may lead to long-run benefits to children's language development Future studies may want to include a delayed post-tes or carry out a more intense intervention to examine long-term effect of CAs on children's general language abilities.

Second, the reading activity was adapted from a commercial book that is available to the public. It is possble that some children had prior exposure to this book, which may influence their verbal engagement and story comprehension. Given that this study was a randomized experiment, the expected likelihood of children who had prior exposure to the book acros the thre conditions should be equivalent. Thus, children's prior exposure should not have confounded with the results regarding the comparisons acros the three reading conditions. Nevertheles, in the future it would be of value to replicate this research with an original book created for the purpose of the research.

Third, this study was conducted in an experimental manner where the human partner's conversational behaviors were scripted. This design increased the internal validity of the findings, reducing the confounding effcts resulting from the variations in ways of human partners actually carrying out the guided conversation. Nevertheles, in a naturalisticsetting, parents may unitize guided conversation in varying degrees and with varying approaches. Future studies may compare children's learning and engagement with CAs with those with their parents and family members who routinely read with them. In addition, in ths study, children had brief casual conversation with the CA, which might be viewed as a training opportunity that familiarized children with the scheme of interacting with the CA. Future studies may want to further explore how to best design such warm-up interactions to beter support children who were either reluctant to participate in the conversation or encountered obstacles (e.g, relied on non-verbal expressions) during their conversation with the CA.

Fourth, the current study has demonstrated that CAs can facilitate storybook reading through conversing with children individ ually. However, this study is not intended to develop agents that stand in the role of parents to red to ther children. Rather, it paves the way towards a new computing paradigm of Human-AI Collaboration" (Grudin, 2017) where CAs (or other AI systems) serve as a collaborator for parents to support more involved parental guidance during storybook reading. In fact, a recent study has suggested that CAs like smart speakers have helped augment parent-child interaction as a third-party mediator (Beneteau et al., 2020; Scoito et al., 2018). Future studies may examine the fesility of using CAs as training system to model to parents the beneficial strategies of guided conversation or redesigning prompts to include parents in the conversation. In addition, future systems may consider how parents, CAs and children may form a \*conversation triad", where parents and CAs collboratively engage children in discussions related to a story. By doing so, CAs potential could be maximined through to fully mobilizing other elements in family contexts that work together to support children's language development.

# 6. Conclusion

This study demonstrated the potentia of smart speaker CAs in carrying out guided conversation in storybook reading activities to nurture children's language development. Given that smart speakers are already acessble in many homes, the endeavor to augment smart speakers' usefulnes as larning tools may have profound impact on children and on the market. Encouragingly, this study demonstrated that the CA developed in this study based on education literature was equally supportive as a human partner in enhancing children's sory comprehension. However, nuanced patterns in children's verbal engagement were also identified: CAs and human partners have their own advantages in some respects. Among the first experimental studies comparing children's learning and engagement with CAs versus adults, this stdy provides intial evidence on the potentil of smart speakers as efetive reading partners. Nevertheless, the precious parent-child interactions cannot be replaced by artificially intlligent systems; yet CAs may supplement parents' current practies and thus enrich children's early literacy experiences. Understanding how children learn from and engage with CAs i an important step in gaining a more complete picture of the role that intlligent systems play in children's educational landscape in today's world.

# Credit author statement

Ying Xu: Conceptualization, Methodology, Data Collction and Analysis, Writing- Original draft preparation; Dakuo Wang: Conceptualization, Writing- Reviewing and Editing; Penelope Collins: Data Interpretation; Hyelim Lee: Data Analysis, Writing - Editing; Mark Warschauer: Data Interpretation, Writing- Reviewing and Editing.

# Author note

We have not known conflict of interest to disclose.

# Appendix A

![](img/c2c7df40638c666eef0f901be3669473a93ce4ffcaf5eb56aae6819f1ce7faf7.jpg)

The figure illustrates the system architecture of the automated CA system.

1. End user (the child) generates a voice input to the Google Home Mini device to respond to a question.   
2. The voice input is streamed to the Dialogflow API.

Y. Xu et al.

3. Dialogflow matches the child voice input to an intent, utilizing the agent's language training model.   
4. Dialogflow sends a webhook request to callfunctions (intent handlers) hosted on Google Cloud.   
5. These intent handlers define the following actions (feedback) for a given intent.   
6. The child user hears the feedback.

# References

Ani  .  1..58 jhri.6.1.admoni   
Akan   0i t     chd ml  n the science of relationships. Developmental Psychology, 42(5), 833-848. https:/doi.org/10.1037/0012-1649.42.5.833   
Ale  er   , a, , o,e . 019Th e p ive a ive angae learning evionmn. Pd of the nee n Aificilnlie 33, 98459846. tp/oi./10.1609/ai301.3019845   
Araujo .018. Living p to the cht hye he ie f mohic   nd oative g rg n tiol aent and company perceptions. Computers in Human Behavior, 85, 183-189. https://doi.org/10.1016/j.chb.2018.03.051   
Arnold, H & hitrst,  J.(1994). Aig gg lent tough pite boo eig  ay f dc eg d  effec.   
Bark  ki ,   7 f e e a ei   th Society, 21(1-2), 217-230. https://doi.org/10.1007/s00146-006-0052-7   
Bee,  ,     5/ doi.org/10.1126/scirobotics.aat5954   
,    . Proceedings of the 2020 CHI confeence on human factors in computing systems (pp. 1-13). https://doi.org/10.1145/3313831.3376344   
u,       i  019.    a   e 2019 CHI conference on human factors in computing systems - CHI '19 (pp. 1-13). https://doi.org/10.1145/3290605.3300473   
Bii,    k   f  i 1) 18-31. https://doi.org/10.1080/02568540903439359   
Blewit, , Rmp M hly, . oo, .  (209. Sh book reg en an hw quesions afc yug chdens wod g Educational Psychology, 101(2), 294-304. https://doi.org/10.1037/a0013844   
Bush J   ht  018 h  t  t h i 1 6./o. org/10.1109/mprv.2018.011591065   
Bus, A. G. (2001). Joint caregiver-child storybook reading: A route to literacy development. Handbook of Early Literacy Research, 171-191.   
Can, k  r   t thf rg  Th   ing 12 (1-2), 31-40.   
Callaghan,  ch .018. tio pol ohn s of te markt.    o, 3) 280-293. https://doi.org/10.1080/17439884.2018.1498355 human-computer interaction (Vol. 3, pp. 1-19). cscw. https://doi.org/10.1145/3359325.   
Chage, 0  t  d PsychoLinguistics, 37(2), 387-410. https://doi.org/10.1017/s0142716415000041   
Cheng, , e, , he,, Che,   ke,  2018. Wy dn i ok: iven ra ad young hin's ctio rr strae. Proceedings of the 17th ACM Conference on Interaction Design and Children, 337-348. https://doi.org/10.1145/3202185.3202749   
Chien, C-W. (2013). Using Raphael's QARs as differentiated instruction with picture books. English Teaching Forum, 51, 20-27 (ERIC).   
rk ,      01   ati agents. In Pcngs fte 2019H ofece on hn fors i cpg stems - H 19 p. 112). tp/.org/10.115/3290605.300705   
Cloud, G. (2020). Dialogueflow documentation. Technical report.   
Cohen, J. (2013). Statistical power analysis for the behavioral sciences. Academic Press.   
Cooter, . (206. n mm nt rad: nttig intion iitc. h Rn chr, 597, 6970. htp/o./0.1598.59.7.9   
Davis .n t       d ie is, 38(4), 207-234. https://doi.org/10.1207/s15326985ep3804_2   
Druga . ic.       t  t07 conference on interaction design and children (pp. 595-600). https://doi.org/10.1145/3078072.3084330   
n,   lr,   ,  l. 1)   n ric cancer: Asment f vebal and non-veral behavior and motion. Joual of Perc Pchoy, 36(5), 565-575. tps:/oi.g/10.1093/esy/jq062   
Fan r  17 Procedings f the 2017 CHI conference on human facors in computing systes (pp. 1805-1816). htps://doi.org/10.1145/3025453.3026048   
Fania,F &a  (2013). G ad pctof hngn is g r eg oi. l of h n g 36, 389421 https://doi.org/10.1111/jrir.12003   
Fik J n l , sd , d . 01ch  mi c  her ? eign andif r.  o  2014/oe  tio RI 14 396. /i. 10.1145/2559636.2559659   
lper, 0.         c h     g Research, 45(1), 100-110. https://doi.org/10.1044/1092-4388(2002/008 thesis]).   
Fryer,  e,  o  io hk,  17g  s t i  cos: n em rio Chatbot and Human task partners. Computers in Human Behavior, 75, 461-468. https://doi.org/10.1016/j.chb.2017.05.045   
ua 015-hd   s.    , 61 31. https://doi.org/10.1002/imhj.21481   
Garg  upta . 0 i ut ike me  st of th  uf ma aer   d hde. P f the otiv, Mobile, Wearable and Ubiquitous Technologies, 4(1), 1-24. https://doi.org/10.1145/3381002   
arg    e    i  g of the 2020 CHI conference on human factors in computing systems (pp. 1-13). https://doi.org/10.1145/3313831.3376631   
olinkoff, ff  w  mi-eod -Pae,  2019 aae mer ing the exist f th 30ion-wod a has serious consequences. Child Development, 90(3), 985-992. https://doi.org/10.1111/cdev.13128   
dn,   ,   r     l. 06i     ec language skills. In Thirtieth AAAI conference on artificial intelligence.   
deaf,  h  j  17th  o  ri -  P f 2017 ACM/IEE International Conference on Human-Robot Interaction,224-233. htps://doi.org/10.1145/2909824.3020236   
Gom .ts tht      P  th     ic   d  ice pp 323-328). Automation and Robotics (ICINc0). https://doi.org/10.5220/0001507103230328.   
Gru . 7.      r tis   c, 1 /i.g 10.2200/s00745ed1v01y201612hci035. i-183.   
Guo . 03.    c  -hd n a  tok     ne, -2. https://doi.org/10.1007/978-1-4471-4784-8_2   
n    29 15-19.   
H       e and interactive ehavior with a pet obt In 2012 EE R-MAN: The 21st IE inationl symposium on robot and human inrctiv comunication (p. 1045-1050). https://doi.org/10.1109/roman.2012.6343887   
Hong, , ng, , Hu,  & he . (2016). Athoring ro-sised inctional matril for improving leg permne an mtivation in FL classrooms. Journal of Educational Technology & Society, 19(1), 337-349.   
H, T  ,   .    c or      h 208 CHI conference on human factors in computing systems - CHI 18 (pp. 1-12). https://doi.org/10.1145/3173574.3173989   
He   . . the SIGCHI conference on human factors in computing systems (pp. 1787-1796). https://doi.org/10.1145/2556288.2557280   
Jacques  td, , er, , d , Lgr, , onde, , e l. (2019. ertional as Aig n the wav f arch and deelpme. n x f t 2019 nfe n m f i mpingtem . 1-). t/.g/11453206073299034   
Kahbaugh,   Hvilnd, J194). ver ntion bwe as ad ens  tdy f arch nd dce i. Jl f Nonverbal Behavior, 18(1), 91-113. https://doi.org/10.1007/bf02169080   
anro    s    18      i   dti. Child Development Perspectives, 12(3), 146-151. https://doi.org/10.1111/cdep.12277   
deu , r he, J  . 09. P   h  in f oral language and decoding skill. Journal of Educational Psychology, 101(4), 765-778. https:/doi.org/10.1037/a0015956   
yf tenth annual ACM/IEE international confernce on human-robot intraction - HRI 15 (p. 67-74). htps://doi.org/10.1145/2696454.2696457 human-robot interaction (HRI) (pp. 231-238).   
Km, ..1). the sm  f   sist k kf  n t d nc ft df readng (DIER). Scientific Studies of Reading, 21(4), 310-333. https://doi.org/10.1080/10888438.2017.1291643   
m, , e  e  , h   a. 13.     f   cn i autism. Journal of Autism and Developmental Disorders, 43(5), 1038-1049. https:/doi.org/10.1007/s10803-012-1645-2   
Km,, k H  Wr,  01) l/  y    ig ng 271),99.h/i.g 10.1007/s11145-013-9434-7   
Kinsella, B. (2020, April 28). Nearly 90 milion U. aduls ave smart speakers, adoption now exceeds one-third of consumer. Voicebot.Ai.   
Kory, J. & Brl, . 014). Stotlg t o ng compnons or prec chdn's ag deont. In The 23d  ineationl symposium on robot and human interactive communication (pp. 643-648). https://doi.org/10.1109/roman.2014.6926325   
ory . 1    t on multimodal interaction - ICMI '13 (pp. 71-72). https:/doi.org/10.1145/2522848.2531750   
Le    ing   
Lrt storytelling approaches. Educational Psychology, 38(5), 596-616. https://doi.org/10.1080/01443410.2017.1363377   
Lever, R., hal, (011). ssing store: n hw a dic reg intention mroe kiderrers ral nrraive constrtion. Jo of Experimental Child Psychology, 108(1), 1-24. https://doi.org/10.1016/j.jecp.2010.07.002   
Lin, L is,  Wg,  . 220 g     live i stl tit it  y ers Education, 143, 103658. https://doi.org/10.1016/j.compedu.2019.103658   
Loeat, ., ir,  (015). ri s his yo enn yog hdes tion th c  tm. In Pn of t 4h ntin conference on interaction design and children - IDC '15 (pp. 335-338). https://doi.org/10.1145/2771839.2771910   
Loat, . ir, 019  an       -tr int h.er , 10.s/ doi.org/10.3389/fpsyg.2019.00008   
Lot,   019  e i of the 18th ACM intenational conference n interaction desig and children (pp. 301-313). htps://doi.org/10.1145/3311927.3323150   
ac et rt 0.   i r t chd P of t th ACM international conference on interaction design and children. https://doi.org/10.1145/3311927.3325336   
Manz P.H gh, ., Bbas,  rllo &rck, 2010ritive  an m-is f fald me literacy interentions  wt extet is thech alial  ow-iome -mrit r linisticllir yg childe? l id eearch Quarterly, 25(4), 409-431. https://doi.org/10.1016/j.ecresq.2010.03.002   
Martin, N. A, & Brownell, R. (2011). Expressve one-word picture vocabulary test-4 (EOwPVT-4). Academic Therapy Publications.   
McHugh, M. L. (2012). Interra reliability: The kappa statistic. Biochemia Medica: Biochemia Medica, 22(3), 276-282.   
eon,    k  o  t t a. 0.     f r  vn. Journal of Applied Developmental Psychology, 30(2), 92-102. https://doi.org/10.1016/j.appdev.2008.10.011   
Michaelis   ,  017. e   wh f a xeri th an n-me g  o r g  P  he 2017 CHI conference on human factors in computing systems (pp. 301-312). https://doi.org/10.1145/3025453.3025499   
ol, . ,  de  ,  0   c ok  si. n, 19(1), 7-26. https://doi.org/10.1080/10409280701838603   
ovella , d,  e,  20.   t y k   f th tin conference on human robot interaction - HRI '09. https://doi.org/10.1145/1514095.1514189   
Nas C. I, Moon, , & Mrkes, J (1997. omutr are scial acrs ie f crrent. Hn Vales an the esin f omputer ecogy, 72, 137.   
as    er   o t o   ing interdependence - CHI '94 (pp. 72-78). https://doi.org/10.1145/191666.191703   
Nei, J.S. (209. he ol f tchers n-ver mcation in E csm  ofN101-110. hp/.g/0.3126/141.3096   
O'Neal, A. L. (2019). Is Gogle Duplex too human?: Exploring user perceptions of opaque conversational agents ([Ph.D. thesis]).   
Paivi, (199)  t t d t st.   f P d d ge, 45) 557. /. org/10.1037/h0084295 Computers & Education, 103924. https://doi.org/10.1016/j.compedu.2020.103924   
acht,    t,  d  ge 017tivh h:     vi. Intelligent Virtual Agents, 343-346. https://doi.org/10.1007/978-3-319-67401-8_44 the 2018 2nd intemational conference on education nd E-laning (Vol. 2018, p. 16-21) CEEL. htps://doi.org/10.1145/3291078.3291115.   
Raphael, T. E. (1986). Teaching question answer relationships, revisited. The Reading Teacher, 39(6), 516-522.   
Raphael, T. E., Highfield, K., & Au, K. H. (2006). Question-Answer relationships. Scholastic.   
Roy, .. 209. Iigiit  isf ih ie. d gihe 1) 5-3./.0.111/j.67-71x.008.01567.x   
oth  e,  r,  00 s o  ti t  ad   The   i Research, 95(5), 259-272. https://doi.org/10.1080/00220670209596600   
Sabharwal, N., & Agrawal, . 2020).Cognitive vrtl sstns using Google Dlogflow. Apres htp:/oi.org/10.1007/978-1-4842-57418   
Sito z,    018.     P 2018 on designing interactive systems conference (pp. 857-868). https://doi.org/10.1145/3196709.3196772   
Shmekhi    Wag  l   rikon .018.  apig the efec f  for p fatti Proceedings of the 2018 CHI confeence on human factors i computing systems - CHI 18 (p. 1-13). htps://doi.org/10.1145/3173574.3173965   
Shan 10    7. org/10.3102/0013189x10369172   
y,  0  h  th  1. doi.org/10.1016/j.compedu.2020.103862   
Splar  , . 1    t     re 112 97-107. https://doi.org/10.1016/j.compedu.2017.05.001   
Takacs, Z. K,  Bus, G. (2018). How pictue n pictre storyboos upport young hldres story comprehension: An eye-tracking experiment. Joundl of Experimental Child Psychology, 174, 1-12. https://doi.org/10.1016/j.jecp.2018.04.013   
Tan,H W  aic. 018) o ife on t effts  l f aig   m-l i f rot anthrhi. n 201827  ntio synt d n etive ntion p. 2-136. ). h./i./10.109 roman.2018.8525584.   
Twari,  y .01   - r n   t  n computing systems (pp. 1807-1816). https://doi.org/10.1145/2556288.2557205   
auero .,     a. 0 or e n Tecnologia Del Habla, 321-326.   
Vukelich, C. (1976). The development of listening comprehension through storytime. Language Arts, 53(8), 889-891.   
esereld,  rt, J 017.   nrtive eion a tio ii of a  othe ui n Speech, and Hearing Services in Schools, 48(4), 260-272. https://doi.org/10.1044/2017 lshss-17-0003 https://doi.org/10.1007/s10643-015-0719-0 in computing systems - CHI '17. https://doi.org/10.1145/3025453.3025496   
Xu, Ying, Warhaer, Mark (2020).  on analsisf ve-a aps on th mrkt for el literacy lomet n Prcdgs of t 19th ACM International Conference on Interaction Design and Children. https:/doi.org/10.1145/3392063.3394418   
Xu, Ying,  Warchauer, Mark (2020). plorin young cilden'sgaent in jon rding with a convertional gt. In Pdngs o the 19th ACM International Conference on Interaction Design and Children (IDC 20). https://doi.org/10.1145/3392063.3394417   
Xu, ing, her, rk 20.ht e yu tkig  erd hins tions of erto as n Pd of he 2020H Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3313831.3376416   
u, ing, hae, Mark (20).ir i t o e on the cr raing covrtional ts inhilds tisio rng  H Conference on Human Factors in Computing Systems Extended Abstracts. https:/doi.org/10.1145/334480.3383000   
Ye, C , Chg, , C   , a. 2018    t  a   t. , aan Proceedings of the ACM on human-computer interaction (Vol. 2, pp. 1-19). Cscw. https:/doi.org/10.1145/3274461.   
eber, s, 003. h eok i r p.   i  nd Teachers, 177-200.   
ou   J 019   t ti   2-), 1-36 https://doi.org/10.1145/3232077   
Zhou, . & Yada, A (2017) Effcs f mutimdia story eig an quetiong n prechoolers vcaulay lng, stoy comprehesin and eading engagement. Educational Technology Research & Development, 65(6), 1523-1545. https://doi.org/10.1007/s11423-017-9533-2