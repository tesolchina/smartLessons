# Language quality, content, structure: What analytic ratings tell us about EFL writing skills at upper secondary school level in Germany and Switzerland

Stefan D. Kellera,\*, Julian Lohmannb, Ruth Trubc, Johanna Fleckensteind, Jennifer Meyere, Thorben Jansene, Jens Mollerb

a University of Teacher Education, Zuerich, Switzerland   
b University of Kiel, Germany   
c University of Applied Sciences and Arts Northwestern Switzerland, Switzerland   
d University of Hildesheim, Germany   
e Leibniz Institute for Science and Mathematics Education, Kiel, Germany

# ARTICLEINFO

# ABSTRACT

Keywords:   
Argumentative writing upper secondary level education analytic analysis language quality content structure

Argumentative writing in English as a foreign language (EFL) is an important skill in upper secondary education in Germany and Switzerland. This article provides insights into students' EFL writing skills in the aspects of language quality, content, and structure $( \mathrm { N } = 2 3 1 4$ TOEFL argumentative essays from two time-points, beginning and end of Year 11). These essays were analyzed by trained human raters using analytic assessment rubrics for each aspect and evaluated in a cross-sectional as well as a longitudinal perspective. Results show that there were significant variations between these aspects in learners' texts, suggesting that they represent separate dimensions of the argumentative writing ability. Scores were lowest for language quality, suggesting that this was the most challenging aspect for EFL learners. Learning gains over one year were largest for structure, smaller for content and smallest for language quality. Overall, learners in Switzerland showed higher skills in all three aspects, but German learners showed larger gains in structure over the school year. Implications for classroom learning and further research are discussed.

# 1. Introduction

The importance of writing for educational suces has long been recognized in the European context (Kellr, Fleckenstein, Krige, Koller & Rupp, 2020; Kolle e al., 2010; Landrieu, De Smedt, Van Keer & De Wever, 2022; Schoonen, 205). Writing in English as a foreign language (EFL) is an important competence for succeeding in many academic disciplines, serves to promote language awareness, and is a means of supporting foreign language acquisition in general (Akukwe et al., 2017). Further, EFL writing is key for success i tertiary education and employment in an increasingly globalized world (Keler, 2013). Writing in general benefits learning in a range f subjects such as social studies, sciences, and mathmatics (Graham et al., 2020). Addtionally,  witing is often used as a proxy for language ability in both standardized tests and language acquisition studies, leading to a greater interest in examining

textual features (Crossley, 2020).

English EFL curricula at upper secondary level (IsCED 3) in Germany and Switzerland stipulate that learners should be able to organize their ideas, structure their writing, and use appropriate language and tone in expressing themselves on a range of culturally relevant topics in English (Swiss Conference of Cantonal Ministers of Education [EDK], 1994; Standing Conference of the Ministers of Education and Cultural Affairs of the Lander in the Federal Republic of Germany [KMK], 2014). To check whether learners have mastered these objectives, previous studies have used holistic ratings to measure the writing ability of EFL learners in these two countries (Keller et al., 2020). Intenationall, studies have focused mainly on language-related aspects (i.e., lexical or syntactical features) when discussing EFL writing development (Barkaoui & Hadidi, 2020; Crossey, 2020; Kim, 2021; Kyle et al, 2021). Yet, as Polo (2017) points out, \*writing development concerns much more than lexical-grammatical development' (p. 26). EFL writing is a many-faceted and complex construct, its study requiring the analysis of varied aspects of communication such as gauging readers responses, choosing corrct levels of register and style (Cumming, 2012), argumentation strtegies (Hyland, 1990). Idell, llthese aspects should be considered when describing the development of leaners' L2 writing sils in a specific genre or educational stting (Tardy, 2006; Tardy & Swales, 2014).

This paper hopes to make an impact by presenting a repeated measurement study on three broad aspects of learners argumentative EFL writing skils: (1) language quality defined as leaners command of genre-specific exical items, grammatical structures, and ability to use argumentative language; (2) content defined as the ability toconstruct a stringent argument in response to the writing prompt that includes arguments for both sides of the question and appropriat support; and (3) structure defined as the abilit to divide an essay into an introduction, main part, and conclusion, and to use paragraphing effectively to support argumentation. It presents both a cros-sectional analysis by comparing results from diffrent countries (Switzerland and Germany), and a longitudinal one by comparing results over a period of (roughly) one school year.

We have structured this paper into four part, as follows: in the Background section, we summarize relevant research on the educational context of EFL learning in Switzerland and Germany. In the Methods section, we describe the development of the analytic rating system, rater training, and statistical analyses conducted in this study. We subsequently describe developmental traectories of learners FL writing sills for language quality, content, and structure in the Rults section, aso focusing on differenes between the two educational systems. inally, we discuss the relevance for teaching argumentative EFL writing together with limitations and perspectives for further research.

# 2. Background

# 2.1. Key aspects of EFL argumentative essays

Learning to write in a foreign language means mastering the conventions of specific genres, including the ability to use language in conventionalized social settings and in accordance with a set of communicative goals (Bhatia, 2004; Hyland, 2008). Genres channel communicative interactions but also exclude language users who are unfamiliar with their normalized practices (Tardy & Swales, 2014). In the genre of argumentative writing, learners must be able to use appropriate grammatical structures and lexical items (including argumentative language) to construct arguments over several paragraphs and to structure these paragraphs in a way that conforms to genre-expectations (Ferretti & Lewis, 2019).

Due to their central position in many educational contexts, English argumentative essays are a well-described genre in terms of their internal structure and textual moves (Hyland, 1990). In Table 1, we have summarized central elements of argumentative essays which are mentioned in linguistic and educational studies both in the L1 and L2 contexts. Taken together, they constitute a set of learning goals at the level of language quality, content and structure which students must master to writ successfull inthis genre.

The elements isted in Table 1 are typicallyalso mentioned in relevant analytic scoring rubrics. As Cushing (2019) notes, most of these rubrics tend to have at least one subscale for content (or ideas), one for organization, and one for language-related aspects (grammar, vocabulary, mechanics.). In high-quality argumentative essays, these elements are combined to support the writer's argument, refute counter arguments and convince readers of the writer's point of view (Zemach & Stafford-Yilmaz, 2008)

Table 1 Central Elements of English Argmentative Eays (Ferreti & Lwis, 2019; Hyland, 190 Staples et l., 2018; Zemach & Stafford-Yilmaz, 2008)   

<html><body><table><tr><td></td><td>Correctness / appropriateness of vocabulary</td></tr><tr><td></td><td>Correctness / appropriateness of grammar Control of language mechanics</td></tr><tr><td></td><td></td></tr><tr><td></td><td>Style and register</td></tr><tr><td>Language quality</td><td>Argumentative language (e. g., structuring words and cohesive devices such as however, first, second, finall, etc.)</td></tr><tr><td></td><td>Appropriate and relevant content</td></tr><tr><td>Content</td><td>Constructing a stringent argument (pros / cons)</td></tr><tr><td></td><td>Finding and listing adequate support</td></tr><tr><td></td><td>Well-defined introduction</td></tr><tr><td></td><td>Main part with body paragraphs</td></tr><tr><td></td><td>Well-defined conclusion</td></tr><tr><td>Structure</td><td>Paragraphing supporting understanding argumentation</td></tr></table></body></html>

As an indication of how wel foreign language learners at upper secondary lel cope with these challenges, a recent study of 130 argumentative EFL essays in the Netherlands is instructive (Landrieu et al., 2022). It found systematic differences in argumentation between weak, mid-range and strong essays. Weak texts were characterized by a lack of laim or arguments, poo factual ccuracy, and poor writing mechanics. Strong texts, by contrast, showed high quality of arumentation (clams, arguments, reuttals), high qualit of content (strong persuasiveness and factualaccuracy) and text structure inroduction, conclusion), as wellas a high lel of linguistic correctness.

# 2.2. Studies of L2 writers' longitudinal development

While there is much cross-sectional research on EFL writing sills (e.g., Landrieu et al., 2022), fewer studies have examined learners' longitudinal L2 writing development (Barkaoui & Hadidi, 2020; Cumming, 2012; Cushing, 2019; Kyle et al. 2021; Polio, 2017). Further, most longitudinal studies have focused on how development in the linguistic characteristics of learners L2 texts is reflected in changes in their writing scores (Barkaoui & Hadidi, 2020). As Polio (2017) has argued, more longitudinal reearch should be conducted on specific genres and tasks of L2 writing whilealso including a wider range of aspects of text qualit. This would involve both observational and implementation studies to understand how writing skills develop over time.

An important theory of learners' longitudinal foreign language development is usage-based theory, which posits that learning occurs as a functio of language use: language items that are heard and used more frequently are more salient for leaners, meaning that they will be leaned erlier or moreily than those that are encountered es frequenly (Kyle et al, 2021; Versoor, 2017). Most studies in this paradigm have focused on lexical and syntactical complexity or sophistication to track the development of their L2 writing proficiency (e.g., Kim, 2021). For lexical features, studies have shown that L2 learners tend to use a higher proportion of low-frequency words as they become more proficient, while also being more likely to use those words in more target-like multiword constructions (Crossley, 2020; Kyle et al., 2021). In terms of phrasal sophistication, features in L2 writing do not generally become more sophisticated, but rather develop toward being more accetable. This means that advanced L2 writers more strongly ollow the phrasal paterns which L1 writers would use i similar stuations (Crossey, 2020). In terms of syntactical development, proficient L2 writers tend to produce longer and more varied syntactic structures than les proficient ones (Lu, 2011), and also tend to use reater clausal subordination (Crossley, 2020; Kyle et al., 2021).

While devlopment in uch lexical and syntactical aspects of writing skill is well documented, the picture s sketchier for the aspect of content. As Crossey (2020) points out, content in argumentative writing is intensely connected with argumentative aspects of claims, these, and rhetorical moves. Whil allthese aspects are important for (L2) writing, they are seldom studied because they are not linguistic in nature (although based on language features). In a study in primary level EFL writing, Bae et al. (2016) showed that content significantly correlated with the linguisic features grammar (.35) and vocabulary (.37) as well as coherence, originality and text length. The study went as far as claiming that content \*can be defined as the sum of thee five elements (p. 302) Ina study on the associatio of sill-learning and L2 writing development, Franciset al. (2002) also showed a clear connection between content-related and language-related aspects. In sample of American EFL learners writing i science education, learners who expressed more complex ideas also used more complex sentencestructures. Content-related variables were highly correlated with language-related ones (esp. sentence complexty), suggesting that the complexit f learners ideas increased in lockstep with ther capacity to express those ideas. Such studies show how formal 2 skils are linked wth content-related dimensions, underscoring the value of integrating these aspects in studies of EFL writing development.

Maybe the least well understood area of EFL writing (interms of longitudinal development) i structure. In a study that focused on EFL learners in lower secondary education in Germany, Siekmann et al. (2022) showed that creating convincing structure and argumentative coherence was particularly dfficult for leaners in Year 9, and that esential part of argumentatiessays such as the conclusion were often missing. In general, EFL learners struggled to establish a broad common thread in their argumentation, with argumentative structure being a strong distinguishing feature between more and less proficient texts.

To the best of our knowledge, there are no studies on the development of structure in upper-secondary EFL writing in Germany or Switzerland, and only few intenationally. One could assume that his aspect is linked with the development of the leaners' lingustic writing ability as they gain more lexical and grammatical ways of making the relationship between different textual elements explicit (Francis et al., 2002). Further, structuring an essy into introduction, main part and conclusion is atypical feature of schoo-related argumentative writing which learners also experience in their L1 (for Germany, see Bremerich-Vos & Scholten-Akoun, 2016), and which might be transferable to some degree between languages (Schnoor & Ursanova, 2022). These assumptions have never been tested, however, for the context in which this study took place.

Overall, one can say that of the complex construct that is L2 writing development, linguistic features of text quality are wel researched whil the picture is sketchier for content and structure. Our study aims to fill hisresearch gap by including all thee e. ements in its analysis, combining a cross-sectional with longitudinal approach.

# 2.3. Expected size of development

For a study that loks at the efectivenessof educational systems in fostering L2 writing skill, the question of expected learning gains is especiall relevant. The tudy by Kellr et al. (2020) showed that learning rates for EFL writing in Year 1 in Switzerland and Germany corresponded to effect sizes of about $d = 0 . 2$ . While Swiss students did better overall, there were no differential growth effects between countries, and the effectivenes of both educational systems in teaching leaners argumentative writing kills was similar $\scriptstyle { \dot { a } } =$ 0.19 for Germany and 0.18 for Switzerland). Such gains were in line with the annual gains in efect size for nationally normed reading tests for school Years 11-12 reported in a meta-analysis by Bloom, Hil, Black, and Lipsey (2008). Further, a recent study from Ger many by Brunner et al. (2023) showed that the mean increase in proficiency in English at lower secondary level (Years 8 and 9) was $d = 0 . 2 7$ No data for English at upper secondary level were given in that study, but across diffrent subjects, the annual academic growth in Years 11-12 was $d = 0 . 1 8$ . Such effect sizes are a useful means of comparison for this study.

# 2.4. Holistic and analytic text analysis

The quality of any empirical study of writing hinges on the appropriatenessof scoring rubrics and assessment procedures (Cushing, 2019). In the measurement literature, these rocedures are typically divided into holistic and analyti assesment, with corresponding rubrics (Bacha, 2001; Barkaoui, 2010; Cushing, 2019; Grotjan & Kleppin, 2017; Huot, 1990). In holistic asessment, raters assess a text as a whole and focus on it overall meaning and message. This typef rating is often used intimed-writig and large-cale contexts and tends to result in higher inter-rater agrement (Barkaoui, 2007; Rupp, Casabianca, Kriger, Kellr & Kollr, 2019; Staples et al., 2018). In analytic assessment, by contrast, raters base their valuation of individual text features on separate scales, aiming at identifying specific paterns and characterisics of a text (Schipolowski & Bohme, 2016). This type of scoring provides insights into individual aspects of writing and is a basis for detailed formative assessment and feedback in the clasroom (Andrade, 2005).

In a previous study of upper secondary learners EFL argumentative writing skill in Switzerland and Germany, Keler et al. (2020) showed that at the end of Year 11, about $7 5 \%$ of students reached level B2 or higher according to the Common European Framework of Reference for Languages (CEFR; Council of Europe, 2001). It further showed that about $2 5 \ \%$ of students were still at level B1 at the second measurement point, and thus at risk of faling to acquire basic EFL argumentative skill for higher education. However, the study did not provide any insights into individual subskills of writing due to its holistic scoring method.

The current study used analyti scoring to focus on three broad aspects of the EFL writing abilit language quality, structure and content) and sought to track them in a longitudinal design. This type of analysis can account for the fact that developing learners typicall perform at ifferent proficiency lees in different sub-skill (Bcha, 2001; Kroll, 1990). For exmple, an analytic analysis of German first graders' L1 essays (PohImann-Rother et al., 2016) showed a two-dimensional structure of writing skill, with semantic-pragmatic aspect of writing distinct from language-stematic aspects. Trib (2022) showed that Swis EFL learners texts in Year 6 contained considerable inter-individual heterogeneity regarding different dimensions of text quality. While individual texts might be internll hetrogeeus in qualit, stdies also show that dfernt trats of  writing are systmaticll correlate eve if they concern quite distinct aspects of text quality. Bae & Bachman (2010), for example, showed that grammar, content, speling, and text length were ll sgnificantly correlated in English and Korean elementary school learners writing. This was true both for related aspects (spelling and grammar,89) and relatively unrelated ones (spelling and text length,53). In the same vein, this study oper. ationalizes theoretically motivated aspects of writing quality which can be assumed to be related to some degree, yet which are considered conceptually different for gaining a differentiated picture of learners' writing development and for supporting that development in the classroom.

# 2.5. EFL writing in Switzerland and Germany

EFL writing curricula in Germany and Switzerland are both based on the CEFR (Council of Europe, 2001) in terms of the level which learners are expected to atin at the end f upper secondary educatio, namely level B2 (Fleckenstein, Kellr, Kriger, Tannenbaum & Koller, 2019). Argumentative writig aths lel involves students being abl to present clear, detiled decriptions on a wide range of subjects, to explain their viewpoint on topical isues, and to weigh the advantages and disadvantages of various options relating to a specific prompt (Council of Europe, 2001). For students surpassing these basic requirements, EFL argumentative writing further in. cludes the development of specific arguments in an introduction, the integration of sub-themes of argumentation, and the appropriate closing of a text with a conclusion (Council of Europe, 2001).

Upper-secondary level English currcula in both countries specify that leaners should be able to address diffrent argumentative positions, use a repertoire of syntactic structures and lexical expressions to express their opinion, and show command of English language mechanics (Fleckenstein et al., 2019). These are also the requirements for pasing the TOEFL writing exams, which often serve as college entrance exams in international contexts (Educational Testing Service [ETs], 2009).

While the curricula for EFL writing in the two countries are similar, the two countries differ in terms of selectiveness of these educational tracks. In Switzerland, about $2 1 ~ \%$ of learners attend higher secondary education (Gymnasium), compared to $3 5 ~ \%$ in Germany (National Statistical Office of Switzerland [BFS], 2016). A previous study on diffrences in EFL learners' argumentative writing skill between these countries (Keller etal., 2020) showed that leaners in Switzerland outperformed students in Germany both at the beinning and at the end of 11th yer i., the peultimate year f upper-econdary education. On the holistic TOEFL  writing assessment scale (Educational Testing Service [ETS], 2009), Swis students were ahead of German ones by about a third of astandard deviation, which translates into an advantage of 15-16 months in terms of chooling time (Keller e al., 2020. Both national samples showed similar proficiency gains over one chool year so that the difference in achievement levels remained largely unchanged at the end of Year 11. As no significant influences of gender, social background or linguistic background on writing development were detected in either country, authors atributed this difference to the structure f the national educational systems. For example, the sample from Switzerland contained a higher percentile of high-performing learners at the second time-point $. 1 8 . 4 \%$ at CEFR levels C1/C2) than the sample from Germany $( 1 1 . 4 \%$ at levels C1/C2), where access to upper-level schooling is less selective and heterogeneity of proficiency lels i larger (Standing onference of the Ministers of Education in Germany K], 2018; Kller et al, 2020).

A further difference between the two countries is the way argumentative EFL writing i tested at the end of upper secondary ed. ucation. In Switzerland, there are no mandatory standards of assessment at the end of secondary education (Kelle, 2013). While EFL argumentative writing figures prominently in the curricula, it is lft to the responsibilit of individual districts often, individual schools to what extent they want to test argumentative writing in the final exams (Swiss onference of Cantonal Ministers of Education EDK, 1994).

Germany, by contrast, has national educational standards for upper secondary education designating argumentative writing as a core element of upper secondary EFL education. These standards are tested in a poo of mandatory asessment tasks at final exams (Institute for Educational Quality Improvement [IQB], 2021). These assessment tass include a section on reading and understanding argumentative texts, a section on interpreting argumentative structures and rhetorical devices, and a section on writing an argumentative esay, either in response o the input texts or as a personal statement. Further, national aessment criteria exist for these tasks, comprising the aspects language quality and content. To achieve high marks in content (which also contains aspects of structure), students are expected to write texts which are highly structured, free from redundance, and coherent in argumentation. In language quality, particular emphasis is given to lexis and grammar as well as consistent functional use of tex-tructuring means (cohesion) (IQB, 2021).

As this study focused on aspects of EFL writing explicitly mentioned in the relevant curricula it allowed us to est whether there is a backwash effect of these standards on teaching, possbly leading to a differential development of writing skill in the two countries which had not been discernible in the earlier, holistic analysis.

We formulated two main research questions for this study:

(1) How does the quality of learners' argumentative essays develop over one year regarding language quality, structure and content?   
(2) Are there any differences in writing sills and learning gains over one school year in argumentative FL writing in Switzerland and Germany in terms of language quality, content and structure?

The first research question concerns the longitudinal development of writing skill over one school year, the second additionally focuses on the influence of different educational systems and student populations.

# 3. Method

# 3.1. Sample and procedure

Data collection was carried out as  repeated measurement design in upper secondary schols in Germany and Switzerland with an interval of nine months between the two measurement points (T1: August/September 2016; T2: May/June 2017). In Switzerland schoolsfrom seven German-speaking cantons (districts) were asked whether they wanted to participate in the study. Data were collected from 91 classes nested in 20 schools, resulting in a sample size of $N = 1 8 8 2$ Swiss students ( $5 8 \%$ female; age $\mathtt { M } _ { \mathrm { T 1 } } = 1 7 . 5 6$ $\mathrm { S D } _ { \mathrm { T 1 } } = 0 . 9 1$ $\mathbf { M } _ { \mathrm { T } 2 } = 1 8 . 2 7$ $\mathrm { S D } _ { \mathrm { T } 2 } = 0 . 9 1 $ ). In Germany, data were gathered in the federal state of Schleswig-Holstein, where 42 schools were randomly selected from the pool of 84 available schools and students were asked for their voluntary participation. In the end. $N =$ 965 students from different upper secondary profiles (e.g., language, science, civics) were included in the study $( 5 8 . 6 \%$ female; age $\mathtt { M } _ { \mathrm { T 1 } } = 1 6 . 9 1$ $\mathrm { S D } _ { \mathrm { T 1 } } = 0 . 5 6$ $\mathbf { M } _ { \mathrm { T 2 } } = 1 7 . 6 1$ $\mathrm { S D } _ { \mathrm { T 2 } } = 0 . 5 6$

Data collection took place on laptops provided by the research team in a rotational matrix design where the order in which learners worked on the two argumentative writing promptsat 1 and T2 was randomlyvaried to minimizesequence efects (Rupp et al., 2019).

# 3.2. Writing prompts

To operationalize EFL argumentative writing skills, the study used prompts from the TOEFL iBT $^ \mathrm { \textregistered }$ writing section (Educational Testin Service (ETS),209). They were chosen because the TOEFL assessment rubri aligns well with the relevant writing curricula in Germany and Switzerland (Educational Testin Service (ETS), 2009; Fleckenstein et al., 2020). In general, T0EFL-iBT $\textsuperscript { \textregistered }$ language tests (and particularly the writing section) have been shown to be responsive to longitudinal development i similar studies involving L2 learners (Barkaoui & Hadidi, 2020; Choi & Papageorgiou, 2014; Ling et al, 2024). Further, learner texts on these prompts can be reliably linked to the competence levels of the CEFR (Fleckenstein et al., 2020).

The following two prompts were chosen: A teacher's ability to relate well with students is more important than excellnt knowledge f the subject being taught (Teacher, or TE prompt) and Television advertising directed toward young children (aged two to five) should not be allowed (Advertising, or AD prompt) Participants were asked to provide detailed reasons for their arguments in a text of approximately 300 words. The writing time was $3 0 \mathrm { { m i n } }$ , and there was no preparation or support (i.e., dictionaries, etc.). In a pilot study, the rearch team tested the suitabilit f the prompts in claes f identicl schoo leel and type checking whether they were within the ability range of the target student populations (Rupp et al., 2019). As neither foor nor ceiling effects were observed, these prompts were then re-used in the main study.

# 3.3. Analytic assessment of learner texts

The original dataset from Keller et al. (2020) contains $N = 5 6 9 4$ texts for the AD und TE prompts (i.e. independent writing TOEFL-iBT $^ \mathrm { \textregistered }$ ) from two time points. Due to the high intensity and cost of rater training and operational scoring, it was beyond the reach of this study to include the whole dataset in the extended analysis. For this reason, we randomly selected $N = 2 3 1 4$ texts from the original dataset for re-analysis, equally balancing texts on the TE and the AD prompt at both time points.

The analytic categories of language quality, structure and content were selected for three reasons. First, we wanted to generate features which represented aspects of the writing ability that could be linked coherently to educational currcula in participating countries (Fleckenstein et al., 2020). Second, we wanted to measure aspects that were congruent with cateories of analysis described in the pedagogical literature on EFL argumentative writing in school contexts (e.g., Cushing, 2019; Jacobs, Zinkgraf, Wormuth, Hearfiel & Hughey, 1981). And third, we wanted to generate suficient statistical reliability by basing each aspect on a set of clearly defined items (sub-scales) which were simple and unambiguous enough for raters to handle in operational scoring (se also 3.5. below).

For this purpose, the research team designed a rating scheme based on existing descriptions and assessment rubrics of EFL argumentative writig (Ferrtti & Lewis, 2019; Hyland, 1990; Jacobs et al., 1981; emach & Stafford-Yilmaz, 2008). Individual sub-scales were developed in co-operation with experts from the International Association for the Evaluation of Educational Achievement (IEA) Data Processing and Research Center (DPC) in Hamburg, which also provided raters for operational scoring. I accordance with similar studies undertaken by DPC, three types of ratings were employed for different sub-scales acording to suitabilit (Bremerich-Vos & Scholten-Akoun, 2016). In the area of language quality, most ratings were done on a Likert cale (1-7), where 1 typically denoted "very high skill" and 7 "ery low skills". Raters either counted the number of instance (e.g, the number of structuring words) or the number of mistakes (e.g., number of wongly used words), which directly yielded the skillevel that was used in thestatistical analysis (e.g., three structuring words $=$ level 3). In the areas of structure and content, where assessment was focused more on the appropriateness of students' writing, either binary ratings ( $0 / 1 =$ appropriate/inappropriate), or three-point ratings ( $3 =$ fully appropriate, $2 =$ partly appropriate, ${ 1 = }$ inappropriate) were used. These sub-scales and rating procedures are shown in Appendix 1 (Tables A1-A3).

After raters had assessed all sub-scales in the areas of language qualit, structure and content, they were provided with an aggregated sum score and were asked for an additional, holistic ssessment of each aspect. They were allowed to deviate from their sum score suggested by their individual scores but were asked not to do so without suficient reason. In these additional scores, for example, raters could indicate that writers had attempted to include ophisticated vocabulary but had not ben properly rewarded for taking that risk. Results showed that raters rarely deviated from their initial scores in the areas of language quality $( 3 . 1 ~ \% )$ and structure $( 2 . 1 ~ \% )$ . Deviations were more frequent for content.

$( 1 7 . 3 \% )$ , maybe because larger portions of text (containing complex and manifold information) had to be evaluated in this area. In those cases where raters' holistic impression differe from the original sum score, the additional score was included in further cal. culations of leaners writig sills. Based on these ratings, we employed a three-dimensional many facets IRT rater modeling approach to receive a single score for each aspect of writing quality and normalized these scores the metric used in the (Programme for International Student Assessment PISA, 2000; see below, Sect. 3.6.1).

# 3.3.1. Language quality

The following ub-scales were used to ases language quality: lexical qualit correctnes and variabilit ofvocabulary,correctness of register; number and quality of structuring words), grammatical quality (correctness of grammar), and language mechanics (spelling, typos, punctuation). Typical, raters counted how often a certain event ocrred in atext to produce an item score. For structuring words, fr example, they counted gere-specific elements such as however, to conclude, et. For correctnes of vocabulary, they counted all words which were either wrongly used in context, missing, or superfluous.

# 3.3.2. Content

The following sub-scales were used to asess content: inroducing the argument (topic becomes clear, hook to catch the reader's attention, author's opinion is apparent), presenting the argument (relevance of arguments for topic; arguments for both sides of the question are mentioned), and concluding the argument (author repeats opinion clearly). From a pedagogical point of view, these are generic aspects of content which are releant in any argumentative text, irespective f topic. This aspect thus expressed whether the individual parts of the essay contained the information they were supposed to contain, and whether learners had constructed a convincing argument to explain their point of view. For a high rating, learners also had to mention arguments for both sides. Raters were not, however, asked to ases the factual truth of the arguments. ata for this study were colcted in the context of timed writing where learners did not have the opportunit to research the topic or perform a detailed topical analysis. Diffrent kinds of arguments were aceptable if the writer's position was clearly laid out in the beginning, supported by evidence in the main section and summarized succinctly in the end.

# 3.3.3. Structure

The following sub-scales were used to asses structure: introduction (present and clearly marked), conclusion (present and clearly marked), and use of paragraphs (dividing the text into meaningful units to guide the reader). The operationalization of tructure was thus based on two factors: first, whether the text had paragraphs and whether they were used consistently todivide the arguments into meaningful units, thus making it easier for the reader to understand the writer's opinion. Second, whether the text had a clearly noticeable introduction and conclusion which was ither marked linguisticall (for example, by starting the first body paragraph with "the most important argument i.." or by announcing the conclusion with finally or to conclude). Alternatively, these parts had to be clearly marked by a paragraph or line break.

From the operationalization of structure and content in our study, it is apparent that these aspects are linked to some degree: only an existing introduction can be asessed in terms of content. A missing introduction thus lowers score both for structure and content. We expected these aspects to be correlated significantly whilestil asuming them to be conceptull sufficientl different to warrant separate interpretation. The conceptual overlap between content and structure is rooted in the multidimensional nature of argumentative essays, which also implies tht analytic rating criteria overlap to some degree. However, this method of analysis is suitable for tracking EFL writing development, which is multidimensional rather than sequential, where growth takes place on many inter. related fronts at once, and which is continuous rather than lockstep (Sadler, 1989).

# 3.4. Rating procedures

The rating process was planned, executed, and evaluated by the author team in cooperation with experts from the IEA/DPC institute (see above) under the leadership of the main author. Six raters were chosen from a pool of raters from DPC who had participated in earlier, similar ratings of texts in English, had a good command of the English language and were familiar with the agency's procedures of asessment. We thus undertook the type of rigorous rater training which can mitigate differences in rater severity and consistency (Cushing, 2019).

In preparation for the ratings, raters were familiarized with the asessment system in a series of training sesions. In this proces, benchmark texts for diffrent levels of proficiency were identified and thir features analyzed to create a common understanding of quality. Between training sessions, raters were asked to use the analytic criteri to asses a booklet of ten texts from atraining sample. In the following training ession, raters went through their ratings one by one. Consistency of aessments was checked, and raters were asked to explain their rationale if iscrepancies appeared between ratings. In this proces, some of the descriptions of sub-scales were adapted and categories deleted because no sufficient consistency between raters could be reached.

# 3.5. Interrater reliability

Each text was rated independently by two raters. Afer a first round of rater training, the interrater rliability was found to be satisfactory in general but not consistently above the threshold of weighted Kappa $>$ .6 (.55 .73). We reviewed all rater scores and found consistently divergent scores from one rater, who was excluded from further analyses. Operational ratings for the full sample were then performed in rater pairs from the pool of five people (see Appendix 2). This improved interrater reliability by $\begin{array} { r l } { \Delta _ { \mathsf { W - K a p p a } } } & { { } = } \end{array}$ .07 on average and ifted th overall reliailities for ll three scales to an acceptable lel. The weighted Kappa was 74 for language qualit, 70 for structure and 1 for contet. Further, the rliailitie for allthre aspts f witing quality we sfficient across both prompts. A complete confusion matrix for all operational raters and rater pairs across both prompts is shown in Appendix 3.

# 3.6. Statistical analyses

# 3.6.1. Modeling rater data

To receive a ingle score for each aspect of writing quality and each text, we employed a three-dimensional many facets IRT rater modeling approach (Robitzsch & Steinfeld, 2018; Wu, 2017). Using this approach allowed controlling for stable between-rater differeces in severit/ lenincy, ctralit / xtremity, and rater iscimintion ften referred to as rater accuracy or consistency , Uto & Ueno, 2020; Wu, 2017). We also accounted fr differences in these rater effects across ifferent aspects of writing quality (language quality vs. structure vs. content). To set up the model, the R-package TAM (Robtzsch & Steinfeld, 2018) was used (see Appendix 4 for details). Expected A Posteriori (EAP) scores were calculated and used as fair score i.., adjusting for systematic rater effects) in further analyses (Eckes, 2015). EAP reliabilities for each scale were found to be good (language quality $= . 8 3$ ; structure $=$ .76; content $= . 7 8$ . Distribution of ratings on all scales is shown in Appendix 5.

To compare results between educational systems, we scaled the EAP factor cores for each analytic dimension to the PISA metric (M $= 5 0 0$ $S D = 1 0 0 ~ $ ). We thus aligned our analysis with prior studies of the same corpus (Keller et al., 2020) and used the preferred metric for comparing educational systems in Europe.

# 3.6.2. Missing data

Our strategy of sampling texts randomly from the original dataset for extended analytic analysis $( N = 2 3 1 4 )$ ) implied that for some students only one of the essays (either from T1 or T2) was selected for the analytic asessment, while for some students both essas were selected. After the sampling procedure, the rate of missing data for the analytic ratings was $3 6 . 7 \%$ across measurement points. Ratings of both measurement time points were available for 486 students in our sample. To account for missing data' and minimize missing data bias, we employed multiple imputation (MI), a state-of-the-art missing data treatment (Enders, 2010) using the Rpackages mice (van Buuren & Grootshuis-Oudshoorn, 2011) and miceadds (Robitsch & Grund, 2021). Considering the nested structure of our data (students nested in schols) we applied  hierarchical MI cheme to produce 100 complete data set for further analyses. MI involves predicting a plausible range of values for each missing data point based on the observed data. From this range of plausible values, the imputed values are repeatedly drawn for each of the 100 datasets. Sampling different plausible values represented in different datasets reflect the uncertainty about what thetrue value should be for each missing data point (Enders, 2010). Each analysis was repeated with each imputed dataset and parameter estimates were pooled afterwards.

# 3.6.3. Regression models and pooling

The research questions formulated in this study were addressed in two regression models. To account for the nested data structure. we applied a multilevel modeling approach with the R-package lme4 (Bates, Machler, Bolker & Walker, 2015). Since we had previously imputed 100 data sets, we used the common procedure of running each model on each data set separately before pooing the results (Enders, 2010). For this purpose, we used the routines implemented in the R-package miml (Grund et al., 2016).

To addres research RQ 1, we first ran a series of multilevel regression models with the dichotomous predictor time while con trolling for the covariates prompt and country. To adress RQ 2, which focused on differences between the two countries, we extended the interaction term between the factors time and country to examine dfferential gains among analytic criteria. For all the predictors and covariates, we used (weighted) effect coding (Hardy, 1993). In this aproach, the main efects in the regression models can be interpreted as the average effct acros the categories of the other covariates The beta weights of the predictor and the covariates represent the difference between the group average and the category-specific averages. To obtai the actual group differences, beta coefficients must therefore be multiplied by two.

In total, we estimated four different efects (main effect for time, country, and prompt, and the moderation effect of time and country) for each of the three ifrent analytic outcomes.We employed Bonferroni orrection to addres the multiple testing problem. Using the typical alpha-level $p < . 0 5$ as baseline, the adjusted alpha level was $\textstyle \alpha = { \frac { . 0 5 } { 4 \times 3 } } = . 0 0 4$

# 4. Results

# 4.1. Correlations between aspects of text quality

Table 2 preents the correlation coficients btwenthe three ifferent scale. All correlations ar igficantl diffen from zero $( p < . 0 0 1 )$ . At both time points, the correlations were smallest between language quality and structure (.28 -.35), larger for language quality and content $( . 6 0 - . 6 3 )$ , and largest for structure and content (.81 -.87). The intra-class correlation coefficients (ICC) representing the proportion of the total variance of each outcome that was between classes (Raudenbush & Bryk, 2002) were.05 for language quality,1 for structure and.07 for content. The variance between clusters turned out tobe statisticall significant (language quality: $F = 1 1 8 . 7$ $p < . 0 0 1$ ; structure: $F = 3 3 7 . 5$ $p < . 0 0 1$ ; content: $F = 1 6 4 . 2$ $p < . 0 0 1 \ r$ , indicating considerable performance differences between classes. These considerable level-2 diffrences between classes necesstated the application of multilel regression models (Bates et al., 2015).

Table 2 Means, Standard Deviations, and Correlations of Writing Skills Within and Across Time Points.   

<html><body><table><tr><td></td><td>Mean (SD)</td><td>Lang. Qual. T1</td><td>Structure T1</td><td>Content T1</td><td> Lang. Qual. T2</td><td>Structure T2</td></tr><tr><td>Lang. Qual. T1</td><td>493.3 (88.8)</td><td>:</td><td></td><td>:</td><td>:</td><td></td></tr><tr><td>Structure T1</td><td>479.1 (88.0)</td><td>.28</td><td>-</td><td></td><td></td><td>:</td></tr><tr><td>Content T1</td><td>488.8 (85.8)</td><td>.60</td><td>.81</td><td>-</td><td></td><td></td></tr><tr><td> Lang. Qual. T2</td><td>510.3 (92.9)</td><td>.64</td><td>.15</td><td>.35</td><td></td><td></td></tr><tr><td>Structure T2</td><td>523.8 (80.8)</td><td>.15</td><td>.24</td><td>.23</td><td>.35</td><td></td></tr><tr><td>Content T2</td><td>513.9 (91.7)</td><td>.32</td><td>.25</td><td>.30</td><td>.63</td><td>.87</td></tr></table></body></html>

Note. Correlation coefficiens shaded in gre oncern the same point of measurement (T1 / 2).All orrelations were statisticllysigificant at $p < . 0 0 1$

Table 3 Regression models. Standardized outcomes transformed to a metric with $\mathbf { M } = 5 0 0$ and $\mathrm { S D } = 1 0 0$   

<html><body><table><tr><td rowspan="2"> Predictor</td><td colspan="4">Language quality</td><td colspan="4">Structure</td><td colspan="4">Content</td></tr><tr><td>Est.</td><td>SE</td><td>t</td><td>p</td><td>Est.</td><td>SE</td><td>t</td><td>p</td><td>Est.</td><td>SE</td><td>t</td><td>p</td></tr><tr><td>Model 1</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Time</td><td>9.32</td><td>1.98</td><td>4.71</td><td>&lt;.001</td><td>25.59</td><td>1.80</td><td>14.18</td><td>&lt;.001</td><td>14.02</td><td>1.91</td><td>7.32</td><td>&lt;.001</td></tr><tr><td>Country (Reference: Germany)</td><td>5.37</td><td>3.57</td><td>1.50</td><td>.133</td><td>22.15</td><td>3.90</td><td>5.67</td><td>&lt;.001</td><td>9.80</td><td>3.77</td><td>2.60</td><td>.009</td></tr><tr><td>Prompt (Reference: AD)</td><td>-2.92</td><td>1.90</td><td>-1.54</td><td>.124</td><td>-2.17</td><td>1.77</td><td>-1.23</td><td>.219</td><td>-1.89</td><td>1.88</td><td>-1.01</td><td>.315</td></tr><tr><td>Model 2 Time</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>9.32</td><td>1.98</td><td>4.71</td><td>&lt;.001</td><td>25.59</td><td>1.78</td><td>14.41 5.66</td><td>&lt;.001 &lt;.001</td><td>14.02 9.80</td><td>1.91 3.77</td><td>7.33</td><td>&lt;.001</td></tr><tr><td>Country (Reference: Germany) Prompt (Reference: AD)</td><td>5.37</td><td>3.57</td><td>1.50</td><td>.133</td><td>22.15</td><td>3.91</td><td>-1.25</td><td>.212</td><td>-1.89</td><td>1.88</td><td>2.60 -1.01</td><td>.009</td></tr><tr><td>Time*Country</td><td>-2.92 0.23</td><td>1.90 1.96</td><td>-1.54 0.12</td><td>.124 .908</td><td>-2.17 -18.94</td><td>1.74 2.04</td><td>-9.30</td><td>&lt;.001</td><td>-3.16</td><td>2.08</td><td>-1.52</td><td>.315 .129</td></tr></table></body></html>

Note. Significant effects listed in bold type. Student-level $\scriptstyle \mathrm { \mathrm { R } } ^ { 2 }$ of Models 1(e, Raudenbush & Bryk, 2002) $R _ { L a n g . q u a l . } ^ { 2 } = . 0 1 ⁄ R _ { S t r u t u r e } ^ { 2 } = . 0 7 ⁄ R _ { C o n t e n t } ^ { 2 } = . 0 2 .$ Student-level $\scriptstyle \mathrm { \mathrm { R } } ^ { 2 }$ of Models 2: $R _ { L a n g . q u a l . } ^ { 2 } = . 0 1 ⁄ R _ { S t r u t u r e } ^ { 2 } = . 1 1 ⁄ R _ { C o n t e n t } ^ { 2 } = . 0 2$ Bonferroni corrected alpha level: $p < . 0 0 4$

# 4.2. Development of learners' argumentative writing skills (RQ 1)

To answer RQ1, which concerned the development of learners' writing skills over the course of one school year, we ran three multilel regression analyes, each incuding one of th text qualities as deendent variable (Table 3, Mode1). he text qualities were regressed on the predctor ime aummy variable. We used effect coding, settig the first measurment time point (beginning f Year 11) to - 1 and the second measurement time point to 1. In addition, we controlled for the factors prompt and country that were also effect coded. Results implied a significant improvement in all three aspects of writing quality (language quality: $b = 9 . 3 , p < . 0 0 1 , R ^ { 2 }$ $= . 0 1$ ; structure: $b = 2 5 . 6 $ $p < . 0 0 1$ $R ^ { 2 } = . 0 6$ ; content: $b = 1 4 . 0$ $p < . 0 0 1$ 3 $R ^ { 2 } = . 0 2 )$ . Because the text qualities had been scaled onto a standardized metric with an overall mean of 500 and an overall standard deviation of 100, the regression coefficients can be interpretd as standardized effct.s i rquired in weightd effet coding, rression cofficients were multiplied y tw o express actual group difference. Accordingly, on average, students improved around half of a standard deviation (i.e. about 45 points on the PISA metric) in structure, a quarter of a standard deviation (i.., about 25 points on the PISA meric) in content, and les than one fifh of a standard deviation (i. about 17 points on the PISA metric) in language qualit. The same patterns are reflected by the coefficients of determination $( \mathbb { R } ^ { 2 } )$ . According to Cohen's conventions, the coefficients of determination imply small effects for content $\scriptstyle ( R ^ { 2 } = . 0 1 )$ and language quality $( R ^ { 2 } = . 0 2 )$ and a medium effect for structure $( R ^ { 2 } = . 0 6 )$

Apart from these main efect ofthe predictor time, only one further covariate ffect wassignificant in this irst serie of regression models (applying the Bonferroni corrected level of significance; Table 3, Model 1) It concerned the aspect of structure, where considerable performance differences became apparent between Swiss and German students. Across prompts and time points, the Swiss students scored almost half a standard deviation higher (about 45 points on the PISA scale) than the German students $( b = 2 2 . 2$ $p < . 0 0 1 )$ . To get clearer picture of differences between countries, we also ran a second serie of regression models (see also Fig.1, below).

![](img/3cba179999155d0996f5e39e2939ff27760b047269abe664ff804514b141d27c.jpg)  
Fig. 1. Interaction Effect of Time\*Country for Structure.

# 4.3. Country effects (RQ 2)

To analyze the influence of different (national) educational systems as a contextual factor on the writing performance gains, we included the interaction term between time and country as afurther predictor in asecond series of regresson models (Table 3, Model 2). These interactions allowed us to investigate whether the learning gains between the two time points were associated with the educational system in which students were placed.

The results show a significant interaction and thus diffrential improvements in the two educational systems for the aspect ol structure, but not for language quality and content. The significant interaction effect for structurei illustrated in Fig. 1.

As Fig. 1 shows, there are what apear to be considerable differences between Swiss and German students regarding their ability to structure argumentative esas at the beinning of Year 11. While Swiss learners initially did significantly better, German learners caught up over the course of one school year.

No such differential developments were observed for content and language quality, where development rates are consistent for the two countries: the quality of both aspects improved similarly in both countries, with Swiss students outperforming German ones at both time points (see Table 3, Model 2).

# 4.4. Further analyses: prompt effects

Although our study had no explicit focus on prompt efect, we tested for possible interactions between topic and writing skillby including the factor of prompt in both regresson models see above, Table 3). This was done mainly to check whether the sequence in which learners worked on the two prompts influenced the outcomes of our study. Results showed interaction effects between time and prompt for content $( b = - 1 8 . 9 4 , p < . 0 0 1 )$ and language quality $( b = - 1 3 . 4 9 , p = . 0 0 1 )$ . Both interaction terms indicate that the time point at which participants worked on the prompts influenced the outcomes: at T1, the AD prompt seems to have been slightly more difficult for learners than the TE prompt (see Appendix 6 for a more detailed discussion of this effect).

# 5. Discussion

# 5.1. Analytic assessment of upper-secondary argumentative writing

This study investigated the development of learners' EFL argumentative writing skill in upper secondary education in Germany and Switzerland through analytic coring I focused on three broad aspect of EFL writing, integrating language qualit, content and structure in is analyic frmework. ts rech is thus broder than stdes which hae fousd on linuistic aspcts , Crossey, 2020) yet more detailed than studies based on holistic asessments (e.g., Keller et al., 2020). Results showed tht al aspects of ESL writing skills were related to each other, revealing low corrlations between language quality and structure (.28/.35), higher ones between language quality and content (.60 /.63) and the highest between structure and content (.81/.87). Despite these substantial intercorrelations, we would argue that the constructs are conceptually different enough to contribute to a better understanding of the internal structure of learner texts (Bae & Bachman, 2010). Further, it is be helpful to distinguish between these aspects when giving feedback in the clsroom, providing learners with instructional support that aligns with concrete strengths or weaknesses in their texts.

The aspect of structure, which has not been extensively studied in the litrature so far, showed low correlations with language quality at both time points. It might represent a rather general argumentative writing strategy which students also encounter in their school language (German), and which can be transferred to some degree between languages (Berman, 1994; Bremerich-Vos & Scholten-Akoun, 2016). The features of language quality, by contrast, tap into general aspects of L2 proficiency where rogres is slow and incremental (e.g., complex grammatical constructions or genre- and topic specific idiomatic language; Elis, 2008). This would explain why we see larger improvement for structure than we do for language quality over one school year.

Correlations were larger for language quality and content at both time points, suggesting a link between the abilit to build a convincing argument (with adequate support) and the ability to express that argument in appropriate words and grammatical structures. As Bae et al. (2016) point out, \*writers do not arrange words at random but in accordance with grammatical and discourse rules to make a text comprehensible. So, clearly, words, grammar, and discourse conventions are used in the service of content" (p. 303). From a classroom perspective, it is vital to recognize the close connection of language quality and content. Especiall at upper-secondary level, command of complex linguistic skills is required of learners to present claims, make arguments and add convincing support (Crossey, 2020; Zemach & Stafford-Yilmaz, 2008). Teaching and practicing such skills explicitly are likely to benefit the content dimension of essays as well.

Correlations were largest between structure and content at both time points, which was due in part to our operationalization (see Sect. 3.3.3). The close link between these aspect also suggests a conceptual connection, as the abilit of building a convincing argument overlaps with the ability of presenting this argument in an introduction, a main part, and a conclusion. This connection might be used as a lever for teaching in the EFL classroom. For example, learners could study model texts for their content (or argumentation) while simultaneously analyzing how that content is represented in the typical paragraph structure of the genre (Hyland, 2008; Zemach & Stafford-Yilmaz, 2008).

# 5.2. Longitudinal development

In terms of development over time, the learning gains over one school year are consistent with those found in other studies both in Germany (Brunner at al., 2023) and internationall (Bloom et al., 2008; see Sect. 2.9, above). Our study found improvements for all aspects of writing over one year, with the largest effect for structure (half of a standard deviation; $R ^ { 2 } = . 0 6 )$ and smaller effects for content (quarter of a standard deviation; $R ^ { 2 } = . 0 1 \mathrm { \Omega }$ ) and language quality (one fifth of a standard deviation; $R ^ { 2 } = . 0 2 \AA$

The relatively small gains in language quality and content are in range with growth efects at upper-secondary level in different subjects (Bloom et al., 2008). Further, it has been shown that learning rates in Englis slow down even further at higher levels of schooling deeleration effect; Lecht, Rtesdorf Pant, Moller & Koller, 2015). ur reults suggest that there is significant otential for improvement where linguistic aspects of text quality are concerned as gaining mastery of genre-specific argumentative language requires extended clasroom input and practice (Kellr, 2013). There is evidence that from Year 8 onwards, English teachers in Germany use large parts of their lesons to explain and practice fomal language kills with their students (Hemke, Hemke, Schrader, Wagner, Nold & Schroder, 2008). Further research is needed to understand how to tailor that support specifially to learners in upper-secondary education. In the context of argumentative EFL writing, this could be done in intervention studies where learners are taught genre-specific language skills. This might include modals and modal alternatives (e.g., \*ought to - it i essential that), argumentative language suitable for developing and structuring an argument (e.g., \*however', \*therefore"), or language to contrast arguments nd counterarguments e., \*some people belie .. Howeer, it must als e recognzed that; \*Whil it istre tha ...it can also be argued that; Zemach & Staford-Yilmaz, 2008). The hypothesis would be that intruction in those genre-specific aspects of language quality would speed up development where, in this study, it was shown to be the slowest.

In terms of structure, our results suggest that students seem to be quite able to divide atext into an introduction, a main part, and a conclusion (at least at T2). This is remarkable as the study by Siekmann (2022) had shown that structure posed a major challenge for EFL learners at lower secondary level. Our study showed steep gains for this aspect above all in the German sample, where aspects related tostructure are explicitly mentioned in asssment criteria for the final exams. However, the fact that our analysis of structure was skewed towards high ratings see Appendix 5) might also indicate that our operationalization was too narrow for this age group. Future studies should look not only at the existence of elements such as introduction, main part, and conclusion, but aso analyze their internal quality.

# 5.3. Differences between countries

Results show that Swis leaners outerformed German learners i all aspects of text quality at both time-points, which i consistent with the holistic ratings of the same corpus (Keller et al., 2020). We believe that reason for wiss earners' generally higher writing skill lies in the fact that access to upper-secondary education is more restricted in Switzerland, with only the hghest-performing learners proceeding to that school type. The steep gains which German learners showed over one school year (particularly in the aspect of structure,see Fig. 1) can be see as testimony to the quality of instruction in German Gymnasiums. Aspects of structure and argumentation play a central role in German national educational tandards and test tasks (IQB, 2021), indicating a backwash effect. However, the consistently high scores for structure in both countries also suggest aceling effect which should be examined in future studies.

# 5.4. Limitations and further research

In this study, we frequently refer to learners' writing skils but should keep in mind that we only measured performance in two writing tass. To have a more rliable measure of writings kills one would have to ssess aners performance in alarger variet of situations and contexts. We should also keep in mind that only one year was examined and it is unclear whether the same trajectory of learning gains holds for each year of secondary education. Furthermore, ssues with reliability of some of our individual items underlying the three aspects of writing quality prevented us from analyzing texts at a more fine-grained level. Reliability improved when these items were summarized into broader aspects of writing, but detailed information about internal structure e.g., grammar and vocabulary within language quality) was lost along the way.

Further, it is unclear how wel students' skils shown in timed writing can be extrapolated to authentic, disciplinary writing tass in other contexts. Previous studies have examined the correlation between learners' scores on TOEFL iBT independent prompts and authentic writing tasks in higher education, finding only weak to moderate correlations between the two (Cho & Bridgeman, 2012; Ginther & Yan, 2017). Whil providing asolid indication of learners' argumentative writing skill, timed impromptu essay writing is limited in terms of its generalizability to ther acadmic genres (Staples et al, 2018). Itis equall uncler to what extent the reults of this study can be generalized beyond the geo-educational context of Switzerland and Germany. One could argue that these countries, with their shared emphasis on English as a gateway to academic suces, are representative of a range of countries in (or associated with) the European union. As English as a second or foreign language i taught all over the world, results might be relevant for EFL writing beyond the European context, for example for English L2 learners in America (Francis et al.; 2002). Based on the available studies, however, it stands to reason that the development of writing skills might be different for learners in other cultures with differing schol languages (e.g., Chinese, see Ling et al., 2014). Green (2005), for example, compared the writing scores of a large sample of writers in the IELTS writing tests over a period of several years and found considerable individual variation in the rate of writing score gains according to test-taker age and region of origin (e., East Asi vs. Europe). It would be useful to have more studies with a similarly broad operationalization of writing skill (including linguistic, sructural and content-related features) to understand how EFL writing development differs across geographical spaces and educational systems.

Additionall, it would be valuable to study in more detail how individual aspects of writing quality develop in the context of classroom teaching, either in observation studies or interventions. The results of this study are useful to gauge which aspects of EFL argumentative writing such future studies should focus on. Yet while textual analyses provide accurate, detailed information about the quality of learners' texts, they also raise important questions about the kind of instruction that produced these gains in understanding and skil, and the perspective of teachers and students about specific chllenges and they trategies they employed. For example, our data suggests that language quality should be afocus ofatention, i.e, mastering the complex lexical and grammaticalstructures that constitute English argumentative language and create the difference between a loosely structured opinion piece and a persuasive, compelling English argumentativessay. The larger question remains of how to integrate that formal focus with a classroom approach that encourages learners to find meaning in writing tasks, to revise their texts substantiall in response to (peer) feedback, and to progress substantiall in ESL writing by drawing on a wide range of linguistic and personal resources. Such questions go largely unanswered in this study but should take a prominent place in future ones.

# Author information

Stefan D. Keller (main author).

Stefan Kellr is Professor of English teaching and learning and Head of Subject Specific Research at Zuerich University of Teacher Education. He has published widely on Writing in English as a Second Language. His paper English writing kill of students in upper secondary education: Results from an empirical study in Switzerland and Germany" was for many months the most downloaded paper of JoSLW.

# CRediT authorship contribution statement

Johanna Fleckenstein: Conceptualization. Ruth Trueb: Writing - review & editing, Writing - original draft, Data curation. Jennifer Meyer: Writing - review & editing, Writing - original draft, Formal analysis. Jens Moller: Writing - rview & editing, Writing  original draft Validation, Supervision, Resources, Proect administration, Methodology, Investigation, Funding acquisition, Conceptualization. Thorben Jansen: Writing - review & editing, Writing - original draft, Conceptualization. Julian Lohmann: Writing - review & editing, Writing - original draft, Investigation, Formal analysis, Data curation. Stefan Daniel Keler: Writing - review & editing, Writing - original draft, Validation, Supervision, Resources, Project administration, Methodology, Investigation, Funding acquisition, Formal analysis, Data curation, Conceptualization.

# Data availability

Data will be made available on request.

# Appendix 1. Analytic assessment scheme (sub-scales) employed in this study

Table A1 Assessment Criteria, Subscales and Type of Assessment for Language Quality.   

<html><body><table><tr><td>Aspect</td><td>Variable</td><td>Assessment type</td></tr><tr><td rowspan="6"> Lexical quality</td><td>Correctness of vocabulary</td><td>1</td></tr><tr><td>Variability of vocabulary</td><td>2</td></tr><tr><td>Register (degree of formality, overly informal expressions)</td><td>2</td></tr><tr><td>Number of structuring words</td><td>1</td></tr><tr><td>Quality of structuring words</td><td>2</td></tr><tr><td>Correctness of grammar</td><td>1</td></tr><tr><td rowspan="3"></td><td>Spelling / Orthography</td><td>1</td></tr><tr><td>Typos</td><td>2</td></tr><tr><td> Punctuation</td><td>1</td></tr></table></body></html>

Note. ${ \bf 1 } =$ Likert scale (1-7 based on number of mistakes or instances of a phenomenon); $2 =$ binary coding (appropriate / inappropriate)

Table A2 Assessment Criteria and Sub-scales for Content.   

<html><body><table><tr><td>Aspect</td><td>Variable</td><td>Assessment type</td></tr><tr><td></td><td>Topic of essay becomes clear</td><td>2</td></tr><tr><td></td><td>Hook (author attempts to catch the reader&#x27;s attention)</td><td>2</td></tr><tr><td>Introduction</td><td>Author&#x27;s own opinion is made clear</td><td>2</td></tr><tr><td>Main body of essay</td><td>Arguments for both sides of the question are mentioned</td><td>3</td></tr><tr><td>Conclusion</td><td>Author repeats opinion clearly</td><td>2</td></tr><tr><td></td><td>Relevance of arguments for prompt</td><td>3</td></tr><tr><td>Argumentation</td><td>Importance of arguments is marked</td><td>2</td></tr></table></body></html>

Note. $2 =$ binary coding (appropriate / inappropriate), $3 =$ Likert scale (fully appropriate, party appropriate, inappropriate)

Table A3 Assessment Criteria and Sub-Scales for Structure.   

<html><body><table><tr><td>Aspect</td><td>Variable</td><td>Assessment type</td></tr><tr><td> Paragraphs</td><td>Use of paragraphs</td><td>3</td></tr><tr><td rowspan="3">Introduction</td><td>Existence of an introduction</td><td>2</td></tr><tr><td>Explicit marking of the introduction</td><td>2</td></tr><tr><td>Existence of a conclusion</td><td>2</td></tr><tr><td>Conclusion</td><td>Explicit marking of the conclusion</td><td>2</td></tr></table></body></html>

Note. $2 =$ binary coding (appropriate / inappropriate), $3 =$ Likert scale (fully appropriate, party appropriate, inappropriate)

Appendix 2. Rating design and rater pairs used in this study   

<html><body><table><tr><td></td><td>01/</td><td>01/</td><td>01/</td><td>01/</td><td>01/</td><td>02/</td><td>02/</td><td> 02/</td><td>02/</td><td>03/</td><td> 03/</td><td>03/</td><td>04/</td><td>04/</td><td>05/</td></tr><tr><td></td><td>02</td><td>03</td><td>04</td><td>05</td><td>06</td><td>03</td><td>04</td><td>05</td><td>06</td><td>04</td><td>05</td><td>06</td><td>05</td><td>06</td><td>06</td></tr><tr><td>N (TE)</td><td>71</td><td>60</td><td>43</td><td>64</td><td>75.</td><td>99</td><td>57</td><td>98</td><td>81</td><td>58</td><td>82</td><td>97</td><td>71</td><td>52</td><td>112</td></tr><tr><td>N (AD)</td><td>82</td><td>73</td><td>58</td><td>73</td><td>74</td><td>100</td><td>51</td><td>112</td><td>93</td><td>54</td><td>111</td><td>99</td><td>40</td><td>46</td><td>103</td></tr><tr><td>N (total)</td><td>153</td><td>133</td><td>101</td><td>137</td><td>149</td><td>199</td><td>108</td><td>210</td><td>174</td><td>112</td><td>193</td><td>196</td><td>111</td><td>98</td><td>215</td></tr></table></body></html>

# Appendix 3. Interrater reliability

Highlighted area in content concerns rater 2, whose reliability was consistently ower than that of the other raters and who was therefore excluded from further analysis.

Table A4 Rater Pairs for All Texts.   
Table A5 Confusion Matrices for Interrater Reliability (Cohen's Kappa).   

<html><body><table><tr><td colspan="7">A5.1 Language Quality</td></tr><tr><td></td><td>Rater 1</td><td> Rater 2</td><td> Rater 3</td><td>Rater 4</td><td> Rater 5</td><td>Rater 6</td></tr><tr><td>Rater 1</td><td>-</td><td>0.609</td><td>0.792</td><td>0.734</td><td>0.763</td><td>0.734</td></tr><tr><td>Rater 2</td><td>0.609</td><td>-</td><td>0.686</td><td>0.714</td><td>0.653</td><td>0.664</td></tr><tr><td>Rater 3</td><td>0.792</td><td>0.686</td><td>-</td><td>0.69</td><td>0.762</td><td>0.752</td></tr><tr><td>Rater 4</td><td>0.734</td><td>0.714</td><td>0.69</td><td>-</td><td>0.661</td><td>0.592</td></tr><tr><td>Rater 5</td><td>0.763</td><td>0.653</td><td>0.762</td><td>0.661</td><td>-</td><td>0.736</td></tr><tr><td> Rater 6</td><td>0.734</td><td>0.664</td><td>0.752</td><td>0.592</td><td>0.736</td><td>-</td></tr><tr><td colspan="7">A5.2 Structure</td></tr><tr><td></td><td> Rater 1</td><td> Rater 2</td><td>Rater 3</td><td>Rater 4</td><td> Rater 5</td><td>Rater 6</td></tr><tr><td>Rater 1</td><td>-</td><td>0.786</td><td>0.806</td><td>0.719</td><td>0.706</td><td>0.738</td></tr><tr><td>Rater 2</td><td>0.786</td><td>-</td><td>0.801</td><td>0.64</td><td>0.655</td><td>0.752</td></tr><tr><td>Rater 3</td><td>0.806</td><td>0.801</td><td>-</td><td>0.695</td><td>0.737</td><td>0.824</td></tr><tr><td>Rater 4</td><td>0.719</td><td>0.64</td><td>0.695</td><td>-</td><td>0.585</td><td>0.733</td></tr><tr><td>Rater 5</td><td>0.706</td><td>0.655</td><td>0.737</td><td>0.585</td><td>:</td><td>0.66</td></tr></table></body></html>

Table A5 (continued)   

<html><body><table><tr><td>A5.2 Structure</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>Rater 1</td><td> Rater 2</td><td>Rater 3</td><td>Rater 4</td><td> Rater 5</td><td>Rater 6</td></tr><tr><td>Rater 6</td><td>0.738</td><td>0.752</td><td>0.824</td><td>0.733</td><td>0.66</td><td></td></tr><tr><td>A5.3 Content</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td>Rater 1</td><td> Rater 2</td><td>Rater 3</td><td>Rater 4</td><td>Rater 5</td><td> Rater 6</td></tr><tr><td>Rater 1</td><td></td><td>0.524</td><td>0.659</td><td>0.548</td><td>0.622</td><td>0.698</td></tr><tr><td>Rater 2</td><td>0.524</td><td>1</td><td>0.554</td><td>0.432</td><td>0.401</td><td>0.488</td></tr><tr><td>Rater 3</td><td>0.659</td><td>0.554</td><td>1</td><td>0.573</td><td>0.675</td><td>0.649</td></tr><tr><td>Rater 4</td><td>0.548</td><td>0.432</td><td>0.573</td><td>1</td><td>0.542</td><td>0.55</td></tr><tr><td>Rater 5</td><td>0.622</td><td>0.401</td><td>0.675</td><td>0.542</td><td>-</td><td>0.597</td></tr><tr><td> Rater 6</td><td>0.698</td><td>0.488</td><td>0.649</td><td>0.55</td><td>0.597</td><td>:</td></tr></table></body></html>

As Table A5.3 shows, coefficients are consistently lower for rater 2, who was subsequently excluded from the analysis (shaded numbers).

Table A6 Interrater Reliabilities for the Three Aspects of Writing quality, Differentiated by Writing Prompt.   

<html><body><table><tr><td></td><td> Interrater correlation Mean</td><td>Interrater correlation Median</td><td>Weighted Cohen&#x27;s Kappa Mean</td><td>Weighted Cohen&#x27;s Kappa Median</td></tr><tr><td> Language quality</td><td>0.75</td><td>0.77</td><td>0.72</td><td>0.74</td></tr><tr><td>Prompt AD</td><td>0.73</td><td>0.73</td><td>0.71</td><td>0.71</td></tr><tr><td>Prompt TEe</td><td>0.75</td><td>0.76</td><td>0.72</td><td>0.73</td></tr><tr><td>Structure</td><td>0.72</td><td>0.73</td><td>0.72</td><td>0.73</td></tr><tr><td>Prompt AD</td><td>0.68</td><td>0.70</td><td>0.68</td><td>0.70</td></tr><tr><td>Prompt TE</td><td>0.76</td><td>0.76</td><td>0.77</td><td>0.76</td></tr><tr><td>Content</td><td>0.64</td><td>0.64</td><td>0.61</td><td>0.61</td></tr><tr><td>Prompt AD</td><td>0.68</td><td>0.70</td><td>0.66</td><td>0.67</td></tr><tr><td>Prompt TEe</td><td>0.56</td><td>0.57</td><td>0.52</td><td>0.52</td></tr></table></body></html>

# Appendix 4. Model fits and comparisons between models

To account for stable between-rater differences and to obtain text-quality scores adjusted for these stable "rater-effcts", we chose an IRT-based many-facets rater modeling approach. In doing so, we set up a series of models and performed stepwise model extensions (Robitzsch & Steinfeld, 2018). We started with a restrictive model, only considering independent effects for each item (language quality vs. structure vs. content), raer, and item-categories (category-steps ranging from 0 to 6). Next, we incorporated step-by-step interaction terms between these three factors until we reached the fll many-facets Rasch model (MFRM) (item\*step\*rater) (models 1.1-1.5). We found that the most complex model (model 1.5) itted the data best (ee Table 7). It encompassed rater-specific leniency / severity and extremity / centrality differing across items.

In a final step, we also teste for differences in rater-discrimination, often referred to as rater consistency or rater accuracy (Model 2.1-2.2). Again, we considered interactions with items (Model 2.2). Fit statistics implied considerable between-rater differences in rater-discrimination varying across items. Thus, we used Model 2.2, the most complex model, to calculate the fair scores for further analyses. In doing so, we accounted for between-rater differences i leniency / everity, extremity / centrality anddscrimination (Uto & Ueno, 2020).

Table A7 Fits and Model Comparisons.   

<html><body><table><tr><td></td><td>Effects</td><td> Npars</td><td>Deviance</td><td>AIC</td><td>BIC</td><td>Chi2</td><td>df</td><td>p (LRT)</td></tr><tr><td>Model 1.0</td><td> Item + rater</td><td>13</td><td>41899.5</td><td>41925.5</td><td>42000.2</td><td>-</td><td></td><td></td></tr><tr><td>Model 1.1</td><td> Item + step + rater</td><td>18</td><td>32648.7</td><td>32684.7</td><td>32788.1</td><td>9250.8</td><td>5.</td><td>&lt;.001</td></tr><tr><td>Model 1.2</td><td>Item*step + rater</td><td>28</td><td>31496.4</td><td>31552.4</td><td>31713.3</td><td>1152.3</td><td>10</td><td>&lt;.001</td></tr><tr><td>Model 1.3</td><td>Item*step + item*rater</td><td>36</td><td>31195.6</td><td>31267.6</td><td>31474.5</td><td>300.7</td><td>8</td><td>&lt;.001</td></tr><tr><td>Model 1.4</td><td>Item*step + item*rater + step*rater</td><td>56</td><td>30964.7</td><td>31076.7</td><td>31398.6</td><td>230.9</td><td>20</td><td>&lt;.001</td></tr><tr><td>Model 1.5</td><td>Item*step*rater</td><td>96</td><td>30653.4</td><td>30845.4</td><td>31397.1</td><td>311.3</td><td>40</td><td>&lt;.001</td></tr><tr><td>Model 2.1</td><td> Model 1.5 + rater discrimination</td><td>98</td><td>31690.2</td><td>31886.2</td><td>32449.4</td><td>-1036.9</td><td>2</td><td>1</td></tr><tr><td>Model 2.2</td><td> Model 1.5 + rater*item discrimination</td><td>108</td><td>30600.1</td><td>30816.1</td><td>31436.8</td><td>1090.1</td><td>10</td><td>.001</td></tr></table></body></html>

![](img/714a529636463d89f33edda0a4a4733998f3ae3d4bf35d66581f505e9da2f696.jpg)  
Appendix 5   
Fig. A1. Distribution of Ratings for the Three aspects of text quality. Note. Likert scale ( $0 =$ very low quality; $6 =$ very high quality).

# Appendix 6

Table A8 Exploring Interaction Effects Among Factors Prompt, Time, and Country.   

<html><body><table><tr><td> Predictor</td><td colspan="4">Language quality</td><td colspan="4">Structure</td><td colspan="4">Content</td></tr><tr><td></td><td>Est.</td><td>SE</td><td>t</td><td>p</td><td>Est.</td><td>SE</td><td>t</td><td>p</td><td>Est.</td><td>SE</td><td>t</td><td>p</td></tr><tr><td>Time</td><td>9.29</td><td>1.97</td><td>4.73</td><td>&lt;.001</td><td>51.18</td><td>3.61</td><td>14.18</td><td>&lt;.001</td><td>25.54</td><td>1.78</td><td>14.37</td><td>&lt;.001</td></tr><tr><td>Country</td><td>5.30</td><td>3.56</td><td>1.49</td><td>0.136</td><td>-4.45</td><td>3.55</td><td>-1.25</td><td>0.210</td><td>22.17</td><td>3.92</td><td>5.65</td><td>&lt;.001</td></tr><tr><td>Prompt (Reference: AD)</td><td>-2.92</td><td>1.88</td><td>-1.55</td><td>0.121</td><td>25.59</td><td>1.78</td><td>14.41</td><td>&lt;.001</td><td>-2.17</td><td>1.74</td><td>-1.25</td><td>0.212</td></tr></table></body></html>

Table A8 (continued)   

<html><body><table><tr><td></td><td colspan="4"> Language quality</td><td colspan="4">Structure</td><td colspan="4">Content</td></tr><tr><td> Predictor</td><td>Est.</td><td>SE</td><td>t</td><td>p</td><td>Est.</td><td>SE</td><td>t</td><td>p</td><td>Est.</td><td>SE</td><td>t</td><td>p</td></tr><tr><td>Time*Country</td><td>-0.12</td><td>1.95</td><td>-0.06</td><td>0.951</td><td>22.15</td><td>3.91</td><td>5.66</td><td>&lt;.001</td><td>-1.38</td><td>1.88</td><td>-0.73</td><td>0.463</td></tr><tr><td>Time*Prompt</td><td>-13.49</td><td>1.90</td><td>-7.11</td><td>&lt;.001</td><td>-2.17</td><td>1.74</td><td>-1.25</td><td>0.212</td><td>-18.94</td><td>2.04</td><td>-9.28</td><td>&lt;.001</td></tr><tr><td>Time*Country*Prompt</td><td>3.73</td><td>1.96</td><td>1.90</td><td>0.058</td><td>-18.94</td><td>2.04</td><td>-9.30</td><td>&lt;.001</td><td>-1.37</td><td>1.79</td><td>-0.76</td><td>0.445</td></tr></table></body></html>

Prompt effects were inserted as predictors of writing skill in our regression models. The prompt dummy was effect coded with reference AD. The analysis presented in Table A9 revealed significant interaction effects between time and prompt for content $\boldsymbol { { \mathit { b } } } =$ 18.94, $p < . 0 0 1 \mathrm { \AA }$ and language quality $( b = - 1 3 . 4 9 , p = . 0 0 1 )$ . Both interaction terms indicate that the time at which learners worked on those prompts (T1 or T2) is correlated significantly with the scores they achieved for those prompts. These interaction effects are illustrated in Figure A2.

![](img/d9821bfa62ec3af282d545ba482b52a006973426a1d82ead9b9bc8d3ced97f86.jpg)  
Fig. A2. Diffrnces Between the Prompts Relating to Language quality (A) and Content B) Regarding the Sequence in which Learners Worked on Them.

As Figure A2 shows, the growth which observe in the aspects of language quality and content was influenced in part by the sequence in which students worked on the two prompts. Students who irst worked on AD had slightly lower scores than students who worked on TE at T1. Conversely, students who worked on AD second had sightly higher scores than those who worked on TE at T2. One reason might be that AD was arelatively astract and distal topi for the learners in our sample and was therefore more difficult to do at T1 (see also Atak & Saricaoglu, 2021). We noticed in the rating process that many learners did not properly understand that this prompt required themto discuss the specific danger of advertising directed at very young children. Instead, they often wrote about the dangers of excessve TV watching in general. For students who worked on AD at T2, it sems to have been easier to overcome those challenges, leading to slightly better results both in content and in language quality (which also included aspects of topic-specific vocabulary). This would also explain why structure, which was the most general aspect of text quality in our operationalization, was not affected by this effect.

# References

competences in foreign languages: Tasks, assessment, feedback]. Narr.   
Andrade, H. G. (2005). hing with rubrics: The go0, the ad, and the gl. Cee chig 53(1), 27-31. htps./o.org/10.3200/H.53.1.27-31   
Atak, . ar21). yic xt   r iv w  st nd h h eft g Writing, 47, 1-11. https://doi.org/10.1016/j.asw.2020.100506 0265532209349470   
Bae, ., er,    (2016. te  f  i wng   ly, 13(4, 302-2/i.g/0.1080 15434303.2016.1246552   
Barkaoui, K, Hdi,  (2020). sn chnge in nish od ng win pfce. Rge. /oi.g/0.324/9781003092346   
rkau, 0  t   e , .. org/10.1080/15434300903464418   
Bkaui, 007).   t o  makg  - .sn  2 6107 h/./0.101/.200.0.01   
acha . (2001n t c ti v stc scg el e 93), 371-33 h/./.101/0346251(01) 00025-2   
t  r,     . 15.   .   1 ./i. 10.18637/jss.v067.i01   
Berman, R. (1994). Learners' transfer of writing skills between languages. TESL Canada Jounal, 12, 29-46.   
m   e 0   f  i interventions. Journal of Research on Educational Effectivenes, 1(4), 289-328. https:/doi.org/10.1080/19345740802400072   
Bhatia, V. K. (2004). Worlds of written discourse: A genre-based view. Continuum.   
Breerich-,  16 ch    in r  rsch suchg [Writing competences of beginning students in teacher education: An empirical study]. Schneider. Meta-analytic results from Germany. Jounal of Reearch on Educational Effectives.htps://doi.org/10.1080/19345747.2023.2175753   
Cho, Y., & Bridman, . (2012). Rtionhip f TE  scres to c pomance: Some ice from Amrican verie. ge ting 29, 421-442.   
Choi    t 111) Educational Testing Service.   
Council of Europe. (2001). Common European framework of reference for languages. Cambridge.   
Crossle,  (st   qty     f c (, 15-3/.17239 jowr-2020.11.03.01 https://doi.org/10.1002/9781405198431.wbeal1299.   
shng, . 019. of wting ll ., The f  inic (1st  . -. e. h/g/0.1002 9781405198431.wbeal0056.pub2.   
Eckes, T. (2015). Introduction to many facet Rasch measurement Analyzing and evaluatig rater-medated asessments (Second ed.). Peter Lang.   
Ellis, R. (2008). Second language acquisition studies. Oxford.   
Educational Testing Service [ETS]. (2009). The official guide to the TOEFL test. McGraw-Hill.   
Ferrt, R s,  209 t i  iwin   ,  in instruction (3rd ed.,, pp. 135-161). Guilford Press.   
,0 te a standard setting study. Assessing Writing, 41, 1-15. https:/doi.org/10.1016/j.asw.2019.100420   
ais ,  t ,  no n a n-li psi   r .,  ( 134 . 173.ld p/./.1016/0166-4115 (02)80017-6.   
ter,  017). th   , , .   352, 271-295. https:/doi.org/10.1177/0265532217704010   
Green, A. (2005). EAP study recommendations and score gains on the IELTS academic writing test. Assessing Writing, 10, 44-60.   
Gm f   .i Research, 90(2), 179-226. https://doi.org/10.3102/0034654320914744   
Grotjahn, R, i,  017). irile ati o rmp Criria m f wtin ome.  B. ke Gja, s. Sch .     n languages. Tasks, assessment, feedback] (pp. 117-157). Narr.   
Grund, s., Robitzsch, A., & Ludtke, O. (2016). Package mitml'. Retrieved from (htp:/cran.r-project.org/web/packages/mitml/).   
Hardy, M. (1993). Regression with dummy variables. Sage Publications, Inc   
Hmke  r    r 00 r onrt .,  r  nh h    . org/10.25656/01:3521.   
Hut . (190. it, alt, d sic cWh w k dh  d  .  ion an io, 42), 201-213.   
Hyland, K (1990.  genredescription of th arumentatie essa. RELC Journal, 21(1, 66-78. htps://doi.org/0.1177/368829002100105   
Hyland, K. (2008). Second language writing. Cambridge University Press.   
Jaobs  a   e (1iP ie r /a. net/publication/247716030_Testing ESL_ Composition a Practical Approach#fullextFileContent) (Accessed 23 November 2023). in Switzerland and Germany. Journal of Second Language Writing, 48, 1-13. https:/doi.org/10.1016/jjslw.2019.100700   
Kel,  i r e   el. Theory, process design, research]. Narr.   
m .   i    in2 n  io , 2-0. /. org/10.7820/vli.v10.2.kramer   
Kollr, ., Knige M, & Tech, . (2010. Sprachliche Kompetenzen im Landererglech [National comparison of language competences). Waxman.   
yle   1    y   cn Language Acquisition, 43(4), 781-812. https://doi.org/10.1017/s0272263120000546   
Landr   ,  r  2 th it f ive   l  ffe rating procedures and exploring inferences of (dis)agreement cases. Frontiers in Educatio, 7 https://doi.org/10.3389/feduc.2022.784261   
ch    5f  f of Gyas prfle on pmae dme in gish chif fir Pch Pgie, 292) 77-8. /.g/10.1024/010-0652 a000153   
Lig  er,   , 2014   s re mo  s- n t   y gment (Research Report No. RR-14-09). Educational Testing Service.   
Lu, . (2011). - tion f ytic xty me a inef ee  wir met.  l, 451) 36-62. https://doi.org/10.5054/tq.2011.240859 e alrii eischg tie  ft a -cs and advantages of analytcl vs. holisticassesment. Jonal for Educational Reearch Online, 8(2), 107-135. htps://doi.org/10.25656/01:12429   
Polo . (2017  a wn d h d  hg 502) 61-275. t//./01017/06148170005   
ational tisifif wan F. 016)tq.  axamsed f /.hs/d/ome) (Accessed 9 June 2024).   
Prm competences of students in international comparison]. Leske & Budrich.   
Raudenbush, S. W., & Bryk, A. S. (2002). Hierarchical linear models: Applications and data analysis methods (Vol. 1). Sage.   
ch    . / R-project.org/package=miceadds) (last accessed on 9.6.2024).

Modelig, 60(1), 101-139. tp://w.scgie-akl.com/fld/wd/t/1-201820180323/6PAM_RHRMain_2018-03-13146.) u       01 Report No. RR-86). Educational Testing Service. https://doi.org/10.1002/ets2.12249 Sader,  (1989. mtie at d the  f intctio stm. Intti Sciece, 18 119-14. p/./0.107/0017714 Sh0a      e assessments. L1 Educational Studies in Language and Litrature, 16(1), 1-22. https:/doi.org/10.17239/L1ESLL-2016.16.01.03 Sri and Writing. https://doi.org/10.1007/s11145-022-10276-4 Schoonen, R. (2005). Generalizability of writing scores: An application of sructural quation modeling. Language Testing,2, 1-30. Writing, 54, 1-13. https://doi.org/10.1016/j.asw.2022.100672 Abl 20072016  c af 007-206./k-tisti schulstatistik/schueler-klassen-lehrer-und-absolventen.html) (last accessed on 9.6.2024). Stag ft  ff td  t01  e frih  e o f  uer secondary education]. Wolters. Stape, , br   01 u-er a tt ict hta  xm str ri TOEFL iBT and disciplinary writing tasks. The Modern Language Journal, 102(2), 310-332. https:/doi.org/10.111/mod.12465 wis f    . EDK. Tad,  006). rst  d   g tive d k .  f  n 2), 79-101. Tardy, C., & Swales, J. (2014). Genre analysis. In K. P. Schneider, & A. Barron (Eds.) Pragmatics of Discowrse (pp. 165-187). De Gruyter. Trub, R. (2022). An Empirical Study of EFL Writing at Primary School. Narr. Uto, M. & Ueo,. (2020.  geralizd many-fct Rasch model nd it ayian estimation sig onian Mnte C. vimerik, 47, 469496. https://doi.org/10.1007/s41237-020-00115-7 van  11i      i, 453 17. /.g 10.18637/jss.v045.i03 erpor, 1).  sts ty     n .) iyy Diane Larsen-Freeman (Vol. 48, pp. 143-162). John Benjamins. Wu, M. (2017). Some IRT-based analyses for interpreting rater effcts. Psychological Test and Asssment Modeling, 59(4), 453-470. Zemach, D., & Stafford-Yilmaz, L. (2008). Writers at work. The essay. Cambridge University Press.