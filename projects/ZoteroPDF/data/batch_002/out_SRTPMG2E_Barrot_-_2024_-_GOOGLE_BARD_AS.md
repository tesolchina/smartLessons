# GOOGLE BARD AS AN AUTOMATEDWRITTEN CORRECTIVE FEEDBACK TOOL:POSSIBILITIES AND DRAWBACKS

Jessie S. Barrot $\textcircled{1}$

National University, Manila, Philippines

# https://bard.google.com

Recent technological advancements have given rise to generative artificial intelligence (AI) tools capable of producing a variety of content types, including texts, images, videos, and sounds, in response to specific prompts (Pavlik, 2023). One such tool is Google Bard (or simply Bard), which was introduced as an experimental version on March 21, 2023, and made accessible in 238 countries. Despite its potential for pedagogical use, some educators have voiced concerns regarding its suitability. In fact, Google has explicitly cautioned its employees against inputting any confidential materials into similar tools (Faguy, 2023). Given the diverse range of opinions surrounding its use, it is essential to examine the features and challenges associated with utilizing Bard, especially within the context of second language (L2) writing. Moreover, this review sheds light on the different affordances of Bard as an automated writing evaluation system. This media review paper on Bard as an automated written corrective feedback (AWCF) tool is grounded in Gibson's (1986) theory of affordances. According to this theory, affordances refer to the perceived and actual opportunities for action that an environment or an object provides to an organism. This theory was constructed based on the idea that affordances (1) are perceived by the individual based on their abilities and the characteristics of the environment, (2) guide the individual's behavior and interactions with the environment, and (3) are objective properties of the environment that can be directly perceived. Thus, it emphasizes the importance of the relationship between the individual and the environment in shaping behavior and cognition. In the context of learning technologies, affordance theory focuses on how Bard's features and functionalities afford certain actions and interactions for users.

Bard is a conversational AI chatbot that mimics human interactions and delivers contextually relevant responses (Bard, 2023). It is powered by PaLM2, a robust language model capable of performing advanced tasks like multilingual translation, classification, and question answering. To access Bard, visit bard.google.com and log in using your personal Google account. You can access it online through widely-used web browsers such as Safari and Chrome. To initiate your interaction with this tool, simply input a prompt into the provided text box and click the “proceed” button beside the text box. Figure 1 illustrates the Bard dashboard, showcasing the menu button, text box, disclaimers, and precautions.

![](img/16aa1d19df084dc911e45bb3c123f6c8b7ccf98b6f86caa98e86715d41ab0cc5.jpg)  
FIGURE 1 Bard dashboard.

Bard presents a range of features particularly valuable for language learning. Notably, it excels in generating linguistically precise and contextually relevant content, serving as a valuable source of English language input for learners. Its human-like responses offer users the opportunity to practice the English language at their convenience, anywhere and any time. Additionally, Bard's memory of prior prompts and responses enables it to sustain conversations in a manner akin to natural human interaction. To enhance the personalized nature of interactions, Bard generates distinct text every time a user inputs a prompt, meaning that the same query may yield various expressions of the same concept.

Bard offers a wide array of writing assistance capabilities. In the pre-writing phase, Bard can generate essay topics across various disciplines and refine them based on specific criteria. Once a topic is chosen, it can facilitate brainstorming, aiding students in generating ideas for outlining. However, it is worth noting that while Bard can produce outlines, it sometimes struggles with formatting correctness and can display rigidity in organizing ideas by adhering to the same pattern or template. In contrast to ChatGPT, Bard has the unique ability to access up-to-date information, which can greatly assist students in gaining a deeper understanding of concepts when crafting their drafts. Nevertheless, it is crucial to emphasize that the content generated by Bard should only be used as a guide and not as the actual content of essays due to ethical and accuracy concerns. In fact, there are existing systems, such as Turnitin, that claim the capability to detect AI-generated texts.

While Bard can be a valuable writing assistant, it does have some limitations and drawbacks. Firstly, it has a tendency to generate inaccurate information. For instance, when prompted to list scholarly references on chatbots, Bard may provide bibliographic information that is either incorrect or nonexistent. This issue underscores the importance of using Bard cautiously as a content generator. Moreover, as an AI system, Bard lacks emotional depth and a distinct voice, which is reflected in its generated content. Consequently, this presents an opportunity for educators to emphasize these two aspects in the teaching and practice of writing in English classrooms.

Bard's ability to provide AWCF is a key affordance that addresses the need of L2 writers for timely and quality feedback. AWCF refers to the feedback given by an automated writing evaluation system about a piece of writing. There are three key tasks that Bard can perform as an AWCF tool: (1) it provides qualitative feedback, (2) it assigns automated scores, and (3) it performs automated language editing. First, this AI tool is capable of providing a wide range of feedback that L2 writers can use to enhance their writing and facilitate the learning process. Feedback tends to be richer and more focused when specific parameters or criteria are set. Among the areas that Bard can evaluate are grammar and mechanics, sentence structure and clarity, word choice, structure and organization, content, cohesion, idea development, style and tone, and audience awareness. Bard highlights both the strengths and weaknesses of the text and makes suggestions on how the text can be further improved. When the approach is an open-ended assessment (i.e., no predetermined criteria), Bard generated feedback based on its massive collection of patterns and associations. This capability to provide qualitative feedback can be utilized for individualized guidance, allowing teachers to offer detailed comments on students' writing and address specific areas of improvement. The qualitative feedback serves as a valuable formative assessment tool and aids teachers in identifying common writing challenges across the class. Encouraging students to reflect on the feedback fosters a deeper understanding of writing conventions and promotes active learning.

Second, this AI tool is capable of assigning holistic and analytic scores to written texts based on its own parameters or based on predetermined criteria. Bard uses scoring algorithms to calculate scores based on the analysis of the essay's content. These algorithms are designed to weigh different aspects of writing. Along with the numerical data are justifications for each assigned score, which are useful for formative and summative assessment purposes. Pedagogically, the scoring features of Bard prove efficient for teachers in grading a large volume of writing assignments promptly. The automated scoring feature ensures consistency in evaluation, as all submissions are assessed based on predefined criteria. The quick feedback turnaround enables teachers to provide timely insights to students and facilitates the learning-from-mistakes process and subsequent improvement. However, it is not clear whether these scores are valid and reliable and can mimic experienced human raters. Initial data indicates that Bard's automated essay scoring varies between two time points.

Finally, Bard serves as an automated language editor, enhancing the mechanics, grammar, syntax, vocabulary, flow, and organization of a written text. To do this, the user may instruct Bard through these prompts or similar prompts: Edit the following text or Improve the grammar and language of the following text. Bard's editing capability can be utilized as a way to teach language forms to students by allowing them to compare their original work with the edited version. This aligns with the noticing hypothesis, which posits that learners need to consciously notice and pay attention to specific linguistic features in the input (i.e., edited version) before they can internalize and acquire those features (Schmidt,  1990). With this affordance, teachers can guide students on effective use, helping them identify and correct grammatical errors. By relying on automated language editing for mechanical corrections, teachers can allocate more time to teach higher-order writing skills, such as critical thinking and content development.

It is important to note that generative AI tools, including Bard, are still under development. It is not yet clear whether the scores and feedback that Bard assigns to written texts are as valid and reliable as those assigned by experienced human raters. Additionally, AWCF tools can sometimes provide inaccurate or misleading feedback, especially if the text is complex or poorly written. Hence, empirical studies are needed to verify the efficacy of Bard as an AWCF tool.

While Bard is currently in its experimental stage, it is poised to significantly influence L2 writing pedagogy in the years ahead. Writing instructors must familiarize themselves with its intricacies and be well-prepared to systematically and ethically incorporate this technology into writing instruction. Furthermore, a comprehensive evaluation of Bard's capabilities is essential to identify any system weaknesses and rectify them for more efficient utilization. Examining students' cognitive, behavioral, and affective engagement with the tool is also a research area deserving of attention. Gaining insights into how students interact with Bard can inform the design of more effective and engaging educational experiences. Bard, with its ability to offer personalized guidance, foster authentic interaction, and adapt to the unique learning needs of individuals, holds transformative potential in the L2 writing domain. However, as we tread the path of technological advancement, it is imperative that we proceed with vigilance, recognizing the ethical and pedagogical implications inherent in generative AI tools. While Bard can provide valuable qualitative feedback, it is essential to remember that this tool is not a perfect replacement for human evaluators, especially in cases where nuanced, context-specific feedback is required. For now, it is safe when used as a supplementary tool alongside human evaluation.

# ORCID

Jessie S. Barrot $\textcircled { 1 }$ https://orcid.org/0000-0001-8517-4058

# REFERENCES

Bard. (2023). Bard FAQ. https:bard.google.com/faq   
Faguy, A. (2023, June 15). Google warns employees about chatbots—including its own Bard—out of privacy concerns, report says. Forbes. https://www.forbes.com/sites/anafaguy/2023/06/15/google-warns-employeesabout-chatbots-including-its-own-bard-out-of-privacy-concerns-report-says/?sh $\displaystyle =$ 63d5150eb613   
Gibson, J. J. (1986). The ecological approach to visual perception. Mahwah, NJ: Lawrence Erlbaum.   
Pavlik, J. V. (2023). Collaborating with ChatGPT: Considering the implications of generative artificial intelligence for journalism and media education. Journalism and Mass Communication Educator, 78(1), 84–93. https:// doi.org/10.1177/10776958221149577   
Schmidt, R. (1990). The role of consciousness in second language learning. Applied Linguistics, 11, 129–158. https://doi.org/10.1093/applin/11.2.129