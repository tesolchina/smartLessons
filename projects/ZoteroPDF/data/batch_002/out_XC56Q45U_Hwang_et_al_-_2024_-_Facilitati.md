# Facilitating authentic contextual EFL speaking and conversation with smart mechanisms and investigating its influence on learning achievements

Wu-Yuin Hwang, Bo-Chen Guo, Anh Hoang, Ching-Chun Chang & Nien-Tsu Wu

To cite this article: Wu-Yuin Hwang, Bo-Chen Guo, Anh Hoang, Ching-Chun Chang & NienTsu Wu (2024) Facilitating authentic contextual EFL speaking and conversation with smart mechanisms and investigating its influence on learning achievements, Computer Assisted Language Learning, 37:7, 1632-1658, DOI: 10.1080/09588221.2022.2095406

To link to this article: https://doi.org/10.1080/09588221.2022.2095406

# Facilitating authentic contextual EFL speaking and conversation with smart mechanisms and investigating its influence on learning achievements

Wu-Yuin Hwanga $\textcircled{1}$ , Bo-Chen Guoa , Anh Hoanga $\textcircled{1}$ , Ching-Chun Changb and Nien-Tsu Wua

a Graduate Institute of Network Learning Technology, National Central University, Taoyuan City, Taiwan; bDepartment of Computer Science, University of Warwick, Coventry, UK

# ABSTRACT

This study introduced an app, called Smart UEnglish, for helping EFL conversation practices in authentic contexts. These conversation practices were categorized into ‘designed talk’ and ‘free talk’, based on the content of an English textbook and authentic ambient environment that includes such things as transportation, weather and scenic descriptions, respectively. The mechanisms in Smart UEnglish were designed in consideration of flexible, sustainable and adaptive conversations to improve English-speaking and lexical resources. Statistical analysis results show that the learning achievement of the experimental group is significantly higher than that of the control group. Moreover, both ‘designed talk’ and ‘free talk’ have significant positive correlations with learning achievement. Further analysis with stepwise multiple regression found that ‘designed talk’ plays the most important role and can significantly influence learning achievement. This is because ‘designed talk’ can motivate them to practice what they learned in class during their daily conversations and consolidate the understanding and applying of English vocabularies and sentence patterns through ‘designed talk’. According to interview records, participants also perceived that using Smart UEnglish for conversation practice in authentic contexts can stimulate their interests and ideas to think and practice more useful English conversation. Hence, Smart UEnglish can effectively help English-speaking and conversation in authentic contexts anytime and anywhere.

# KEYWORDS

English conversation; authentic learning; mobile learning; speech recognition; smart chatbot

# 1.  Introduction

Most studies of computer-assisted language learning put focus on Mobile-Assisted Language Learning (MALL) as it was recognized to be beneficial to English learners (Lin et  al., 2020). A majority of people currently own cellphones- this offers students an excellent opportunity to learn in the real world. Students were more likely to become engaged in authentic learning contexts, especially in familiar ones that they encounter daily and frequently (Golonka et  al., 2014). This potential has led many scholars to become interested in MALL (Hsu, 2020; Nguyen et  al., 2018), and several studies have successfully implemented it (Golonka et  al., 2014; Nguyen et  al., 2018). In particular, there were some interesting studies on how to improve English-speaking skills like using chatbots (Alm & Nkomo, 2020; Fryer et  al., 2019; Hsu, 2020). Results from previous studies proved that traditional chatbots had the potential to facilitate English-speaking skills, as well as conversation in authentic contexts (Fryer et  al., 2019). Traditional chatbots could support learners by helping them practice repeatedly until they could speak English correctly and fluently. Furthermore, compared to conversations with another human, conversing with machines like chatbots helped in reducing the learners’ anxiety. However, traditional chatbots also had several shortcomings which caused confusion among students, regarding conversation-making, such as not understanding the speaker’s intents properly. Another limitation of traditional chatbots is the inability to continue conversations on the same topic, which reduced the students’ motivations and interests in conversing with chatbots (Fryer et  al., 2019). Therefore, there arises a need for traditional chatbots to overcome the above drawbacks. This age is marked by the penetration of ‘smart’ ideas into many educational aspects, where researchers define ‘smart’ in terms of learners, technology, and learning environment (Zhu et  al., 2016). For educational environment, ‘smart’ can refer to engaging, intelligent and scalable, where the learning environment can provide tailored and personalized services (Zhu et  al., 2016). For English learning, using recognition technology like speech-to-text recognition (STR) can diagnose students’ speech and provide personalized feedback, using GPS technology can know students’ locations and provide context-aware topics for conversations and speaking. In this circumstance, traditional chatbot can be considered as ‘smart’ learning if it can be tailored to personal needs and the context-awareness using the above mentioned technologies. Therefore, we aim to boost the traditional chatbot into a better version, a ‘smart’ chatbot. In this study, the smart chatbot app, called Smart UEnglish, was proposed to facilitate individual intents based on the students’ portfolios data (such as students’ identities, feedback, date, time, locations, other real-time information, and their surrounding contexts). The proposed smart chatbot was expected to overcome the shortcomings of traditional chatbots, including non-persistent conversation on the same topic, conversation without error tolerance, conversation without connection in authentic contexts, and no clear feedback or suggestions to help students make improvements. Moreover, in an effort to motivate students to engage in conversation practices in real life situations, this study establishes the conversations in authentic contexts and examines whether this approach is helpful for students’ English-speaking abilities.

Based on these motivations, the research questions are proposed as below:

1. What is the difference in students’ learning achievements between learning with UEnglish (without smart mechanisms) and learning with Smart UEnglish (with smart mechanisms)?   
2. What is the correlation between students’ learning behaviors and their learning achievements, while using Smart UEnglish, and its influence on learning achievements?   
3. What are students’ perceptions and motivations toward the proposed Smart UEnglish system?

# 2.  Literature review

# 2.1.  Mobile learning in authentic contexts

Nowadays, with the development of wireless technology, mobile devices have become an inseparable part of a person’s daily life (Karlsson et  al., 2017; Poushter, 2016). Many previous studies of MALL discipline were unanimously agreed that, because of their portability and multimedia capabilities, learning with mobile devices has been widely adopted into many curricula and there were many opportunities for mobile learning in authentic contexts (Hsieh et  al., 2016; Huang & Chiu, 2015; Hwang & Tsai, 2011; Lombardi, 2007; Shadiev et  al., 2016). The essential features of mobile learning were that it allowed students to learn across different contexts through mobile devices, allowed them to record their progress, and provided real-time information of their usage. Moreover, mobile learning has been found to help increase students’ motivation to learn, and to connect newly acquired knowledge with familiar contexts (Golonka et  al., 2014; Zohoorian, 2015). Therefore, with the support of mobile devices, students can explore and interact in authentic contexts, whether in class or after class.

As stated by Hwang et  al. (2014), mobile devices have empowered students to break through the limitations of traditional learning, so that they can learn not only in the traditional classroom, but also anytime anywhere. Hwang et  al. (2014) proposed User-Oriented Context-to-Text Recognition for Learning (U-CTRL) system to help students learning with recognizing physical objects to texts in authentic contexts. The results showed that learning in authentic context with U-CTRL support was effective for students’ cognition in English through applying the knowledge to solve daily-life problems. The key factors for future advancements that have been identified is ‘Designing for authentic learning by embracing new media and new cultures of learning’ (Hung et  al., 2013). Learning in authentic contexts was proved to help students to have significant better performance than those who were taught using traditional indoor lectures (Hwang et  al., 2018). Therefore, student should have more chances to interact with real world environment to learn, with technology supports, especially mobile technology supports.

Another study by Shadiev et  al. (2016) stated that mobile devices provided opportunities for learning in diverse environments, and allowed students to learn things that were relevant to their daily life. This study applied STR technology to assist non-native English-speaking participants to learn in a real-life context, a seminar that was given in English. The results showed that most of participants perceived that transcripts were useful for learning. However, participants with different learning achievements demonstrated different learning behaviours when using transcripts, and some participants used transcripts effectively while some participants did not. It showed that participants did not need the same support, there was a need for individualizing the support for different kind of participants.

# 2.2.  Enhance EFL speaking and conversation with authentic contextual supports

In English learning, although both listening and speaking are considered as primary skills, speaking is usually considered to be more difficult, compared to listening, because it requires learners to combine multiple skills (Little, 2006). In general, speaking skills are used in daily conversations when people exchange ideas with each other. Hence, conversation is considered as the best way to practice EFL speaking. As interpretation by Voloshinov et  al. (1973), ‘conversations are not individual, isolated monologic utterances, but the interaction of at least two utterances’.

Ahn and Lee (2016) designed a mobile application, called Speaking English 60 Junior, that allowed students to practice speaking English in authentic contexts, where they can practice by reading words out repeatedly. Because the speaking content was related to the surrounding environment, the students’ practices were more meaningful and what they learned could be carved more meaningfully and deeply in their mind.

Hwang et  al. (2016) designed a mobile game-based learning system that allowed students to practice English listening and speaking in authentic contexts. The learning material of this jigsaw-like game was designed for students to practice in real-life environment (classroom, school yard, …) so that it was meaningful to them. The results showed that learning in authentic contexts helped students got high level of learning motivation and their spoken English became more correct and clearer.

Sun et  al. (2017) presented a study on improving the English-speaking skills of young learners through a mobile social network. Students were required to use Papa for English-speaking study. It allowed students to upload photos, and then record a sound file describing them, while others could click on the ‘like’ button or leave text or audio comments for the photos and audio files. Studies had shown that this learning method could increase the English-speaking fluency, reduce anxiety, and increase their motivation to learn English.

Nguyen et al. (2018) developed a mobile application for English-speaking practice in authentic contexts, which called ezTranslate. It translated Chinese sentences entered through voice input into English. Then text-to-speech could pronounce the results of the translation. Finally, students did pronunciation exercises by automatic speech-recognition function. They called this kind of practice ‘shadowing’. It allowed students to learn English both inside and outside the classroom.

Zhang et  al. (2019) developed a system that allowed students to make annotations on pre-prepared learning material. With this function, researchers designed an activity called ‘English Drama’, where students took photos, uploaded them and then annotated them by voice, so that they could practice the sentences in authentic contexts and train their English-speaking abilities.

In authentic contexts, students could interact more with their surroundings and they were stimulated to cultivate their sense of knowing the characteristics of the surrounding contexts (Hwang et  al., 2019). Therefore, conversations practices would be favorable by learning in authentic contexts. All of these studies have achieved promising results, which can help students improve their English speaking ability. However, The aboved studies were about practicing conversation through interaction with real people and although conversation partners can be easily arranged in class, it is difficult to do the same after class hours.

# 2.3.  Smart mechanisms for EFL speaking and conversation

In recent years, chatbots have been widely developed to have conversations with people, and the most common application of the traditional chatbot is English conversation practice (Dahiya, 2017; Fryer et  al., 2019; Haristiani et  al., 2019). There were many advantages of English conversation practice with traditional chatbots, such as inspiring students’ learning interest and motivation, and providing continuous and repeated practice (Dahiya, 2017; Fryer et  al., 2019; Haristiani et  al., 2019). However, there were still some drawbacks of traditional chatbots for conversations, for example, non-persistent conversation on the same topic, conversation without connection to authentic contexts, and no clear feedback and suggestion (Fryer et  al., 2019). Considering the sustainability of conversations, a previous study by Ahn and Lee (2016) divided the conversation of one topic into many picture frames, with two sentences in each frame. Consequently, students had discontinuous conversations as they switched to the next picture to practice the next sentence. Hence, chatbot should be improved to keep the continuity of the conversation.

As defined by Zhu et  al. (2016), a smart learning environment should be capable of providing a tailored and personalized learning service (e.g., context awareness, adaptive content, collaborative and interactive tool, rapid evaluation and real-time feedback, etc.). Therefore, we proposed four mechanisms that make chatbots smarter and help students have better learning experiences and increase their learning achievements of English conversation.

Regarding to theoretical support for smart mechanisms to support MALL, we relied on Enactivism theory. From the perspective of knowledge acquisition, Enactivism theory is well-known as the combination of constructivism and cognition, stating that environment and cognition are inseparable. Students are not only passively absorbing information from the environment, but also actively interacting with it to obtain knowledge, so knowledge is closely related to our real environment (Di Paolo et  al., 2010). This conception of Enactivism means that the more interaction there is with the surrounding environment, the more knowledge students gather. Many previous studies succeeded relying on Enactivism theory to implement the English speaking practice system and some of them used speech recognition technology to give speaking accuracy and provided feedback like pronunciation errors (Hwang et  al., 2019; Nguyen et  al., 2018; Zhang et  al., 2019). However, these previous studies did not consider smart mechanisms about how to sustain English speaking motivation and provide adaptive speaking based on learners’ surroundings. Moreover, how to understand users’ speaking intent smartly with tolerating minor speaking errors for conversation, particularly in authentic contexts, is also required for considerations. Consequently, we initiated the idea of the smart mechanisms to effectively support students in having more and more interactions in authentic contexts. The smart mechanism of ‘flexible conversation’ can tolerate minor speaking errors and understand users’ intents, so that students can undergo a conversation easier; ‘sustainable conversation’ can stimulate students to make longer conversation; ‘adaptive conversation’ can recommend to students more ideas and information related to themselves, so that the conversations can be livelier; and ‘feedback function’ aims to support students in making more meaningful conversations. Therefore, these four proposed smart mechanisms are expected to support MALL in authentic context, so that students can get feedback immediate and improve their English speaking.

# 3.  System design

Because students usually find difficult to identify which parts they should modify and how they could improve in English speaking practices (Hwang et  al., 2019; Nguyen et  al., 2018), some basic features of Smart UEnglish (Figure 1) were implemented to provide individual feedback and help students fix their mistakes immediately on pronunciation fluency (Figure 1a) and speaking fluency (Figure 1b). The adding photos/ flashcards functions of Smart UEnglish aimed to enhance students’ memory of the translation record (Figure 1c). The students learning portfolios were stored locally with history function and synchronized to the cloud database server (Figure 1d). Smart UEnglish not only supported learners in term of individual speaking practice but also enabled students to practice English conversations with smart chatbot. There were four smart mechanisms integrated in the smart chatbot as following:

![](img/ffdab802d53de35b924d2a4c67e12910e778c79b677ec3ff5e815f6a7a7dfa4f.jpg)  
Figure 1. Basic features of Smart UE nglish including (a) Pronunciation Fluency; (b) Speaking Fluency; (c) Adding photos function; and (d) History function.

a. Flexible Conversation: With the implementation of machine learning and natural language processing of Dialogflow, an innovative cloud service provided by Google, Smart UEnglish was able to better understand speakers’ intents to give suitable responses in conversation.   
b. Sustainable conversion: People do not usually end a conversation within one or two sentences, but with a longer sequence of sentences on the same topic. Therefore, sustainability (of conversation) was defined in this study as to sustain one conversation’s continuity and we named this mechanism as ‘Sustainable conversion’. Smart UEnglish uses the label function in Dialogflow to keep conversation on the same topic and sustain the conversation continuity.   
c. Adaptive Conversation: The chatbot should provide different conversations based on information received from the students’ surrounding contexts, such as time, location, and portfolios or experience. Adaptive conversation can track students’ surrounding context and record their previous learning record, thereby, giving adaptive conversation.   
d. Feedback Function: Personalized feedback can help improve students’ learning efficiency and achievement (Pérez-Segura et  al., 2020). Feedback content contains two kinds of information: one to provide the accuracy of the answer, and the other to instruct students on how to get the correct answer (Hattie & Gan, 2011).

Smart UEnglish has three main features to support students’ conversation activities in English, including: ‘designed talk’ feature, ‘free talk’ feature, ‘leaderboard and homework’ feature (Figures 2–5).

1. ‘Designed Talk’: It allowed students to practice conversation by asking them to use designed English sentence patterns to have a conversation with a chatbot (Figure 2). The sentence patterns for these conversations were designed, and all the content came from their learning material. In this section, students were asked some questions and respond through voice recognition (Figure 2a). Students could see more details of the feedback for suggestions, and pronunciation if they click on their answers (Figure 2b). For suggestion feedback, the wrong words in students’ answer would be marked by strikethrough and the missing words would be added and underlined. For pronunciation feedback, students’ wrong word would be separated into a block, and students can see the spelling of the word and listen to its pronunciation (Figure 2b). In addition to the feedback, there was guidance functions (Figure 3) where students could click on the sentence to get the translation and listen to it again (Figure 3a). Moreover, when students did not know how to answer a question, they could click the instruction button to know the meaning and usage of English vocabulary and sentence patterns that should be used for the answer, and provides pronunciation for students to listen to (Figure 3b).

![](img/b330ae347d2e1668f209f378cf1a744b9626459dee400094b9c8f26d832bfb43.jpg)  
Figure 2. ‘Designed talk’ and its feedback.

![](img/10a45f9afbfa03c2cb8dc502b9a50cd185d556f1bf156418dc491f6f5111819a.jpg)  
Figure 3. T he details of (a) translation and (b) guidance for designed talk.

![](img/df5d8132d692c95b056e025a7b67c0477c5ee917f37da98c2bc0db25139e0b06.jpg)  
Figure 4. ‘Free talk’.

![](img/7a3ba126efb4cbac428267f5e8267d920b9a72a049cc76e1a05c7f3dd21f2f01.jpg)  
Figure 5. Features of (a) Leaderboard and (b) Homework.

2. ‘Free Talk’: Students were not limited to sentence patterns and could talk freely to the chatbot. This practice provided students with the ability to engage in daily life conversations on specific topics, such as transportation, scenic spots, restaurants, and weather. The difference was that chatbot was capable of giving answers in authentic contexts according to students’ surroundings, like location information, time or weather (Figure 4).

3. ‘Leaderboard and Homework’: This provides students with the ability to view their achievements and upload their exam records and homework (Figure 5). This function can stimulate students’ motivation and enhance the learning result.

# 4.  Methodology

For the sampling design, we chose the non-probability sampling method (or say, non-random methods) and followed the purposive sampling approach. For sampling strategy, we considered the target participants, especially the most accessible ones who could satisfy our eligibility criteria, for recruitment for the experiment. Accordingly, we conducted a quasi-experimental research and recruited students from an elementary school who were all in the same grade (sixth-grade, with ages 11 − 12), with similar knowledge of English and able to use tablets and the Internet well. The whole plan of the experiment and duration was announced for recruiting participants. As a result, a total of forty-three students (25 males and 18 females) were willing to participate in our experiment for 10 weeks. The participation agreement and the permission to collect data from the participants was obtained from all of the participants and their parents. Moreover, with those agreements, all students’ information and portfolios data were conserved and protected. They were divided into two groups: twenty students served as the control group (CG) and the other twenty-three served as the experimental group (EG). Both had the same learning topic. The EG was supported by the UEnglish with smart mechanisms (‘designed talk’, ‘free talk’ with chatbot) to conduct the course, while the CG was supported by the UEnglish without smart mechanisms. The students were not aware of the different approach applied in the groups.

The flow of this study is described in Figure 6. It followed pre-test, warm up activity, shadowing activity, ‘designed talk’ activity, ‘free talk’ activity, assignment, post-test and interview, in that sequence. In this experiment, both the EG and the CG had the same learning time, the same learning material, and the same topics. The activities were also conducted in the same place in the same authentic contexts - the campus of the participants’ school.

For every three weeks of learning of each topic (Transportation/ Activities), both groups began by using the shadowing function to practice their pronunciation of English vocabulary, phrases and sentences.

![](img/d64317d2fc44f2794a5032c36f90d274a0c1a7699c494884551a5677e811700b.jpg)  
Figure 6. E xperimental flow.

However, the CG practiced English sentence patterns through the shadowing function and the paper-based learning material, while the EG used ‘designed talk’, ‘free talk’ and conversing with the chatbot to practice the same. In the warm up activity, the EG practiced using the shadowing function and having conversations with chatbot, while the CG practiced using only the shadowing function. In the shadowing activity, students used this same function to practice pronunciation of English words, phrases and sentences, by the process of checking Chinese vocabulary on the learning material, translating through the translation function, doing shadowing practices, and finally taking photos. In the ‘designed talk’ activity, the EG used Smart UEnglish to practice conversation by using the ‘designed talk’ function. Based on the topic, the students were taken to the campus to find scenarios of their interest for conversation practices. The smart chatbot used the information regarding students’ locations and the time to ask questions. Students had to listen and understand these questions based on the context of their current surroundings, and then answer them appropriately, such as where they were now, what the time was, how the weather was, or which restaurants were nearby, etc. Therefore, the role of ‘authentic contexts’ in students’ ELF learning activities can drive our smart chatbot to ask meaningful questions. Moreover, students can also answer questions meaningfully in their surrounding contexts. In the ‘free talk’ activity, the EG made conversations with chatbot using the ‘free talk’ function, on topics such as daily conversations, nearby restaurants, recent weather, and transportation. Along with the ‘designed talk’ or ‘free talk’ activities of the EG, the CG did the shadowing activity (sentence patterns). They received paper-based learning material that included sample sentences, allowing them to learn English sentence patterns. In conversation assignment, the students of the EG were paired up and asked to make conversation on a given topic, while the CG answered questions on the paper-based learning material. All the students had to record and upload their conversations.

After the learning activities, there were the post-test and the interview activities. The content of post-test was at a similar difficulty level to the pre-test. In the interview, six students (three groups, two students in each group) were selected from both the EG and the CG based on system usage and learning achievement, including two students of the highest usage, two students of the highest achievement, and two students of the lowest achievement. The interview questions were as follows:

1. Do you like to use Smart UEnglish to practice English? Why?   
2. Do you want to keep using Smart UEnglish to practice English? Why?   
3. Do you think using Smart UEnglish is helpful to your English? Why?   
4. Which function of Smart UEnglish/UEnglish do you like most? Why?

5. Did you encounter any problems or difficulties during the activities?

Students’ learning behaviors were recorded based on the data collected on conversation-practicing status and according weighted score. The variables of learning behaviors were selected on the basis of previous studies (Bava Harji & Gheitanchian, 2017; Fathi & Rahimi, 2020; Nguyen et  al., 2018). This data included quantitative variables of learning behaviors (i.e., quantities of ‘designed talk’ and of ‘free talk’) and semi-quantitative variables of learning behaviors (i.e., weighted score of ‘designed talk’ and complexity of ‘free talk’). ‘Quantity of designed talk’ and ‘quantity of free talk’ were the times each function was practiced, respectively. ‘Weighted score of designed talk’ is calculated by multiplying the complexity of a sentence with the accuracy of pronunciation. Complexity is defined by the length of words used in a sentence, for example, ‘I go to school on foot’. The complexity of this sentence is 6. Learning achievement is evaluated through pre-test and post-test with paper-based test and oral test. The pre-test and post-test based on IELTS test (https://www.ielts.org/-/media/pdfs/speaking-band-descriptors.ashx$\mathtt { ? l a \mathrm { = } e n }$ ) were designed by an English teacher with more than 10-years of teaching experience (Appendix). Therefore, our test design had good reliability and validity. The paper-based test included ten spelling questions, ten multiple-choice questions, as well as two story-writing questions. The oral test required students to speak and record their answers to two story-writing questions. We used 5-point-scale criterion for oral speaking (Hughes, 2007) to evaluate the oral test. There were five dimensions to this criterion, including accent, grammar, fluency, vocabulary and comprehension, which can thoroughly assess speaking performance. Two individual raters, one English Teacher and one researcher, who are both experienced in English teaching, gave the test scores. There was a high inter-reliability of the oral test scores with Spearman’s rho 0.878. The paper test was evaluated in three dimensions: memory, comprehension, and grammar accuracy; the oral test was also evaluated in three dimensions: lexical resource, pronunciation, and fluency.

# 5.  Results and discussion

# 5.1.  Analysis of learning achievement

To measure the students’ prior knowledge and learning achievements, pre-test and post-test were conducted for two groups. The ANOVA pre-test results (Table 1) showed that the mean of the pre-test total score of the EG $( \mathrm { M } = 6 0 . 8 2 $ , $\mathrm { S D } = 3 . 1 4 )$ was higher than that of the CG ( $\mathrm { \Delta } \mathrm { M } = 5 6 . 9 5$ , $\mathrm { S D } ~ = ~ 3 . 7 9 { } ~ .$ ). However, there was no significant difference between the two groups $\mathrm { ~ \textit ~ { ~ F ~ } ~ } = \mathrm { ~ } . 6 2 9$ , $\mathrm { p } = . 4 3 2 )$ ). Furthermore, not all parts of the paper test and oral test reached a significant level. This implied that the two groups had similar English skills before the experiment.

Table 1. R esults of pre-test.   

<html><body><table><tr><td>Variables</td><td>Group</td><td>N</td><td>M</td><td>SD</td><td>F</td><td>Sig.</td></tr><tr><td>Total score</td><td>Control</td><td>20</td><td>56.95</td><td>3.79</td><td>.629</td><td>.432</td></tr><tr><td rowspan="2">Paper test</td><td>Experimental</td><td>23</td><td>60.82</td><td>3.14</td><td></td><td rowspan="2"></td></tr><tr><td>Control</td><td>20</td><td>37.65</td><td>11.98</td><td>.104</td></tr><tr><td></td><td>Experimental</td><td>23</td><td>38.73</td><td>10.12</td><td></td><td>.748</td></tr><tr><td rowspan="2"> Remembering</td><td>Control</td><td>20</td><td>9.75</td><td>3.95</td><td>.503</td><td>.482</td></tr><tr><td>Experimental</td><td>23</td><td>10.52</td><td>3.17</td><td></td><td></td></tr><tr><td rowspan="2">Understanding</td><td>Control</td><td>20</td><td>21.00</td><td>6.18</td><td>.158</td><td>.693</td></tr><tr><td>Experimental</td><td>23</td><td>21.69</td><td>5.29</td><td></td><td></td></tr><tr><td rowspan="2">Accuracy</td><td>Control</td><td>20</td><td>6.90</td><td>3.43</td><td>.141</td><td>.709</td></tr><tr><td>Experimental</td><td>23</td><td>6.52</td><td>3.16</td><td></td><td></td></tr><tr><td rowspan="2">Oral test</td><td>Control</td><td>20</td><td>19.30</td><td>5.98</td><td>2.224</td><td>.144</td></tr><tr><td>Experimental</td><td>23</td><td>22.09</td><td>6.22</td><td></td><td></td></tr><tr><td rowspan="2">Lexical resource Control</td><td></td><td>20</td><td>3.95</td><td>1.93</td><td>.841</td><td>.365</td></tr><tr><td>Experimental</td><td>23</td><td>4.43</td><td>1.53</td><td></td><td></td></tr><tr><td rowspan="2"> Pronunciation</td><td>Control</td><td>20</td><td>7.40</td><td>2.52</td><td>.575</td><td>.453</td></tr><tr><td> Experimental</td><td>23</td><td>8.00</td><td>2.64</td><td></td><td></td></tr><tr><td rowspan="2">Fluency</td><td>Control</td><td>20</td><td>7.95</td><td>2.76</td><td>.629</td><td>.432</td></tr><tr><td> Experimental</td><td>23</td><td>9.65</td><td>2.93</td><td></td><td></td></tr></table></body></html>

Table 2. R esults of post-test.   

<html><body><table><tr><td>Variables</td><td>Group</td><td>N</td><td>M</td><td>SD</td><td>F</td><td>Sig.</td></tr><tr><td rowspan="2">Total score</td><td>Control</td><td>20</td><td>57.60</td><td>18.06</td><td>5.768</td><td>.021</td></tr><tr><td>Experimental</td><td>23</td><td>70.78</td><td>17.86</td><td></td><td></td></tr><tr><td>Paper test</td><td>Control</td><td>20</td><td>33.70</td><td>12.70</td><td>3.441</td><td>.071</td></tr><tr><td rowspan="2"> Remembering</td><td>Experimental</td><td>23</td><td>40.56</td><td>11.56</td><td></td><td></td></tr><tr><td>Control</td><td>20</td><td>9.25</td><td>4.87</td><td>4.513</td><td>.040</td></tr><tr><td>Understanding</td><td>Experimental</td><td>23</td><td>12.13</td><td>4.03</td><td></td><td></td></tr><tr><td rowspan="2"></td><td>Control</td><td>20</td><td>17.05</td><td>5.36</td><td>2.001</td><td>.165</td></tr><tr><td> Experimental</td><td>23</td><td>19.48</td><td>5.83</td><td></td><td></td></tr><tr><td rowspan="2">Accuracy</td><td>Control</td><td>20</td><td>7.40</td><td>4.17</td><td>2.085</td><td>.156</td></tr><tr><td> Experimental</td><td>23</td><td>8.96</td><td>2.85</td><td></td><td></td></tr><tr><td>Oral test</td><td>Control Experimental</td><td>20</td><td>23.90</td><td>6.85</td><td>7.907</td><td>.008</td></tr><tr><td rowspan="2">Lexical resource</td><td>Control</td><td>23</td><td>30.22</td><td>7.75</td><td></td><td></td></tr><tr><td></td><td>20</td><td>3.95</td><td>2.09</td><td>10.654</td><td>.002</td></tr><tr><td rowspan="2"> Pronunciation</td><td>Experimental Control</td><td>23</td><td>7.00</td><td>3.69</td><td></td><td></td></tr><tr><td></td><td>20</td><td>9.30</td><td>2.72</td><td>4.556</td><td>.039</td></tr><tr><td rowspan="2">Fluency</td><td>Experimental</td><td>23</td><td>11.00</td><td>2.50</td><td></td><td></td></tr><tr><td>Control</td><td>20</td><td>10.65</td><td>3.15</td><td>2.625</td><td>.113</td></tr><tr><td></td><td>Experimental</td><td>23</td><td>12.22</td><td>3.18</td><td></td><td></td></tr></table></body></html>

The ANCOVA result of the post-test (Table 2) showed that the total score of the EG $\mathrm { ' } \mathrm { M } = 7 0 . 7 8$ , $\mathrm { S D } ~ = ~ 1 7 . 8 6 )$ was higher than that of the CG $\mathrm { \Delta } M = 5 7 . 6 0 \mathrm { \Omega }$ , $\mathrm { S D } = 1 8 . 0 6 \AA$ and reached a significant level $( \mathrm { F } = 5 . 7 6 8 $ , $\mathrm { ~ p ~ } = \ . 0 2 1 \mathrm { ~ }$ ). Moreover, the EG’s oral test results $( \mathrm { M } = 3 0 . 2 2$ , $\mathrm { S D } = 7 . 7 5$ ) were higher than the CG’s $( \mathrm { M } = 2 3 . 9 0$ , $\mathrm { S D } ~ = ~ 6 . 8 5 { } ~ ,$ and reached a significant level $\mathrm { { F } = 7 . 9 0 7 }$ , $\mathrm {  ~ p ~ } = \mathrm {  ~ . 0 0 8 ~ }$ ). This implied that the EG’s learning achievement was better than the CG, especially in the oral test.

In the part that tested memory, the average score of the EG $( \mathrm { M } = 1 2 . 1 3 $ , $\mathrm { S D } = 4 . 0 3 )$ ) was higher than that of the CG $( \mathrm { M } = 9 . 2 5 $ , $\mathrm { S D } = 4 . 8 7 ,$ and reached a significant level ( ${ \mathrm { F } } = 4 . 5 1 3$ , $\mathrm { ~ p ~ } = \mathrm { ~ . 0 4 0 } ^ { \cdot }$ . Moreover, the EG outperformed the CG in two parts of the oral test, including lexical resource $\mathrm { ( F = 1 0 . 6 5 4 }$ , $\mathrm {  ~ p ~ } = ~ . 0 0 2 ^ { \cdot }$ ) and pronunciation ${ ' } \mathrm { F } = 4 . 5 5 6 $ , $\mathrm {  ~ p ~ } = \mathrm {  ~ . 0 3 9 ~ } _ { \mathrm { \small { \cdot } } }$ ). This suggests that Smart UEnglish was beneficial to the students’ memory of new vocabulary and application of the same in conversation, as well as correction of their pronunciation.

Using Smart UEnglish in a familiar context, students could apply sentence patterns to the conversation more easily with the related vocabulary. Students used related vocabulary and sentence patterns in authentic contexts without having to imagine a scenario that didn’t exist, which helped them to consolidate their memory by applying what they saw during the conversation. This result reflects many previous studies which mentioned that learning-by-doing is the most effective way to learn (Golonka et  al., 2014; Lombardi, 2007). Lombardi (2007) stated that students were most often engaged in solving real-world problems, and they expressed a preference for it over listening. In this study, the conversation practices required students to practice in real situations, so they could easily recall the sentences they had used.

# 5.2.  Relationship between learning behaviors and learning achievement

# 5.2.1.  Quantitative variables of learning behaviors

Quantitative variables of the students’ learning behaviors included ‘quantity of designed talk’ and ‘quantity of free talk’. These were the times that ‘designed talk’ and ‘free talk’ are practiced, respectively. The Pearson correlation between these quantitative variables and the post-test in EG was shown in Table 3.

First, ‘quantity of designed talk’ had positive correlation with fluency $\left( \mathbf { r } ~ = ~ . 4 6 5 \right.$ , $\mathrm { ~ p ~ = ~ } . 0 2 5$ ) and ‘quantity of free talk’ $\left( \mathbf { r } \ = \ . 7 2 7 \ \mathrm { ~ p ~ } = \ . 0 0 0 \right)$ . It means more conversation practice could improve the students’ abilities to compose sentences with multiple words as well as their fluency. Secondly, there was a positive correlation between ‘quantity of free talk’ and lexical resource $\mathrm { ( r = \ . 4 4 4 }$ , $\mathrm { \tt ~ p } = . 0 3 4 )$ ), oral test $( \mathbf { r } = . 5 0 7$ , $\mathrm { \tt { p } } = . 0 1 4 ,$ ), as well as the total score $\left( \mathbf { r } \ = \ . 4 6 2 \right.$ , $\mathrm {  ~ p ~ } = \mathrm {  ~ . 0 2 7 ~ } .$ ). These results indicated that students could use this function to improve their learning achievements of the oral test, total score and lexical resource. Although the correlation between ‘quantity of free talk’ and fluency as well as pronunciation did not reach a significant level, the oral score did. It means that doing ‘free talk’ practice could improve students’ English-speaking abilities. They could correct their own pronunciation, increased fluency and greatly improved their vocabulary in conversations through ‘free talk’ practice. Especially for lexical resource, this function seemed to be more advanced than ‘designed talk’, as students got a lot of extra content from it, such as the English words for weather, transportation and scenic spots. This way, students could learn more vocabularies to use in their conversations.

Table 3. P earson correlation between quantitative variables and post-test in the EG .   

<html><body><table><tr><td>Variable</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td><td>11</td></tr><tr><td>1. Paper test</td><td></td><td></td><td></td><td></td><td>.000** .000** .000** .000** .000** .000** .000** .000** .000** .000**</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>2. Remember</td><td>.867**</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>3. Understanding</td><td></td><td>.918** .611**</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>4. Grammar accuracy</td><td></td><td></td><td>.955** .856** .813**</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>5. Oral test</td><td></td><td></td><td>.698** .650** .569** .749**</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>6. Lexical resource</td><td></td><td></td><td></td><td>.654** .621** .568** .613** .746**</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>7. Pronunciation</td><td></td><td></td><td></td><td>.593**.518*.479* .694**.908** .437*</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>8. Fluency</td><td></td><td></td><td></td><td>.475*.456*.350.568**.857**.314 .920**</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>9. Total score</td><td></td><td></td><td></td><td>.950** .844** .841** .943** .886** .747** .778** .680**</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>10. Quantity of &#x27;designed talk&#x27;</td><td></td><td>.234.166</td><td>.237</td><td>.231</td><td>.381</td><td>.137</td><td>.386</td><td>.465*</td><td>.317</td><td></td><td></td></tr><tr><td>11. Quantity of &#x27;free talk&#x27;</td><td>.373</td><td>.388</td><td>.299</td><td>.355</td><td>.507*</td><td>.444*</td><td>.407</td><td>.399</td><td></td><td>.462* .727**</td><td></td></tr></table></body></html>

\* Correlation is significant at the 0.05 level (2-tailed). \*\*Correlation is significant at the 0.01 level (2-tailed).

Interestingly, ‘quantity of designed talk’ had no significant correlation with the ‘total score’ of students’ post-test scores, while ‘quantity of free talk’ did (Table 3). This means that ‘free talk’ affected learning achievements more than ‘designed talk’. This result agreed well with a previous study by (Hwang et  al., 2021), where students were allowed to discover the school campus freely, based on their interests and needs, to stimulate them to do free talk with a robot, therefore significantly improving their learning achievements.

Through observing students’ usage data, we found that some high values of quantitative variables were induced because some students practiced the same sentence repeatedly even though they had got full marks. So it was necessary to conduct analysis with other variables to know more about the relationship between the students’ learning behaviors and learning achievement.

# 5.2.2.  Semi-quantitative variables of learning behavior

Semi-quantitative variables of students’ learning behaviors included ‘weighted score of designed talk’ and ‘complexity of free talk’ and the Pearson correlation analysis results between these semi-quantitative variables and the post-test of EG were shown in Table 4.

First of all, we found that the ‘weighted score of designed talk’ had a positive correlation with ‘complexity of free talk’ $( \mathbf { r } = . 5 8 1$ , $\mathrm { ~ p ~ } = \mathrm { ~ } . 0 0 4 )$ . Since ‘free talk’ was a more advanced function, students would not use it until they were familiar with ‘designed talk’, so there was a significant correlation between the ‘weighted score of designed talk’ and ‘complexity of free talk’.

Moreover, we found that the ‘weighted score of designed talk’ had a positive correlation with comprehension $\mathbf { \Phi } ( \mathbf { r } = . 4 3 3$ , $\mathrm {  ~ p ~ } = \mathrm {  ~ . 0 3 9 ~ } ,$ ). This result implied that students could use Smart UEnglish to help their understanding of English sentence patterns or words. One student said, ‘I really like the translation function, it allows me to understand the meaning of the conversation and learn some new words’.

Table 4. P earson correlation between semi-quantitative variables and post-test in the EG .   

<html><body><table><tr><td>Variable</td><td>1 2 3</td><td></td><td></td><td>4 5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td></tr><tr><td>1. Paper test</td><td></td><td colspan="6">.000** .000** .000** .000** .000** .000** .000** .000** .000** .000**</td><td></td><td>11</td><td></td></tr><tr><td>2. Remember</td><td>.867**</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>3. Understanding</td><td>.918** .611**</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>4. Grammar accuracy</td><td>.955** .856** .813**</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>5. Oral test</td><td>.698** .650** .569** .749**</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>6. Lexical resource</td><td>.654** .621** .568** .613** .746**</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>7. Pronunciation</td><td>.593** .518*.479* .694**.908** .437*</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>8. Fluency</td><td>.475*.456*.350 .568**.857**.314 .920**</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>9. Total score</td><td>.950** .844** .841** .943** .886** .747** .778** .680**</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>10. Weighted score of &#x27;designed talk&#x27;</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>.405.295 .433*.338 .700**.601**.529**.593**.566**</td><td></td><td></td></tr><tr><td>11. Complexity of &#x27;free talk&#x27;.</td><td>.452*</td><td></td><td></td><td></td><td>.365 .441* .416* .509* .507*.398</td><td></td><td></td><td></td><td>.339.514* .581**</td><td></td></tr></table></body></html>

\* Correlation is significant at the 0.05 level (2-tailed). \*\*Correlation is significant at the 0.01 level (2-tailed).

Finally, the ‘weighted score of designed talk’ had positive correlation with the oral test $( \mathbf { r } ~ = ~ . 7 0 0$ , $\mathrm { ~ p ~ } = \mathrm { ~ . 0 0 0 }$ ), lexical resource $\mathrm { ~ ( r ~ = ~ } . 6 0 1$ , ${ \mathfrak { p } } =$ .002), pronunciation $\left( \mathrm { \bf r } \ = \ . 5 2 9 \mathrm { \bf ~ p } = \ . 0 0 9 \right)$ and fluency $\mathrm { ~ ( r ~ = ~ } . 5 9 3$ , $\mathrm { ~ p ~ } =$ .003). All of these variables were related to oral abilities, from which the ‘designed talk’ could improve the students’ speaking skills. These findings indicated that conversation practice had an important role in learning English, particularly an oral ability.

On the other hand, there was a positive correlation between the ‘complexity of free talk’ and the paper test $( \mathbf { r } = . 4 5 2$ , $\mathrm { ~ p ~ } = \mathrm { ~ } . 0 3 0 \mathrm { ~ }$ , comprehension $( \mathbf { r } = . 4 4 1 ~ \mathrm { p } = . 0 3 5 )$ , grammar accuracy $( \mathbf { r } = . 4 1 6 ~ \mathrm { p } = . 0 4 8 )$ ), lexical resource $\left( \mathrm { r } \ = \ . 5 0 7 \ \mathrm { p } \ = \ . 0 1 4 \right)$ and the total score $\left( \mathrm { r } \ = \ . 5 1 4 \ \mathrm { p } \ = \ \right.$ .012). Compared to ‘designed talk’, ‘free talk’ had two more variables that reached a significant level- a paper test and grammar accuracy (Table 4)- this confirms that ‘free talk’ affects learning achievements more than ‘designed talk’. Unlike ‘designed talk’, ‘free talk’ did not provide the students with fixed sentence patterns. They had to correct the vocabulary, phrases and grammar of the sentences in the conversation until the chatbot could give them the correct responses. Therefore, students made progress in a paper test through free talk activity.

Intriguingly, we found that the semi-quantitative variables show more effect on the post-test scores than the quantitative variables, e.g., there was one variable significantly correlated to ‘quantity of designed talk’ (Table 3), while there were six variables significantly correlated to ‘weighted score of designed talk’ (Table 4); there were four variables significantly correlated to ‘quantity of free talk’ (Table 3), while there were seven variables significantly correlated to ‘complexity of free talk’ (Table 4). Unlike the ‘quantity of designed talk’ and ‘quantity of free talk’, which only represented the number of times the students practiced without considering the quality of each practice, the ‘weighted score of designed talk’ and ‘complexity of free talk’ considered the accuracy and the complexity of each practice. However, the accuracy and complexity of the students’ speaking affected their learning achievements more significantly than their number of practices (in term of the quantitative variables).

The semi-quantitative variables included considering the accuracy of pronunciation and complexity of sentence making, therefore can represent students’ English abilities. Hence, it was shown the semi-quantitative variables had more significant correlation to the students’ learning achievements than the quantitative variables. Regarding to ‘free talk’, students could use mobile devices to explore authentic contexts and practice what they feel interested in English and this study showed that ‘free talk’ can influence learning achievements than ‘designed talk’. So, using MALL to design free exploration activities in authentic contexts to help English practice become promising and worth our further investigation in near future.

# 5.2.3.  Multiple regression analysis of student’s learning behaviors

In this part, we used behavior data in a stepwise multiple regression analysis to investigate which is the most important factor of predicting the students’ learning achievements. Table 5 showed the results of a model summary in a stepwise multiple regression analysis. According to this, only the ‘weighted score of designed talk’ $\mathrm { \Delta t } = 3 . 1 4 4$ , $\mathrm { ~ p ~ } = \ . 0 0 5 ,$ ) entered into the regression equation and was found to be significantly related to post-test scores. This means that only ‘weighted score of designed talk’ was the factor of predicting students’ learning achievements. This is because the students’ English abilities were not enough to conduct ‘free talk’ from the beginning, without the help of sentence patterns and teaching material. Therefore, students had to get familiar with ‘designed talk’ before using ‘free talk’, which may affect the results of the correlation coefficient.

# 5.3.  Students’ perception toward using smart UEnglish

Almost all of the students expressed an interest in conversation practice activities with Smart UEnglish and its provided functions. Students expressed in the interview:

‘This APP is very helpful for my English learning. I can practice the dialogue with it so that I can have a conversation with foreigners when I meet them’.

Table 5. M ultiple regression model coefficients.   

<html><body><table><tr><td></td><td colspan="2">Unstandardized coefficients</td><td>Standardized coefficients</td><td></td><td></td></tr><tr><td> Model</td><td>B</td><td>Std. error</td><td>Beta</td><td>t</td><td>Sig.</td></tr><tr><td>1 (Constant)</td><td>59.514</td><td>4.767</td><td></td><td>12.484</td><td>.000</td></tr><tr><td>Weighted score of. designed talk</td><td>.001</td><td>.000</td><td>.566</td><td>3.144</td><td>.005</td></tr></table></body></html>

‘There is leaderboard function in this app. I want to get higher rank in leaderboard that will make me feel happy’.

This study echoed previous studies’ conclusion that students should have chances to contact situational materials in authentic contexts so that they would later recall what they had learned in similar scenarios (Hwang et  al., 2015; 2018; 2019). A student said that, ‘I like Smart UEnglish because its learning contents is the in-situ contexts, I can learn and apply what I learned to conversations immediately’.

Distinctive from previous studies, the smart mechanisms were proposed in this study and were proved to significantly improve the students’ learning motivations and achievements, based on statistic results (section 5.1 and 5.2) and interviews. Through the free activities in this study, the smart mechanism of ‘adaptive conversation’ manifested the ability to guide the conversation in a lively and interesting way, based on the students’ current information. One student stated, ‘I like the conversation function most because the conversation content comes from my daily life, which makes me feel interested’.

The smart mechanism of ‘sustainable conversation’ was testified when the smart chatbot, based on the students’ current information (like the nearest restaurants, nearest bus stop, etc.), kept asking questions and making suggestions to encourage the students to talk more, so that they could make each conversation last longer than two sentences. For example, a student was asked: ‘How do you go back home after school?’ and when the answer is ‘By bus’, the chatbot suggested nearby bus stops.

With smart mechanism of ‘flexible conversation’, students would not be stuck with minor errors during a conversation with the smart chatbot as the smart chatbot could understand students’ meaning for conversations. Moreover, through another kind of smart mechanism- feedback of pronunciation accuracy for each oral practice - the mistakes could be pointed out and corrected effectively and efficiently. The flow of conversation, therefore, would be uninterrupted and, consequently, the students’ learning motivation would be increased. One student said, ‘I like to do conversation practice, because it improves my English skills, and it also tells me where I made mistakes’.

# 5.4.  Implications and suggestions

# 5.4.1.  Implications

The conversation function included in both the ‘designed talk’ and the ‘free talk’ are helpful to the students’ English-speaking abilities. Flexible Conversation, Sustainable Adaptive Conversation, and Learning Feedback enable students to practice conversation more effectively and maintain their learning motivation. Flexible Conversation allows students to practice conversations more smoothly. Sustainable Conversation allows them to have conversations on the same topic, which they are more interested in than pronunciation practices. Adaptive Conversation provides a variety of responses in a conversation, making the students feel more like practicing a conversation with a real person. Learning Feedback instantly lets them know how well they speak and helps them to improve.

# 5.4.2.  Suggestions

First of all, designing a system to be used in authentic contexts should give learners a stronger sense of interaction with the environment, which is conducive to students’ memory and learning. Moreover, activities should be conducted at an appropriate time and place, in accordance with the surroundings for conversation practice in order to enhance the conversation content related to surrounding contexts and sustain the conversation by finding related topic from the surroundings (Liu et  al., 2021; Manabe et  al., 2021; Zhang et  al., 2019). For example, a sentence pattern in the textbook is ‘What do you do after class?’ It is necessary to bring the students to the playground where they usually play after class, and let them look at the familiar facilities to form a reply and continue conversation by asking question. However, few studies addressed how to implement smart mechanisms to help conversation practice in authentic contexts like sustain conversation and provide personalized conversation based on students’ portfolios and the contexts surround them.

In terms of the smart mechanisms, with Flexible Conversation, Sustainable Conversation, Adaptive Conversation, and Learning Feedback features, our chatbot can learn from the collected data, such as students’ learning portfolios and feedbacks, and may become smarter. However, according to the regression analysis, the relationship between pronunciation and fluency and ‘free talk’ were not significant. This was because the ‘free talk’ was a more advanced function, and it did not provide sentence patterns and words for students to reference like those in ‘designed talk’. Therefore, if researchers want to develop a conversation system for students to practice English conversation in the future, scaffolding should be considered.

# 6.  Conclusion

In this study, a smart learning system, Smart UEnglish, has been designed to enable students to practice English conversation in authentic contexts. According to reflections from the results and discussion of this study, as well as some previous related research (Hwang et  al., 2019; Nguyen et  al., 2018; Shadiev et  al., 2018), learning in authentic contexts can help increase students’ learning motivation by connecting new knowledge with their surroundings. Not only is it designed to fit with an authentic contextual learning style, Smart UEnglish is also implemented with smart functions to support students’ learning activities. The pioneer features of Smart UEnglish are highlighted in this study with the four proposed smart mechanisms to reinforce the traditional chatbot, including Flexible Conversation, Sustainable Conversation, Adaptive Conversation, and Feedback Function for learning. The analysis results show that the EG performed better than the CG in the oral test, which means using Smart UEnglish with the four smart mechanisms helped improve the students’ English-speaking abilities. When students have meaningful conversations in the environment that they feel familiar with, they connect what they learn to their daily life and, therefore, their learning motivations and achievements are increased. By upgrading the traditional chatbot to a smart chatbot, the main contributions of this study were highlighted as the four smart mechanisms’ advantages in supporting students’ learning in an authentic context. The ‘Flexible Conversation’ is successful in making uninterrupted conversation for students. The ‘Sustainable Conversation’ is successful in guiding students to make conversations last longer. The ‘Adaptive Conversation’ was expressed by students as ‘interested’ because of the conversation content related to their daily life when they had the interview. The ‘Feedback Function’ was also recognized by students to be helpful in speaking practices.

In terms of learning activities, it was found that the more complicated sentence students practice in ‘designed talk’, the better learning achievements they obtained. This is because the participants were elementary school students and they need consolidate fundamental practice from textbook and extend to use more complicated words and phrases related to authentic contexts supported by smart mechanisms. The interview results showed that students have positive perception toward the proposed Smart UEnglish system.

The limitations in this study were the duration and number of participants. The duration of the experiment in this study was too short and students did not have much time to use Smart UEnglish, which may have affected the results. So, we must expand the duration of the activities in the future and allow students to take the tablet home for use, then further examine the results. Moreover, the number of participants in the experiment was limited; only 43. Therefore, in future studies, we expect to increase the number of participants to enlarge the size of the study results.

# Disclosure statement

No potential conflict of interest was reported by the authors.

# Notes on contributors

Dr. Wu-Yuin Hwang is currently a distinguished Professor of the Graduate Institute of Network Learning Technology, National Central University, Taiwan. His current research interests are related to integration of IOT, Robots and multimedia sensors of mobile devices for interactions among human and all things in AR contexts like smart agriculture, buildings and campus. Dr. Hwang received the Ta-You Wu, Memorial Award from National Science Council in 2005. He is also ranked in top 7 scholars of the world in terms of high-quality journal publication performance of instructional design and technology. (Email wyhwang1206@gmail.com)

Mr. Bo-Chen Guo got his master degree from the Graduate Institute of Network Learning Technology, National Central University, Taiwan in 2020. His research interests include EFL teaching and educational technology. (Email k840304@gmail.com)

Ms. Anh Hoang received B.S. degree from Hanoi University of Science, Vietnam in 2010 and M.S. degree from National Central University, Taiwan in 2012. She is currently a Ph.D. candidate of Graduate Institute of Network Learning Technology, National Central University, Taiwan. Her research interests include language learning, mobile learning in authentic context and smart education. (Email hohoangtenanh@gmail.com)

Ching-Chun Chang received his PhD degree in computer science from the University of Warwick, U.K., in 2019. He participated in a short-term scientific mission supported by European Cooperation in Science and Technology Actions with the Faculty of Computer Science, Otto von Guericke University Magdeburg, Germany, in 2016. He was granted the Marie-Curie Fellowship and participated in a research and innovation staff exchange scheme supported by Marie Skłodowska-Curie Actions at the Department of Electrical and Computer Engineering, New Jersey Institute of Technology, USA, in 2017. He was a Visiting Scholar at the School of Computer and Mathematics, Charles Sturt University, Australia, in 2018, and at the School of Information Technology, Deakin University, Australia, in 2019. He was a Research Fellow at the Department of Electronic Engineering, Tsinghua University, China, in 2020. He has been a Postdoctoral Fellow at the National Institute of Informatics, Japan, since 2021. His research interests include steganography, watermarking, forensics, biometrics, cybersecurity, applied cryptography, image processing, computer vision, natural language processing, computational linguistics, machine learning, and artificial intelligence. (Email C.Chang.2@warwick.ac.uk)

Mr. Nien-Tsu Wu is currently a Ph.D. student of Graduate Institute of Network Learning Technology, National Central University, Taiwan. He is also the director of the Institute for Information Industry (III) and primarily focused the educational technology development. His areas of interest include network learning platform and activity design, heterogeneous database management, software engineering, and project management. (Email zalex@iii.org.tw)

# ORCID

Wu-Yuin Hwang $\textcircled{1}$ http://orcid.org/0000-0001-5684-3590   
Anh Hoang $\textcircled{1}$ http://orcid.org/0000-0003-4224-9835

# References

Ahn, T. Y., & Lee, S. M. (2016). User experience of a mobile speaking application with automatic speech recognition for EFL learning. British Journal of Educational Technology, 47(4), 778–786. https://doi.org/10.1111/bjet.12354   
Alm, A., & Nkomo, L. M. (2020). Chatbot experiences of informal language learners: A sentiment analysis. International Journal of Computer-Assisted Language Learning and Teaching (IJCALLT), 10(4), 51–65. https://doi.org/10.4018/IJCALLT.2020100104   
Bava Harji, M., & Gheitanchian, M. (2017). Effects of multimedia task-based teaching and learning approach on EFL learners’ accuracy, fluency and complexity of oral production. Turkish Online Journal of Educational Technology-TOJET, 16(2), 25–34.   
Dahiya, M. (2017). A tool of conversation: Chatbot. International Journal of Computer Sciences and Engineering, 5(5), 158–161.   
Di Paolo, E., Rohde, M., & De Jaegher, H. (2010). Horizons for the enactive mind: Values, social interaction, and play. In J. Stewart, O. Gapenne, E. A. Di Paolo (Eds.), Enaction: Towards a new paradigm for cognitive science (pp. 33–85). MIT Press.   
Fathi, J., & Rahimi, M. (2020). Examining the impact of flipped classroom on writing complexity, accuracy, and fluency: A case of EFL students. Computer Assisted Language Learning, 1–39. https://doi.org/10.1080/09588221.2020.1825097   
Fryer, L. K., Nakao, K., & Thompson, A. (2019). Chatbot learning partners: Connecting learning experiences, interest and competence. Computers in Human Behavior, 93, 279–289. https://doi.org/10.1016/j.chb.2018.12.023   
Golonka, E. M., Bowles, A. R., Frank, V. M., Richardson, D. L., & Freynik, S. (2014). Technologies for foreign language learning: A review of technology types and their effectiveness. Computer Assisted Language Learning, 27(1), 70–105. https://doi.org/1 0.1080/09588221.2012.700315   
Haristiani, N., Danuwijaya, A., Rifa’i, M., & Sarila, H. (2019). Gengobot: A chatbot-based grammar application on mobile instant messaging as language learning medium. Journal of Engineering Science and Technology, 14(6), 3158–3173.   
Hattie, J., & Gan, M. (2011). Instruction based on feedback. In R. E. Mayer; P. A. Alexander (Eds.), Handbook of research on learning and instruction (pp. 249–271). Routledge.   
Hsieh, S.-W., Ho, S.-C., Wu, M-p., & Ni, C.-Y. (2016). The Effects of concept map-oriented gesture-based teaching system on learners’ learning performance and cognitive load in earth science course. Eurasia Journal of Mathematics, Science and Technology Education, 12(3), 621–635. https://doi.org/10.12973/eurasia.2016.1235a   
Hsu, L. (2020). To CALL or not to CALL: Empirical evidence from neuroscience. Computer Assisted Language Learning,  35(4), 1–24.   
Huang, Y.-M., & Chiu, P.-S. (2015). The effectiveness of the meaningful learning-based evaluation for different achieving students in a ubiquitous learning context. Computers & Education, 87, 243–253. https://doi.org/10.1016/j.compedu.2015.06.009   
Hughes, R. (2007). Testing the visible: Literate biases in oral language testing. Journal of Applied Linguistics and Professional Practice, 1(3), 295–309. https://doi.org/10.1558/ japl.v1.i3.295   
Hung, D., Lee, S.-S., & Lim, K. Y. (2013). Moving forward: Key areas of educational research for the Asia Pacific. The Asia-Pacific Education Researcher, 22(2), 219–220. https://doi.org/10.1007/s40299-012-0037-x   
Hwang, W. Y., Hoang, A., & Lin, Y. H. (2021). Smart mechanisms and their influence on geometry learning of elementary school students in authentic contexts. Journal of Computer Assisted Learning, 37(5), 1441–1454. https://doi.org/10.1111/jcal.12584   
Hwang, W.-Y., Hoang, A., & Tu, Y.-H. (2019). Exploring authentic contexts with ubiquitous geometry to facilitate elementary school students’ geometry learning. The Asia-Pacific Education Researcher,  29(3), 269–283.   
Hwang, W.-Y., Lin, L.-K., Ochirbat, A., Shih, T. K., & Kumara, W. (2015). Ubiquitous Geometry: Measuring Authentic Surroundings to Support Geometry Learning of the Sixth-Grade Students. Journal of Educational Computing Research, 52(1), 26–49. https://doi.org/10.1177/0735633114568852   
Hwang, W.-Y., Nguyen, T.-H., & Pham, X.-L. (2019). Peer tutoring to facilitate cognitive diffusion of English as a foreign language learning: using speech translation and Shadowing in familiar authentic contexts. Journal of Educational Computing Research, 57(4), 901–929. https://doi.org/10.1177/0735633118776209   
Hwang, W.-Y., Purba, S. W. D., Liu, Y.-F., Zhang, Y.-Y., & Chen, N.-S. (2018). An investigation of the effects of measuring authentic contexts on geometry learning achievement. IEEE Transactions on Learning Technologies,  12(3), 291–302. https:// doi.org/10.1109/TLT.2018.2853750   
Hwang, W.-Y., Shadiev, R., & Huang, Y.-M. (2014). Cognitive diffusion model with user-oriented context-to-text recognition for learning to promote high level cognitive processes. In Y-M. Huang, H-C. Chao, D-J. Deng, J. J. (Jong Hyuk) Park (Eds.), Advanced technologies, embedded and multimedia for human-centric computing (pp. 267–274). Springer.   
Hwang, W.-Y., Shih, T. K., Ma, Z.-H., Shadiev, R., & Chen, S.-Y. (2016). Evaluating listening and speaking skills in a mobile game-based learning environment with situational contexts. Computer Assisted Language Learning, 29(4), 639–657. https:// doi.org/10.1080/09588221.2015.1016438   
Hwang, G. J., & Tsai, C. C. (2011). Research trends in mobile and ubiquitous learning: A review of publications in selected journals from 2001 to 2010. British Journal of Educational Technology, 42(4), E65–E70. https://doi.org/10.1111/j.1467-8535.2011.01183.x   
Karlsson, M., Penteniari, G., & Croxson, H. (2017). Accelerating affordable smartphone ownership in emerging markets. In GSMA, pp. 1–59.   
Lin, C.-C., Lin, V., Liu, G.-Z., Kou, X., Kulikova, A., & Lin, W. (2020). Mobile-assisted reading development: A review from the Activity Theory perspective. Computer Assisted Language Learning, 33(8), 833–864. https://doi.org/10.1080/09588221.2019.1 594919   
Little, D. (2006). The Common European Framework of Reference for Languages: Content, purpose, origin, reception and impact. Language Teaching, 39(3), 167–190. https://doi.org/10.1017/S0261444806003557   
Liu, Y.-F., Hwang, W.-Y., & Liu, Z.-Y. (2021). Effects of mobile drama with authentic contexts on English learning. Journal of Educational Computing Research, 59(7), 1294–1318. https://doi.org/10.1177/0735633121994289   
Lombardi, M. M. (2007). Authentic learning for the 21st century: An overview. Educause Learning Initiative, 1(2007), 1–12.   
Manabe, K., Hwang, W.-Y., & Chuang, Y.-W. (2021). English learning enhanced by collaborative contextual drama in an authentic context. Interactive Learning Environments, 1–17. https://doi.org/10.1080/10494820.2021.1972321   
Nguyen, T.-H., Hwang, W.-Y., Pham, X.-L., & Ma, Z.-H. (2018). User-oriented EFL speaking through application and exercise: Instant speech translation and shadowing in authentic context. Journal of Educational Technology & Society, 21(4), 129–142.   
Pérez-Segura, J. J., Sánchez Ruiz, R., González-Calero, J. A., & Cózar-Gutiérrez, R. (2020). The effect of personalized feedback on listening and reading skills in the learning of EFL. Computer Assisted Language Learning,  35(3), 1–23.   
Poushter, J. (2016). Smartphone ownership and internet usage continues to climb in emerging economies. Pew Research Center, 22(1), 1–44.   
Shadiev, R., Hwang, W. Y., Huang, Y. M., & Liu, T. Y. (2018). Facilitating application of language skills in authentic environments with a mobile learning system. Journal of Computer Assisted Learning, 34(1), 42–52. https://doi.org/10.1111/jcal.12212   
Shadiev, R., Hwang, W.-Y., Huang, Y.-M., & Liu, C.-J. (2016). Investigating applications of speech-to-text recognition technology for a face-to-face seminar to assist learning of non-native English-speaking participants. Technology, Pedagogy and Education, 25(1), 119–134. https://doi.org/10.1080/1475939X.2014.988744   
Sun, Z., Lin, C.-H., You, J., Shen, H. J., Qi, S., & Luo, L. (2017). Improving the English-speaking skills of young learners through mobile social networking. Computer Assisted Language Learning, 30(3-4), 304–324. https://doi.org/10.1080/09588221.2017.1308384   
Voloshinov, V. N., Matejka, L., & Titunik, I. (1973). Marxism and the philosophy of language [by] VN Volosinov (L. Matejka & I. Titunik, Trans.). Harvard University Press (1986).   
Zhang, H., Hwang, W.-Y., Tseng, S.-Y., & Chen, H. S. (2019). Collaborative drama-based EFL learning in familiar contexts. Journal of Educational Computing Research, 57(3), 697–722. https://doi.org/10.1177/0735633118757731   
Zhu, Z.-T., Yu, M.-H., & Riezebos, P. (2016). A research framework of smart education. Smart Learning Environments, 3(1), 4. https://doi.org/10.1186/s40561-016-0026-2   
Zohoorian, Z. (2015). Motivation level: A study on the effect of an authentic context. Procedia Social and Behavioral Sciences, 192, 15–25. https://doi.org/10.1016/j.sbspro.2015.06.003

# Appendix

Pretest

# 一. 單字測驗:

查看照片後寫下對應的交通工具的與活動的英文。

![](img/fccb28a393bf4c5476ac4b9de9ac41f37cbb3b51ff45fa3b1e89f742cfb522a3.jpg)

二. 選擇測驗：查看問句後選擇正確的回答。

<html><body><table><tr><td></td><td></td><td>How do you go to school?</td></tr><tr><td></td><td></td><td>(A) I go home on foot.</td></tr><tr><td>1.()</td><td></td><td>(B)I go to school by bus.</td></tr></table></body></html>

<html><body><table><tr><td>2.()</td><td>Dose she go home on foot?. (A) No. she doesn&#x27;t. She goes to school by train. (B) No. she doesn&#x27;t. She goes home by taxi..</td></tr><tr><td>3.()</td><td>What do you do after school? (A) I go swimming after school. (B) I will go swimming tomorrow.</td></tr><tr><td>4.()</td><td>What do you do after class? (A) I do my homework at 5:30. (B) I play with my friend after class..</td></tr></table></body></html>

# 三. 造句測驗：查看圖片後完成你認為的圖片中的對話, 將對話念出並使用平板錄音。

![](img/b4a4104b3c0514812bdae3fa5ea6b372358395528219de8331d481296309877f.jpg)

Girl: Good morning!   
Boy: Good morning!   
Boy: How do school?   
Girl: Girl: It is free time now.   
Boy: Yes! Class finished.   
Boy: What do in your free time? Girl:

![](img/05d7197115926e5acd3ae88a33be9c4230aba463095b2d4c5843e4379830adcb.jpg)