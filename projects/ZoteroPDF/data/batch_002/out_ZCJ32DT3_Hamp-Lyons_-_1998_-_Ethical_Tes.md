# Ethical Test Preparation Practice: The Case of the TOEFL

LIZ HAMP-LYONS Hong Kong Polytechnic University

■ Millions of learners of EFL/ESL take English language tests every year, and teachers often worry that learners’ attention may be distracted from the real business of learning the language and focussed on mastering item types for the tests instead (Buck, 1988; Raimes, 1990; Shohamy, 1992). The question of washback, the influence of tests onto teaching and learning, has been well discussed elsewhere (Alderson & HampLyons, 1996; Alderson & Wall, 1993; Bailey, 1996; Wall & Alderson, 1993). The discussion here focuses on the role of textbooks in test washback, raising questions about the prevalent practices of test preparation and the materials used in it.

In raising these questions, I take as my example one test, the Test of English as a Foreign Language (TOEFL), produced by the Educational Testing Service (ETS).1 The TOEFL is the most commonly taken international English language test in the world. Approximately a million people take the TOEFL every year (ETS, 1996), a number exceeded only by the approximately 2 million people within China who take the College English Test (CET) each year (Cheng, 1997).

# WASHBACK AND THE TOEFL

In their study of TOEFL preparation classes and teachers, Alderson and Hamp-Lyons (1996) concluded that

Tests will have different amounts and types of washback on some teachers than on other teachers and learners. Washback will vary by

the level of the stakes, the extent to which the test is counter to current practice,

the extent to which teachers and textbook writers think about appropriate methods for test preparation, and   
the extent to which teachers and textbook writers are willing to innovate. (p. 295)

Clearly, the TOEFL is an example of a very high stakes English language test; it is also very counter to current instructional practice in English language teaching. One might therefore expect it to have considerable washback onto teaching and learning. To the extent that teachers see their principal task as helping learners increase their knowledge of and ability to use English, think about what is appropriate in test preparation, and consciously choose appropriate content and methods, their TOEFL teaching might have beneficial washback (Bailey, 1996; Shohamy, 1993). To the extent that the content and design of TOEFL preparation textbooks support teachers in their principal task of helping learners increase their knowledge of and ability to use English, these textbooks might have beneficial washback. But this is no easy task: It requires the inclusion of appropriate content carefully designed to match learning needs and sequence and planned to support good classroom pedagogic practices; it also requires keeping close sight of what is appropriate in test preparation practices and what the demands of the test itself are. This suggests, then, that the task of designing and writing test preparation textbooks would be more highly skilled and complex even than the task of designing and writing mainstream language learning textbooks.

# QUESTIONS ABOUT TEST PREPARATION

There is a great deal the TESOL profession does not know about the teaching of TOEFL or other test preparation. How much of it goes on, both in the U.S. and around the world? Who teaches it? What English language teaching qualifications do the teachers have? What special qualifications or training is needed to teach TOEFL (or other test) preparation? Does ETS offer a training program for TOEFL preparation teachers? Do other test agencies offer training courses for test preparation teachers? Has TESOL’s Committee on Professional Standards looked specifically at test preparation practices? An informal enquiry of 10 language schools in the U.S. revealed that none required any specific qualification for their teachers of TOEFL preparation classes besides that for teachers of other courses. Similarly, my informal enquiry of six frontistiria (private language schools) in Greece in 1995 and 1996 failed to find one that ran test preparation training for the many teachers of First Certificate in English (FCE) and other University of Cambridge Local Examinations Syndicate tests.

Most surprising is the fact that there seem to have been no studies of whether TOEFL preparation (or, indeed, as far as I am aware, other ESL/EFL test preparation) courses actually do improve scores, as this is the very reason all students take such courses. Evidence for the effectiveness of test preparation courses more generally seems hard to come by. Powers (1993) carried out a meta-analysis of studies of the effect of coaching on Scholastic Aptitude Test (SAT) scores and found only dubious evidence for the claims made by coaching companies and publishers of test preparation materials that either courses or published materials have any significant effect on students’ SAT scores. Alderson and Hamp-Lyons (1996) did not look at the question of whether TOEFL preparation courses are effective—that is, whether students who take a TOEFL preparation course succeed in raising their TOEFL scores. Given the vast size of the TOEFL preparation industry, it would seem useful to know whether TOEFL activities have any effect and, if so, which have the greatest effect. The burden of proof seems to rest squarely with the textbook-publishing industry. But there is no imperative for the industry to provide this proof because its market is so bullish without it.

# FINDINGS FROM A TEXTBOOK ANALYSIS

In a paper presented at the 1996 International Language Testing Research Colloquium (Hamp-Lyons, 1996), I argued that, because the TOEFL is such a high-stakes test, it is likely to have a powerful washback effect and that the effect will be in a negative rather than a positive direction. I supported my comments with an analysis of five TOEFL preparation textbooks selected at random from those on the market in spring 1996. My purpose was not to critique those particular books but rather to use them to illustrate my general concerns about test preparation practice in TESOL and to propose general principles for the profession.2

Starting with the patterns that grew out of the Alderson and HampLyons (1996) research (including related discussions with graduate students and teachers about issues of test preparation), discussions with teachers and language testers, and recursive examination of those patterns in the books themselves, I developed a framework against which I could evaluate each textbook. The framework consisted of a set of descriptors that identified the features of each textbook. By looking at the values given on the descriptors in the framework, I was able, for example, to discover that only one of the five textbooks has guidance for teachers built into the text (although one has a teacher’s book, it is really an answer key). Typically the books contain practice tests, exercises, grammar exercises for selected key grammar points, a tape and tape script, and an answer key, and score well on the features able to self-score and contain answer key. Clearly, in these books the learner is assumed to be able to prepare independently for the TOEFL. However, when I looked at the feature help with self-diagnosis/assessment, I found that whereas learners can score themselves, they are not helped to diagnose problem areas, patterns of need, or even areas of strength. Learners are left to try to work out for themselves what to do after having counted the number of items right and wrong and worked out a weighted score. Furthermore, what the books typically offer students next is another practice test. Yet the field of TEFL/TESL is only just beginning to venture into the area of independent learning, and few learners in the many countries where students and adults eagerly spend their money studying to succeed on the TOEFL in order to get a postgraduate place at a university or a job have been trained in the skills of autonomous learning.

I found that the skills promoted by the textbooks generally consist of (a) test-taking strategies and (b) mastery of language structures, lexis, and discourse semantics that have been observed on previous TOEFLs. Because the books are built around the model of the test and because the test is not intended to reveal or reflect a model of language in use, even if it is built upon one, teacher and learners find themselves teaching—and trying to learn—discrete chunks of language rules and vocabulary items without context or even much co-text. TOEFL items are selected for their psychometric properties, which is entirely appropriate for a test within this paradigm, but it has nothing to say to a pedagogy. If the TOEFL program intends to test any underlying language abilities through its choice of items, these underlying abilities are not easy to infer from a study of the published handbooks and manuals. Although there are many research reports on the TOEFL, they are quite technical and forbidding to the nontester (and, interestingly, authors of TOEFL textbooks tend not to be language testers, at least not in the sense that their research interests lie in the area of testing), and the test specifications are “confidential and proprietary” (personal communication, TOEFL program director, May 1996). These two obstacles could help explain why the books used for this study promote skills that relate quite exactly to the item types and item content found on the actual test rather than to any EFL/ESL curriculum or syllabus or to any model of language in use. These test preparation books consist, to a greater or lesser extent, of practice tests or exercises that themselves follow exactly the same format as the subsection of the test they are preparing students for. When strategies are taught, they are usually very general (e.g., for the listening test, “Beware of distractors that sound very similar to what was spoken as these are often incorrect”). Only one has any significant amount of helpful test-taking material, and much of it is quite specific and unlikely to be of much help on other kinds of tests, such as essay tests or oral proficiency interviews. When exercises or practice tests are presented, there is no preceding material to teach the point tested by each item. One book does not even contain an explanation of what makes the right answers right. Only one book has consistent explanations of why each distractor was wrong. Teachers, then (or students, if they are using such a book for self-study), must figure out and then teach or explain each tested point themselves.

In Alderson and Hamp-Lyons’ (1996) study, the highly experienced teacher who was new to teaching TOEFL preparation found it very difficult to plan classes around the units in the textbook, and classes were disorganized and full of vague, confusing, or incorrect explanations of arcane grammar points the textbook author considered likely to be tested on the TOEFL. This teacher was, perhaps, still subconsciously seeking the underlying logic in pedagogical grammar terms that he felt must underpin the book. But item order within the subtests of the TOEFL is inherently nonprogressive. Because there is no inherent rational structure to item order on the TOEFL, lesson plans have to be designed on some other basis, rational or otherwise. In the Alderson and Hamp-Lyons study, even the highly experienced teacher of TOEFL preparation courses, whose lessons were clearly tightly planned and based on his own TOEFL preparation textbook, was unable to devise a rational basis for his classes: Each lesson consisted of working through the practice test material in the textbook in the same pattern as the inexperienced teacher, but with accurate, focused, and clear grammatical explanations. The problems that the absence of pedagogic logic might have generated seemed to have been avoided by the teacher’s questioning strategy, which was structured to enable him to insert probes into the lesson so that he could present the set-piece grammar or vocabulary explanation he had planned to fit an item whether or not the student nominated to answer it gave the right or the wrong answer.

Although the TOEFL preparation textbooks I evaluated contain some material focused on the period before the student takes a practice test and a great deal of material concerned with actually practicing the tests, they typically contain no material to help teachers or students after they have taken the test or a practice test. Once teachers (or self-study students) have checked answers against the answer key and (if they have bought the right book) read the explanations of why the wrong answers they chose are wrong, what strategies can they employ next? The solution the books generally offer is to work through another practice test. Because the items on each test are different, and because there is no published TOEFL syllabus or set of specifications, the only strategy for deciding what language areas to focus on would seem to be to work out the probable frequency of different types of items or probes across multiple, actual TOEFL forms. But even this strategy leaves the teacher with nothing more than a laundry list of grammatical or lexical points to be covered—and the laundry lists in the books I studied contain from 24 to 170 grammar points in the structure and written expression sections. Developing a rational syllabus that does not match up with the test in any obvious way would appear to be very difficult, but so is finding ways to make using a book that follows the format of the TOEFL interesting and credible as a learning experience.

# ETHICAL TEST PREPARATION?

Coupled with the pedagogic difficulties, test preparation teachers face a very difficult set of ethical decisions about what materials are appropriate to use. Mehrens and Kaminsky (1989) and Popham (1991) each describe a scale of ethical test preparation practices, both of which see practice on a published previous or parallel form as educationally indefensible (boosting scores without mastery) and of dubious ethicality (coaching merely for score gain). All the textbooks I surveyed were at the unethical/indefensible end of the scales. Previous form preparation may also be of dubious legality; only ETS and the TOEFL program know the answer to this, but it seems most likely that parallel forms of the TOEFL tests are generated from disclosed versions of the test by permutating the items from a number of tests to create new versions, with a word here and there changed. It should be noted that the TOEFL program itself publishes TOEFL preparation materials using disclosed test items because it believes that all students should be adequately prepared for the form of the test so that they are not disadvantaged by a differential test practice effect. However, the TOEFL uses its own proprietary material to do this and ensures that the test version it releases possesses all the properties of actual tests. This is not the case for most commercially published TOEFL preparation material.

None of the textbooks I analyzed provides general instruction or testtaking instruction except as they relate to preparation for the TOEFL; further, they do little with task types or item formats other than those predicted to occur on the TOEFL on the basis of analysis of past forms. On Popham’s (1991) scale, same-format preparation is considered to be ethical, as “no behavior unacceptable to the profession” (p. 13) takes place, but it is also considered educationally indefensible.

# CONCERNS FOR TESOL

I believe that it is time the TESOL profession looked seriously at how much same-format preparation takes place in test preparation courses and investigated whether and how much time and student energy are diverted from mainstream, well-designed language classes, built around appropriate curricula and materials for the proficiency level of the students, into unproductive, test-mimicking exercises. The fact that the problems teachers face in selecting and using test preparation materials have been ignored for so long in TESOL despite the enormous TOEFL (and other test) preparation industry means that no guidance is available to teachers on good conduct in test preparation teaching or on the selection of ethical and appropriate test preparation materials.

Many other questions need to be raised about TOEFL test preparation practices and test preparation in general: Can a test be blamed for the ways in which some teachers teach toward it? If teachers do not teach communicatively in TOEFL preparation courses, is it the fault of the test, the teachers, or the test preparation materials? Or is it the fault of the students who demand a certain kind of teaching, as the teachers Alderson and Hamp-Lyons (1996) talked to often claimed? Alderson and Hamp-Lyons found that the teachers’ claims were contradicted by what students themselves said. Is it perhaps the fault of the teaching institutions, which do not provide any kind of teacher training in TOEFL preparation? Although many language schools do have high standards for the qualifications of their teachers and apply them to TOEFL teachers, others seem to regard TOEFL preparation teaching as a kind of battery farming or as a proving ground for new teachers and have less (or un-) qualified teachers teaching test preparation to bigger classes: While I was at the University of Colorado, Denver, one of my graduating English majors, having never taught anything to anyone before and having no teaching qualifications, got a job in a small, new local language school and was set immediately to teaching TOEFL preparation. Or is training in teaching test preparation the responsibility of the textbook writers and publishers? Is it instead perhaps the responsibility of the testing agency? (It is not, in fact, possible to become an accredited TOEFL teacher: ETS does not offer training, although it thought at one time of doing so.) Or is it the responsibility of programs leading to a diploma in teaching English as a foreign language to adults, a master’s in TESOL, and similar EFL/ESL teacher education courses to know the market their student teachers will enter and do more to prepare them for it? I offer no answers here. The goal is rather to begin to ask the questions.

As the TESOL profession and the international organization TESOL, Inc., matures, it must move toward a code of practice for its practitioners and members, as other professional associations have done, and in my view such a code of practice should include test preparation practices and materials. The responsibility for inadequate test preparation materials of dubious ethicality must be shared by testing agencies, who develop and market tests that lend themselves to sterile, nondevelopmental preparation practices; by publishers, virtually all of whom in the TESOL field sell at least one test preparation course that fits the criteria for educational indefensibility and doubtful ethicality described above; and by authors who write and sell books that do not have as their purpose the instructed acquisition of English language proficiency. But professional associations also should take some responsibility. I am not aware of any studies of English language test preparation, by TESOL or any other professional association, such as the International Association of Teachers of English as a Foreign Language, headquartered in Britain, or the Association Internationale de Linguistique Appliquée, the world organization of applied linguists, currently headquartered in Minneapolis, in the U.S.

Although I believe that language testing researchers should be much more concerned than they have been about test preparation practices, following the lead of researchers in educational measurement, this is not a problem in language testing (at least, not by any usual definition of what language testing is) and certainly cannot be solved by research, though it can be much better understood. Rather, it is a problem in program administration, in teaching, in textbook authoring, and in the educational-commercial interface in the TESOL profession. Because this is such a far-reaching issue with such impact on the lives of the learners to whom L2 educators owe their concern, I suggest that TESOL itself take the lead in developing a code of ethical test preparation practice for teachers, textbook authors, and publishers to follow. TESOL’s primary responsibility is to its members. TESOL members’ primary responsibility is to their students: Many TESOL members teach students who want— who need—to succeed on the TOEFL, or CET, or International English Language Testing Service, or Michigan English Language Assessment Battery, or FCE, or the many other English language tests that exist around the world.

# ACKNOWLEDGMENTS

I am very appreciative of Charles Alderson’s conceptualizing questions about the effects of textbooks in exam preparation courses, although all the views expressed here are my own.

# THE AUTHOR

Liz Hamp-Lyons is Professor of English and Head of Department at the Hong Kong Polytechnic University. Her research interests include L1 and L2 writing pedagogy and materials, writing assessment, performance assessment, language testing ethics, English for academic and specific purposes, and critical discourse analysis. She has published extensively, including Assessing Second Language Writing in Academic Contexts (Ablex, 1991) and, with Bill Condon, Assessing College Writing Portfolios: Theory, Practice, Research (Hampton Press, in press).

# REFERENCES

Alderson, J. C., & Hamp-Lyons, L. (1996). TOEFL test preparation classes: A study of washback. Language Testing, 13, 280–297.   
Alderson, J. C., & Wall, D. (1993). Does washback exist? Applied Linguistics, 14, 116– 129.   
Bailey, K. M. (1996). Working for washback: A review of the washback concept in language testing. Language Testing, 13, 257–279.   
Buck, G. (1988). Testing listening comprehension in Japanese university entrance examinations. JALT Journal, 10, 15–42.   
Cheng, M. (1997, October). An overview of college English in China. Paper presented at the Hong Kong Polytechnic University.   
Educational Testing Service. (1996). TOEFL test and score manual. Princeton, NJ: Author.   
Hamp-Lyons, L. (1990). Preparing for the Test of Written English. Rowley, MA: Newbury House.   
Hamp-Lyons, L. (1996, July). Ethical test preparation practice: The case of the TOEFL. Paper presented at the 18th Annual Language Testing Research Colloquium, Tampere, Finland.   
Mehrens, W. A., & Kaminsky, J. (1989). Methods for improving standardized test scores: Fruitful, fruitless or fraudulent? Educational Measurement: Issues and Practice, 8(1), 14–22.   
Popham, W. J. (1991). Appropriateness of teachers’ test-preparation practices. Educational Measurement: Issues and Practice, 10(4), 12–15.   
Powers, D. (1993). Coaching for the SAT: A summary of the summaries and an update. Educational Measurement: Issues and Practice, 12(2), 24–30, 39.   
Raimes, A. (1990). The TOEFL Test of Written English: Causes for concern. TESOL Quarterly, 24, 427–442.   
Shohamy, E. (1992). Beyond proficiency testing: A diagnostic feedback model for assessing foreign language learning. Modern Language Journal, 76, 513–521.   
Shohamy, E. (1993). The power of tests: The impact of language tests on teaching and learning (Occasional paper). Washington, DC: National Foreign Language Center.   
Wall, D., & Alderson, J. C. (1993). Examining washback: The Sri Lankan impact study. Language Testing 10, 41–69.