# The effect of feedback on metacognitive strategy use in EFL writing

Jianhua Zhang & Lawrence Jun Zhang

To cite this article: Jianhua Zhang & Lawrence Jun Zhang (2024) The effect of feedback on metacognitive strategy use in EFL writing, Computer Assisted Language Learning, 37:5-6, 1198-1223, DOI: 10.1080/09588221.2022.2069822

To link to this article: https://doi.org/10.1080/09588221.2022.2069822

# The effect of feedback on metacognitive strategy use in EFL writing

Jianhua Zhanga,b $\textcircled{1}$ and Lawrence Jun Zhangb ic

a School of Foreign Languages, Sichuan University of Arts and Sciences, Dazhou, China; bFaculty of Education and Social Work, University of Auckland, Auckland, New Zealand

# ABSTRACT

This study mainly explored the effects of teacher feedback, peer feedback and automated feedback on the use of metacognitive strategies in EFL writing. Ninety-seven participants were recruited and divided into three groups, who received two months of feedback from teachers, peers and an automatic writing evaluation system, respectively, and then completed English writing tasks. Metacognitive strategies in this study entail planning strategies (including language knowledge accumulation strategies and pre-planning strategies), monitoring strategies (including selective attention strategies and self-monitoring strategies), and self-evaluation strategies. By conducting repeated-measures ANOVA on three groups of participants’ use of metacognitive strategies before and after receiving different feedbacks, it was found that there were statistically significant differences in the effects of teacher feedback, peer feedback, and automated feedback on the use of selective attention strategies, whereas there were no statistically significant differences in the impact of those aforementioned types of feedback on other metacognitive strategies. It was also found that automated feedback had a hindrance effect on the use of monitoring strategies, whereas teacher feedback and peer feedback had a promotive effect on the use of all metacognitive strategies.

# KEYWORDS

Automated feedback; teacher feedback; peer feedback; metacognitive strategies

# 1.  Introduction

Feedback is indispensable in the process of teaching writing, especially in the English as a foreign language (EFL) context, such as China (Zhan et  al., 2021; Zhang & Cheng, 2021). Traditionally, teacher feedback is most frequently employed along with peer feedback in first and second language writing teaching. The advancements in natural language processing and latent semantic analysis facilitated the generation of automated writing evaluation tools (Jiang & Yu, 2020), which have been employed to provide feedback to student writers’ essays in the EFL context. The feedback generated by automated writing evaluation tools is generally named automated feedback. The role of the automated feedback has recently drawn a lot of scholars’ attention (e.g. Conijn et  al., 2020; Jiang & Yu, 2020; Li et  al., 2019; Ranalli, 2018; Sarré et  al., 2021).

Hyland and Hyland (2006) believe that the ultimate goal of feedback is to make students become more independent writers. They can evaluate their essays critically and change their cognitive process and essays when necessary in the writing process. To achieve this goal, they must develop and master metacognitive skills or strategies. Furthermore, Butler and Winne (1995) proposed that feedback has a particular impact on the choice and formulation of learners’ goals, the selection, adoption and output of cognitive strategies, and the evaluation of learning outcomes, thus further affecting learners’ academic achievement. The selection and formulation of goals, the selection and adoption of cognitive strategies, and the evaluation of learning outcomes are precisely what metacognitive strategies focus on (Anderson, 2007, 2008; O’Malley & Chamot, 1990). Hattie and Timperley (2007) pointed out that feedback is helpful for students to master metacognitive skills or strategies. However, to our knowledge, few available studies have provided empirical evidence for the effect of feedback on the use of metacognitive strategies in the writing process.

To address the research gap in the literature, therefore, this current study intended to explore the influence of three types of feedback (including automated feedback, teacher feedback and peer feedback) on the use of metacognitive strategies in English writing, hoping to expand further and deepen the understanding of the influence of feedback on metacognition in second language writing.

# 2.  Literature review and conceptual framework

# 2.1.  Metcognition in the EFL writing context

Metacognition is considered to be the most crucial factor affecting learning. Zhang and Zhang (2008,  2018) pointed out that metacognition is vital to foreign language learning. Metacognition refers to an individual’s ‘knowledge and cognition about cognitive phenomena’ (Flavell, 1979, p. 906), which was mainly divided into metacognitive knowledge and metacognitive regulation. The former concerns ‘knowledge of congition and awareness of one’s own cognition’ (Harris et  al., 2010, p. 227), whereas the latter embraces ‘consciously planning, monitoring, and evaluating cognitive activities’ (Harris et  al., 2010, p. 231). Metacognitive regulation are conceived as ‘potent catalysts for developing competence and promoting performance in writing’ (Harris et  al., 2010, p. 231). Recent work has elaborated on the notion of metacognitive regulation and metacognitive experiences in the realm of foreign/second langauge writing research (Sun et  al., 2021).

Brown (1987) divided metacognitive regulation into planning, monitoring, and evaluation. These strategies are called metacognitive strategies. O’Malley and Chamot put forward metacognitive strategies from the perspective of learning strategies. They believe that metacognitive strategies refer to ‘the necessary conditions for learners to successfully plan, monitor and evaluate learning activities by adjusting or self-managing the cognitive process through planning, monitoring and evaluation, which plays the most critical role in improving learning effects’ (O’Malley & Chamot, 1990, pp. 119–120). Comparing those definitions of metacognitive strategy, we can find that planning, monitoring and evaluation are the core elements of metacognitive strategy use. Planning is a series of action learners could employ to predict, allocate time and effort, select strategies, set goals, and make plans to achieve these goals (Brown, 1987; Pintrich, 2004; Schraw et  al., 2006). Monitoring concerns the control that a learner could have over whether certain strategies are appropriate to complete a learning task (Cera et  al., 2013), incorporating monitoring variations in his/her personal factors such as cognition, emotion, motivation and task factors like task requirements and time (Zimmerman, 2002). Evaluation is defined as ‘appraising the products and regulatory processes of one’s learning’ (Schraw et  al., 2006, p. 114). Zhang and Qin (2018) found similar factor structures of metacognitive strategies employed by Chinese EFL writing learners in a multimedia-learning context: Pre-planning, self-monitoring, and self-assessment are three main facets of metacognitive strategies. Therefore, in this study, metacognitive strategies for English writing mainly include planning strategies, monitoring strategies and self-evaluation strategies. Planning strategies entail two components: Language accumulation strategies and pre-planning strategies, whereas monitoring strategies include two subconstructs: Selective attention strategies and self-monitoring strategies.

Many empirical studies have confirmed that metacognitive strategies can improve English writing performance (e.g. Lu, 2006). Lu (2006) explored the relationship between a group of English majors’ metacognitive strategy use and their English writing performance in one of China’s universities and found that: (1) Language proficiency has a certain impact on the use of metacognitive strategies; and (2) the use of pre-planning and selective attention is the main influence on English writing performance.

# 2.2.  Feedback in EFL writing contexts

Feedback plays an indispensable part in the teaching of writing, especially from the perspective of process-based writing and formative evaluation (Huang & Zhang, 2020; Keh, 1990; Wu et  al., 2021;  Zhang  & Cheng, 2021). Many empirical studies have confirmed that feedback can promote the improvement of L2 or EFL Writing (e.g. Ferris & Roberts, 2001; Wang & Liu, 2012; Wu & Zhang, 2016; Yang, 2006; Yang et  al., 2013). Therefore, in English writing teaching, teachers can use different kinds of feedback to improve students’ English writing performance. There have been two main types of feedback in the traditional English writing class: teacher feedback and peer feedback. The former was defined as the information provided by teachers regarding different aspects of EFL writing (Hattie & Timperley, 2007), whereas the latter was defined as the information offered by EFL students’ peers with respect to their writing (Hattie & Timperley, 2007; see also Zhang & Cheng, 2021, for a review). In recent years, the rapid development of computer technology and natural language processing and latent semantic analysis made it possible to produce tools for evaluating writings or essays in an automated manner. Therefore, several automated writing evaluation tools are available for EFL writing teachers to utilize in their classroom, for instance, www.pigai.org and iWrite in China. Some of these automated writing evaluation tools are freely available on the Internet. EFL writing teachers can easily employ them in their writing instruction to provide automated feedback on students’ essays. The main advantage of automated feedback is that it can provide timely, efficient and flexible feedback for students’ essays (Wilson & Czik, 2016).

The role of the automated feedback has recently drawn a lot of attention from scholars (e.g. Conijn et  al., 2020; Jiang & Yu, 2020; Li et  al., 2019; Ranalli, 2018; Sarré et  al., 2021; Tian & Zhou, 2020, Zhu et  al., 2020). Ranalli (2018) explored the factors that might affect L2 writers’ use of automated feedback for correction purposes. He found that higher perceptions of mental-effort expenditure, lower ratings of clarity and helpfulness and specific feedback might enable L2 writers to successfully correct errors in their writings than generic feedback. Furthermore, Zhu et  al. (2020) investigated the effect of automated feedback on young L1 learners’ revision behaviour and learning gains in argumentative writing. They revealed that contextualized feedback was more effective in facilitating young learners’ writing. In addition, Jiang and Yu (2020) explored how Chinese EFL student writers appropriate automated feedback in their writing through examining different sources of qualitative data, such as drafts, documents, and interviews. They demonstrated that EFL student writers might employ three forms of appropriation due to contextual factors such as various artifacts, rules, their peers and the roles the student writers have taken on. Besides, Barrot (2021) investigated the effect of automated feedback on L2 writing accuracy. He revealed that automated feedback could improve L2 writers’ writing accuracy through promoting their noticing, offering an adaptive metalinguistic explanation, and facilitating their engagement in self-directed learning.

The utility of automated feedback in comparison to teacher feedback and/or peer feedback attracted a lot of attention from scholars (e.g. Huang & Zhang, 2014; Li, 2019; Tian & Zhou, 2020; Wu & Zhang, 2016; Zhang & Hyland, 2018; Zhou, 2013). While comparing the role of teacher feedback and automated feedback in EFL writing, Wu and Zhang (2016) found that EFL learners preferred teacher feedback to automated feedback and that automated feedback might induce more self-revision. In addition, Zhang and Hyland (2018) compared Chinese EFL students’ engagement with teacher feedback and automated feedback in a case study. They found that students’ engagement might play a crucial mediating role in their use of feedback and the effect of feedback on their writing development. To our knowledge, a limited number of researchers focused on the comparison of the effects of the above three kinds of feedback on English writing (e.g., Huang & Zhang, 2014; Li, 2019; Tian & Zhou, 2020; Zhou, 2013). By comparing the effects of teacher feedback, peer feedback, and automated feedback on English writing, Zhou (2013) found that different kinds of feedback had different effects on English writing in a foreign language context: Teacher feedback could improve the structure and organization of students’ English writing; peer feedback might have certain impacts on eliminating students’ negative affective factors (such as writing anxiety) and enhancing their interest in English writing; automated feedback could be helpful for students to enhance the structure and words of their essays. Later, Huang and Zhang (2014) found that teacher feedback, peer feedback, and automated feedback might show differences in the number, content and type of modification induced from students, suggesting that the three forms of feedback should be effectively combined in English writing teaching. This finding was confirmed by Li (2019), where she put forward the effective combination of teacher feedback, peer feedback and automated feedback in English writing instruction by assigning teacher feedback the role of directing or guiding the learning of English writing, peer feedback the role of promoting that learning, and automated feedback the role of facilitating that learning. Besides, Tian and

Zhou (2020) further compared the effects of teacher feedback, peer feedback and automated feedback on EFL writing from the perspective of learner engagement. They found that students engaged with different types of feedback in a dynamic and reciprocal manner, which was mediated by a series of individual and contextual factors, such as proficiency, majors, and emotions towards feedbacks.

The available studies contributed tremendously to our understanding of the role of automated feedback, teacher feedback, and peer feedback in EFL writing. Hyland and Hyland (2006) suggest that the feedback employed in writing instructions is ultimately designed to facilitate students to grow into more independent writers. However, few studies have concentrated on whether those kinds of feedback would help students in an EFL context to become independent writers. Becoming independent writers means that students could conduct a critical evaluation or assessment on their own essays and adjust their cognitive process and essays when necessary according to the individual and contextual factors in the writing process. To accomplish this goal, they should acquire a range of metacognitive skills or strategies, such as planning strategies, monitoring strategies, and evaluation strategies.

# 2.3.  Conceptual framework

Butler and Winne (1995) proposed that feedback might have an impact on students’ decision-making or judgement on the following questions: how to choose and formulate their learning goals, how to select, adopt and perform their cognitive strategies to accomplish their goals, how to evaluate their learning outcomes or performance. The answer to the afore-mentioned questions could further affect learners’ academic achievement. The selection and formulation of learning goals, the selection and adoption of cognitive strategies appropriate for learning tasks, and the evaluation of learning outcomes or performance are exactly the contents that metacognitive strategies covered (Chamot & Harris, 2019; O’Malley & Chamot, 1990; Zhang & Zhang, 2018). Therefore, it is hypothesized that feedback might have an impact on metacognitive strategies. Besides, Hattie and Timperley claimed that feedback is designed ‘to reduce discrepancies between current understandings and performance and a goal’ (2007, p. 86), thus offering answers to three key queries regarding goals, progress and further activities leading to more progress. These questions might work at four levels: Task level, process level, self-regulation level, and self-level. Metacognition is assumed to be involved in self-regulation (Zimmerman, 1995;  Zhang & Zhang, 2019). Therefore, Hattie and Timperley (2007) pointed out that feedback is conducive to students’ acquisition of metacognitive skills. In addition, recent experimental studies in fields such as testing demonstrated that feedback might have an effect on metacognitive knowledge or metacognitive strategies (Callender et  al., 2016; Miller & Geraci, 2011; Molin et  al., 2020). Miller and Geraci (2011) found that students might improve their metacognitive monitoring when offered concrete feedback on the tests in a cognitive psychology course. Through analyzing students’ judgment of their performance and their actual performance in two tests, Callender et  al. (2016) found that the feedback on the test performance might have improved students’ metacognitive judgement, which is closely related to evaluation strategies. Molin et  al. (2020) found that the combination of teacher feedback with student discussion might have a significant positive effect on students’ development of metacognitive strategies in the physics course. However, to our knowledge, there have been few available studies on the impact of feedback on the use of metacognitive strategies in the writing process.

To bridge the research gap in the literature, the current study aimed to explore the effects of teacher feedback, peer feedback and automated feedback on the use of metacognitive strategies in EFL writing. Metacognitive strategies in this study entail planning, monitoring, and self-evaluation strategies. Specifically, it tried to answer three research questions:

1. To what extent are the different impacts of teacher feedback, peer feedback, and automated feedback on the use of planning strategies?   
2. To what extent are the different impacts of teacher feedback, peer feedback, and automated feedback on the use of monitoring strategies?   
3. To what extent are the different impacts of teacher feedback, peer feedback, and automated feedback on the use of self-evaluation strategies?

# 3.  Research design

# 3.1.  Participants

According to the research questions, we randomly selected 97 non-English sophomores from three intact classes in one of the universities in Sichuan Province, China, including 36 men and 61 women. They enrolled in such four-year programs as education, management, and business. Before the experiment, they were randomly divided into three experimental groups, receiving teacher feedback, peer feedback and automated feedback on their essays, respectively, throughout the experiment. In order to ensure that the English proficiency of the participants was equal, we collected their scores of the College English Test - Band Four (CET-4) in China, which is designed especially for Chinese EFL learners, and then conducted an ANOVA analysis. The results are shown in Table 1.

Table 1. D escriptive statistics and ANO VA analysis results of CET -4 scores.   

<html><body><table><tr><td></td><td>N</td><td>Mean</td><td>SD</td><td>F</td><td>Sig.</td></tr><tr><td>Teacher feedback group</td><td>34</td><td>365.44</td><td>42.557</td><td>1.846</td><td>0.164</td></tr><tr><td>Peer feedback group</td><td>33</td><td>380.67</td><td>47.651</td><td></td><td></td></tr><tr><td>Automated feedback group</td><td>30</td><td>383.70</td><td>30.805</td><td></td><td></td></tr></table></body></html>

Table 2. ANO VA results of participants’ scores of English essays.   

<html><body><table><tr><td></td><td>N</td><td>Mean</td><td>SD</td><td>F</td><td>Sig.</td></tr><tr><td>Teacher feedback group</td><td>34</td><td>51.06</td><td>6.55</td><td>2.146</td><td>0.123</td></tr><tr><td>Peer feedback group</td><td>33</td><td>53.23</td><td>6.86</td><td></td><td></td></tr><tr><td>Automated feedback group</td><td>30</td><td>54.13</td><td>4.66</td><td></td><td></td></tr></table></body></html>

It can be seen from Table 1 that there were no statistically significant differences among the three groups in terms of English proficiency ( $F { = } 1 . 8 4 6$ , $\begin{array} { r } { p = 0 . 1 6 4 , } \end{array}$ ).

# 3.2.  Experiment procedures

This experiment was mainly divided into three stages: the pre-test stage, the experimental stage and the post-test stage.

# 3.2.1.  Pre-test phase

Before the beginning of the experiment, we conducted a pre-test on three groups of participants, including two aspects: the level of English writing and the use of metacognitive strategies in English writing. In order to avoid the possible interferences between the two items, the test for English writing proficiency and the survey for metacognitive strategy use in English writing were administrated at an interval of one week. The EFL writing proficiency test required the participants to complete a 120–180 word argumentative essay entitled Air Pollution within 30 minutes. Then, the essays of three groups were evaluated by two experienced EFL teachers through global scoring on a scale of 1 to 100. The inter-rater reliability of the two scorers was $\alpha { = } 0 . 9 8 4$ . Finally, the final score of each pre-test essay was the average of two scorers’ scores. Finally, we performed an ANOVA on the final scores of three groups’ English essays, and the results are shown in Table 2. Results show that there were no statistically significant differences among the three groups in terms of English writing proficiency ${ \mathit { \Delta } } ^ { \prime } F { = } 2 . 1 4 6$ , $\begin{array} { r } { p = 0 . 1 2 3 , } \end{array}$ .

In addition, we investigated EFL writers’ use of metacognitive strategies in English writing through the adjusted Metacognitive Strategies Questionnaire, which was originally developed by Lu (2006). The items in the questionnaire tapping into planning strategies involved two distinct contents: one is related to the writing task situation and the other to writers’ accumulation of language knowledge. The item ‘I set writing goals (for example, to improve my writing level and obtain writing information)’. was removed because it was concerned with writing motivation. This current study divided planning strategy into two sub-strategies: language knowledge accumulation strategies and pre-planning strategies. As a result, three kinds of metacognitive strategies were included in this current study: Planning strategies (including language knowledge accumulation strategies and pre-planning strategies), monitoring strategies (including selective attention strategies and self-monitoring strategies), and self-evaluation strategies. Consequentially, the revised Writing Metacognitive Strategy Questionnaire included 26 items: Nine items tapping into planning strategies, 11 items into monitoring strategies, and six items into self-evaluation strategies. The reliability of the questionnaire was examined by employing Cronbach’s reliability coefficient. The reliability coefficient is 0.836, which is higher than the acceptable threshold of 0.7 (Pallant, 2016), indicating that the questionnaire had good internal consistency.

# 3.2.2.  Experiment stage

The whole experiment lasted for eight weeks, during which participants completed a writing task every two weeks. The topics and requirements of the writing tasks were the same for three groups of participants, but they received different kinds of feedback where the essays might be reviewed and commented in terms of vocabulary, sentence, organization, and content, and scored on a 0–100 scale. The topics of the writing tasks were closely related to the contents of the textbooks utilized in the participants’ English course and pertaining to their life and study (see Supplementary material, Appendix for the details of the writing topics). Each group received feedback twice for each writing task through receiving different kinds of feedback.

Teacher feedback group. The participants in this group submitted a first draft to the English teacher after finishing each writing task. Then, the teacher gave specific feedback and an overall score on all the first drafts and returned them to the participants. According to the feedback given by the teacher, the participants revised their first drafts and handed them back to the teacher. Then, the English teacher gave feedback and scores on the second drafts and returned them to the participants again. The second revised drafts were submitted to the teacher for grading, and then the teacher returned them to the participants as the final drafts.

Peer feedback group. Before completing the writing task, participants in this group received peer feedback training from their English teachers to understand and familiarise themselves with the function, content, and method of peer feedback. Then they were given a model of peer feedback from which they could learn how to offer feedback on their peers’ essays. Every two participants were randomly paired to form a peer feedback group. After finishing each writing task, the participants exchanged their first draft in the feedback group, gave feedback on their partners’ first drafts, and then returned them to their partners. According to the feedback given by their peers, the participants revised their own first drafts and exchanged them in the feedback group again. Then, the peer gave feedback on their partner’s second draft and returned it to their partners for revision again. Finally, the revised second drafts were exchanged within each peer group for scoring and then participants kept them as the final drafts.

Automated feedback group. The participants in this group were trained by their English teachers to help them understand and be familiar with the functions, contents and methods of automated feedback. The automatic scoring system utilized in this current study came from www. pigai.org, which was one of the online English writing platforms in China. On this writing platform, the participants finished their writing tasks. After finishing each writing task, they submitted their first drafts to the automatic scoring system for feedback. According to the feedback given by the system, the participants revised their first drafts and then submitted them to the system for feedback again. Then, the participants revised their second drafts based on the automated feedback and submitted them to the system again for the final scores.

# 3.2.3.  Post-test phase

At the end of the experiment, we conducted a post-test on three groups of participants. The post-test involved the same content as the pre-test: the test for English writing proficiency and the survey for the use of metacognitive strategies in English writing. Similarly, the test and the survey were administered at an interval of one week. In order to avoid the effect of practice, the topic of Water Pollution was adopted in the English writing test at the post-test stage. Then, the participants’ essays were evaluated in the same way by the same scorers in the pre-test stage. Similarly, participants’ use of the metacognitive strategies in English writing was examined again for comparative analysis.

# 3.3.  Analysis

In order to ensure that there were no significant differences among the three groups in terms of English proficiency and English writing, we collected their scores of CET-4 and English writing. We then performed an analysis of variance (ANOVA) on them with the help of SPSS 20. In order to explore whether three kinds of feedback have different effects on writing metacognitive strategies, we conducted repeated-measures ANOVA on the use of metacognitive strategies in English writing before and after the experiment. In addition, we conducted paired $t { \cdot }$ -tests to investigate whether there is a statistically significant difference in metacognitive strategy use from pre- to post-test within each treatment group and calculate the corresponding effect size.

# 4.  Results

# 4.1.  The influence of different kinds of feedback on planning strategies

Before performing the repeated-measures ANOVA, we examined the homogeneity of variance of planning strategies before and after the experiment, and the results were shown in Table 3.

It can be seen from Table 3 that the homogeneity of variance of language knowledge accumulation meets the assumption for ANOVA, that is, $\boldsymbol { p }$ language knowledge accumulation $= 0 . 1 4 9 > 0 . 0 5$ . Although the p-value of pre-planning is smaller than the critical point of 0.05, the deviation is not too large. The homogeneity test of variance also basically meets the assumption of ANOVA.

We conducted repeated-measures ANOVA on planning strategy, and the results are shown in Table 4.

Table 4 shows that the p-values of language knowledge accumulation and pre-planning are greater than the critical value of 0.05, indicating that there is no significant difference in the influence of the three feedback forms on the two planning strategies. In order to further explore the impact of these feedback forms on the planning strategy, we conducted a post hoc LSD analysis and profile analysis. The results of the LSD analysis are shown in Table 5.

Table 3. R esults of homogeneity of variance of planning strategies.   

<html><body><table><tr><td></td><td>Box&#x27;s M</td><td>F</td><td>DF1</td><td>DF2</td><td>Sig.</td></tr><tr><td>LKA strategies</td><td>9.774</td><td>1.579</td><td>6</td><td>203770.014</td><td>0.149</td></tr><tr><td>Pre-planning strategies</td><td>16.183</td><td>2.614</td><td>6</td><td>203770.014</td><td>0.016</td></tr></table></body></html>

\* DF $=$ degree of freedom, LKA $=$ language knowledge accumulation.

Table 4. R esults of repeated measures ANO VA on planning strategies.   

<html><body><table><tr><td></td><td>III sum of square.</td><td>DF</td><td>SD</td><td>F</td><td>Sig.</td><td>n2</td></tr><tr><td>LKA strategies</td><td>124.689</td><td>2</td><td>62.345</td><td>2.562</td><td>0.083</td><td>0.061</td></tr><tr><td>Pre-planning strategies</td><td>6.083</td><td>2</td><td>3.042</td><td>0.234</td><td>0.792</td><td>0.005</td></tr></table></body></html>

$\mathsf { ^ { * } D F = }$ degree of freedom; $\mathsf { S D } =$ standard deviation, LKA $=$ language knowledge accumulation.

Table 5. R esults of LSD analysis of planning strategies.   

<html><body><table><tr><td></td><td>(l)group</td><td>(J)group</td><td>DM</td><td>SE</td><td>Sig.</td></tr><tr><td rowspan="2">LKA strategies</td><td>TFG</td><td>PFG</td><td>1.68</td><td>0.852</td><td>0.052</td></tr><tr><td>TFG</td><td>AFG</td><td>0.03</td><td>0.874</td><td>0.976</td></tr><tr><td rowspan="3">Pre-planning strategies</td><td>PFG</td><td>AFG</td><td>1.71.</td><td>0.880</td><td>0.056</td></tr><tr><td>TFG</td><td>PFG</td><td>0.41</td><td>0.623</td><td>0.509</td></tr><tr><td>TFG</td><td>AFG</td><td>0.30</td><td>0.639</td><td>0.641</td></tr><tr><td></td><td>PFG</td><td>AFG</td><td>0.11</td><td>0.643</td><td>0.860</td></tr></table></body></html>

\* LKA $=$ language knowledge accumulation; TFG $=$ teacher feedback group; $\mathsf { P F G = }$ peer feedback group; $\mathsf { A F G = }$ automated feedback group; MD $=$ mean difference; $\mathsf { S E } =$ standard error.

![](img/cebc7a45584a0e94a9c080dfe6593c9a34e500b62193d75ea2b8a14970122231.jpg)

![](img/760638fedfa762f4fe7bb9757a357e9ad22b5d2a1eaf4d45bdfada2982d6e65f.jpg)  
Figure 1. T he profile of language knowledge accumulation strategies.   
Figure 2. T he profile of pre-planning strategies.

As can be seen from Table 5, there is no significant difference between the three feedback forms in terms of the effects on such planning strategies as language knowledge accumulation strategies and pre-planning strategies.

The results of profile analysis of language knowledge accumulation strategies and pre-planning strategies are shown in Figures 1 and 2, respectively. They show that teacher feedback, peer feedback and automated feedback have different promotive effects on the use of language knowledge accumulation strategies and pre-planning strategies, respectively. Specifically, teacher feedback and peer feedback show almost the same strong promotive effect on the use of the aforementioned planning strategies, whereas automated feedback has relatively weak promotive effects on those planning strategies.

As can be seen from Table 6, the paired $t$ -test shows that (1) teacher feedback had a significant impact on language knowledge accumulation strategies $\mathit { \Omega } \left( \mathrm { t } = - 2 . 1 2 4 \right.$ , $p = 0 . 0 4 1 < 0 . 0 5 )$ , while peer feedback and automated feedback have no significant impact $( t _ { \mathrm { p e e r ~ f e e d b a c k } } ~ = ~ - 0 . 1 9$ $\boldsymbol { P } _ { \mathrm { p e e r } }$ feedback $= \ 0 . 8 5 > 0 . 0 5 .$ , tautomated feedback $= \ - 1 . 4 0 { \dot { 1 } }$ , $\boldsymbol { p }$ automated feedback= $0 . 1 7 2 > 0 . 0 5 )$ ; (2) Teacher feedback, peer feedback and automated feedback had no significant effect on pre planning strategies (tteacher feedback $= - 1 . 5 5 9$ , pteacher feedback $= \ 0 . 1 2 9 > 0 . 0 5$ , $t _ { \mathrm { p e e r ~ f e e d b a c k } } = - 1 . 9 0 1$ , $\boldsymbol { p }$ peer feedback $= \ 0 . 0 6 6 > 0 . 0 5$ , tautomated feedback $= - 0 . 3 7 7$ , $\boldsymbol { p }$ automated feedback $= \ 0 . 7 0 9 > 0 . 0 5 )$ . The effect sizes in Table 6 show that (1) teacher feedback had the greatest impact on language knowledge accumulation strategies ( $d = 0 . 7 3 0 4 ^ { \cdot }$ ), followed by automated feedback ( $\mathit { \check { d } } = 0 . 5 1 1 8 $ , and peer feedback has the weakest impact $\stackrel { \prime } { d } = 0 . 0 6 6 4 )$ ; (2) Peer feedback had the greatest impact on pre-planning strategies $\prime d = 0 . 6 6 3 5$ ), followed by teacher feedback $\mathit { \Delta } d = 0 . 5 3 4 5 $ ), and automated feedback has the weakest impact $\prime d = 0 . 1 3 7 7 .$ ).

Table 6. T he paired t-test result of planning strategies.   

<html><body><table><tr><td>Group</td><td>Planning strategies</td><td>test</td><td>N</td><td>Mean</td><td>SD</td><td>t-value</td><td>Sig.</td><td>Effect size</td></tr><tr><td rowspan="4">Teacher feedback</td><td>Language knowledge Pre-test</td><td></td><td>34</td><td>14.71</td><td>4.38</td><td>-2.124</td><td>0.041</td><td>0.7304</td></tr><tr><td>accumulation</td><td>Post-test</td><td>34</td><td>16.15</td><td>4.12</td><td></td><td></td><td></td></tr><tr><td>Preplanning</td><td>Pre-test</td><td>34</td><td>11.18</td><td>3.424</td><td>-1.559</td><td>0.129</td><td>0.5345</td></tr><tr><td>Peer feedback Language knowledge Pre-test</td><td>Post-test</td><td>34</td><td>12.06</td><td>3.472</td><td></td><td></td><td></td></tr><tr><td rowspan="4"></td><td></td><td></td><td>33</td><td>17.06</td><td>4.168</td><td>0.19</td><td>0.85</td><td>0.0664</td></tr><tr><td>accumulation</td><td>Post-test</td><td>33</td><td>17.15</td><td>3.346</td><td></td><td></td><td></td></tr><tr><td> Preplanning</td><td>Pre-test</td><td>33</td><td>11.67</td><td>2.521</td><td>-1.901</td><td>0.066</td><td>0.6635</td></tr><tr><td></td><td>Post-test</td><td>33</td><td>12.39</td><td>2.263</td><td></td><td></td><td></td></tr><tr><td rowspan="4">Automated feedback</td><td>Language knowledge Pre-test</td><td></td><td>30</td><td>14.93</td><td>3.300</td><td>1.401</td><td>0.172</td><td>0.5118</td></tr><tr><td>accumulation Preplanning</td><td>Post-test</td><td>30</td><td>15.87</td><td>3.875</td><td></td><td></td><td></td></tr><tr><td></td><td>Pre-test</td><td>30</td><td>11.83</td><td>2.151</td><td>0.377</td><td>0.709</td><td>0.1377</td></tr><tr><td></td><td>Post-test</td><td>30</td><td>12.00</td><td>3.096</td><td></td><td></td><td></td></tr></table></body></html>

Table 7. R esults of the test of homogeneity of variance of monitoring strategies.   

<html><body><table><tr><td></td><td>Box&#x27;s M</td><td>F</td><td>DF1</td><td>DF2</td><td>Sig.</td></tr><tr><td>Selective attention</td><td>7.775</td><td>1.256</td><td>6</td><td>203770.014</td><td>0.274</td></tr><tr><td>Self-monitoring</td><td>3.985</td><td>0.644</td><td>6</td><td>203770.014</td><td>0.695</td></tr></table></body></html>

\* DF $=$ degree of freedom.

# 4.2.  Influence of different kinds of feedback on monitoring strategies

Before performing the repeated-measures ANOVA, we examined the homogeneity of variance of monitoring strategies before and after the experiment, and the results were shown in Table 7.

It can be seen from Table 7 that the homogeneity test of variance of selective attention strategies and self-monitoring strategies satisfies the assumption of ANOVA $( p$ selective attention $= \ 0 . 2 7 4 > 0 . 0 5$ and $\boldsymbol { p }$ self-monitoring $= \ 0 . 6 9 5 > 0 . 0 5$ ).

Similarly, we performed repeated-measures ANOVA on monitoring strategies before and after the experiment, and the results were shown in Table 8.

It can be seen from Table 8 that the $\boldsymbol { p }$ -value of selective attention strategies is less than the critical value of 0.05, which means that there are statistically significant differences among teacher feedback, peer feedback, and automated feedback in terms of the influence on the use of selective attention strategies in EFL writing. In comparison, the $\boldsymbol { p }$ -value of self-monitoring is greater than the critical value of 0.05, indicating that there are no statistically significant differences among those feedback in terms of the influence on the use of self-monitoring strategies.

In order to further explore the impact of these kinds of feedback on the use of monitoring strategies, we conducted a post hoc LSD analysis and a profile analysis. The results of the LSD analysis of monitoring are shown in Table 9.

Table 9 demonstrates that there are statistically significant differences between the teacher feedback and the peer feedback $\scriptstyle ( p = 0 . 0 1 2 )$ in terms of the influence on the use of selective attention strategies, whereas there are no statistically significant differences between other comparison pairs (the teacher feedback vs the automated feedback; the peer feedback vs the automated feedback) in terms of the effects on the use of selective attention strategies. On the other hand, there are no statistically significant differences among teacher feedback, peer feedback, and automated feedback regarding the influence on the use of self-monitoring strategies.

Table 8. R esults of repeated-measures ANO VA of monitoring strategies.   

<html><body><table><tr><td></td><td>III sum of square</td><td>DF</td><td>SD</td><td>F</td><td>Sig</td><td>n?</td></tr><tr><td>Selective attention</td><td>144.188</td><td>2</td><td>72.094</td><td>3.322</td><td>0.040</td><td>0.066</td></tr><tr><td>Self-monitoring</td><td>133.155</td><td>2</td><td>66.577</td><td>1.906</td><td>0.154</td><td>0.039</td></tr></table></body></html>

\* DF $=$ degree of freedom; $\mathsf { S D } =$ standard deviation.

Table 9. R esults of LSD analysis of monitoring.   

<html><body><table><tr><td></td><td>(l)group</td><td>(J)group</td><td>DM</td><td>SE</td><td>Sig.</td></tr><tr><td rowspan="3">Selective attention strategies</td><td>TFG</td><td>PFG</td><td>2.06*</td><td>0.805</td><td>0.012</td></tr><tr><td>TFG</td><td>AFG</td><td>0.80</td><td>0.825</td><td>0.332</td></tr><tr><td>PFG</td><td>AFG</td><td>1.26</td><td>0.831</td><td>0.134</td></tr><tr><td rowspan="3">Self-monitoring strategies</td><td>TFG</td><td>PFG</td><td>1.97</td><td>1.021</td><td>0.056</td></tr><tr><td>TFG</td><td>AFG</td><td>0.72</td><td>1.047</td><td>0.495</td></tr><tr><td>PFG</td><td>AFG</td><td>1.26</td><td>1.054</td><td>0.236</td></tr></table></body></html>

\* TFG $=$ teacher feedback group; PFG $=$ peer feedback group; AFG $=$ automated feedback group.

The results of the profile analysis of selective attention strategies and self-monitoring strategies are shown in Figures 3 and 4, respectively. They demonstrate that teacher feedback, peer feedback, and automated feedback have different effects on the use of monitoring strategies. To be specific, teacher feedback and peer feedback might facilitate EFL students to use selective attention strategies and self-monitoring strategies to different degrees, respectively. On the contrary, automated feedback might hinder EFL students’ use of selective attention strategies and self-monitoring strategies.

![](img/76e7ac00350b9f75e71bd0ba50418c85c202f642ca79c565598017ac4f460521.jpg)  
Figure 3. T he profile of selective attention strategies.

![](img/394c62e59b82f3daafdb12aa3ff3cf656077fa8c6cc389bcdf3a2dac84221b0c.jpg)  
Figure 4. T he profile of self-monitoring strategies.

Table 10. T he paired $t$ -test results of monitoring strategies.   

<html><body><table><tr><td>Group</td><td>Monitoring strategies</td><td>test</td><td>N</td><td>Mean</td><td>SD</td><td>t-value</td><td>Sig.</td><td>Effect size</td></tr><tr><td rowspan="4">Teacher feedback</td><td>Selective attention</td><td>pre-test</td><td>34</td><td>15.59</td><td>4.031</td><td>1.174</td><td>0.249</td><td>0.4027</td></tr><tr><td></td><td>Post-test</td><td>34</td><td>16.47</td><td>3.918</td><td></td><td></td><td></td></tr><tr><td>Self-monitoring</td><td>pre-test</td><td>34</td><td>18.18</td><td>5.102</td><td>0.973</td><td>0.338</td><td>0.3336</td></tr><tr><td></td><td>Post-test</td><td>34</td><td>19.09</td><td>5.299</td><td></td><td></td><td></td></tr><tr><td rowspan="4">Peer feedback</td><td>Selective attention</td><td>pre-test</td><td>33</td><td>17.82</td><td>3.893</td><td>0.984</td><td>0.332</td><td>0.3431</td></tr><tr><td></td><td>Post-test</td><td>33</td><td>18.36</td><td>3.471</td><td></td><td></td><td></td></tr><tr><td>Self-monitoring</td><td>pre-test</td><td>33</td><td>19.97</td><td>4.707</td><td>1.816</td><td>0.079</td><td>0.6324</td></tr><tr><td>Automated feedback Selective attention</td><td>Post-test pre-test</td><td>33 30</td><td>21.24 17.60</td><td>4.228 3.147</td><td>2.057</td><td>0.049</td><td>0.7515</td></tr><tr><td rowspan="4"></td><td></td><td>Post-test</td><td>30</td><td>16.07</td><td>4.394</td><td></td><td></td><td></td></tr><tr><td>Self-monitoring</td><td>pre-test</td><td>30</td><td>19.60</td><td>4.753</td><td>0.589</td><td>0.561</td><td>0.2148</td></tr><tr><td></td><td>Post-test</td><td>30</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table></body></html>

Table 11. R esults of variance homogeneity test of self-evaluation strategies.   

<html><body><table><tr><td></td><td>Box&#x27;s M</td><td>F</td><td>DF1</td><td>DF2</td><td>Sig.</td></tr><tr><td>Self-evaluation</td><td>8.075</td><td>1.304</td><td>6</td><td>203770.014</td><td>0.251</td></tr></table></body></html>

Table 12. R esults of repeated measures ANO VA of the use of self-evaluation.   

<html><body><table><tr><td></td><td>III sum of square</td><td>DF</td><td>MS</td><td>F</td><td>Sig.</td><td>n?</td></tr><tr><td>Self-evaluation</td><td>18.449</td><td>2</td><td>9.225</td><td>0.396</td><td>0.674</td><td>0.008</td></tr></table></body></html>

It can be found from Table 10 that the paired $t { \cdot }$ -test shows that (1) automated feedback has a significant impact on selective attention strategies $t = 2 . 0 5 7$ , $p = 0 . 0 4 9 < 0 . 0 5$ ), while teacher feedback and peer feedback have no significant impact $( t _ { \mathrm { t e a c h e r ~ f e e d b a c k } } = - 1 . 1 7 4$ , pteacher feedback $=$ $0 . 2 4 9 > 0 . 0 5$ , tautomated feedback $= - 0 . 9 8 4$ , $\boldsymbol { p }$ automated feedback $= 0 . 3 3 2 > 0 . 0 5 )$ ; (2) Teacher feedback, peer feedback and automated feedback had no significant effect on self-monitoring strategies $( \mathrm { t } _ { \mathrm { t e a c h e r ~ f e e d b a c k } } = - 0 . 9 8 4 _ { \cdot }$ pteacher feedback $= \ 0 . 3 3 8 > 0 . 0 5$ , tpeer feedback $= - 1 . 8 1 6$ , $\boldsymbol { p }$ peer feedback $= \ 0 . 0 7 9 > 0 . 0 5$ , tautomated feedback $= \ 0 . 5 8 9$ , $\boldsymbol { p }$ automated feedback $= \ 0 . 5 6 \dot { 1 } > 0 . 0 5 )$ . The effect sizes in Table 10 reveals that (1) automated feedback had the greatest impact on selective attention strategies $\scriptstyle ( d = 0 . 7 5 1 5 )$ ), followed by teacher feedback ( $\dot { \boldsymbol { d } } = 0 . 4 0 2 7 \mathrm { , }$ , and peer feedback had the weakest impact $\left( d = 0 . 3 4 3 1 \right)$ ); (2) Peer feedback demonstrated the greatest impact on self-monitoring strategies $\left( d = 0 . 6 3 2 4 \right)$ , followed by teacher feedback ( $\left. d = 0 . 3 3 3 6 \right)$ , and automated feedback held the weakest impact $\stackrel { \prime } { d } = 0 . 2 1 4 8 \rangle$ .

# 4.3.  The influence of different kinds of feedback on self-evaluation strategies

In the same vein, we tested the homogeneity of variance of self-evaluation strategies before and after the experiment, the results of which are shown in Table 11.

It can be seen from Table 11 that the homogeneity test of variance of self-evaluation strategies meets the assumption of ANOVA (pself-evaluation $= \ 0 . 2 5 1 > 0 . 0 5$ ).

Similarly, we performed repeated-measures ANOVA of self-evaluation strategies before and after the experiment, whose results were shown in Table 12.

It can be seen from Table 12 that the $\boldsymbol { p }$ -value of self-evaluation strategies is greater than the critical value of 0.05, indicating that there are no statistically significant differences among teacher feedback, peer feedback, and automated feedback regarding the influence on the use of self-evaluation strategies in EFL writing.

In order to further explore the impact of these kinds of feedback on the use of self-evaluation strategies, we conducted a post hoc LSD analysis and a profile analysis. The results of the LSD analysis were shown in Table 13.

It can be seen from Table 13 that there are no statistically significant differences among teacher feedback, peer feedback, and automated in terms of the impact on the use of self-evaluation strategies in EFL writing.

The results of the profile analysis of self-evaluation strategies are presented in Figure 5. They reveal that teacher feedback, peer feedback and automated feedback have different promotive effects on the use of self-evaluation strategies in EFL writing. Specifically speaking, teacher feedback and automated feedback show almost the same strong promotive effect on the use of self-evaluation strategies, whereas peer feedback has the relatively weak promotive effects on those self-evaluation strategies.

Table 13. R esults of LSD analysis of self-evaluation strategies.   

<html><body><table><tr><td></td><td>(l)group</td><td>(J)group</td><td>MD</td><td>SE</td><td>Sig.</td></tr><tr><td rowspan="2">Self-evaluation</td><td>TFG</td><td>PFG</td><td>0.35</td><td>0.834</td><td>0.671</td></tr><tr><td>TFG</td><td>AFG</td><td>0.76</td><td>0.855</td><td>0.376</td></tr><tr><td></td><td>PFG</td><td>AFG</td><td>0.41</td><td>0.878</td><td>0.638</td></tr></table></body></html>

\* TFG $=$ teacher feedback group; $\mathsf { P F G = }$ peer feedback group; $\mathsf { A F G = }$ automated feedback group; $\mathsf { M D = }$ mean difference; $\mathsf { S E = }$ standard error.

![](img/c5d8498ac5e682801dd7cd3fe10b9a5ba155df8c6f9bd088f83f75c7a18db597.jpg)  
Estimated marginal mean for self-evaluation   
Figure 5. T he profile of self-evaluation strategies.

Table 14. T he paired $t$ -test result of self-evaluation strategies.   

<html><body><table><tr><td>Group</td><td>test</td><td>N</td><td>Mean</td><td>SD</td><td>t-value</td><td>Sig.</td><td>Effect size</td></tr><tr><td rowspan="2">Teacher feedback</td><td>Pre-test</td><td>34</td><td>13.03</td><td>3.786</td><td>2.647</td><td>0.012</td><td>0.9136</td></tr><tr><td>Post-test</td><td>34</td><td>14.56</td><td>4.244</td><td></td><td></td><td></td></tr><tr><td rowspan="2">Peer feedback</td><td>Pre-test</td><td>33</td><td>12.91</td><td>4.072</td><td>1.449</td><td>0.157</td><td>0.3431</td></tr><tr><td>Post-test</td><td>33</td><td>13.97</td><td>3.450</td><td></td><td></td><td></td></tr><tr><td rowspan="2">Automated feedback</td><td>Pre-test</td><td>30</td><td>12.37</td><td>3.690</td><td>2.672</td><td>0.012</td><td>0.9811</td></tr><tr><td>Post-test</td><td>30</td><td>13.70</td><td>3.678</td><td></td><td></td><td></td></tr></table></body></html>

As can be seen from Table 14, paired t-test shows that teacher feedback and automated feedback had a significant impact on self-evaluation strategies (tteacher feedback $= - 2 . 6 4 7$ , pteacher feedback $= \ 0 . 0 1 2 < 0 . 0 5$ , tautomated feedback $= - 2 . 6 7 2$ , $\boldsymbol { p }$ automated feedback $= 0 . 0 1 2 < 0 . 0 5 )$ , while peer feedback had no significant impact $\mathit { \check { t } } = - 1 . 4 4 9$ , $p { = } 0 . 1 5 7 { > } 0 . 0 5 )$ . The effect sizes in Table 14 shows that automated feedback has the greatest effect on self-evaluation strategies ( $\stackrel { \cdot } { d } = 0 . 9 8 1 1 \dot { 1 }$ ), followed by teacher feedback ( $\left. d = 0 . 9 1 3 6 \right)$ ), and peer feedback has the weakest impact $\acute { \iota } d = 0 . 3 4 3 1 \dot { \iota }$ ). Therefore, it can be concluded that automated feedback had the greatest impact on self-evaluation strategies, followed by teacher feedback, and peer feedback had the weakest impact.

# 5.  Discussion

# 5.1.  The impact of different kinds of feedback on planning strategies

The first research question mainly explored the effects of teacher feedback, peer feedback and automated feedback on planning strategies. In this study, planning included two different dimensions: language knowledge accumulation strategies and pre-planning strategies. Repeated measures ANOVA showed that there were no significant differences among teacher feedback, peer feedback and automated feedback in terms of the effect on the use of language knowledge accumulation strategies and pre-planning strategies in EFL writing. This finding was also confirmed by the post hoc LSD analysis. The profile analysis demonstrated that teacher feedback, peer feedback, and automated feedback had different promotive effects on the use of planning strategies in EFL writing. Paired $t { \cdot }$ -tests and corresponding effect sizes revealed that (1) teacher feedback had the greatest impact on language knowledge accumulation strategies, followed by automated feedback and peer feedback has the weakest impact; (2) Peer feedback had the greatest impact on pre-planning strategies, followed by teacher feedback, and automated feedback has the weakest impact.

Many scholars have pointed out that the importance of planning and goals to learners and learning is self-evident (for example, O’Malley & Chamot, 1990). Goals can help students make clear the direction of their efforts, and plans can help them achieve their goals efficiently. In English writing, goals included task goals and learning goals. Learning goals are closely related to language knowledge accumulation strategies, while task goals are closely relevant to pre-planning strategies. The three kinds of feedback can facilitate students to realize the gaps in their language knowledge and proficiency and therefore promote the use of language knowledge accumulation strategies.

It has been suggested that pre-planning can improve English writing achievement and its different dimensions, such as vocabulary, syntax, and cohesion (Ellis & Yuan, 2004; Johnson et  al., 2012; Li, 2008; Ong & Zhang, 2010, 2013). However, Zhang (2018) found that training cannot effectively promote the acquisition of planning strategies. Peer feedback is more conducive to students’ communication and learning from others than teacher feedback and automated feedback. It is easier for peers to share successful experiences, such as the use of pre-planning strategies. Therefore, peer feedback can promote the use of pre-planning strategies.

# 5.2.  The influence of different kinds of feedback on monitoring strategies

The second research question focused on the influence of teacher feedback, peer feedback and automated feedback on the use of monitoring strategies in EFL writing. In this study, monitoring strategies mainly include two different dimensions: selective attention strategies and self-monitoring strategies. Repeated measures ANOVA showed that there were statistically significant differences among teacher feedback, peer feedback, and automated feedback in terms of the effects on the use of selective attention strategies in EFL writing, but there was statistically no significant differences in terms of the effects on the use of self-monitoring strategies. Moreover, the profile analysis demonstrated that teacher feedback and peer feedback could promote the use of monitoring strategies while automated feedback can hinder the use of monitoring strategies. Paired $t \cdot$ -tests and corresponding effect sizes suggested that automated feedback had the greatest impact on selective attention strategies, followed by teacher feedback, and peer feedback had the weakest impact; (2) Peer feedback demonstrated the greatest impact on self-monitoring strategies, followed by teacher feedback, and automated feedback held the weakest impact.

Feedback influences learning through the help of monitoring (Butler & Winne, 1995). Monitoring might enable students to pay attention to the difference between their existing linguistic knowledge and writing skills and the required linguistic knowledge and writing skills to accomplish their expected goal. The purpose of feedback is to eliminate and bridge these differences (Hattie & Timperley, 2007). Therefore, monitoring is closely related to feedback. Selective attention mainly refers to students’ attention and monitoring of vocabulary, punctuation, grammar and other surface features in English writing, while self-monitoring mainly refers to students’ attention and monitoring of content, theme, structure, coherence, argumentation and other deep factors and cognitive activities. Compared with teacher feedback and peer feedback, automated feedback could provide students with more efficient, comprehensive and timely feedback on surface linguistic features, which can be obtained anytime and anywhere. Although automated feedback can improve students’ lexical use in their English essays (Zhou, 2013), students might give up using selective attention and self-monitoring because of their natural inertia and dependence on automated feedback. That was confirmed by the changes of selective attention strategy and self-monitoring strategy shown by the profile analysis (see Figures 3 and 4). Research has found that peer feedback might share the following characteristics: Focusing more on content (Yang, 2006) and being specific; teacher feedback covers vocabulary, grammar, structure and content, and offers general comments on students’ English essays. Students who participated in the peer feedback group can easily understand the students’ cognitive activities by reviewing the students’ English exercises and inducing their reflection on their own essays and cognitive activities, thus promoting the use of selective attention and self-monitoring.

# 5.3.  The influence of different kinds of feedback on self-evaluation strategies

The third research question mainly explored the influence of teacher feedback, peer feedback and automated feedback on the use of self-evaluation strategies in EFL writing. Repeated-measures ANOVA showed that there were no significant differences among teacher feedback, peer feedback and automated feedback in terms of the effects on the use of self-evaluation strategies. Besides, the profile analysis indicated that teacher feedback, peer feedback, and automated feedback could promote EFL students’ use of self-evaluation in their English writing. Paired $t { \cdot }$ -tests and corresponding effect sizes showed that automated feedback had the greatest impact on self-evaluation strategies, followed by teacher feedback, and peer feedback had the weakest impact.

Self-evaluation strategies are considered to be the core of metacognitive strategies (Wen, 1996). In this study, self-evaluation strategies cover the evaluation of writing content, text structure, writing methods, the realization of writing goals, the gains and losses of writing, among other things. In order to evaluate these contents mentioned above, students first need to establish a series of standards. The establishment and formation of these standards provide the basis for students’ employment of self-evaluation strategies in their English writing. As mentioned above, automated feedback was generated by automated writing evaluation tools, which might include rich English monolingual and bilingual corpus resources and authoritative digital dictionaries and provide immediate, comprehensive, and detailed feedback on students’ English essays. Therefore, automated feedback could be more easily accepted by students and can continuously strengthen the standard for students’ self-evaluation. Besides, research demonstrated that teacher feedback might be EFL student writers’ favourite when offered several choices for feedback (Yang, 2006). Because teacher feedback is authoritative, objective and accurate, it might facilitate students to form the standards for self-evaluation. In addition, although peer feedback had low recognition and acceptance among EFL students (Zhou, 2013), it might help them form an English learning community (Cai, 2011), which might facilitate the communication among EFL students that could help them adjust their self-evaluation criteria and make them more consistent with the standards set by the English writing. Thus, teacher feedback, peer feedback, and automated feedback could improve the use of self-evaluation strategies.

# 6.  Conclusion

This study explored the effects of different kinds of feedback on the use of metacognitive strategies in EFL writing. Through repeated-measures ANOVA analysis of metacognitive strategies before and after receiving teacher feedback, peer feedback and automated feedback, it was found that there were statistically significant differences among teacher feedback, peer feedback, and automated feedback in terms of the effects on the use of selective attention strategies, whereas there were no statistically significant differences among those aforementioned feedbacks in terms of the effects on the use of such metacognitive strategies as language knowledge accumulation strategies, pre-planning strategies, self-monitoring strategies and self-evaluation strategies. In addition, this study also found that teacher feedback, peer feedback, and automated feedback could promote the use of planning strategies and self-evaluation strategies. Although the automated feedback had a hindrance effect on the use of monitoring strategies, teacher feedback and peer feedback still had a promoting effect on the use of monitoring strategies. Therefore, the current study might offer tentative empirical evidence to support the facilitative effect of feedback on metacognition and self-regulation more broadly.

This study has some implications for EFL writing teaching in a context like China. First of all, English writing teachers should realize that not all kinds of feedback (including teacher feedback, peer feedback, and automated feedback) have a promotive effect on the use of all metacognitive strategies in English writing. The current study found that different kinds of feedback had different promotive effects on the use of metacognitive strategies in English writing though the automated feedback had a hindrance effect on the use of monitoring strategies. Therefore, writing teachers should be cautious when utilizing automated feedback in their English writing instructions. Automated feedback should not serve as the single source of feedback on student’ essays. Writing teachers might try to integrate automated feedback with either teacher feedback or peer feedback. Secondly, in teaching writing , teachers should be aware of the differential effect of feedback types on subcategories of metacognitive strategies and could employ different feedbackto enhance the development of metacognitive strategies. For instance, teachers could employ teacher feedback to improve students’ use of language accumulation strategies, automated feedback to enhance their use of self-evaluation strategies.

Although there are some findings in this study, there may be some limitations due to the constraints of experimental conditions, experimental methods and available resources. First, this study only focused on the effects of feedback on the use of metacognitive strategies in an EFL writing context. Therefore, it is hoped that the follow-up research will investigate the effects of feedback on metacognitive knowledge in English writing so as to show the influence of feedback on metacognition in English writing more comprehensively and clearly. Second, the experiment lasted for only two months, which may not clearly show the effect of feedback on metacognitive strategies in English writing. Therefore, it is suggested that the follow-up study should extend the experimental time to six or twelve months.

# Disclosure statement

No potential conflict of interest was reported by the authors.

# Notes on contributors

Zhang Jianhua is a PhD student in Applied Linguistics at the School of Curriculum and Pedagogy, Faculty of Education and Social Work, The University of Auckland, New Zealand. He is a Professor of English Applied Linguistics at the School of Foreign Languages, Sichuan University of Arts and Science. He holds an MA in Foreign

Linguistics and Applied Linguistics from Xi’an International Studies University, China. His research interests lie in second language writing and second language acquisition. He has published papers in SSCI-indexed journals such as Asia Pacific Journal of Education, Journal of Quantitative Linguistics and Reading & Writing Quarterly.

Lawrence Jun Zhang, PhD, is Professor of Linguistics-in-Education and Associate Dean for the Faculty of Education and Social Work,The University of Auckland, New Zealand. His major interests and 100-plus publications are on learner metacognition, language-teacher education and L2 reading-writing development. He is Co-Chief-Editor for System and an associate editor for Frontiers in Psychology, serving as an editorial board member for Applied Linguistics Review, Australian Review of Applied Linguistics, Journal of Second Language Writing, Metacognition and Learning, Chinese Journal of Applied Linguistics and RELC Journal. He was honoured by the TESOL International Association (USA) in 2016 with the award of $^ { \mathfrak { c } } 5 0$ at 50’, acknowledging $^ { \mathfrak { c } } 5 0$ Outstanding Leaders’ and was officially installed as a newly elected member of the Board of Directors of the Association in 2017. Email: lj.zhang@auckland.ac.nz

# ORCID

Jianhua Zhang $\textcircled{1}$ http://orcid.org/0000-0002-5892-5757   
Lawrence Jun Zhang $\textcircled{1}$ http://orcid.org/0000-0003-1025-1746

# References

Anderson, N. J. (2007). Metacognition in writing: Facilitating writer awareness. In A. Stubbs & J. Chapman (Eds.), Rhetoric, uncertainty, and the university as text: How students construct the academic experience (pp. 19–43) Canadian Plains Research Center, University of Regina.   
Anderson, N. J. (2008). Metacognition and good language learners. In C. Griffiths (Ed.), Lessons from good language learners (pp. 99–109) Cambridge University Press.   
Barrot, J. S. (2021). Using automated written corrective feedback in the writing classrooms: Effects on L2 writing accuracy. Computer Assisted Language Learning, 1–24. https://doi.org/10.1080/09588221.2021.1936071   
Brown, A. L. (1987). Metacognition, executive control, self-regulation and other more mysterious mechanisms. In Weinert, F. E. & R. H. Kluwe (Eds.), Metacognition, motivation, and understanding (pp. 65–116). Lawrence Erlbaum Associates.   
Butler, D. L., & Winne, P. H. (1995). Feedback and self-regulated learning. Review of Educational Research, 65(3), 245–281. https://doi.org/10.3102/00346543065003245   
Cai, J. (2011). A contrastive study on online peer feedback and online teacher feedback of Chinese college students’ English writing. Foreign language World, 24(02), 65–72.   
Callender, A. A., Franco-Watkins, A. M., & Roberts, A. S. (2016). Improving metacognition in the classroom through instruction, training, and feedback. Metacognition and Learning, 11(2), 215–235. https://doi.org/10.1007/s11409-015-9142-6   
Cera, R., Mancini, M., & Antionietti, A. (2013). Relationships between metacognition, self-efficacy and self-regulation in learning. Journal of Educational, Cultural and Psychological Studies, 7, 115–141.   
Chamot, A. U., & Harris, V. (Eds.) (2019). Learning strategy instruction in the language classroom: Issues and Implementation. Multilingual Matters.   
Conijn, R., Martinez-Maldonado, R., Knight, S., Buckingham Shum, S., Van Waes, L., & van Zaanen, M. (2020). How to provide automated feedback on the writing process? A participatory approach to design writing analytics tools. Computer Assisted Language Learning, 1–31. https://doi.org/10.1080/09588221.2020.1839503   
Ellis, R., & Yuan, P. (2004). The effects of planning on fluency, complexity, and accuracy in second language writing. Studies in Second Language Acquisition, 26, 59–84. https://doi.org/10.1017/S0272263104261034   
Ferris, R., & Roberts, B. (2001). Error feedback in L2 writing classes: How explicit does it need to be? Journal of Second Language Writing,  10(3), 161–184. https://doi. org/10.1016/S1060-3743(01)00039-X   
Flavell, J. H. (1979). Metacognition and cognitive monitoring: A new area of cognitive-developmental inquiry. American Psychologist, 34(10), 906–911. https://doi. org/10.1037/0003-066X.34.10.906   
Harris, K. R., Santangelo, T., & Graham, S. (2010). Metacognition and strategies instruction in writing. In H. S. Waters &W. Scheneider (Eds.), Metacognition, strategy use, and instruction (pp. 226–256). The Guilford Press.   
Hattie, J., & Timperley, H. (2007). The power of feedback. Review of Educational Research, 77(1), 81–112. https://doi.org/10.3102/003465430298487   
Huang, J., & Zhang, W. (2014). The influence of multiple feedback on College Students’ English composition revision. Foreign Languages in China, 11(1), 51–56.   
Huang, Y., & Zhang, L. J. (2020). Does a process-genre approach help improve students’ argumentative writing in English as a foreign language? Findings from an intervenon study. Reading & Writing Quarterly, 36(4), 339–364. https://doi.org/10.1080/105735 69.2019.1649223   
Hyland, K., & Hyland, F. (2006). Feedback on second language students’ writing. Language Teaching, 39(2), 83–101. https://doi.org/10.1017/S0261444806003399   
Jiang, L., & Yu, S. (2020). Appropriating automated feedback in L2 writing: Experiences of Chinese EFL student writers. Computer Assisted Language Learning, 1–25. https:// doi.org/10.1080/09588221.2020.1799824   
Johnson, M. D., Mercado, L., & Acevedo, A. (2012). The effect of planning sub-processes on L2 writing fluency, grammatical complexity, and lexical complexity. Journal of Second Language Writing, 21(3), 264–282. https://doi.org/10.1016/j.jslw.2012.05.011   
Keh, C. L. (1990). Feedback in the writing process: A model and methods from implementation. ELT Journal, 44(4), 294–394. https://doi.org/10.1093/elt/44.4.294   
Li, G. (2019). Research on the influence of multiple feedback on English composition revision based on automatic evaluation system. Foreign Language Education, 40(4), 72–76.   
Li, R., Meng, Z., Tian, M., Zhang, Z., Ni, C., & Xiao, W. (2019). Examining EFL learners’ individual antecedents on the adoption of automated writing evaluation in China. Computer Assisted Language Learning, 32(7), 784–804. https://doi.org/10.108 0/09588221.2018.1540433   
Li, Z. (2008). Quantitative analysis on the effects of English Majors’ planning variables on their writing performance. Foreign Language Teaching and Research, 40(3), 178–183.   
Lu, W. (2006). Exploring the relationship between metacognitive strategies and EFL   
writing. Foreign Languages and Their Teaching, 35(9), $2 5 - 2 7 + 3 9$ .   
Miller, T. M., & Geraci, L. (2011). Training metacognition in the classroom: The influence of incentives and feedback on exam predictions. Metacognition and Learning, 6(3), 303–314. https://doi.org/10.1007/s11409-011-9083-7   
Molin, F., Haelermans, C., Cabus, S., & Groot, W. (2020). The effect of feedback on metacognition – A randomized experiment using polling technology. Computers & Education, 152, 103885. https://doi.org/10.1016/j.compedu.2020.103885   
O’Malley, M., & Chamot, U. (1990). Learning strategies in second language acquisition. Cambridge University Press.   
Ong, J., & Zhang, L. J. (2013). Effects of the manipulation of cognitive processes on EFL writers’ text quality. TESOL Quarterly, 47(2), 375–398. https://doi.org/10.1002/ tesq.55   
Ong, J., & Zhang, L. J. (2010). Effects of task complexity on the fluency and lexical complexity in EFL students’ argumentative writing. Journal of Second Language Writing, 19, 218–233. https://doi.org/10.1016/j.jslw.2010.10.003   
Pallant, J. (2016). SPSS survival manual (6th ed.). McGraw-Hill Education.   
Pintrich, P. R. (2004). A conceptual framework for assessing motivation and self-regulated learning in college students. Educational Psychology Review, 16, 385–407. https://doi. org/10.1007/s10648-004-0006-x   
Ranalli, J. (2018). Automated written corrective feedback: How well can students make use of it? Computer Assisted Language Learning, 31(7), 653–674. https://doi.org/10.1 080/09588221.2018.1428994   
Sarré, C., Grosbois, M., & Brudermann, C. (2021). Fostering accuracy in L2 writing: Impact of different types of corrective feedback in an experimental blended learning EFL course. Computer Assisted Language Learning, 34(5–6), 707–729. https://doi.org /10.1080/09588221.2019.1635164   
Schraw, G., Crippen, K. J., & Hartley, K. (2006). Promoting self-regulation in science education: Metacognition as part of a broader perspective on learning. Research in Science Education, 36, 111–139. https://doi.org/10.1007/s11165-005-3917-8   
Sun, Q. Y., Zhang, L. J., & Carter, S. (2021). Investigating students’ metacognitive experiences: Insights from the English as a foreign language learners’ writing metacognitive experiences questionnaire (EFLLWMEQ). Frontiers in Psychology, 12(744842), 1–15.   
Tian, L., & Zhou, Y. (2020). Learner engagement with automated feedback, peer feedback and teacher feedback in an online EFL writing context. System, 91, 102247. https://doi.org/10.1016/j.system.2020.102247   
Wang, Y., & Liu, Z. (2012). A study on the effects of teacher feedback on accuracy, fluency, complexity and overall quality of English writing. Foreign Language Education, 33(6), 49–53.   
Wen, Q. (1996). On English learning strategies. Shanghai Foreign Language Education Press.   
Wilson, J., & Czik, A. (2016). Automated essay evaluation software in English Language Arts language arts classrooms: Effects on teacher feedback, student motivation, and writing quality. Computers and Education, 100, 94–109. https://doi.org/10.1016/j. compedu.2016.05.004   
Wu, X. M., Dixon, H. R., & Zhang, L. J. (2021). Sustainable development of students’ learning capabilities: The case of university students’ attitudes towards teachers, peers, and themselves as oral feedback sources in learning English. Sustainability, 13(9), 5211. https://doi.org/10.3390/su13095211   
Wu, Y., & Zhang, W. (2016). Research on the influence of automatic composition evaluation system and teacher feedback on college students’ English composition revision. China Foreign Language Education, 9(1), 12–19.   
Yang, M. (2006). Teacher feedback or /and peer feedback: A comparative study in the Chinese EFL writing class. Modern Foreign Languages (Quarterly), 29(3), $2 9 3 - 3 0 1 + 3 3 0$ .   
Yang, L., Yang, M., & Zhang, Y. (2013). A comparative study of three feedback methods in English Writing Teaching in China. Foreign Language Teaching, 34(3), 63–67.   
Zimmerman, B. J. (1995). Self-regulation involves more than metacognition: A social cognitive perspective. Educational Psychologist, 30(4), 217–221. https://doi.org/10.1207/ s15326985ep3004_8   
Zimmerman, B. J. (2002). Becoming a self-regulated learner: An overview. Theory into Practice, 41, 64–70. https://doi.org/10.1207/s15430421tip4102_2   
Zhan, J., Sun, Q. Y., & Zhang, L. J. (2021). Effects of manipulating writing task complexity on EFL learners’ vocabulary and syntactic learning. Language Teaching Research, 1–22. https://doi.org/10.1177/13621688211024360   
Zhang, J. (2018). The effect of strategic planning training on cohesion in EFL learners’ essays. Reading & Writing Quarterly, 34(6), 554–567. https://doi.org/10.1080/105735 69.2018.1506371   
Zhang, D., & Zhang, L. J. (2019). Metacognition and self-regulated learning in second/ foreign language teaching. In X. A. Gao (Ed.), Second handbook of English language teaching (pp. 883–898). Cambridge, MA: Springer Nature. https://link.springer.com/ referenceworkentry/ https://doi.org/10.1007/978-3-319-58542-0_47-1   
Zhang, L. J., & Cheng, X. L. (2021). Examining the effects of comprehensive written corrective feedback on L2 EAP students’ linguistic performance: A mixed-methods study. Journal of English for Academic Purposes, 54, 101043. https://doi.org/10.1016/j. jeap.2021.101043   
Zhang, L. J., & Qin, T. L. (2018). Validating a questionnaire on EFL writers’ metacognitive awareness of writing strategies in multimedia environments. In Å. Haukås, C. Bjørke, & M. Dypedahl (Eds.), Metacognition in language learning and teaching (pp. 157–178). Routledge.   
Zhang, L. J., & Zhang, D. (2008). Metacognition, metalinguistic awareness, self-regulation and foreign language teaching. Foreign Language Education in China, 1(1), $5 5 \mathrm { - } 6 4 ~ +$ 84–85. https://doi.org/10.24285/CLER.2005.08.1.55   
Zhang, L. J., & Zhang, D. (2018). Metacognition in T ESOL: Theory and practice. In J. Liontas &amp; A. Shehadeh (Eds.), The TESOL encyclopedia of English language teaching (Vol. II, pp. 682–792). Malden, MA: Wiley. https://doi.org/10.1002/9781118784235.eelt0803   
Zhang, Z., & Hyland, K. (2018). Student engagement with teacher and automated feedback on L2 writing. Assessing Writing, 36, 90–102. https://doi.org/10.1016/j. asw.2018.02.004   
Zhou, Y. (2013). A comparative study of feedback in college English writing. Journal of Foreign Languages, 34(3), 87–96.   
Zhu, M., Liu, O. L., & Lee, H. S. (2020). The effect of automated feedback on revision behavior and learning gains in formative assessment of scientific argument writing. Computers and Education, 143, 1–15. https://doi.org/10.1016/j.compedu.2019.103668