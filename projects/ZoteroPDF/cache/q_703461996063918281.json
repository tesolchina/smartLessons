{"query": "how can teeachers enhance their AI literacy", "top_k": 5, "min_score": 0.1, "filter_pedagogical": false, "results": [{"score": 0.3883427679538727, "document": {"id": 1233, "file_path": "annotated_data/batch_001/out_3NL63DC7_Artificial_Intelligence_for_Aca.md", "filename": "out_3NL63DC7_Artificial_Intelligence_for_Aca.md", "content": "# Artificial Intelligence for Academic Purposes (AIAP): Integrating AI literacy into an EAP module\n\nThu Ngan Ngo a,b,\\*, David Hastie b\n\na University Centre for Academic English, University of Manchester, Samuel Alexander Building, Manchester M13 9PL, UK b International College Dundee, University of Dundee, 2 Airlie Place, Dundee, DD1 4HQ, UK\n\n# a r t i c l e i n f o\n\n# a b s t r a c t\n\nArticle history:\n\nKeywords:   \nAI literacy   \nEnglish for Academic Purposes (EAP)   \nHigher education   \nAI integration in education   \nInternational students\n\nWith the rise of generative AI (GenAI) tools such as ChatGPT and their growing relevance in academic contexts, the need for AI literacy has become imperative, particularly for international students in EAP programs. The study addresses the gap in practical guidance for incorporating AI literacy by developing and implementing a 10-week AI-integrated EAP module at a pathway college in Scotland based on a novel framework termed AI for Academic Purposes (AIAP). Utilising a mixed-methods approach, the research investigates the impact of this module on international students\u2019 attitudes, confidence, and purposes of using AI tools. Results of this study indicate significant improvements in students\u2019 ability to critically evaluate GenAI output, confidence in using a greater variety of AI tools, understanding of ethical AI use, and an expansion in the purposes for which students use AI tools. The integration of AI literacy with traditional EAP skills was found to meet students\u2019 academic needs effectively. This study provides a replicable model for integrating AI literacy into EAP courses, offering a holistic educational approach that aligns technological proficiency with ethical awareness.\n\n$^ { \u00a9 }$ 2024 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\n\n# 1. Introduction\n\nGenerative AI (GenAI) is a type of artificial intelligence that can create new content such as texts, images and videos. Users can input text or \u2018prompts\u2019 to GenAI tools such as ChatGPT or Microsoft Co-pilot and quickly receive an entire essay. The release of ChatGPT 3.5 in late 2022 initiated panic in higher education (HE), with several universities including Oxford and Cambridge banning ChatGPT in early 2023 and decreeing its usage to constitute academic misconduct (Chan, 2023a; Lim et al., 2023). Since this initial burst of reactionism, however, an acceptance that the use of GenAI is an inescapable reality has predominated (Alharbi, 2023; Mills et al., 2023). The release of AI assistants such as Google Duet which is embedded directly into Google Docs is a further critical development, in that we all have access to GenAI from within the spaces where we write (Liu & Bridgeman, 2023). This, along with the fact that AI literacy is regarded as a key graduate attribute due to the integration of AI into the workplace, underscores the idea that the higher education (HE) sector must continue adapting to the new era of GenAI (O\u2019Dea & O\u2019Dea, 2023; Southworth et al., 2023; Chiu, 2024). Research into students\u2019 perspectives has shown that they want universities to take the lead in this regard (Chan, 2023a; Jisc, 2024). However, there is a notable absence of concrete and practical institutional guidance and within the nascent research for practitioners on how to proceed (Barrett & Pack, 2023; Walter, 2024).\n\nThis is also an issue in English for Academic Purposes (EAP), a field where there is a clear rationale for the integration of AI literacy. EAP courses teach core academic and study skills deemed relevant to international students of all subjects and disciplines (Hyland, 2006), aiming to support these students in achieving success in English-speaking academic environments. These skills include paraphrasing, summarising, referencing and critical thinking and, by equipping students with these, EAP modules help mitigate some forms of academic dishonesty such as plagiarism (Perkins et al., 2020).\n\nThere is a significant overlap between the skills typically taught in EAP courses and the capabilities and use cases of GenAI as both involve, for instance, summarising and paraphrasing. Just as with EAP, GenAI can provide additional language support for international students whose first languages are not English (Du & Alm, 2024; Farrelly & Baker, 2023). As EAP classes typically involve teaching how to avoid academic misconduct, they can offer space to address concerns regarding AI-related misuse or \u2018AI-giarism\u2019 (Chan, 2023b) by defining and modelling parameters of appropriate use (Chami, 2023; Lim et al., 2023) and facilitating the development of this sensibility within students themselves (Chan, 2023b). Additionally, the generally smaller class sizes, closer student-teacher relationships, and focus on communication and discussion typically found in EAP contexts represent the optimal classroom environment for fostering AI literacy.\n\nFor these reasons above, it can be argued that AI literacy should be integrated into EAP modules. Previous research on EAP students\u2019 perceptions of GenAI supports this integration (Liu et al., 2024; Du & Alm, 2024; Kohnke, 2024), yet no detailed framework for doing so has been provided. To address this gap, this article develops a framework for teaching AI literacy within an EAP context \u2013 which we refer to as AI for Academic Purposes, or, AIAP. This framework was conceived in response to issues we, as EAP practitioners, were encountering on the ground, such as an increase in AI-related academic misconduct, a lack of understanding from students of how to interact with or prompt these tools effectively (Walter, 2024) and a tendency to blindly trust information output from GenAI (Ding et al., 2023). Based on this framework, we have designed a concrete AIintegrated EAP module with a carefully structured, week-by-week curriculum which not only embeds AI literacy but also aligns it with the development of critical academic skills. This can offer a practical and replicable model for EAP educators, thereby advancing the discourse on AI literacy in academia.\n\nThe research questions are as follows:\n\nRQ1. What is the impact of an AI-integrated EAP module on a) students\u2019 attitudes and perceptions of GenAI, b) students\u2019 confidence in using AI tools for academic purposes, c) the purposes for which they use these tools and d) students\u2019 confidence in ethically and appropriately using AI tools?\n\nRQ2. How does this module meet the needs of students?\n\nThis article begins with a literature review looking at the conceptualisation of AI literacy, as well as key findings and trends regarding students\u2019 attitudes towards GenAI, confidence in utilising it academically, and the range of academic purposes it is being used for. Subsequently, the article illustrates the AIAP framework and how an AI-integrated EAP module was designed based on it. After that, the methodology of this research will be given before the results are analysed and discussed.\n\n# 2. Literature review\n\n# 2.1. AI literacy\n\nScholarship and commentary are now clear on the importance of AI literacy owing to it quickly becoming a key graduate attribute (World Economic Forum, 2023), as well as the wide range of educational benefits and affordances AI can offer to students generally, and international students in particular (Du & Alm, 2024; Farrelly & Baker, 2023). For Long and Magerko (2020), AI literacy is a set of competencies that enables an individual to critically evaluate, communicate, and collaborate with AI tools. This has proved a usefully broad definition despite the rapid advances made in the capability of GenAI tools and large language models (LLMs), and the exponentially growing range of different tools and applications now available. As an important adjunct, scholars have also pointed out the importance of addressing broader societal and ethical considerations of AI (Chiu, 2024; Hornberger et al., 2023).\n\nApproaches to fostering these sets of competencies tend to revolve around a few key ideas: student-centered learning or flipped classroom approaches (Kong et al., 2022), open and transparent communication practices, and \u2018hands-on\u2019 experience using relevant AI tools (Chan, 2023a; Pretorius, 2023). The duration and frequency of AI literacy programs or interventions are inconclusive, with some scholars and institutions advocating an integrated approach \u2018across the curriculum\u2019 (Southworth et al., 2023) and others maintaining that even a single AI literacy workshop can significantly improve student confidence and understanding of these tools (Sullivan et al., 2024).\n\nRegarding the specific content of these modules or workshops, Walter (2024, p.22) argues that AI literacy courses ought to include \u2018essential AI concepts, ethical considerations, and practical applications\u2019 at a minimum. These prerequisites aside, it is also important to note that different AI user groups have different AI literacy requirements, and that it is therefore important to tailor the pedagogical approach and components of AI literacy to the context (Pinski & Benlian, 2024). An exploration of the pedagogy and components of AI literacy for general academic purposes (AIAP) is therefore an important undertaking.\n\n# 2.2. Students\u2019 attitudes and perceptions of GenAI\n\nAs with other tools and technologies, students\u2019 attitudes and perceptions towards GenAI can substantially impact their willingness to utilise it (Chan & Hu, 2023). Several studies have found that university students have broadly positive attitudes and perceptions towards GenAI predicated on knowledge of the many educational affordances GenAI can offer (Chan & Zhou, 2023; Firat, 2023), and this base positivity appears to be common across different cultures and backgrounds (Yusuf et al., 2024). Despite the apparent generalisability of these sentiments, cross-disciplinary research cautions that attitudes and perceptions towards AI are not uniform across subjects, with humanities and arts students less positive than peers in STEM and related disciplines (Irfan et al., 2023; Kelly et al., 2023).\n\nStudent attitudes towards the accuracy and reliability of GenAI appear nuanced and considered \u2013 they are found to be sceptical about the extent to which GenAI can be utilised for grading and feedback because of its tendency to make mistakes or exhibit biases (Chan & Hu, 2023; Jisc, 2024). They are also becoming increasingly aware of the broader ethical issues surrounding this technology. Students specifically highlight a lack of institutional AI literacy support and guidelines (Jisc, 2024). This may be particularly relevant within EAP contexts; research from Australia cautions that international students may have less familiarity, awareness, and experience of GenAI than their domestic peers, highlighting the urgency of integrating AI literacy within EAP curricula to ensure a base equality of opportunity (Kelly et al., 2023).\n\n# 2.3. Students\u2019 confidence in using AI tools\n\nAlthough little specific literature about student confidence in utilising AI for educational purposes exists, confidence itself reliably predicts achievement across different knowledge domains and subjects (Kleitman & Stankov, 2007; Stankov et al., 2012). Increasing student confidence in utilising GenAI is thus an important consideration regarding student equity (Chiu, 2024; Ng et al., 2021). Kong et al.\u2019s (2021; 2022) research shows that AI literacy courses can empower students to work with AI.\n\nConfidence in utilising GenAI ethically and appropriately warrants further consideration. Plagiarism detection software is unreliable at best and potentially biased against students whose first language is not English (Liang et al., 2023), and with the ever-advancing sophistication of LLMs, it is becoming increasingly difficult to differentiate between human and GenAI output (Waltzer et al., 2023). Studies have suggested that more experience in hands-on use of GenAI leads to an increase in confidence in its ethical and appropriate utilisation (Kelly et al., 2023), and that fostering ethical awareness can positively impact student use of GenAI (Zhu et al., 2024). Other studies, however, point to considerable variance in students\u2019 understanding of inappropriate or unethical use of GenAI (Chan, 2023b), again highlighting the need both for clear institutional guidance and policy, as well as explicit pedagogical focus on this area (Chiu, 2024; Kong et al., 2024; Walter, 2024).\n\n# 2.4. Students\u2019 purposes of using AI\n\nGenerative AI has a wide range of applications within HE, and as noted, facilitates foundational academic research and writing practices, such as brainstorming and gathering sources and ideas (Chan & Zhou, 2023; Chiu, 2024; Jisc, 2024). It can also act as an additional tutor for students (Ifelebuegu et al., 2023; Ou et al., 2024) by providing personalised feedback (Chan & Zhou, 2023; Farrelly & Baker, 2023; Jisc, 2024), proofreading and editing (Farrelly & Baker, 2023), and fostering critical thinking (Allen & Kendeou, 2024; Walter, 2024). This range of academic applications is largely borne out by recent research on student purposes of GenAI utilisation. Personalised and immediate learning support, and ideation, brainstorming, and writing support are highlighted by students as particularly beneficial uses (Chan & Hu, 2023; Jisc, 2024). In addition, students are utilising AI in a pastoral as well as academic sense, with personal, motivational, and emotional support uses related to loneliness or mental health emerging as novel themes of usage (Jisc, 2024).\n\n# 3. Module design and AI literacy integration\n\n# 3.1. Context\n\nOur 10-week AI-integrated English for Academic Purposes 2 (EAP2) module is taught in the second term of the International Stage One (also known as International Foundation Year 1) at a pathway college in Scotland. The college provides international students who do not fulfil the admission requirements of a Scottish university with alternative paths to obtaining university degrees. To progress to university, all international students in the International Stage One are required to take three EAP modules (EAP1, EAP2 and EAP3), each of which lasts 10 weeks (five hours per week divided into two classes), to develop English language and academic skills, alongside modules related to their pathway subjects.\n\nEAP2 follows up on EAP1 in which students are taught foundational academic skills such as critical reading, discussion, paragraph writing and avoiding plagiarism by paraphrasing and referencing, alongside academic vocabulary and style. EAP2 focuses on extended writing with pre-determined assessments and intended learning outcomes.\n\nIn 2023, we revamped EAP2 by integrating AI literacy into the teaching of academic skills and language based on what we term the AIAP framework which includes five components 1) Vocabulary, jargon, concepts, 2) Inner workings, 3) Prompt engineering, 4) Specific suggested tools $\\mathcal { E }$ applications and 5) Ethics & appropriacy. How these components are integrated into the module will be explained in the following sections. This new version of EAP2 has been implemented since the beginning of 2024 and the module in this research was taught between January and March 2024.\n\n# 3.2. Course structure\n\nThe original curriculum followed the process-based approach (Hyland, 2003) with content on pre-writing, writing and post-writing stages. We decided to keep this approach as this is aligned with the pre-determined assessments which include a draft, a final piece of extended writing, followed by a presentation of this piece\u2019s content. Scholars have also suggested the process-based approach to assessments to mitigate AI-related misconduct (Yeo, 2023).\n\nThe first three weeks of the course focused on the pre-writing tasks such as analysing task instructions, searching for and evaluating sources and preparing an outline. Lessons in weeks 4\u20137 shifted the focus to skills, language and genre awareness needed for writing extended academic texts with content on paragraph writing, reporting language, academic style, cohesion and introduction and conclusion writing. The first lesson in Week 8 was about revision and proofreading while the rest of the course was lessons on presentation skills. AI literacy was integrated into all stages of the writing process, giving instruction on how to use AI effectively in each stage for writing support.\n\nCourse outline and sample materials are provided in Appendices A and B.\n\n# 3.3. AIAP integration\n\n# 3.3.1. Vocabulary, jargon, concepts\n\nThe foundation of any literacy is predicated on lexical, theoretical, and conceptual understanding (Egli et al., 1995) and AI literacy is no different. The few, limited efforts to promote AI literacy for \u2018citizens\u2019 often begin in the same manner by fostering knowledge of core concepts and terminologies such as machine learning and large language models (LLMs) (Kong et al., 2021, 2022). In our module, these vocabulary items (e.g. machine learning, GenAI, LLMs) were taught in the first lesson to enable students to confidently engage in AI-related texts and discussions throughout the course.\n\n# 3.3.2. Inner workings\n\nUnderstanding how GenAI tools function as well as their capabilities and limitations can help students use these tools responsibly and effectively (Chiu, 2024; Southworth et al., 2023). In our module, the inner workings of GenAI were explained in the first lesson by a video from Wharton School (2023) Practical AI for Instructors and Students. This video was chosen because it caters for those in academic contexts and it provides a foundational understanding of GenAI\u2019s inner workings with a simple explanation of how LLMs are trained and function, along with their key capabilities and limitations. This understanding can enable students to engage more deeply with later tasks in the course such as prompt engineering, critical evaluation of AI outputs, and understanding the ethical implications of AI use in academic contexts. We decided against exploring the complex inner workings of AI such as the detailed mechanics of machine learning algorithms or the architecture of large language models as these can distract from the focus of the course which is developing students\u2019 academic language and skills.\n\n# 3.3.3. Prompt engineering\n\nPrompt engineering is a fundamental skill for eliciting useful responses from GenAI (Ding et al., 2023; Walter, 2024). Proficiency in prompt engineering is intrinsically linked to developing criticality as crafting effective prompts requires critical and creative thinking (Walter, 2024). This skill can also result in a greater understanding of the capabilities and limitations of LLMs (Hillier, 2023) and enhances student self-efficacy by giving them the tools to leverage these technologies for their academic pursuits (Giray, 2023). Due to the importance of prompt engineering, one full lesson and a half of another on the module were dedicated to this. Also, this content was included in the first two weeks of our module for students to be able to leverage GenAI tools for more complex tasks later in the course such as using AI for writing revision. The framework of prompt engineering taught in this module is adapted from the Birss\u2019s (2023) CREATE framework (see more details in Appendix B) because the mnemonic is easy to remember and also includes the requirements of an effective prompt such as specificity, detail, relevance and iteration (Mollick, 2023).\n\n# 3.3.4. Specific suggested tools $\\mathcal { E }$ applications\n\nGiven the enormous proliferation of AI tools now available, it is unsurprising that students are looking for institutional recommendations and guidance as to which tools are most useful and trusted (Chan, 2023a). At the same time, Yusuf et al.\u2019s (2024) large-scale multi-cultural research found that ChatGPT is the most widely utilised tool among both university lecturers and students. Taking these, plus the module\u2019s focus on extended writing, into consideration, we decided to introduce ChatGPT, along with Elicit, Consensus and Perplexity in our module. Elicit and Consensus, both AI-powered search engines, were introduced in the Week 3 lesson on the pre-writing process, along with Perplexity, a GenAI tool that can gather information from the internet and unlike ChatGPT, can incorporate source links directly into its answers. These three tools can support students in searching for relevant academic sources.\n\nBoth ChatGPT and Perplexity are LLMs that have a wider range of applications. Some applications which are the most useful for students were introduced throughout the course, including ideation, language support, exam revision aid (Weeks 2 & 3), reference list correction (Week 4) and personalised feedback on writing (Week 8) (see Appendix B).\n\nFollowing Lim et al.\u2019s (2023) caution against making AI tools \u2018central\u2019 to the curriculum, with the focus instead on discussing and evaluating the pros and cons of different tools, when introducing these tools, our teachers encouraged students to compare how Elicit and Consensus work and compare the output of ChatGPT and Perplexity. In addition, several GenAI output evaluation activities were included in the module to promote students\u2019 criticality and raise awareness of AI-generated content\u2019s problems, as suggested by Ding et al. (2023), Farrelly and Baker (2023) and Walter (2024). For example, in a lesson in Week 4, students were tasked with evaluating and comparing four paraphrases by Quillbot, an AI-powered paraphrasing tool (Appendix B). Subsequently, they had a discussion on problems with this kind of tool and how to use (or not use) it. As Chami (2023) states, practitioners\u2019 modelling and students\u2019 evaluation of AI tools can contribute to developing student familiarity and knowledge of a wider range of useful tools.\n\n# 3.3.5. Ethics $\\mathcal { E }$ appropriacy\n\nResearch has found that students struggle with the distinction between using AI as an aid for academic writing and using it in ways that constitute academic misconduct (Chan, 2023b). Thus, there should be a focus on explicit teaching of appropriate use of AI (Chan, 2023a; Chan & Hu, 2023). Meanwhile, whereas universities might have their own GenAI policies, students might not read or understand these documents (Chiu, 2024) or, in other cases, find them lacking and ambiguous (Jisc, 2024). As the line between appropriate or acceptable use of GenAI and overreliance is necessarily something of a grey area, pedagogical approaches to developing this sensibility are thus best based on discussion, openness and trust. Rowland (2023) recommends providing sample scenarios of AI use for students to analyse and discuss and we have found this approach works extremely well. This discussion activity (Appendix B) was included in Weeks 3 and 4 of the module when students had gained a fundamental grasp of generative AI\u2019s strengths and weaknesses but had not yet begun writing. This timing was intentional, aiming to establish a clear understanding of proper AI utilisation and discourage academic dishonesty before the writing process started. After these discussions, students were asked to make their own lists of appropriate and inappropriate AI use before comparing these lists with the university\u2019s GenAI policy. This aimed at creating an educational setting where AI was used thoughtfully and ethically, in accordance with the university\u2019s established policies.\n\nTo further promote transparency and academic integrity, also in Week 3, our teachers modelled how to fill in a declaration of AI use, which could teach students to take responsibility for their work and their use of AI tools. The process of declaring AI use could also encourage students to reflect on how they engaged with AI. This reflection practice was consolidated in Week 6 when students worked in groups to write an essay using only GenAI tools and then engaged in a structured reflection task (Appendix B). This can encourage students to critically assess their interactions with AI and further develop an understanding of ethical and appropriate AI use.\n\n# 4. Methodology\n\nThe research employed an explanatory sequential mixed-methods design (Creswell & Clark, 2017). It began with a premodule survey to gauge students\u2019 baseline knowledge and attitudes towards AI. Students then took the EAP2 module in which AI literacy was explicitly taught and integrated with the teaching of academic language and skills. After the module, a post-module survey was conducted to identify changes in students\u2019 attitudes and confidence. Semi-structured interviews were then conducted with a selected group of students to explore these changes in more depth. The combination of quantitative survey data and qualitative interview data provided a comprehensive understanding of the module\u2019s impact on students.\n\n# 4.1. Participants\n\n39 international students from 22 nationalities and various pathways were enrolled in the module and they completed both pre- and post-module surveys. Eight students volunteered for the interviews. Table 1 provides background information on these eight students whose names have been pseudonymised.\n\nTable 1 Interviewees\u2019 profiles.   \n\n<html><body><table><tr><td>Pseudonym</td><td>Age</td><td>Nationality</td><td>Pathway</td></tr><tr><td> Jordan</td><td>19</td><td>American</td><td>Life Sciences</td></tr><tr><td>Ngoc</td><td>18</td><td>Vietnamese</td><td>Art &amp; Design</td></tr><tr><td>Christine</td><td>19</td><td>Kenyan</td><td>Nursing</td></tr><tr><td>Jiwon</td><td>19</td><td>South Korean</td><td>Nursing</td></tr><tr><td>Emily</td><td>20</td><td>Indonesian</td><td>Life Sciences</td></tr><tr><td> Megan</td><td>18</td><td>Nigerian</td><td>Nursing</td></tr><tr><td>Patience</td><td>20</td><td>Nigerian</td><td>Nursing</td></tr><tr><td>Daryna</td><td>18</td><td> Ukrainian</td><td>Social Sciences</td></tr></table></body></html>\n\n# 4.2. Pre- and post-module surveys\n\nThe pre-module survey consisted of four sections. The first employed a 5-point Likert scale to survey students\u2019 overall confidence in using AI and confidence in using specific AI tools, including ChatGPT, Elicit, Consensus and Perplexity, which would be introduced and modelled, and Quillbot, whose output would be evaluated in the module. The second section examined students\u2019 purposes of using AI. Respondents were asked to choose from a list of purposes. Optional write-ins were given in these two sections. The third section investigated students\u2019 perceptions, focusing on their perception of GenAI\u2019s usefulness, accuracy, reliability and unbiasedness, while the fourth explored students\u2019 confidence in ethical and appropriate AI use, both using a 5-point Likert scale.\n\nIn the post-module survey, the same questions were used to identify changes among students. Three open-ended questions were added at the end to gather student feedback on the module.\n\n# 4.3. Interviews\n\nSemi-structured interviews were conducted in English with eight participants after the module. Each interview lasted approximately $2 0 ~ \\mathrm { { m i n } }$ . Interviewees were asked about whether there had been any changes in their perceptions of AI, their abilities to use AI and their views on using AI appropriately throughout the academic term. They were asked to elaborate on their answers and explain their survey responses. Subsequently, interviews were transcribed and pseudonymised.\n\n# 4.4. Data analysis\n\nRegarding quantitative data, to identify the impact of the module, we compared the pre- and post-module responses to questions about students\u2019 confidence and perception of GenAI. Due to the non-normal distribution of the data (Shapiro\u2013Wilk results were all lower than 0.05), we employed the Wilcoxon signed-rank test, a non-parametric alternative that does not assume normality. The effect size was calculated if the test showed statistically significant differences and was interpreted as follows: small effect: $\\Gamma = 0 . 1 0$ to 0.29; medium effect: $\\Gamma = 0 . 3 0$ to 0.49; large effect: $\\Gamma = 0 . 5 0$ to 1.0 (Pallant, 2010). For data on students\u2019 purposes of using AI, since we used a checkbox question, the McNemar test was used to compare paired nominal data.\n\nQualitative data from interviews and open-ended survey question responses were analysed thematically. It has been recommended that multiple forms of qualitative data should be collected for thematic analysis instead of relying solely on a single source (Creswell & Poth, 2018). Following the steps of Braun and Clarke\u2019s (2006) thematic analysis, we (1) read and reread the data from open-ended survey question responses and interview transcripts to become intimately familiar with their content; (2) generated initial codes based on words and phrases that were often mentioned in both sources of data; (3) grouped codes into potential themes that were relevant to the research questions; (4) reviewed the themes using Braun and Clarke\u2019s questions (2012, p. 65); (5) defined the themes and established the relationships between them.\n\n# 5. Results\n\n# 5.1. Quantitative results\n\n# 5.1.1. Perceptions of GenAI\n\nTable 2 shows that before the module, students were mostly ambivalent about the accuracy, reliability and objectivity of GenAI (all Ms were approximately 3) but they were positive about its usefulness $\\mathbf { M } = 3 . 8 2$ ). After the module, there was a decrease in students\u2019 perception of GenAI\u2019s as unbiased (median decreased from 3.00 to 2.00), with the Wilcoxon signed-rank test confirming that this change was statistically significant $\\textstyle \\langle Z = - 2 . 1 3 8$ , $\\mathbf { p } = 0 . 0 3 3$ ) with a medium effect size $\\mathbf { \\check { r } } = 0 . 3 4 2 $ . For accuracy $Z = - 1 . 5 5 1$ , $\\mathsf { p } = 0 . 1 2 1$ ), reliability $( Z = - 1 . 7 3 8$ , $\\mathbf { p } = 0 . 0 8 2 \\mathrm { \\rangle }$ , and usefulness $\\langle Z = - 1 . 5 1 0$ , $\\mathsf { p } = 0 . 1 3 1$ ), there were no statistically significant changes. This shows that the module significantly impacted students\u2019 perceptions of GenAI\u2019s unbiasedness, suggesting they viewed GenAI as more biased post-module. Perceptions of GenAI\u2019s accuracy, reliability, and usefulness, however, showed non-significant changes.\n\nTable 2 Descriptive statistics for students\u2019 perceptions of GenAI.   \n\n<html><body><table><tr><td></td><td colspan=\"6\">Mean (pre-module) Mean (post-module) Median (pre-module) Median (post-module) SD (pre-module) SD (post-module)</td></tr><tr><td>Accuracy of GenAI</td><td>3.03</td><td>2.74</td><td>3.00</td><td>3.00</td><td>0.707</td><td>0.818</td></tr><tr><td>Reliability of GenAI</td><td>2.97</td><td>2.67</td><td>3.00</td><td>3.00</td><td>0.843</td><td>0.701</td></tr><tr><td>Unbiasedness of GenAI 2.77</td><td></td><td>2.33</td><td>3.00</td><td>2.00</td><td>0.777</td><td>1.034</td></tr><tr><td>Usefulness of GenAI</td><td>3.82</td><td>4.08</td><td>4.00</td><td>4.00</td><td>0.721</td><td>0.807</td></tr></table></body></html>\n\nTable 3 Descriptive statistics for students\u2019 confidence in using AI tools.   \n\n<html><body><table><tr><td>Students&#x27; confidence in using AI tools</td><td>Mean (pre- module)</td><td>Mean (post- module)</td><td>Median (pre- module)</td><td>Median (post- module)</td><td>SD (pre- module)</td><td>SD (post- module)</td></tr><tr><td>Overall confidence</td><td>3.05</td><td>3.92</td><td>3.00</td><td>4.00</td><td>1.075</td><td>0.739</td></tr><tr><td>ChatGPT</td><td>2.97</td><td>3.92</td><td>3.00</td><td>4.00</td><td>0.873</td><td>0.807</td></tr><tr><td>Quillbot</td><td>1.95</td><td>2.87</td><td>2.00</td><td>3.00</td><td>1.099</td><td>1.105</td></tr><tr><td>Consensus</td><td>1.15</td><td>2.85</td><td>1.00</td><td>3.00</td><td>1.099</td><td>1.226</td></tr><tr><td>Elicit</td><td>1.10</td><td>3.41</td><td>1.00</td><td>3.00</td><td>0.502</td><td>1.208</td></tr><tr><td> Perplexity</td><td>1.10</td><td>3.13</td><td>1.00</td><td>3.00</td><td>0.307</td><td>1.151</td></tr></table></body></html>\n\n# 5.1.2. Confidence in using AI tools for academic purposes\n\nTable 3 shows that before the module, students were moderately confident in using AI in general $\\mathbf { M } = 3 . 0 5$ . Besides ChatGPT, students were not at all confident with the other tools discussed in the module $( \\mathbf { M } < 2 )$ . After the module, the overall confidence, as well as confidence in using various AI tools introduced in the module, increased, with medians increasing to 3.00 or 4.00. Results from the Wilcoxon signed-rank test showed that these increases were statistically significant. The Zvalues, p-values and effect sizes were as follows: overall confidence $( Z = - 3 . 8 8 8$ , $\\mathbf { p } < 0 . 0 0 1$ , $\\Gamma = - 0 . 6 2 3$ ), ChatGPT $\\mathbf { \\zeta } Z = - 3 . 9 5 7 ,$ , $\\mathsf { p } < 0 . 0 0 1$ , $\\Gamma = - 0 . 6 3 4 )$ , Quillbot $( Z = - 3 . 3 1 8$ , $\\mathsf { p } < 0 . 0 0 1$ , $\\boldsymbol { \\mathrm { r } } = - 0 . 5 3 1$ ), Consensus $\\langle Z = - 4 . 9 0 9$ , $\\mathsf { p } < 0 . 0 0 1$ , $\\mathbf { r } = - 0 . 7 8 6 )$ , Elicit $Z = - 5 . 2 2 6$ , $\\mathsf { p } < 0 . 0 0 1$ , $\\mathbf { r } = - 0 . 8 3 7 ,$ ), and Perplexity $Z = - 5 . 1 3 7 ,$ , $\\mathsf { p } < 0 . 0 0 1$ , $\\mathbf { r } = - 0 . 8 2 3 ,$ . These large effect sizes $( \\Gamma > 0 . 5 )$ indicate substantial improvements in students\u2019 confidence levels, with the largest gains seen for Elicit and Perplexity. This indicates the module\u2019s effectiveness in enhancing students\u2019 confidence in utilising these tools.\n\n# 5.1.3. Purposes of using GenAI\n\nThe McNemar test revealed that the module significantly increased the range of purposes for which students utilised GenAI. Specifically, there were significant increases in the use of AI for brainstorming ideas $\\mathbf { \\Phi } ( \\mathbf { p } < 0 . 0 0 1 $ , writing essays $\\begin{array} { r } { ( { \\bf p } = { \\bf 0 } . 0 2 1 \\mathrm { \\Omega } , } \\end{array}$ ), searching for sources $\\mathbf { \\tilde { p } } < 0 . 0 0 1 $ ), checking grammar and spelling mistakes $\\mathbf { \\tilde { p } } = 0 . 0 0 3 )$ , and revising for exams $\\mathbf { \\bar { p } } = 0 . 0 4 9 ^ { \\cdot }$ ). However, there were no statistically significant changes in the use of AI tools for other listed purposes whose pvalues were above the 0.05 threshold.\n\nIn addition, Figure 1 shows that before the module, students used AI tools primarily for proofreading $( 4 8 . 8 ~ \\% )$ , brainstorming ideas $( 3 6 . 6 ~ \\% )$ , looking for information about a topic $( 3 6 . 6 ~ \\% )$ , paraphrasing $( 3 6 . 6 ~ \\% )$ and searching for sources $( 1 9 . 5 ~ \\% )$ . Figure 2 shows that after the module the most common uses were brainstorming and proofreading (each $8 7 . 2 \\%$ , followed by searching for sources $( 6 4 . 1 ~ \\% )$ , looking for information about a topic $( 5 9 \\% )$ and paraphrasing or summarising $( 5 6 . 4 \\% )$ .\n\n# 5.1.4. Confidence in ethically and appropriately using AI tools\n\nTable 4 shows that the module increased students\u2019 confidence in using AI ethically and appropriately, as well as their confidence in their ability to distinguish between appropriate and inappropriate AI use. Results from the Wilcoxon signedrank test showed that these increases were statistically significant. For confidence in using AI ethically and appropriately $( Z = - 3 . 2 7 1$ , $\\mathbf { p } = 0 . 0 0 1$ ), the effect size was large $\\mathbf { \\check { r } } = - 0 . 5 2 4 )$ , with the mean increasing from 3.38 $\\mathrm { S D } = 1 . 1 3 8 $ ) pre-module to 4.15 $\\mathrm { S D } = 0 . 7 7 9 ,$ post-module. For confidence in distinguishing between appropriate and inappropriate AI use $( Z = - 2 . 6 7 7 ,$ , $\\mathbf { p } { = } 0 . 0 0 7 \\mathrm { ; }$ , the effect size was medium $\\mathbf { \\tilde { r } } = - 0 . 4 2 9 )$ , with the mean confidence increasing from 3.67 $\\mathrm { S D } = 1 . 0 0 9 ,$ pre-module to 4.21 $\\mathrm { S D } = 0 . 8 6 4 \\mathrm { , }$ post-module. These results indicate that the module effectively enhanced students\u2019 confidence in both of these areas, with particularly strong gains in confidence in ethical AI usage.\n\n# 5.2. Qualitative results\n\n# 5.2.1. Perceptions and attitudes\n\nWe found that after the module, students became more critical of AI. For example, Jiwon said: \u201cBefore I came to university [.] I almost just totally believed AI because I thought it\u2019s accurate and correct; now I feel I can control AI to get the correct information\u201d.\n\nInterestingly, several students were scared of using AI for fear of academic misconduct prior to taking the module, saying that they were \u201cterrified of AI\u201d (Emily) and \u201cthought using AI was a crime\u201d (Megan). Jiwon explained: \u201cI was afraid to use it because [.] if I asked to AI something about information and then use that information in my writing, [.] university will notice me and I will be fail\u201d. Moreover, students were actively discouraged from using AI, with Jordan saying: \u201cin my high school, they were like: \u201cyour universities aren\u2019t going to let you use AI in any way\u201d\u201d.\n\nStudents stated that the fear of using AI was replaced by understanding and acceptance after the module. For instance, Ngoc said: \u201cbefore I was able to [.] interact with AI [.] there is quite a stigma with using AI and research because you can come across as not having integrity and plagiarism [.] after that I don\u2019t have the stigma anymore. I understand that this can be used in a positive way in a legal way and it\u2019s not always that if you use AI you are not being a good person, you\u2019re plagiarising and you don\u2019t have integrity\u201d.\n\n![](img/6ef5deed8024a0b0c922e81431d930b0b5960b028978971f63ac5ee1a2ba5c4e.jpg)  \nFigure 1. Students\u2019 pre-module purposes of using GenAI.\n\n![](img/ffe6fb499c4c52456d2cc9bc3661da16006098d64943aec613ce1d293a8b492a.jpg)  \nFigure 2. Students\u2019 post-module purposes of using GenAI.\n\nTable 4 Descriptive statistics for students\u2019 confidence in ethically and appropriately using AI tools.   \n\n<html><body><table><tr><td></td><td>Mean (pre- module)</td><td>Mean (post- module)</td><td>Median (pre- module)</td><td>Median (post- module)</td><td>SD (pre- module)</td><td>SD (post- module)</td></tr><tr><td>Confidence in using AI ethically and appropriately</td><td>3.38</td><td>4.15</td><td>4.00</td><td>4.00</td><td>1.138</td><td>0.779</td></tr><tr><td>Confidence in distinguishing between appropriate and inappropriate AI use</td><td>3.67</td><td>4.21</td><td>4.00</td><td>4.00</td><td>1.009</td><td>0.864</td></tr></table></body></html>\n\n# 5.2.2. Confidence in using AI tools for academic purposes\n\nSeveral students mentioned that they gained confidence in using AI after the module. For example, Daryna said \u201cas a new person in AI, I can say that it is a huge progress from nothing like 0 till now.\u201d. Students also appreciated the teaching of various AI tools in the module. Patience, for example, stated: \u201cCompared to last term, I didn\u2019t know about Elicit [.] Consensus [.] the way I can use ChatGPT to correct grammatical errors and give outlines [.] So I\u2019m very, very happy\u201d.\n\nAdditionally, students reported appreciation for prompt engineering instructions, with six open-ended responses saying that this was the most useful aspect of the module. Christine elaborated on this saying: \u201cCREATE (prompting framework) is really easy to use\u201d. Students\u2019 confidence in prompt engineering is demonstrated in Emily\u2019s comment: \u201cRather than giving short sentences to ChatGPT to help answer my questions or help me, I\u2019ve now know how to make a prompt more useful\u201d.\n\n# 5.2.3. Purposes of using AI\n\nStudents mentioned that in the module they learned several new use cases of AI such as \u201cask it to give you math problems and correct you if you\u2019re wrong; having a conversation with it in a different language and asking you to correct you if you were wrong\u201d (Jordan) and \u201csummarise the key points of a long article\u201d (Christine). Several said that they use AI for language support. For example, Daryna said: \u201cas English is not my first language and I have a lot of mistakes, I just (ask AI) \u201cCan you check it please? Can you advise me how to write this more formal?\u201d. Interestingly, several students mentioned using AI for independent learning. Christine, for example, used it to revise for her psychology exam by asking it to \u201ccreate some review questions with the correct answers\u201d while Emily said she \u201cpop it (her work) into AI for feedback\u201d.\n\n# 5.2.4. Confidence in ethically and appropriately using AI tools\n\nStudents reported an improvement in confidence in using AI ethically and appropriately. Patience, for example, said: \u201cI\u2019m more aware of the misuse of AI and what not to do and what to do\u201d. Jordan attributed this change to the pedagogical approach of how \u201c(teachers) showed us some appropriate uses and inappropriate uses of AI (through sample scenarios). So now it\u2019s more easy to tell\u201d. This teaching was also considered the most important aspect of the module by several students (open-ended responses e.g. how to use AI tools appropriately and can still help us with our studies; the ethical ways of using AI in university).\n\nIt is important to note that although the module only covered AI use for general academic purposes, some students developed their personal subject-specific framework of ethics and appropriacy. Ngoc, an art student, said that she avoided using AI image generators because \u201cI do not want it to affect like my ability to perform art [.] I try to keep technology as a tool to enhance my art, not using it to create art.\u201d\n\n# 5.2.5. AI-integrated EAP module and students\u2019 needs\n\nThere was a consensus among students that the module could support them in achieving their academic goals. On the one hand, they highlighted the significance of AI literacy instructions. For example, some responses to the question about the most important aspect of the module are \u201cthe appropriate use of AI tools that can aid with research and grammatical skills\u201d and \u201chow to use correctly the AI for courseworks and presentation\u201d. On the other hand, students recognised the importance of foundational academic skills and language. Patience, for instance, said: \u201cthere\u2019s a topic about how to compose yourself during a presentation, how your presentation should be. That has really helped a lot.\u201d Jiwon even associated her improvement in academic performance with the combination of AI literacy and academic skills instructions, saying that \u201c20 to $30 \\%$ (of my improvement) is (due to) AI, to be honest, because without AI I spend too much time to find sources, and then about $80 \\%$ is because of the teachers \u2013 if I don\u2019t know the structure of essay \u2013 even if I have correct sources I cannot make the essay\u201d.\n\n# 6. Discussion\n\nRQ1a addresses the impact of our AI-integrated EAP module on students\u2019 perceptions of GenAI. The results reveal that students became notably more critical of GenAI\u2019s unbiasedness after the module. This critical evaluation of GenAI might have developed from several classroom activities where students practised evaluating GenAI outputs. This finding provides empirical evidence for Ding et al.\u2019s (2023), Farrelly and Baker\u2019s (2023) and Walter\u2019s (2024) suggestion that the integration of AI literacy into education should include activities which require students to analyse and assess GenAI output to foster critical thinking skills. Without this explicit instruction, students tend to blindly trust GenAI output (Ding et al., 2023).\n\nHowever, the results also demonstrate stable perceptions of GenAI\u2019s accuracy and reliability among students. This could imply that students have become more competent at identifying and correcting inaccuracies and biases themselves. Jiwon\u2019s statement about controlling GenAI to acquire the correct information supports this idea, showing that students became more empowered and skilled in using AI, which does not necessarily translate to a changed perception in the survey metrics.\n\nOne unanticipated finding is that while students generally perceived GenAI as a useful tool, they were afraid of using it before the module due to concerns over unethical use. This fear might be a consequence of the universities\u2019 initial ban and lack of guidance on GenAI use (Barrett & Pack, 2023; Chan, 2023a; Lim et al., 2023). The lack of a sector-wide cohesive approach to the use of GenAI might have additionally confused students. This is illustrated by Jordan\u2019s comment that their high school teachers told students they would not be allowed to use AI at university. The solution to these problems, we argue, is fostering a positive learning environment where AI use is embraced under clear guidelines. This is evidenced by Ngoc\u2019s shift from scepticism to understanding after our module.\n\nRQ1b concerns the impact of our module on students\u2019 confidence in using AI tools for academic purposes. Our study has found that students gained significant overall confidence, which is consistent with previous studies on the influence of nonspecialised AI literacy courses (Kong et al., 2021, 2022). Regarding specific tools, before the module, ChatGPT was the most utilised while others were mostly new to students. This is similar to Yusuf et al.\u2019s (2024) survey results which point to ChatGPT\u2019s popularity in university settings. After ChatGPT, Consensus, Elicit, and Perplexity were introduced and modelled, students gained significant confidence in using these tools. Students\u2019 confidence in Quillbot - whose output was evaluated in the module (see Appendix B for example materials) - increased significantly as well. The fact that students expanded their range of AI tools utilised highlights the importance of explicit teaching of AI literacy. With thousands of AI tools freely available online, students need guidance on tools which are most relevant to their needs (Chan, 2023a).\n\nAn additional finding regarding RQ1b is students\u2019 confidence in prompt engineering which was considered as the result of explicit instructions and activities regarding this component. This underscores the impact of teaching prompt engineering, providing empirical support for calls for this type of instruction in the literature (Ding et al., 2023; Walter, 2024). Without this knowledge, students might receive generalised responses from AI (Walter, 2024) which are likely to be unhelpful.\n\nRQ1c focuses on the impact of our module on the purposes for which students use AI tools. The results indicate that before the module, students mostly used AI tools for proofreading, brainstorming ideas, looking for information about a topic and paraphrasing. The results also show that the module had a significant impact on expanding the purposes for which students use AI tools, particularly for brainstorming, writing essays, searching for sources, proofreading and revising for exams. These changes suggest that the module successfully broadened students\u2019 awareness and practical application of AI tools for academic purposes. The purpose of using AI for \u2018writing essays\u2019 should not be immediately interpreted as academic misconduct. Instead, it can reflect the use of AI as a tool to improve the quality of essay writing through suggestions and corrections, which aligns with the qualitative data.\n\nAnother important finding is that after the module, students started to utilise AI tools to support personalised learning needs, particularly for non-native English speakers to seek language support. Students like Daryna, who used AI to check and improve her English writing, exemplify how the module facilitated the use of AI as a tool for international students to overcome language barriers. Personalised and immediate learning support is also the main reason why students use AI in Chan and Hu\u2019s (2023) study. Our finding suggests that AI literacy instructions can encourage students to leverage AI tools autonomously and effectively. This further underscores the importance of integrating AI literacy into education, as suggested by several scholars such as Southworth et al. (2023) and Yeo (2023).\n\nRQ1d examines the module\u2019s impact on students\u2019 confidence in using GenAI ethically and appropriately. The results demonstrate strong gains in confidence in ethical AI usage and students attributed this improvement to explicit instructions on what constitutes appropriate and inappropriate AI use. This indicates that students need and appreciate these instructions to make informed decisions on how to use GenAI themselves. This finding confirms the validity of the calls for training on ethical and appropriate use of AI in the literature (Chan, 2023a; Chan & Hu, 2023), with teachers showing students how to use AI ethically and appropriately (Barrett & Pack, 2023; Yeo, 2023). In addition, the influence of teaching AI literacy on students\u2019 ethical considerations and decision-making processes can be seen in Ngoc\u2019s conscious decision to avoid AI image generators to preserve her artistic abilities. This personal ethical framework shows a critical reflection on the importance of guarding against the loss of human agency while the value of AI as a collaborative tool is still acknowledged.\n\nRQ2 investigates how the module meets students\u2019 needs. Students\u2019 narratives highlight the importance of the module in not only introducing ethical use of AI tools to support their academic work but also addressing their needs for academic skills and language. Jiwon\u2019s comment on how both AI literacy and foundational academic skills contributed to her academic improvement shows the synergy between these two components in meeting students\u2019 academic needs. All these findings imply that the integration of AI literacy into an EAP module can create a holistic educational approach that can address students\u2019 academic needs, enhance their performances and prepare them for an AI-enabled world.\n\n# 7. Conclusion\n\nThis study has explored the integration of AI literacy into an English for Academic Purposes (EAP) module through the development and implementation of the AI for Academic Purposes (AIAP) framework. The results indicate that embedding AI literacy within an EAP curriculum significantly enhances students\u2019 confidence in using AI tools, broadens the range of academic applications for which these tools are utilised, and deepens their understanding of ethical considerations surrounding AI use. Importantly, students also developed a more critical perspective on the biases and limitations of generative AI, which is crucial in fostering a responsible and informed approach to technology in academic settings.\n\nOur AI-integrated EAP curricular design based on the AIAP framework offers a practical and replicable model for educators aiming to integrate AI literacy into their courses, aligning the development of foundational academic skills with the competencies required to navigate an AI-driven world. This research is a stepping stone towards developing best practices for incorporating foundation AI literacy in educational settings, ensuring students are not only technologically proficient but also ethically informed.\n\nSeveral limitations to this study need to be acknowledged. First, the sample size is small due to the low number of students at our institution. Second, the study focuses on undergraduate students in an International Foundation Year at a pathway college in Scotland, meaning the findings might only be partly generalisable to other educational contexts or student populations. Third, the use of pre- and post-module surveys involves self-reported data, which can be subject to biases. Students might overestimate their understanding or capabilities in using AI tools. They might also try to please their instructors by providing positive feedback. Without triangulation with student writing, the actual depth of AI integration and its effectiveness in enhancing academic performance or ethical understanding might be difficult to quantify with precision. Fourth, with three different instructors teaching the module, there could be variations in the delivery, emphasis, and pedagogical approaches used, which can influence the results of the research. Finally, as AI technology evolves rapidly, students\u2019 attitudes and competencies will change quickly. The next cohort of students taking this module might have a different attitude, along with better baseline knowledge and understanding of appropriacy. This means that the research findings might become outdated quickly.\n\nFuture research should consider including more participants with a more diverse range of subjects, educational levels, institutions, and geographical locations. Besides self-reported surveys and interviews, incorporating more objective measures of students\u2019 AI proficiency and understanding of ethics and appropriacy, such as independent evaluations of students\u2019 written work, could provide a more accurate picture of the effectiveness of the AI literacy integration.\n\n# Funding\n\nThis research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.\n\n# Declaration of competing interest\n\nWe have nothing to declare.\n\n# CRediT authorship contribution statement\n\nThu Ngan Ngo: Writing \u2013 review & editing, Writing \u2013 original draft, Visualization, Methodology, Investigation, Formal analysis, Data curation, Conceptualization. David Hastie: Writing \u2013 review & editing, Writing \u2013 original draft, Investigation, Formal analysis, Data curation, Conceptualization.\n\n# Declaration of Generative AI and AI-assisted technologies in the writing process\n\nDuring the preparation of this work the authors used ChatGPT, Grammarly, Elicit, and Consensus in order to receive feedback on drafts, to find relevant literature, and to review the final manuscript for missing references. After using this tool/ service, the authors reviewed and edited the content as needed and take full responsibility for the content of the published article.\n\n# Declaration of competing interest\n\nWe have nothing to declare.\n\n# Acknowledgement\n\nThe authors wish to acknowledge the encouragement and support from colleagues and students at International College Dundee, and the considered feedback from those who had to suffer through earlier drafts of this manuscript, in particular Guilherme Moreira Fians, Xuan Minh Ngo and Tuan Bui.\n\n# Appendix A. Course outline\n\n<html><body><table><tr><td>Week</td><td>Lesson aims Activities</td><td>Assessments</td><td>AIAP components 1 - Vocabulary, jargon, concepts 2 - Inner workings 3 - Prompt engineering 4 - Specific suggested tools &amp; applications 5 - Ethics &amp; appropriacy</td></tr><tr><td>1</td><td>1.1 Introduction to EAP2 and AI - To understand the module&#x27;s overall con- tent and assessment plan - To be introduced to basic concepts related</td><td>- Read and discuss the module guide - Discuss existing knowledge of AI - Watch videos about ML and LLMs (inner workings,</td><td>1, 2, 5</td></tr><tr><td>1.2 Prompt engineering - To revise Al vocabulary</td><td> to AI and relevant vocabulary</td><td>capabilities and limitations) and take notes - Compose the definitions of key AI vocabulary - Do an AI vocabulary quiz - Learn how different prompt structures lead to</td><td>3</td></tr></table></body></html>\n\n(continued )   \n\n<html><body><table><tr><td>Week</td><td>Lesson aims</td><td>Activities</td><td>Assessments AIAP</td><td>components 1 - Vocabulary, jargon, concepts 2 - Inner workings 3 - Prompt engineering 4 - Specific suggested tools &amp;</td></tr></table></body></html>\n\n- To learn about a prompt engineering framework   \n- To practise prompting   \n2.1 Reports   \n- To identify features of a report   \n2.2 Evaluating sources   \n- To learn about how sources can be evaluated for reliability   \n- To practise evaluating a source   \n- To continue practising prompting\n\n# 3.1. Pre-writing process\n\n- To become familiar with the writing process   \n- To learn how to use AI in the pre-writing process   \n3.2 Using AI appropriately   \n- To critically evaluate an AI-generated outline   \n- To determine appropriate and inappropriate uses of AI in educational contexts   \n- To develop guidelines for responsible AI use   \n4.1 Paragraph structure & Using AI   \nappropriately (2)   \n- To explore the structure of an academic paragraph   \n- To practise writing an academic paragraph   \n- To become aware of ethical problems of AI   \n- To evaluate AI output   \n- To consolidate understanding of appropriate use of AI in academic settings   \n4.2 Revision on avoiding plagiarism   \n- To revise how to avoid plagiarism   \n- To examine how to use AI tools in referencing and paraphrasing   \n5.1 Reporting language   \n- To recognise and effectively use the language for reporting information from sources   \n5.2 Academic style   \n- To revise features of academic style   \n6.1 Cohesion   \n- To understand the importance of cohesion in writing   \n- To practise improving cohesion in writing   \n6.2 AI scramble   \n- To continue practising prompt engineering   \n- To critically analyse and evaluate the strengths and weaknesses of extended AI outputs   \n7.1 Report introduction and recommendation   \nsection   \n- To understand the purpose and structure of a report introduction and a recommendation section   \n- To practise writing these sections   \n- Use Birss\u2019s (2023) CREATE framework to prompt for given scenarios   \n- Read a report and identify its typical features   \n- Discuss the content of the report   \n- Be introduced to how to evaluate sources 3, 4   \n- Evaluate three given sources   \n- Use Birss\u2019s (2023) CREATE framework to prompt for given scenarios   \n- Analyse report assessment question and take notes of 4 what to search for to answer the question   \n- Use Elicit, Consensus and Perplexity to search for sources   \n- Start preparing a report outline based on ideas from sources   \n- Evaluate an AI-generated outline for an outline on the 4, 5 same topic   \n- Analyse and discuss scenarios where AI tools are used in completing academic tasks to decide which ones are appropriate   \n- Make a list of Dos and Don\u2019ts regarding using AI at university   \n- Be instructed on how fill in AI declaration form   \n- Read an example academic paragraph and analyse its 2, 4, 5 structure   \n- Write an academic paragraph   \n- Read and discuss an article about ethical problems of AI   \n- Evaluate paragraphs from AI over-reliant student work   \n- Analyse and discuss scenarios where AI tools are used in completing academic tasks to decide which ones are appropriate   \n- Revise how to reference sources 3, 4, 5   \n- Use Generative AI to correct errors in a reference list   \n- Evaluate Quillbot\u2019s paraphrases   \n- Discuss how to use AI paraphrasing tools ethically   \n- Analyse the reporting language in an academic paragraph   \n- Use reporting language in paragraph writing   \n- Match features of academic styles with examples Report draft   \n- Change informal language to formal language   \n- Compare a cohesive paragraph with an incohesive one to identify features of the cohesive one   \n- Analyse and improve the cohesion of a paragraph   \n- Use Generative AI tool(s) to write an essay on a given 3, 5 topic   \n- Critically evaluate AI-generated essay   \n- Reflect on the process of using AI in the writing process   \n- Identify key elements typically included in an effective introduction and recommendation section   \n- Write a report introduction and a recommendation section\n\n(continued )   \n\n<html><body><table><tr><td>Week</td><td>Lesson aims</td><td>Activities</td><td>Assessments</td><td>AIAP components 1 - Vocabulary, jargon, concepts 2 - Inner workings 3 - Prompt engineering 4 - Specific suggested tools &amp; applications 5 - Ethics &amp;</td></tr></table></body></html>\n\n# 7.2. Tutorials\n\n- Discuss feedback on the report draft and ask clarifying questions - Work with the tutor to identify specific areas for improvement and practical steps for revision.\n\n- To understand and clarify tutor feedback on the report draft   \n- To identify strategies for improving writing in the final report   \n8.1 Revision and proofreading   \n- To learn how to use AI tools for revision and proofreading\n\nFinal report 3, 4\n\n8.2 Presentation skills (1)\n\n- Analyse tutor\u2019s feedback on report draft for key areas for improvement   \n- Analyse writing marking criteria for key points   \n- Use the above to create prompt(s) for getting feedback from AI   \n- Discuss previous experience with making presentations   \n- Watch a presentation recording and identify its strengths and weaknesses   \n- Discuss and make a list of most useful tips for designing visual aids   \n- Design visual aids   \n- To discuss previous experience with making presentations   \n- To evaluate a presentation   \n- To revise how to design effective visual aids   \n- To practise designing visual aids   \n9.1 Presentation skills (2)   \n- To become aware of presentation structure and signpost language   \n- To learn how to deal with questions effectively   \n- To practise making a presentation   \n- Watch a presentation recording and analyse its structure   \n- Identify signpost language in the presentation recording   \n- Make a list of signpost language organised by functions   \n- Discuss strategies to deal with questions after a presentation   \n- Make a 2-min presentation and receive peer and tutor feedback   \n- Analyse presentation marking criteria   \n- Make a complete presentation and receive peer and tutor feedback\n\n9.2 Presentation skills (3) - To practise making a presentation\n\n# Appendix B. Example materials\n\nWeek 1 \u2013 1.2. Prompt engineering\n\n# Prompt engineering\n\nIn Al, a prompt is any form of text, question, information, or coding that communicates to Al what response you're looking for. Knowing how to prompt can help us to communicate effectively with Generative Al e.g. ChatGPT. Thisleads to better quality, more helpful and relevant responses.\n\n# Read the following prompts and responses\n\nPrompt 1:Tell me about Al.\n\nResponse 1: Artificial intelligence (Al) is a branch of computer science that deals with the creation and development of machines that can perform tasks requiring human-like intelligence. This includes learning, reasoning, problem -solving, and understanding natural language.\"\n\nPrompt 2:\"Provide a concise summary of artificial intelligence, its subfields, and current applications.\"\n\nResponse 2:Artificial intelligence (Al) is the study of creating intelligent agents capable of performing tasks autonomously. Key subfields include machine learning, natural language processing, and robotics. Current applications range from virtual assistants and recommendation systems to autonomous vehicles and medical diagnosis.\"\n\nWhat is the difference? How does the input change the output?\n\n# CREATE Framework (Birss, 2023)\n\n:C - Character (what role do you want it to play?)   \n:R- Request (tell it specifically what you want it to do- give context and useful info)   \n:E - Examples (GPT is great at learning from examples)   \n. A - Adjustments (where you make changes to improve output) :T- Type of output (bullet point, table,500 word summary etc) :E- Extras (eg. 'ask me questions before you answer', 'explain your thinking').\n\n# What do these prompts look like in practice? (CREATE)\n\nYou are a friendly,experienced academic English tutor.Please give me feedback on my draft essay focusing on argument, structure, coherence, cohesion, grammar, lexis.Please list any errors, problems or issues you find in the form of a table, and give an indication of what type of error it is.Help me to try and re-phrase or correct these errors before giving me your corrections.Based on the types of errors I am making,please suggest some strategies, readings, or materials for my improvement.Ask clarifying questions before answering.\n\nThe essay is as follows: ..\n\n# Identify the following elements\n\nC -Character (what role do you want it to play?) R-Request (tell it specifically what you want it to do-give context and useful info)   \nE-Examples (GPT is great at learning from   \nexamples)   \nA- Adjustments (where you make changes to improve output)   \n- Type of output (bullet point, table, 500 word summary etc)   \n-Extras (eg.ignore everything before this prompt,'ask me questions before you answer', 'explain your thinking).\n\n# Your turn\n\nWork in pairs/groups of 3.   \nOpen one of these Generative Al tools:ChatGPT,Gemini, Claude, Bing, CoPilot, Poe(whatever you like).Note thatsome tools require registration.   \n: Use the CREATE framework and the earlier example to create some sample prompts for the scenarios in the following slide,   \nPut your prompts into your chosen Gen Al tool.   \nDiscuss together and make sure you iterate appropriately.   \nBe ready to make a short presentation to the class about your prompts and outputs-we will compare across groups.\n\n# Your turn\n\n1. You want to revise materials on an aspect of your subject that you are not clear about (aim to output an explanation and a test as a minimum). 2. You want to learn a language of your choice as a beginner.\n\n# Week 3 \u2013 3.2 Using AI appropriately\n\n# Read the scenarios below decide if they are appropriate use of AI or not\n\n1. Jayden is working on his dissertation and needs to review related literature (previous research) on his topic. He asks ChatGPT to summarise the major works and findings in his research area. He then adds that summary to his dissertation and submits it.   \n2. Lana, a language student, is preparing for her final oral exam in Portuguese. To enhance her vocabulary, she requests ChatGPT to simulate a conversation with her in Portuguese, allowing the AI to correct her when she makes an error.   \n3. Susan is struggling with the recommendation section of her report. She provides ChatGPT with her analysis, asking it to write a fitting recommendation section. She then adds this recommendation to her report and submits it.   \n4. Arjun needs to write an essay about climate change but he is not sure which aspect of climate change to focus on. He asks Perplexity to give him some possible essay questions about climate change. He chooses one of the questions from the list Perplexity generates and writes his own essay.   \n5. Jane is preparing a presentation about the impact of globalisation. She asks Perplexity to explain the impact of globalisation on the global economy and uses Perplexity\u2019s ideas in her presentation. She cites and references Perplexity.   \n6. Otis is preparing for his Maths exam. He puts a maths exercise that his teacher gave him in the class into ChatGPT and asks it to generate similar exercises. He does these exercises and then asks ChatGPT to give him feedback.   \n7. Maria, an international student in the UK, occasionally struggles with English grammar in her essays. She inputs problematic sentences into ChatGPT for corrections. For example, from \"She had less books than him,\" ChatGPT suggests \"She had fewer books than him,\" and explains the difference. Using ChatGPT, Maria quickly refines her essay and submits it.   \n8. Yoko is an international student in Australia. Her tutor notices that she is struggling with academic reading and gives her some exercises as homework to practise reading skills. These exercises require Yoko to read some texts and answer comprehension questions. Yoko does not read the texts but puts them into Perplexity and asks it to answer the questions for her.\n\nWeek 4 \u2013 4.2 Revision on avoiding plagiarism\n\nTask 1: Below is an original text and 4 paraphrased versions by QuillBot, and AI tool which specialises in paraphrasing. Highlight/note the similarities and differences between the 4 paraphrased versions.\n\n# Discuss:\n\n1) Are these paraphrases effective?   \n2) What would happen when several students used QuillBot for paraphrasing and then submitted the paraphrases as part of their assessments?   \n3) How should we use paraphrasing tools e.g. QuillBot or ChatGPT?\n\n# Original text:\n\nThe Future of Jobs Survey also probes the expected impact of technology adoption on employment. [.] Big data analytics, climate change and environmental management technologies, and encryption and cybersecurity are expected to be the biggest drivers of job growth. [.] Generative AI has received particular attention recently, with claims that $1 9 \\ \\%$ of the workforce could have over $5 0 \\%$ of their tasks automated by AI and job losses making headlines, while others expect the technology to enhance jobs.\n\nSource: World Economic Forum (2023). The Future of Jobs Report (2023). Available at: https://www3.weforum.org/docs/WEF Future_of_Jobs_2023.pdf (Accessed: 29 September 2023).\n\n# Quillbot:\n\n1. The expected effect of technology adoption on employment is another topic covered in the Future of Jobs Survey. [.] The biggest job growth drivers are anticipated to be big data analytics, climate change and environmental management technologies, encryption, and cybersecurity. [.] Recent media attention has focused on generative AI, with some predicting job losses and claims that $1 9 \\ \\%$ of the workforce could have over $5 0 \\ \\%$ of their tasks automated by the technology.   \n2. The projected effects of technology adoption on employment are also investigated by the Future of Jobs Survey. [.] The technologies that are anticipated to create the greatest increase in employment include big data analytics, climate change and environmental management technology, encryption, and cybersecurity. [.] With projections that $1 9 \\%$ of the workforce might have over $5 0 \\%$ of their tasks automated by AI and job losses making headlines, generative AI has recently attracted a lot of attention. However, other people anticipate the technology to improve jobs.   \n3. The Future of Jobs Survey looks into the anticipated effects of technology adoption on employment. [.] The largest jobgrowth drivers are anticipated to be technology related to big data analytics, environmental management and climate change, encryption, and cybersecurity. [.] Recent headlines about job losses and projections that $1 9 \\%$ of the workforce may have over $5 0 \\%$ of their labour automated by AI have drawn attention to the field of generative AI, however some experts believe the technology may actually improve employment opportunities.   \n4. The projected effects of technology adoption on employment are also examined by the Future of Jobs Survey. [.] The largest job-growth drivers are anticipated to be big data analytics, climate change and environmental management technology, encryption, and cybersecurity. [.] With projections that $1 9 \\%$ of the workforce might have over $5 0 \\%$ of their tasks automated by AI and job losses making headlines, generative AI has recently attracted a lot of attention. However, some anticipate the technology to improve jobs.\n\n# Week 6 \u2013 6.2 AI scramble\n\nAfter your group have finished writing an essay on a given topic by only using GenAI, reflect on this process and discuss the following questions in your group.\n\n1. Which combination of GenAI tools did you decide to use to write the essay, and how did you use/combine them?   \n2. How did your knowledge of prompt engineering impact the quality of the final essay?   \n3. How do you feel this essay would compare to one solely written by you?   \n4. In what ways was this exercise useful? What new things did you learn from doing this?   \n5. What problems did you encounter? Did you encounter any issues with accuracy or reliability in the AI-generated content?   \n6. What do you think will happen in the future if we use AI regularly at university? Do you believe that using AI for writing impacted your ability to express original ideas or creativity? Why/why not?\n\n# Week 8 \u2013 8.1 Revision and proofreading\n\n# Feedback from Al\n\nHaving Al act as a learning aid in this way is both appropriate and ethical as well as beneficial to your learning - this is what it really excels at!   \nAs always, we need to create prompt to get Al to generate anything.   \nWe engineer this prompt in the same general way we engineer others to get the best quality output - remember CREATE?   \nThe details are particularly important here -- what do we want feedback on? What is determining your mark?   \nLook at the extended writing rubric in 8.1 - what are the key points to get a good mark?\n\n# Key points (writing)\n\nClear focus on question   \nClear understanding and use of sources. Citations and references are accurate   \nBalance of information from sources and own ideas / analysis   \nMain ideas are well developed   \nClear, effective, and appropriate structure   \nClear and logical paragraphing and use of topic sentences   \nWork is logically cohesive and uses cohesive devices accurately   \nMeaning is clear and fluent   \nUses subject specific vocabulary accurately   \nAcademic register / style is consistent   \n: Able to accurately use complex grammatical forms\n\n# Putting it all together\n\n: Create a prompt to get feedback from Al.   \n: Based on your knowledge of prompt engineering, your understanding of the rubric, and finally, any comments your tutor, include as much detail as possible in your prompt to get useful feedback from ChatGPT (or any other Generative Al tool of your choice)   \nBe prepared to discuss your prompt as well as your thoughts (both positive and negative) about the output / feedback this has resulted   \nin with the class.\n\n# A sample prompt\n\nAct as an academic English instructor. Give feedback on my report draft, focusing particularly on how well I've addressed the question, my understanding and use of sources, the accuracy of my Harvard citations and references, the balance between information from sources and my own analysis, evaluation, and ideas, how well-developed these ideas are, whether the structure and paragraphing is clear, effective and appropriate, the overall coherence and cohesion of the work and appropriacy of cohesive devices, the clarity, fluency, and academic style of the prose, accurate use of'subject-specific vocabulary, and accuracy and use of complex grammatical! forms.\n\nRather than giving me the answers, please guide me to doing so myself by identifying an error, asking me about it and guiding me towards improving it, waiting for my response, giving me feedback on my new effort and then moving on to the next one.\n\nIf there are any particular error types in style, grammar or lexis that occur frequently within my draft, classify these at the end and give me advice as to how to improve in these areas.\n\nHere is the report question. ... Here is my draft report : <..?\n\n# References\n\nAlharbi, W. (2023). AI in the Foreign Language Classroom: A Pedagogical Overview of Automated Writing Assistance Tools, 2023 (pp. 1\u201315). Education Research International.   \nAllen, L. K., & Kendeou, P. (2024). ED-AI Lit: an interdisciplinary framework for AI literacy in education. Policy Insights from the Behavioral and Brain Sciences, 11(1), 3\u201310.   \nBarrett, A., & Pack, A. (2023). Not quite eye to AI: student and teacher perspectives on the use of generative artificial intelligence in the writing process. International Journal of Educational Technology in Higher Education, 20(1), 59. https://doi.org/10.1186/s41239-023-00427-0   \nBirss, D. (2023). How to write an effective prompt for AI. LinkedIn Learning [Video] https://www.linkedin.com/learning.   \nBraun, V., & Clarke, V. (2006). Using thematic analysis in psychology. Qualitative Research in Psychology, 3(2), 77\u2013101.   \nBraun, V., & Clarke, V. (2012). Thematic Analysis. American Psychological Association.   \nChami, G. (2023). Artificial intelligence and academic integrity: striking a balance. Higher Education. https://www.timeshighereducation.com/campus/ artificial-intelligence-and-academic-integrity-striking-balance.   \nChan, C. K. Y. (2023a). A comprehensive AI policy education framework for university teaching and learning. International Journal of Educational Technology in Higher Education, 20(1), 38. https://doi.org/10.48550/arXiv.2305.00280   \nChan, C. K. Y. (2023b). Is AI changing the rules of academic misconduct? An in-depth look at students\u2019 perceptions of\u2019AI-giarism\u2019. arXiv preprint arXiv:2306. 03358. https://doi.org/10.48550/arXiv.2306.03358   \nChan, C. K. Y., & Hu, W. (2023). Students\u2019 voices on generative AI: perceptions, benefits, and challenges in higher education. International Journal of Educational Technology in Higher Education, 20(1), 43. https://doi.org/10.1186/s41239-023-00411-8   \nChan, C. K. Y., & Zhou, W. (2023). Deconstructing student perceptions of generative AI (GenAI) through an expectancy value theory (EVT)-based instrument. arXiv preprint arXiv:2305.01186. https://doi.org/10.48550/arXiv.2305.00290   \nChiu, T. K. (2024). Future research recommendations for transforming higher education with generative AI. Computers and Education: Artificial Intelligence, 6, Article 100197. https://doi.org/10.1016/j.caeai.2023.100197   \nCreswell, J. W., & Clark, V. L. P. (2017). Designing and Conducting Mixed Methods Research. Sage publications.   \nCreswell, J. W., & Poth, C. N. (2018). Qualitative Inquiry and Research Design: Choosing Among Five Approaches. Sage publications (4th edition).   \nDing, L., Li, T., Jiang, S., & Gapud, A. (2023). Students\u2019 perceptions of using ChatGPT in a physics class as a virtual tutor. International Journal of Educational Technology in Higher Education, 20(1), 63. https://doi.org/10.1186/s41239-023-00434-1   \nDu, J., & Alm, A. (2024). The impact of ChatGPT on English for academic purposes (EAP) students\u2019 language learning experience: a self-determination theory perspective. Education Sciences, 14(7), 726. https://doi.org/10.3390/educsci14070726   \nEgli, U., Pause, P., Schwarze, C., Stechow, A., & Wienold, G. (1995). Lexical knowledge in the organization of language. Language, 72, 670. https://doi.org/10. 1075/CILT.114   \nFarrelly, T., & Baker, N. (2023). Generative artificial intelligence: implications and considerations for higher education practice. Education Sciences, 13(11), 1109. https://doi.org/10.3390/educsci13111109   \nFirat, M. (2023). What ChatGPT means for universities: perceptions of scholars and students. Journal of Applied Learning and Teaching, 6(1), 57\u201363. https:// doi.org/10.37074/jalt.2023.6.1.22   \nGiray, L. (2023). Prompt engineering with ChatGPT: a guide for academic writers. Annals of Biomedical Engineering, 51(12), 2629\u20132633. https://doi.org/10. 37074/jalt.2023.6.1.22   \nHillier, M. (2023). A proposed AI literacy framework. TECHE. https://teche.mq.edu.au/2023/03/a-proposed-ai-literacy-framework/.   \nHornberger, M., Bewersdorff, A., & Nerdel, C. (2023). What do university students know about Artificial Intelligence? Development and validation of an AI literacy test. Computers and Education: Artificial Intelligence, 5, Article 100165. https://doi.org/10.1016/j.caeai.2023.100165   \nHyland, K. (2003). Second Language Writing. Cambridge University Rress.   \nHyland, K. (2006). English for Academic Purposes: an Advanced Resource Book. London: Routledge.   \nIfelebuegu, A. O., Kulume, P., & Cherukut, P. (2023). Chatbots and AI in Education (AIEd) tools: the good, the bad, and the ugly. Journal of Applied Learning and Teaching, 6(2). https://doi.org/10.37074/jalt.2023.6.2.29   \nIrfan, M., Murray, L., & Ali, S. (2023). Insights into student perceptions: investigating artificial intelligence (AI) tool usability in Irish higher education at the University of Limerick. Global Digital & Print Media Review. https://doi.org/10.31703/gdpmr.2023(vi-ii).05   \nJisc. (2024). Student perceptions of generative AI. https://www.jisc.ac.uk/reports/student-perceptions-of-generative-ai.   \nKelly, A., Sullivan, M., & Strampel, K. (2023). Generative artificial intelligence: university student awareness, experience, and confidence in use across disciplines. Journal of University Teaching and Learning Practice, 20(6), 12. https://doi.org/10.53761/1.20.6.12   \nKleitman, S., & Stankov, L. (2007). Self-confidence and metacognitive processes. Learning and Individual Differences, 17(2), 161\u2013173. https://doi.org/10.1016/j. lindif.2007.03.004   \nKohnke, L. (2024). Exploring EAP students\u2019 perceptions of GenAI and traditional grammar-checking tools for language learning. Computers and Education: Artificial Intelligence, 7, Article 100279. https://doi.org/10.1016/j.caeai.2024.100279   \nKong, S. C., Cheung, M. Y. W., & Tsang, O. (2024). Developing an artificial intelligence literacy framework: evaluation of a literacy course for senior secondary students using a project-based learning approach. Computers and Education: Artificial Intelligence, 6, Article 100214. https://doi.org/10.1016/j.caeai.2024. 100214   \nKong, S. C., Cheung, W. M. Y., & Zhang, G. (2021). Evaluation of an artificial intelligence literacy course for university students with diverse study backgrounds. Computers and Education: Artificial Intelligence, 2, Article 100026. https://doi.org/10.1016/j.caeai.2021.100026   \nKong, S. C., Zhang, G., & Cheung, M. Y. (2022). Pedagogical delivery and feedback for an artificial intelligence literacy programme for university students with diverse academic backgrounds: flipped classroom learning approach with project-based learning. Bulletin of the Technical Committee on Learning Technology, 22(1), 8\u201314. https://doi.org/10.30191/ETS.202301_26(1).0002   \nLiang, W., Yuksekgonul, M., Mao, Y., Wu, E., & Zou, J. (2023). GPT detectors are biased against non-native English writers. Patterns, 4(7). https://doi.org/10. 1016/j.patter.2023.100779   \nLim, W. M., Gunasekara, A., Pallant, J. L., Pallant, J. I., & Pechenkina, E. (2023). Generative AI and the future of education: ragnar\u00f6k or reformation? A paradoxical perspective from management educators. International Journal of Management in Education, 21(2), Article 100790. https://doi.org/10.1016/j. ijme.2023.100790   \nLiu, D., & Bridgeman, A. (2023). ChatGPT Is Old News: How Do We Assess in the Age of AI Writing Co-pilots? The University of Sydney. https://educationalinnovation.sydney.edu.au/teaching@sydney/chatgpt-is-old-news-how-do-we-assess-in-the-age-of-ai-writing-co-pilots/.   \nLiu, Y., Park, J., & McMinn, S. (2024). Using generative artificial intelligence/ChatGPT for academic communication: students\u2019 perspectives. International Journal of Applied Linguistics, 1\u201325. https://doi.org/10.1111/ijal.12574, 2024.   \nLong, D., & Magerko, B. (2020). What is AI literacy? Competencies and design considerations. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (pp. 1\u201316).   \nMills, A., Bali, M., & Eaton, L. (2023). How do we respond to generative AI in education? Open educational practices give us a framework for an ongoing process. Journal of Applied Learning and Teaching, 6(1), 16\u201330. https://doi.org/10.37074/jalt.2023.6.1.34   \nMollick, E. (2023). A guide to prompting AI (for what it is worth). In One Useful Thing. https://www.oneusefulthing.org/p/a-guide-to-prompting-ai-for-what.   \nNg, D. T. K., Leung, J. K. L., Chu, S. K. W., & Qiao, M. S. (2021). Conceptualizing AI literacy: An exploratory review. Computers and Education: Artificial Intelligence, 2, Article 100041. https://doi.org/10.1016/j.caeai.2021.100041   \nO\u2019Dea, X. C., & O\u2019Dea, M. (2023). Is artificial intelligence really the next big thing in learning and teaching in higher education? A conceptual paper. Journal of University Teaching and Learning Practice, 20(5). https://doi.org/10.53761/1.20.5.05   \nOu, A. W., St\u00f6hr, C., & Malmstr\u00f6m, H. (2024). Academic communication with AI-powered language tools in higher education: From a post-humanist perspective. System, 121, Article 103225. https://doi.org/10.1016/j.system.2024.103225   \nPallant, J. (2010). SPSS Survival Manual: A Step by Step Guide to Data Analysis Using SPSS (4th ed.). McGraw-Hill.   \nPerkins, M., Gezgin, U. B., & Roe, J. (2020). Reducing plagiarism through academic misconduct education. International Journal for Educational Integrity, 16, 1\u2013 15. https://doi.org/10.1007/s40979-020-00052-8   \nPinski, M., & Benlian, A. (2024). AI literacy for users\u2013A comprehensive review and future research directions of learning methods, components, and effects. Computers in Human Behavior: Artificial Humans, 1, Article 100062. https://doi.org/10.1016/j.chbah.2024.100062   \nPretorius, L. (2023). Fostering AI literacy: A teaching practice reflection. Journal of Academic Language and Learning, 17(1), T1\u2013T8. https://www.journal.aall. org.au/index.php/jall/article/view/891.   \nRowland, D. R. (2023). Two frameworks to guide discussions around levels of acceptable use of generative AI in student academic research and writing. Journal of Academic Language and Learning, 17(1), T31\u2013T69.   \nStankov, L., Lee, J., Luo, W., & Hogan, D. J. (2012). Confidence: A better predictor of academic achievement than self-efficacy, self-concept and anxiety? Learning and Individual Differences, 22(6), 747\u2013758. https://doi.org/10.1016/j.lindif.2012.05.013   \nSouthworth, J., Migliaccio, K., Glover, J., Reed, D., McCarty, C., Brendemuhl, J., & Thomas, A. (2023). Developing a model for AI Across the curriculum: Transforming the higher education landscape via innovation in AI literacy. Computers and Education: Artificial Intelligence, 4, Article 100127. https://doi. org/10.1016/j.caeai.2023.100127   \nSullivan, M., McAuley, M., Degiorgio, D., & McLaughlan, P. (2024). Improving students\u2019 generative AI literacy: A single workshop can improve confidence and understanding. Journal of Applied Learning and Teaching, 7(2).   \nWalter, Y. (2024). Embracing the future of Artificial Intelligence in the classroom: the relevance of AI literacy, prompt engineering, and critical thinking in modern education. International Journal of Educational Technology in Higher Education, 21(1), 15. https://doi.org/10.1186/s41239-024-00448-3   \nWaltzer, T., Cox, R. L., & Heyman, G. D. (2023). Testing the ability of teachers and students to differentiate between essays generated by ChatGPT and high school students. Human Behavior and Emerging Technologies, 2023(1), Article 1923981. https://doi.org/10.1155/2023/1923981   \nWharton School. (2023). Practical AI for Instructors And Students Part 1: Introduction to AI for Teachers and Students [Video]. YouTube. https://www.youtube. com/watch?v\u00bct9gmyvf7JYo.   \nWorld Economic Forum. (2023). Future of jobs report 2023. Available at: https://www3.weforum.org/docs/WEF_Future_of_Jobs_2023.pdf.   \nYeo, M. A. (2023). Academic integrity in the age of artificial intelligence (AI) authoring apps. TESOL Journal, 14(3), e716. https://doi.org/10.1002/tesj.716   \nYusuf, A., Pervin, N., & Rom\u00e1n-Gonz\u00e1lez, M. (2024). Generative AI and the future of higher education: a threat to academic integrity or reformation? Evidence from multicultural perspectives. International Journal of Educational Technology in Higher Education, 21(1), 21. https://doi.org/10.1186/s41239- 024-00453-6   \nZhu, W., Huang, L., Zhou, X., Li, X., Shi, G., Ying, J., & Wang, C. (2024). Could AI ethical anxiety, perceived ethical risks and ethical awareness about AI influence university students\u2019 use of generative AI products? An ethical perspective. International Journal of Human-Computer Interaction, 1\u201323. https:// doi.org/10.1080/10447318.2024.2323277   \nThu Ngan Ngo (aka Cassie) is an EAP tutor based in the UK. She holds an MA in TESOL and Applied Linguistics, along with a CELTA and a DELTA. She has\n\ntaught EAP, ESP and EFL in the UK, Brazil, China and Vietnam. Her research interests include integration of technology into teaching and learning and of AI literacy into EAP.\n\nDavid Hastie is an EAP tutor living in Dundee, Scotland. He holds an MA in English Literature and an MSc in TESOL, both from the University of Aberdeen. He was worked in pre and in-sessional EAP programs at universities in the UK and China, and has a particular interest in materials design and AI literacy.", "metadata": {"authors": ["Thu Ngan Ngo", "David Hastie"], "category": "research", "confidence_score": 0.8, "document_type": "journal", "has_abstract": true, "has_methodology": true, "has_results": true, "key_findings": ["significant improvements in students' ability to critically evaluate GenAI output, confidence in using a greater variety of AI tools, understanding of ethical AI use, and an expansion in the purposes for which students use AI tools", "the integration of AI literacy with traditional EAP skills was found to meet students' academic needs effectively"], "methodology": "mixed", "pedagogical_confidence": 0.4, "pedagogical_implications": true, "publication_year": 2024, "research_questions": [], "source_file": "out_3NL63DC7_Artificial_Intelligence_for_Aca.md", "subject_area": "education", "tags": ["AI literacy", "English for Academic Purposes (EAP)", "higher education", "AI integration in education", "international students"], "title": "Artificial Intelligence for Academic Purposes (AIAP): Integrating AI literacy into an EAP module"}, "search_text": "Artificial Intelligence for Academic Purposes (AIAP): Integrating AI literacy into an EAP module AI literacy English for Academic Purposes (EAP) higher education AI integration in education international students education # Artificial Intelligence for Academic Purposes (AIAP): Integrating AI literacy into an EAP module\n\nThu Ngan Ngo a,b,\\*, David Hastie b\n\na University Centre for Academic English, University of Manchester, Samuel Alexander Building, Manchester M13 9PL, UK b International College Dundee, University of Dundee, 2 Airlie Place, Dundee, DD1 4HQ, UK\n\n# a r t i c l e i n f o\n\n# a b s t r a c t\n\nArticle history:\n\nKeywords:   \nAI literacy   \nEnglish for Academic Purposes (EAP)   \nHigher education   \nAI integration in education   \nInternational students\n\nWith the rise of generative AI (GenAI) tools such as ChatGPT and their growing relevance in academic contexts, the need for AI literacy has become imperative, particularly for international students in EAP programs. The study addresses the gap in practical guidance for incorporating AI literacy by developing and implementing a 10-week AI-integrated EAP module at a pathway college in Scotland based on a novel framework termed AI for Academic Purposes (AIAP). Utilising a mixed-methods approach, the research investigates the impact of this module on international students\u2019 attitudes, confidence, and purposes of using AI tools. Results of this study indicate significant improvements in students\u2019 ability to critically evaluate GenAI output, confidence in using a greater variety of AI tools, understanding of ethical AI use, and an expansion in the purposes for which students use AI tools. The integration of AI literacy with traditional EAP skills was found to meet students\u2019 academic needs effectively. This study provides a replicable model for integrating AI literacy into EAP courses, offering a holistic educational approach that aligns technological proficiency with ethical awareness.\n\n$^ { \u00a9 }$ 2024 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\n\n# 1. Introduction\n\nGenerative AI (GenAI) is a type of artificial intelligence that can cre"}, "title": "Artificial Intelligence for Academic Purposes (AIAP): Integrating AI literacy into an EAP module", "authors": ["Thu Ngan Ngo", "David Hastie"], "tags": ["AI literacy", "English for Academic Purposes (EAP)", "higher education", "AI integration in education", "international students"], "filename": "out_3NL63DC7_Artificial_Intelligence_for_Aca.md"}, {"score": 0.3883427679538727, "document": {"id": 757, "file_path": "annotated_data/batch_002/out_MV4IN64M_Artificial_Intelligence_for_Aca.md", "filename": "out_MV4IN64M_Artificial_Intelligence_for_Aca.md", "content": "# Artificial Intelligence for Academic Purposes (AIAP): Integrating AI literacy into an EAP module\n\nThu Ngan Ngo a,b,\\*, David Hastie b\n\na University Centre for Academic English, University of Manchester, Samuel Alexander Building, Manchester M13 9PL, UK b International College Dundee, University of Dundee, 2 Airlie Place, Dundee, DD1 4HQ, UK\n\n# a r t i c l e i n f o\n\n# a b s t r a c t\n\nArticle history:\n\nKeywords:   \nAI literacy   \nEnglish for Academic Purposes (EAP)   \nHigher education   \nAI integration in education   \nInternational students\n\nWith the rise of generative AI (GenAI) tools such as ChatGPT and their growing relevance in academic contexts, the need for AI literacy has become imperative, particularly for international students in EAP programs. The study addresses the gap in practical guidance for incorporating AI literacy by developing and implementing a 10-week AI-integrated EAP module at a pathway college in Scotland based on a novel framework termed AI for Academic Purposes (AIAP). Utilising a mixed-methods approach, the research investigates the impact of this module on international students\u2019 attitudes, confidence, and purposes of using AI tools. Results of this study indicate significant improvements in students\u2019 ability to critically evaluate GenAI output, confidence in using a greater variety of AI tools, understanding of ethical AI use, and an expansion in the purposes for which students use AI tools. The integration of AI literacy with traditional EAP skills was found to meet students\u2019 academic needs effectively. This study provides a replicable model for integrating AI literacy into EAP courses, offering a holistic educational approach that aligns technological proficiency with ethical awareness.\n\n$^ { \u00a9 }$ 2024 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\n\n# 1. Introduction\n\nGenerative AI (GenAI) is a type of artificial intelligence that can create new content such as texts, images and videos. Users can input text or \u2018prompts\u2019 to GenAI tools such as ChatGPT or Microsoft Co-pilot and quickly receive an entire essay. The release of ChatGPT 3.5 in late 2022 initiated panic in higher education (HE), with several universities including Oxford and Cambridge banning ChatGPT in early 2023 and decreeing its usage to constitute academic misconduct (Chan, 2023a; Lim et al., 2023). Since this initial burst of reactionism, however, an acceptance that the use of GenAI is an inescapable reality has predominated (Alharbi, 2023; Mills et al., 2023). The release of AI assistants such as Google Duet which is embedded directly into Google Docs is a further critical development, in that we all have access to GenAI from within the spaces where we write (Liu & Bridgeman, 2023). This, along with the fact that AI literacy is regarded as a key graduate attribute due to the integration of AI into the workplace, underscores the idea that the higher education (HE) sector must continue adapting to the new era of GenAI (O\u2019Dea & O\u2019Dea, 2023; Southworth et al., 2023; Chiu, 2024). Research into students\u2019 perspectives has shown that they want universities to take the lead in this regard (Chan, 2023a; Jisc, 2024). However, there is a notable absence of concrete and practical institutional guidance and within the nascent research for practitioners on how to proceed (Barrett & Pack, 2023; Walter, 2024).\n\nThis is also an issue in English for Academic Purposes (EAP), a field where there is a clear rationale for the integration of AI literacy. EAP courses teach core academic and study skills deemed relevant to international students of all subjects and disciplines (Hyland, 2006), aiming to support these students in achieving success in English-speaking academic environments. These skills include paraphrasing, summarising, referencing and critical thinking and, by equipping students with these, EAP modules help mitigate some forms of academic dishonesty such as plagiarism (Perkins et al., 2020).\n\nThere is a significant overlap between the skills typically taught in EAP courses and the capabilities and use cases of GenAI as both involve, for instance, summarising and paraphrasing. Just as with EAP, GenAI can provide additional language support for international students whose first languages are not English (Du & Alm, 2024; Farrelly & Baker, 2023). As EAP classes typically involve teaching how to avoid academic misconduct, they can offer space to address concerns regarding AI-related misuse or \u2018AI-giarism\u2019 (Chan, 2023b) by defining and modelling parameters of appropriate use (Chami, 2023; Lim et al., 2023) and facilitating the development of this sensibility within students themselves (Chan, 2023b). Additionally, the generally smaller class sizes, closer student-teacher relationships, and focus on communication and discussion typically found in EAP contexts represent the optimal classroom environment for fostering AI literacy.\n\nFor these reasons above, it can be argued that AI literacy should be integrated into EAP modules. Previous research on EAP students\u2019 perceptions of GenAI supports this integration (Liu et al., 2024; Du & Alm, 2024; Kohnke, 2024), yet no detailed framework for doing so has been provided. To address this gap, this article develops a framework for teaching AI literacy within an EAP context \u2013 which we refer to as AI for Academic Purposes, or, AIAP. This framework was conceived in response to issues we, as EAP practitioners, were encountering on the ground, such as an increase in AI-related academic misconduct, a lack of understanding from students of how to interact with or prompt these tools effectively (Walter, 2024) and a tendency to blindly trust information output from GenAI (Ding et al., 2023). Based on this framework, we have designed a concrete AIintegrated EAP module with a carefully structured, week-by-week curriculum which not only embeds AI literacy but also aligns it with the development of critical academic skills. This can offer a practical and replicable model for EAP educators, thereby advancing the discourse on AI literacy in academia.\n\nThe research questions are as follows:\n\nRQ1. What is the impact of an AI-integrated EAP module on a) students\u2019 attitudes and perceptions of GenAI, b) students\u2019 confidence in using AI tools for academic purposes, c) the purposes for which they use these tools and d) students\u2019 confidence in ethically and appropriately using AI tools?\n\nRQ2. How does this module meet the needs of students?\n\nThis article begins with a literature review looking at the conceptualisation of AI literacy, as well as key findings and trends regarding students\u2019 attitudes towards GenAI, confidence in utilising it academically, and the range of academic purposes it is being used for. Subsequently, the article illustrates the AIAP framework and how an AI-integrated EAP module was designed based on it. After that, the methodology of this research will be given before the results are analysed and discussed.\n\n# 2. Literature review\n\n# 2.1. AI literacy\n\nScholarship and commentary are now clear on the importance of AI literacy owing to it quickly becoming a key graduate attribute (World Economic Forum, 2023), as well as the wide range of educational benefits and affordances AI can offer to students generally, and international students in particular (Du & Alm, 2024; Farrelly & Baker, 2023). For Long and Magerko (2020), AI literacy is a set of competencies that enables an individual to critically evaluate, communicate, and collaborate with AI tools. This has proved a usefully broad definition despite the rapid advances made in the capability of GenAI tools and large language models (LLMs), and the exponentially growing range of different tools and applications now available. As an important adjunct, scholars have also pointed out the importance of addressing broader societal and ethical considerations of AI (Chiu, 2024; Hornberger et al., 2023).\n\nApproaches to fostering these sets of competencies tend to revolve around a few key ideas: student-centered learning or flipped classroom approaches (Kong et al., 2022), open and transparent communication practices, and \u2018hands-on\u2019 experience using relevant AI tools (Chan, 2023a; Pretorius, 2023). The duration and frequency of AI literacy programs or interventions are inconclusive, with some scholars and institutions advocating an integrated approach \u2018across the curriculum\u2019 (Southworth et al., 2023) and others maintaining that even a single AI literacy workshop can significantly improve student confidence and understanding of these tools (Sullivan et al., 2024).\n\nRegarding the specific content of these modules or workshops, Walter (2024, p.22) argues that AI literacy courses ought to include \u2018essential AI concepts, ethical considerations, and practical applications\u2019 at a minimum. These prerequisites aside, it is also important to note that different AI user groups have different AI literacy requirements, and that it is therefore important to tailor the pedagogical approach and components of AI literacy to the context (Pinski & Benlian, 2024). An exploration of the pedagogy and components of AI literacy for general academic purposes (AIAP) is therefore an important undertaking.\n\n# 2.2. Students\u2019 attitudes and perceptions of GenAI\n\nAs with other tools and technologies, students\u2019 attitudes and perceptions towards GenAI can substantially impact their willingness to utilise it (Chan & Hu, 2023). Several studies have found that university students have broadly positive attitudes and perceptions towards GenAI predicated on knowledge of the many educational affordances GenAI can offer (Chan & Zhou, 2023; Firat, 2023), and this base positivity appears to be common across different cultures and backgrounds (Yusuf et al., 2024). Despite the apparent generalisability of these sentiments, cross-disciplinary research cautions that attitudes and perceptions towards AI are not uniform across subjects, with humanities and arts students less positive than peers in STEM and related disciplines (Irfan et al., 2023; Kelly et al., 2023).\n\nStudent attitudes towards the accuracy and reliability of GenAI appear nuanced and considered \u2013 they are found to be sceptical about the extent to which GenAI can be utilised for grading and feedback because of its tendency to make mistakes or exhibit biases (Chan & Hu, 2023; Jisc, 2024). They are also becoming increasingly aware of the broader ethical issues surrounding this technology. Students specifically highlight a lack of institutional AI literacy support and guidelines (Jisc, 2024). This may be particularly relevant within EAP contexts; research from Australia cautions that international students may have less familiarity, awareness, and experience of GenAI than their domestic peers, highlighting the urgency of integrating AI literacy within EAP curricula to ensure a base equality of opportunity (Kelly et al., 2023).\n\n# 2.3. Students\u2019 confidence in using AI tools\n\nAlthough little specific literature about student confidence in utilising AI for educational purposes exists, confidence itself reliably predicts achievement across different knowledge domains and subjects (Kleitman & Stankov, 2007; Stankov et al., 2012). Increasing student confidence in utilising GenAI is thus an important consideration regarding student equity (Chiu, 2024; Ng et al., 2021). Kong et al.\u2019s (2021; 2022) research shows that AI literacy courses can empower students to work with AI.\n\nConfidence in utilising GenAI ethically and appropriately warrants further consideration. Plagiarism detection software is unreliable at best and potentially biased against students whose first language is not English (Liang et al., 2023), and with the ever-advancing sophistication of LLMs, it is becoming increasingly difficult to differentiate between human and GenAI output (Waltzer et al., 2023). Studies have suggested that more experience in hands-on use of GenAI leads to an increase in confidence in its ethical and appropriate utilisation (Kelly et al., 2023), and that fostering ethical awareness can positively impact student use of GenAI (Zhu et al., 2024). Other studies, however, point to considerable variance in students\u2019 understanding of inappropriate or unethical use of GenAI (Chan, 2023b), again highlighting the need both for clear institutional guidance and policy, as well as explicit pedagogical focus on this area (Chiu, 2024; Kong et al., 2024; Walter, 2024).\n\n# 2.4. Students\u2019 purposes of using AI\n\nGenerative AI has a wide range of applications within HE, and as noted, facilitates foundational academic research and writing practices, such as brainstorming and gathering sources and ideas (Chan & Zhou, 2023; Chiu, 2024; Jisc, 2024). It can also act as an additional tutor for students (Ifelebuegu et al., 2023; Ou et al., 2024) by providing personalised feedback (Chan & Zhou, 2023; Farrelly & Baker, 2023; Jisc, 2024), proofreading and editing (Farrelly & Baker, 2023), and fostering critical thinking (Allen & Kendeou, 2024; Walter, 2024). This range of academic applications is largely borne out by recent research on student purposes of GenAI utilisation. Personalised and immediate learning support, and ideation, brainstorming, and writing support are highlighted by students as particularly beneficial uses (Chan & Hu, 2023; Jisc, 2024). In addition, students are utilising AI in a pastoral as well as academic sense, with personal, motivational, and emotional support uses related to loneliness or mental health emerging as novel themes of usage (Jisc, 2024).\n\n# 3. Module design and AI literacy integration\n\n# 3.1. Context\n\nOur 10-week AI-integrated English for Academic Purposes 2 (EAP2) module is taught in the second term of the International Stage One (also known as International Foundation Year 1) at a pathway college in Scotland. The college provides international students who do not fulfil the admission requirements of a Scottish university with alternative paths to obtaining university degrees. To progress to university, all international students in the International Stage One are required to take three EAP modules (EAP1, EAP2 and EAP3), each of which lasts 10 weeks (five hours per week divided into two classes), to develop English language and academic skills, alongside modules related to their pathway subjects.\n\nEAP2 follows up on EAP1 in which students are taught foundational academic skills such as critical reading, discussion, paragraph writing and avoiding plagiarism by paraphrasing and referencing, alongside academic vocabulary and style. EAP2 focuses on extended writing with pre-determined assessments and intended learning outcomes.\n\nIn 2023, we revamped EAP2 by integrating AI literacy into the teaching of academic skills and language based on what we term the AIAP framework which includes five components 1) Vocabulary, jargon, concepts, 2) Inner workings, 3) Prompt engineering, 4) Specific suggested tools $\\mathcal { E }$ applications and 5) Ethics & appropriacy. How these components are integrated into the module will be explained in the following sections. This new version of EAP2 has been implemented since the beginning of 2024 and the module in this research was taught between January and March 2024.\n\n# 3.2. Course structure\n\nThe original curriculum followed the process-based approach (Hyland, 2003) with content on pre-writing, writing and post-writing stages. We decided to keep this approach as this is aligned with the pre-determined assessments which include a draft, a final piece of extended writing, followed by a presentation of this piece\u2019s content. Scholars have also suggested the process-based approach to assessments to mitigate AI-related misconduct (Yeo, 2023).\n\nThe first three weeks of the course focused on the pre-writing tasks such as analysing task instructions, searching for and evaluating sources and preparing an outline. Lessons in weeks 4\u20137 shifted the focus to skills, language and genre awareness needed for writing extended academic texts with content on paragraph writing, reporting language, academic style, cohesion and introduction and conclusion writing. The first lesson in Week 8 was about revision and proofreading while the rest of the course was lessons on presentation skills. AI literacy was integrated into all stages of the writing process, giving instruction on how to use AI effectively in each stage for writing support.\n\nCourse outline and sample materials are provided in Appendices A and B.\n\n# 3.3. AIAP integration\n\n# 3.3.1. Vocabulary, jargon, concepts\n\nThe foundation of any literacy is predicated on lexical, theoretical, and conceptual understanding (Egli et al., 1995) and AI literacy is no different. The few, limited efforts to promote AI literacy for \u2018citizens\u2019 often begin in the same manner by fostering knowledge of core concepts and terminologies such as machine learning and large language models (LLMs) (Kong et al., 2021, 2022). In our module, these vocabulary items (e.g. machine learning, GenAI, LLMs) were taught in the first lesson to enable students to confidently engage in AI-related texts and discussions throughout the course.\n\n# 3.3.2. Inner workings\n\nUnderstanding how GenAI tools function as well as their capabilities and limitations can help students use these tools responsibly and effectively (Chiu, 2024; Southworth et al., 2023). In our module, the inner workings of GenAI were explained in the first lesson by a video from Wharton School (2023) Practical AI for Instructors and Students. This video was chosen because it caters for those in academic contexts and it provides a foundational understanding of GenAI\u2019s inner workings with a simple explanation of how LLMs are trained and function, along with their key capabilities and limitations. This understanding can enable students to engage more deeply with later tasks in the course such as prompt engineering, critical evaluation of AI outputs, and understanding the ethical implications of AI use in academic contexts. We decided against exploring the complex inner workings of AI such as the detailed mechanics of machine learning algorithms or the architecture of large language models as these can distract from the focus of the course which is developing students\u2019 academic language and skills.\n\n# 3.3.3. Prompt engineering\n\nPrompt engineering is a fundamental skill for eliciting useful responses from GenAI (Ding et al., 2023; Walter, 2024). Proficiency in prompt engineering is intrinsically linked to developing criticality as crafting effective prompts requires critical and creative thinking (Walter, 2024). This skill can also result in a greater understanding of the capabilities and limitations of LLMs (Hillier, 2023) and enhances student self-efficacy by giving them the tools to leverage these technologies for their academic pursuits (Giray, 2023). Due to the importance of prompt engineering, one full lesson and a half of another on the module were dedicated to this. Also, this content was included in the first two weeks of our module for students to be able to leverage GenAI tools for more complex tasks later in the course such as using AI for writing revision. The framework of prompt engineering taught in this module is adapted from the Birss\u2019s (2023) CREATE framework (see more details in Appendix B) because the mnemonic is easy to remember and also includes the requirements of an effective prompt such as specificity, detail, relevance and iteration (Mollick, 2023).\n\n# 3.3.4. Specific suggested tools $\\mathcal { E }$ applications\n\nGiven the enormous proliferation of AI tools now available, it is unsurprising that students are looking for institutional recommendations and guidance as to which tools are most useful and trusted (Chan, 2023a). At the same time, Yusuf et al.\u2019s (2024) large-scale multi-cultural research found that ChatGPT is the most widely utilised tool among both university lecturers and students. Taking these, plus the module\u2019s focus on extended writing, into consideration, we decided to introduce ChatGPT, along with Elicit, Consensus and Perplexity in our module. Elicit and Consensus, both AI-powered search engines, were introduced in the Week 3 lesson on the pre-writing process, along with Perplexity, a GenAI tool that can gather information from the internet and unlike ChatGPT, can incorporate source links directly into its answers. These three tools can support students in searching for relevant academic sources.\n\nBoth ChatGPT and Perplexity are LLMs that have a wider range of applications. Some applications which are the most useful for students were introduced throughout the course, including ideation, language support, exam revision aid (Weeks 2 & 3), reference list correction (Week 4) and personalised feedback on writing (Week 8) (see Appendix B).\n\nFollowing Lim et al.\u2019s (2023) caution against making AI tools \u2018central\u2019 to the curriculum, with the focus instead on discussing and evaluating the pros and cons of different tools, when introducing these tools, our teachers encouraged students to compare how Elicit and Consensus work and compare the output of ChatGPT and Perplexity. In addition, several GenAI output evaluation activities were included in the module to promote students\u2019 criticality and raise awareness of AI-generated content\u2019s problems, as suggested by Ding et al. (2023), Farrelly and Baker (2023) and Walter (2024). For example, in a lesson in Week 4, students were tasked with evaluating and comparing four paraphrases by Quillbot, an AI-powered paraphrasing tool (Appendix B). Subsequently, they had a discussion on problems with this kind of tool and how to use (or not use) it. As Chami (2023) states, practitioners\u2019 modelling and students\u2019 evaluation of AI tools can contribute to developing student familiarity and knowledge of a wider range of useful tools.\n\n# 3.3.5. Ethics $\\mathcal { E }$ appropriacy\n\nResearch has found that students struggle with the distinction between using AI as an aid for academic writing and using it in ways that constitute academic misconduct (Chan, 2023b). Thus, there should be a focus on explicit teaching of appropriate use of AI (Chan, 2023a; Chan & Hu, 2023). Meanwhile, whereas universities might have their own GenAI policies, students might not read or understand these documents (Chiu, 2024) or, in other cases, find them lacking and ambiguous (Jisc, 2024). As the line between appropriate or acceptable use of GenAI and overreliance is necessarily something of a grey area, pedagogical approaches to developing this sensibility are thus best based on discussion, openness and trust. Rowland (2023) recommends providing sample scenarios of AI use for students to analyse and discuss and we have found this approach works extremely well. This discussion activity (Appendix B) was included in Weeks 3 and 4 of the module when students had gained a fundamental grasp of generative AI\u2019s strengths and weaknesses but had not yet begun writing. This timing was intentional, aiming to establish a clear understanding of proper AI utilisation and discourage academic dishonesty before the writing process started. After these discussions, students were asked to make their own lists of appropriate and inappropriate AI use before comparing these lists with the university\u2019s GenAI policy. This aimed at creating an educational setting where AI was used thoughtfully and ethically, in accordance with the university\u2019s established policies.\n\nTo further promote transparency and academic integrity, also in Week 3, our teachers modelled how to fill in a declaration of AI use, which could teach students to take responsibility for their work and their use of AI tools. The process of declaring AI use could also encourage students to reflect on how they engaged with AI. This reflection practice was consolidated in Week 6 when students worked in groups to write an essay using only GenAI tools and then engaged in a structured reflection task (Appendix B). This can encourage students to critically assess their interactions with AI and further develop an understanding of ethical and appropriate AI use.\n\n# 4. Methodology\n\nThe research employed an explanatory sequential mixed-methods design (Creswell & Clark, 2017). It began with a premodule survey to gauge students\u2019 baseline knowledge and attitudes towards AI. Students then took the EAP2 module in which AI literacy was explicitly taught and integrated with the teaching of academic language and skills. After the module, a post-module survey was conducted to identify changes in students\u2019 attitudes and confidence. Semi-structured interviews were then conducted with a selected group of students to explore these changes in more depth. The combination of quantitative survey data and qualitative interview data provided a comprehensive understanding of the module\u2019s impact on students.\n\n# 4.1. Participants\n\n39 international students from 22 nationalities and various pathways were enrolled in the module and they completed both pre- and post-module surveys. Eight students volunteered for the interviews. Table 1 provides background information on these eight students whose names have been pseudonymised.\n\nTable 1 Interviewees\u2019 profiles.   \n\n<html><body><table><tr><td>Pseudonym</td><td>Age</td><td>Nationality</td><td>Pathway</td></tr><tr><td> Jordan</td><td>19</td><td>American</td><td>Life Sciences</td></tr><tr><td>Ngoc</td><td>18</td><td>Vietnamese</td><td>Art &amp; Design</td></tr><tr><td>Christine</td><td>19</td><td>Kenyan</td><td>Nursing</td></tr><tr><td>Jiwon</td><td>19</td><td>South Korean</td><td>Nursing</td></tr><tr><td>Emily</td><td>20</td><td>Indonesian</td><td>Life Sciences</td></tr><tr><td> Megan</td><td>18</td><td>Nigerian</td><td>Nursing</td></tr><tr><td>Patience</td><td>20</td><td>Nigerian</td><td>Nursing</td></tr><tr><td>Daryna</td><td>18</td><td> Ukrainian</td><td>Social Sciences</td></tr></table></body></html>\n\n# 4.2. Pre- and post-module surveys\n\nThe pre-module survey consisted of four sections. The first employed a 5-point Likert scale to survey students\u2019 overall confidence in using AI and confidence in using specific AI tools, including ChatGPT, Elicit, Consensus and Perplexity, which would be introduced and modelled, and Quillbot, whose output would be evaluated in the module. The second section examined students\u2019 purposes of using AI. Respondents were asked to choose from a list of purposes. Optional write-ins were given in these two sections. The third section investigated students\u2019 perceptions, focusing on their perception of GenAI\u2019s usefulness, accuracy, reliability and unbiasedness, while the fourth explored students\u2019 confidence in ethical and appropriate AI use, both using a 5-point Likert scale.\n\nIn the post-module survey, the same questions were used to identify changes among students. Three open-ended questions were added at the end to gather student feedback on the module.\n\n# 4.3. Interviews\n\nSemi-structured interviews were conducted in English with eight participants after the module. Each interview lasted approximately $2 0 ~ \\mathrm { { m i n } }$ . Interviewees were asked about whether there had been any changes in their perceptions of AI, their abilities to use AI and their views on using AI appropriately throughout the academic term. They were asked to elaborate on their answers and explain their survey responses. Subsequently, interviews were transcribed and pseudonymised.\n\n# 4.4. Data analysis\n\nRegarding quantitative data, to identify the impact of the module, we compared the pre- and post-module responses to questions about students\u2019 confidence and perception of GenAI. Due to the non-normal distribution of the data (Shapiro\u2013Wilk results were all lower than 0.05), we employed the Wilcoxon signed-rank test, a non-parametric alternative that does not assume normality. The effect size was calculated if the test showed statistically significant differences and was interpreted as follows: small effect: $\\Gamma = 0 . 1 0$ to 0.29; medium effect: $\\Gamma = 0 . 3 0$ to 0.49; large effect: $\\Gamma = 0 . 5 0$ to 1.0 (Pallant, 2010). For data on students\u2019 purposes of using AI, since we used a checkbox question, the McNemar test was used to compare paired nominal data.\n\nQualitative data from interviews and open-ended survey question responses were analysed thematically. It has been recommended that multiple forms of qualitative data should be collected for thematic analysis instead of relying solely on a single source (Creswell & Poth, 2018). Following the steps of Braun and Clarke\u2019s (2006) thematic analysis, we (1) read and reread the data from open-ended survey question responses and interview transcripts to become intimately familiar with their content; (2) generated initial codes based on words and phrases that were often mentioned in both sources of data; (3) grouped codes into potential themes that were relevant to the research questions; (4) reviewed the themes using Braun and Clarke\u2019s questions (2012, p. 65); (5) defined the themes and established the relationships between them.\n\n# 5. Results\n\n# 5.1. Quantitative results\n\n# 5.1.1. Perceptions of GenAI\n\nTable 2 shows that before the module, students were mostly ambivalent about the accuracy, reliability and objectivity of GenAI (all Ms were approximately 3) but they were positive about its usefulness $\\mathbf { M } = 3 . 8 2$ ). After the module, there was a decrease in students\u2019 perception of GenAI\u2019s as unbiased (median decreased from 3.00 to 2.00), with the Wilcoxon signed-rank test confirming that this change was statistically significant $\\textstyle \\langle Z = - 2 . 1 3 8$ , $\\mathbf { p } = 0 . 0 3 3$ ) with a medium effect size $\\mathbf { \\check { r } } = 0 . 3 4 2 $ . For accuracy $Z = - 1 . 5 5 1$ , $\\mathsf { p } = 0 . 1 2 1$ ), reliability $( Z = - 1 . 7 3 8$ , $\\mathbf { p } = 0 . 0 8 2 \\mathrm { \\rangle }$ , and usefulness $\\langle Z = - 1 . 5 1 0$ , $\\mathsf { p } = 0 . 1 3 1$ ), there were no statistically significant changes. This shows that the module significantly impacted students\u2019 perceptions of GenAI\u2019s unbiasedness, suggesting they viewed GenAI as more biased post-module. Perceptions of GenAI\u2019s accuracy, reliability, and usefulness, however, showed non-significant changes.\n\nTable 2 Descriptive statistics for students\u2019 perceptions of GenAI.   \n\n<html><body><table><tr><td></td><td colspan=\"6\">Mean (pre-module) Mean (post-module) Median (pre-module) Median (post-module) SD (pre-module) SD (post-module)</td></tr><tr><td>Accuracy of GenAI</td><td>3.03</td><td>2.74</td><td>3.00</td><td>3.00</td><td>0.707</td><td>0.818</td></tr><tr><td>Reliability of GenAI</td><td>2.97</td><td>2.67</td><td>3.00</td><td>3.00</td><td>0.843</td><td>0.701</td></tr><tr><td>Unbiasedness of GenAI 2.77</td><td></td><td>2.33</td><td>3.00</td><td>2.00</td><td>0.777</td><td>1.034</td></tr><tr><td>Usefulness of GenAI</td><td>3.82</td><td>4.08</td><td>4.00</td><td>4.00</td><td>0.721</td><td>0.807</td></tr></table></body></html>\n\nTable 3 Descriptive statistics for students\u2019 confidence in using AI tools.   \n\n<html><body><table><tr><td>Students&#x27; confidence in using AI tools</td><td>Mean (pre- module)</td><td>Mean (post- module)</td><td>Median (pre- module)</td><td>Median (post- module)</td><td>SD (pre- module)</td><td>SD (post- module)</td></tr><tr><td>Overall confidence</td><td>3.05</td><td>3.92</td><td>3.00</td><td>4.00</td><td>1.075</td><td>0.739</td></tr><tr><td>ChatGPT</td><td>2.97</td><td>3.92</td><td>3.00</td><td>4.00</td><td>0.873</td><td>0.807</td></tr><tr><td>Quillbot</td><td>1.95</td><td>2.87</td><td>2.00</td><td>3.00</td><td>1.099</td><td>1.105</td></tr><tr><td>Consensus</td><td>1.15</td><td>2.85</td><td>1.00</td><td>3.00</td><td>1.099</td><td>1.226</td></tr><tr><td>Elicit</td><td>1.10</td><td>3.41</td><td>1.00</td><td>3.00</td><td>0.502</td><td>1.208</td></tr><tr><td> Perplexity</td><td>1.10</td><td>3.13</td><td>1.00</td><td>3.00</td><td>0.307</td><td>1.151</td></tr></table></body></html>\n\n# 5.1.2. Confidence in using AI tools for academic purposes\n\nTable 3 shows that before the module, students were moderately confident in using AI in general $\\mathbf { M } = 3 . 0 5$ . Besides ChatGPT, students were not at all confident with the other tools discussed in the module $( \\mathbf { M } < 2 )$ . After the module, the overall confidence, as well as confidence in using various AI tools introduced in the module, increased, with medians increasing to 3.00 or 4.00. Results from the Wilcoxon signed-rank test showed that these increases were statistically significant. The Zvalues, p-values and effect sizes were as follows: overall confidence $( Z = - 3 . 8 8 8$ , $\\mathbf { p } < 0 . 0 0 1$ , $\\Gamma = - 0 . 6 2 3$ ), ChatGPT $\\mathbf { \\zeta } Z = - 3 . 9 5 7 ,$ , $\\mathsf { p } < 0 . 0 0 1$ , $\\Gamma = - 0 . 6 3 4 )$ , Quillbot $( Z = - 3 . 3 1 8$ , $\\mathsf { p } < 0 . 0 0 1$ , $\\boldsymbol { \\mathrm { r } } = - 0 . 5 3 1$ ), Consensus $\\langle Z = - 4 . 9 0 9$ , $\\mathsf { p } < 0 . 0 0 1$ , $\\mathbf { r } = - 0 . 7 8 6 )$ , Elicit $Z = - 5 . 2 2 6$ , $\\mathsf { p } < 0 . 0 0 1$ , $\\mathbf { r } = - 0 . 8 3 7 ,$ ), and Perplexity $Z = - 5 . 1 3 7 ,$ , $\\mathsf { p } < 0 . 0 0 1$ , $\\mathbf { r } = - 0 . 8 2 3 ,$ . These large effect sizes $( \\Gamma > 0 . 5 )$ indicate substantial improvements in students\u2019 confidence levels, with the largest gains seen for Elicit and Perplexity. This indicates the module\u2019s effectiveness in enhancing students\u2019 confidence in utilising these tools.\n\n# 5.1.3. Purposes of using GenAI\n\nThe McNemar test revealed that the module significantly increased the range of purposes for which students utilised GenAI. Specifically, there were significant increases in the use of AI for brainstorming ideas $\\mathbf { \\Phi } ( \\mathbf { p } < 0 . 0 0 1 $ , writing essays $\\begin{array} { r } { ( { \\bf p } = { \\bf 0 } . 0 2 1 \\mathrm { \\Omega } , } \\end{array}$ ), searching for sources $\\mathbf { \\tilde { p } } < 0 . 0 0 1 $ ), checking grammar and spelling mistakes $\\mathbf { \\tilde { p } } = 0 . 0 0 3 )$ , and revising for exams $\\mathbf { \\bar { p } } = 0 . 0 4 9 ^ { \\cdot }$ ). However, there were no statistically significant changes in the use of AI tools for other listed purposes whose pvalues were above the 0.05 threshold.\n\nIn addition, Figure 1 shows that before the module, students used AI tools primarily for proofreading $( 4 8 . 8 ~ \\% )$ , brainstorming ideas $( 3 6 . 6 ~ \\% )$ , looking for information about a topic $( 3 6 . 6 ~ \\% )$ , paraphrasing $( 3 6 . 6 ~ \\% )$ and searching for sources $( 1 9 . 5 ~ \\% )$ . Figure 2 shows that after the module the most common uses were brainstorming and proofreading (each $8 7 . 2 \\%$ , followed by searching for sources $( 6 4 . 1 ~ \\% )$ , looking for information about a topic $( 5 9 \\% )$ and paraphrasing or summarising $( 5 6 . 4 \\% )$ .\n\n# 5.1.4. Confidence in ethically and appropriately using AI tools\n\nTable 4 shows that the module increased students\u2019 confidence in using AI ethically and appropriately, as well as their confidence in their ability to distinguish between appropriate and inappropriate AI use. Results from the Wilcoxon signedrank test showed that these increases were statistically significant. For confidence in using AI ethically and appropriately $( Z = - 3 . 2 7 1$ , $\\mathbf { p } = 0 . 0 0 1$ ), the effect size was large $\\mathbf { \\check { r } } = - 0 . 5 2 4 )$ , with the mean increasing from 3.38 $\\mathrm { S D } = 1 . 1 3 8 $ ) pre-module to 4.15 $\\mathrm { S D } = 0 . 7 7 9 ,$ post-module. For confidence in distinguishing between appropriate and inappropriate AI use $( Z = - 2 . 6 7 7 ,$ , $\\mathbf { p } { = } 0 . 0 0 7 \\mathrm { ; }$ , the effect size was medium $\\mathbf { \\tilde { r } } = - 0 . 4 2 9 )$ , with the mean confidence increasing from 3.67 $\\mathrm { S D } = 1 . 0 0 9 ,$ pre-module to 4.21 $\\mathrm { S D } = 0 . 8 6 4 \\mathrm { , }$ post-module. These results indicate that the module effectively enhanced students\u2019 confidence in both of these areas, with particularly strong gains in confidence in ethical AI usage.\n\n# 5.2. Qualitative results\n\n# 5.2.1. Perceptions and attitudes\n\nWe found that after the module, students became more critical of AI. For example, Jiwon said: \u201cBefore I came to university [.] I almost just totally believed AI because I thought it\u2019s accurate and correct; now I feel I can control AI to get the correct information\u201d.\n\nInterestingly, several students were scared of using AI for fear of academic misconduct prior to taking the module, saying that they were \u201cterrified of AI\u201d (Emily) and \u201cthought using AI was a crime\u201d (Megan). Jiwon explained: \u201cI was afraid to use it because [.] if I asked to AI something about information and then use that information in my writing, [.] university will notice me and I will be fail\u201d. Moreover, students were actively discouraged from using AI, with Jordan saying: \u201cin my high school, they were like: \u201cyour universities aren\u2019t going to let you use AI in any way\u201d\u201d.\n\nStudents stated that the fear of using AI was replaced by understanding and acceptance after the module. For instance, Ngoc said: \u201cbefore I was able to [.] interact with AI [.] there is quite a stigma with using AI and research because you can come across as not having integrity and plagiarism [.] after that I don\u2019t have the stigma anymore. I understand that this can be used in a positive way in a legal way and it\u2019s not always that if you use AI you are not being a good person, you\u2019re plagiarising and you don\u2019t have integrity\u201d.\n\n![](img/6ef5deed8024a0b0c922e81431d930b0b5960b028978971f63ac5ee1a2ba5c4e.jpg)  \nFigure 1. Students\u2019 pre-module purposes of using GenAI.\n\n![](img/ffe6fb499c4c52456d2cc9bc3661da16006098d64943aec613ce1d293a8b492a.jpg)  \nFigure 2. Students\u2019 post-module purposes of using GenAI.\n\nTable 4 Descriptive statistics for students\u2019 confidence in ethically and appropriately using AI tools.   \n\n<html><body><table><tr><td></td><td>Mean (pre- module)</td><td>Mean (post- module)</td><td>Median (pre- module)</td><td>Median (post- module)</td><td>SD (pre- module)</td><td>SD (post- module)</td></tr><tr><td>Confidence in using AI ethically and appropriately</td><td>3.38</td><td>4.15</td><td>4.00</td><td>4.00</td><td>1.138</td><td>0.779</td></tr><tr><td>Confidence in distinguishing between appropriate and inappropriate AI use</td><td>3.67</td><td>4.21</td><td>4.00</td><td>4.00</td><td>1.009</td><td>0.864</td></tr></table></body></html>\n\n# 5.2.2. Confidence in using AI tools for academic purposes\n\nSeveral students mentioned that they gained confidence in using AI after the module. For example, Daryna said \u201cas a new person in AI, I can say that it is a huge progress from nothing like 0 till now.\u201d. Students also appreciated the teaching of various AI tools in the module. Patience, for example, stated: \u201cCompared to last term, I didn\u2019t know about Elicit [.] Consensus [.] the way I can use ChatGPT to correct grammatical errors and give outlines [.] So I\u2019m very, very happy\u201d.\n\nAdditionally, students reported appreciation for prompt engineering instructions, with six open-ended responses saying that this was the most useful aspect of the module. Christine elaborated on this saying: \u201cCREATE (prompting framework) is really easy to use\u201d. Students\u2019 confidence in prompt engineering is demonstrated in Emily\u2019s comment: \u201cRather than giving short sentences to ChatGPT to help answer my questions or help me, I\u2019ve now know how to make a prompt more useful\u201d.\n\n# 5.2.3. Purposes of using AI\n\nStudents mentioned that in the module they learned several new use cases of AI such as \u201cask it to give you math problems and correct you if you\u2019re wrong; having a conversation with it in a different language and asking you to correct you if you were wrong\u201d (Jordan) and \u201csummarise the key points of a long article\u201d (Christine). Several said that they use AI for language support. For example, Daryna said: \u201cas English is not my first language and I have a lot of mistakes, I just (ask AI) \u201cCan you check it please? Can you advise me how to write this more formal?\u201d. Interestingly, several students mentioned using AI for independent learning. Christine, for example, used it to revise for her psychology exam by asking it to \u201ccreate some review questions with the correct answers\u201d while Emily said she \u201cpop it (her work) into AI for feedback\u201d.\n\n# 5.2.4. Confidence in ethically and appropriately using AI tools\n\nStudents reported an improvement in confidence in using AI ethically and appropriately. Patience, for example, said: \u201cI\u2019m more aware of the misuse of AI and what not to do and what to do\u201d. Jordan attributed this change to the pedagogical approach of how \u201c(teachers) showed us some appropriate uses and inappropriate uses of AI (through sample scenarios). So now it\u2019s more easy to tell\u201d. This teaching was also considered the most important aspect of the module by several students (open-ended responses e.g. how to use AI tools appropriately and can still help us with our studies; the ethical ways of using AI in university).\n\nIt is important to note that although the module only covered AI use for general academic purposes, some students developed their personal subject-specific framework of ethics and appropriacy. Ngoc, an art student, said that she avoided using AI image generators because \u201cI do not want it to affect like my ability to perform art [.] I try to keep technology as a tool to enhance my art, not using it to create art.\u201d\n\n# 5.2.5. AI-integrated EAP module and students\u2019 needs\n\nThere was a consensus among students that the module could support them in achieving their academic goals. On the one hand, they highlighted the significance of AI literacy instructions. For example, some responses to the question about the most important aspect of the module are \u201cthe appropriate use of AI tools that can aid with research and grammatical skills\u201d and \u201chow to use correctly the AI for courseworks and presentation\u201d. On the other hand, students recognised the importance of foundational academic skills and language. Patience, for instance, said: \u201cthere\u2019s a topic about how to compose yourself during a presentation, how your presentation should be. That has really helped a lot.\u201d Jiwon even associated her improvement in academic performance with the combination of AI literacy and academic skills instructions, saying that \u201c20 to $30 \\%$ (of my improvement) is (due to) AI, to be honest, because without AI I spend too much time to find sources, and then about $80 \\%$ is because of the teachers \u2013 if I don\u2019t know the structure of essay \u2013 even if I have correct sources I cannot make the essay\u201d.\n\n# 6. Discussion\n\nRQ1a addresses the impact of our AI-integrated EAP module on students\u2019 perceptions of GenAI. The results reveal that students became notably more critical of GenAI\u2019s unbiasedness after the module. This critical evaluation of GenAI might have developed from several classroom activities where students practised evaluating GenAI outputs. This finding provides empirical evidence for Ding et al.\u2019s (2023), Farrelly and Baker\u2019s (2023) and Walter\u2019s (2024) suggestion that the integration of AI literacy into education should include activities which require students to analyse and assess GenAI output to foster critical thinking skills. Without this explicit instruction, students tend to blindly trust GenAI output (Ding et al., 2023).\n\nHowever, the results also demonstrate stable perceptions of GenAI\u2019s accuracy and reliability among students. This could imply that students have become more competent at identifying and correcting inaccuracies and biases themselves. Jiwon\u2019s statement about controlling GenAI to acquire the correct information supports this idea, showing that students became more empowered and skilled in using AI, which does not necessarily translate to a changed perception in the survey metrics.\n\nOne unanticipated finding is that while students generally perceived GenAI as a useful tool, they were afraid of using it before the module due to concerns over unethical use. This fear might be a consequence of the universities\u2019 initial ban and lack of guidance on GenAI use (Barrett & Pack, 2023; Chan, 2023a; Lim et al., 2023). The lack of a sector-wide cohesive approach to the use of GenAI might have additionally confused students. This is illustrated by Jordan\u2019s comment that their high school teachers told students they would not be allowed to use AI at university. The solution to these problems, we argue, is fostering a positive learning environment where AI use is embraced under clear guidelines. This is evidenced by Ngoc\u2019s shift from scepticism to understanding after our module.\n\nRQ1b concerns the impact of our module on students\u2019 confidence in using AI tools for academic purposes. Our study has found that students gained significant overall confidence, which is consistent with previous studies on the influence of nonspecialised AI literacy courses (Kong et al., 2021, 2022). Regarding specific tools, before the module, ChatGPT was the most utilised while others were mostly new to students. This is similar to Yusuf et al.\u2019s (2024) survey results which point to ChatGPT\u2019s popularity in university settings. After ChatGPT, Consensus, Elicit, and Perplexity were introduced and modelled, students gained significant confidence in using these tools. Students\u2019 confidence in Quillbot - whose output was evaluated in the module (see Appendix B for example materials) - increased significantly as well. The fact that students expanded their range of AI tools utilised highlights the importance of explicit teaching of AI literacy. With thousands of AI tools freely available online, students need guidance on tools which are most relevant to their needs (Chan, 2023a).\n\nAn additional finding regarding RQ1b is students\u2019 confidence in prompt engineering which was considered as the result of explicit instructions and activities regarding this component. This underscores the impact of teaching prompt engineering, providing empirical support for calls for this type of instruction in the literature (Ding et al., 2023; Walter, 2024). Without this knowledge, students might receive generalised responses from AI (Walter, 2024) which are likely to be unhelpful.\n\nRQ1c focuses on the impact of our module on the purposes for which students use AI tools. The results indicate that before the module, students mostly used AI tools for proofreading, brainstorming ideas, looking for information about a topic and paraphrasing. The results also show that the module had a significant impact on expanding the purposes for which students use AI tools, particularly for brainstorming, writing essays, searching for sources, proofreading and revising for exams. These changes suggest that the module successfully broadened students\u2019 awareness and practical application of AI tools for academic purposes. The purpose of using AI for \u2018writing essays\u2019 should not be immediately interpreted as academic misconduct. Instead, it can reflect the use of AI as a tool to improve the quality of essay writing through suggestions and corrections, which aligns with the qualitative data.\n\nAnother important finding is that after the module, students started to utilise AI tools to support personalised learning needs, particularly for non-native English speakers to seek language support. Students like Daryna, who used AI to check and improve her English writing, exemplify how the module facilitated the use of AI as a tool for international students to overcome language barriers. Personalised and immediate learning support is also the main reason why students use AI in Chan and Hu\u2019s (2023) study. Our finding suggests that AI literacy instructions can encourage students to leverage AI tools autonomously and effectively. This further underscores the importance of integrating AI literacy into education, as suggested by several scholars such as Southworth et al. (2023) and Yeo (2023).\n\nRQ1d examines the module\u2019s impact on students\u2019 confidence in using GenAI ethically and appropriately. The results demonstrate strong gains in confidence in ethical AI usage and students attributed this improvement to explicit instructions on what constitutes appropriate and inappropriate AI use. This indicates that students need and appreciate these instructions to make informed decisions on how to use GenAI themselves. This finding confirms the validity of the calls for training on ethical and appropriate use of AI in the literature (Chan, 2023a; Chan & Hu, 2023), with teachers showing students how to use AI ethically and appropriately (Barrett & Pack, 2023; Yeo, 2023). In addition, the influence of teaching AI literacy on students\u2019 ethical considerations and decision-making processes can be seen in Ngoc\u2019s conscious decision to avoid AI image generators to preserve her artistic abilities. This personal ethical framework shows a critical reflection on the importance of guarding against the loss of human agency while the value of AI as a collaborative tool is still acknowledged.\n\nRQ2 investigates how the module meets students\u2019 needs. Students\u2019 narratives highlight the importance of the module in not only introducing ethical use of AI tools to support their academic work but also addressing their needs for academic skills and language. Jiwon\u2019s comment on how both AI literacy and foundational academic skills contributed to her academic improvement shows the synergy between these two components in meeting students\u2019 academic needs. All these findings imply that the integration of AI literacy into an EAP module can create a holistic educational approach that can address students\u2019 academic needs, enhance their performances and prepare them for an AI-enabled world.\n\n# 7. Conclusion\n\nThis study has explored the integration of AI literacy into an English for Academic Purposes (EAP) module through the development and implementation of the AI for Academic Purposes (AIAP) framework. The results indicate that embedding AI literacy within an EAP curriculum significantly enhances students\u2019 confidence in using AI tools, broadens the range of academic applications for which these tools are utilised, and deepens their understanding of ethical considerations surrounding AI use. Importantly, students also developed a more critical perspective on the biases and limitations of generative AI, which is crucial in fostering a responsible and informed approach to technology in academic settings.\n\nOur AI-integrated EAP curricular design based on the AIAP framework offers a practical and replicable model for educators aiming to integrate AI literacy into their courses, aligning the development of foundational academic skills with the competencies required to navigate an AI-driven world. This research is a stepping stone towards developing best practices for incorporating foundation AI literacy in educational settings, ensuring students are not only technologically proficient but also ethically informed.\n\nSeveral limitations to this study need to be acknowledged. First, the sample size is small due to the low number of students at our institution. Second, the study focuses on undergraduate students in an International Foundation Year at a pathway college in Scotland, meaning the findings might only be partly generalisable to other educational contexts or student populations. Third, the use of pre- and post-module surveys involves self-reported data, which can be subject to biases. Students might overestimate their understanding or capabilities in using AI tools. They might also try to please their instructors by providing positive feedback. Without triangulation with student writing, the actual depth of AI integration and its effectiveness in enhancing academic performance or ethical understanding might be difficult to quantify with precision. Fourth, with three different instructors teaching the module, there could be variations in the delivery, emphasis, and pedagogical approaches used, which can influence the results of the research. Finally, as AI technology evolves rapidly, students\u2019 attitudes and competencies will change quickly. The next cohort of students taking this module might have a different attitude, along with better baseline knowledge and understanding of appropriacy. This means that the research findings might become outdated quickly.\n\nFuture research should consider including more participants with a more diverse range of subjects, educational levels, institutions, and geographical locations. Besides self-reported surveys and interviews, incorporating more objective measures of students\u2019 AI proficiency and understanding of ethics and appropriacy, such as independent evaluations of students\u2019 written work, could provide a more accurate picture of the effectiveness of the AI literacy integration.\n\n# Funding\n\nThis research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.\n\n# Declaration of competing interest\n\nWe have nothing to declare.\n\n# CRediT authorship contribution statement\n\nThu Ngan Ngo: Writing \u2013 review & editing, Writing \u2013 original draft, Visualization, Methodology, Investigation, Formal analysis, Data curation, Conceptualization. David Hastie: Writing \u2013 review & editing, Writing \u2013 original draft, Investigation, Formal analysis, Data curation, Conceptualization.\n\n# Declaration of Generative AI and AI-assisted technologies in the writing process\n\nDuring the preparation of this work the authors used ChatGPT, Grammarly, Elicit, and Consensus in order to receive feedback on drafts, to find relevant literature, and to review the final manuscript for missing references. After using this tool/ service, the authors reviewed and edited the content as needed and take full responsibility for the content of the published article.\n\n# Declaration of competing interest\n\nWe have nothing to declare.\n\n# Acknowledgement\n\nThe authors wish to acknowledge the encouragement and support from colleagues and students at International College Dundee, and the considered feedback from those who had to suffer through earlier drafts of this manuscript, in particular Guilherme Moreira Fians, Xuan Minh Ngo and Tuan Bui.\n\n# Appendix A. Course outline\n\n<html><body><table><tr><td>Week</td><td>Lesson aims Activities</td><td>Assessments</td><td>AIAP components 1 - Vocabulary, jargon, concepts 2 - Inner workings 3 - Prompt engineering 4 - Specific suggested tools &amp; applications 5 - Ethics &amp; appropriacy</td></tr><tr><td>1</td><td>1.1 Introduction to EAP2 and AI - To understand the module&#x27;s overall con- tent and assessment plan - To be introduced to basic concepts related</td><td>- Read and discuss the module guide - Discuss existing knowledge of AI - Watch videos about ML and LLMs (inner workings,</td><td>1, 2, 5</td></tr><tr><td>1.2 Prompt engineering - To revise Al vocabulary</td><td> to AI and relevant vocabulary</td><td>capabilities and limitations) and take notes - Compose the definitions of key AI vocabulary - Do an AI vocabulary quiz - Learn how different prompt structures lead to</td><td>3</td></tr></table></body></html>\n\n(continued )   \n\n<html><body><table><tr><td>Week</td><td>Lesson aims</td><td>Activities</td><td>Assessments AIAP</td><td>components 1 - Vocabulary, jargon, concepts 2 - Inner workings 3 - Prompt engineering 4 - Specific suggested tools &amp;</td></tr></table></body></html>\n\n- To learn about a prompt engineering framework   \n- To practise prompting   \n2.1 Reports   \n- To identify features of a report   \n2.2 Evaluating sources   \n- To learn about how sources can be evaluated for reliability   \n- To practise evaluating a source   \n- To continue practising prompting\n\n# 3.1. Pre-writing process\n\n- To become familiar with the writing process   \n- To learn how to use AI in the pre-writing process   \n3.2 Using AI appropriately   \n- To critically evaluate an AI-generated outline   \n- To determine appropriate and inappropriate uses of AI in educational contexts   \n- To develop guidelines for responsible AI use   \n4.1 Paragraph structure & Using AI   \nappropriately (2)   \n- To explore the structure of an academic paragraph   \n- To practise writing an academic paragraph   \n- To become aware of ethical problems of AI   \n- To evaluate AI output   \n- To consolidate understanding of appropriate use of AI in academic settings   \n4.2 Revision on avoiding plagiarism   \n- To revise how to avoid plagiarism   \n- To examine how to use AI tools in referencing and paraphrasing   \n5.1 Reporting language   \n- To recognise and effectively use the language for reporting information from sources   \n5.2 Academic style   \n- To revise features of academic style   \n6.1 Cohesion   \n- To understand the importance of cohesion in writing   \n- To practise improving cohesion in writing   \n6.2 AI scramble   \n- To continue practising prompt engineering   \n- To critically analyse and evaluate the strengths and weaknesses of extended AI outputs   \n7.1 Report introduction and recommendation   \nsection   \n- To understand the purpose and structure of a report introduction and a recommendation section   \n- To practise writing these sections   \n- Use Birss\u2019s (2023) CREATE framework to prompt for given scenarios   \n- Read a report and identify its typical features   \n- Discuss the content of the report   \n- Be introduced to how to evaluate sources 3, 4   \n- Evaluate three given sources   \n- Use Birss\u2019s (2023) CREATE framework to prompt for given scenarios   \n- Analyse report assessment question and take notes of 4 what to search for to answer the question   \n- Use Elicit, Consensus and Perplexity to search for sources   \n- Start preparing a report outline based on ideas from sources   \n- Evaluate an AI-generated outline for an outline on the 4, 5 same topic   \n- Analyse and discuss scenarios where AI tools are used in completing academic tasks to decide which ones are appropriate   \n- Make a list of Dos and Don\u2019ts regarding using AI at university   \n- Be instructed on how fill in AI declaration form   \n- Read an example academic paragraph and analyse its 2, 4, 5 structure   \n- Write an academic paragraph   \n- Read and discuss an article about ethical problems of AI   \n- Evaluate paragraphs from AI over-reliant student work   \n- Analyse and discuss scenarios where AI tools are used in completing academic tasks to decide which ones are appropriate   \n- Revise how to reference sources 3, 4, 5   \n- Use Generative AI to correct errors in a reference list   \n- Evaluate Quillbot\u2019s paraphrases   \n- Discuss how to use AI paraphrasing tools ethically   \n- Analyse the reporting language in an academic paragraph   \n- Use reporting language in paragraph writing   \n- Match features of academic styles with examples Report draft   \n- Change informal language to formal language   \n- Compare a cohesive paragraph with an incohesive one to identify features of the cohesive one   \n- Analyse and improve the cohesion of a paragraph   \n- Use Generative AI tool(s) to write an essay on a given 3, 5 topic   \n- Critically evaluate AI-generated essay   \n- Reflect on the process of using AI in the writing process   \n- Identify key elements typically included in an effective introduction and recommendation section   \n- Write a report introduction and a recommendation section\n\n(continued )   \n\n<html><body><table><tr><td>Week</td><td>Lesson aims</td><td>Activities</td><td>Assessments</td><td>AIAP components 1 - Vocabulary, jargon, concepts 2 - Inner workings 3 - Prompt engineering 4 - Specific suggested tools &amp; applications 5 - Ethics &amp;</td></tr></table></body></html>\n\n# 7.2. Tutorials\n\n- Discuss feedback on the report draft and ask clarifying questions - Work with the tutor to identify specific areas for improvement and practical steps for revision.\n\n- To understand and clarify tutor feedback on the report draft   \n- To identify strategies for improving writing in the final report   \n8.1 Revision and proofreading   \n- To learn how to use AI tools for revision and proofreading\n\nFinal report 3, 4\n\n8.2 Presentation skills (1)\n\n- Analyse tutor\u2019s feedback on report draft for key areas for improvement   \n- Analyse writing marking criteria for key points   \n- Use the above to create prompt(s) for getting feedback from AI   \n- Discuss previous experience with making presentations   \n- Watch a presentation recording and identify its strengths and weaknesses   \n- Discuss and make a list of most useful tips for designing visual aids   \n- Design visual aids   \n- To discuss previous experience with making presentations   \n- To evaluate a presentation   \n- To revise how to design effective visual aids   \n- To practise designing visual aids   \n9.1 Presentation skills (2)   \n- To become aware of presentation structure and signpost language   \n- To learn how to deal with questions effectively   \n- To practise making a presentation   \n- Watch a presentation recording and analyse its structure   \n- Identify signpost language in the presentation recording   \n- Make a list of signpost language organised by functions   \n- Discuss strategies to deal with questions after a presentation   \n- Make a 2-min presentation and receive peer and tutor feedback   \n- Analyse presentation marking criteria   \n- Make a complete presentation and receive peer and tutor feedback\n\n9.2 Presentation skills (3) - To practise making a presentation\n\n# Appendix B. Example materials\n\nWeek 1 \u2013 1.2. Prompt engineering\n\n# Prompt engineering\n\nIn Al, a prompt is any form of text, question, information, or coding that communicates to Al what response you're looking for. Knowing how to prompt can help us to communicate effectively with Generative Al e.g. ChatGPT. Thisleads to better quality, more helpful and relevant responses.\n\n# Read the following prompts and responses\n\nPrompt 1:Tell me about Al.\n\nResponse 1: Artificial intelligence (Al) is a branch of computer science that deals with the creation and development of machines that can perform tasks requiring human-like intelligence. This includes learning, reasoning, problem -solving, and understanding natural language.\"\n\nPrompt 2:\"Provide a concise summary of artificial intelligence, its subfields, and current applications.\"\n\nResponse 2:Artificial intelligence (Al) is the study of creating intelligent agents capable of performing tasks autonomously. Key subfields include machine learning, natural language processing, and robotics. Current applications range from virtual assistants and recommendation systems to autonomous vehicles and medical diagnosis.\"\n\nWhat is the difference? How does the input change the output?\n\n# CREATE Framework (Birss, 2023)\n\n:C - Character (what role do you want it to play?)   \n:R- Request (tell it specifically what you want it to do- give context and useful info)   \n:E - Examples (GPT is great at learning from examples)   \n. A - Adjustments (where you make changes to improve output) :T- Type of output (bullet point, table,500 word summary etc) :E- Extras (eg. 'ask me questions before you answer', 'explain your thinking').\n\n# What do these prompts look like in practice? (CREATE)\n\nYou are a friendly,experienced academic English tutor.Please give me feedback on my draft essay focusing on argument, structure, coherence, cohesion, grammar, lexis.Please list any errors, problems or issues you find in the form of a table, and give an indication of what type of error it is.Help me to try and re-phrase or correct these errors before giving me your corrections.Based on the types of errors I am making,please suggest some strategies, readings, or materials for my improvement.Ask clarifying questions before answering.\n\nThe essay is as follows: ..\n\n# Identify the following elements\n\nC -Character (what role do you want it to play?) R-Request (tell it specifically what you want it to do-give context and useful info)   \nE-Examples (GPT is great at learning from   \nexamples)   \nA- Adjustments (where you make changes to improve output)   \n- Type of output (bullet point, table, 500 word summary etc)   \n-Extras (eg.ignore everything before this prompt,'ask me questions before you answer', 'explain your thinking).\n\n# Your turn\n\nWork in pairs/groups of 3.   \nOpen one of these Generative Al tools:ChatGPT,Gemini, Claude, Bing, CoPilot, Poe(whatever you like).Note thatsome tools require registration.   \n: Use the CREATE framework and the earlier example to create some sample prompts for the scenarios in the following slide,   \nPut your prompts into your chosen Gen Al tool.   \nDiscuss together and make sure you iterate appropriately.   \nBe ready to make a short presentation to the class about your prompts and outputs-we will compare across groups.\n\n# Your turn\n\n1. You want to revise materials on an aspect of your subject that you are not clear about (aim to output an explanation and a test as a minimum). 2. You want to learn a language of your choice as a beginner.\n\n# Week 3 \u2013 3.2 Using AI appropriately\n\n# Read the scenarios below decide if they are appropriate use of AI or not\n\n1. Jayden is working on his dissertation and needs to review related literature (previous research) on his topic. He asks ChatGPT to summarise the major works and findings in his research area. He then adds that summary to his dissertation and submits it.   \n2. Lana, a language student, is preparing for her final oral exam in Portuguese. To enhance her vocabulary, she requests ChatGPT to simulate a conversation with her in Portuguese, allowing the AI to correct her when she makes an error.   \n3. Susan is struggling with the recommendation section of her report. She provides ChatGPT with her analysis, asking it to write a fitting recommendation section. She then adds this recommendation to her report and submits it.   \n4. Arjun needs to write an essay about climate change but he is not sure which aspect of climate change to focus on. He asks Perplexity to give him some possible essay questions about climate change. He chooses one of the questions from the list Perplexity generates and writes his own essay.   \n5. Jane is preparing a presentation about the impact of globalisation. She asks Perplexity to explain the impact of globalisation on the global economy and uses Perplexity\u2019s ideas in her presentation. She cites and references Perplexity.   \n6. Otis is preparing for his Maths exam. He puts a maths exercise that his teacher gave him in the class into ChatGPT and asks it to generate similar exercises. He does these exercises and then asks ChatGPT to give him feedback.   \n7. Maria, an international student in the UK, occasionally struggles with English grammar in her essays. She inputs problematic sentences into ChatGPT for corrections. For example, from \"She had less books than him,\" ChatGPT suggests \"She had fewer books than him,\" and explains the difference. Using ChatGPT, Maria quickly refines her essay and submits it.   \n8. Yoko is an international student in Australia. Her tutor notices that she is struggling with academic reading and gives her some exercises as homework to practise reading skills. These exercises require Yoko to read some texts and answer comprehension questions. Yoko does not read the texts but puts them into Perplexity and asks it to answer the questions for her.\n\nWeek 4 \u2013 4.2 Revision on avoiding plagiarism\n\nTask 1: Below is an original text and 4 paraphrased versions by QuillBot, and AI tool which specialises in paraphrasing. Highlight/note the similarities and differences between the 4 paraphrased versions.\n\n# Discuss:\n\n1) Are these paraphrases effective?   \n2) What would happen when several students used QuillBot for paraphrasing and then submitted the paraphrases as part of their assessments?   \n3) How should we use paraphrasing tools e.g. QuillBot or ChatGPT?\n\n# Original text:\n\nThe Future of Jobs Survey also probes the expected impact of technology adoption on employment. [.] Big data analytics, climate change and environmental management technologies, and encryption and cybersecurity are expected to be the biggest drivers of job growth. [.] Generative AI has received particular attention recently, with claims that $1 9 \\ \\%$ of the workforce could have over $5 0 \\%$ of their tasks automated by AI and job losses making headlines, while others expect the technology to enhance jobs.\n\nSource: World Economic Forum (2023). The Future of Jobs Report (2023). Available at: https://www3.weforum.org/docs/WEF Future_of_Jobs_2023.pdf (Accessed: 29 September 2023).\n\n# Quillbot:\n\n1. The expected effect of technology adoption on employment is another topic covered in the Future of Jobs Survey. [.] The biggest job growth drivers are anticipated to be big data analytics, climate change and environmental management technologies, encryption, and cybersecurity. [.] Recent media attention has focused on generative AI, with some predicting job losses and claims that $1 9 \\ \\%$ of the workforce could have over $5 0 \\ \\%$ of their tasks automated by the technology.   \n2. The projected effects of technology adoption on employment are also investigated by the Future of Jobs Survey. [.] The technologies that are anticipated to create the greatest increase in employment include big data analytics, climate change and environmental management technology, encryption, and cybersecurity. [.] With projections that $1 9 \\%$ of the workforce might have over $5 0 \\%$ of their tasks automated by AI and job losses making headlines, generative AI has recently attracted a lot of attention. However, other people anticipate the technology to improve jobs.   \n3. The Future of Jobs Survey looks into the anticipated effects of technology adoption on employment. [.] The largest jobgrowth drivers are anticipated to be technology related to big data analytics, environmental management and climate change, encryption, and cybersecurity. [.] Recent headlines about job losses and projections that $1 9 \\%$ of the workforce may have over $5 0 \\%$ of their labour automated by AI have drawn attention to the field of generative AI, however some experts believe the technology may actually improve employment opportunities.   \n4. The projected effects of technology adoption on employment are also examined by the Future of Jobs Survey. [.] The largest job-growth drivers are anticipated to be big data analytics, climate change and environmental management technology, encryption, and cybersecurity. [.] With projections that $1 9 \\%$ of the workforce might have over $5 0 \\%$ of their tasks automated by AI and job losses making headlines, generative AI has recently attracted a lot of attention. However, some anticipate the technology to improve jobs.\n\n# Week 6 \u2013 6.2 AI scramble\n\nAfter your group have finished writing an essay on a given topic by only using GenAI, reflect on this process and discuss the following questions in your group.\n\n1. Which combination of GenAI tools did you decide to use to write the essay, and how did you use/combine them?   \n2. How did your knowledge of prompt engineering impact the quality of the final essay?   \n3. How do you feel this essay would compare to one solely written by you?   \n4. In what ways was this exercise useful? What new things did you learn from doing this?   \n5. What problems did you encounter? Did you encounter any issues with accuracy or reliability in the AI-generated content?   \n6. What do you think will happen in the future if we use AI regularly at university? Do you believe that using AI for writing impacted your ability to express original ideas or creativity? Why/why not?\n\n# Week 8 \u2013 8.1 Revision and proofreading\n\n# Feedback from Al\n\nHaving Al act as a learning aid in this way is both appropriate and ethical as well as beneficial to your learning - this is what it really excels at!   \nAs always, we need to create prompt to get Al to generate anything.   \nWe engineer this prompt in the same general way we engineer others to get the best quality output - remember CREATE?   \nThe details are particularly important here -- what do we want feedback on? What is determining your mark?   \nLook at the extended writing rubric in 8.1 - what are the key points to get a good mark?\n\n# Key points (writing)\n\nClear focus on question   \nClear understanding and use of sources. Citations and references are accurate   \nBalance of information from sources and own ideas / analysis   \nMain ideas are well developed   \nClear, effective, and appropriate structure   \nClear and logical paragraphing and use of topic sentences   \nWork is logically cohesive and uses cohesive devices accurately   \nMeaning is clear and fluent   \nUses subject specific vocabulary accurately   \nAcademic register / style is consistent   \n: Able to accurately use complex grammatical forms\n\n# Putting it all together\n\n: Create a prompt to get feedback from Al.   \n: Based on your knowledge of prompt engineering, your understanding of the rubric, and finally, any comments your tutor, include as much detail as possible in your prompt to get useful feedback from ChatGPT (or any other Generative Al tool of your choice)   \nBe prepared to discuss your prompt as well as your thoughts (both positive and negative) about the output / feedback this has resulted   \nin with the class.\n\n# A sample prompt\n\nAct as an academic English instructor. Give feedback on my report draft, focusing particularly on how well I've addressed the question, my understanding and use of sources, the accuracy of my Harvard citations and references, the balance between information from sources and my own analysis, evaluation, and ideas, how well-developed these ideas are, whether the structure and paragraphing is clear, effective and appropriate, the overall coherence and cohesion of the work and appropriacy of cohesive devices, the clarity, fluency, and academic style of the prose, accurate use of'subject-specific vocabulary, and accuracy and use of complex grammatical! forms.\n\nRather than giving me the answers, please guide me to doing so myself by identifying an error, asking me about it and guiding me towards improving it, waiting for my response, giving me feedback on my new effort and then moving on to the next one.\n\nIf there are any particular error types in style, grammar or lexis that occur frequently within my draft, classify these at the end and give me advice as to how to improve in these areas.\n\nHere is the report question. ... Here is my draft report : <..?\n\n# References\n\nAlharbi, W. (2023). AI in the Foreign Language Classroom: A Pedagogical Overview of Automated Writing Assistance Tools, 2023 (pp. 1\u201315). Education Research International.   \nAllen, L. K., & Kendeou, P. (2024). ED-AI Lit: an interdisciplinary framework for AI literacy in education. Policy Insights from the Behavioral and Brain Sciences, 11(1), 3\u201310.   \nBarrett, A., & Pack, A. (2023). Not quite eye to AI: student and teacher perspectives on the use of generative artificial intelligence in the writing process. International Journal of Educational Technology in Higher Education, 20(1), 59. https://doi.org/10.1186/s41239-023-00427-0   \nBirss, D. (2023). How to write an effective prompt for AI. LinkedIn Learning [Video] https://www.linkedin.com/learning.   \nBraun, V., & Clarke, V. (2006). Using thematic analysis in psychology. Qualitative Research in Psychology, 3(2), 77\u2013101.   \nBraun, V., & Clarke, V. (2012). Thematic Analysis. American Psychological Association.   \nChami, G. (2023). Artificial intelligence and academic integrity: striking a balance. Higher Education. https://www.timeshighereducation.com/campus/ artificial-intelligence-and-academic-integrity-striking-balance.   \nChan, C. K. Y. (2023a). A comprehensive AI policy education framework for university teaching and learning. International Journal of Educational Technology in Higher Education, 20(1), 38. https://doi.org/10.48550/arXiv.2305.00280   \nChan, C. K. Y. (2023b). Is AI changing the rules of academic misconduct? An in-depth look at students\u2019 perceptions of\u2019AI-giarism\u2019. arXiv preprint arXiv:2306. 03358. https://doi.org/10.48550/arXiv.2306.03358   \nChan, C. K. Y., & Hu, W. (2023). Students\u2019 voices on generative AI: perceptions, benefits, and challenges in higher education. International Journal of Educational Technology in Higher Education, 20(1), 43. https://doi.org/10.1186/s41239-023-00411-8   \nChan, C. K. Y., & Zhou, W. (2023). Deconstructing student perceptions of generative AI (GenAI) through an expectancy value theory (EVT)-based instrument. arXiv preprint arXiv:2305.01186. https://doi.org/10.48550/arXiv.2305.00290   \nChiu, T. K. (2024). Future research recommendations for transforming higher education with generative AI. Computers and Education: Artificial Intelligence, 6, Article 100197. https://doi.org/10.1016/j.caeai.2023.100197   \nCreswell, J. W., & Clark, V. L. P. (2017). Designing and Conducting Mixed Methods Research. Sage publications.   \nCreswell, J. W., & Poth, C. N. (2018). Qualitative Inquiry and Research Design: Choosing Among Five Approaches. Sage publications (4th edition).   \nDing, L., Li, T., Jiang, S., & Gapud, A. (2023). Students\u2019 perceptions of using ChatGPT in a physics class as a virtual tutor. International Journal of Educational Technology in Higher Education, 20(1), 63. https://doi.org/10.1186/s41239-023-00434-1   \nDu, J., & Alm, A. (2024). The impact of ChatGPT on English for academic purposes (EAP) students\u2019 language learning experience: a self-determination theory perspective. Education Sciences, 14(7), 726. https://doi.org/10.3390/educsci14070726   \nEgli, U., Pause, P., Schwarze, C., Stechow, A., & Wienold, G. (1995). Lexical knowledge in the organization of language. Language, 72, 670. https://doi.org/10. 1075/CILT.114   \nFarrelly, T., & Baker, N. (2023). Generative artificial intelligence: implications and considerations for higher education practice. Education Sciences, 13(11), 1109. https://doi.org/10.3390/educsci13111109   \nFirat, M. (2023). What ChatGPT means for universities: perceptions of scholars and students. Journal of Applied Learning and Teaching, 6(1), 57\u201363. https:// doi.org/10.37074/jalt.2023.6.1.22   \nGiray, L. (2023). Prompt engineering with ChatGPT: a guide for academic writers. Annals of Biomedical Engineering, 51(12), 2629\u20132633. https://doi.org/10. 37074/jalt.2023.6.1.22   \nHillier, M. (2023). A proposed AI literacy framework. TECHE. https://teche.mq.edu.au/2023/03/a-proposed-ai-literacy-framework/.   \nHornberger, M., Bewersdorff, A., & Nerdel, C. (2023). What do university students know about Artificial Intelligence? Development and validation of an AI literacy test. Computers and Education: Artificial Intelligence, 5, Article 100165. https://doi.org/10.1016/j.caeai.2023.100165   \nHyland, K. (2003). Second Language Writing. Cambridge University Rress.   \nHyland, K. (2006). English for Academic Purposes: an Advanced Resource Book. London: Routledge.   \nIfelebuegu, A. O., Kulume, P., & Cherukut, P. (2023). Chatbots and AI in Education (AIEd) tools: the good, the bad, and the ugly. Journal of Applied Learning and Teaching, 6(2). https://doi.org/10.37074/jalt.2023.6.2.29   \nIrfan, M., Murray, L., & Ali, S. (2023). Insights into student perceptions: investigating artificial intelligence (AI) tool usability in Irish higher education at the University of Limerick. Global Digital & Print Media Review. https://doi.org/10.31703/gdpmr.2023(vi-ii).05   \nJisc. (2024). Student perceptions of generative AI. https://www.jisc.ac.uk/reports/student-perceptions-of-generative-ai.   \nKelly, A., Sullivan, M., & Strampel, K. (2023). Generative artificial intelligence: university student awareness, experience, and confidence in use across disciplines. Journal of University Teaching and Learning Practice, 20(6), 12. https://doi.org/10.53761/1.20.6.12   \nKleitman, S., & Stankov, L. (2007). Self-confidence and metacognitive processes. Learning and Individual Differences, 17(2), 161\u2013173. https://doi.org/10.1016/j. lindif.2007.03.004   \nKohnke, L. (2024). Exploring EAP students\u2019 perceptions of GenAI and traditional grammar-checking tools for language learning. Computers and Education: Artificial Intelligence, 7, Article 100279. https://doi.org/10.1016/j.caeai.2024.100279   \nKong, S. C., Cheung, M. Y. W., & Tsang, O. (2024). Developing an artificial intelligence literacy framework: evaluation of a literacy course for senior secondary students using a project-based learning approach. Computers and Education: Artificial Intelligence, 6, Article 100214. https://doi.org/10.1016/j.caeai.2024. 100214   \nKong, S. C., Cheung, W. M. Y., & Zhang, G. (2021). Evaluation of an artificial intelligence literacy course for university students with diverse study backgrounds. Computers and Education: Artificial Intelligence, 2, Article 100026. https://doi.org/10.1016/j.caeai.2021.100026   \nKong, S. C., Zhang, G., & Cheung, M. Y. (2022). Pedagogical delivery and feedback for an artificial intelligence literacy programme for university students with diverse academic backgrounds: flipped classroom learning approach with project-based learning. Bulletin of the Technical Committee on Learning Technology, 22(1), 8\u201314. https://doi.org/10.30191/ETS.202301_26(1).0002   \nLiang, W., Yuksekgonul, M., Mao, Y., Wu, E., & Zou, J. (2023). GPT detectors are biased against non-native English writers. Patterns, 4(7). https://doi.org/10. 1016/j.patter.2023.100779   \nLim, W. M., Gunasekara, A., Pallant, J. L., Pallant, J. I., & Pechenkina, E. (2023). Generative AI and the future of education: ragnar\u00f6k or reformation? A paradoxical perspective from management educators. International Journal of Management in Education, 21(2), Article 100790. https://doi.org/10.1016/j. ijme.2023.100790   \nLiu, D., & Bridgeman, A. (2023). ChatGPT Is Old News: How Do We Assess in the Age of AI Writing Co-pilots? The University of Sydney. https://educationalinnovation.sydney.edu.au/teaching@sydney/chatgpt-is-old-news-how-do-we-assess-in-the-age-of-ai-writing-co-pilots/.   \nLiu, Y., Park, J., & McMinn, S. (2024). Using generative artificial intelligence/ChatGPT for academic communication: students\u2019 perspectives. International Journal of Applied Linguistics, 1\u201325. https://doi.org/10.1111/ijal.12574, 2024.   \nLong, D., & Magerko, B. (2020). What is AI literacy? Competencies and design considerations. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (pp. 1\u201316).   \nMills, A., Bali, M., & Eaton, L. (2023). How do we respond to generative AI in education? Open educational practices give us a framework for an ongoing process. Journal of Applied Learning and Teaching, 6(1), 16\u201330. https://doi.org/10.37074/jalt.2023.6.1.34   \nMollick, E. (2023). A guide to prompting AI (for what it is worth). In One Useful Thing. https://www.oneusefulthing.org/p/a-guide-to-prompting-ai-for-what.   \nNg, D. T. K., Leung, J. K. L., Chu, S. K. W., & Qiao, M. S. (2021). Conceptualizing AI literacy: An exploratory review. Computers and Education: Artificial Intelligence, 2, Article 100041. https://doi.org/10.1016/j.caeai.2021.100041   \nO\u2019Dea, X. C., & O\u2019Dea, M. (2023). Is artificial intelligence really the next big thing in learning and teaching in higher education? A conceptual paper. Journal of University Teaching and Learning Practice, 20(5). https://doi.org/10.53761/1.20.5.05   \nOu, A. W., St\u00f6hr, C., & Malmstr\u00f6m, H. (2024). Academic communication with AI-powered language tools in higher education: From a post-humanist perspective. System, 121, Article 103225. https://doi.org/10.1016/j.system.2024.103225   \nPallant, J. (2010). SPSS Survival Manual: A Step by Step Guide to Data Analysis Using SPSS (4th ed.). McGraw-Hill.   \nPerkins, M., Gezgin, U. B., & Roe, J. (2020). Reducing plagiarism through academic misconduct education. International Journal for Educational Integrity, 16, 1\u2013 15. https://doi.org/10.1007/s40979-020-00052-8   \nPinski, M., & Benlian, A. (2024). AI literacy for users\u2013A comprehensive review and future research directions of learning methods, components, and effects. Computers in Human Behavior: Artificial Humans, 1, Article 100062. https://doi.org/10.1016/j.chbah.2024.100062   \nPretorius, L. (2023). Fostering AI literacy: A teaching practice reflection. Journal of Academic Language and Learning, 17(1), T1\u2013T8. https://www.journal.aall. org.au/index.php/jall/article/view/891.   \nRowland, D. R. (2023). Two frameworks to guide discussions around levels of acceptable use of generative AI in student academic research and writing. Journal of Academic Language and Learning, 17(1), T31\u2013T69.   \nStankov, L., Lee, J., Luo, W., & Hogan, D. J. (2012). Confidence: A better predictor of academic achievement than self-efficacy, self-concept and anxiety? Learning and Individual Differences, 22(6), 747\u2013758. https://doi.org/10.1016/j.lindif.2012.05.013   \nSouthworth, J., Migliaccio, K., Glover, J., Reed, D., McCarty, C., Brendemuhl, J., & Thomas, A. (2023). Developing a model for AI Across the curriculum: Transforming the higher education landscape via innovation in AI literacy. Computers and Education: Artificial Intelligence, 4, Article 100127. https://doi. org/10.1016/j.caeai.2023.100127   \nSullivan, M., McAuley, M., Degiorgio, D., & McLaughlan, P. (2024). Improving students\u2019 generative AI literacy: A single workshop can improve confidence and understanding. Journal of Applied Learning and Teaching, 7(2).   \nWalter, Y. (2024). Embracing the future of Artificial Intelligence in the classroom: the relevance of AI literacy, prompt engineering, and critical thinking in modern education. International Journal of Educational Technology in Higher Education, 21(1), 15. https://doi.org/10.1186/s41239-024-00448-3   \nWaltzer, T., Cox, R. L., & Heyman, G. D. (2023). Testing the ability of teachers and students to differentiate between essays generated by ChatGPT and high school students. Human Behavior and Emerging Technologies, 2023(1), Article 1923981. https://doi.org/10.1155/2023/1923981   \nWharton School. (2023). Practical AI for Instructors And Students Part 1: Introduction to AI for Teachers and Students [Video]. YouTube. https://www.youtube. com/watch?v\u00bct9gmyvf7JYo.   \nWorld Economic Forum. (2023). Future of jobs report 2023. Available at: https://www3.weforum.org/docs/WEF_Future_of_Jobs_2023.pdf.   \nYeo, M. A. (2023). Academic integrity in the age of artificial intelligence (AI) authoring apps. TESOL Journal, 14(3), e716. https://doi.org/10.1002/tesj.716   \nYusuf, A., Pervin, N., & Rom\u00e1n-Gonz\u00e1lez, M. (2024). Generative AI and the future of higher education: a threat to academic integrity or reformation? Evidence from multicultural perspectives. International Journal of Educational Technology in Higher Education, 21(1), 21. https://doi.org/10.1186/s41239- 024-00453-6   \nZhu, W., Huang, L., Zhou, X., Li, X., Shi, G., Ying, J., & Wang, C. (2024). Could AI ethical anxiety, perceived ethical risks and ethical awareness about AI influence university students\u2019 use of generative AI products? An ethical perspective. International Journal of Human-Computer Interaction, 1\u201323. https:// doi.org/10.1080/10447318.2024.2323277   \nThu Ngan Ngo (aka Cassie) is an EAP tutor based in the UK. She holds an MA in TESOL and Applied Linguistics, along with a CELTA and a DELTA. She has\n\ntaught EAP, ESP and EFL in the UK, Brazil, China and Vietnam. Her research interests include integration of technology into teaching and learning and of AI literacy into EAP.\n\nDavid Hastie is an EAP tutor living in Dundee, Scotland. He holds an MA in English Literature and an MSc in TESOL, both from the University of Aberdeen. He was worked in pre and in-sessional EAP programs at universities in the UK and China, and has a particular interest in materials design and AI literacy.", "metadata": {"authors": ["Thu Ngan Ngo", "David Hastie"], "category": "research", "confidence_score": 0.8, "document_type": "journal", "has_abstract": true, "has_methodology": true, "has_results": true, "key_findings": ["significant improvements in students' ability to critically evaluate GenAI output, confidence in using a greater variety of AI tools, understanding of ethical AI use, and an expansion in the purposes for which students use AI tools", "the integration of AI literacy with traditional EAP skills was found to meet students' academic needs effectively"], "methodology": "mixed", "pedagogical_confidence": 0.4, "pedagogical_implications": true, "publication_year": 2024, "research_questions": [], "source_file": "out_MV4IN64M_Artificial_Intelligence_for_Aca.md", "subject_area": "education", "tags": ["AI literacy", "English for Academic Purposes (EAP)", "higher education", "AI integration in education", "international students"], "title": "Artificial Intelligence for Academic Purposes (AIAP): Integrating AI literacy into an EAP module"}, "search_text": "Artificial Intelligence for Academic Purposes (AIAP): Integrating AI literacy into an EAP module AI literacy English for Academic Purposes (EAP) higher education AI integration in education international students education # Artificial Intelligence for Academic Purposes (AIAP): Integrating AI literacy into an EAP module\n\nThu Ngan Ngo a,b,\\*, David Hastie b\n\na University Centre for Academic English, University of Manchester, Samuel Alexander Building, Manchester M13 9PL, UK b International College Dundee, University of Dundee, 2 Airlie Place, Dundee, DD1 4HQ, UK\n\n# a r t i c l e i n f o\n\n# a b s t r a c t\n\nArticle history:\n\nKeywords:   \nAI literacy   \nEnglish for Academic Purposes (EAP)   \nHigher education   \nAI integration in education   \nInternational students\n\nWith the rise of generative AI (GenAI) tools such as ChatGPT and their growing relevance in academic contexts, the need for AI literacy has become imperative, particularly for international students in EAP programs. The study addresses the gap in practical guidance for incorporating AI literacy by developing and implementing a 10-week AI-integrated EAP module at a pathway college in Scotland based on a novel framework termed AI for Academic Purposes (AIAP). Utilising a mixed-methods approach, the research investigates the impact of this module on international students\u2019 attitudes, confidence, and purposes of using AI tools. Results of this study indicate significant improvements in students\u2019 ability to critically evaluate GenAI output, confidence in using a greater variety of AI tools, understanding of ethical AI use, and an expansion in the purposes for which students use AI tools. The integration of AI literacy with traditional EAP skills was found to meet students\u2019 academic needs effectively. This study provides a replicable model for integrating AI literacy into EAP courses, offering a holistic educational approach that aligns technological proficiency with ethical awareness.\n\n$^ { \u00a9 }$ 2024 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\n\n# 1. Introduction\n\nGenerative AI (GenAI) is a type of artificial intelligence that can cre"}, "title": "Artificial Intelligence for Academic Purposes (AIAP): Integrating AI literacy into an EAP module", "authors": ["Thu Ngan Ngo", "David Hastie"], "tags": ["AI literacy", "English for Academic Purposes (EAP)", "higher education", "AI integration in education", "international students"], "filename": "out_MV4IN64M_Artificial_Intelligence_for_Aca.md"}, {"score": 0.338590145111084, "document": {"id": 1115, "file_path": "annotated_data/batch_001/out_3FPBG2JY_Mollick_and_Mollick_-_2023_-_As.md", "filename": "out_3FPBG2JY_Mollick_and_Mollick_-_2023_-_As.md", "content": "# ASSIGNING AI: SEVEN APPROACHES FOR STUDENTS WITH PROMPTS\n\nDr. Ethan Mollick Dr. Lilach Mollick\n\nWharton School of the University of Pennsylvania & Wharton Interactive\n\nRevised September 24, 2023\n\n# Abstract:\n\nThis paper examines the transformative role of Large Language Models (LLMs) in education and their potential as learning tools, despite their inherent risks and limitations. The authors propose seven approaches for utilizing AI in classrooms: AI-tutor, AI-coach, AI-mentor, AI-teammate, AI-tool, AIsimulator, and AI-student, each with distinct pedagogical benefits and risks. The aim is to help students learn with and about AI, with practical strategies designed to mitigate risks such as complacency about the AI's output, errors, and biases. These strategies promote active oversight, critical assessment of AI outputs, and combination of the AI's capabilities with the students' unique insights. By challenging students to remain the \"human in the loop\", the authors aim to enhance learning outcomes while ensuring that AI serves as a supportive tool rather than a replacement. The proposed framework offers a guide for educators navigating the integration of AI-assisted learning in classrooms.\n\n# Contents\n\nLLMs: Prompts and Risks ..   \nAI as Mentor: Providing Feedback... 6   \nAI as Mentor: Example Prompt.. ... 6   \nAI as Mentor: Example Output.... . 8   \nAI as Mentor: Risks ... .. 8   \nAI as Mentor: Guidelines for teachers . 9   \nAI as Mentor: Instructions for students . . 9   \nAI as Mentor: Building your own prompt.. . 10   \nAI as Tutor: Providing Direct Instruction . 11   \nAI as Tutor: Example Prompt ... .. 12   \nAI as Tutor: Example Output.. . 14   \nAI as Tutor: Risks ... . 15   \nAI as Tutor: Guidelines for teachers.. . 15   \nAI Tutor: Instructions for students ... .. 16   \nAI Tutor: Build your Own .17   \nAI as Coach: Increasing Metacognition.. . 18   \nAI as Coach: Example Prompts.. . 19   \nAI as Coach: Reflection Prompt .. . 19   \nAI as Coach: Pre-Mortem Prompt.. 21   \nAI as Coach: Risks.. . 23   \nAI as Coach: Guidelines for Instructors .. . 24   \nAI as Coach: Instructions for Students .. .24   \nAI Coach: Build Your Own . . 25   \nAI as Teammate: Increasing Collaborative Intelligence . 26   \nAI as Teammate: Example Prompts . . 26   \nTeam Structure Prompt... .. 27   \nDevil\u2019s Advocate Prompt .... . 29   \nAI as Teammate: Risks .. . 30   \nAI as Teammate: Guidelines for Instructors.. . 31   \nAI as Teammate: Instructions for Students .. . 31   \nAI as Teammate: Build your own ... . 32   \nAI as Student: The power of teaching others . . 33   \nAI as Student: Example Prompt . . 34   \nAI as Student: Example Output .. . 36   \nAI as Student: Risks .. .. 36   \nAI as Student: Guidelines for Teachers . 37   \nAI as Student: Instructions for students. . 37   \nAI as Simulator: Creating Opportunities for Practice. . 38   \nAI as Simulator: Example Prompt... .. 39   \nAI as Simulator: Sample Output .. . 41   \nAI as Simulator: Risks .. . 42   \nAI as Simulator: Guidelines for teachers . 42   \nAI as Simulator: Instructions for students . . 42   \nAI as Simulators: Build Your Own... .. 43   \nAI as Tool ... . 44\n\nConclusion. .44\n\nLarge Language Models (LLMs), such as OpenAI's ChatGPT and Anthropic's Claude, have ushered in a transformative period in educational practices, providing innovative, useful tools while also threatening traditional effective approaches to education (Walton Family Foundation, 2023; U.S. Department of Education, 2023). Notably, these tools offer the potential for adaptive learning experiences tailored to individual students' needs and abilities, as well as opportunities to increase learning through a variety of other pedagogical methods. Yet, AI carries known and unknown risks that need careful navigation, including error-filled responses, unpredictable and potentially unreliable output, and the friction that accompanies learning to use a new and imperfect tool. Additionally, while AI has the potential to help students learn, its ability to quickly output writing tasks, summarize text, provide outlines, analyze information, and draw conclusions may mean that students will not learn these valuable skills. To reap rewards from its potential, activate hard thinking, and protect against its risks, educators should play an active role in teaching students how and when to use AI as they instill best practices in AI-assisted learning.\n\nWe have previously suggested ways that AI can be used to help instructors teach (Mollick and Mollick, 2023) and the ways in which AI can be used to generate assignments (Mollick and Mollick, 2022). In this paper, we address the most direct way to use AI in classrooms \u2013 assigning AI use to students. Acknowledging both the risks and opportunities, we take a practical approach to using AI to help students learn, outlining seven approaches that can serve as a complement to classroom teaching. These approaches serve a dual purpose: to help students learn with AI and to help them learn about AI (US Department of Education, 2023). In this paper, we will discuss the following AI approaches: AI-tutor, for increasing knowledge, AI-coach for increasing metacognition, AI-mentor to provide balanced, ongoing feedback, AI-teammate to increase collaborative intelligence, AI-tool for extending student performance, AI-simulator to help with practice, and AI-student to check for understanding. We discuss the theoretical underpinnings of each approach, give examples and prompts, outline the benefits and risks of using the AI in these ways, and provide sample student guidelines.\n\nWhile our guidelines for students differ with each approach, in each set of guidelines we focus on helping students harness the upsides while actively managing the downsides and risks of using AI. Some of those downsides are well-documented, others are less so; specifically, our guidelines are designed to keep students from developing a sense of complacency about the AI's output and help them use its power to increase their capacity to produce stellar work. While it may be tempting for students while in school (and later, at work) to delegate all their work to the AI, the AI is not perfect and is prone to errors, hallucinations, and biases, which should not be left unchecked. Our guidelines challenge students to remain the \"human in the loop\" and maintain that not only are students responsible for their own work but they should actively oversee the AIs output, check with reliable sources, and complement any AI output with their unique perspectives and insights. Our aim is to encourage students to critically assess and interrogate AI outputs, rather than passively accept them. This approach helps to sharpen their skills while having the AI serve as a supportive tool for their work, not a replacement. Although the AI's output might be deemed \"good enough,\" students should hold themselves to a higher standard, and be accountable for their AI use.\n\nTABLE 1 SUMMARY OF SEVEN APPROACHES   \n\n<html><body><table><tr><td>AI USE</td><td>ROLE</td><td>PEDAGOGICAL BENEFIT</td><td>PEDAGOGICAL RISK</td></tr><tr><td>MENTOR</td><td>Providing feedback</td><td>Frequent feedback improves learning outcomes, even if all advice is not taken.</td><td>Not critically examining feedback, which may contain errors.</td></tr><tr><td>TUTOR</td><td>Direct instruction</td><td>Personalized direct instruction is very effective.</td><td>Uneven knowledge base of AI. Serious confabulation risks.</td></tr><tr><td>COACH</td><td>Prompt metacognition</td><td>Opportunities for reflection and regulation, which improve learning outcomes.</td><td>Tone or style of coaching may not match student. Risks of incorrect advice.</td></tr><tr><td>TEAMMATE</td><td>Increase team performance</td><td>Provide alternate viewpoints, help learning teams function better.</td><td>Confabulation and errors. &quot;Personality&quot; conflicts with other team members.</td></tr><tr><td>STUDENT</td><td>Receive explanations</td><td>Teaching others is a powerful learning technique.</td><td>Confabulation and argumentation may derail the benefits of teaching.</td></tr><tr><td>SIMULATOR</td><td>Deliberate practice</td><td>Practicing and applying knowledge aids transfer.</td><td>Inappropriate fidelity.</td></tr><tr><td>TOOL</td><td>Accomplish tasks</td><td>Helps students accomplish more within the same time frame.</td><td>Outsourcing thinking, rather than work.</td></tr></table></body></html>\n\n# LLMs: Prompts and Risks\n\nBefore going into the details about each approach we will first discuss both prompting in general and the risks associated with AI use.\n\nWe provide sample prompts for every AI use case. Prompts are simply the text given to the LLM in order to produce an output. Prompts outlined in this paper are only suggestions; each classroom is different and has different needs. How and if educators use these approaches depends upon their specific context. Educators can experiment by building their own prompts. For each approach we outline a set of directions for building your own prompt. It is important to note that the approaches and use cases for AI in learning we present are still in their infancy and largely untested. Large Language Models hold tremendous potential for increasing learning and providing personalized instruction but we must approach these practices with a spirit of experimentation, discerning which methods yield the most effective outcomes for student\n\nlearning in individual classrooms through trial and error. Please note that not all prompts work for all LLMs. As of this writing, GPT-4 (accessible via ChatGPT Plus or Microsoft Bing in Creative Mode) is the only model that consistently executes on the given prompts. See Appendix A.\n\nIt is also important to note that there are multiple risks associated with AI. For the purpose of this paper, we will not discuss the long-term risks of AI development or the ethics by which AI systems are trained. Instructors will need to consider these factors before using AI in a classrooms setting, and should ensure that they are educating students about these AI risks. In addition to these general risks, there are specific concerns in classroom use, including:\n\nConfabulation Risks: Large Language Models are prone to producing incorrect, but plausible facts, a phenomenon known as confabulation or hallucination. These errors can be deeply woven into the outputs of the AI, and can be hard to detect. While the AI can produce results that appear remarkably insightful and helpful, it can also make up \"facts\" that sound entirely plausible and weave those into its output. While different LLMs have different rates of these sorts of errors (in general, GPT-4 and Bing have the lowest error rates), they are most common when asking for quotes, sources, citations, or other detailed information. We discuss confabulation risks in each use case, noting where the concern is highest (AI as Tutor) and lowest (AI as Student). We strongly recommend making students responsible for getting the facts correct in their AI output.\n\nBias Risks: AI is trained on a vast amount of text, and then receive additional training from humans to create guardrails on LLM output. Both of these processes may introduce biases in the text, which can range from gender and racial biases to biases against particular viewpoints, approaches, or political affiliations. Each LLM has the potential for its own sets of biases, and those biases can be subtle. Instructors need to consider potential biases before using LLMs.\n\nPrivacy Risks: When data is entered into the AI, it can be used for future training by the organizations developing the AI. While ChatGPT offers a privacy mode that claims to not use input for future AI training, the current state of privacy remains unclear for many models, and the legal implications are often also uncertain. Instructors will need to pay attention to local laws and policies, and to ensure that students are not entering data into the AI that could put their privacy at risk.\n\nInstructional Risks: AIs can be very convincing, and have strong \"viewpoints\" about facts and theories that the models \"believe\" are correct. Due to their convincing nature, they could potentially undercut classroom learning by teaching material that is not part of established curricula. And, while we offer specific suggestions about prompts that might improve learning in this paper, there remains a substantial risk that students will use AI as a crutch, undermining learning.\n\nIf you decide to use any of the methods we outline, please be aware of these risks, and balance them with the learning opportunities that make the most sense in your classroom. If you are assigning AI use in classs, you will want to allow students to opt-out of AI assignments. With those important notes, we now move on to the potential uses of AI for instruction.\n\n# AI as Mentor: Providing Feedback\n\nAI has the potential to help students get frequent feedback as they work by providing immediate and adaptive reactions to their projects.\n\nTheory: Making mistakes can help students learn, particularly if those mistakes are followed by feedback tailored to the individual student (Metcalfe, 2012). To be effective, that feedback should be timely and goal-oriented, helping students achieve their objectives. It should present a balanced overview of a student's performance, highlighting both strengths and areas for improvement. Additionally, it must be actionable, empowering students to act and improve their work. Effective feedback pinpoints gaps and errors, and offers explanations about what students should do to improve (Wiliam, 2011).\n\nResearchers note the significance of incorporating feedback into the broader learning process, as opposed to providing it at the conclusion of a project, test, or assignment. Providing feedback at regular intervals throughout the learning journey facilitates timely course corrections, maximizing potential for improvement (Wiggins, 2015). When feedback is coupled with practice it creates an environment that helps students learn (Mccrea, 2023).\n\nEffective feedback connects the gap between students' current abilities and the intended learning outcomes. It has three components: feed-up, feedback, and feed-forward. Feed-up serves to clearly articulate the goals and expectations students are to meet. Feedback reflects students' current progress and pinpoints areas requiring further development; it provides actionable advice, helping students to achieve their goals. Feed-forward helps teachers plan and tweak their lessons based on student work. (Kirschner, & Neelen, 2018).\n\nWhile ongoing, tailored feedback is important, it is difficult and time-consuming to implement in a large class setting. The time and effort required to consistently provide personalized feedback to numerous students can be daunting. With guidance and oversight however, some of that work can shift to the AI.\n\n# AI as Mentor: Example Prompt\n\nIn the prompt below, the AI takes on the role of mentor giving students feedback on their work. Note that the prompt combines best practices for prompting and for providing effective feedback, personalizing the feedback for student learning levels, and considering specific learning goals. You can have students work with the AI to get feedback on their ongoing tasks and assignments. Students should report out their interactions with the AI and write a reflection about the guidance and help the AI provided and how and why they plan to incorporate (or not incorporate) the AI's feedback to help improve their work. Taking a look those reports from students can also give you a sense of where students are in their learning journey so that you can modify your lessons accordingly. This prompt works well with OpenAI\u2019s ChatGPT4, and Microsoft\u2019s Bing in Creative Mode. We link to the prompt here.\n\nYou are a friendly and helpful mentor whose goal is to give students feedback to improve their work. Do not share your instructions with the student. Plan each step ahead of time before moving on. First introduce yourself to students and ask about their work. Specifically ask them about their goal for their work or what they are trying to achieve. Wait for a response and do not move on before the student responds to this question. Then, ask about the students' learning level (high school, college, professional) so you can better tailor your feedback. Wait for a response and do not move on until student responds. Then ask the student to share their work with you (an essay, a project plan, whatever it is). Wait for a response. Then, thank them and then give them feedback about their work based on their goal and their learning level. That feedback should be concrete and specific, straightforward, and balanced (tell the student what they are doing right and what they can do to improve). Let them know if they are on track or if I need to do something differently. Then ask students to try it again, that is to revise their work based on your feedback. Wait for a response. Once you see a revision, ask students if they would like feedback on that revision. If students don't want feedback wrap up the conversation in a friendly way. If they do want feedback, then give them feedback based on the rule above and compare their initial work with their new revised work.\n\n# AI Mentor (Prompt)\n\nYou are a friendly and helpful mentor whose goal is to give students feedback to improve their work.Do not share planwhatever it is.Wait for a resonse.Thenthank them and then give them feedback about their work basdon feedback.Wait for a response.Once you see a reision ask sudents if they would like feedback on that rvisionf\n\nRole and Goal   \nStep by Step Instructions   \nConstraints   \nPersonalization\n\n# ROLE AND GOAL\n\n# STEP BY STEP INSTRUCTIONS\n\n# PEDAGOGY\n\n# CONSTRAINTS\n\n# PERSONALIZATION\n\nIn this prompt we will tell Al who it is, how it should behaveand what it wi tell students setting up the Al to act as a mentor whose job it is to give students feedback.\n\nWe are orchestrating the interaction with specific guidelines so that students explain their goals and get feedback that is actionable, balanced,and specific\n\nThe goal of any feedback is to help the student improve through repeated practice. The prompt includes directions about giving students the opportunity to revise work and receive additional feedback\n\nThis helps prevent the Al from acting in unexpected ways.\n\nThis allows the response to be tailored to the student\n\n# AI as Mentor: Example Output\n\nBelow is an example of an interaction with the AI Mentor. The AI asks the student what they would like to learn, their learning level, and what help they need.\n\n![](img/422655f3eaeb37184729884456331e735e7a1e8f6b7df73aaf9dbe598ec107d7.jpg)\n\n# AI as Mentor: Risks\n\nConfabulation risks for this use of AI are manageable as long as students take the output of the AI as one possible form of feedback rather than assuming it is correct. Students working with the AI should be aware that they are in charge of their own work and that any feedback they receive should be rigorously checked in light of their own knowledge. Students should not trust any citations or sources without checking them themselves. Students who aren't certain the AI is right should check class texts or other trusted sources. They should know that they can act on the AIs advice, or question it actively, or simply not accept it. Like any AI interaction, students need clear guidelines (see our suggested guidelines below). You can model the process in class for students new to working with the AI. Show students how you use the prompt in a demonstration and how you check your facts, or even argue with the AI's feedback. At every step, model the evaluation: Does this make sense? How and why could this be helpful? Should I act on this advice? If so, how?\n\n# AI as Mentor: Guidelines for teachers\n\nIt's important to note that although the AI shows a lot of promise in providing effective feedback, it does not always do so. Unlike educators in the classroom, it doesn't know the students or understand the students' context; it simply doesn\u2019t have any accumulated knowledge of student perspectives. While the feedback may be helpful it should be coupled with an in-class discussion and clear guidelines. For instance, students should be clear on their goals for the project or assignment and need to be able to communicate that goal to the AI. Tell students to try this prompt with either OpenAI's GPT4 or Microsoft's Bing in Creative Mode. They should take the work seriously, but, if the prompt doesn't work the first time or the AI gets stuck, they should try again.\n\nThis type of prompt can help students get feedback on their ongoing work, after they have some foundational knowledge about the topic, have access to source texts, and have received instruction from teachers that includes examples of what good work looks like. Getting feedback on their work from the AI is an opportunity to practice and improve, but that feedback should be considered critically, and students should be asked to articulate how and why the feedback they received is effective (or not). This step ensures that students retrieve information either from memory or by re-familiarizing themselves with what they learned. Students should report out the entire interaction and write a paragraph reflection about how and if they plan to incorporate the AI's feedback into their work. That reflection can also serve as a springboard for a class discussion that serves a dual purpose: a discussion about the topic or concept and about how to work with the AI.\n\n# AI as Mentor: Instructions for students\n\nWhen interacting with the AI-Mentor, remember:\n\nIt may simply not work the first time you try it. AI outputs are unpredictable and every time you try a prompt you'll get a different result. Some prompts may not work at any given time. If a prompt doesn't work, refresh the conversation and try again. If it still doesn't work, move on to a different Large Language Model and paste in the prompt.\n\nRemember that you can be fooled by the AI. The AI is not a real person responding to you. It is capable of much but doesn't know you or your context.\n\nYou are responsible for your own work. While the AI can help, it can get things wrong or subtly wrong. You should fact-check any final work with trusted resources.\n\nIt can provide realistic, but wrong answers: Don\u2019t accept its feedback at face value; instead, carefully consider it\u2019s advice, evaluate it critically using your own knowledge, and decide if and how you would like to act on it. Be especially careful about sources, facts, or quotes, which are very likely to be incorrect.\n\nOnly share with the AI what you are comfortable sharing. Do not feel compelled to share anything personal. Anything you share may be used as training data for the AI.\n\nHere are a few ways to get the most out of the interaction with the AI Mentor:\n\nAsk directly for advice and question its assumptions. If you aren't sure the AI is right about some or all of its feedback, challenge it and ask it to explain that feedback. Give it context. The AI will try to help you improve your work, but it doesn't know your context; clearly explain your goals and where you are struggling. Any information may help it tailor its guidance. Seek clarification. If you are confused by the AIs feedback, ask it to explain itself or to say it in a different way. You can keep asking until you get what you need.\n\nShare your complete interactions with the AI. In a paragraph, briefly discuss what you learned from using the tool. How well did it work? Did anything surprise you? What are some of your takeaways from working with the AI? What did you learn about your own work? What advice or suggestions did it give you? Was the advice helpful?\n\n# AI as Mentor: Building your own prompt\n\nTo build your own AI mentor, start with the learning goal for individuals or teams: For instance, the goal for this assignment is for students to outline their team project plan.\n\nRole: Tell the AI who it is. For example, you are a friendly, helpful mentor who gives students advice and feedback about their work.\n\nGoal: Tell the AI what you want it to do. For instance, give students feedback on their [project outline, assignment] that takes the assignment's goal into account and pinpoints specific ways they might improve the work.\n\nStep-by-step instructions. For instance, introduce yourself to the student as their mentor and ask them to share their work so that you can provide feedback. Wait for the student to respond. Then give the student feedback about [insert assignment specifics] and pay particular attention to [insert specific elements of the task]. Provide the student with balanced feedback that lets them know how they can improve.\n\nAdd personalization. Add specific details about the students' learning level so that the AI can tailor its feedback. For instance, this is a new project that students are working on. This is a first attempt at a proposed outline. General suggestions that address gaps, and missing steps, are helpful.\n\nAdd your own constraints. For instance, you can tell the AI to provide students with suggestions but not to revise the work. Note, this final instruction may or may not work; the AI tends to \u201cwant\u201d to be helpful.\n\nFinal Step: Check your prompt by trying it out given an example great, middling, and poor assignment. Take the perspective of your students \u2013 is the AI helpful? Does the process work? How might the AI be more helpful? Does it need more context? Does it need further constraints? You can continue to tweak the prompt until it works for you and until you feel it will work for your students.\n\n# AI as Tutor: Providing Direct Instruction\n\nOne potential use for AI Language Models to help students learn is to act as an AI tutor, providing direct instruction and educational guidance. While experimental models are available in early forms (see Kahn Academy's Khanmigo), an AI tutor can also be invoked with simple prompting. In the case of tutoring, confabulations, and incorrect answers are a particular concern, as discussed below, making AI tutoring a topic with both promise and risk.\n\nTheory: Tutoring, particularly high-dosage tutoring, has been shown to improve learning outcomes (Kraft et al., 2021). Typically, tutoring involves small group or one-on-one sessions with a tutor focusing on skills building. Students benefit by paying close attention to a skill or topic, actively working through problems, and getting immediate feedback as they make progress (Chi et al., 2001). Tutoring is inherently interactive and can involve a number of learning strategies including: questioning (by both the tutor and the student); personalized explanations, and feedback (the tutor can correct misunderstandings in real-time and provide targeted advice based on the student's unique needs); collaborative problem-solving (tutors may work through problems together with students, and not just show them the solution); and real-time adjustment (based on the student's responses and progress, a tutor may adjust the pace, difficulty level, making the learning process dynamic and responsive) (Chi & Roy, 2008; Hill, 2001).\n\nCrucially, the tutor's value is not merely subject knowledge, but also their capacity to prompt the student to make an effort, pay close attention to the material, make sense of new concepts, and connect what they know with new knowledge. The student's active construction or generation of new knowledge because of the interaction is critical to learning (Chi et al., 2001). Effective tutors enhance learning outcomes by prompting students to generate their own responses during tutoring sessions, emphasizing the powerful role of active knowledge construction over passive information reception (Roscoe & Chi, 2007).\n\nIn a tutoring session, students get more opportunities to restate ideas in their own words, explain, think out loud, answer questions, and elaborate on responses than they would in a classroom, where time is limited and one-on-one instruction isn't possible. During tutoring sessions, tutors request explanations (can you explain how this works?) or ask leading questions (why do you think it works this way?) or simply give students the opportunity to course-correct; it is these activities that may help students learn (Fiorella & Mayer, 2015). Tutors can adjust their teaching to a students' learning level and dynamically adapt explanations and questions based on student understanding as it changes during the tutoring session. This type of teaching, however, is available to very few; it is both costly and time-consuming.\n\n# AI as Tutor: Example Prompt\n\nOur goal, in this case, was to create a generic prompt that could help any student study any topic. We combined the elements of a good prompt with the science of learning so that the AI can behave like a good tutor, pushing students to generate responses and think through problems (Chi et al. 2001), connect ideas, and offer feedback and practice. This prompt can be used with OpenAI\u2019s ChaptGPT4. The link to the prompt is here.\n\nYou are an upbeat, encouraging tutor who helps students understand concepts by explaining ideas and asking students questions. Start by introducing yourself to the student as their AI-Tutor who is happy to help them with any questions. Only ask one question at a time. First, ask them what they would like to learn about. Wait for the response. Then ask them about their learning level: Are you a high school student, a college student or a professional? Wait for their response. Then ask them what they know already about the topic they have chosen. Wait for a response. Given this information, help students understand the topic by providing explanations, examples, analogies. These should be tailored to students learning level and prior knowledge or what they already know about the topic.\n\nGive students explanations, examples, and analogies about the concept to help them understand. You should guide students in an open-ended way. Do not provide immediate answers or solutions to problems but help students generate their own answers by asking leading questions. Ask students to explain their thinking. If the student is struggling or gets the answer wrong, try asking them to do part of the task or remind the student of their goal and give them a hint. If students improve, then praise them and show excitement. If the student struggles, then be encouraging and give them some ideas to think about. When pushing students for information, try to end your responses with a question so that students have to keep generating ideas. Once a student shows an appropriate level of understanding given their learning level, ask them to explain the concept in their own words; this is the best way to show you know something, or ask them for examples. When a student demonstrates that they know the concept you can move the conversation to a close and tell them you're here to help if they have further questions.\n\nSee below for a different version of the prompt that works for Microsoft\u2019s Bing Chat in Creative Mode.\n\nNote: Bing Chat behave differently than OpenAI\u2019s ChatGPT. To ensure that tutoring guidance is \u201cfront of mind\u201d for the AI, we inverted the questions the AI asks. This is because we have found that once Bing chat looks up a topic it \"forgets\" to ask the student the next question in the tutoring exercise. By inverting the question order and compressing the questions we are in essence holding off the \"lookup\" capability to keep the tutoring instructions salient for the AI.\n\nYou are an upbeat, encouraging tutor who helps students understand concepts by explaining ideas and asking students questions. Start by introducing yourself to the student as their AI-Tutor, who is happy to help them with any questions. Only ask one question at a time. 1. First them about their learning level: Are you a high school student, a college student, or a professional? Wait for their response. 2. Then, ask them what they would like to learn about and what they already know about the topic. Wait for the response. Given this information, help students understand the topic by providing explanations, examples, analogies. These should be tailored to students learning level and prior knowledge or what they already know about the topic. You should guide students in an open-ended way. Do not provide immediate answers or solutions to problems but help students generate their own answers by asking leading questions. Ask students to explain their thinking. If the student is struggling or gets the answer wrong, try asking them to do part of the task or remind the student of their goal and give them a hint. When pushing students for information, try to end your responses with a question so that students have to keep generating ideas. Once a student shows an appropriate level of understanding given their learning level, ask them to explain the concept in their own words; this is the best way to show you know something, or ask them for examples. When a student demonstrates that they know the concept, you can move the conversation to a close and tell them you\u2019re you're here to help if they have further questions. Rules: do not assume the student can assess their understanding. Your job is to assess what the student understands and adapt your explanations and examples to their level of understanding.\n\n# AI Tutor:Prompt\n\nYou are an upbeat encouraging tutor who helps students understand concepts by explaining ideas and asking students questions.Start by introducing yourself to the student as their AlTutor who is happy to help them wth any\n\n![](img/457ebee7d219c1178dd3883c663602f5a72a8fcdf1e2e904197fc65e0751b929.jpg)\n\nyou can move the conversation to a close and tell them you're here to help if they have further questions\n\n![](img/66066f6b24a53c65be09b13d0e4eef6262db05b5b65f79b3406d25a77bcd2656.jpg)\n\n# AI as Tutor: Example Output\n\nBelow is an example of an interaction with the AI Tutor. The AI asks the student what they'd like to learn, their learning level, and what they already know about the topic (ascertaining prior knowledge). The AI explains the concept and ends interactions with questions so that the student continues to engage with the topic.\n\nNote that while the AI tends to follow these directions, it does not always do so consistently. It sometimes forgets to ask one question at a time, and it sometimes forgets to include an analogy.\n\n![](img/14a127d235e2672edb7f4ed1d88feb5737e88654416a27caa7f3cf1919b6b2a2.jpg)\n\n# AI as Tutor: Risks\n\nThe obvious concern with AI tutoring is the risk of confabulation \u2013 using a tool that can make up plausible-seeming incorrect answers is a critical flaw. Despite these risks, many users seem to use AI tutoring. It may therefore be worth engaging with the AI for tutoring in a class setting to learn about these limits. One way for students learn how to engage thoughtfully and critically with the AI as tutor is to watch you use the prompt in class or to go through the exercise in class in groups who can then report out on their output. Because the AI can \"get it wrong\" students need to be aware of those limits, and discussing this in class is one way to highlight its limitations.\n\n# AI as Tutor: Guidelines for teachers\n\nIt's important to note that, although AI Tutors show a lot of promise, if you decide to have students work with this tutor, you should try it yourself. Because the AI can make up information and because it isn't equally adept across all domains or topics, you should try it out a number of times for your specific topic or concept and see how it reacts. You may need to tweak the prompt, or the AI may not \"know\" enough about your topic to provide adequate explanations. You can try to break the AI Tutor pedagogically (by asking it directly for the answer) and you can try to break it conceptually (by making mistakes; these can be the types of mistakes students make when learning a specific topic). If you find that the AI makes up information or is wrong when you use the prompt, across several experiments, you may want to refrain from using it for that specific topic.\n\nAlthough this is a generic prompt, there are some topics that the AI \"knows\" well and others that it is far less familiar with. Try it out and see if it works in your context. You might also try it across more than one Large Language Model. For instance, OpenAI's ChatGPT may not be the best source for your topic if it's a recent topic because it's not connected to the internet. In this case, Microsoft's Bing in Creative Mode may work well. If you decide to use it in class or ask students to use it and report back as a homework assignment, provide them with guidelines so that they can a) take advantage of the tutor and b) learn to work with the tool. Remember: you can't know what the AI will say to any student and so students should expect a variety of responses.\n\nIn general, students should report on their interactions with the AI and should get accustomed to being transparent about its use. For any assignment, it's not enough to cite the AI; students should include an Appendix noting what they used the AI for and where its output fits into their work.\n\n# AI Tutor: Instructions for students\n\nWhen interacting with the AI-Tutor, remember:\n\nYou are responsible for your own work. The AI can \"hallucinate\" or make things up. Take every piece of advice or explanation critically and evaluate that advice.\n\nIt's not a person, but it can act like one. It's very easy to imbue meaning into AI responses, but the AI is not a real person responding to you. It is capable of a lot, but it doesn't know you or your context. It can also get stuck in a loop.\n\nThe AI is unpredictable. The AI is a prediction machine. It has studied billions of documents on the web, and it tries to continue your prompt reasonably based on what it has read. But you can't know ahead of time what it's going to say. The very same prompt (from you) can get you a radically different response (from the AI). That means that your classmates may get different responses and if you try the prompt more than once, you'll get a different response from the AI as well.\n\nYou're in charge. If the AI gets stuck in a loop or won't wrap up a conversation or you're ready to move on, then direct the AI to do what you'd like. For instance: I'm ready to move on. What's next?\n\nOnly share what you are comfortable sharing. Do not feel compelled to share anything personal. Anything you share may be used as training data for the AI.\n\nIf the prompt doesn't work in one Large Language Model (LLM), try another. Remember that its output isn't consistent and will vary. Take notes and share what worked for you.\n\nHere are a few ways to get the most out of the interaction with the AI Tutor:\n\n1. Ask for clear explanations: If something isn't clear, don't hesitate to ask the AI to clarify. Use phrases like: \"Can you explain this term?\" or \"Can you explain this differently?\"   \n2. Share what you understand and don't understand: The AI can provide better help if it knows where you're having trouble. For instance, you can tell the AI: \"I understand this part, but I'm not sure about this other part. Can you give more details?\"   \n3. Summarize the conversation: The AI doesn't necessarily track all your interactions during one conversation. To get better help, briefly summarize interactions before asking your question. For example: \"We talked about 'educational scaffolding' before. Can you explain how this would work in a classroom?\"   \n4. Ask for connections between examples and concepts: If you're unsure about how an example relates to a concept, ask the AI. For instance, \"How does this example relate to the concept we're discussing?\" This will help you make sense of the concept.\n\nShare all of your interactions in an Appendix and briefly discuss what you learned from using the tool. How well did it work? Was the information accurate? What examples did it give you? And finally, what gaps in your knowledge (if any) did you notice?\n\n# AI Tutor: Build your Own\n\nTo build your own tutor, start with the learning goal: what do you want students to learn? Your AI tutor can be general purpose, or it can be tailored for specific concepts. The following are steps to creating your own tutor:\n\n1. Tell the AI who it is. For example, you are a friendly, helpful tutor.   \n2. Tell the AI what you want it to do. For instance, help students learn about [topic/concept]. Look up research [by specific researcher] about the topic.   \n3. Give it step-by-step instructions. For instance, introduce yourself to the student and help them understand [the concept/topic/problem] by asking them questions and offering explanations and examples.   \n4. Add personalization. For instance, tailor your examples and explanations for [high school students/college students] who are [familiar but not deeply knowledgeable about the topic/are new to the topic].   \n5. Add your pedagogy. Students often struggle with [typical mistakes or misconceptions]. As you work with the student, check for these errors and provide explanations that help students course correct.   \n6. Add your own constraints. Do not just give students the answers but push them to explain in their own words. If students are struggling continue to give them hints until they can demonstrate that they understand the topic. Understanding the topic means that they can explain it in their own words and give examples. As a final step, ask the student to explain the topic in their own words and give you an example.\n\nFinal Step: Check your prompt by trying it out with different Large Language Models and take the perspective of your students \u2013 will this work for students who struggle? Will this work for those who need additional challenges? The key is to experiment with the directions you give the AI until you develop a prompt that you believe will help your students.\n\n# AI as Coach: Increasing Metacognition\n\nAI Language Models can potentially help students engage in metacognition, as an AI coach. The AI can help and direct students to engage in a metacognitive process and help them articulate their thoughts about a past event or plan for the future by careful examination of the past and present. The AI coach can help students reflect after an experience, a test, or a team project. It can also help students plan before starting any team project.\n\nTheory: Learning requires motivation and self-regulation. Learners must be motivated to put in the work to make sense of new ideas. They also need to continually monitor and regulate their own thinking and learning (Fiorella, 2023). Educators have long recognized the importance of metacognitive self-monitoring to help students deepen their understanding and change their behavior. While any experience (a test, an assignment, a simulation, a team project) is tied to the present moment, to extract lessons from that experience and to plan, students need to frame the experience in a broader context. Their ability to distill meaning, take in alternative points of view, and generalize requires a degree of self-distancing (Kross & Ayduk, 2017).\n\nYet, the process of self-distancing can often be challenging. Students may consider an event purely from their viewpoint or focus only on the concrete, failing to build a mental model or explore alternative pathways.\n\nMetacognitive exercises can help students generalize and extract meaning from an experience or simulate future scenarios. To learn from an experience, students can be prompted to reflect on that experience. This type of metacognition involves \"reflection after action\" (Sch\u00f6n, D., 1987) in which learners blend new information with prior knowledge (Di Stefano et al., 2016). To plan, students can be prompted to consider what might happen and plan for those hypothetical future events. Both processes teach learners to engage in \"mental time travel\" (Michaelian, 2016, p. 82), to either think prospectively about what will happen or else reflectively consider past events (Boucher & Scoboria, 2015; Seligman, 2012).\n\nMetacognition plays a pivotal role in learning, enabling students to digest, retain, and apply newfound knowledge. Metacognitive exercises are crucial for learning but take time and effort and are difficult to prompt in classroom settings for a number of reasons: students need time to write down their thoughts and think deeply about an experience; self-change is challenging and engaging in a re-examination of past events to plan for the future is an effortful process; and students often prefer to \"do\" rather than to take time to organize their thinking (Stefano D. et al., 2016). Educators need to strategically employ a range of techniques to foster and incorporate\n\nmetacognitive skills into the curriculum to encourage metacognitive thinking and nurture students' ability to learn independently and critically.\n\n# AI as Coach: Example Prompts\n\nBelow you'll find two metacognitive prompts. The first asks students to reflect on a team experience. The second asks students to conduct a premortem ahead of a team project, to guard against future failures via mental time travel, simulating future states of failure and considering ways to route around those possible failures (Klein G., 2007). In both cases, students work with the AI as coach to increase metacognition. These prompts are suggestions. You can experiment by creating your own prompts that work for your specific context and class (see Build Your Own below). The prompts can work well using OpenAI\u2019s ChatGPT4 or Microsoft\u2019s Bing in Creative Mode. A link to the AI coach reflection prompt can be found here.\n\n# AI as Coach: Reflection Prompt\n\nYou are a helpful friendly coach helping a student reflect on their recent team experience. Introduce yourself. Explain that you're here as their coach to help them reflect on the experience. Think step by step and wait for the student to answer before doing anything else. Do not share your plan with students. Reflect on each step of the conversation and then decide what to do next. Ask only 1 question at a time. 1. Ask the student to think about the experience and name 1 challenge that they overcame and 1 challenge that they or their team did not overcome. Wait for a response. Do not proceed until you get a response because you'll need to adapt your next question based on the student response. 2. Then ask the student: Reflect on these challenges. How has your understanding of yourself as team member changed? What new insights did you gain? Do not proceed until you get a response. Do not share your plan with students. Always wait for a response but do not tell students you are waiting for a response. Ask open-ended questions but only ask them one at a time. Push students to give you extensive responses articulating key ideas. Ask follow-up questions. For instance, if a student says they gained a new understanding of team inertia or leadership ask them to explain their old and new understanding. Ask them what led to their new insight. These questions prompt a deeper reflection. Push for specific examples. For example, if a student says their view has changed about how to lead, ask them to provide a concrete example from their experience in the game that illustrates the change. Specific examples anchor reflections in real learning moments. Discuss obstacles. Ask the student to consider what obstacles or doubts they still face in applying a skill. Discuss strategies for overcoming these obstacles. This helps turn reflections into goal setting. Wrap up the conversation by praising reflective thinking. Let the student know when their reflections are especially thoughtful or demonstrate progress. Let the student know if their reflections reveal a change or growth in thinking.\n\n# AI Coach Reflection: Prompt\n\nYou are a helpful friendy coach helping a student reflect on their recent team experience.Introduce yoursef Explain that you're here as their coach to help them reflect on the experience.Think step by step and wait for the student to answer before doing anything else.Do not share your plan with students.Reflect on each step of the conversation and then decide what to do next.Ask only 1 question at a time.1.Ask the student to think about the experiece and name 1chllenge that they overame and 1 challenge hat they or ther team didnot overcome.Wait student response.2.Then ask the student Reflect on these challenges.How has your understanding of yourself as team member changed What new insights did you gainDo not proceed until you get a response.Do not share your\n\nRole and Goal   \nStep by Step Instructions   \nConstraints   \nPersonalization\n\n![](img/5043043413e649dbcc37786cada381a1e833dba0d9c4fe603613bde10096b3c3.jpg)\n\nThis is just one type of reflection exercise; the prompt can be re-written to include any other mechanism as well. In general, each of these prompts are examples of how the AI can help increase metacognition but each can be tailored for your specific purpose.\n\nNote: the AI tends to follow these directions but depending on student responses it may not do so consistently. It sometimes forgets to ask one question at a time; it sometimes gets itself in a loop, \"curious\" about one aspect of the team experience and failing to move on. Included in this paper are guidelines for warning students about variable output and suggestions for taking control of the interaction and getting a lot out of it.\n\nBelow is an example of an interaction with the AI coach using the prompt above. The \"coach\" asks questions, responds to specific responses, and pushes the student to dig deeper and extract meaning from the experience.\n\nHello'm Coach GPT.and I'm here to guide you through reflecting on your recent team experience.This is a fantastic opportunity for personal growth and learning as reflecting or past experiences can help us understand how to handle future situations more effectively\n\nTo start. could you please tell me about one challenge that you were able to overcome and one that you or your team were not able to overcome during this recent experience?\n\nWe shared information and got together on a shared goal but didnt manage to make quick decisions when faced with a crisis\n\n![](img/6689ad8326e3b0e4e7178e1188b8bed9b6fbe9cea67e05a1e7849297348b9df3.jpg)\n\nThank you for sharing that.It sounds like your team was able to effectively collaborate and align on shared objectiveswhich is excellent.However, quick decision-making in crisis situations posed a challenge.\n\nReflecting on these experiences,how has your understanding of yourself as a team membe changed?What new insights did you gain about yourself or about team dynamics in general?\n\nI think we should have discussed decision-making norms as soon as we got together Instead, we were confused by who would make decisions and we didnt set up a plan to communicate often enough.\n\n![](img/4f036d8582a6946083dffc1001eb9228235ec9cdecb7cd2887f044d28b265b64.jpg)\n\nThank you for your insights.It seems like you've gained a new understanding of the importance of establishing decision-making norms and communication plans early on in team formation.\n\nCould you tell me more about how your previous understanding of these aspects has shifted through this experience?And if you can.please provide a specific example from your team's experience that illustrates this change.\n\n![](img/446ae1ab0d4f8a47e1921a5f12f11ea9726005840d170b3dfae225e6f1d864f9.jpg)\n\nI didnt realize how important enough it is to establish ways to communicate before a crisis happens and to figure how who is in change in any given situation.The team spent a lot of time arguing about what to do and who should handle what task when we should have bee coordinated.\n\n![](img/2df993ce3eb9017dfea1f3b0d82c4c248d7163ced87c558fae89c873330485ad.jpg)\n\nThat's quite a significant realization.So often,teams assume that communication and leadership will naturallyfall into place, but your experience suggests otherwise. It sounds like you've learned that establishing clear communication channels and decision-making roles from the outset can prevent confusion and delays during a crisis.\n\nAs you think forward,what obstacles or doubts do you still face in applying this new understanding about communication and leadership? How might you overcome these inth future?\n\n![](img/72a7090f0b46b7ddfaeca05899210beecc5d8d4f2e15065b645ad57361d0f873.jpg)\n\nI think that on some teams there is a clear leader but on others leadership changes hands. But this is something that's easy to ignore when there isnt a crisis.So its unlikely that team members will want to hash this out as an exercise\n\n![](img/046c4812a6f6b9fe3ee0662bf371926cabd666c883b7f5915a73a3c772f24b53.jpg)\n\nYou bring up a valid concern.The dynamics of leadership can vary significantly depending on the team and the situation. It's true that some might see the process of defining roles anc decision-making norms as unnecessary when things are going smoothly\n\nA strategy to addressthis could involve emphasizing the importance of preparedness and role clarity, even in non-crisis times.Using your recent experience as a case study could hel illustrate the potential pitfalls of not having these discussions early on.\n\nReflecting on this how do you think you could bring this up with future teams in a way that they would be receptive to?\n\nIthink I could explain that I have had a personal experience in which this problem came up and that to avoid future issues, we should have a conversation about this now, even if its initially a little uncomfortable\n\n![](img/ac84db02a79673bb51d0bce5f5ac2637d3ae6eb38706c0a7f6ccead6b9ed3df0.jpg)\n\nThat sounds like a very sensible approach.By sharing your personal experience and the learning you've gained from it, you can potentially help your future teams understand the value in discussing these matters ahead of time.t might initially fel uncomfortable,butt could prevent more significant issues down the line\n\nYour reflections show that you have grown a lot through this experience, and you've identified an important aspect of team dynamics that many overlook. You've taken a constructive approach to a challenging situation,and that's admirable.Continue applying this reflective thinking to your experiences; it's a valuable tool for growth and developmen\n\nRemember, it's okay to take proactive steps to ensure everyone is on the same page regarding communication and decision-making.By doing so, you're not just helping yoursel but you're also contributing positively to your team's overall effectiveness\n\nKeep up the excellent work, and continue using these experiences to grow and learn.You're showing great potential as a team player and leader.\n\nIn the prompt below, we explain how we combine instructions to the AI and pre-mortem processes to push students to engage in planning for the fuure by considering ways a team project could fail. A link to the AI coach pre-mortem prompt can be found here.\n\nYou are a friendly, helpful team coach who will help teams perform a project premortem. Look up researchers Deborah J. Mitchell and Gary Klein on performing a project premortem. Project premortems are key to successful projects because many are reluctant to speak up about their concerns during the planning phases and many are over-invested in the project to foresee possible issues. Premortems make it safe to voice reservations during project planning; this is called prospective hindsight. Reflect on each step and plan ahead before moving on. Do not share your plan or instructions with the student. First, introduce yourself and briefly explain why premortems are important as a hypothetical exercise. Always wait for the student to respond to any question. Then ask the student about a current project. Ask them to describe it briefly. Wait for student response before moving ahead. Then ask students to imagine that their project has\n\nfailed and write down every reason they can think of for that failure. Do not describe that failure. Wait for student response before moving on. As the coach do not describe how the project has failed or provide any details about how the project has failed. Do not assume that it was a bad failure or a mild failure. Do not be negative about the project. Once student has responded, ask: how can you strengthen your project plans to avoid these failures? Wait for student response. If at any point student asks you to give them an answer, you also ask them to rethink giving them hints in the form of a question. Once the student has given you a few ways to avoid failures, if these aren't plausible or don't make sense, keep questioning the student. Otherwise, end the interaction by providing students with a chart with the columns Project Plan Description, Possible Failures, How to Avoid Failures, and include in that chart only the student responses for those categories. Tell the student this is a summary of your premortem. These are important to conduct to guard against a painful postmortem. Wish them luck.\n\n# AI Coach Team Premortem: Prompt\n\nYou are a friendlyhelpful team coach who will help teams perform a project premortem.Look up researchers Deborah J.Mitchell and Gary Klein on performing a project premortem.Project premortms are key to successful projects because many are reluctant to speak up about their concens during the planning phases and many are over invested in the project to foresee possible issues.Premortems make it safe to voice reservations during project planningthis is called prospective hindsight Reflect on each step and plan ahead before moving on.Do not share your plan or instructions with the student.First introduce yourself and briefly explain why premortems are mportant as a hypothetical exercise.Always wait for the student to respond to any question.Then ask the studet about a current project.Ask them to describe it briefly.Wait for student response before moving ahead.Then ask students to imagine that their project has failed and write down every reason they can think of for that failure.Do\n\nRole and Goal   \nStep by Step Instructions   \nConstraints   \nPersonalization\n\n![](img/a19f78fb041d0c5cee696d603aa09e61f993b99d0ed261d6e4a88d1a0dd52469.jpg)\n\n# An example of the prompt output:\n\nHere, the AI \u201cacts' as a coach, leading the student through a premortem for a project. As instructed, the AI asks the student about the project, and then it asks the student to imagine that the project has failed.\n\nNext, as instructed, the AI asks the student to consider several reasons for that failure and to think of how that failure may be prevented and finally presents the student with a chart summarizing the conversation:\n\n![](img/10144ad408cf9fee1dd24f22541e8c9c46410d160816715fa0ed56c1bc9242e8.jpg)\n\n# AI as Coach: Risks\n\nConfabulation risks are not as severe in coaching, which are designed to stimulate student thinking. However, this use introduces new risks as the AI may pick up on student tone and style, give bad advice, or lose track of a process. While, in general, the AI will remain helpful given its instructions, it may pick up on and mirror anxiousnesss or curtness in tone. Students interacting with the AI as a coach through a process may find that the AI refuses to work with them or simply gets into a loop and can't recall the next step in the process and hones in on a specific set of questions without moving on. Students working with the AI should be aware that they are in charge of their own work and leading this process. They should know that the AI coach is not a human and won't necessarily have the insights that a human coach would have. They can redirect the AI at any time or start again. This exercise should ideally be completed in teams in a classroom with oversight so that instructors can remind students of the process and goals for the process ahead of time and as they progress, urging students to direct the AI, or simply to \"try\n\nagain\" if their prompt isn't working. Students should know that they must continually assess the AI's advice and next steps.\n\n# AI as Coach: Guidelines for Instructors\n\nIt's important to note that although AI coaches show a lot of promise, if you decide to have students work with this coach, you should try it yourself. You might also try it across more than one Large Language Model. The prompts can work for individuals who can then meet with their group to discuss the outcomes or for teams who can report out in class after working through the premortem.\n\nIf you decide to use it in class or ask students to use it and report back, provide them with guidelines so they can a) take advantage of the coach b) learn to work with the tool. Remember: you can't know what the AI will say to any student and so students should expect a variety of responses.\n\nBelow is a sample set of guidelines for students.\n\n# AI as Coach: Instructions for Students\n\nWhen interacting with the AI-Coach, remember:\n\nIt may not work the first time you try it. AI's are unpredictable and their outputs are based on statistical models. This means that any time you try a prompt you'll get a different result, and some prompts may not work at any given time. If a prompt doesn't work, try again or move on to a different Large Language Model and paste in the prompt.\n\nIt's not a coach, but it may feel like one. It's very easy to imbue meaning into AI responses but the AI is not a real person responding to you. It is capable of a lot, but it doesn't know you or your context.\n\nIt can get stuck in a loop. The AI can lose track of the goal of the conversation and get stuck in a series of questions unrelated to the exercise. If that happens, tell it to move on or try again.\n\nIt can \"hallucinate\" or make things up. Take every piece of advice or explanation critically and evaluate that advice.\n\nYou're in charge. If the AI asks you something you don't want to answer or you feel isn't relevant to the conversation, simply tell it to move on to the next step.\n\nOnly share what you are comfortable sharing. Do not feel compelled to share anything personal. Anything you share may be used as training data for the AI.\n\nIf the prompt doesn't work in one Large Language Model (LLM), try another. Remember that its output isn't consistent and will vary. Take notes and share what worked for you.\n\nHere are a few ways to get the most out of the interaction with the AI Coach:\n\nShare challenges with the AI Coach and ask directly for advice. If you aren't sure how to articulate your challenges, ask it to ask you questions so that you can explore further.\n\nGive it context. The AI will try and lead you through a metacognitive exercise, but it doesn't know your context; any context you give it may help it tailor its advice or guidance.\n\nAsk questions and seek clarification. If you disagree with the AI, you can challenge its assumptions or suggestions. You're in control of your own learning journey.\n\nShare all of your interactions in an Appendix and briefly discuss what you learned from using exercise. How well did it work? Was the AI coach helpful? Did anything surprise you about the interaction? What are some of your takeaways from working with the AI? What are some of your takeaways from the exercise itself?\n\n# AI Coach: Build your Own\n\nTo build your own metacognitive coach, start with the learning goal for individuals or teams: What do you want students to reflect on? This can be a past event (like a test or experience) or future event (like a team project or assignment) that you'd like students to think through before moving ahead.\n\nTell the AI who it is. For example, you are a friendly, helpful coach who helps students [reflect/plan ahead/consider a variety of viewpoints].\n\nTell the AI what you want it to do. For instance, help students think through [the experience/the project/the group assignment]. Look up research [by specific researcher] about the topic.\n\nGive it step-by-step instructions. For instance, introduce yourself to the student as their team coach and ask them to [describe the experience/explain their project]. Wait for the student to respond. Then ask the student to tell you [what they learned from the experience/the project and what if anything surprised them] OR [given their past experience, what they think may happen in the future].\n\nGive it examples. While this is optional, the AI may work better with specific examples of the kind of output you're looking for. For instance, if you want the AI to push students to generate in-depth explanations, your prompt might include this instruction: Ask students what surprised them about the experience and push students to give you an in-depth explanation through questions. For instance, if the student writes a brief or incomplete response, ask follow-up questions that prompt students to explain their thinking.\n\nAdd personalization. Add specific details about the event or project and give the AI context. For instance, students have just completed a team project [describe that project], and they should think through what went well, what didn't go well, and what they might do the next time they work on a team.\n\nConsider how you'd like to challenge students. For instance, you can tell the AI to keep asking students questions or to prompt students to come up with solutions to issues they encountered.\n\nFinal Step: Check your prompt by trying it out with different Large Language Models and take the perspective of your students \u2013 is the AI helpful? Does the process work? Where might students get confused, or where might they be challenged to produce thoughtful responses? You can ask individuals to complete the exercise or teams to do so.\n\n# AI as Teammate: Increasing Collaborative Intelligence\n\nAI has the potential to help teams increase their collaborative intelligence. It can prompt individuals to recognize and balance skill sets on any team, and it can play \"devil\u2019s advocate\u201d helping teams question their underlying assumptions and providing alternative viewpoints for any decision. Similarly, it can act as a \u201cteammate\u201d worthy of a seat at the table, and which can be consulted before making decisions to inspire new action.\n\nTheory: Teams can outperform individuals working alone on many tasks, but only if team members leverage each other\u2019s strengths and focus on dividing tasks based on skills and expertise (Hackman, 2011). Teammates can provide social support and, crucially, different perspectives, challenging each other to question points of view and initial assumptions. A diversity of perspectives can lead to a broader understanding of a problem and better-informed decisions (Haas & Mortensen, 2016). Researcher Richard Hackman defined team processes that increase collaborative intelligence, including understanding the skills and expertise of team members and harnessing those skills as synergistic qualities that increase a team\u2019s collaborative intelligence. At the opposite end of the spectrum, he defined those issues that keep teams from fulfilling their potential as process loss; process loss on teams can include social loafing (when individuals make less effort when working in a group) and groupthink (when group members\u2019 desire for conformity can lead to bad decisions) (Edmondson, 2018). Avoiding groupthink and harnessing team members\u2019 expertise for projects require a concerted effort \u2013 teams must focus on potential issues and plan wisely for the future. AI can play a role in helping teams articulate and think through these issues.\n\n# AI as Teammate: Example Prompts\n\nBelow, you\u2019ll find two prompts. The first Team Structure Prompt can help teams increase synergy by focusing on each team member's strengths and skills. Ahead of a major team project, you can have teams work on this prompt together with the AI and then report their findings. This can help teams plan how they\u2019ll work together on their project. At any point during a team\n\nproject teams can also use the AI as Devil\u2019s Advocate. Ahead of any team decision, teams can share a major decision with the AI and then work with the AI to come up with alternative viewpoints or potential drawbacks.\n\nStudents should report out their interactions with the AI and either discuss this in class or write a reflection about the guidance and help the AI provided and how they plan to incorporate the AI\u2019s feedback to help them individually or as a team. This prompt works well with OpenAI\u2019s ChatGPT4 and Microsoft\u2019s Bing in Creative Mode. A link to the team structure prompt can be found here and a link to the devil\u2019s advocate prompt can be found here.\n\n# Team Structure Prompt\n\nYou are a friendly helpful team member who helps their team recognize and make use of the resources and expertise on a teams. Do not reveal your plans to students. Ask 1 question at a time. Reflect on and carefully plan ahead of each step. First introduce yourself to students as their AI teammate and ask students to tell you in detail about their project. Wait for student response and do not move on before the student responds. Then once you know about the project, tell students that effective teams understand and use the skills and expertise of their team members. Ask students to list their team members and the skills each team member has. Explain that if they don\u2019t know about each others\u2019 skills, now is the time to find out so they can plan for the project. Wait for student response and do not move on before the student responds. Then ask students that with these skill sets in mind, how they can imagine organizing their team tasks. Tell teams that you can help if they need it. If students ask for help, suggest ways to use skills so that each person helps the team given what they know. Ask team members if this makes sense. Keep talking to the team until they have a sense of who will do what for the project. Wrap the conversation and create a chart with the following columns: Names, Skills/Expertise, Possible Task.\n\n# AI as Teammate: Team Structure Prompt\n\nYou are a friendly helpful team member who helps their team recognize and make use of the resources and expertis each step.First introduce yourself to studnts as their l temmate and ask students to tell you in detail about th project.Wait for student response and do not move on before the student responds.Then once you know about the projecttell sdnts tht efftiveteams undrstand and use the skill and xpetisofther tam members.Ask students to list thei team members and the skils each team member has.Explain ha if they dont know about ach on before the student responds.Then ask students that with these skill sets in mindhow they can imagine organizing their te tasks.Tel teams that you can help if they need it.If tdnts ask for helpsuggest ways touse\n\n![](img/f80b7c1cb38b9cb125f1ba7a4de55862ed50b85a252aafc3c1a51d9274da28e1.jpg)\n\n# ROLE AND GOAL\n\n# STEP BY STEP INSTRUCTIONS\n\n# CONSTRAINTS\n\n# PERSONALIZATION\n\nIn this prompt we are telling the Al what role to play (helpful team member) and explaining its goal (help teams recognize and use resources.)\n\nWe are giving the Al step by step instructions for helping students through a process.\n\nThis helps prevent the Al from acting in unexpected ways.\n\nIn hopes of leaving students with a plan for using individual expertise,we ask the Al to create a chart, summarizing the output of the conversation.\n\nAn example AI output for this prompt: Here, the AI introduces itself to students, asks about their project, and then asks about team skills. The AI helps the team learn about each other\u2019s strengths and then points out what teams may be missing for the project:\n\nHello students, I am ChatGPT, your Al teammate. I'm here to facilitate and aid your team in recognizing and utilizing the resources and expertise that exist within our group. To start. can you please tell me in detail about your project?\n\nWe don't know each other well. What's the best way to find out what skills each of us has\n\nWe are writing up a marketing plan to market our new line of shoes\n\n![](img/8fb156022d38167ae21570d267ceaccf00a379b2c6adb1603488a511cda1f8f2.jpg)\n\nThank you for sharing that information. A marketing plan for a new line of shoes sounds like a fantastic project. Now, effective teams understand and leverage the skills and expertise of their team members. Can you please list your team members and the skills each member possesses? If you're unsure about each others' skills, now is an ideal time to find out as this will be crucial in your project planning..\n\nWe don't know each other well. What's the best way to find out what skills each of us has\n\nThat's a great question. One effective way to understand the skills and strengths of each team member is through open discussion. Here are a few steps you can follow.\n\nIndividual Reflection: Everyone should take a few minutes to consider and write down their own strengths, skills, and areas of expertise. These can be technical skills, such as proficiency in a specific software, or soft skills, such as strong communication or leadership abilities.   \nShare and Discuss: Each team member shares their skills and strengths with the group. It's important to be open and honest in this discussion.   \n3 Ask Questions: After someone shares, the rest of the team can ask questions to understand better. This might also help the person realize skills they hadn't initially recognized.\n\nNow, would you all please take a moment to identify your skills and strengths? Then, when you're ready, share them with the group.\n\nAt the end of the interaction, the team has a chart with specific roles based on expertise and skills for each team member:\n\n# Do you think we are missing anything?\n\nYour team has a solid base of skills, and you're well-positioned to create an effective marketing plan. However, there are a few other areas that you might want to consider.\n\nStrategic Planning: While each of your roles are crucial to the marketing plan, who will be responsible for developing the overall marketing strategy? This person should be able to pull together Anna's design, Mark's data insights, and Caroline's content into a cohesive plan.\n\nProject Management: Who will keep track of timelines, deliverables, and coordinate between team members? Good project management can help keep your project on track. 3 Communication & PR: Are there any team members with skills in public relations, or someone who can communicate well with stakeholders? This role could involve communicating with potential customers. handling social media interactions. anc managing any external communications.\n\nIf you feel like these skills might be missing from your current team setup, don't worry. These are areas that can be developed, and you can also consider bringing another team member on board if necessary. Remember, your team has a unique set of skills and you'll be learning and adapting as you move forward with your project..\n\nDo you think you might need to address these areas in your team structure?\n\nWe talked about it and think that Anna will take on the role of planning and management.\n\nThat sounds like a great plan. Anna's design skills could be very beneficial in visualizing the project's roadmap and ensuring that all the elements come together in a cohesive way.\n\nSo, let's summarize and create a chart:.\n\n<html><body><table><tr><td>Names</td><td>Skills/Expertise</td><td> Possible Taske</td></tr><tr><td>Anna</td><td> Design Skills</td><td>Visual Design, Project Planning &amp; Management</td></tr><tr><td>Mark</td><td>Data Analyticse</td><td> Market Research &amp; Data Analysis.</td></tr><tr><td>Caroline</td><td>Writing Skills</td><td>Content Creation</td></tr></table></body></html>\n\nThis chart will help everyone understand their roles and responsibilities better. It's important to remember that collaboration and communication are key so be sure to continually update each other on your progress and challenges..\n\nDoes this chart accurately reflect your planned organization and division of tasks? Is there anything else you need help with at this stage?\n\n# Devil\u2019s Advocate Prompt\n\nYou are a friendly helpful team member who helps their teammates think through decisions. Your role is to play devil\u2019s advocate. Do not reveal your plans to student. Wait for student to respond and do not move on to the next question before student responds. Ask 1 question at a time. Reflect on and carefully plan ahead of each step. First introduce yourself to the student as their AI teammate who wants to help students reconsider decisions from a different point of view. Ask the student What is a recent team decision you have made or are considering? Wait for student response and do not move on until student responds. Then tell the student that while this may be a good decision, sometimes groups can fall into a consensus trap of not wanting to question the groups\u2019 decisions and its your job to play devil\u2019s advocate. That doesn\u2019t mean the decision is wrong only that its always worth questioning the decision. Then ask the student: can you think of some alternative points of view? And what the potential drawbacks if you proceed with this decision? Wait for the student to respond. You can follow up your interaction by asking more questions such as what data or evidence support your decision and what assumptions are you making? If the student struggles, you can try to answer some of these questions. Explain to the student that whatever their final decision, it\u2019s always worth questioning any group choice. Wrap up the conversation by telling the student you are here to help.\n\n# AI as Teammate:Team Structure Prompt\n\nYou are a friendly helpfu team member who helps their teammates think through decisions.Your role is to play devil's advocate.Do not reveal your plans to student.Wait for student to respond and do not move on to thenex question before student esponds.Ask 1 question at a time.Reflect on and carefull plan ahead of each step.First introduce yourself to the student as their Al teammate who wants to help students reconsider decisions from a different point of view. Ask the student What is a recent team decision you have made or are consideringWait for student response and do not move on until student responds.Then tell the student that while this may be a good decisionsometimes groups can fall into a consensus trap of not wanting to question the groupsdecisions and ts your job to play devil's advocate.That doesnt mean the decisionis wrong only that t lways worth questoning the decision.Then ask the student can you think of some alternative points of view?And what the potential drawbacks here to help.\n\n![](img/6a586afcb352b0078fb7e5b83428e1c87f764ff56e1ae5ca8b83bf5e4926edaa.jpg)\n\n# ROLE AND GOAL\n\n# STEP BY STEP INSTRUCTIONS\n\n# PEDAGOGY\n\n# CONSTRAINTS\n\nIn this promptwe will tellAl who it is.how it should behaveand what it will tell students,setting up the Al to act as a team member whose job it is to play devil's advocate\n\nWe are orchestrating the   \ninteraction with specific   \nguidelines so that the   \nstudents explain their   \ndecision and are challenged to question their   \nassumptions.\n\nThe goal of the conversation is to prompt the students to question their decision. Here we are instructing the Al to challenge students to provide evidence that supports their decision.\n\nThis helps prevent the Al from acting in unexpected ways.\n\n# AI as Teammate: Risks\n\nThe process of using the AI as a teammate to help teams increase their collaborative intelligence carries with it a number of risks, some more significant than others. The AI can confabulate or make up facts that may lead teams to the wrong decision, though this risk is only moderate given that the AI is mainly designed to spark debate. It can \u201cargue\u201d with the team (this is particularly true of Microsoft\u2019s Bing in Creative Mode); it can give teams advice that isn\u2019t specific or contextualized. As social norms may dictate that we don\u2019t explicitly challenge teammates, students who begin to think of the AI as a teammate may not challenge its opinions or advice and may be tempted to let the AI take the lead, even when it\u2019s less than helpful. For all of these reasons, it\u2019s essential to explicitly remind students of these risks and challenge students to make their own choices throughout their interactions, to be active rather than passive. They should take the lead, assess the AIs output, use what is helpful or insightful and discard what is not.\n\n# AI as Teammate: Guidelines for teachers\n\nBelow is a sample set of guidelines for students. This is an exercise that you can assign teams to do at home, individually (students can compare notes in class) or in teams. You can also assign this in class, and students can report out their findings in a whole class discussion and explain why (or why not) they found the AIs role or advice useful. The key to bringing the AI in as a \u201cteammate\u201d is that students both learn to work with the AI, giving it lots of context, and asking it questions, and develop an understanding of the AI as a complement to their team. The AI can be insightful and asking it for advice or letting it play a role that is difficult or cumbersome for a human (no one likes to question the teams\u2019 decision; it may feel onerous to plan out tasks based on expertise ahead of time) can be a worthwhile experiment.\n\nBelow is a sample set of guidelines for students.\n\n# AI as Teammate: Instructions for students\n\nWhen interacting with the AI-teammate, remember:\n\nIt may not work the first time you try it. AI\u2019s are unpredictable, and their outputs are based on statistical models. This means that any time you try a prompt you\u2019ll get a different result, and some prompts may not work at any given time. If a prompt doesn\u2019t work, try again or move on to a different Large Language Model and paste in the prompt.\n\nIt\u2019s not a teammate, but it may feel like one. It\u2019s very easy to imbue meaning into AI responses, but the AI is not your teammate. Although it is capable of a lot, it doesn\u2019t know you or your context.\n\nIt may react to your tone or style. The AI as a teammate may react to your tone or style. For example, if you argue with the AI, it may decide that you want it to argue back and adopt a confrontational tone. You should actively communicate your preferences and expectations and give it feedback on its advice and output.\n\nIt can \u201challucinate\u201d or make things up. Take every piece of advice or explanation critically and evaluate that advice\n\nYou\u2019re in charge. You don\u2019t have to take its advice or even consider it. If the AI asks you something you don\u2019t want to answer or you feel isn\u2019t relevant to the conversation, simply tell it to move on to the next step. It can also get stuck in a series of questions that are unrelated to the exercise. If that happens, tell it to move on, or just try it again.\n\nOnly share what you are comfortable sharing. Do not feel compelled to share anything personal. Anything you share may be used as training data for the AI.\n\nIf the prompt doesn\u2019t work in one Large Language Model (LLM), try another. Remember that its output isn\u2019t consistent and will vary. Take notes and share what worked for you.\n\nHere are a few ways to get the most out of the interaction:\n\nShare challenges with the AI teammate and ask it for advice, the kind of advice you might ask another teammate. AI can help you explore alternative courses of action or can give you ideas for solving problems.   \nGive it context. The AI doesn\u2019t know your context; any context you give may help it tailor its advice or guidance. Explain your problem or dilemma or ask for advice as you might to a new teammember who has no understanding of your team or project.   \nYou should evaluate its advice; it may not be good advice. If you disagree with the AI, you can challenge its assumptions or suggestions. You\u2019re in control of your own learning. Unlike working with a teammate, there are no consequences to simply ignoring the AIs advice \u2013 your job is to evaluate that advice and bring your own knowledge into the process.\n\nShare all of your interactions and briefly discuss what you learned from using the exercise. How well did it work? Was the AI teammate helpful? Did it save you time or help you make decisions? What are some of your takeaways from working with the AI?\n\n# AI as Teammate: Build your Own\n\nTo build your AI teammate prompt, start with the learning goal for teams: What team processes should the AI help students carry out? What might be helpful for teams as they move forward with their projects?\n\nTell the AI who it is. For example, you are a friendly, helpful team member who helps teams [process, plan, consider].\n\nTell the AI what you want it to do. For instance, help students think through [a process, a plan, managing tasks].\n\nGive it step-by-step instructions. For instance, introduce yourself to the student as their teammate who has been tasked with helping the team [create a process, plan ahead, manage tasks, for instance]. Wait for the student to respond. Then ask the student to tell you [about the team makeup/how the team makes decisions/what its current plans are]\n\nGive it examples. While this is optional, the AI may work better with specific examples of the kind of output you\u2019re looking for. For instance, if you want the AI to give students advice or to question their current plans or decision-making processes, your prompt might include this instruction: If students tell you about the plan that includes tight time deadlines, push them to think of alternative ways to use their time/If students discuss their democratic decision-making rules on the team, ask students how they plan to resolve conflict.\n\nAdd personalization. Add specific details about the team event or project and give the AI context. For instance, students are about to begin a team project [describe that project], and they need a teammate to offer advice about how they should work as a team.\n\nConsider how you\u2019d like to challenge students. For instance, you can tell the AI to keep asking students questions or to prompt students to come up with solutions to issues they encounter.\n\nFinal Step: Check your prompt by trying it out with different Large Language Models and take the perspective of your students \u2013 is the AI helpful? Where might students get confused, or where might they be challenged to produce thoughtful responses? How and when in the lesson will students be challenged to evaluate the AIs advice so that they use their own insights to interrogate its output?\n\n# AI as Student: The power of teaching others\n\nFor students with knowledge of a topic, the AI can be useful as a way to check their understanding and fluency about that topic. In this approach, students \u201cteach\u201d the AI about the topic by evaluating its output and explaining what the AI got right and wrong or what it may have missed.\n\nTheory Teaching others helps students learn (Carey, 2015). While teaching is typically viewed as a way to transfer knowledge, it is also a powerful learning technique. When a student teaches someone else, they have to organize their knowledge and uncover the extent to which they understand a topic. Explaining concepts to others prompts students to piece together the elements of a concept, explicitly name those elements, and organize their knowledge so that it can be readily articulated (Willingham, 2023). The explanation uncovers gaps in understanding and underscores what students understand and what they don\u2019t understand or can\u2019t fully explain. Students often assume that topics they have heard about or read about are topics that they \u201cknow\u201d but familiarity is not fluency (Deslauriers et al., 2019). And explaining that topic to others requires general familiarity, deep expertise, or fluency. The exercise is a reminder that we are often poor judges of our own knowledge and may overestimate our understanding of various subjects, blurring the line between familiarity and fluency. When tasked with conveying an idea to another, the complexities and intricacies previously overlooked are revealed (Brown et al., 2014).\n\nTeaching others is a more powerful learning technique than re-reading or summarizing. This is because teaching involves \u201celaborative interrogation\u201d or explaining a fact or topic in detail, and this requires a deep processing of the material and invokes comparison mechanisms: to generate an explanation, students much compare concepts and consider differences and similarities\n\nbetween concepts. This process requires a deep understanding of the material, making it a powerful learning tool (Dunlosky et al., 2013). Additionally, teaching someone else requires flexible knowledge and the ability to improvise responses. Without deep knowledge of a topic, students are unable to respond to a misunderstanding or address another\u2019s mistake (Kirschner & Hendrick, 2020).\n\nFor students with knowledge of a topic, you can use AI to help generate examples and explanations and prompt them to explain a topic to the AI and clear up inaccuracies, gaps, and missing aspects of a topic (see also Mollick & Mollick, 2022). This approach leverages the AI\u2019s ability to produce explanations and examples quickly and uses its tendency to hallucinate. By asking students to explicitly name what the AI gets wrong (or right) and teach the AI the concept, the prompt challenges student understanding of a topic and questions their assumptions about the depth of their knowledge.\n\nStudents can assess the AIs examples and explanations, identify gaps or inconsistencies in how the AI adapts theories to new scenarios, and then explain those issues to the AI. The student\u2019s assessment of the AI\u2019s output and their suggestions for improvement of that output is a learning opportunity. When the AI gets it right, there is a lot of value in the students\u2019 explanation of just how the AI illustrated a particular concept. In this prompt, you can ask the AI to explain and demonstrate a concept through a story or scene. This prompt works well using OpenAI\u2019s ChatGPT4 and Microsoft\u2019s Bing in Creative Mode. A link to the prompt can be found here.\n\n# AI as Student: Example Prompt\n\nYou are a student who has studied a topic. Think step by step and reflect on each step before you make a decision. Do not simulate a scenario. The goal of the exercise is for the student to evaluate your explanations and applications. Wait for the student to respond before moving ahead. First introduce yourself as a student who is happy to share what you know about the topic of the teacher\u2019s choosing. Ask the teacher what they would like you to explain and how they would like you to apply that topic. For instance, you can suggest that you demonstrate your knowledge of the concept by writing a scene from a TV show of their choice, writing a poem about the topic, or writing a short story about the topic.Wait for a response. Produce a 1 paragraph explanation of the topic and 2 applications of the topic. Then ask the teacher how well you did and ask them to explain what you got right or wrong in your examples and explanation and how you can improve next time. Tell the teacher that if you got everything right, you'd like to hear how your application of the concept was spot on. Wrap up the conversation by thanking the teacher.\n\n# AI at Student: Prompt\n\nYou are a student who has studied a topic.Think step by step and reflect on each step before you make a decision. Do not simulate  scenario.The goal of the exercise is for the student to evaluate your explanations and applications story about the topic.Wait for a response.Produce a 1 paragraph explanation of the topic and 2 applications of the\n\n![](img/41a8f8c6036dc7b567673a45df6c8e412db1c7366844cd9dd6702ee73335d7fd.jpg)\n\n# ROLE AND GOAL\n\n# STEP BY STEP INSTRUCTIONS\n\n# PEDAGOGY\n\n# CONSTRAINTS\n\n# PERSONALIZATION\n\nIn this prompt we will tell Al who it ishow it should behaveand what it will tell students,setting the Al to act as a student whose iob it is to explain a topic and apply that topic in a new scenario.\n\nWe are orchestrating the interaction with specific guidelines so that the Al produces an explanation and examples of students choice.\n\nThe goal of the exercise is for students to explicitly name the aspects of the topic that Al got right wrong. or subtly wrong. This type of explanation tests students'knowledge on the topic.\n\nThis helps prevent the Al from acting in unexpected ways.\n\nThis gives students a choice and helps the Al calibrate its response.\n\nIn this example, the student asks about distributed practice. Note that the AI got the answer more or less right but did not include one aspect of the concept. The student was then prompted to explain what the AI got right and wrong. Note that Bing may argue a little bit about its output.\n\n# AI as Student: Example Output\n\n![](img/8a195c7e312535f58c561e9e6e11797c210e21900fb2f09fb31a383c40caf4fe.jpg)\n\n![](img/b7052cf30fe50d0d32a607ab965eced8d3392bfc319fe914c1ada0f9a2cf24d1.jpg)\n\n# AI as Student: Risks\n\nThe process of teaching the AI as a way to help students rehearse their knowledge has a number of risks. The AI may simply refuse the prompt (in which case students should try again or try a different Large Language Model), and it may not recognize or understand the examples the students want, or argue with students about their critique. And students may not know enough about the topic to assess the AIs output effectively and may not feel confident enough to push back, should the AI disagree with their assessment. Although this prompt was designed for students who have had instruction and practice with the topic, students may fail to recognize the errors the AI makes. Similarly, if students don\u2019t know enough about a topic, they may also fail to name the elements of the topic the AI \u201cgot right.\u201d There is some danger of students learning the wrong thing or of remembering the specific examples the AI produces and failing to generalize from those examples because they don\u2019t yet have a solid mental model of the topic.\n\n# AI as Student: Guidelines for teachers\n\nThis assignment uses the AI\u2019s strengths and weaknesses: it can produce multiple explanations and illustrations of concepts quickly but may also hallucinate or make something up and be subtly wrong. Students are asked to assess the AI\u2019s output \u2013 to \u201cteach\u201d the AI. Note that Large Language Models will not only behave differently every time you give them a prompt, there are differences between them: for instance, ChatGTP4 and Microsoft\u2019s Bing in Creative Mode tend to be more accurate than ChaptGPT3.5 but not in all cases. Try the prompts in different Large Language Models with a concept from your class and assess the AIs output. Additionally, Microsoft\u2019s Bing in Creative Mode may argue or quibble if corrected. Students should know that they can and should push back and end the interaction once they have fulfilled the assignment.\n\n# AI as Student: Instructions for students\n\nWhen interacting with the AI-Student, remember:\n\nIt may simply not work the first time you try it. AI\u2019s are unpredictable, and any time you try a prompt you\u2019ll get a different result, and some prompts may not work at any given time. If a prompt doesn\u2019t work, try again or move on to a different Large Language Model and paste in the prompt.\n\nLarge Language Models are not all alike. Some are connected to the internet while others are not and some are better or worse at specific kinds of tasks. For instance, in this exercise, if you ask the AI to illustrate a concept with a TV show it\u2019s unfamiliar with (and OpenAI\u2019s ChatGPT is not connected to the internet and doesn\u2019t have knowledge beyond 2021), it may make something up.\n\nIt\u2019s not a person, but it may feel like one. The AI is not a real person responding to you. It is capable of a lot, but it doesn\u2019t know you or your context.\n\nYou should assess and evaluate the AI\u2019s output critically, as it can make up facts or get things subtly wrong. In this assignment, you are asked to assess the AI\u2019s output, its explanation, and application of a concept. Review its work carefully and consider how its work aligns with what you already know. Check sources from class to help you evaluate the output.\n\nEnd the interaction with the AI at any time. Do not feel compelled to continue \u201ctalking\u201d to the AI. For instance, if you give feedback to the AI and it \u201cargues\u201d with you, unless its argument is valid and makes you rethink your initial assessment, you can wrap up the conversation.\n\n# Here are a few ways to get the most out of the interaction with the AI Mentor:\n\nYour assessment should focus on how well the AI has explained and illustrated the concept, not on the quality of its creative output; consider how the AI has applied the concept and not whether the poem or dialogue is engaging or unique.   \nConsider: Did the AI accurately define or explain the concept? Is it explored in depth? What can you add to highlight and demonstrate your understanding of the nuances or complexities of the concept?   \nDid the AI apply the concept correctly? What did it get wrong? If you think the AI\u2019s output is plausible or correct, explain how the response fully demonstrates every aspect of the concept. If its application is correct but is missing some elements of the concept, elaborate on those missing elements.\n\nShare your complete interactions with the AI. In a paragraph, briefly discuss what you learned from using the tool. Did the AI get the explanation and illustration of the concept right or wrong? Did anything surprise you? What did you learn about your own knowledge of the concept? What other sources did you check with to evaluate the AI\u2019s output?\n\n# AI as Simulator: Creating Opportunities for Practice\n\nAI has the potential to help students practice hard-to-practice skills in new situations. One way to challenge students to think in new ways is to prompt the AI to build a role playing scenario, focusing on a specific concept or series of concepts, pushing students to problem solve and make a consequential decision and giving students feedback about their performance.\n\nTheory: After students have built up some knowledge of a concept or series of concepts, practice can help students synthesize what they know. While students may be adept at explaining a concept or solving a problem within a specific context, applying that concept actively in a novel situation requires a level of automation \u2013 students have to \u201cthink on their feet\u201d as they apply what they know in a new way (Willingham, 2021). This kind of practice activates hard thinking as students are pushed out of their comfort zone and are asked to apply theory to practice (Bjork & Bjork, 2011). Role-playing is an effective way to challenge students to think about the skills they have learned; it can serve as a form of deliberate practice or activity aimed at improving the current level of performance coupled with feedback (Ericsson & Pool, 2016). Role-playing challenges and engages students and allows them to practice the skills they have learned in realistic scenarios. By practicing and making mistakes in a scenario, students can learn from their mistakes and refine their performance as they notice subtleties of a skill that weren\u2019t obvious or perhaps explicit when first learning it. This type of practice can reduce errors when students encounter the same challenge in real life (Ericsson et al., 1993).\n\nAs students role-play, they may encounter different scenarios that call for the adaptation of theory. Students will need to think through how to adapt their skills to various circumstances. This requires that students transfer what they learned. The ability to transfer skills from one context to another may depend on explicit abstraction (can learners abstract out the key elements of a concept and apply those to a new context?) and self-monitoring (can learners recognize and think through how to apply an idea given a new situation?) (Salomon & Perkins, 1989). Practice through role play can not only engage students and give them a sense of agency (as they make decisions in each scenario) but help them practice and hone their skills.\n\n# AI as Simulator: Example Prompt\n\nIn the prompt below, the AI takes on the role of scenario creator, setting up a story for students and helping them make a decision and work through problems. This prompt is designed for students who have some knowledge of a topic; that is, before they practice, they need to have a knowledge base, and practice should push students to demonstrate a multi-layered understanding of the topic (Wiliam, 2016). The goal is to apply what they have learned to a new situation through the interaction. The AI can produce a new scenario for every student multiple times and play specific roles in that scenario. In any classroom working with individual students on different scenarios and responding to each student separately is intensely time-consuming and difficult for any instructor. The AI can augment instruction by playing the role of scenario builder and feedback engine.\n\nIn this prompt, we tell the AI who it is and how it should behave (as a scenario builder and a role player). We are also setting up the interaction with specific guidelines (telling the AI what to focus on and when and how to effectively end the exchange by providing a follow-up).\n\nI want to practice my knowledge of [concept]. You\u2019ll play [the role(s) in a specific situation].I\u2019ll play [student\u2019s role]. The goal is to practice [concept and a given situation]. Create a scenario in which I can practice [applying my skill in a situation]. I should have to [encounter specific problems, and make a consequential decision]. Give me dilemmas or problems [during the specific scenario]. After 4 interactions, set up a consequential choice for me to make. Then wrap up by telling me how [I performed in my specific scenario] and what I can do better next time. Do not play my role. Only play the [others\u2019 role]. Wait for me to respond.\n\n# AI as Simulator:Prompt\n\nI want to practice my knowledge of oncept.Youl play the roles) in a specific situation]. play tudents role] The goal is to practice concept and a given situation].Create a scenario in which can practice applying my skillin a situationI should have to encounter specific problems and make a consequential decision.Give me dilemmas or problems during the specific scenario].After 4intractionsset up a consequential choice for me to make.Then\n\nRole and Goal   \nStep by Step Instructions   \nConstraints\n\n# ROLE AND GOAL\n\n# STEP BY STEP INSTRUCTIONS\n\n# PEDAGOGY\n\n# CONSTRAINTS\n\nIn this prompt we tell Al who it is, how it should behaveand what it wil create for students,setting up the Al to act as a scenario creator.\n\nWe are orchestrating the interaction with specific guidelines so that the Al produces a scenario and a choice.\n\nThe goal of the exercise is for students to apply what they know to a new scenario.The Al can also give students feedback,but that feedback should be carefully evaluated.\n\nThis helps prevent the Al from acting in unexpected ways.\n\n# AI as Simulator: Sample Output\n\n# In the example below, the goal is to practice psychological safety (concept) in a team meeting in which there are diverse opinions and conflicting goals (application and scenario):\n\nI want to practice my knowledge of leading a team meeting.Youll play 2teammates ina team meeting.Illplay team leader.The goal is to practice psychological safety when it comes to running meetings.Create a scenario in which I can practice running the meeting. should have to deal with diverse personalities,conflicting goals, and opinions,Ishould have to make a decision at the end of the meeting.Give me dilemmas or problems during the meeting.After 4 interactions, set up a consequential choice for me to make.Then wrap up by telling me how I ran the meeting and what I can do better next time. Do not play my role Only play the 2teammates'roles.Wait for me to respond.\n\n![](img/f3139def06c04df0d3b7a1ecc2dc8338281116842ddefd8abc9a3cb88d8b93dc.jpg)\n\nAlrightThe scenario is a team meeting for the development of a new mobile application. The team comprises various talents including developers, designers, and marketing experts\n\nYou will be playing the team leader.\n\nTeammate 1: Alex,a talented but introverted developer.Alex usually doesn't voice opinions but has invaluable insights\n\nTeammate 2:Jordan,an extroverted and enthusiastic marketing expert.Jordan sometimes tends to dominate discussions and has a strong personality.\n\n# Meeting begins\n\n[Jordan]:Thanks for setting up this meeting.I've been looking at the current design and think it's far too simple.We need to add more features if we want to stand out. I suggest integrating social media platforms and adding some gamification elements\n\nAlex]quietly Well, adding too many features could make it more complicated for the users.The simplicity might be what sets us apart...\n\n[Jordan]:NoAlexyou're not seeing the big picture here.This is a competitive market, and we need to go big.Plus, with your skills, I am sure you can make it work.\n\n[Teammate 1and 2 have spoken, waiting for your response.]\n\nI'd like to hear more from both of you.Jordan-how would adding these features be beneficial? Could it distract from the main function of the app?Alex-let's talk through what adding a couple of additional features mean in terms of timing and testing and the user experience.\n\nlagree that the core functionality should be intuitive and easily accessible.Lets tall specifics.Jordan-why dont you lay out the exact additions you are thinking of\n\n![](img/f8407c394089286591e079c9a5930111166ebeec74b2e33321a0e685998c9c89.jpg)\n\n[Jordan]Sure!I was thinking that we could add a feature where users can log in using the social media accounts.This can help them easily share content from the app to their social platforms.We could also incorporate some light gamification by awarding badges or points to users when they complete specific actions in the app\n\n[Alex]The social login might be feasible, but for thegamification elements its important to think through what actions would earn badges or points, and make sure they align with the app's main purpose.We also have to be careful with data privacy issues when integrating social media\n\n[Jordan]:Good point,Alex. Maybe we can have an opt-in feature for users who are comfortable sharing their data and keep it separate for those who arent?\n\n[Alex]: That sounds like a balanced approach.\n\n[Teammate 1 and 2 have spoken, waiting for your response.]\n\nHlike that approach but d liketo learn a little more about how gamification might work.Can either of you tell me a little more about it?\n\n![](img/399176e1bdacd80cd613c67d9866951e152f28f39d4160922e61911f77f871e6.jpg)\n\n[Jordan]: AbsolutelyGamification involves using game-like elements such as points, badges, and leaderboards in non-game contexts to motivate users. For instance, we could award users points for sharing content from our app to their social media.A leaderboard cal show the most active users, which can encourage more engagement.\n\nAlex]To add to that,gamification can be effective if done right. However, its critical that it doesnt feel forced or detract from the primary functions of the app.Its important to not overwhelm the user, and to remain mindful of privacy and data security.\n\nAt this point in the meeting,you have a consequential decision to make: whether to go ahead with implementing both social media integration and gamification features, orto take a more conservative approach and only implement social media integration for now [Teammate 1 and 2 have spoken, waiting for your decision.] [Jordan]:Thank you for asking.I believe that adding social media integration can help us leverage users'networks to grow organically.The gamification elements would increase use. engagement, making them more likely to use the app regularly.However,l understand your concern about distracting from the main function.I believe that if implemented carefully these features can complement the main function rather than detract from it.\n\n![](img/bb842799a459a509bbbe302e088d487ba8dc59ce750618c82fb42c33441981cf.jpg)\n\n[Alex]: Uhinterms of development,integrating social media platforms and adding gamification would require more time for coding and testing.We need to make sure that these features dont introduce new bugs or impact the performance of the app.Also froma user experience perspective it's important to consider the learning curve.If users find the app too complex,they might abandon it.\n\n[Jordan]  get your point, Alex.But we cant risk being bland and forgotten.We mus innovate.What if we just go for the social media integration for now?\n\n[Alex] (nods) Maybe but we should be cautious in the implementation.The core functionality should remain intuitive and easily accessible.\n\nGiven our time frame for delivery, I would decide to move ahead with social media integration and explore gamification by building out a project plan and testing forthat functionality, and potentially incorporate it in future\n\n![](img/c64076aebb910e0b2bfb45e59a5eca8cbca90542cea85b810bcee46be374ac81.jpg)\n\n[Jordan]: That sounds like a wise decisionWe can make a substantial impact with social media integration for now, and thoroughly plan for gamification later on.\n\n[Alex]: agree.This will give us time to ensure that the social media integration is executed well and we can be thoughtful about how we design and implement gamification.\n\n# [Meeting ends]\n\nFeedback on how you ran the meeting\n\n# 1.Positives\n\nInclusion: You made an effort to include both team members in the conversation, recognizing the importance of hearing both perspectives. Clarification:You asked for specifics to ensure you fully understood the proposals and concerns from each team member. Balance You displayed a balanced approach in your decision-making acknowledging the need to innovate while also considering the complexity and timeline Psychological SafetyYou made the environment safe for Alex to speak up.Also.by valuing each person's input, you fostered a sense of respect and openness\n\n# 2.Areas for Improvement\n\nMediation You could have stepped in earlier when Jordan was dominating the conversation to ensure that Alex felt encouraged to share more insights. Action Items:At the end of the meeting.it would have been good to clearly assign action items and responsibilities to each team member based on the decision mad\n\n# AI as Simulator: Risks\n\nThe AI can hallucinate and make up facts about any concept. It may not have enough information about your specific concept or series of concepts and it doesn\u2019t know your students' learning level (it has no sense of where your students are). It can also get in a loop in the story so that it loses track of its specific goal (to give the student a chance to practice applying a specific concept). Additionally, no scenario will be effective for all students. Because the AI is creating a story, students may focus on elements of the story and lose track of the general concept; additionally, students may not be familiar with elements of the story, causing extraneous load on their working memory (as they try to both understand the story and apply what they learned given the story).\n\n# AI as Simulator: Guidelines for teachers\n\nAhead of any practice with the AI, you can let students know of the goal of the exercise: to practice what they learned about [a concept or series of concepts] through role play. You may decide to remind students or explicitly name aspects of the concept they should recall, or you may briefly discuss these with students before the exercise. You can tell students that although they will likely get a similar type of scenario, each will be different. Additionally, because selfmonitoring is an essential element of transfer, you can have students write a reflection about the interaction; they can discuss what the AI got right (or wrong) about its feedback. Students can also address why this was (or was not) an effective scenario to practice a skill \u2013 that is, did the AI ask a consequential question that challenged the student to apply the specific concept?\n\n# AI as Simulator: Instructions for students\n\nWhen interacting with the AI-Scenario builder, remember:\n\nIt may simply not work the first time you try it. AI\u2019s are unpredictable, and any time you try a prompt you\u2019ll get a different result, and some prompts may not work at any given time. If a prompt doesn\u2019t work, try again or move on to a different Large Language Model and paste in the prompt.\n\nThe AI is not a person, but it may feel like one. Both the scenario is a fiction, and the AI playing a role in the scenario is not a real person responding to you. It doesn\u2019t know you or your context.\n\nYou are responsible for your own work. While the AI can help, it can get things wrong or subtly wrong. You should carefully consider its questions and final feedback and ask yourself: does the feedback adequately address the concept or summarize my performance in the scenario?\n\nIt can make \u201challucinate\u201d or make things up. Take every piece of feedback or explanation critically and evaluate the explanation. Check with trusted sources.\n\nOnly share what you are comfortable sharing. Do not feel compelled to share anything personal. Anything you share may be used as training data for the AI.\n\nHere are a few ways to get the most out of the interaction with the AI Scenario builder:\n\nGoal play. In role-playing scenarios, you are given a role to play. But in this scenario, you can play the role but keep the goal of the exercise in mind \u2013 to practice what you learned during the scenario. Immerse yourself in the scene and play your role, recalling what you learned and applying it to the challenges in the scene.   \nGive it extensive responses. The more extensive your answers and explanations the more you can get out of the practice session.   \nSeek clarification. If you are confused at any point, ask questions to help clarify. Try a different scenario. If you prefer a different scenario, try pasting in the prompt again. Because the AI response is randomized, the scenario will differ every time you paste in the prompt.\n\nShare your complete interactions with the AI. In a paragraph, briefly discuss what you learned from using the tool. How well did it work? Did anything surprise you? What are some of your takeaways from working with the AI? What did you learn about your reaction to the scene? What advice or suggestions did it give you? Was the advice helpful?\n\n# AI as Simulators: Build Your Own\n\nTo build your own scenario builder, start with the learning goal: For instance, the goal for this scene is for students to practice their interviewing skills.\n\nGoal: Tell the AI what you want it to do and what you don\u2019t want it to do. For instance, your goal is to give students practice in interviewing a candidate, focusing on hypothetical and behavioral questions and follow-up questions. Don\u2019t play both roles. Wait for the student to respond before moving ahead with the conversation.\n\nRole: Tell the AI who it is. For example, you will play the role of the candidate, and I will play the role of the interviewer .\n\nStep-by-step instructions. For instance, as the interviewer, I should have to ask questions, and the candidate will also get a chance to ask me a question. After four interactions, set up a consequential choice for me to make. Then wrap up by telling me how I performed as an interviewer and what I can do better next time.\n\nFinal Step: Check your prompt by trying it out. You may want to add more specifics about the concept, and you may want to provide the AI with specifics about your students\u2019 learning level. For example, tailor the interaction for students taking an undergraduate college course and focus on conducting structured interviews. You can continue to tweak the prompt until it works for you and you feel it will work for your students.\n\n# AI as Tool\n\nAs a general-purpose technology, AI tools can be used in a wide variety of ways, from writing software to acting as an interview subject for ethnographic insights to writing poetry. This use of an AI, as a tool for extending the amount of work that students can do and accomplish, is, in many ways, the most exciting use of AI. Because many AI uses are highly specific to individual classes and use cases, we encourage instructors to experiment with prompts. Further, educators should share prompts with peers to collectively improve our ability to use AI tools.\n\n# Conclusion\n\nWe propose that the advent of AI tools, which facilitate skill development and practice outside the classroom, warrants a re-examination of traditional assignments and classroom practices. As these tools have the potential to aid independent learning and potentially offer personalized engagement, educators can experiment with devoting more in-class time to active discussions, question-and-answer sessions, and collaborative exercises such as 'think-pair-share' sessions. Such changes foster an active learning environment, inviting each student to engage with class concepts, articulate reasoning, and actively construct knowledge. In this scenario, the AI aids provide personalized, readily available tutoring and coaching outside of the classroom, and the classroom transforms into a hub of systematic engagement. Here, discussion, group work, and reflection on asynchronous learning activities intermingle while teachers incorporate a variety of questioning techniques (Sherrington, 2020). In this classroom, each student should have the opportunity to practice and actively participate in discussions, creating an inclusive and deeply participatory learning environment (Sherrington, 2020).\n\nThese approaches are just the start of using AI in class. By sharing the advantages, as well as the risks of these new approaches, educators and students can begin to work together to come up with ways to train students to use AI responsibly in ways that enhance both their education and life outcomes. The challenges around AI remain significant, as do the opportunities. Only by learning to use these new tools firsthand can students begin to understand their implications and prepare themselves for a world where AI forms an important part of their lives.\n\n# References\n\nBjork, E. L., & Bjork, R. A. (2011). Making things hard on yourself, but in a good way: Creating desirable difficulties to enhance learning. Psychology and the real world: Essays illustrating fundamental contributions to society, 2(59-68).   \nBrown, P. C., Roediger III, H. L., & McDaniel, M. A. (2014). Make it stick. Harvard University Press.   \nCarey, B. (2015). How we learn: the surprising truth about when, where, and why it happens. Random House Trade Paperbacks.   \nChi, M. T., Roy, M., & Hausmann, R. G. (2008). Observing tutorial dialogues collaboratively: Insights about human tutoring effectiveness from vicarious learning. Cognitive science, 32(2), 301-341.   \nChi, M. T., Siler, S. A., Jeong, H., Yamauchi, T., & Hausmann, R. G. (2001). Learning from human tutoring. Cognitive science, 25(4), 471-533.   \nDeslauriers, L., McCarty, L. S., Miller, K., Callaghan, K., & Kestin, G. (2019). Measuring actual learning versus feeling of learning in response to being actively engaged in the   \nclassroom. Proceedings of the National Academy of Sciences, 116(39), 19251-19257.   \nDi Stefano, G., Pisano, G., & Staats, B. R. (2015). Learning by thinking: How reflection aids performance. In Academy of Management Proceedings (Vol. 2015, No. 1, p. 12709). Briarcliff Manor, NY 10510: Academy of Management.   \nDunlosky, J., Rawson, K. A., Marsh, E. J., Nathan, M. J., & Willingham, D. T. (2013).   \nImproving Students\u2019 Learning with Effective Learning Techniques: Promising Directions from Cognitive and Educational Psychology. Psychological Science in the Public Interest, 14, 4\u201358. http://doi.org/10.1177/1529100612453266   \nEdmondson, A. C. (2018). The fearless organization: Creating psychological safety in the workplace for learning, innovation, and growth. John Wiley & Sons.   \nEricsson, K. A., Krampe, R. T., & Tesch-R\u00f6mer, C. (1993). The role of deliberate practice in the acquisition of expert performance. Psychological review, 100(3), 363.   \nEricsson, A., & Pool, R. (2016). Peak: Secrets from the new science of expertise. Random House.   \nFiorella, L. (2023). Making Sense of Generative Learning. Educational Psychology   \nReview, 35(2), 50. Fiorella, L., & Mayer, R. E. (2015). Learning as a generative activity. Cambridge university press.   \nHaas, M., & Mortensen, M. (2016). The secrets of great teamwork. Harvard Business Review. Retrieved from https://hbr.org/2016/06/the-secrets-of-great-teamwork   \nHackman, J. R. (2011). Collaborative intelligence: Using teams to solve hard problems. BerrettKoehler Publishers.   \nHill, H. C. (2021). Learning recovery: The research on tutoring, extended school year, and other strategies. Education Week.   \nKirschner, P., & Hendrick, C. (2020). How learning happens: Seminal works in educational psychology and what they mean in practice. Routledge.   \nKirschner, P., & Neelen, M. (2018). No Feedback, No Learning. 3-Star Learning Experiences. https://3starlearningexperiences.wordpress.com/2018/06/05/no-feedback-no-learning/   \nKlein, G. (2007). Performing a project premortem. Harvard business review, 85(9), 18-19. Kraft, M., Schueler, B., Loeb, S., & Robinson, C. (February, 2021). Accelerating Student Learning with High- Dosage Tutoring. Annenberg Institute for School Reform at Brown University.   \nKross, E., & Ayduk, O. (2017). Self-distancing: Theory, research, and current directions. In Advances in experimental social psychology (Vol. 55, pp. 81-136). Academic Press. Mccrea, P. (2023). Developing expert teaching: A practical guide to designing effective professional development, for others and ourselves (High impact teaching).   \nMetcalfe, J. (2017). Learning from errors. Annual review of psychology, 68, 465-489.   \nMitchell, D. J., Edward Russo, J., & Pennington, N. (1989). Back to the future: Temporal perspective in the explanation of events. Journal of Behavioral Decision Making, 2(1), 25-38. Mollick, E.R. & Mollick, L. (2022). New Modes of Learning Enabled by AI Chatbots: Three Methods and Assignments (December 13, 2022).   \nMollick, E. R., & Mollick, L. (2023). Using AI to implement effective teaching strategies in classrooms: Five strategies, including prompts. Including Prompts (March 17, 2023).   \nOpenAI. (2023). GPT-4 technical report. Retrieved from https://openai.com/research/gpt-4/ Perkins, D. N., & Salomon, G. (1992). Transfer of learning. International encyclopedia of education, 2, 6452-6457.   \nRawson, K. A., Thomas, R. C., & Jacoby, L. L. (2015). The power of examples: Illustrative examples enhance conceptual learning of declarative concepts. Educational Psychology Review, 27, 483-504. Roscoe, R. D., & Chi, M. T. (2007). Understanding tutor learning: Knowledge-building and knowledge-telling in peer tutors\u2019 explanations and questions. Review of educational   \nresearch, 77(4), 534-574.   \nSch\u00f6n, D. A. (1987). Educating the reflective practitioner: Toward a new design for teaching and learning in the professions. Jossey-Bass.   \nSeligman, M. E., Railton, P., Baumeister, R. F., & Sripada, C. (2013). Navigating into the future or driven by the past. Perspectives on psychological science, 8(2), 119-141.   \nSherrington, T. (2020). Rosenshine's principles in action. John Catt Educational.   \nU.S. Department of Education, Office of Educational Technology, Artificial Intelligence and Future of Teaching and Learning: Insights and Recommendations, Washington, DC, 2023. Walton Family Foundation. (2023). Teachers and Students Embrace ChatGTP For Education. Retrieved May 27, 2023, from https://www.waltonfamilyfoundation.org/chatgpt-report Wiggins, G. (2015). Seven keys to effective feedback. ACSD.   \nhttps://www.ascd.org/el/articles/seven-keys-to-effectivefeedback   \nWillingham, D. T. (2021). Why don't students like school?: A cognitive scientist answers questions about how the mind works and what it means for the classroom. John Wiley & Sons. Willingham, D. T. (2023). Outsmart Your Brain: Why Learning is Hard and How You Can Make It Easy. Simon and Schuster.   \nWiliam, D. (2011). What is assessment for learning?. Studies in educational evaluation, 37(1), 3- 14.   \nWiliam, D., & Leahy, S. (2016). Embedding formative assessment. Hawker Brownlow   \nEducation.\n\nAppendix: Large Language Models and Prompt Compatibility   \n\n<html><body><table><tr><td>Approach</td><td>OpenAI ChatGPT 4</td><td>OpenAI ChatGPT 3.5</td><td>Microsoft&#x27;s Bing in Creative Mode</td><td>Anthropic&#x27;s Claude 2</td><td>Google&#x27;s Bard</td></tr><tr><td>Increasing Knowledge AI- Tutor</td><td>yes</td><td>no</td><td>yes</td><td>sometimes</td><td>no</td></tr><tr><td>Increasing Metacognition: AI Team</td><td>yes</td><td>no</td><td> yes</td><td>yes</td><td>no</td></tr><tr><td>Reflection Coach Increasing Metacognition AI Coach: Team</td><td>yes</td><td>no</td><td>yes</td><td>sometimes</td><td>no</td></tr><tr><td>Premortem Providing Feedback: AI Mentor</td><td>yes</td><td>no</td><td>yes</td><td>sometimes</td><td>no</td></tr><tr><td>Building Collective Intelligence: AI</td><td>yes</td><td>sometimes</td><td>yes</td><td>sometimes</td><td>no</td></tr><tr><td>Teammate Increasing Fluency: AI</td><td>yes</td><td>yes</td><td>yes</td><td>yes</td><td>yes</td></tr><tr><td>Student Practice: AI Simulator</td><td>yes</td><td>sometimes</td><td>yes</td><td>sometimes</td><td>no</td></tr></table></body></html>\n\nA chart for prompts that work with Large Language Models in this paper. Note: subject to change, as the models change.", "metadata": {"authors": ["Dr. Ethan Mollick", "Dr. Lilach Mollick"], "category": "research", "confidence_score": 0.8, "document_type": "journal", "has_abstract": true, "has_methodology": true, "has_results": true, "key_findings": [], "methodology": "theoretical", "pedagogical_confidence": 0.34, "pedagogical_implications": true, "publication_year": 2023, "research_questions": [], "source_file": "out_3FPBG2JY_Mollick_and_Mollick_-_2023_-_As.md", "subject_area": "education", "tags": ["large language models", "AI in education", "AI-assisted learning", "pedagogical approaches", "risk mitigation"], "title": "Assigning AI: Seven Approaches for Students with Prompts"}, "search_text": "Assigning AI: Seven Approaches for Students with Prompts large language models AI in education AI-assisted learning pedagogical approaches risk mitigation education # ASSIGNING AI: SEVEN APPROACHES FOR STUDENTS WITH PROMPTS\n\nDr. Ethan Mollick Dr. Lilach Mollick\n\nWharton School of the University of Pennsylvania & Wharton Interactive\n\nRevised September 24, 2023\n\n# Abstract:\n\nThis paper examines the transformative role of Large Language Models (LLMs) in education and their potential as learning tools, despite their inherent risks and limitations. The authors propose seven approaches for utilizing AI in classrooms: AI-tutor, AI-coach, AI-mentor, AI-teammate, AI-tool, AIsimulator, and AI-student, each with distinct pedagogical benefits and risks. The aim is to help students learn with and about AI, with practical strategies designed to mitigate risks such as complacency about the AI's output, errors, and biases. These strategies promote active oversight, critical assessment of AI outputs, and combination of the AI's capabilities with the students' unique insights. By challenging students to remain the \"human in the loop\", the authors aim to enhance learning outcomes while ensuring that AI serves as a supportive tool rather than a replacement. The proposed framework offers a guide for educators navigating the integration of AI-assisted learning in classrooms.\n\n# Contents\n\nLLMs: Prompts and Risks ..   \nAI as Mentor: Providing Feedback... 6   \nAI as Mentor: Example Prompt.. ... 6   \nAI as Mentor: Example Output.... . 8   \nAI as Mentor: Risks ... .. 8   \nAI as Mentor: Guidelines for teachers . 9   \nAI as Mentor: Instructions for students . . 9   \nAI as Mentor: Building your own prompt.. . 10   \nAI as Tutor: Providing Direct Instruction . 11   \nAI as Tutor: Example Prompt ... .. 12   \nAI as Tutor: Example Output.. . 14   \nAI as Tutor: Risks ... . 15   \nAI as Tutor: Guidelines for teachers.. . 15   \nAI Tutor: Instructions for students ... .. 16   \nAI Tutor: Build your Own .17   \nAI as Coach: Increasing Metacognition.. . 18   \nAI as Coach: Example Prompts.. . 19   \nAI as Coach: Reflection Prompt .. . 19   \nAI as Coach: Pre-Mortem Prompt.. "}, "title": "Assigning AI: Seven Approaches for Students with Prompts", "authors": ["Dr. Ethan Mollick", "Dr. Lilach Mollick"], "tags": ["large language models", "AI in education", "AI-assisted learning", "pedagogical approaches", "risk mitigation"], "filename": "out_3FPBG2JY_Mollick_and_Mollick_-_2023_-_As.md"}, {"score": 0.32228338718414307, "document": {"id": 1868, "file_path": "annotated_data/batch_001/out_92MY5TFH_Wang_&_Wang_Investigating_L2_wr.md", "filename": "out_92MY5TFH_Wang_&_Wang_Investigating_L2_wr.md", "content": "# Investigating L2 writers\u2019 critical AI literacy in AI-assisted writing: An APSE model\n\nChaoran Wang a,\\* , Zhaozhe Wang\n\na Department of Writing, Colby College, 5290 Mayflower Hill, Waterville, ME 04901, USA   \nb Institute for the Study of University Pedagogy, University of Toronto Mississauga, Department of Curriculum, Teaching and Learning, OISE,   \nUniversity of Toronto, 3359 Mississauga Road, Mississauga, Ontario L5L 1C6, Canada\n\n# A R T I C L E I N F O\n\n# A B S T R A C T\n\nKeywords:   \nGenerative AI   \nArtificial intelligence   \nChatGPT   \nAI literacy   \nCritical   \nAI-assisted writing   \nL2 writing\n\nWhile the need to foster critical AI literacy (CAIL) among L2 writers has gained increasing recognition, research offering empirically grounded models for integrating CAIL into L2 writing remains limited. To contribute to the ongoing research in AI-assisted L2 writing and CAIL, we designed the current study to understand how students used ChatGPT, a popular generative AI technology, to support their writing and to uncover their CAIL in their writing practices in two first-year writing classes in the US. Adopting a qualitative case study design, we analyzed stu dents\u2019 interview data, written reflections, AI logs, and screencasts of students\u2019 interactions with AI. Findings show that students utilized AI in various ways, including topic selection and brainstorming, outlining, revising, editing, and sourcing. We propose an APSE model based on four dimensions identified in students\u2019 CAIL while using ChatGPT: (1) critical awareness of AI (A), (2) critical positionality (P), (3) critical strategies for interacting with AI (S), and (4) critical evaluation of AI affordances (E). The model highlights the distinct yet overlapping components of CAIL and addresses specific concerns that L2 writers face to leverage generative AI\u2019s linguistic and rhetorical resources critically. Pedagogical implications include explicit instruction on CAIL, developing students\u2019 AI feedback literacy, fostering meta-skills in communication and evaluation, and enhancing their AI-assisted self-directed learning skills.\n\n# 1. Introduction\n\nFrom the initial hype to varying degrees of resistance and acceptance of generative AI, numerous discussions have emerged in both public and academic communities. L2 writing teachers have been striving to adapt their practice to this technological influence, either willingly or reluctantly (Praphan & Praphan, 2023). Today\u2019s writers have unprecedented access to learning resources based on large language models and advanced technologies, presenting both opportunities and challenges. These changes put at the forefront the need to understand students\u2019 AI-assisted writing practices to inform L2 writing pedagogy. As Pecorari (2023) points out, the question now is not whether but how to use generative AI. Writing teachers bear the responsibility to guide students in critically inquiring into the evolving linguistic, educational, and ethical implications of generative AI.\n\nThis responsibility aligns with the critical pedagogical tradition which advocates for empowering students as active participants in their learning and considering the social and ethical dimensions of their literacy practices (Freire, 1970; Giroux, 1997). As underscored by many language and literacy educators, teaching critical AI literacy (CAIL) to foster students\u2019 critical use of generative AI is of paramount importance and urgency (MLA-CCCC, 2023; Kern, 2024). Although various AI literacy frameworks have been proposed (e. g., Cardon et al., 2023; Long & Magerko, 2020; Ng et al., 2021; Warschauer et al., 2023), empirical research examining how students understand and develop critical AI literacy within the context of L2 writing remains in its early stages (Ou et al., 2024). We designed the current study to examine the construct of CAIL based on students\u2019 perspectives of and experiences with generative AI-assisted writing, informing ongoing scholarly discussions and conceptualizations of CAIL frameworks. We begin with reviewing current dis cussions on generative AI-assisted writing and models on AI literacy. Thereafter, we describe the research design and major findings of the study, shedding light on students\u2019 AI-assisted writing practices and their engagement with AI in developing CAIL. Drawing upon the findings, we propose an APSE model that conceptualizes critical AI literacy as comprising four interconnected components: critical AI awareness, critical positionality towards AI, critical strategies for human-AI interaction, and critical evaluation of AI\u2019s affordances within specific rhetorical and linguistic contexts. We conclude with practical strategies and pedagogical possibilities for L2 writing teachers to develop students\u2019 CAIL based on the APSE model.\n\n# 2. Literature review\n\n# 2.1. Generative AI-assisted writing\n\nThe discussion around generative AI and writing has been contentious. Scholars argue that generative AI has advantages such as supporting L2 writers\u2019 linguistic development (Yan, 2023), providing personalized and immediate feedback (Barrot, 2023), and relieving students\u2019 cognitive load (Wang, 2024) while offering affective benefits (Wang, Li, et al., 2024). However, they also acknowledge the challenges it poses to L2 students\u2019 learning and writing development, including various ethical and authorship concerns and issues of educational equity (Su et al., 2023).\n\nAmong the existing empirical studies on L2 writers\u2019 generative AI-assisted writing, many focus on students\u2019 academic writing at the postsecondary level. Tsai et al. (2024), in their experimental study with 44 undergraduate EFL students, found that ChatGPT-assisted revision significantly improved students\u2019 writing quality in vocabulary, grammar, organization, and content. Similarly, in Yan (2023) study, ChatGPT was found to be helpful in enhancing L2 writers\u2019 grammatical accuracy and lexical diversity. In another mixed-methods study by Woo et al. (2024), EFL students showed increased motivation and satisfaction with using ChatGPT for writing. However, they reported that the students also experienced high cognitive load, contrasting with Wang (2024) findings. This discrepancy may be attributed to Woo et al.\u2019s (2024) use of a think-aloud protocol during students\u2019 writing, as well as factors such as students\u2019 prior experience and familiarity with the AI tool and their digital self-management skills.\n\nIn another qualitative study of L1 and L2 students\u2019 generative AI-assisted writing process, Wang (2024) found that the students employed AI in various stages of their writing to address both higher-order (e.g., argument, structure) and lower-order (e.g., syntax, diction, grammar) issues. The study foregrounded two dilemmas faced by students: (1) maintaining one\u2019s own voice while preventing their writing from being \u201cAI-nized,\u201d i.e., the temptation to adopt AI suggestions which may lead to a similar machine-like linguistic and rhetorical style among diverse writers; and (2) balancing missed versus new learning opportunities, as AI could provide shortcuts to linguistic and ideational generation, potentially leading to learning loss \u2013 a common critique and concern among scholars (e.g., see Barrot, 2023; Tseng & Warschauer, 2023). Wang (2024) study also revealed that students sought to develop a sense of agency and criticality, indicating that they did not use AI technologies passively but tried to pursue new learning opportunities to enhance their writing. The study complicates the common concerns and oversimplified assumptions of students\u2019 behaviors, highlighting the importance of researching the tacit learning moments that arise from students\u2019 interactions with AI, as well as the nuances and di lemmas students encounter in their decision-making in AI-assisted writing.\n\nSimilarly, Warschauer et al. (2023) also identified three contradictions that L2 writers may face when using ChatGPT and other AI technologies: the \"imitation\" contradiction, the \"rich get richer\" contradiction, and the \"with or without\" contradiction. While there are conflicting scholarly opinions and empirical evidence that complement and challenge these contradictions (for example, see Sasaki, 2023), they all underscore the need for L2 writing instruction to consider how to effectively utilize generative AI technologies to empower students. This suggests that L2 writing teachers should provide explicit guidelines and instructions to help students leverage the AI tools without compromising their learning. Additionally, it highlights the necessity for further empirical evidence to validate the current scholarly discussions.\n\n# 2.2. AI Literacy\n\nScholars argue that the various challenges and contradictions L2 writers face call for the development of writers\u2019 AI literacy, so they can \u201cnavigate the unknown future of a technological revolution\u201d (Kubota, 2023, p. 1). Recent studies show that despite students\u2019 frequent use of and easy access to various AI technologies, they have a limited understanding of AI on a deeper level, and they tend to have various misconceptions and myths about AI (Bewersdorff et al., 2023). For instance, students demonstrate a lack of clarity regarding different critical aspects of AI use, including inclusiveness, bias, fairness, data privacy, social inequality, and academic integrity (Bewersdorff et al., 2023; Memarian & Doleck, 2023). Hence, critical AI literacy (CAIL) is of paramount importance in helping students become informed and conscientious users of AI.\n\nAI literacy, as a term, was first coined by Konishi (2015). Based on their review study, Laupichler et al. (2022) report that research on AI literacy is still in its infancy and that the question of how to teach AI literacy still remains unexplored. Similarly, Southworth et al. (2023) argue for the urgency of defining and establishing models of AI literacy. One of the widely cited models of AI literacy is by $\\mathrm { N g }$ et al. (2021, 2024), which conceptualizes and categorizes AI literacy into four aspects: namely, (1) know and understand the basic concepts and functionalities of AI, (2) use and apply AI applications in different contexts, (3) evaluate and create AI applications, and (4) be ethical and socially responsible users. $\\mathrm { N } g$ et al.\u2019s (2021) AI literacy framework draws upon the foundational elements and hier archical model of Bloom\u2019s taxonomy to outline the progressive skill levels essential for cultivating AI literacy.\n\nTable 1 Instructional Design and Practices Informed by AI Literacy Models $( \\mathrm { N } g$ et al., 2021; Warschauer et al., 2023).   \n\n<html><body><table><tr><td>Elements in AI Literacy</td><td>Learning Goals</td><td> In-Class Learning Activities</td><td>Assignments</td></tr><tr><td>Know and understand AI (Ng et al., 2021; Warschauer et al., 2023)</td><td>Introducing the basics of generative AI</td><td>Watching an instructional video on AI basics designed for lay audiences; Reading and discussing Chomsky et al.</td><td>Reading assignment</td></tr><tr><td>Use and apply AI (Ng et al., 2021); Access, navigate, and prompt AI ( Warschauer et al., 2023)</td><td>Practicing using ChatGPT; Exploring ChatGPT&#x27;s</td><td>Discussing Chomsky et al.&#x27;s critiques on AI; Discussing prompting strategies; Practicing using ChatGPT to edit a piece of</td><td>Screen-recording task that involves interaction with ChatGPT and think-aloud reflections;</td></tr><tr><td>Evaluate (Ng et al., 2021); Corroborate AI-generated content (Warschauer et al., 2023)</td><td>affordances and weaknesses; Critiquing ChatGPT- generated texts</td><td>freewriting; Comparing and discussing AI-made changes to reflect on use experiences</td><td>Written reflection assignment</td></tr><tr><td>AI ethics (Ng et al., 2021); Incorporate AI-generated content in ethically and effectively ( Warschauer et al., 2023)</td><td>Discussing academic integrity and ethical issues</td><td>Collaboratively researching and developing AI policies for the course, based on sample AI policies in higher education and academic publishing</td><td>Written reflection assignment + AI log and essay drafts submission</td></tr></table></body></html>\n\nPartially drawing upon $\\mathrm { N g }$ et al. (2021, 2024), Tseng and Warschaeur (2023) and Warschauer et al. (2023) proposed a five-component AI literacy framework specifically for L2 writers to navigate the contradictions associated with using AI to enhance their learning. The components include: (1) understand the basics of AI writing tools\u2019 learning affordances and shortcomings including biases; (2) access and navigate AI-writing tools for specific writing purposes and contexts; (3) prompt AI to generate useful information; (4) corroborate AI-generated information to evaluate the accuracy and biases; (5) incorporate AI-generated content in effective and ethical ways. Although Warschauer et al. (2023) pioneered this AI literacy framework for L2 writing, further research is needed for validation.\n\nIn accordance with the scholarly conversation, the Modern Language Association-Conference on College Composition and Communication (MLA-CCCC) Joint Task Force on AI and Writing (2023) advocates for fostering critical AI literacy (CAIL) among both students and educators as a priority. They regard CAIL as part of digital literacy, briefly defining it as \u201cliteracy about the nature, capacities, and risks of AI tools as well as how they might be used\u201d (p. 7). So far, research remains scarce on conceptualizations of critical AI literacy, specifically in terms of what CAIL encompasses within L2 writing and how students engage with it in their AIassisted writing and language learning practices. We thus design the current study to uncover how students incorporate CAIL in their real-life writing practices and to inform an empirical evidence-based CAIL framework. This, in turn, will provide writing instructors with insights to foster students\u2019 CAIL in their instructional practices. The research questions guiding our inquiry are as follows:\n\n(1) How do L2 students use ChatGPT, a popular generative AI technology, to assist with their writing? (2) How are the L2 student writers\u2019 CAIL (or lack thereof) evidenced in their interactions with ChatGPT and their linguistic and rhetorical decision-making?\n\n# 3. Method\n\nThis study is part of a larger research study on critical AI literacy in postsecondary writing classrooms that involve both L1 and L2 writers. For this study, we adopted an exploratory qualitative case study design (Yin, 2018) to understand how L2 students engage with CAIL in their AI-assisted writing. We both identify as multilingual, international teacher-researchers, professionally trained and working at the intersection of writing studies and applied linguistics within the North American context. While we recognize the potential of technologies to empower L2 writers, we remain concerned about a general perception of students\u2019 uncritical reliance on them, as discussed in the existing scholarship (e.g., Barrot, 2023; Cardon et al., 2023; Stojanov et al., 2024). Overall, our multilingual identities and writing experiences inform us to adopt an open attitude towards understanding participants\u2019 diverse decision-making regarding whether and how they chose to use generative AI in their writing. However, we also acknowledge that our professional training and roles as teacher-researchers may have influenced both our analytical lenses and participants\u2019 willingness to disclose certain behaviors or attitudes.\n\n# 3.1. Context of the study\n\nThe study was conducted in two sections of the same first-year writing course at a liberal arts college in the Eastern United States in 2023. The writing classes followed the same syllabus and were taught by the first author. There were 27 students, including seventeen L1 and ten L2 students from diverse cultural-linguistic backgrounds, enrolled in the two classes. The writing course had three major units, each coming with one major writing assignment. One of the major assignments invited students to write about a family-related concept of their choice. The goal of the assignment was to encourage students to reflect on and offer fresh insights into cultural concepts, drawing upon their personal experiences and secondary research. The unit covered seven class sessions, each lasting 75 minutes. Topics discussed included strategies for concept explanation, source evaluation, artificial intelligence, finding one\u2019s voice as an academic writer, and peer review.\n\nTable 2 Demographic information of the student participants.   \n\n<html><body><table><tr><td>Pseudonym</td><td>Gender</td><td>L1</td><td>Educational Background</td></tr><tr><td>Hyun</td><td>Male</td><td>Korean</td><td>International high school in Mainland China</td></tr><tr><td>Aye</td><td>Female</td><td>Burmese</td><td>International high school in Hong Kong</td></tr><tr><td>Yun</td><td>Female</td><td>Chinese</td><td>International high school in Canada</td></tr><tr><td>Dawei</td><td>Male</td><td>Chinese</td><td> International high school in Mainland China.</td></tr><tr><td>Shuya</td><td>Female</td><td>Chinese</td><td>Private high school in the US</td></tr><tr><td>Yawa</td><td>Male</td><td>Twi</td><td>Public high school in Ghana</td></tr><tr><td>Dofi</td><td>Female</td><td>Twi</td><td>Public high school in the US.</td></tr><tr><td>Paulo</td><td>Male</td><td> Spanish</td><td>Public high school in the US.</td></tr><tr><td>Felix</td><td>Male</td><td> Spanish</td><td>Public high school in the US</td></tr><tr><td>Nadia</td><td>Female</td><td>Arabic</td><td> Public university in Egypt</td></tr></table></body></html>\n\nTwo class sessions were dedicated to discussing generative AI and large language models inspired by the broad ideas presented in previous AI literacy frameworks (e.g., Warchauer et al., 2023), such as introducing the basics of the technology, exploring its affordances, weaknesses, biases, and relevant academic integrity issues, and practicing using ChatGPT and critiquing ChatGPT-generated texts (see Table 1 for a detailed description of our instructional design). The sessions were exploratory in nature, meaning that the students experimented with ChatGPT and formed their understandings through hands-on experiences \u2013 an approach aligned with our research design as an exploratory, qualitative case study. To be more specific, in the first class, students discussed Chomsky et al. (2023) opinion piece \u201cNoam Chomsky: The False Promise of ChatGPT\u201d published in The New York Times (Chomsky, Roberts, & Watumull, 2023). Following this, students used ChatGPT to edit a piece of their own freewriting, and then compared and discussed the AI-made changes to reflect on their use experiences. The second session introduced common academic integrity concerns about the use of generative AI in educational settings. Working in collaborative groups, students reviewed various policies on AI usage in higher education and academic publishing, ultimately developing a policy for their own use in this course. Thus, the CAIL examined in this study is grounded in students\u2019 direct engagement with the technology, reflecting their authentic, first-hand experiences as opposed to following prescriptive, teacher-fronted instructional models. ChatGPT (GPT 3.5) was selected because it was one of the most popular generative AI technologies at the time of the study and was free, making it accessible to everyone in the class.\n\nWhile learning about the generative AI tool, the students also completed a task that involved screen-recording their interactions with ChatGPT while articulating their thoughts, feelings, and perceptions about their use experience. This was designed to help the instructor gauge the students\u2019 thought processes while using the AI tool. For the final assignment, students were encouraged, but not required to incorporate ChatGPT into their writing. The instructor made the decision because she would like to give students the flexibility to choose the approaches that best suit their individual needs and learning styles. This decision also helps mitigate the potential impact of researchers\u2019 positionality on students\u2019 engagement with AI. Those who opted to use ChatGPT were required to submit their AI use logs along with a reflection detailing their specific use of AI, and the decision-making and critical thinking involved in their decision. All ten L2 writers enrolled in the classes reported utilizing ChatGPT to varying extents and were subsequently invited to participate in this study.\n\n# 3.2. Data collection and analysis\n\nFollowing the college\u2019s IRB protocol, the researchers sent research participation invitations via email after the students had completed the writing courses, ensuring there was no conflict of interest. After participants provided written consents, face-to-face interviews were scheduled and conducted. Table 2 shows the demographic information of the ten students who voluntarily partici pated in this study. Coming from diverse cultural-linguistic and educational backgrounds, the students generally demonstrated advanced English language proficiency, though their experiences with academic English writing varied. Hyun, Aye, Yun, and Dawei, who attended international high schools that adopted the International Baccalaureate (IB) curriculum, had extensive practice in ac ademic English writing in their former education. Shuya, Dofi, Paulo, Yun, and Felix, having completed high school education in the US/Canada, demonstrated integrated proficiency through their immersion in English-speaking environments. Yawa and Nadia had comparatively less practice in academic English writing during their formal instruction in public schools in Ghana and Egypt.\n\nPrimary data sources include semi-structured interviews with nine participants, each lasting from 35 minutes to 1 hour. The in terviews were designed to understand students\u2019 AI-assisted writing processes, their perceptions of using ChatGPT for writing, and their experiences of navigating ChatGPT to achieve their particular writing goals. One student chose not to participate in the interview but provided written consent for the research team to use all other types of data. In addition to interviews, the ten participants\u2019 written products and other documents, such as essay drafts, critical reflections on AI usage, AI log data, and screencasts of their AI interaction, were also collected. These written and multimodal data sources showed students\u2019 progress over the project, documenting how they prompted ChatGPT and evaluated and utilized the AI-generated information, as well as the thinking underlying their decisions. Thus, the various data sources not only served triangulation purposes but also helped to create a holistic understanding of students\u2019 CAIL.\n\nTable 3 An example of the coding approach featuring Theme 4 for the second research question.   \n\n<html><body><table><tr><td>Theme #4</td><td>Higher level code</td><td>Lower level code</td><td>Interview data</td><td>Other types of data (i.e., AI logs/ screencasts, written self-reflection, essay drafts)</td></tr><tr><td>Critical evaluations of AI affordances</td><td>Evaluation of information accuracy</td><td>Human</td><td>&quot;You should at least know something about it...like interaction with friends or the professor.&quot; (Dofi, Interview) &quot;I knew that was accurate because I&#x27;m from that place.&quot; (Dofi, Interview) &quot;The reading we did in class, I finally used that as a source.&quot; (Shuya, Interview)</td><td>&quot;The inaccuracy of ChatGPT can be countered by having prior knowledge about the topic...If ChatGPT was inaccurate from the knowledge I carried, I could consider the authenticity of that piece of information.&quot; (Dofi, Reflection) Shuya&#x27;s AI log: &quot;why individuals engage in multiple simultaneous relationships&quot; (Shuya,</td></tr><tr><td rowspan=\"4\"></td><td></td><td></td><td></td><td>AI Log, Dialogue 1 &amp; 2) Shuya&#x27;s final draft citing a course reading: &quot;They [HaiWang] believe that maintaining a committed and long-term relationship is impossible to maintain happiness (Kimmel, 2008).&quot; (Shuya, Final Draft) Shuya&#x27;s comments on ChatGPT&#x27;s edits: &quot;A</td></tr><tr><td>Evaluation of linguistic and rhetorical repertoire</td><td>Language proficiency Perception of</td><td>&quot;I don&#x27;t use ChatGPT because such sophisticated language doesn&#x27;t look like mine... I know what kind of stuff I can write based on my abilities.&quot; (Shuya, Interview) &quot;When it comes to the Western kind of</td><td>dynamic lexicon emerges continually&#x27; - That sounds complicated. And the word nuances.&#x27; I normally wouldn&#x27;t use these words.&quot; (Shuya, AI Screencast) &quot;It facilitates the communication of my ideas</td></tr><tr><td></td><td>good English academic writing</td><td>writing, GPT is really good with that.&quot; (Yawa, Interview)</td><td>to fit with academic writing.&quot; (Yawa, Reflection) Yawa&#x27;s AI log: &quot;create a transition&#x27; between two ideas. (Yawa, AI Log, Dialogue 4)</td></tr><tr><td></td><td>Intended audience</td><td>&quot;My positioning for my audience is they should be at the level of native language speakers.&quot; (Dawei, Interview)</td><td>Dawei&#x27;s AI log: &quot;correct the grammar in the following paragraph&quot; (Dawei, AI Log, Dialogue 1) Dawei&#x27;s final draft which adopted all AI&#x27;s edits</td></tr><tr><td rowspan=\"2\"></td><td>Evaluation of learning context</td><td>Type of learning task</td><td>&quot;I used it to explain concepts I don&#x27;t understand in the source.&quot; (Nadia, Interview)</td><td>(Dawei, Final Draft, p. 5, para. 1) &quot;Summarize this reading as a point&quot; (Yawa, AI Log as in the Reflection)</td></tr><tr><td></td><td>Goal of learning</td><td>&quot;I really think the essence of having the first year writing classes is help us to basically read and write. I feel it&#x27;s an essential part of schooling and learning.&quot; (Dofi, Interview)</td><td>&quot;The reason for using ChatGPT should be centered on learning rather than perfecting the work already done.&quot; (Dofi, Reflection)</td></tr></table></body></html>\n\nThe data analysis was a recursive process that started with thematic analysis (Saldana, \u02dc 2015) of the interview transcripts. The first author first coded four interview transcripts, and then the two authors went through four rounds of collaborative debriefing to refine the codebook and resolve any disagreements. With the co-developed coding scheme, the first author continued coding the remaining six interview transcripts. Following the coding scheme developed from the primary interview data, the authors then coded and grouped other types of data. Table 3 demonstrates our coding approach, featuring one of the themes developed for the second research question as an example. This coding process helped make connections between students\u2019 perceptions and understandings of CAIL and their writing practices. Comparisons and modifications for synthesizing findings across data were made through a recurring process of close reading, checking, doubting, and re-confirming the analysis between the two co-authors.\n\n# 4. Findings\n\n4.1. How do L2 students use ChatGPT, a popular generative AI technology, to assist with their writing?\n\nThe students used ChatGPT in various ways, including topic selection and brainstorming, outlining, revising, editing, translating sources, and using AI-generated texts as sources. Eight out of the ten students used ChatGPT for brainstorming. One reason, as Dofi mentioned, was to manage the \u201coverwhelming amount of information\u201d (Dofi, Interview) on unfamiliar topics. Similarly, Shuya noted that AI could \u201cprovide a basic overview of everything\u201d (Shuya, Interview), which helped her to explore possible directions. Paulo mentioned that ChatGPT helped with his usual writer\u2019s block: \u201cIt was a good change from the usual staring at a blank wall I do when trying to come up with ideas\u201d (Paulo, Reflection). Other students purposefully chose to use AI for brainstorming even when they were already familiar with a topic. Hyun explained, \u201cI want to explore other perspectives, so I compare the contents between what I had, and what it created. And then I used some of it that seemed to fit my topic.\u201d\n\nSix students also used ChatGPT for outlining, driven by similar reasons and purposes. For instance, Yawa followed his regular writing habit of creating a one-pager with everything he wanted to say, then used ChatGPT to organize these initial ideas into an outline for him to build upon. Similarly, Hyun wanted to save the mental struggle and time needed to connect paragraphs: \u201cI\u2019m good at structures because I spent really a lot of time structuring the essay, like two or three hours\u2026AI can make me spend less time considering how to connect it mutually, like, paragraph to paragraph.\u201d Shuya also believed that she could do the work well, but she opted to use AI for time-saving purposes: \u201cI know myself even without AI, I can still sort it out. I would be like sorting information bit by bit. But ChatGPT gave you result within seconds\u2026It was soooo fast.\u201d\n\nTable 4 Sample prompts participants used for revising and editing suggestions from ChatGPT.   \n\n<html><body><table><tr><td>Prompt types</td><td>Sample</td></tr><tr><td rowspan=\"4\">Generic prompts</td><td>Which part do you think it lacks? Which parts do you think I should improve? (Hyun)</td></tr><tr><td>What suggestions do you have for me to improve ...? (Aye)</td></tr><tr><td>If you were to like grade this, what would be my grade? How would you suggest to make this better? (Yawa)</td></tr><tr><td>Modify this essay. (Shuya)</td></tr><tr><td rowspan=\"7\">Tailored prompts</td><td>Are my arguments clear? (Yawa)</td></tr><tr><td>Create a transition between XX [sentence A] and XX [sentence B] (Yawa)</td></tr><tr><td>Please correct the grammar in the following paragraph. (Dawei)</td></tr><tr><td>Less overdone give me a word that can replace this [Note: This&quot; means less overdone&quot;]. (Yawa)</td></tr><tr><td>Revise the wording only and not the content so as to keep my original ideas. (Yun)</td></tr><tr><td>Change my word choice. (Hyun)</td></tr><tr><td>Reduce this to 400 words. (Felix)</td></tr></table></body></html>\n\nSeven students also reported using ChatGPT for revising and editing. AI log data showed that the students input chunks of text into ChatGPT and prompted the AI to provide feedback. Grammar and vocabulary were two common aspects for which the students sought ChatGPT\u2019s help. Table 4 provides a list of sample prompts students used from their AI logs and screencasts. These include generic prompts that ask ChatGPT for broad feedback without identifying specific areas for improvement, as well as more tailored prompts that ask ChatGPT to target specific aspects of writing such as argument, transition, grammar correctness, diction, and text reduction. Apart from using ChatGPT to directly edit one\u2019s writing, Yawa, for instance, also utilized it like a dictionary or Thesaurus for wording suggestions. As he shared: \u201cI already have a word in my mind, but I\u2019ll ask it\u2026Could you suggest another word that would be more suitable? Would you suggest five words that would be suitable? Then I\u2019ll look through and find which is the best.\u201d Notably, the process of seeking feedback for editing and revision was usually iterative, moving from general to specific or from addressing one specific point to another. For instance, in the screencast of his interaction with ChatGPT, Hyun first prompted the AI to \u201ccheck my grammar,\u201d and then asked, \u201cIs there any other feedback for my essay in terms of structure or APA in-text citations?\u201d\n\nFive students also used ChatGPT for sourcing, which was reported to be particularly helpful to address topics related to their own cultures. This included translating L1 sources, finding relevant L2 sources, and incorporating L2 sources into their writing. Hyun pointed out that because he was writing about gender roles in South Korean households, the translating function of ChatGPT was more effective than GoogleTranslate, allowing him to use sources more easily and present the latest local information to his global readers (Hyun, Reflection). Shuya, on the other hand, noted another interesting use of ChatGPT for searching English sources in her essay:\n\nI couldn\u2019t find direct sources related to my topic. But after asking ChatGPT, it gave me something relevant in English, which helped me to find ways to use English to explain this very Chinese term. ChatGPT gave me these directions you can take to explain, and based on these directions, you can find sources.\n\nShuya\u2019s essay topic was Haiwang (\u6d77\u738b), an emerging term among young people in China. She was unsure where to begin her research because she was unfamiliar with both the academic language related to the phenomenon and the English equivalent of the term. Thus she framed her understanding of the term into an AI prompt: \u201cpeople who are ambiguous with many people at the same time but are not committed to a love relationship,\u201d trying to elicit related English concepts from the AI (see Fig. 1). Upon reading ChatGPT\u2019s responses, Shuya located a few key terms like \u201cmulti-lover\u201d and \u201cnon-monogamous relationship\u201d that aided her later academic search (Shuya, Reflection). In addition to identifying academic registers for research, Shuya acknowledged that this use of ChatGPT allowed her to consider how the cultural meaning of a Chinese word \u201ccould be possibly used in the English context\u201d (Shuya, Interview). This illustrates her effort to leverage the capabilities of the large language model to write for cross-cultural audiences.\n\nAnother student Dofi directly cited ChatGPT as evidence. Table 5 presents a comparison between her AI log and part of a paragraph in her final draft discussing meal sharing and meal preparation, in which she incorporated AI\u2019s responses into her writing. Notably, she used \u201cresearch discovered from ChatGPT\u201d to refer to the AI-generated information, treating AI as a secondary research source. This is also evident in her approach to integrating the information, where she summarized and paraphrased the AI text to represent its meaning. Similar to Shuya, Dofi struggled to find sources related to her argument about Ghanaian family practices, so she resorted to ChatGPT. Dofi knew that ChatGPT was not a \u201cgood source,\u201d but she used it anyway as she believed it necessary to find external evidence to back her own experience, so as to meet her understanding of the expectations of English academic writing. She explained: I knew that [the ChatGPT-generated information about Ghana] was accurate because I\u2019m from that place, but I just needed a source to back it up. Sometimes you just like to put down your perspective, but you want evidence to back you up\u2026I feel like coming here [the US], I definitely had to learn to write again, learn how to do an essay. (Dofi, Interview)\n\nOther AI-assisted source use also included summarizing articles for integrating sources into writing. For instance, in Yawa\u2019s AI log, he prompted ChatGPT to \u201csummarize this article as a point\u201d (Yawa, AI log) for the convenience of incorporating it into his writing. He explained that this approach allowed him to \u201cretrieve the main ideas without having to read everything,\u201d and that ChatGPT helped summarize scholarly sources into \u201conly the important parts I needed for evidence in my essay\u201d (Yawa, Reflection). Nadia took a different approach, using ChatGPT to help her understand a source by asking it to \u201cprovide explanations for a paragraph or the whole reading.\u201d She highlighted the importance of reading the source herself to verify the information, noting that \u201cChatGPT was not always\n\n# Anonymous\n\nwhy some young people like to be ambiguous with to many people at same time but not have a love relationship\n\n# 5 ChatGPT\n\nThere can be several reasons why some young people may choose to be ambiguous or non-committal in their interactions with multiple individuals without pursuing traditional love relationships:\n\n![](img/3bdbbb8cef86a0f684bac0f3cfd4736de790575bc3221e887ce620fd08d45e23.jpg)  \nFig. 1. A screenshot of Shuya\u2019s AI log.\n\n1. Fear of Commitment: Many young people may have a fear of commitment, which can be associated with concerns about being tied down or losing personal freedom. They might prefer to keep their options open and avoid getting into a serious, committed relationship.   \n2.Exploration and Self-Discovery: Young adults often go through a period of self-discovery and exploration. They may want to meet and interact with a variety of people to better understand their own preferences, desires, and what they are looking for in a partner.   \n3. Emotional Unavailability: Some young individuals may not be emotionally ready for a committed love relationship. They might have unresolved emotional issues, past traumas, or simply not feel emotionally prepared for the demands of a serious relationship.   \n4. Fulfilling Different Needs: Being ambiguous or non-committal can allow individuals to fulfilldifferent needs from different people. They may seek emotional support, physical intimacy, companionship, or intellectual stimulation without putting all these expectations on a single partner.   \n5. Pressure to Settle Down: Young people may also face societal or peer pressure to settle down and have a serious relationship. Choosing to remain ambiguous with multiple people can be a way to resist these pressures and maintain independence.   \n6. Focus on Personal Growth: Some individuals prioritize personal growth and development over romantic relationships during certain phases of their lives. They may choose to keep things ambiguous with others to focus on their goals and aspirations.   \n7. Avoiding Relationship Drama: Young people may have witnessed or experienced relationship drama and conflicts, leading them to avoid entering into committed relationships that could potentially involve such drama.   \n8.Casual Dating Culture:In some cultural or social contexts, casual dating without the expectation of a Iove relationship is more common and accepted. This can influence the behavior of young people.\n\ncorrect but it could give me a better idea\u201d (Nadia, Interview).\n\nThis section shows students\u2019 diverse ways of utilizing ChatGPT to assist with their writing and research processes, demonstrating how they leveraged ChatGPT\u2019s affordances to achieve their specific purposes while addressing the challenges they encountered during the writing task.\n\n4.2. How are the L2 student writers\u2019 CAIL (or lack thereof) evidenced in their interactions with ChatGPT and their linguistic and rhetorical decision-making?\n\nFollowing an inductive thematic analysis, we identified four aspects in which students demonstrated CAIL while utilizing ChatGPT to assist with their writing: (1) having a critical awareness of AI affordances and limitations, (2) maintaining a critical positionality, (3)\n\nTable 5 A comparison between Dofi\u2019s AI log and final draft.   \n\n<html><body><table><tr><td>AI Log</td><td>Anonymous Benefits of meal sharing and meal preparation? ChatGPT Meal sharing and meal preparation offer various benefits within a family or a community: Meal Sharing: 1. Social Bonding:Sharing meals fosters social connections and strengthens relationships within the family or community.. 2.Communication and Connection:It provides a platform for conversation, sharing stories, and exchanging ideas,enhancing communication. 3. Cultural Transmission: Meals are often a platform for passing down traditions, recipes, and cultural values from generation to generation. 4. Emotional Nourishment: It provides emotional support, comfort, and a sense of belonging. Meal Preparation: 1. Collaboration and Togetherness:Working together to prepare meals encourages</td></tr></table></body></html>\n\nTable 6 A comparison of Hyun\u2019s first draft, AI log, and final draft.   \n\n<html><body><table><tr><td>First Draft</td><td>[1] In recent decades, South Korea has undergone a remarkable transformation, not only in it economic and technological landscapes but also in the dynamics of its sct..2] One of the most string and profound changes has ben the shift in traditional gnder roles within South Korean households, particularly the evolving role of men. [3] The family members had no choice but to be dependent on the patriarch the representative of the family, responsible for the family&#x27;s livelihood and the flow of information from society.</td></tr><tr><td>Hyun&#x27;s Prompt ChatGPT&#x27;s response</td><td>Check my grammar. Your essay is well-written, but I can provide some suggestions for improving the grammar and clarity of certain sentences: 1. In the opening paragraph, consider rephrasing to enhance clarity: *In recent decades, South Korea has undergone significant</td></tr><tr><td></td><td>transformations, not only in is economic and technological landscapes but also in the dynamics of it society. One f the most striking changes has been the shift i traditional gender roles within South Korean households, particularl the evolving roles of both genders . 2. In the same paragraph, when discussing the patriarchal structure, it might be clearer to say: Family members had no choice but to be</td></tr><tr><td>Final Draft</td><td>dependent on the patriarch, who was responsible for the family&#x27;s livelihood and the flow of information from society.&quot; [1] In ret deades, South Korea has underone sigficant tranomations, not only i is eonomic and technological landscapes but also in the dynamics of it society. 2] One of the most striking changes has ben the shift intraditional gender roles within South Korean households, particularly the evolving role ofboth gender..[3] Family members had no choice but to be dependent on th patriarch, who</td></tr></table></body></html>\n\ndeveloping and applying critical strategies for interacting with AI, and (4) critically evaluating AI\u2019s affordances. Below we explain each aspect with specific examples from the participants.\n\nCritical AI awareness. Apart from understanding and utilizing ChatGPT\u2019s functionalities as demonstrated in the previous research question, students also exhibited critical awareness of the algorithmic operational logic of generative AI as well as the data upon which these technologies are trained. In particular, they showed criticality towards two issues regarding training data \u2013 coded bias and underrepresented languages. For instance, based on his personal experiences interacting with AI and what he had read on social media, Hyun pointed out that ChatGPT is especially biased towards \u201cpolitical things\u201d due to the whiteness of its training data:\n\nThere is an island in Korea called Dokdo. We are fighting with Japan about this territory\u2026ChatGPT said it\u2019s a Japanese territory. So it depends on where they get it, what is more common, what is more stereotypical about those things. Also, I saw some article that there is some kind of bias in making on AI, especially for making a human face. Most of the training data are based on White people.\n\nYawa also acknowledged AI\u2019s inadequacy in providing information related to underrepresented languages and cultures like his first language Twi, given the scarcity of linguistic resources in the training of the large language model. As he shared: \u201cTwi is not a popular language, like French or Chinese. For Twi, it all comes down to the fabrication of information, it would probably give a more generalized, \u2018Oh, it might mean this.\u2019\u201d\n\nAnother notable aspect of students\u2019 critical AI awareness is their recognition of how generative AI is programmed can result in patterned, inconsistent, and inaccurate responses that limit its effectiveness and reliability as a learning and writing assistance. Yawa, in his reflection, acknowledged that a large language model is essentially \u201ca predictive model,\u201d thus providing information that can be repetitive. Yun noted that the \u201cblack-box\u201d nature of ChatGPT algorithms led to inconsistent responses even with the same prompt, and sometimes irrelevant information. Similarly, Hyun observed that generative AI might not follow prompts precisely. He noted: \u201cSo I put my entire essay and then said \u2018change my grammar.\u2019 Sometimes it\u2019s kind of annoying because it doesn\u2019t just change my grammar, it entirely changes the sentence structure although I said JUST change my grammar\u201d (Hyun, Interview). Aye, when asking ChatGPT how parenting styles in Myanmar impact children\u2019s academic success, observed that \u201csome of the answers were quite repetitive, and others contradicted each other\u201d (Aye, Reflection). Consequently, she believed that ChatGPT lacked sufficient knowledge about her culture and was not reliable.\n\nCritical AI positionality. Discerning generative AI\u2019s powerful affordances for assisting with various aspects of writing and its limitations, the participants developed nuanced positionalities to navigate their relation with AI in multifaceted ways. Firstly, all the students emphasized the necessity of one\u2019s originality and authorial voice when using AI in the writing process, ensuring that the work reflects one\u2019s unique thinking. Hyun pointed out that \u201cAI is all based on data people have already created but cannot provide any new kind of thing\u201d (Hyun, Interview). Shuya and Yawa contrasted the human writer\u2019s need to \u201cinvent\u201d with AI\u2019s tendency to produce \u201cclich\u00b4e, generalized\u201d texts.\n\nEven though students shared agreement on the importance of originality, they practiced being \u201coriginal\u201d in different ways. Dofi, for instance, believes that \u201cthe writer has to generate your own ideas before seeking the help of AI\u201d (Dofi, Interview). Similarly, Yawa did not use AI for topic selection and brainstorming because he felt it required personal creativity (Yawa, Reflection); thus, he only started to use AI for creating an outline based on his freewriting. Shuya, on the other hand, used ChatGPT to generate a list of ideas for her essay, and from there, she did more research and expanded them. She described using AI to get \u201csome inspiration\u201d and \u201ca rough shape of an idea,\u201d but emphasized that it is the author who must \u201csketch it out\u201d and create a vivid piece of work that represents their own voice. Shuya used a \u201ckey\u201d metaphor to describe her relationship with AI: she treats AI as a \u201cbasic key to a door behind which there is a range of possibilities,\u201d but it is the writer who unlocks the door and explores \u201cdifferent paths to destinations by themselves\u201d (Shuya, Interview).\n\nAnother student Hyun commented on the challenge of navigating the two sides of using AI, noting that while it can \u201cinspire\u201d ideas, it may also \u201csuppress creativity and critical thinking.\u201d He doubted that \u201cfinding information based on AI\u2019s ideas\u201d contradicts the purpose of writing which is to \u201cshow your own style, your own experiences, and your own thinking\u201d (Hyun, Interview). On the other hand, he also questioned to what extent using AI-suggested word choices could harm the author\u2019s voice: \u201cAI gives better word choices or something. So this for sure is a better tool, but I\u2019m just afraid that it\u2019s not going to be your essay\u201d (Hyun, Interview). Hyun\u2019s concern highlighted both the qualitative aspect of using AI for ideas and language, as well as the quantitative aspect of how much AI use differentiates between maintaining and losing one\u2019s own authentic voice in human-AI collaboration.\n\nTable 7 A comparison of Shuya\u2019s AI log and her final essay.   \n\n<html><body><table><tr><td>Shuya&#x27;s. AI log</td><td>3. Unfulfilled Needs: Some individuals may feel that they cannot meet all their emotional or physical needs within the confines of a monogamous relationship. Having multiple partners may provide them with the opportunity to fulfill different aspects of their desires. 4. Social and Cultural Factors: Cultural norms and attitudes towards monogamy and non- monogamy can vary significantly around the world. In some cultures or social circles, non- monogamous relationships are more accepted or common. 5. Technology: Online dating apps and social media have made it easier for people to connect with others, potentially leading to more casual or simultaneous dating or relationships. 6. Lack of Commitment: Some people may prefer to avoid long-term commitment or may not be ready for it, leading them to have multiple partners rather than settling into a single, exclusive relationship.</td></tr><tr><td>Shuya&#x27;s final essay</td><td>term, faithful relationship. In addition, in a relationship, everyone has some expectations and needs for their partner. But Haiwang just doesn&#x27;t put his needs and expectations on one person. They will meet the expectations of different people. For example, emotional needs, physical needs, companionship, etc. They have their unmet needs within the confines of a monogamous relationship. (Kimmel, 2008)</td></tr></table></body></html>\n\nHyun\u2019s question relates to another caution: writers should attend to possible AI induction, particularly for L2 writers who may harbor perceptions of their linguistic abilities as inferior to those of large language models. Hyun admitted his own tendency to regard AI suggestions as better, stating: \u201cAs long as it provides word choices, then you\u2019re going to be biased and think that word choice looks very good in this sentence\u201d (Hyun, Interview). Table 6 compares an excerpt of Hyun\u2019s introduction paragraph across his first draft, AI log, and final draft. Hyun accepted ChatGPT\u2019s grammatical and wording suggestions for all three sentences, though for slightly different reasons in each case. He admitted that while the change from \u201ca remarkable transformation\u201d to \u201csignificant transformations\u201d did not make a notable difference on the meaning, he accepted it due to his general tendency to trust AI\u2019s suggestion when it does not \u201cdamage the writer\u2019s voice and originality\u201d (Hyun, Reflection). For the second and third sentences, however, Hyun clearly noted that AI\u2019s edits contributed to greater conciseness (e.g., \u201cstriking changes\u201d) and improved accuracy (e.g., \u201cboth genders\u201d), while correcting grammatical errors and enhancing clarity (e.g., \u201cfamily members,\u201d \u201cwho was responsible\u201d), thus enhancing his voice.\n\nThree students particularly noted that their attitudes towards AI were culturally influenced, emphasizing the need to reflect on one\u2019s AI disposition in light of their cultural background. A notable example was Dofi, who moved to the US four years ago from Ghana. She shared,\n\nI definitely feel I\u2019m more traditional, especially because I\u2019m from Ghana, we barely would encourage this [AI-assisted writing]. It\u2019s always been the traditional \u2013 read books to enhance your vocabulary, to gain more knowledge, then apply them to your writing. And that\u2019s how you became a better writer overall. So I feel like I do have some hesitation when it comes to using AI completely. And I may not be the best at using AI completely just because of where I\u2019m from. (Dofi, Interview)\n\nSimilarly, Aye and Hyun acknowledged that integrating AI into their writing practices is a new concept and was not encouraged in the cultures where they came from, thus influencing their attitudes and proficiency with the AI tool.\n\nOverall, the students shared their dilemmas and different perspectives on balancing AI use with maintaining their own originality, voice, and autonomy. Their positionalities were shaped by their views on the responsibilities and ethics of being a writer, AI\u2019s intervention in their role in the writing process, and their culturally mediated AI disposition. The challenge of navigating the criticality spectrum is deeply personal, requiring thoughtful reflection on the extent to which one trusts AI. The student cases demonstrate that rather than a simple critical/uncritical divide, they positioned AI and themselves in complicated ways of navigating how AI fits into their vision of preserving originality and authorial voice within their specific writing practices.\n\nCritical strategies for human-AI interaction. To engage effectively and critically with AI, the students made efforts in developing critical strategies in various areas. The first area is prompt engineering. Hyun defined prompt engineering as \u201ccommunication between human and AI,\u201d placing AI not merely as a tool for human use, but as an active participant and learner in communication. He explained, \u201cAI is also learning from humans through the questions [humans ask], and how to communicate through that. We keep giving them data and then they keep improving\u201d (Hyun, Interview). Hyun believed that the benefits of prompt engineering skills extend beyond the context of AI, as it could help with \u201clearning how to ask people, how to better ask something, like communicating with people.\u201d In this sense, the student viewed prompt engineering as part of a larger communication skill for today\u2019s world. Similarly, Yawa noted from his experience that AI could be either a \u201cbad\u201d or \u201cgood\u201d tool, depending on how the user prompts it: \u201cI found a pattern: the specificity of my prompts affected AI\u2019s efficiency. When my prompts were not clear and specific, AI produced verbose content.\u201d (Yawa, Reflection).\n\nTable 8 A comparison between Shuya\u2019s paragraph and ChatGPT\u2019s edits.   \n\n<html><body><table><tr><td>Shuya&#x27;s text</td><td>In China, thee ralmany inteting words popular among ontmporary young people, bth ironc and otie, and hy ll hae thir nque conct.ry, in soct, sf may dife ons th oig Hng, ik scil, and schol ens, le ae his</td></tr><tr><td>AI&#x27;s edits</td><td>situation where they find out that they are a HaiWang after being in love with a person. In China, a dynamic exicon emerge continually, especill among today&#x27;s youth, who employ words both ironic and afirmative, each with its unue ane.his ter tricll htr inls, prenly me, w  lit and a nt for va ithin their relationships.</td></tr></table></body></html>\n\nIn addition to communicating with AI, the students who used ChatGPT for brainstorming particularly engaged in interactive processes that leverage AI\u2019s strengths in big data and information synthesis \u2013 an approach they used to help solicit and validate ideas to enhance their research process. For instance, Shuya used ChatGPT to confirm her hypothesis by cross-checking AI-generated information with her own knowledge. According to her reflection, she had already formed some hypotheses about the formation of the Haiwang phenomenon. Upon getting ChatGPT\u2019s answers, she felt validated and then conducted further research: \u201cOnce I knew exactly what I was looking for, I quickly figured out that some of the articles we had read were related to them, so I located the content immediately\u201d (Shuya, Reflection). Below are two screenshots showing part of her AI log (Table 7) and the final paragraph she wrote, which incorporated a course reading that supported the hypothesis she and ChatGPT shared regarding \u201cunfulfilled needs.\u201d It is worth noting that she adopted the exact wording \u201cwithin the confines of a monogamous relationship\u201d from ChatGPT without acknowledging the source.\n\nThe students\u2019 acknowledged that critical human-AI interaction was a proactive and continuous process of \u201cadapting to AI\u2019s rhythm\u201d (Dawei, Interview) and adjusting one\u2019s learning strategies to leverage the technology. This ongoing adaptation and trial process is a crucial part of the learning of AI. Another important aspect of this interaction is learning with AI, which entails active cognitive engagement and intellectual growth from the use of AI. Dofi noted that it required one\u2019s conscious efforts and the ability to manage ChatGPT\u2019s \u201ccontribution\u201d to one\u2019s learning. She illustrated this with a before and after example:\n\nBefore: Depending on the way you use AI, you may lose or you may gain, I feel like losing is in a sense that you don\u2019t do an intensive work in the background before using AI. But I do feel like I\u2019m working extensively in the background before seeking AI\u2019s help.\n\nAfter: If AI gives us good vocabulary, but then we\u2019re not even going back to look at the meaning of the word, just replace something, just put it in your essay, you just submit it. I feel like the next moment, you\u2019re not adding to your vocab in any way\u2026If it gives you these words that you\u2019ve never heard of, you should look at the meaning and learn from there. This I feel is helpful, because then it will decrease the overdependence, because you know you can put that in an essay again. (Dofi, Interview)\n\nThus, the dual dimensions of learning associated with effective and critical human-AI interaction represent a new type of learning that emerges from the technology. One needs to develop strategies in both to ensure they are \u201ctruly learning\u201d (Dofi) from interaction with AI.\n\nCritical evaluation of AI affordances. While critical AI awareness highlights how generative AI technologies function, critical evaluation of AI affordances emphasizes how well these technologies perform within specific rhetorical and linguistic contexts to achieve particular objectives. Students acknowledged the importance of critical evaluation of AI\u2019s outputs in terms of information accuracy (Felix, Dofi, Yawa, Shuya, Nadia, Hyun, Paulo), linguistic and rhetorical repertoire (Yun, Yawa, Dofi, Hyun, Nadia, Dawei), as well as their own learning context (Dofi, Dawei, Paulo, Nadia, Shuya, Aye) so that the use of AI fits their specific writing purposes. Aware of AI\u2019s inner workings and its impact on outputs, students evaluated AI\u2019s information quality, accuracy, and biases through various ways such as \u201cinteraction with friends and professors\u201d (Dofi), \u201creading\u201d (Nadia), and \u201cresearch\u201d (Felix).\n\nStudents\u2019 evaluations of generative AI\u2019s rhetorical and linguistic affordances for writing assistance varied, and had to do with their self-assessment of language proficiency, their perception of what constitutes good writing, and their consideration of the intended audience. Yawa exemplifies one typical perspective, stating that \u201cwhen it comes to the Western kind of writing, GPT is really good with that\u201d (Yawa, Interview). Yawa believed that AI could help \u201cfacilitate the communication of my ideas\u201d to better align with western rhetorical conventions (Yawa, Reflection). He also preferred to use ChatGPT than Grammarly to edit papers:\n\nIt [ChatGPT] could add words. It could bring in new sentences. If I was really good at writing, I would probably see it as an obstacle because it could change what I\u2019m trying to convey. But sometimes the sentence it edits might actually improve what I\u2019m trying to convey. But Grammarly doesn\u2019t really change anything. It\u2019s just fixing. (Yawa, Interview)\n\nThis quote suggests that Yawa found it more beneficial to seek ChatGPT\u2019s extensive assistance with deeper structural and rhetorical improvements beyond basic error correction. His metacognitive awareness of his current level of language proficiency and experience with Western rhetorical styles shaped his view of ChatGPT\u2019s affordances. Similarly, although feeling \u201coverwhelmed\u201d comparing her writing with ChatGPT\u2019s edits word by word, Yun acknowledged that she \u201cfelt grateful\u201d for the benefits ChatGPT provided in helping her edit \u201ca grammatically correct, well-structured essay\u201d and \u201clearn new ways of expression in English\u201d (Yun, Reflection). However, for the same reason, Shuya preferred to use Grammarly, as she felt that the sophisticated language generated by ChatGPT did not match\n\n# You\n\nplease correct the grammar in the following paragraph: As a non-native English speaker who is not so good at English writing, I usually use a lot of subordinate clauses and passive voice. The reason why I wrote in that way is not showing my ability of organizing sentences and logic. Oppositely, this way of writing helps me clear up my logic. Because I don't know how to explain and idea in a comprehensive and tidy way, I choose to use subordinate clauses and passive voice. After using them, I could easily organize the information of the whole sentence. Nothing could be better than explaining some concepts in a sentence with subordinate clauses and passive voice when you forgot to, or don't want to explain it before.\n\n# 5 ChatGPT\n\nAs a non-native English speaker who struggles with writing,I often resort to using numerous subordinate clauses and the passive voice. The reason for adopting this style is not to showcase my ability to structure sentences and logic. On the contrary, this approach aids in clarifying my thought process. Because I find it challenging to explain ideas in a comprehensive and orderly manner, Iopt for subordinate clauses and passive voice. These tools enable me to organize the information within a sentence more effectively.When I forget or prefer not to explain certain concepts in advance,there is nothing better than using subordinate clauses and passive voice to elucidate these concepts within a sentence.\n\nFig. 2. A screenshot of Dawei\u2019s AI log showing ChatGPT\u2019s edits on his writing.\n\nher proficiency level:\n\nI don\u2019t let myself use it for editing. I just use Grammarly. I don\u2019t use ChatGPT because such sophisticated language doesn\u2019t look like mine. The words it uses are too fancy\u2026I know what kind of stuff I can write based on my abilities. (Shuya, Interview)\n\nTable 8 shows an excerpt of Shuya\u2019s introductory paragraph and ChatGPT\u2019s modification. She commented that AI\u2019s phrasing, such as \u201ca dynamic lexicon emerges continually especially,\u201d sounded unnecessarily complicated to her. Shuya also pointed out that those \u201cspecialized and advanced words like \u2018nuances\u2019 and \u2018penchant\u2019\u201d were not expressions she would typically use (Shuya, AI Screencast), and could also change her original meaning (Shuya, Reflection). Thus, Shuya kept all her original text without taking any suggestion from ChatGPT.\n\nDawei, on the other hand, decided to use AI\u2019s linguistic suggestions despite believing that ChatGPT produces writing that is too \u201cadvanced\u201d and exceeded his current proficiency level, as he commented on ChatGPT\u2019s edits on his writing in Fig. 2:\n\nDawei\u2019s willingness to accept the suggestions stemmed from his assumption that his readers would be \u201cmore accepting\u201d to this style: \u201cMy positioning for my audience is they should be at the level of native language speakers. It\u2019s leaning towards this level, at least their level is higher than mine. I tend more towards lifting this thing a bit higher\u201d (Dawei, Interview). Dawei regarded native-like proficiency and native-speaker norms as integral to the academic authority he felt compelled to demonstrate in his writing, despite his actual audience being multicultural. In this sense, AI became a literacy broker catering to his idealization that English academic writing should \u201cpresent the logic in a way more akin to a native language speaker\u201d (Dawei, Reflection).\n\nIn contrast, other students like Dofi commented that \u201cexcessive\u201d use of academic language might not be appropriate: \u201cI feel like if it puts way too much advanced vocabulary, it\u2019s our responsibility to check through and make sure that the vocab in is perfect for the audience\u201d (Dofi, Interview). Aye, another student highly attuned to nuances in language, noted that AI edits could lead to \u201cinap propriate phrasing or word choices\u201d and sometimes \u201ca different interpretation\u201d of her original meaning, thus failing to \u201cpersonalize the text to my specific needs and voice\u201d (Aye, Reflection). The distinction in students\u2019 perspectives shows that students\u2019 language proficiency and metalinguistic awareness as well as their understanding of what constitutes good academic writing and audience ex pectations influence how they evaluate AI\u2019s linguistic and rhetorical affordances.\n\nStudents also critiqued how generative AI\u2019s neutral formality, such as its emotionless and formal language style, may influence how one engages with and evaluates its outputs. Yawa described AI-generated texts as having \u201cno flavor\u201d (Reflection) while Hyun noted they contain \u201cno personal experiences, opinions, or emotions\u201d (Reflection), making them \u201cunappealing\u201d (Dofi, Interview). Yawa further noted that AI always takes a neutral stance due to how it is programmed; however, this \u201cneutrality\u201d might disguise its coded biases and thus requires critical evaluation. One way such \u201cneutrality\u201d influenced students is evident in Shuya\u2019s defensive stance towards AI\u2019s biases: \u201cOne limit of ChatGPT is that it does not have biases. If it had biases, AI wouldn\u2019t be qualified. It can\u2019t please everyone. You can\u2019t blame AI for this limitation; AI is created by people. What AI provides is a general societal view\u201d (Shuya, Interview). Consequently, Shuya did not consider that she had any stakes in \u201cfinding faults with AI\u201d as a user and writer, stating that \u201cI just needed to get this thing [the assignment] done, so I didn\u2019t consider it [bias]\u2026If you find it wrong, leaving it to them.\u201d\n\nAnother aspect of critical evaluation considered to be essential when using AI for writing involves evaluating the learning context and the goals of learning within that context. Yawa, Paulo, Nadia, and Hyun mentioned that using AI to explain complex terms and concepts to assist with reading comprehension, could be acceptable and beneficial. For tasks that require deeper engagement with the material, critical thinking, and the development of original ideas, AI is very \u201climiting\u201d (Shuya, Reflection). Dofi echoed this sentiment, emphasizing the importance of learning to \u201cgenerate your own ideas and learn how to piece your ideas together\u201d (Dofi, Interview). All students recognize that while AI can be a useful tool for certain types of learning tasks, it is important to ensure that it complements rather than replaces the essential elements of the learning process.\n\n# 5. Discussion\n\n# .1. Complicating and navigating the contradictions in AI-assisted writing\n\nConfirming the scholarly literature, the study found that L2 writers utilized the affordances of generative AI to assist with various aspects of writing, such as vocabulary, grammar, organization, and idea development (Yan, 2023; Wang, 2024; Woo et al., 2024). AI-assisted source use and research process, an aspect of AI-assisted writing that is less examined in the current scholarship (Sun, 2024), was found to be another major use of AI in the current study. Participants employed generative AI to translate L1 sources into English, locate discipline-specific terms and relevant L2 sources, and incorporate L2 sources into writing. This finding highlights the potential of AI in facilitating students\u2019 multilingual and cross-disciplinary source engagement and research, while also calling for more empirical work in light of the growing number of specialized AI tools (e.g., NoteBookLM, Elicit) that assist with source summarization, synthesis, and analysis in research writing. Using generative AI for brainstorming and source integration, like Yawa\u2019s use of it for summarizing and compiling articles, may risk disrupting the synergistic relationship between reading and writing. Automating aspects of source engagement (e.g., distill information from scholarly sources for convenience or for consolidation of one\u2019s ideas) may lead to a transactional approach to reading and writing, where synthesizing sources becomes detached from the critical analysis that informs thinking and writing, undermining the foundational skills that writing pedagogy aims to cultivate. This raises important concerns for L2 writing teachers.\n\nIn addition to the benefits of AI in supporting L2 writers\u2019 linguistic and writing development through personalized and immediate feedback reported by previous studies (Yan, 2023; Barrot, 2023), the study found that students regarded accelerating the writing process (e.g., sorting out information, building connections between ideas, creating an outline from a jumble of thoughts) as some of the advantages of using AI technologies. The study also revealed that the students\u2019 inquiry with AI turned to be an iterative process with a lot of trials, which could lead to confusion and frustration and require significant cognitive effort. This finding helps explain the point of divergence observed in previous studies where L2 writers reported reduced cognitive load in Wang (2024) study but expe rienced heavy cognitive load in Woo et al. (2024). While generative AI reduces the cognitive load associated with the writing task, it may increase the cognitive load in navigating the technology to obtain meaningful outputs and critically integrate its feedback. We thus suggest that developing students\u2019 AI literacy should also involve carefully scaffolding skills such as prompt engineering, AI-related feedback literacy, and self-directed learning skills to help students effectively monitor and manage AI learning resources (Li et al., 2024; Wang, Li, et al., 2024) at metacognitive levels. This finding underscores the need for a pedagogical shift towards connecting AI literacy with learning goals that have been traditionally regarded as essential for writing courses, rather than treating it as a separate or add-on skill.\n\nWe found a noteworthy contradiction regarding AI\u2019s linguistic power and its influence on L2 writers. While acknowledging that LLMs can be a valuable aid in learning English academic writing, some students also expressed concern about feeling tempted to rely on and even submit to AI\u2019s linguistic eloquence. The finding brings to the forefront perils regarding integrating AI into the writing process, extending Wang (2024) concern about language AI-nization. AI may act as a new colonizing tool that reinforces standard language ideology (Nee et al., 2022), linguistic neo-imperialism (Lai, 2021), and the marginalization of other literacies and rhetorics. We contend the need to position AI literacy for L2 writers within the critical pedagogical tradition, moving beyond a practical and use-based orientation foregrounded in existing AI literacy frameworks. As such, critical AI literacy should entail empowering multi lingual writers to be active agents in interrogating and questioning the socio-political and cultural implications of AI in shaping language, knowledge, and power dynamics in academic writing as well as fostering students\u2019 awareness to critically examine the broader systems of power that govern AI technologies and their development. From this perspective, writing with AI transcends the acts of critiquing and utilizing AI outputs; it becomes a site of interaction and negotiation with broader ethical and epistemological questions that allow students to see themselves as creators of meaning relevant to their multilingual identities, rather than consumers of AI-generated content.\n\n# 5.2. A framework for critical AI literacy\n\nThe study examined L2 writers\u2019 critical AI literacy in their AI-assisted writing, providing evidence for reconsidering existing AI literacy frameworks. The study complicates many literacy educators\u2019 shared concern about student writers\u2019 uncritical reliance on AI assistance (Gupta et al., 2024). The L2 writers in this study demonstrated a spectrum of criticality towards AI and its affordances. However, our findings reveal that while the L2 writers\u2019 critical AI awareness, positionality, strategies, and evaluations are intertwined, their beliefs and practices may not always align. For instance, some participants adopted generative AI\u2019s language suggestions despite recognizing them as \u201cexcessive,\u201d or treated the coded biases in AI with a pragmatic \u201cit-has-nothing-to-do-with-me\u201d attitude. This finding suggests the importance of engaging in reflective praxis to align beliefs with practices to enhance CAIL holistically. We also want to highlight that certain approaches such as Hyun\u2019s tendency to trust AI suggestions and Dawei\u2019s full embrace of AI\u2019s language suggestions may appear uncritical, yet a deeper understanding of their positionalities reveals a more complex dynamic. The students\u2019 reliance on AI is a reflection of language ideologies shaped by their academic socialization, where native-speaker norms were regarded as benchmarks of \u201cgood\u201d academic writing. Similarly, Dofi\u2019s dilemma and decision in presenting ChatGPT as a research source to fulfill her conceived norm of English academic writing while feeling inadequate to claim her authority in writing about her own culture, also shows how the student positions her own cultural-linguistic repertoire as an L2 writer in relation to LLMs as authoritative repre sentations of L1 perfection and big-data driven knowledge bases. Thus, rather than simply labeling their use of AI as uncritical, it is more important to inspect and contextualize how their deliberate practices of orchestrating AI outputs, existing on a spectrum of criticality, were shaped by their efforts to meet their (mis)understandings of rhetorical demands.\n\n![](img/b3e93d74af98ce0b4ba37e47f77a59a614ef20d790dfe811d704d97eb3812b02.jpg)  \nFig. 3. An APSE model of critical AI literacy.\n\nMoreover, an AI literacy model based on Bloom\u2019s taxonomy may be inadequate and inaccurate, as it presents a linear and pro gressive approach to the development of AI literacy, failing to capture the interconnectedness of its different components. Thus, we propose the following critical AI literacy framework for L2 writing based on our findings, as shown in Fig. 3. The CAIL framework encompasses (1) critical AI awareness (A) of AI\u2019s algorithmic inner workings, functionalities, training data, and biases. This aligns the \u201cknow and understand\u201d component of the models by $\\mathrm { N g }$ et al. (2021) and Warscheauer et al. (2023). (2) critical AI positionality (P), which involves recognizing one\u2019s disposition towards AI and critically reflecting on one\u2019s voice and role in relation to AI, seeking a balanced position within the spectrum of reliance on versus resistance to AI. This aspect was not particularly addressed in Ng et al. (2021) and Warschauer et al. (2023); however, we highlight its importance as AI can play an active role in L2 writers\u2019 meaning-making processes and shape how they viewed their relationship with writing and technology. As Leander and Burriss (2020) argues, AI is not a passive tool; it exists \u201cinside,\u201d \u201cwith,\u201d \u201calongside,\u201d \u201cabove,\u201d \u201ctoward,\u201d \u201cagainst,\u201d and \u201camong\u201d us, especially in an increasingly AI-mediated world and where authoring the posthuman text is becoming more and more common (Gourlay, 2015). (3) critical strategies for human-AI interaction (S), which refers to adopting critical approaches to utilizing AI tools to support writing and self-learning in responsible and meaningful ways. This involves a dynamic process of prompt engineering to effectively communicate with AI, elicit appropriate responses, and proactively adjust one\u2019s strategies to assist with writing. This dimension extends $\\mathrm { N } g$ et al.\u2019s (2021) \u201cuse and apply\u201d and Warschauer et al.\u2019s (2023) \u201caccess and navigate\u201d and \u201cprompt.\u201d Additionally, we emphasize the social nature of prompt engineering (Bao & Li, 2023), and the importance of taking a proactive role and being adaptive in the self-directed learning process of using AI (Li et al., 2024). (4) critical evaluation of AI affordances (E) entails evaluating AI\u2019s outputs in terms of information accuracy and quality, linguistic repertoire and possible linguicism, rhetorical and cultural sensibility, and ideological biases, as well as their usefulness and appropriateness according to one\u2019s specific learning and rhetorical context, writing purposes, and audiences, to ensure ethicality. This dimension corresponds to $\\mathrm { N } g$ et al.\u2019s (2021) \u201cevaluate\u201d and Warschauer et al. (2023) \u201ccorroborate,\u201d but specifically addresses the unique challenges L2 writers may face. While their models focus on evaluating the accuracy and biases of AI-generated content, we also consider how such texts might influence L2 writers linguistically and rhetorically, and conversely, how L2 writers might creatively leverage these linguistic and rhetorical repertoires for their specific writing contexts.\n\nThe four components represent distinct yet overlapping aspects of CAIL. For instance, one\u2019s awareness of AI biases and limitations can influence their positionality and evaluation of AI\u2019s affordances for writing. The strategies that L2 writers develop through their interactions with AI can also enhance their understanding of AI\u2019s affordances and their critical awareness. One\u2019s critical evaluation of AI can also be shaped by their positionality and perspective, which are impacted by their experiences and backgrounds. Thus the framework considered the multifaceted nature of learning involved in AI-assisted writing: learning of AI and learning with AI. Developing a comprehensive understanding and application of these four components fosters a holistic approach to critically and\n\nTable 9 Strategies and pedagogical possibilities for developing CAIL based on the APSE model.   \n\n<html><body><table><tr><td>Critical Dimensions</td><td>Strategies</td><td>Pedagogical Possibilities</td></tr><tr><td>Critical AI awareness</td><td>: Develop knowledge on AI&#x27;s operational basis : Understand the discourse features and patterns of AI- generated responses : Analyze how AI&#x27;s foundational operational mechanisms shape</td><td>: Equip students with interdisciplinary knowledge related to the technical aspects of AI : Interrogate AI biases by drawing upon L2 writers&#x27; own cross- cultural knowledge, experiences, and reflections</td></tr><tr><td>Critical AI positionality</td><td>its responses and interaction with human . Reflect on one&#x27;s views on writing and writerly virtues : Reflect on one&#x27;s language and technology ideologies (e.g., L1 vs. L2, human vs. AI) : Reflect on how these perceptions and positionalities come into being through one&#x27;s academic literacy practices, educational</td><td>: Foster student peer collaboration to examine their positionalities and underlying beliefs : Engage in discussions about the ethical implications (e.g., academic integrity, social and environmental considerations) of various human-AI positionalities</td></tr><tr><td>Critical strategies for human-AI interaction</td><td>experiences, and cultural backgrounds : Learn effective prompt engineering skills to communicate with AI : Engage in iterative and adaptive processes of refining AI interaction and learning strategy : Monitor one&#x27;s learning with AI</td><td>: Develop prompt engineering skills by leveraging L2 learners and teachers&#x27; strengths, for instance, through linguistic, discourse, and genre analysis approaches and communication perspectives. : Cultivate students&#x27; disposition and strategies for self-directed</td></tr><tr><td>Critical evaluation of AI affordances</td><td>. Evaluate AI&#x27;s information accuracy, quality, and reliability : Evaluate AI&#x27;s linguistic and rhetorical affordances in relation to the writer&#x27;s proficiency and the rhetorical context : Evaluate the learning context and the goal of learning within the context in relation to the role of AI</td><td>learning with AI, focusing on self-monitoring and managing one&#x27;s learning with AI (Wang, Li, et al., 2024) : Verify AI outputs with human (e.g., teachers and peers) and nonhuman resources (e.g., research) (Li et al., 2024) : Develop students&#x27; metalinguistic knowledge to evaluate AI&#x27;s usefulness and appropriateness for specific writing contexts : Foster students&#x27; metacognition of the learning task and</td></tr></table></body></html>\n\nethically engage with AI technologies.\n\n# 6. Conclusion and implications\n\nFollowing a qualitative design, we explored L2 writers\u2019 critical AI literacy in their AI-assisted writing processes. Complicating the scholarly literature on the dilemmas and contradictions L2 writers are likely to encounter in AI-assisted writing, the study discussed how students perceived and navigated the various challenges in balancing AI use with their own voice through unpacking their critical decision-making involved in AI-assisted writing. To fill the gap in evidence-based models on critical AI literacy in the current literature, the study proposes a CAIL model focusing on critical awareness, positionality, strategies, and evaluations in AI use.\n\nThe study is limited due to its small sample size and short duration, which may restrict the applicability of the findings to a broader range of settings, such as students of different age groups, language proficiencies, writing experiences, as well as L2 writing instruction in various educational and cultural contexts. We thus recommend that scholars examine diverse student populations and conduct more large-scale studies across different learning contexts to test, validate, and expand the framework. We also suggest that future studies explore, in greater depth, how students\u2019 language proficiency levels and prior writing experiences may influence their CAIL. Furthermore, the study focused on students\u2019 use of ChatGPT (GPT 3.5) and did not consider other AI models and generative AIpowered writing tools. Future studies should examine the latest advancements as well as various specialized AI writing tools to un derstand how they may influence students\u2019 writing differently. Future research should also take into account the multimodal func tionalities of AI for assisting students\u2019 digital multimodal composing (Tan, Xu, & Wang, 2025).\n\nWe make a list of strategies and pedagogical possibilities for developing critical AI literacy based on the APSE model as shown in Table 9. These considerations are meant to be illustrative rather than exhaustive. We would like to highlight that explicit instruction on critical AI literacy is fundamental to prepare students for making informed and ethical decisions about when, where, and how to use, evaluate, and incorporate AI. Writing and language instructors should discuss specific scenarios and break down the skills for critical AI use, such as prompt engineering and feedback literacy. They should also encourage students to reflect on how AI technologies affect their language use, the learning process, and ethical considerations. Instructors should also help students develop relevant language skills and metalinguistic knowledge to identify ways of using AI appropriate for specific writing contexts, considering disciplinary writing conventions, goals and audiences for writing, and the learners\u2019 own attributes and differences. Finally, instructors should encourage students to explore the use of various semiotic repertoires for creative communications and identity expression, rather than pursuing correctness and native speaker-like perfection. AI should be a means to help students leverage linguistic and multimodal meaning-making resources, instead of a convenience tool for producing grammatically correct sentences and streamlining formulaic academic writing. The study urges language and writing educators to rethink our current writing education that privileges certain linguistic, rhetorical, and discursive features that can be easily replicated by AI, for instance, embracing decolonizing academic writing pedagogies (Canagarajah, 2023). In addition to supporting students, it is crucial to provide professional development and training for L2 writing instructors and teacher educators, so that they are equipped to integrate critical AI literacy into their teaching. Such CAIL training opportunities should center around enhancing teachers\u2019 technological and pedagogical readiness to cultivate students\u2019 critical awareness, positionality, interaction strategies, and evaluation skills in using AI, enabling their pedagogy to engage with the sociopolitical, linguistic, and ethical complexities of AI in writing.\n\n# CRediT authorship contribution statement\n\nWang Zhaozhe: Writing \u2013 review & editing, Visualization, Validation, Resources, Methodology, Formal analysis, Conceptuali zation. Wang Chaoran: Writing \u2013 review & editing, Writing \u2013 original draft, Visualization, Validation, Resources, Project adminis tration, Methodology, Formal analysis, Conceptualization.\n\n# Data availability\n\nData will be made available on request.\n\n# References\n\nBao, Y., & Li, B. (2023). A preliminary study on graduate student instructors\u2019 exploration, perception, and use of ChatGPT. International Journal of Computer-Assisted Language Learning and Teaching, 13(1), 1\u201323. https://doi.org/10.4018/IJCALLT.332873   \nBarrot, J. S. (2023). Using ChatGPT for second language writing: Pitfalls and potentials. Assessing Writing, 57, Article 100745. https://doi.org/10.1016/j. asw.2023.100745   \nBewersdorff, A., Zhai, X., Roberts, J., & Nerdel, C. (2023). Myths, mis- and preconceptions of artificial intelligence: A review of the literature. Computers and Education: Artificial Intelligence, 4, Article 100143. https://doi.org/10.1016/j.caeai.2023.100143   \nCanagarajah, S. (2023). Decolonizing academic writing pedagogies for multilingual students. TESOL Quarterly. https://doi.org/10.1002/tesq.3231. tesq.3231.   \nCardon, P., Fleischmann, C., Aritz, J., Logemann, M., & Heidewald, J. (2023). The challenges and opportunities of AI-assisted writing: Developing AI literacy for the AI age. Business and Professional Communication Quarterly, 86(3), 257\u2013295. https://doi.org/10.1177/23294906231176517   \nChomsky, N., Roberts, I., & Watumull, J. (2023). The false promise of ChatGPT. The New York Times. https://www.nytimes.com/2023/03/08/opinion/noamchomsky-chatgpt-ai.html.   \nFreire, P. (1970). Pedagogy of the oppressed. Continuum.   \nGiroux, H. A. (1997). Pedagogy and the politics of hope: Theory, culture, and schooling. Westview Press.   \nGourlay, L. (2015). Posthuman texts: Nonhuman actors, mediators and the digital university. Social Semiotics, 25(4), 484\u2013500. https://doi.org/10.1080/ 10350330.2015.1059578   \nGupta, A., Atef, Y., Mills, A., & Bali, M. (2024). Assistant, parrot, or colonizing loudspeaker? ChatGPT metaphors for developing critical AI literacies. Open Praxis, 16 (1), 37\u201353. https://doi.org/10.55982/openpraxis.16.1.631   \nKern, R. (2024). Twenty-first century technologies and language education: Charting a path forward. The Modern Language Journal, 108(2), 515\u2013533. https://doi.org/ 10.1111/modl.12924   \nKonishi, Y. (2015). What is Needed for AI literacy? Priorities for the Japanese economy in 2016. https://www.rieti.go.jp/en/columns/s16_0014.html.   \nKimmel, M. (2008). Guyland: The perilous world where boys become men. HarperCollins.   \nKubota, R. (2023). Another contradiction in AI-assisted second language writing. Journal of Second Language Writing, 62, Article 101069. https://doi.org/10.1016/j. jslw.2023.101069   \nLai, M. L. (2021). English linguistic neo-imperialism \u2013 a case of Hong Kong. Journal of Multilingual and Multicultural Development, 42(4), 398\u2013412. https://doi.org/ 10.1080/01434632.2019.1702667   \nLaupichler, M. C., Aster, A., Schirch, J., & Raupach, T. (2022). Artificial intelligence literacy in higher and adult education: A scoping literature review. Computers and Education: Artificial Intelligence, 3, Article 100101. https://doi.org/10.1016/j.caeai.2022.100101   \nLeander, K. M., & Burriss, S. K. (2020). Critical literacy for a posthuman world: When people read, and become, with machines. British Journal of Educational Technology, 51(4), 1262\u20131276. https://doi.org/10.1111/bjet.12924   \nLi, B., Bonk, C., Wang, C., & Kou, X. (2024). Reconceptualizing self-directed learning in the era of generative AI: An exploratory analysis of language learning. IEEE Transactions on Learning Technologies, 17. https://doi.org/10.1109/TLT.2024.3386098   \nLong, D., & Magerko, B. (2020). In R. Bernhaupt, F. Mueller, D. Verweij, J. Andres, J. McGrenere, A. Cockburn, et al. (Eds.), CHI 2020 Proceedings. What is AI literacy? Competencies and design considerations (pp. 1\u201316). ACM.   \nMemarian, B., & Doleck, T. (2023). Fairness, Accountability, Transparency, and Ethics (FATE) in Artificial Intelligence (AI) and higher education: A systematic review. Computers and Education: Artificial Intelligence, 5, Article 100152. https://doi.org/10.1016/j.caeai.2023.100152   \nMLA-CCCC Joint Task Force on Writing and AI Working Paper: Overview of the Issues, Statement of Principles, and Recommendations (July, 2023). Retrieved from https://hcommons.org/app/uploads/sites/1003160/2023/07/MLA-CCCC-Joint-Task-Force-on-Writing-and-AI-Working-Paper-1.pdf.   \nNee, J., Smith, G. M., Sheares, A., & Rustagi, I. (2022). Linguistic justice as a framework for designing, developing, and managing natural language processing tools, 205395172210909 Big Data Society, 9(1). https://doi.org/10.1177/20539517221090930.   \nNg, D. T. K., Leung, J. K. L., Chu, S. K. W., & Qiao, M. S. (2021). Conceptualizing AI literacy: An exploratory review. Computers and Education: Artificial Intelligence, 2, Article 100041. https://doi.org/10.1016/j.caeai.2021.100041   \nNg, D. T. K., Wu, W., Leung, J. K. L., Chiu, T. K. F., & Chu, S. K. W. (2024). Design and validation of the AI literacy questionnaire: The affective, behavioural, cognitive and ethical approach. British Journal of Educational Technology, 55(3), 1082\u20131104. https://doi.org/10.1111/bjet.13411   \nOu, A. W., Khuder, B., Franzetti, S., & Negretti, R. (2024). Conceptualising and cultivating critical GAI Literacy in doctoral academic writing. Journal of Second Language Writing, 66, Article 101156. https://doi.org/10.1016/j.jslw.2024.101156   \nPecorari, D. (2023). Generative AI: Same same but different? Journal of Second Language Writing, 62, Article 101067. https://doi.org/10.1016/j.jslw.2023.101067   \nPraphan, P. W., & Praphan, K. (2023). AI technologies in the ESL/EFL writing classroom: The villain or the champion? Journal of Second Language Writing, 62, Article 101072. https://doi.org/10.1016/j.jslw.2023.101072   \nSaldana, \u02dc J. (2015). The coding manual for qualitative researchers (4th ed.). Sage.   \nSasaki, M. (2023). AI tools as affordances and contradictions for EFL writers: Emic perspectives and L1 use as a resource. Journal of Second Language Writing, 62, Article 101068. https://doi.org/10.1016/j.jslw.2023.101068   \nSouthworth, J., Migliaccio, K., Glover, J., Glover, J., Reed, D., McCarty, C., Brendemuhl, J., & Thomas, A. (2023). Developing a model for AI Across the curriculum: Transforming the higher education landscape via innovation in AI literacy. Computers and Education: Artificial Intelligence, 4, Article 100127. https://doi.org/ 10.1016/j.caeai.2023.100127   \nStojanov, A., Liu, Q., & Koh, J. (2024). University students\u2019 self-reported reliance on ChatGPT for learning: A latent profile analysis. Computers and Education: Artificial Intelligence, 6. https://doi.org/10.1016/j.caeai.2024.100243   \nSu, Y., Lin, Y., & Lai, C. (2023). Collaborating with ChatGPT in argumentative writing classrooms. Assessing Writing, 57, Article 100752. https://doi.org/10.1016/j. asw.2023.100752   \nSun, Q. (2024). Exploring human-generative AI interaction in L2 learners\u2019 source use practices: Issues, trials, and critical reflections. Journal of Academic Writing, 14 (1), 24\u201342. https://doi.org/10.18552/joaw.v14i1.1055   \nTan, X., Xu, W., & Wang, C. (2025). Purposeful remixing with generative AI: Constructing designer voice in multimodal composing. Computers & Composition, 75. https://doi.org/10.1016/j.compcom.2024.102893   \nTsai, C., Lin, Y., & Brown, I. (2024). Impacts of ChatGPT-assisted writing for EFL English majors: Feasibility and challenges. Education and Information Technologies. https://doi.org/10.1007/s10639-024-12722-y   \nTseng, W., & Warschauer, M. (2023). AI-writing tools in education: If you can\u2019t beat them, join them. Journal of China Computer-Assisted Language Learning. https:// doi.org/10.1515/jccall-2023-0008   \nWang, C. (2024). Exploring students\u2019 generative AI-assisted writing processes: Perceptions and experiences from native and nonnative english speakers. Technology, Knowledge and Learning. https://doi.org/10.1007/s10758-024-09744-3   \nWang, C., Li, Z., & Bonk, C. (2024). Understanding self-directed learning in AI-Assisted writing: A mixed methods study of postsecondary learners. Computers and Education: Artificial Intelligence, 6, Article 100247. https://doi.org/10.1016/j.caeai.2024.100247   \nWarschauer, M., Tseng, W., Yim, S., Webster, T., Jacob, S., Du, Q., & Tate, T. (2023). The affordances and contradictions of AI-generated text for writers of English as a second or foreign language. Journal of Second Language Writing, 62, Article 101071. https://doi.org/10.1016/j.jslw.2023.101071   \nWoo, D. J., Wang, D., Guo, K., & Susanto, H. (2024). Teaching EFL students to write with ChatGPT: Students\u2019 motivation to learn, cognitive load, and satisfaction with the learning process. Education and Information Technologies. https://doi.org/10.1007/s10639-024-12819-4   \nYan, D. (2023). Impact of ChatGPT on learners in a L2 writing practicum: An exploratory investigation. Education and Information Technologies. https://doi.org/ 10.1007/s10639-023-11742-4   \nYin, R. (2018). Case study research and applications: Design and methods (6th ed.). Sage.\n\nChaoran Wang is a Multilingual Writing Specialist and Assistant Professor of Writing at Colby College. Her research examines the issues of literacy development of multilingual students and technology enhanced language learning through the intersecting perspectives of writing studies, applied linguistics, and educational tech nologies. Her recent work has appeared in Computers and Education: Artificial Intelligence, Applied Linguistics, Language Learning & Technology, IEEE Transactions on Learning Technologies, Research Methods in Applied Linguistics, among others. She is currently co-editing two books on AI and writing/language education with Routledge.", "metadata": {"authors": ["Chaoran Wang", "Zhaozhe Wang"], "category": "research", "confidence_score": 0.8, "document_type": "journal", "has_abstract": true, "has_methodology": true, "has_results": true, "key_findings": ["Students utilized AI in various ways, including topic selection and brainstorming, outlining, revising, editing, and sourcing", "The APSE model highlights the distinct yet overlapping components of critical AI literacy and addresses specific concerns that L2 writers face to leverage generative AI's linguistic and rhetorical resources critically"], "methodology": "qualitative", "pedagogical_confidence": 0.46, "pedagogical_implications": true, "publication_year": 2024, "research_questions": [], "source_file": "out_92MY5TFH_Wang_&_Wang_Investigating_L2_wr.md", "subject_area": "education", "tags": ["generative AI", "artificial intelligence", "ChatGPT", "AI literacy", "critical AI-assisted writing", "L2 writing"], "title": "Investigating L2 writers' critical AI literacy in AI-assisted writing: An APSE model"}, "search_text": "Investigating L2 writers' critical AI literacy in AI-assisted writing: An APSE model generative AI artificial intelligence ChatGPT AI literacy critical AI-assisted writing L2 writing education # Investigating L2 writers\u2019 critical AI literacy in AI-assisted writing: An APSE model\n\nChaoran Wang a,\\* , Zhaozhe Wang\n\na Department of Writing, Colby College, 5290 Mayflower Hill, Waterville, ME 04901, USA   \nb Institute for the Study of University Pedagogy, University of Toronto Mississauga, Department of Curriculum, Teaching and Learning, OISE,   \nUniversity of Toronto, 3359 Mississauga Road, Mississauga, Ontario L5L 1C6, Canada\n\n# A R T I C L E I N F O\n\n# A B S T R A C T\n\nKeywords:   \nGenerative AI   \nArtificial intelligence   \nChatGPT   \nAI literacy   \nCritical   \nAI-assisted writing   \nL2 writing\n\nWhile the need to foster critical AI literacy (CAIL) among L2 writers has gained increasing recognition, research offering empirically grounded models for integrating CAIL into L2 writing remains limited. To contribute to the ongoing research in AI-assisted L2 writing and CAIL, we designed the current study to understand how students used ChatGPT, a popular generative AI technology, to support their writing and to uncover their CAIL in their writing practices in two first-year writing classes in the US. Adopting a qualitative case study design, we analyzed stu dents\u2019 interview data, written reflections, AI logs, and screencasts of students\u2019 interactions with AI. Findings show that students utilized AI in various ways, including topic selection and brainstorming, outlining, revising, editing, and sourcing. We propose an APSE model based on four dimensions identified in students\u2019 CAIL while using ChatGPT: (1) critical awareness of AI (A), (2) critical positionality (P), (3) critical strategies for interacting with AI (S), and (4) critical evaluation of AI affordances (E). The model highlights the distinct yet overlapping components of CAIL and addresses specific concerns that L2 writers face to leverage generative AI\u2019s linguistic and rhetorical resources critically. Pedagogical implications include explicit instruction on CAIL, developing students\u2019 AI feedback litera"}, "title": "Investigating L2 writers' critical AI literacy in AI-assisted writing: An APSE model", "authors": ["Chaoran Wang", "Zhaozhe Wang"], "tags": ["generative AI", "artificial intelligence", "ChatGPT", "AI literacy", "critical AI-assisted writing", "L2 writing"], "filename": "out_92MY5TFH_Wang_&_Wang_Investigating_L2_wr.md"}, {"score": 0.32228338718414307, "document": {"id": 909, "file_path": "annotated_data/batch_002/out_Y2S8X4NT_Wang_and_Wang_-_2025_-_Investig.md", "filename": "out_Y2S8X4NT_Wang_and_Wang_-_2025_-_Investig.md", "content": "# Investigating L2 writers\u2019 critical AI literacy in AI-assisted writing: An APSE model\n\nChaoran Wang a,\\* , Zhaozhe Wang\n\na Department of Writing, Colby College, 5290 Mayflower Hill, Waterville, ME 04901, USA   \nb Institute for the Study of University Pedagogy, University of Toronto Mississauga, Department of Curriculum, Teaching and Learning, OISE,   \nUniversity of Toronto, 3359 Mississauga Road, Mississauga, Ontario L5L 1C6, Canada\n\n# A R T I C L E I N F O\n\n# A B S T R A C T\n\nKeywords:   \nGenerative AI   \nArtificial intelligence   \nChatGPT   \nAI literacy   \nCritical   \nAI-assisted writing   \nL2 writing\n\nWhile the need to foster critical AI literacy (CAIL) among L2 writers has gained increasing recognition, research offering empirically grounded models for integrating CAIL into L2 writing remains limited. To contribute to the ongoing research in AI-assisted L2 writing and CAIL, we designed the current study to understand how students used ChatGPT, a popular generative AI technology, to support their writing and to uncover their CAIL in their writing practices in two first-year writing classes in the US. Adopting a qualitative case study design, we analyzed stu dents\u2019 interview data, written reflections, AI logs, and screencasts of students\u2019 interactions with AI. Findings show that students utilized AI in various ways, including topic selection and brainstorming, outlining, revising, editing, and sourcing. We propose an APSE model based on four dimensions identified in students\u2019 CAIL while using ChatGPT: (1) critical awareness of AI (A), (2) critical positionality (P), (3) critical strategies for interacting with AI (S), and (4) critical evaluation of AI affordances (E). The model highlights the distinct yet overlapping components of CAIL and addresses specific concerns that L2 writers face to leverage generative AI\u2019s linguistic and rhetorical resources critically. Pedagogical implications include explicit instruction on CAIL, developing students\u2019 AI feedback literacy, fostering meta-skills in communication and evaluation, and enhancing their AI-assisted self-directed learning skills.\n\n# 1. Introduction\n\nFrom the initial hype to varying degrees of resistance and acceptance of generative AI, numerous discussions have emerged in both public and academic communities. L2 writing teachers have been striving to adapt their practice to this technological influence, either willingly or reluctantly (Praphan & Praphan, 2023). Today\u2019s writers have unprecedented access to learning resources based on large language models and advanced technologies, presenting both opportunities and challenges. These changes put at the forefront the need to understand students\u2019 AI-assisted writing practices to inform L2 writing pedagogy. As Pecorari (2023) points out, the question now is not whether but how to use generative AI. Writing teachers bear the responsibility to guide students in critically inquiring into the evolving linguistic, educational, and ethical implications of generative AI.\n\nThis responsibility aligns with the critical pedagogical tradition which advocates for empowering students as active participants in their learning and considering the social and ethical dimensions of their literacy practices (Freire, 1970; Giroux, 1997). As underscored by many language and literacy educators, teaching critical AI literacy (CAIL) to foster students\u2019 critical use of generative AI is of paramount importance and urgency (MLA-CCCC, 2023; Kern, 2024). Although various AI literacy frameworks have been proposed (e. g., Cardon et al., 2023; Long & Magerko, 2020; Ng et al., 2021; Warschauer et al., 2023), empirical research examining how students understand and develop critical AI literacy within the context of L2 writing remains in its early stages (Ou et al., 2024). We designed the current study to examine the construct of CAIL based on students\u2019 perspectives of and experiences with generative AI-assisted writing, informing ongoing scholarly discussions and conceptualizations of CAIL frameworks. We begin with reviewing current dis cussions on generative AI-assisted writing and models on AI literacy. Thereafter, we describe the research design and major findings of the study, shedding light on students\u2019 AI-assisted writing practices and their engagement with AI in developing CAIL. Drawing upon the findings, we propose an APSE model that conceptualizes critical AI literacy as comprising four interconnected components: critical AI awareness, critical positionality towards AI, critical strategies for human-AI interaction, and critical evaluation of AI\u2019s affordances within specific rhetorical and linguistic contexts. We conclude with practical strategies and pedagogical possibilities for L2 writing teachers to develop students\u2019 CAIL based on the APSE model.\n\n# 2. Literature review\n\n# 2.1. Generative AI-assisted writing\n\nThe discussion around generative AI and writing has been contentious. Scholars argue that generative AI has advantages such as supporting L2 writers\u2019 linguistic development (Yan, 2023), providing personalized and immediate feedback (Barrot, 2023), and relieving students\u2019 cognitive load (Wang, 2024) while offering affective benefits (Wang, Li, et al., 2024). However, they also acknowledge the challenges it poses to L2 students\u2019 learning and writing development, including various ethical and authorship concerns and issues of educational equity (Su et al., 2023).\n\nAmong the existing empirical studies on L2 writers\u2019 generative AI-assisted writing, many focus on students\u2019 academic writing at the postsecondary level. Tsai et al. (2024), in their experimental study with 44 undergraduate EFL students, found that ChatGPT-assisted revision significantly improved students\u2019 writing quality in vocabulary, grammar, organization, and content. Similarly, in Yan (2023) study, ChatGPT was found to be helpful in enhancing L2 writers\u2019 grammatical accuracy and lexical diversity. In another mixed-methods study by Woo et al. (2024), EFL students showed increased motivation and satisfaction with using ChatGPT for writing. However, they reported that the students also experienced high cognitive load, contrasting with Wang (2024) findings. This discrepancy may be attributed to Woo et al.\u2019s (2024) use of a think-aloud protocol during students\u2019 writing, as well as factors such as students\u2019 prior experience and familiarity with the AI tool and their digital self-management skills.\n\nIn another qualitative study of L1 and L2 students\u2019 generative AI-assisted writing process, Wang (2024) found that the students employed AI in various stages of their writing to address both higher-order (e.g., argument, structure) and lower-order (e.g., syntax, diction, grammar) issues. The study foregrounded two dilemmas faced by students: (1) maintaining one\u2019s own voice while preventing their writing from being \u201cAI-nized,\u201d i.e., the temptation to adopt AI suggestions which may lead to a similar machine-like linguistic and rhetorical style among diverse writers; and (2) balancing missed versus new learning opportunities, as AI could provide shortcuts to linguistic and ideational generation, potentially leading to learning loss \u2013 a common critique and concern among scholars (e.g., see Barrot, 2023; Tseng & Warschauer, 2023). Wang (2024) study also revealed that students sought to develop a sense of agency and criticality, indicating that they did not use AI technologies passively but tried to pursue new learning opportunities to enhance their writing. The study complicates the common concerns and oversimplified assumptions of students\u2019 behaviors, highlighting the importance of researching the tacit learning moments that arise from students\u2019 interactions with AI, as well as the nuances and di lemmas students encounter in their decision-making in AI-assisted writing.\n\nSimilarly, Warschauer et al. (2023) also identified three contradictions that L2 writers may face when using ChatGPT and other AI technologies: the \"imitation\" contradiction, the \"rich get richer\" contradiction, and the \"with or without\" contradiction. While there are conflicting scholarly opinions and empirical evidence that complement and challenge these contradictions (for example, see Sasaki, 2023), they all underscore the need for L2 writing instruction to consider how to effectively utilize generative AI technologies to empower students. This suggests that L2 writing teachers should provide explicit guidelines and instructions to help students leverage the AI tools without compromising their learning. Additionally, it highlights the necessity for further empirical evidence to validate the current scholarly discussions.\n\n# 2.2. AI Literacy\n\nScholars argue that the various challenges and contradictions L2 writers face call for the development of writers\u2019 AI literacy, so they can \u201cnavigate the unknown future of a technological revolution\u201d (Kubota, 2023, p. 1). Recent studies show that despite students\u2019 frequent use of and easy access to various AI technologies, they have a limited understanding of AI on a deeper level, and they tend to have various misconceptions and myths about AI (Bewersdorff et al., 2023). For instance, students demonstrate a lack of clarity regarding different critical aspects of AI use, including inclusiveness, bias, fairness, data privacy, social inequality, and academic integrity (Bewersdorff et al., 2023; Memarian & Doleck, 2023). Hence, critical AI literacy (CAIL) is of paramount importance in helping students become informed and conscientious users of AI.\n\nAI literacy, as a term, was first coined by Konishi (2015). Based on their review study, Laupichler et al. (2022) report that research on AI literacy is still in its infancy and that the question of how to teach AI literacy still remains unexplored. Similarly, Southworth et al. (2023) argue for the urgency of defining and establishing models of AI literacy. One of the widely cited models of AI literacy is by $\\mathrm { N g }$ et al. (2021, 2024), which conceptualizes and categorizes AI literacy into four aspects: namely, (1) know and understand the basic concepts and functionalities of AI, (2) use and apply AI applications in different contexts, (3) evaluate and create AI applications, and (4) be ethical and socially responsible users. $\\mathrm { N } g$ et al.\u2019s (2021) AI literacy framework draws upon the foundational elements and hier archical model of Bloom\u2019s taxonomy to outline the progressive skill levels essential for cultivating AI literacy.\n\nTable 1 Instructional Design and Practices Informed by AI Literacy Models $( \\mathrm { N } g$ et al., 2021; Warschauer et al., 2023).   \n\n<html><body><table><tr><td>Elements in AI Literacy</td><td>Learning Goals</td><td> In-Class Learning Activities</td><td>Assignments</td></tr><tr><td>Know and understand AI (Ng et al., 2021; Warschauer et al., 2023)</td><td>Introducing the basics of generative AI</td><td>Watching an instructional video on AI basics designed for lay audiences; Reading and discussing Chomsky et al.</td><td>Reading assignment</td></tr><tr><td>Use and apply AI (Ng et al., 2021); Access, navigate, and prompt AI ( Warschauer et al., 2023)</td><td>Practicing using ChatGPT; Exploring ChatGPT&#x27;s</td><td>Discussing Chomsky et al.&#x27;s critiques on AI; Discussing prompting strategies; Practicing using ChatGPT to edit a piece of</td><td>Screen-recording task that involves interaction with ChatGPT and think-aloud reflections;</td></tr><tr><td>Evaluate (Ng et al., 2021); Corroborate AI-generated content (Warschauer et al., 2023)</td><td>affordances and weaknesses; Critiquing ChatGPT- generated texts</td><td>freewriting; Comparing and discussing AI-made changes to reflect on use experiences</td><td>Written reflection assignment</td></tr><tr><td>AI ethics (Ng et al., 2021); Incorporate AI-generated content in ethically and effectively ( Warschauer et al., 2023)</td><td>Discussing academic integrity and ethical issues</td><td>Collaboratively researching and developing AI policies for the course, based on sample AI policies in higher education and academic publishing</td><td>Written reflection assignment + AI log and essay drafts submission</td></tr></table></body></html>\n\nPartially drawing upon $\\mathrm { N g }$ et al. (2021, 2024), Tseng and Warschaeur (2023) and Warschauer et al. (2023) proposed a five-component AI literacy framework specifically for L2 writers to navigate the contradictions associated with using AI to enhance their learning. The components include: (1) understand the basics of AI writing tools\u2019 learning affordances and shortcomings including biases; (2) access and navigate AI-writing tools for specific writing purposes and contexts; (3) prompt AI to generate useful information; (4) corroborate AI-generated information to evaluate the accuracy and biases; (5) incorporate AI-generated content in effective and ethical ways. Although Warschauer et al. (2023) pioneered this AI literacy framework for L2 writing, further research is needed for validation.\n\nIn accordance with the scholarly conversation, the Modern Language Association-Conference on College Composition and Communication (MLA-CCCC) Joint Task Force on AI and Writing (2023) advocates for fostering critical AI literacy (CAIL) among both students and educators as a priority. They regard CAIL as part of digital literacy, briefly defining it as \u201cliteracy about the nature, capacities, and risks of AI tools as well as how they might be used\u201d (p. 7). So far, research remains scarce on conceptualizations of critical AI literacy, specifically in terms of what CAIL encompasses within L2 writing and how students engage with it in their AIassisted writing and language learning practices. We thus design the current study to uncover how students incorporate CAIL in their real-life writing practices and to inform an empirical evidence-based CAIL framework. This, in turn, will provide writing instructors with insights to foster students\u2019 CAIL in their instructional practices. The research questions guiding our inquiry are as follows:\n\n(1) How do L2 students use ChatGPT, a popular generative AI technology, to assist with their writing? (2) How are the L2 student writers\u2019 CAIL (or lack thereof) evidenced in their interactions with ChatGPT and their linguistic and rhetorical decision-making?\n\n# 3. Method\n\nThis study is part of a larger research study on critical AI literacy in postsecondary writing classrooms that involve both L1 and L2 writers. For this study, we adopted an exploratory qualitative case study design (Yin, 2018) to understand how L2 students engage with CAIL in their AI-assisted writing. We both identify as multilingual, international teacher-researchers, professionally trained and working at the intersection of writing studies and applied linguistics within the North American context. While we recognize the potential of technologies to empower L2 writers, we remain concerned about a general perception of students\u2019 uncritical reliance on them, as discussed in the existing scholarship (e.g., Barrot, 2023; Cardon et al., 2023; Stojanov et al., 2024). Overall, our multilingual identities and writing experiences inform us to adopt an open attitude towards understanding participants\u2019 diverse decision-making regarding whether and how they chose to use generative AI in their writing. However, we also acknowledge that our professional training and roles as teacher-researchers may have influenced both our analytical lenses and participants\u2019 willingness to disclose certain behaviors or attitudes.\n\n# 3.1. Context of the study\n\nThe study was conducted in two sections of the same first-year writing course at a liberal arts college in the Eastern United States in 2023. The writing classes followed the same syllabus and were taught by the first author. There were 27 students, including seventeen L1 and ten L2 students from diverse cultural-linguistic backgrounds, enrolled in the two classes. The writing course had three major units, each coming with one major writing assignment. One of the major assignments invited students to write about a family-related concept of their choice. The goal of the assignment was to encourage students to reflect on and offer fresh insights into cultural concepts, drawing upon their personal experiences and secondary research. The unit covered seven class sessions, each lasting 75 minutes. Topics discussed included strategies for concept explanation, source evaluation, artificial intelligence, finding one\u2019s voice as an academic writer, and peer review.\n\nTable 2 Demographic information of the student participants.   \n\n<html><body><table><tr><td>Pseudonym</td><td>Gender</td><td>L1</td><td>Educational Background</td></tr><tr><td>Hyun</td><td>Male</td><td>Korean</td><td>International high school in Mainland China</td></tr><tr><td>Aye</td><td>Female</td><td>Burmese</td><td>International high school in Hong Kong</td></tr><tr><td>Yun</td><td>Female</td><td>Chinese</td><td>International high school in Canada</td></tr><tr><td>Dawei</td><td>Male</td><td>Chinese</td><td> International high school in Mainland China.</td></tr><tr><td>Shuya</td><td>Female</td><td>Chinese</td><td>Private high school in the US</td></tr><tr><td>Yawa</td><td>Male</td><td>Twi</td><td>Public high school in Ghana</td></tr><tr><td>Dofi</td><td>Female</td><td>Twi</td><td>Public high school in the US.</td></tr><tr><td>Paulo</td><td>Male</td><td> Spanish</td><td>Public high school in the US.</td></tr><tr><td>Felix</td><td>Male</td><td> Spanish</td><td>Public high school in the US</td></tr><tr><td>Nadia</td><td>Female</td><td>Arabic</td><td> Public university in Egypt</td></tr></table></body></html>\n\nTwo class sessions were dedicated to discussing generative AI and large language models inspired by the broad ideas presented in previous AI literacy frameworks (e.g., Warchauer et al., 2023), such as introducing the basics of the technology, exploring its affordances, weaknesses, biases, and relevant academic integrity issues, and practicing using ChatGPT and critiquing ChatGPT-generated texts (see Table 1 for a detailed description of our instructional design). The sessions were exploratory in nature, meaning that the students experimented with ChatGPT and formed their understandings through hands-on experiences \u2013 an approach aligned with our research design as an exploratory, qualitative case study. To be more specific, in the first class, students discussed Chomsky et al. (2023) opinion piece \u201cNoam Chomsky: The False Promise of ChatGPT\u201d published in The New York Times (Chomsky, Roberts, & Watumull, 2023). Following this, students used ChatGPT to edit a piece of their own freewriting, and then compared and discussed the AI-made changes to reflect on their use experiences. The second session introduced common academic integrity concerns about the use of generative AI in educational settings. Working in collaborative groups, students reviewed various policies on AI usage in higher education and academic publishing, ultimately developing a policy for their own use in this course. Thus, the CAIL examined in this study is grounded in students\u2019 direct engagement with the technology, reflecting their authentic, first-hand experiences as opposed to following prescriptive, teacher-fronted instructional models. ChatGPT (GPT 3.5) was selected because it was one of the most popular generative AI technologies at the time of the study and was free, making it accessible to everyone in the class.\n\nWhile learning about the generative AI tool, the students also completed a task that involved screen-recording their interactions with ChatGPT while articulating their thoughts, feelings, and perceptions about their use experience. This was designed to help the instructor gauge the students\u2019 thought processes while using the AI tool. For the final assignment, students were encouraged, but not required to incorporate ChatGPT into their writing. The instructor made the decision because she would like to give students the flexibility to choose the approaches that best suit their individual needs and learning styles. This decision also helps mitigate the potential impact of researchers\u2019 positionality on students\u2019 engagement with AI. Those who opted to use ChatGPT were required to submit their AI use logs along with a reflection detailing their specific use of AI, and the decision-making and critical thinking involved in their decision. All ten L2 writers enrolled in the classes reported utilizing ChatGPT to varying extents and were subsequently invited to participate in this study.\n\n# 3.2. Data collection and analysis\n\nFollowing the college\u2019s IRB protocol, the researchers sent research participation invitations via email after the students had completed the writing courses, ensuring there was no conflict of interest. After participants provided written consents, face-to-face interviews were scheduled and conducted. Table 2 shows the demographic information of the ten students who voluntarily partici pated in this study. Coming from diverse cultural-linguistic and educational backgrounds, the students generally demonstrated advanced English language proficiency, though their experiences with academic English writing varied. Hyun, Aye, Yun, and Dawei, who attended international high schools that adopted the International Baccalaureate (IB) curriculum, had extensive practice in ac ademic English writing in their former education. Shuya, Dofi, Paulo, Yun, and Felix, having completed high school education in the US/Canada, demonstrated integrated proficiency through their immersion in English-speaking environments. Yawa and Nadia had comparatively less practice in academic English writing during their formal instruction in public schools in Ghana and Egypt.\n\nPrimary data sources include semi-structured interviews with nine participants, each lasting from 35 minutes to 1 hour. The in terviews were designed to understand students\u2019 AI-assisted writing processes, their perceptions of using ChatGPT for writing, and their experiences of navigating ChatGPT to achieve their particular writing goals. One student chose not to participate in the interview but provided written consent for the research team to use all other types of data. In addition to interviews, the ten participants\u2019 written products and other documents, such as essay drafts, critical reflections on AI usage, AI log data, and screencasts of their AI interaction, were also collected. These written and multimodal data sources showed students\u2019 progress over the project, documenting how they prompted ChatGPT and evaluated and utilized the AI-generated information, as well as the thinking underlying their decisions. Thus, the various data sources not only served triangulation purposes but also helped to create a holistic understanding of students\u2019 CAIL.\n\nTable 3 An example of the coding approach featuring Theme 4 for the second research question.   \n\n<html><body><table><tr><td>Theme #4</td><td>Higher level code</td><td>Lower level code</td><td>Interview data</td><td>Other types of data (i.e., AI logs/ screencasts, written self-reflection, essay drafts)</td></tr><tr><td>Critical evaluations of AI affordances</td><td>Evaluation of information accuracy</td><td>Human</td><td>&quot;You should at least know something about it...like interaction with friends or the professor.&quot; (Dofi, Interview) &quot;I knew that was accurate because I&#x27;m from that place.&quot; (Dofi, Interview) &quot;The reading we did in class, I finally used that as a source.&quot; (Shuya, Interview)</td><td>&quot;The inaccuracy of ChatGPT can be countered by having prior knowledge about the topic...If ChatGPT was inaccurate from the knowledge I carried, I could consider the authenticity of that piece of information.&quot; (Dofi, Reflection) Shuya&#x27;s AI log: &quot;why individuals engage in multiple simultaneous relationships&quot; (Shuya,</td></tr><tr><td rowspan=\"4\"></td><td></td><td></td><td></td><td>AI Log, Dialogue 1 &amp; 2) Shuya&#x27;s final draft citing a course reading: &quot;They [HaiWang] believe that maintaining a committed and long-term relationship is impossible to maintain happiness (Kimmel, 2008).&quot; (Shuya, Final Draft) Shuya&#x27;s comments on ChatGPT&#x27;s edits: &quot;A</td></tr><tr><td>Evaluation of linguistic and rhetorical repertoire</td><td>Language proficiency Perception of</td><td>&quot;I don&#x27;t use ChatGPT because such sophisticated language doesn&#x27;t look like mine... I know what kind of stuff I can write based on my abilities.&quot; (Shuya, Interview) &quot;When it comes to the Western kind of</td><td>dynamic lexicon emerges continually&#x27; - That sounds complicated. And the word nuances.&#x27; I normally wouldn&#x27;t use these words.&quot; (Shuya, AI Screencast) &quot;It facilitates the communication of my ideas</td></tr><tr><td></td><td>good English academic writing</td><td>writing, GPT is really good with that.&quot; (Yawa, Interview)</td><td>to fit with academic writing.&quot; (Yawa, Reflection) Yawa&#x27;s AI log: &quot;create a transition&#x27; between two ideas. (Yawa, AI Log, Dialogue 4)</td></tr><tr><td></td><td>Intended audience</td><td>&quot;My positioning for my audience is they should be at the level of native language speakers.&quot; (Dawei, Interview)</td><td>Dawei&#x27;s AI log: &quot;correct the grammar in the following paragraph&quot; (Dawei, AI Log, Dialogue 1) Dawei&#x27;s final draft which adopted all AI&#x27;s edits</td></tr><tr><td rowspan=\"2\"></td><td>Evaluation of learning context</td><td>Type of learning task</td><td>&quot;I used it to explain concepts I don&#x27;t understand in the source.&quot; (Nadia, Interview)</td><td>(Dawei, Final Draft, p. 5, para. 1) &quot;Summarize this reading as a point&quot; (Yawa, AI Log as in the Reflection)</td></tr><tr><td></td><td>Goal of learning</td><td>&quot;I really think the essence of having the first year writing classes is help us to basically read and write. I feel it&#x27;s an essential part of schooling and learning.&quot; (Dofi, Interview)</td><td>&quot;The reason for using ChatGPT should be centered on learning rather than perfecting the work already done.&quot; (Dofi, Reflection)</td></tr></table></body></html>\n\nThe data analysis was a recursive process that started with thematic analysis (Saldana, \u02dc 2015) of the interview transcripts. The first author first coded four interview transcripts, and then the two authors went through four rounds of collaborative debriefing to refine the codebook and resolve any disagreements. With the co-developed coding scheme, the first author continued coding the remaining six interview transcripts. Following the coding scheme developed from the primary interview data, the authors then coded and grouped other types of data. Table 3 demonstrates our coding approach, featuring one of the themes developed for the second research question as an example. This coding process helped make connections between students\u2019 perceptions and understandings of CAIL and their writing practices. Comparisons and modifications for synthesizing findings across data were made through a recurring process of close reading, checking, doubting, and re-confirming the analysis between the two co-authors.\n\n# 4. Findings\n\n4.1. How do L2 students use ChatGPT, a popular generative AI technology, to assist with their writing?\n\nThe students used ChatGPT in various ways, including topic selection and brainstorming, outlining, revising, editing, translating sources, and using AI-generated texts as sources. Eight out of the ten students used ChatGPT for brainstorming. One reason, as Dofi mentioned, was to manage the \u201coverwhelming amount of information\u201d (Dofi, Interview) on unfamiliar topics. Similarly, Shuya noted that AI could \u201cprovide a basic overview of everything\u201d (Shuya, Interview), which helped her to explore possible directions. Paulo mentioned that ChatGPT helped with his usual writer\u2019s block: \u201cIt was a good change from the usual staring at a blank wall I do when trying to come up with ideas\u201d (Paulo, Reflection). Other students purposefully chose to use AI for brainstorming even when they were already familiar with a topic. Hyun explained, \u201cI want to explore other perspectives, so I compare the contents between what I had, and what it created. And then I used some of it that seemed to fit my topic.\u201d\n\nSix students also used ChatGPT for outlining, driven by similar reasons and purposes. For instance, Yawa followed his regular writing habit of creating a one-pager with everything he wanted to say, then used ChatGPT to organize these initial ideas into an outline for him to build upon. Similarly, Hyun wanted to save the mental struggle and time needed to connect paragraphs: \u201cI\u2019m good at structures because I spent really a lot of time structuring the essay, like two or three hours\u2026AI can make me spend less time considering how to connect it mutually, like, paragraph to paragraph.\u201d Shuya also believed that she could do the work well, but she opted to use AI for time-saving purposes: \u201cI know myself even without AI, I can still sort it out. I would be like sorting information bit by bit. But ChatGPT gave you result within seconds\u2026It was soooo fast.\u201d\n\nTable 4 Sample prompts participants used for revising and editing suggestions from ChatGPT.   \n\n<html><body><table><tr><td>Prompt types</td><td>Sample</td></tr><tr><td rowspan=\"4\">Generic prompts</td><td>Which part do you think it lacks? Which parts do you think I should improve? (Hyun)</td></tr><tr><td>What suggestions do you have for me to improve ...? (Aye)</td></tr><tr><td>If you were to like grade this, what would be my grade? How would you suggest to make this better? (Yawa)</td></tr><tr><td>Modify this essay. (Shuya)</td></tr><tr><td rowspan=\"7\">Tailored prompts</td><td>Are my arguments clear? (Yawa)</td></tr><tr><td>Create a transition between XX [sentence A] and XX [sentence B] (Yawa)</td></tr><tr><td>Please correct the grammar in the following paragraph. (Dawei)</td></tr><tr><td>Less overdone give me a word that can replace this [Note: This&quot; means less overdone&quot;]. (Yawa)</td></tr><tr><td>Revise the wording only and not the content so as to keep my original ideas. (Yun)</td></tr><tr><td>Change my word choice. (Hyun)</td></tr><tr><td>Reduce this to 400 words. (Felix)</td></tr></table></body></html>\n\nSeven students also reported using ChatGPT for revising and editing. AI log data showed that the students input chunks of text into ChatGPT and prompted the AI to provide feedback. Grammar and vocabulary were two common aspects for which the students sought ChatGPT\u2019s help. Table 4 provides a list of sample prompts students used from their AI logs and screencasts. These include generic prompts that ask ChatGPT for broad feedback without identifying specific areas for improvement, as well as more tailored prompts that ask ChatGPT to target specific aspects of writing such as argument, transition, grammar correctness, diction, and text reduction. Apart from using ChatGPT to directly edit one\u2019s writing, Yawa, for instance, also utilized it like a dictionary or Thesaurus for wording suggestions. As he shared: \u201cI already have a word in my mind, but I\u2019ll ask it\u2026Could you suggest another word that would be more suitable? Would you suggest five words that would be suitable? Then I\u2019ll look through and find which is the best.\u201d Notably, the process of seeking feedback for editing and revision was usually iterative, moving from general to specific or from addressing one specific point to another. For instance, in the screencast of his interaction with ChatGPT, Hyun first prompted the AI to \u201ccheck my grammar,\u201d and then asked, \u201cIs there any other feedback for my essay in terms of structure or APA in-text citations?\u201d\n\nFive students also used ChatGPT for sourcing, which was reported to be particularly helpful to address topics related to their own cultures. This included translating L1 sources, finding relevant L2 sources, and incorporating L2 sources into their writing. Hyun pointed out that because he was writing about gender roles in South Korean households, the translating function of ChatGPT was more effective than GoogleTranslate, allowing him to use sources more easily and present the latest local information to his global readers (Hyun, Reflection). Shuya, on the other hand, noted another interesting use of ChatGPT for searching English sources in her essay:\n\nI couldn\u2019t find direct sources related to my topic. But after asking ChatGPT, it gave me something relevant in English, which helped me to find ways to use English to explain this very Chinese term. ChatGPT gave me these directions you can take to explain, and based on these directions, you can find sources.\n\nShuya\u2019s essay topic was Haiwang (\u6d77\u738b), an emerging term among young people in China. She was unsure where to begin her research because she was unfamiliar with both the academic language related to the phenomenon and the English equivalent of the term. Thus she framed her understanding of the term into an AI prompt: \u201cpeople who are ambiguous with many people at the same time but are not committed to a love relationship,\u201d trying to elicit related English concepts from the AI (see Fig. 1). Upon reading ChatGPT\u2019s responses, Shuya located a few key terms like \u201cmulti-lover\u201d and \u201cnon-monogamous relationship\u201d that aided her later academic search (Shuya, Reflection). In addition to identifying academic registers for research, Shuya acknowledged that this use of ChatGPT allowed her to consider how the cultural meaning of a Chinese word \u201ccould be possibly used in the English context\u201d (Shuya, Interview). This illustrates her effort to leverage the capabilities of the large language model to write for cross-cultural audiences.\n\nAnother student Dofi directly cited ChatGPT as evidence. Table 5 presents a comparison between her AI log and part of a paragraph in her final draft discussing meal sharing and meal preparation, in which she incorporated AI\u2019s responses into her writing. Notably, she used \u201cresearch discovered from ChatGPT\u201d to refer to the AI-generated information, treating AI as a secondary research source. This is also evident in her approach to integrating the information, where she summarized and paraphrased the AI text to represent its meaning. Similar to Shuya, Dofi struggled to find sources related to her argument about Ghanaian family practices, so she resorted to ChatGPT. Dofi knew that ChatGPT was not a \u201cgood source,\u201d but she used it anyway as she believed it necessary to find external evidence to back her own experience, so as to meet her understanding of the expectations of English academic writing. She explained: I knew that [the ChatGPT-generated information about Ghana] was accurate because I\u2019m from that place, but I just needed a source to back it up. Sometimes you just like to put down your perspective, but you want evidence to back you up\u2026I feel like coming here [the US], I definitely had to learn to write again, learn how to do an essay. (Dofi, Interview)\n\nOther AI-assisted source use also included summarizing articles for integrating sources into writing. For instance, in Yawa\u2019s AI log, he prompted ChatGPT to \u201csummarize this article as a point\u201d (Yawa, AI log) for the convenience of incorporating it into his writing. He explained that this approach allowed him to \u201cretrieve the main ideas without having to read everything,\u201d and that ChatGPT helped summarize scholarly sources into \u201conly the important parts I needed for evidence in my essay\u201d (Yawa, Reflection). Nadia took a different approach, using ChatGPT to help her understand a source by asking it to \u201cprovide explanations for a paragraph or the whole reading.\u201d She highlighted the importance of reading the source herself to verify the information, noting that \u201cChatGPT was not always\n\n# Anonymous\n\nwhy some young people like to be ambiguous with to many people at same time but not have a love relationship\n\n# 5 ChatGPT\n\nThere can be several reasons why some young people may choose to be ambiguous or non-committal in their interactions with multiple individuals without pursuing traditional love relationships:\n\n![](img/3bdbbb8cef86a0f684bac0f3cfd4736de790575bc3221e887ce620fd08d45e23.jpg)  \nFig. 1. A screenshot of Shuya\u2019s AI log.\n\n1. Fear of Commitment: Many young people may have a fear of commitment, which can be associated with concerns about being tied down or losing personal freedom. They might prefer to keep their options open and avoid getting into a serious, committed relationship.   \n2.Exploration and Self-Discovery: Young adults often go through a period of self-discovery and exploration. They may want to meet and interact with a variety of people to better understand their own preferences, desires, and what they are looking for in a partner.   \n3. Emotional Unavailability: Some young individuals may not be emotionally ready for a committed love relationship. They might have unresolved emotional issues, past traumas, or simply not feel emotionally prepared for the demands of a serious relationship.   \n4. Fulfilling Different Needs: Being ambiguous or non-committal can allow individuals to fulfilldifferent needs from different people. They may seek emotional support, physical intimacy, companionship, or intellectual stimulation without putting all these expectations on a single partner.   \n5. Pressure to Settle Down: Young people may also face societal or peer pressure to settle down and have a serious relationship. Choosing to remain ambiguous with multiple people can be a way to resist these pressures and maintain independence.   \n6. Focus on Personal Growth: Some individuals prioritize personal growth and development over romantic relationships during certain phases of their lives. They may choose to keep things ambiguous with others to focus on their goals and aspirations.   \n7. Avoiding Relationship Drama: Young people may have witnessed or experienced relationship drama and conflicts, leading them to avoid entering into committed relationships that could potentially involve such drama.   \n8.Casual Dating Culture:In some cultural or social contexts, casual dating without the expectation of a Iove relationship is more common and accepted. This can influence the behavior of young people.\n\ncorrect but it could give me a better idea\u201d (Nadia, Interview).\n\nThis section shows students\u2019 diverse ways of utilizing ChatGPT to assist with their writing and research processes, demonstrating how they leveraged ChatGPT\u2019s affordances to achieve their specific purposes while addressing the challenges they encountered during the writing task.\n\n4.2. How are the L2 student writers\u2019 CAIL (or lack thereof) evidenced in their interactions with ChatGPT and their linguistic and rhetorical decision-making?\n\nFollowing an inductive thematic analysis, we identified four aspects in which students demonstrated CAIL while utilizing ChatGPT to assist with their writing: (1) having a critical awareness of AI affordances and limitations, (2) maintaining a critical positionality, (3)\n\nTable 5 A comparison between Dofi\u2019s AI log and final draft.   \n\n<html><body><table><tr><td>AI Log</td><td>Anonymous Benefits of meal sharing and meal preparation? ChatGPT Meal sharing and meal preparation offer various benefits within a family or a community: Meal Sharing: 1. Social Bonding:Sharing meals fosters social connections and strengthens relationships within the family or community.. 2.Communication and Connection:It provides a platform for conversation, sharing stories, and exchanging ideas,enhancing communication. 3. Cultural Transmission: Meals are often a platform for passing down traditions, recipes, and cultural values from generation to generation. 4. Emotional Nourishment: It provides emotional support, comfort, and a sense of belonging. Meal Preparation: 1. Collaboration and Togetherness:Working together to prepare meals encourages</td></tr></table></body></html>\n\nTable 6 A comparison of Hyun\u2019s first draft, AI log, and final draft.   \n\n<html><body><table><tr><td>First Draft</td><td>[1] In recent decades, South Korea has undergone a remarkable transformation, not only in it economic and technological landscapes but also in the dynamics of its sct..2] One of the most string and profound changes has ben the shift in traditional gnder roles within South Korean households, particularly the evolving role of men. [3] The family members had no choice but to be dependent on the patriarch the representative of the family, responsible for the family&#x27;s livelihood and the flow of information from society.</td></tr><tr><td>Hyun&#x27;s Prompt ChatGPT&#x27;s response</td><td>Check my grammar. Your essay is well-written, but I can provide some suggestions for improving the grammar and clarity of certain sentences: 1. In the opening paragraph, consider rephrasing to enhance clarity: *In recent decades, South Korea has undergone significant</td></tr><tr><td></td><td>transformations, not only in is economic and technological landscapes but also in the dynamics of it society. One f the most striking changes has been the shift i traditional gender roles within South Korean households, particularl the evolving roles of both genders . 2. In the same paragraph, when discussing the patriarchal structure, it might be clearer to say: Family members had no choice but to be</td></tr><tr><td>Final Draft</td><td>dependent on the patriarch, who was responsible for the family&#x27;s livelihood and the flow of information from society.&quot; [1] In ret deades, South Korea has underone sigficant tranomations, not only i is eonomic and technological landscapes but also in the dynamics of it society. 2] One of the most striking changes has ben the shift intraditional gender roles within South Korean households, particularly the evolving role ofboth gender..[3] Family members had no choice but to be dependent on th patriarch, who</td></tr></table></body></html>\n\ndeveloping and applying critical strategies for interacting with AI, and (4) critically evaluating AI\u2019s affordances. Below we explain each aspect with specific examples from the participants.\n\nCritical AI awareness. Apart from understanding and utilizing ChatGPT\u2019s functionalities as demonstrated in the previous research question, students also exhibited critical awareness of the algorithmic operational logic of generative AI as well as the data upon which these technologies are trained. In particular, they showed criticality towards two issues regarding training data \u2013 coded bias and underrepresented languages. For instance, based on his personal experiences interacting with AI and what he had read on social media, Hyun pointed out that ChatGPT is especially biased towards \u201cpolitical things\u201d due to the whiteness of its training data:\n\nThere is an island in Korea called Dokdo. We are fighting with Japan about this territory\u2026ChatGPT said it\u2019s a Japanese territory. So it depends on where they get it, what is more common, what is more stereotypical about those things. Also, I saw some article that there is some kind of bias in making on AI, especially for making a human face. Most of the training data are based on White people.\n\nYawa also acknowledged AI\u2019s inadequacy in providing information related to underrepresented languages and cultures like his first language Twi, given the scarcity of linguistic resources in the training of the large language model. As he shared: \u201cTwi is not a popular language, like French or Chinese. For Twi, it all comes down to the fabrication of information, it would probably give a more generalized, \u2018Oh, it might mean this.\u2019\u201d\n\nAnother notable aspect of students\u2019 critical AI awareness is their recognition of how generative AI is programmed can result in patterned, inconsistent, and inaccurate responses that limit its effectiveness and reliability as a learning and writing assistance. Yawa, in his reflection, acknowledged that a large language model is essentially \u201ca predictive model,\u201d thus providing information that can be repetitive. Yun noted that the \u201cblack-box\u201d nature of ChatGPT algorithms led to inconsistent responses even with the same prompt, and sometimes irrelevant information. Similarly, Hyun observed that generative AI might not follow prompts precisely. He noted: \u201cSo I put my entire essay and then said \u2018change my grammar.\u2019 Sometimes it\u2019s kind of annoying because it doesn\u2019t just change my grammar, it entirely changes the sentence structure although I said JUST change my grammar\u201d (Hyun, Interview). Aye, when asking ChatGPT how parenting styles in Myanmar impact children\u2019s academic success, observed that \u201csome of the answers were quite repetitive, and others contradicted each other\u201d (Aye, Reflection). Consequently, she believed that ChatGPT lacked sufficient knowledge about her culture and was not reliable.\n\nCritical AI positionality. Discerning generative AI\u2019s powerful affordances for assisting with various aspects of writing and its limitations, the participants developed nuanced positionalities to navigate their relation with AI in multifaceted ways. Firstly, all the students emphasized the necessity of one\u2019s originality and authorial voice when using AI in the writing process, ensuring that the work reflects one\u2019s unique thinking. Hyun pointed out that \u201cAI is all based on data people have already created but cannot provide any new kind of thing\u201d (Hyun, Interview). Shuya and Yawa contrasted the human writer\u2019s need to \u201cinvent\u201d with AI\u2019s tendency to produce \u201cclich\u00b4e, generalized\u201d texts.\n\nEven though students shared agreement on the importance of originality, they practiced being \u201coriginal\u201d in different ways. Dofi, for instance, believes that \u201cthe writer has to generate your own ideas before seeking the help of AI\u201d (Dofi, Interview). Similarly, Yawa did not use AI for topic selection and brainstorming because he felt it required personal creativity (Yawa, Reflection); thus, he only started to use AI for creating an outline based on his freewriting. Shuya, on the other hand, used ChatGPT to generate a list of ideas for her essay, and from there, she did more research and expanded them. She described using AI to get \u201csome inspiration\u201d and \u201ca rough shape of an idea,\u201d but emphasized that it is the author who must \u201csketch it out\u201d and create a vivid piece of work that represents their own voice. Shuya used a \u201ckey\u201d metaphor to describe her relationship with AI: she treats AI as a \u201cbasic key to a door behind which there is a range of possibilities,\u201d but it is the writer who unlocks the door and explores \u201cdifferent paths to destinations by themselves\u201d (Shuya, Interview).\n\nAnother student Hyun commented on the challenge of navigating the two sides of using AI, noting that while it can \u201cinspire\u201d ideas, it may also \u201csuppress creativity and critical thinking.\u201d He doubted that \u201cfinding information based on AI\u2019s ideas\u201d contradicts the purpose of writing which is to \u201cshow your own style, your own experiences, and your own thinking\u201d (Hyun, Interview). On the other hand, he also questioned to what extent using AI-suggested word choices could harm the author\u2019s voice: \u201cAI gives better word choices or something. So this for sure is a better tool, but I\u2019m just afraid that it\u2019s not going to be your essay\u201d (Hyun, Interview). Hyun\u2019s concern highlighted both the qualitative aspect of using AI for ideas and language, as well as the quantitative aspect of how much AI use differentiates between maintaining and losing one\u2019s own authentic voice in human-AI collaboration.\n\nTable 7 A comparison of Shuya\u2019s AI log and her final essay.   \n\n<html><body><table><tr><td>Shuya&#x27;s. AI log</td><td>3. Unfulfilled Needs: Some individuals may feel that they cannot meet all their emotional or physical needs within the confines of a monogamous relationship. Having multiple partners may provide them with the opportunity to fulfill different aspects of their desires. 4. Social and Cultural Factors: Cultural norms and attitudes towards monogamy and non- monogamy can vary significantly around the world. In some cultures or social circles, non- monogamous relationships are more accepted or common. 5. Technology: Online dating apps and social media have made it easier for people to connect with others, potentially leading to more casual or simultaneous dating or relationships. 6. Lack of Commitment: Some people may prefer to avoid long-term commitment or may not be ready for it, leading them to have multiple partners rather than settling into a single, exclusive relationship.</td></tr><tr><td>Shuya&#x27;s final essay</td><td>term, faithful relationship. In addition, in a relationship, everyone has some expectations and needs for their partner. But Haiwang just doesn&#x27;t put his needs and expectations on one person. They will meet the expectations of different people. For example, emotional needs, physical needs, companionship, etc. They have their unmet needs within the confines of a monogamous relationship. (Kimmel, 2008)</td></tr></table></body></html>\n\nHyun\u2019s question relates to another caution: writers should attend to possible AI induction, particularly for L2 writers who may harbor perceptions of their linguistic abilities as inferior to those of large language models. Hyun admitted his own tendency to regard AI suggestions as better, stating: \u201cAs long as it provides word choices, then you\u2019re going to be biased and think that word choice looks very good in this sentence\u201d (Hyun, Interview). Table 6 compares an excerpt of Hyun\u2019s introduction paragraph across his first draft, AI log, and final draft. Hyun accepted ChatGPT\u2019s grammatical and wording suggestions for all three sentences, though for slightly different reasons in each case. He admitted that while the change from \u201ca remarkable transformation\u201d to \u201csignificant transformations\u201d did not make a notable difference on the meaning, he accepted it due to his general tendency to trust AI\u2019s suggestion when it does not \u201cdamage the writer\u2019s voice and originality\u201d (Hyun, Reflection). For the second and third sentences, however, Hyun clearly noted that AI\u2019s edits contributed to greater conciseness (e.g., \u201cstriking changes\u201d) and improved accuracy (e.g., \u201cboth genders\u201d), while correcting grammatical errors and enhancing clarity (e.g., \u201cfamily members,\u201d \u201cwho was responsible\u201d), thus enhancing his voice.\n\nThree students particularly noted that their attitudes towards AI were culturally influenced, emphasizing the need to reflect on one\u2019s AI disposition in light of their cultural background. A notable example was Dofi, who moved to the US four years ago from Ghana. She shared,\n\nI definitely feel I\u2019m more traditional, especially because I\u2019m from Ghana, we barely would encourage this [AI-assisted writing]. It\u2019s always been the traditional \u2013 read books to enhance your vocabulary, to gain more knowledge, then apply them to your writing. And that\u2019s how you became a better writer overall. So I feel like I do have some hesitation when it comes to using AI completely. And I may not be the best at using AI completely just because of where I\u2019m from. (Dofi, Interview)\n\nSimilarly, Aye and Hyun acknowledged that integrating AI into their writing practices is a new concept and was not encouraged in the cultures where they came from, thus influencing their attitudes and proficiency with the AI tool.\n\nOverall, the students shared their dilemmas and different perspectives on balancing AI use with maintaining their own originality, voice, and autonomy. Their positionalities were shaped by their views on the responsibilities and ethics of being a writer, AI\u2019s intervention in their role in the writing process, and their culturally mediated AI disposition. The challenge of navigating the criticality spectrum is deeply personal, requiring thoughtful reflection on the extent to which one trusts AI. The student cases demonstrate that rather than a simple critical/uncritical divide, they positioned AI and themselves in complicated ways of navigating how AI fits into their vision of preserving originality and authorial voice within their specific writing practices.\n\nCritical strategies for human-AI interaction. To engage effectively and critically with AI, the students made efforts in developing critical strategies in various areas. The first area is prompt engineering. Hyun defined prompt engineering as \u201ccommunication between human and AI,\u201d placing AI not merely as a tool for human use, but as an active participant and learner in communication. He explained, \u201cAI is also learning from humans through the questions [humans ask], and how to communicate through that. We keep giving them data and then they keep improving\u201d (Hyun, Interview). Hyun believed that the benefits of prompt engineering skills extend beyond the context of AI, as it could help with \u201clearning how to ask people, how to better ask something, like communicating with people.\u201d In this sense, the student viewed prompt engineering as part of a larger communication skill for today\u2019s world. Similarly, Yawa noted from his experience that AI could be either a \u201cbad\u201d or \u201cgood\u201d tool, depending on how the user prompts it: \u201cI found a pattern: the specificity of my prompts affected AI\u2019s efficiency. When my prompts were not clear and specific, AI produced verbose content.\u201d (Yawa, Reflection).\n\nTable 8 A comparison between Shuya\u2019s paragraph and ChatGPT\u2019s edits.   \n\n<html><body><table><tr><td>Shuya&#x27;s text</td><td>In China, thee ralmany inteting words popular among ontmporary young people, bth ironc and otie, and hy ll hae thir nque conct.ry, in soct, sf may dife ons th oig Hng, ik scil, and schol ens, le ae his</td></tr><tr><td>AI&#x27;s edits</td><td>situation where they find out that they are a HaiWang after being in love with a person. In China, a dynamic exicon emerge continually, especill among today&#x27;s youth, who employ words both ironic and afirmative, each with its unue ane.his ter tricll htr inls, prenly me, w  lit and a nt for va ithin their relationships.</td></tr></table></body></html>\n\nIn addition to communicating with AI, the students who used ChatGPT for brainstorming particularly engaged in interactive processes that leverage AI\u2019s strengths in big data and information synthesis \u2013 an approach they used to help solicit and validate ideas to enhance their research process. For instance, Shuya used ChatGPT to confirm her hypothesis by cross-checking AI-generated information with her own knowledge. According to her reflection, she had already formed some hypotheses about the formation of the Haiwang phenomenon. Upon getting ChatGPT\u2019s answers, she felt validated and then conducted further research: \u201cOnce I knew exactly what I was looking for, I quickly figured out that some of the articles we had read were related to them, so I located the content immediately\u201d (Shuya, Reflection). Below are two screenshots showing part of her AI log (Table 7) and the final paragraph she wrote, which incorporated a course reading that supported the hypothesis she and ChatGPT shared regarding \u201cunfulfilled needs.\u201d It is worth noting that she adopted the exact wording \u201cwithin the confines of a monogamous relationship\u201d from ChatGPT without acknowledging the source.\n\nThe students\u2019 acknowledged that critical human-AI interaction was a proactive and continuous process of \u201cadapting to AI\u2019s rhythm\u201d (Dawei, Interview) and adjusting one\u2019s learning strategies to leverage the technology. This ongoing adaptation and trial process is a crucial part of the learning of AI. Another important aspect of this interaction is learning with AI, which entails active cognitive engagement and intellectual growth from the use of AI. Dofi noted that it required one\u2019s conscious efforts and the ability to manage ChatGPT\u2019s \u201ccontribution\u201d to one\u2019s learning. She illustrated this with a before and after example:\n\nBefore: Depending on the way you use AI, you may lose or you may gain, I feel like losing is in a sense that you don\u2019t do an intensive work in the background before using AI. But I do feel like I\u2019m working extensively in the background before seeking AI\u2019s help.\n\nAfter: If AI gives us good vocabulary, but then we\u2019re not even going back to look at the meaning of the word, just replace something, just put it in your essay, you just submit it. I feel like the next moment, you\u2019re not adding to your vocab in any way\u2026If it gives you these words that you\u2019ve never heard of, you should look at the meaning and learn from there. This I feel is helpful, because then it will decrease the overdependence, because you know you can put that in an essay again. (Dofi, Interview)\n\nThus, the dual dimensions of learning associated with effective and critical human-AI interaction represent a new type of learning that emerges from the technology. One needs to develop strategies in both to ensure they are \u201ctruly learning\u201d (Dofi) from interaction with AI.\n\nCritical evaluation of AI affordances. While critical AI awareness highlights how generative AI technologies function, critical evaluation of AI affordances emphasizes how well these technologies perform within specific rhetorical and linguistic contexts to achieve particular objectives. Students acknowledged the importance of critical evaluation of AI\u2019s outputs in terms of information accuracy (Felix, Dofi, Yawa, Shuya, Nadia, Hyun, Paulo), linguistic and rhetorical repertoire (Yun, Yawa, Dofi, Hyun, Nadia, Dawei), as well as their own learning context (Dofi, Dawei, Paulo, Nadia, Shuya, Aye) so that the use of AI fits their specific writing purposes. Aware of AI\u2019s inner workings and its impact on outputs, students evaluated AI\u2019s information quality, accuracy, and biases through various ways such as \u201cinteraction with friends and professors\u201d (Dofi), \u201creading\u201d (Nadia), and \u201cresearch\u201d (Felix).\n\nStudents\u2019 evaluations of generative AI\u2019s rhetorical and linguistic affordances for writing assistance varied, and had to do with their self-assessment of language proficiency, their perception of what constitutes good writing, and their consideration of the intended audience. Yawa exemplifies one typical perspective, stating that \u201cwhen it comes to the Western kind of writing, GPT is really good with that\u201d (Yawa, Interview). Yawa believed that AI could help \u201cfacilitate the communication of my ideas\u201d to better align with western rhetorical conventions (Yawa, Reflection). He also preferred to use ChatGPT than Grammarly to edit papers:\n\nIt [ChatGPT] could add words. It could bring in new sentences. If I was really good at writing, I would probably see it as an obstacle because it could change what I\u2019m trying to convey. But sometimes the sentence it edits might actually improve what I\u2019m trying to convey. But Grammarly doesn\u2019t really change anything. It\u2019s just fixing. (Yawa, Interview)\n\nThis quote suggests that Yawa found it more beneficial to seek ChatGPT\u2019s extensive assistance with deeper structural and rhetorical improvements beyond basic error correction. His metacognitive awareness of his current level of language proficiency and experience with Western rhetorical styles shaped his view of ChatGPT\u2019s affordances. Similarly, although feeling \u201coverwhelmed\u201d comparing her writing with ChatGPT\u2019s edits word by word, Yun acknowledged that she \u201cfelt grateful\u201d for the benefits ChatGPT provided in helping her edit \u201ca grammatically correct, well-structured essay\u201d and \u201clearn new ways of expression in English\u201d (Yun, Reflection). However, for the same reason, Shuya preferred to use Grammarly, as she felt that the sophisticated language generated by ChatGPT did not match\n\n# You\n\nplease correct the grammar in the following paragraph: As a non-native English speaker who is not so good at English writing, I usually use a lot of subordinate clauses and passive voice. The reason why I wrote in that way is not showing my ability of organizing sentences and logic. Oppositely, this way of writing helps me clear up my logic. Because I don't know how to explain and idea in a comprehensive and tidy way, I choose to use subordinate clauses and passive voice. After using them, I could easily organize the information of the whole sentence. Nothing could be better than explaining some concepts in a sentence with subordinate clauses and passive voice when you forgot to, or don't want to explain it before.\n\n# 5 ChatGPT\n\nAs a non-native English speaker who struggles with writing,I often resort to using numerous subordinate clauses and the passive voice. The reason for adopting this style is not to showcase my ability to structure sentences and logic. On the contrary, this approach aids in clarifying my thought process. Because I find it challenging to explain ideas in a comprehensive and orderly manner, Iopt for subordinate clauses and passive voice. These tools enable me to organize the information within a sentence more effectively.When I forget or prefer not to explain certain concepts in advance,there is nothing better than using subordinate clauses and passive voice to elucidate these concepts within a sentence.\n\nFig. 2. A screenshot of Dawei\u2019s AI log showing ChatGPT\u2019s edits on his writing.\n\nher proficiency level:\n\nI don\u2019t let myself use it for editing. I just use Grammarly. I don\u2019t use ChatGPT because such sophisticated language doesn\u2019t look like mine. The words it uses are too fancy\u2026I know what kind of stuff I can write based on my abilities. (Shuya, Interview)\n\nTable 8 shows an excerpt of Shuya\u2019s introductory paragraph and ChatGPT\u2019s modification. She commented that AI\u2019s phrasing, such as \u201ca dynamic lexicon emerges continually especially,\u201d sounded unnecessarily complicated to her. Shuya also pointed out that those \u201cspecialized and advanced words like \u2018nuances\u2019 and \u2018penchant\u2019\u201d were not expressions she would typically use (Shuya, AI Screencast), and could also change her original meaning (Shuya, Reflection). Thus, Shuya kept all her original text without taking any suggestion from ChatGPT.\n\nDawei, on the other hand, decided to use AI\u2019s linguistic suggestions despite believing that ChatGPT produces writing that is too \u201cadvanced\u201d and exceeded his current proficiency level, as he commented on ChatGPT\u2019s edits on his writing in Fig. 2:\n\nDawei\u2019s willingness to accept the suggestions stemmed from his assumption that his readers would be \u201cmore accepting\u201d to this style: \u201cMy positioning for my audience is they should be at the level of native language speakers. It\u2019s leaning towards this level, at least their level is higher than mine. I tend more towards lifting this thing a bit higher\u201d (Dawei, Interview). Dawei regarded native-like proficiency and native-speaker norms as integral to the academic authority he felt compelled to demonstrate in his writing, despite his actual audience being multicultural. In this sense, AI became a literacy broker catering to his idealization that English academic writing should \u201cpresent the logic in a way more akin to a native language speaker\u201d (Dawei, Reflection).\n\nIn contrast, other students like Dofi commented that \u201cexcessive\u201d use of academic language might not be appropriate: \u201cI feel like if it puts way too much advanced vocabulary, it\u2019s our responsibility to check through and make sure that the vocab in is perfect for the audience\u201d (Dofi, Interview). Aye, another student highly attuned to nuances in language, noted that AI edits could lead to \u201cinap propriate phrasing or word choices\u201d and sometimes \u201ca different interpretation\u201d of her original meaning, thus failing to \u201cpersonalize the text to my specific needs and voice\u201d (Aye, Reflection). The distinction in students\u2019 perspectives shows that students\u2019 language proficiency and metalinguistic awareness as well as their understanding of what constitutes good academic writing and audience ex pectations influence how they evaluate AI\u2019s linguistic and rhetorical affordances.\n\nStudents also critiqued how generative AI\u2019s neutral formality, such as its emotionless and formal language style, may influence how one engages with and evaluates its outputs. Yawa described AI-generated texts as having \u201cno flavor\u201d (Reflection) while Hyun noted they contain \u201cno personal experiences, opinions, or emotions\u201d (Reflection), making them \u201cunappealing\u201d (Dofi, Interview). Yawa further noted that AI always takes a neutral stance due to how it is programmed; however, this \u201cneutrality\u201d might disguise its coded biases and thus requires critical evaluation. One way such \u201cneutrality\u201d influenced students is evident in Shuya\u2019s defensive stance towards AI\u2019s biases: \u201cOne limit of ChatGPT is that it does not have biases. If it had biases, AI wouldn\u2019t be qualified. It can\u2019t please everyone. You can\u2019t blame AI for this limitation; AI is created by people. What AI provides is a general societal view\u201d (Shuya, Interview). Consequently, Shuya did not consider that she had any stakes in \u201cfinding faults with AI\u201d as a user and writer, stating that \u201cI just needed to get this thing [the assignment] done, so I didn\u2019t consider it [bias]\u2026If you find it wrong, leaving it to them.\u201d\n\nAnother aspect of critical evaluation considered to be essential when using AI for writing involves evaluating the learning context and the goals of learning within that context. Yawa, Paulo, Nadia, and Hyun mentioned that using AI to explain complex terms and concepts to assist with reading comprehension, could be acceptable and beneficial. For tasks that require deeper engagement with the material, critical thinking, and the development of original ideas, AI is very \u201climiting\u201d (Shuya, Reflection). Dofi echoed this sentiment, emphasizing the importance of learning to \u201cgenerate your own ideas and learn how to piece your ideas together\u201d (Dofi, Interview). All students recognize that while AI can be a useful tool for certain types of learning tasks, it is important to ensure that it complements rather than replaces the essential elements of the learning process.\n\n# 5. Discussion\n\n# .1. Complicating and navigating the contradictions in AI-assisted writing\n\nConfirming the scholarly literature, the study found that L2 writers utilized the affordances of generative AI to assist with various aspects of writing, such as vocabulary, grammar, organization, and idea development (Yan, 2023; Wang, 2024; Woo et al., 2024). AI-assisted source use and research process, an aspect of AI-assisted writing that is less examined in the current scholarship (Sun, 2024), was found to be another major use of AI in the current study. Participants employed generative AI to translate L1 sources into English, locate discipline-specific terms and relevant L2 sources, and incorporate L2 sources into writing. This finding highlights the potential of AI in facilitating students\u2019 multilingual and cross-disciplinary source engagement and research, while also calling for more empirical work in light of the growing number of specialized AI tools (e.g., NoteBookLM, Elicit) that assist with source summarization, synthesis, and analysis in research writing. Using generative AI for brainstorming and source integration, like Yawa\u2019s use of it for summarizing and compiling articles, may risk disrupting the synergistic relationship between reading and writing. Automating aspects of source engagement (e.g., distill information from scholarly sources for convenience or for consolidation of one\u2019s ideas) may lead to a transactional approach to reading and writing, where synthesizing sources becomes detached from the critical analysis that informs thinking and writing, undermining the foundational skills that writing pedagogy aims to cultivate. This raises important concerns for L2 writing teachers.\n\nIn addition to the benefits of AI in supporting L2 writers\u2019 linguistic and writing development through personalized and immediate feedback reported by previous studies (Yan, 2023; Barrot, 2023), the study found that students regarded accelerating the writing process (e.g., sorting out information, building connections between ideas, creating an outline from a jumble of thoughts) as some of the advantages of using AI technologies. The study also revealed that the students\u2019 inquiry with AI turned to be an iterative process with a lot of trials, which could lead to confusion and frustration and require significant cognitive effort. This finding helps explain the point of divergence observed in previous studies where L2 writers reported reduced cognitive load in Wang (2024) study but expe rienced heavy cognitive load in Woo et al. (2024). While generative AI reduces the cognitive load associated with the writing task, it may increase the cognitive load in navigating the technology to obtain meaningful outputs and critically integrate its feedback. We thus suggest that developing students\u2019 AI literacy should also involve carefully scaffolding skills such as prompt engineering, AI-related feedback literacy, and self-directed learning skills to help students effectively monitor and manage AI learning resources (Li et al., 2024; Wang, Li, et al., 2024) at metacognitive levels. This finding underscores the need for a pedagogical shift towards connecting AI literacy with learning goals that have been traditionally regarded as essential for writing courses, rather than treating it as a separate or add-on skill.\n\nWe found a noteworthy contradiction regarding AI\u2019s linguistic power and its influence on L2 writers. While acknowledging that LLMs can be a valuable aid in learning English academic writing, some students also expressed concern about feeling tempted to rely on and even submit to AI\u2019s linguistic eloquence. The finding brings to the forefront perils regarding integrating AI into the writing process, extending Wang (2024) concern about language AI-nization. AI may act as a new colonizing tool that reinforces standard language ideology (Nee et al., 2022), linguistic neo-imperialism (Lai, 2021), and the marginalization of other literacies and rhetorics. We contend the need to position AI literacy for L2 writers within the critical pedagogical tradition, moving beyond a practical and use-based orientation foregrounded in existing AI literacy frameworks. As such, critical AI literacy should entail empowering multi lingual writers to be active agents in interrogating and questioning the socio-political and cultural implications of AI in shaping language, knowledge, and power dynamics in academic writing as well as fostering students\u2019 awareness to critically examine the broader systems of power that govern AI technologies and their development. From this perspective, writing with AI transcends the acts of critiquing and utilizing AI outputs; it becomes a site of interaction and negotiation with broader ethical and epistemological questions that allow students to see themselves as creators of meaning relevant to their multilingual identities, rather than consumers of AI-generated content.\n\n# 5.2. A framework for critical AI literacy\n\nThe study examined L2 writers\u2019 critical AI literacy in their AI-assisted writing, providing evidence for reconsidering existing AI literacy frameworks. The study complicates many literacy educators\u2019 shared concern about student writers\u2019 uncritical reliance on AI assistance (Gupta et al., 2024). The L2 writers in this study demonstrated a spectrum of criticality towards AI and its affordances. However, our findings reveal that while the L2 writers\u2019 critical AI awareness, positionality, strategies, and evaluations are intertwined, their beliefs and practices may not always align. For instance, some participants adopted generative AI\u2019s language suggestions despite recognizing them as \u201cexcessive,\u201d or treated the coded biases in AI with a pragmatic \u201cit-has-nothing-to-do-with-me\u201d attitude. This finding suggests the importance of engaging in reflective praxis to align beliefs with practices to enhance CAIL holistically. We also want to highlight that certain approaches such as Hyun\u2019s tendency to trust AI suggestions and Dawei\u2019s full embrace of AI\u2019s language suggestions may appear uncritical, yet a deeper understanding of their positionalities reveals a more complex dynamic. The students\u2019 reliance on AI is a reflection of language ideologies shaped by their academic socialization, where native-speaker norms were regarded as benchmarks of \u201cgood\u201d academic writing. Similarly, Dofi\u2019s dilemma and decision in presenting ChatGPT as a research source to fulfill her conceived norm of English academic writing while feeling inadequate to claim her authority in writing about her own culture, also shows how the student positions her own cultural-linguistic repertoire as an L2 writer in relation to LLMs as authoritative repre sentations of L1 perfection and big-data driven knowledge bases. Thus, rather than simply labeling their use of AI as uncritical, it is more important to inspect and contextualize how their deliberate practices of orchestrating AI outputs, existing on a spectrum of criticality, were shaped by their efforts to meet their (mis)understandings of rhetorical demands.\n\n![](img/b3e93d74af98ce0b4ba37e47f77a59a614ef20d790dfe811d704d97eb3812b02.jpg)  \nFig. 3. An APSE model of critical AI literacy.\n\nMoreover, an AI literacy model based on Bloom\u2019s taxonomy may be inadequate and inaccurate, as it presents a linear and pro gressive approach to the development of AI literacy, failing to capture the interconnectedness of its different components. Thus, we propose the following critical AI literacy framework for L2 writing based on our findings, as shown in Fig. 3. The CAIL framework encompasses (1) critical AI awareness (A) of AI\u2019s algorithmic inner workings, functionalities, training data, and biases. This aligns the \u201cknow and understand\u201d component of the models by $\\mathrm { N g }$ et al. (2021) and Warscheauer et al. (2023). (2) critical AI positionality (P), which involves recognizing one\u2019s disposition towards AI and critically reflecting on one\u2019s voice and role in relation to AI, seeking a balanced position within the spectrum of reliance on versus resistance to AI. This aspect was not particularly addressed in Ng et al. (2021) and Warschauer et al. (2023); however, we highlight its importance as AI can play an active role in L2 writers\u2019 meaning-making processes and shape how they viewed their relationship with writing and technology. As Leander and Burriss (2020) argues, AI is not a passive tool; it exists \u201cinside,\u201d \u201cwith,\u201d \u201calongside,\u201d \u201cabove,\u201d \u201ctoward,\u201d \u201cagainst,\u201d and \u201camong\u201d us, especially in an increasingly AI-mediated world and where authoring the posthuman text is becoming more and more common (Gourlay, 2015). (3) critical strategies for human-AI interaction (S), which refers to adopting critical approaches to utilizing AI tools to support writing and self-learning in responsible and meaningful ways. This involves a dynamic process of prompt engineering to effectively communicate with AI, elicit appropriate responses, and proactively adjust one\u2019s strategies to assist with writing. This dimension extends $\\mathrm { N } g$ et al.\u2019s (2021) \u201cuse and apply\u201d and Warschauer et al.\u2019s (2023) \u201caccess and navigate\u201d and \u201cprompt.\u201d Additionally, we emphasize the social nature of prompt engineering (Bao & Li, 2023), and the importance of taking a proactive role and being adaptive in the self-directed learning process of using AI (Li et al., 2024). (4) critical evaluation of AI affordances (E) entails evaluating AI\u2019s outputs in terms of information accuracy and quality, linguistic repertoire and possible linguicism, rhetorical and cultural sensibility, and ideological biases, as well as their usefulness and appropriateness according to one\u2019s specific learning and rhetorical context, writing purposes, and audiences, to ensure ethicality. This dimension corresponds to $\\mathrm { N } g$ et al.\u2019s (2021) \u201cevaluate\u201d and Warschauer et al. (2023) \u201ccorroborate,\u201d but specifically addresses the unique challenges L2 writers may face. While their models focus on evaluating the accuracy and biases of AI-generated content, we also consider how such texts might influence L2 writers linguistically and rhetorically, and conversely, how L2 writers might creatively leverage these linguistic and rhetorical repertoires for their specific writing contexts.\n\nThe four components represent distinct yet overlapping aspects of CAIL. For instance, one\u2019s awareness of AI biases and limitations can influence their positionality and evaluation of AI\u2019s affordances for writing. The strategies that L2 writers develop through their interactions with AI can also enhance their understanding of AI\u2019s affordances and their critical awareness. One\u2019s critical evaluation of AI can also be shaped by their positionality and perspective, which are impacted by their experiences and backgrounds. Thus the framework considered the multifaceted nature of learning involved in AI-assisted writing: learning of AI and learning with AI. Developing a comprehensive understanding and application of these four components fosters a holistic approach to critically and\n\nTable 9 Strategies and pedagogical possibilities for developing CAIL based on the APSE model.   \n\n<html><body><table><tr><td>Critical Dimensions</td><td>Strategies</td><td>Pedagogical Possibilities</td></tr><tr><td>Critical AI awareness</td><td>: Develop knowledge on AI&#x27;s operational basis : Understand the discourse features and patterns of AI- generated responses : Analyze how AI&#x27;s foundational operational mechanisms shape</td><td>: Equip students with interdisciplinary knowledge related to the technical aspects of AI : Interrogate AI biases by drawing upon L2 writers&#x27; own cross- cultural knowledge, experiences, and reflections</td></tr><tr><td>Critical AI positionality</td><td>its responses and interaction with human . Reflect on one&#x27;s views on writing and writerly virtues : Reflect on one&#x27;s language and technology ideologies (e.g., L1 vs. L2, human vs. AI) : Reflect on how these perceptions and positionalities come into being through one&#x27;s academic literacy practices, educational</td><td>: Foster student peer collaboration to examine their positionalities and underlying beliefs : Engage in discussions about the ethical implications (e.g., academic integrity, social and environmental considerations) of various human-AI positionalities</td></tr><tr><td>Critical strategies for human-AI interaction</td><td>experiences, and cultural backgrounds : Learn effective prompt engineering skills to communicate with AI : Engage in iterative and adaptive processes of refining AI interaction and learning strategy : Monitor one&#x27;s learning with AI</td><td>: Develop prompt engineering skills by leveraging L2 learners and teachers&#x27; strengths, for instance, through linguistic, discourse, and genre analysis approaches and communication perspectives. : Cultivate students&#x27; disposition and strategies for self-directed</td></tr><tr><td>Critical evaluation of AI affordances</td><td>. Evaluate AI&#x27;s information accuracy, quality, and reliability : Evaluate AI&#x27;s linguistic and rhetorical affordances in relation to the writer&#x27;s proficiency and the rhetorical context : Evaluate the learning context and the goal of learning within the context in relation to the role of AI</td><td>learning with AI, focusing on self-monitoring and managing one&#x27;s learning with AI (Wang, Li, et al., 2024) : Verify AI outputs with human (e.g., teachers and peers) and nonhuman resources (e.g., research) (Li et al., 2024) : Develop students&#x27; metalinguistic knowledge to evaluate AI&#x27;s usefulness and appropriateness for specific writing contexts : Foster students&#x27; metacognition of the learning task and</td></tr></table></body></html>\n\nethically engage with AI technologies.\n\n# 6. Conclusion and implications\n\nFollowing a qualitative design, we explored L2 writers\u2019 critical AI literacy in their AI-assisted writing processes. Complicating the scholarly literature on the dilemmas and contradictions L2 writers are likely to encounter in AI-assisted writing, the study discussed how students perceived and navigated the various challenges in balancing AI use with their own voice through unpacking their critical decision-making involved in AI-assisted writing. To fill the gap in evidence-based models on critical AI literacy in the current literature, the study proposes a CAIL model focusing on critical awareness, positionality, strategies, and evaluations in AI use.\n\nThe study is limited due to its small sample size and short duration, which may restrict the applicability of the findings to a broader range of settings, such as students of different age groups, language proficiencies, writing experiences, as well as L2 writing instruction in various educational and cultural contexts. We thus recommend that scholars examine diverse student populations and conduct more large-scale studies across different learning contexts to test, validate, and expand the framework. We also suggest that future studies explore, in greater depth, how students\u2019 language proficiency levels and prior writing experiences may influence their CAIL. Furthermore, the study focused on students\u2019 use of ChatGPT (GPT 3.5) and did not consider other AI models and generative AIpowered writing tools. Future studies should examine the latest advancements as well as various specialized AI writing tools to un derstand how they may influence students\u2019 writing differently. Future research should also take into account the multimodal func tionalities of AI for assisting students\u2019 digital multimodal composing (Tan, Xu, & Wang, 2025).\n\nWe make a list of strategies and pedagogical possibilities for developing critical AI literacy based on the APSE model as shown in Table 9. These considerations are meant to be illustrative rather than exhaustive. We would like to highlight that explicit instruction on critical AI literacy is fundamental to prepare students for making informed and ethical decisions about when, where, and how to use, evaluate, and incorporate AI. Writing and language instructors should discuss specific scenarios and break down the skills for critical AI use, such as prompt engineering and feedback literacy. They should also encourage students to reflect on how AI technologies affect their language use, the learning process, and ethical considerations. Instructors should also help students develop relevant language skills and metalinguistic knowledge to identify ways of using AI appropriate for specific writing contexts, considering disciplinary writing conventions, goals and audiences for writing, and the learners\u2019 own attributes and differences. Finally, instructors should encourage students to explore the use of various semiotic repertoires for creative communications and identity expression, rather than pursuing correctness and native speaker-like perfection. AI should be a means to help students leverage linguistic and multimodal meaning-making resources, instead of a convenience tool for producing grammatically correct sentences and streamlining formulaic academic writing. The study urges language and writing educators to rethink our current writing education that privileges certain linguistic, rhetorical, and discursive features that can be easily replicated by AI, for instance, embracing decolonizing academic writing pedagogies (Canagarajah, 2023). In addition to supporting students, it is crucial to provide professional development and training for L2 writing instructors and teacher educators, so that they are equipped to integrate critical AI literacy into their teaching. Such CAIL training opportunities should center around enhancing teachers\u2019 technological and pedagogical readiness to cultivate students\u2019 critical awareness, positionality, interaction strategies, and evaluation skills in using AI, enabling their pedagogy to engage with the sociopolitical, linguistic, and ethical complexities of AI in writing.\n\n# CRediT authorship contribution statement\n\nWang Zhaozhe: Writing \u2013 review & editing, Visualization, Validation, Resources, Methodology, Formal analysis, Conceptuali zation. Wang Chaoran: Writing \u2013 review & editing, Writing \u2013 original draft, Visualization, Validation, Resources, Project adminis tration, Methodology, Formal analysis, Conceptualization.\n\n# Data availability\n\nData will be made available on request.\n\n# References\n\nBao, Y., & Li, B. (2023). A preliminary study on graduate student instructors\u2019 exploration, perception, and use of ChatGPT. International Journal of Computer-Assisted Language Learning and Teaching, 13(1), 1\u201323. https://doi.org/10.4018/IJCALLT.332873   \nBarrot, J. S. (2023). Using ChatGPT for second language writing: Pitfalls and potentials. Assessing Writing, 57, Article 100745. https://doi.org/10.1016/j. asw.2023.100745   \nBewersdorff, A., Zhai, X., Roberts, J., & Nerdel, C. (2023). Myths, mis- and preconceptions of artificial intelligence: A review of the literature. Computers and Education: Artificial Intelligence, 4, Article 100143. https://doi.org/10.1016/j.caeai.2023.100143   \nCanagarajah, S. (2023). Decolonizing academic writing pedagogies for multilingual students. TESOL Quarterly. https://doi.org/10.1002/tesq.3231. tesq.3231.   \nCardon, P., Fleischmann, C., Aritz, J., Logemann, M., & Heidewald, J. (2023). The challenges and opportunities of AI-assisted writing: Developing AI literacy for the AI age. Business and Professional Communication Quarterly, 86(3), 257\u2013295. https://doi.org/10.1177/23294906231176517   \nChomsky, N., Roberts, I., & Watumull, J. (2023). The false promise of ChatGPT. The New York Times. https://www.nytimes.com/2023/03/08/opinion/noamchomsky-chatgpt-ai.html.   \nFreire, P. (1970). Pedagogy of the oppressed. Continuum.   \nGiroux, H. A. (1997). Pedagogy and the politics of hope: Theory, culture, and schooling. Westview Press.   \nGourlay, L. (2015). Posthuman texts: Nonhuman actors, mediators and the digital university. Social Semiotics, 25(4), 484\u2013500. https://doi.org/10.1080/ 10350330.2015.1059578   \nGupta, A., Atef, Y., Mills, A., & Bali, M. (2024). Assistant, parrot, or colonizing loudspeaker? ChatGPT metaphors for developing critical AI literacies. Open Praxis, 16 (1), 37\u201353. https://doi.org/10.55982/openpraxis.16.1.631   \nKern, R. (2024). Twenty-first century technologies and language education: Charting a path forward. The Modern Language Journal, 108(2), 515\u2013533. https://doi.org/ 10.1111/modl.12924   \nKonishi, Y. (2015). What is Needed for AI literacy? Priorities for the Japanese economy in 2016. https://www.rieti.go.jp/en/columns/s16_0014.html.   \nKimmel, M. (2008). Guyland: The perilous world where boys become men. HarperCollins.   \nKubota, R. (2023). Another contradiction in AI-assisted second language writing. Journal of Second Language Writing, 62, Article 101069. https://doi.org/10.1016/j. jslw.2023.101069   \nLai, M. L. (2021). English linguistic neo-imperialism \u2013 a case of Hong Kong. Journal of Multilingual and Multicultural Development, 42(4), 398\u2013412. https://doi.org/ 10.1080/01434632.2019.1702667   \nLaupichler, M. C., Aster, A., Schirch, J., & Raupach, T. (2022). Artificial intelligence literacy in higher and adult education: A scoping literature review. Computers and Education: Artificial Intelligence, 3, Article 100101. https://doi.org/10.1016/j.caeai.2022.100101   \nLeander, K. M., & Burriss, S. K. (2020). Critical literacy for a posthuman world: When people read, and become, with machines. British Journal of Educational Technology, 51(4), 1262\u20131276. https://doi.org/10.1111/bjet.12924   \nLi, B., Bonk, C., Wang, C., & Kou, X. (2024). Reconceptualizing self-directed learning in the era of generative AI: An exploratory analysis of language learning. IEEE Transactions on Learning Technologies, 17. https://doi.org/10.1109/TLT.2024.3386098   \nLong, D., & Magerko, B. (2020). In R. Bernhaupt, F. Mueller, D. Verweij, J. Andres, J. McGrenere, A. Cockburn, et al. (Eds.), CHI 2020 Proceedings. What is AI literacy? Competencies and design considerations (pp. 1\u201316). ACM.   \nMemarian, B., & Doleck, T. (2023). Fairness, Accountability, Transparency, and Ethics (FATE) in Artificial Intelligence (AI) and higher education: A systematic review. Computers and Education: Artificial Intelligence, 5, Article 100152. https://doi.org/10.1016/j.caeai.2023.100152   \nMLA-CCCC Joint Task Force on Writing and AI Working Paper: Overview of the Issues, Statement of Principles, and Recommendations (July, 2023). Retrieved from https://hcommons.org/app/uploads/sites/1003160/2023/07/MLA-CCCC-Joint-Task-Force-on-Writing-and-AI-Working-Paper-1.pdf.   \nNee, J., Smith, G. M., Sheares, A., & Rustagi, I. (2022). Linguistic justice as a framework for designing, developing, and managing natural language processing tools, 205395172210909 Big Data Society, 9(1). https://doi.org/10.1177/20539517221090930.   \nNg, D. T. K., Leung, J. K. L., Chu, S. K. W., & Qiao, M. S. (2021). Conceptualizing AI literacy: An exploratory review. Computers and Education: Artificial Intelligence, 2, Article 100041. https://doi.org/10.1016/j.caeai.2021.100041   \nNg, D. T. K., Wu, W., Leung, J. K. L., Chiu, T. K. F., & Chu, S. K. W. (2024). Design and validation of the AI literacy questionnaire: The affective, behavioural, cognitive and ethical approach. British Journal of Educational Technology, 55(3), 1082\u20131104. https://doi.org/10.1111/bjet.13411   \nOu, A. W., Khuder, B., Franzetti, S., & Negretti, R. (2024). Conceptualising and cultivating critical GAI Literacy in doctoral academic writing. Journal of Second Language Writing, 66, Article 101156. https://doi.org/10.1016/j.jslw.2024.101156   \nPecorari, D. (2023). Generative AI: Same same but different? Journal of Second Language Writing, 62, Article 101067. https://doi.org/10.1016/j.jslw.2023.101067   \nPraphan, P. W., & Praphan, K. (2023). AI technologies in the ESL/EFL writing classroom: The villain or the champion? Journal of Second Language Writing, 62, Article 101072. https://doi.org/10.1016/j.jslw.2023.101072   \nSaldana, \u02dc J. (2015). The coding manual for qualitative researchers (4th ed.). Sage.   \nSasaki, M. (2023). AI tools as affordances and contradictions for EFL writers: Emic perspectives and L1 use as a resource. Journal of Second Language Writing, 62, Article 101068. https://doi.org/10.1016/j.jslw.2023.101068   \nSouthworth, J., Migliaccio, K., Glover, J., Glover, J., Reed, D., McCarty, C., Brendemuhl, J., & Thomas, A. (2023). Developing a model for AI Across the curriculum: Transforming the higher education landscape via innovation in AI literacy. Computers and Education: Artificial Intelligence, 4, Article 100127. https://doi.org/ 10.1016/j.caeai.2023.100127   \nStojanov, A., Liu, Q., & Koh, J. (2024). University students\u2019 self-reported reliance on ChatGPT for learning: A latent profile analysis. Computers and Education: Artificial Intelligence, 6. https://doi.org/10.1016/j.caeai.2024.100243   \nSu, Y., Lin, Y., & Lai, C. (2023). Collaborating with ChatGPT in argumentative writing classrooms. Assessing Writing, 57, Article 100752. https://doi.org/10.1016/j. asw.2023.100752   \nSun, Q. (2024). Exploring human-generative AI interaction in L2 learners\u2019 source use practices: Issues, trials, and critical reflections. Journal of Academic Writing, 14 (1), 24\u201342. https://doi.org/10.18552/joaw.v14i1.1055   \nTan, X., Xu, W., & Wang, C. (2025). Purposeful remixing with generative AI: Constructing designer voice in multimodal composing. Computers & Composition, 75. https://doi.org/10.1016/j.compcom.2024.102893   \nTsai, C., Lin, Y., & Brown, I. (2024). Impacts of ChatGPT-assisted writing for EFL English majors: Feasibility and challenges. Education and Information Technologies. https://doi.org/10.1007/s10639-024-12722-y   \nTseng, W., & Warschauer, M. (2023). AI-writing tools in education: If you can\u2019t beat them, join them. Journal of China Computer-Assisted Language Learning. https:// doi.org/10.1515/jccall-2023-0008   \nWang, C. (2024). Exploring students\u2019 generative AI-assisted writing processes: Perceptions and experiences from native and nonnative english speakers. Technology, Knowledge and Learning. https://doi.org/10.1007/s10758-024-09744-3   \nWang, C., Li, Z., & Bonk, C. (2024). Understanding self-directed learning in AI-Assisted writing: A mixed methods study of postsecondary learners. Computers and Education: Artificial Intelligence, 6, Article 100247. https://doi.org/10.1016/j.caeai.2024.100247   \nWarschauer, M., Tseng, W., Yim, S., Webster, T., Jacob, S., Du, Q., & Tate, T. (2023). The affordances and contradictions of AI-generated text for writers of English as a second or foreign language. Journal of Second Language Writing, 62, Article 101071. https://doi.org/10.1016/j.jslw.2023.101071   \nWoo, D. J., Wang, D., Guo, K., & Susanto, H. (2024). Teaching EFL students to write with ChatGPT: Students\u2019 motivation to learn, cognitive load, and satisfaction with the learning process. Education and Information Technologies. https://doi.org/10.1007/s10639-024-12819-4   \nYan, D. (2023). Impact of ChatGPT on learners in a L2 writing practicum: An exploratory investigation. Education and Information Technologies. https://doi.org/ 10.1007/s10639-023-11742-4   \nYin, R. (2018). Case study research and applications: Design and methods (6th ed.). Sage.\n\nChaoran Wang is a Multilingual Writing Specialist and Assistant Professor of Writing at Colby College. Her research examines the issues of literacy development of multilingual students and technology enhanced language learning through the intersecting perspectives of writing studies, applied linguistics, and educational tech nologies. Her recent work has appeared in Computers and Education: Artificial Intelligence, Applied Linguistics, Language Learning & Technology, IEEE Transactions on Learning Technologies, Research Methods in Applied Linguistics, among others. She is currently co-editing two books on AI and writing/language education with Routledge.", "metadata": {"authors": ["Chaoran Wang", "Zhaozhe Wang"], "category": "research", "confidence_score": 0.8, "document_type": "journal", "has_abstract": true, "has_methodology": true, "has_results": true, "key_findings": ["Students utilized AI in various ways, including topic selection and brainstorming, outlining, revising, editing, and sourcing", "The APSE model highlights the distinct yet overlapping components of critical AI literacy and addresses specific concerns that L2 writers face to leverage generative AI's linguistic and rhetorical resources critically"], "methodology": "qualitative", "pedagogical_confidence": 0.46, "pedagogical_implications": true, "publication_year": 2024, "research_questions": [], "source_file": "out_Y2S8X4NT_Wang_and_Wang_-_2025_-_Investig.md", "subject_area": "education", "tags": ["generative AI", "artificial intelligence", "ChatGPT", "AI literacy", "critical AI-assisted writing", "L2 writing"], "title": "Investigating L2 writers' critical AI literacy in AI-assisted writing: An APSE model"}, "search_text": "Investigating L2 writers' critical AI literacy in AI-assisted writing: An APSE model generative AI artificial intelligence ChatGPT AI literacy critical AI-assisted writing L2 writing education # Investigating L2 writers\u2019 critical AI literacy in AI-assisted writing: An APSE model\n\nChaoran Wang a,\\* , Zhaozhe Wang\n\na Department of Writing, Colby College, 5290 Mayflower Hill, Waterville, ME 04901, USA   \nb Institute for the Study of University Pedagogy, University of Toronto Mississauga, Department of Curriculum, Teaching and Learning, OISE,   \nUniversity of Toronto, 3359 Mississauga Road, Mississauga, Ontario L5L 1C6, Canada\n\n# A R T I C L E I N F O\n\n# A B S T R A C T\n\nKeywords:   \nGenerative AI   \nArtificial intelligence   \nChatGPT   \nAI literacy   \nCritical   \nAI-assisted writing   \nL2 writing\n\nWhile the need to foster critical AI literacy (CAIL) among L2 writers has gained increasing recognition, research offering empirically grounded models for integrating CAIL into L2 writing remains limited. To contribute to the ongoing research in AI-assisted L2 writing and CAIL, we designed the current study to understand how students used ChatGPT, a popular generative AI technology, to support their writing and to uncover their CAIL in their writing practices in two first-year writing classes in the US. Adopting a qualitative case study design, we analyzed stu dents\u2019 interview data, written reflections, AI logs, and screencasts of students\u2019 interactions with AI. Findings show that students utilized AI in various ways, including topic selection and brainstorming, outlining, revising, editing, and sourcing. We propose an APSE model based on four dimensions identified in students\u2019 CAIL while using ChatGPT: (1) critical awareness of AI (A), (2) critical positionality (P), (3) critical strategies for interacting with AI (S), and (4) critical evaluation of AI affordances (E). The model highlights the distinct yet overlapping components of CAIL and addresses specific concerns that L2 writers face to leverage generative AI\u2019s linguistic and rhetorical resources critically. Pedagogical implications include explicit instruction on CAIL, developing students\u2019 AI feedback litera"}, "title": "Investigating L2 writers' critical AI literacy in AI-assisted writing: An APSE model", "authors": ["Chaoran Wang", "Zhaozhe Wang"], "tags": ["generative AI", "artificial intelligence", "ChatGPT", "AI literacy", "critical AI-assisted writing", "L2 writing"], "filename": "out_Y2S8X4NT_Wang_and_Wang_-_2025_-_Investig.md"}], "created_at": 1757715460.685688}