---
authors:
- Ulrike Cress
- Vania Dimitrova
- Marcus Specht
category: research
confidence_score: 0.8
document_type: conference
has_abstract: true
has_methodology: true
has_results: true
key_findings: []
methodology: theoretical
publication_year: 2009
research_questions: []
source_file: Implementation and Evaluation of a Tool for Setting Goals in Self-regulated
  Learning with Web Resources.clean.md
subject_area: education
tags:
- technology enhanced learning
- interdisciplinary
- informal learning
- knowledge communities
title: Learning in the Synergy of Multiple Disciplines
---

# Learning in the Synergy of Multiple Disciplines
## 4th European Conference on Technology Enhanced Learning, EC-TEL 2009

**Nice, France, September 29–October 2, 2009**

### Editors
- Ulrike Cress, Knowledge Media Research Center (KMRC), Tübingen, Germany
- Vania Dimitrova, University of Leeds, UK  
- Marcus Specht, Open University of the Netherlands, Netherlands

### Preface

This conference on technology enhanced learning is the fourth event in a series that started in 2006. It was held from September 29th to October 2nd, 2009 in Nice (France). The EC-TEL conference series provides a forum for presenting and promoting high-quality research in the area of technology enhanced learning.

The EC-TEL conference was originally launched by the European network of excellence ProLearn and attracted many people from both the ProLearn and Kaleidoscope networks of excellence. In 2009, a new European network, STELLAR, was launched, which continues the work and success of the former networks and takes a broader multi-disciplinary perspective. A key issue is making the research communities aware of the different projects and activities within Europe and beyond. The aim is to build an integrated research arena in which groups with different backgrounds can build on each other and where the synergy between multiple research approaches and disciplines is fostered.

The face of learning is changing substantially. As a result, the topic of technology enhanced learning has to take a broader interdisciplinary perspective. Formal learning is surrounded by a variety of opportunities for informal learning, classroom learning is complemented by workplace learning, and even the frontiers between teaching and learning are disappearing. People are learning collaboratively, they engage in knowledge communities and change from knowledge recipients to knowledge producers. These developments are driven by new technologies: large scale knowledge repositories provide learners with content and support them in an individualized and adaptive way; semantic technologies provide contextualized and task-specific information; the Web 2.0 enables people to participate actively in knowledge communication and knowledge construction, mobile and ubiquitous computing technologies enable the integration of informal and formal learning support. These new tools and technical means call for psychological and educational models of learning, which will have to take into account the vast diversity of situations in which learning takes place today, as well as the specific needs of individuals, tutors and organisations.

The papers submitted to this conference reflect this broad range of topics. A total of 25% of all submissions used the keyword "user-adaptive systems and personalisation", which has been a typical topic of advanced learning environments for many years. The keywords "learning communities and communities of practice" and "collaborative knowledge building" were used by 23% of the submissions. These topics indicate a new perspective on learning and a drift from formal to more informal and natural learning. This tendency is also evident in the strong presence of the keywords "informal learning", "learner motivation and engagement", "problem and project-based learning", "distance learning", "knowledge management and organisational learning", and "instruction design".

## Preface

One fifth of the submissions exploited the newly emerging technological directions of "semantic web and Web 2.0".

The EC-TEL 2009 was truly international and highly competitive. Overall, 136 paper submissions and 22 poster submissions from 469 authors in 43 countries were received. The majority of submissions came from European countries (29 countries), but authors also came from 8 Asian and 4 American countries, as well as one African country. One submission was received from Australia.

Program Committee members, coming from 19 countries, represented a broad spectrum of disciplines connected to technology enhanced learning. A rigorous review process was conducted where each submission was reviewed by at least three reviewers.

Out of all submissions, 35 were accepted as full papers (22%), 17 as short papers and a further 35 as posters. In the proceedings, the full papers are allowed up to 15 pages and the short papers and posters up to 6 pages. The conference programme included three keynote speakers who gave an idea of the wide range of technology enhanced learning. Short abstracts of the keynote talks are included in the proceedings.

The contributions presented in this volume show the colourfulness of research in technology enhanced learning. They describe technical innovations, demonstrate creative educational settings, invent exciting research questions and show successful implementations. We are confident that this spectrum of research will promote creativity and synergy.

A conference of this size would not have been possible without the invaluable help of the organising committee: the workshop chairs Nikol Rummel and Peter Dolog, the doctoral consortium chairs Frank Fischer and Stefanie Lindstaedt, the demonstration chairs Alexandra Cristea and Nikos Karacapilidis, and the industrial session chair Volker Zimmermann. Special thanks go to the head of the local organizing team Katherine Maillet, as well as the publicity chairs Marcela Morales and Mohamed Amine Chatti.

The EC-TEL 2009 conference promises to be a stimulating research event, presenting state-of-the-art projects and shaping the future of technology enhanced research in Europe and beyond.

September 2009  
Ulrike Cress  
Vania Dimitrova  
Marcus Specht

## Conference Organisation

### General Chair
- Marcus Specht, Centre for Learning Sciences and Technology, OUNL, NL

### Programme Chairs
- Ulrike Cress, Knowledge Media Research Center, Germany
- Vania Dimitrova, University of Leeds, UK

### Local Organisation Chair
- Katherine Maillet, Institut Telecom, Telecom & Management SudParis, France

### Doctoral Consortium Chairs
- Frank Fischer, LMU University of Munich, Germany
- Stefanie Lindstaedt, Know Center, Austria

### Workshop Chairs
- Nikol Rummel, University of Freiburg, Germany
- Peter Dolog, Aalborg University, Denmark

### Demonstration Chairs
- Alexandra Cristea, University of Warwick, UK
- Nikos Karacapilidis, University of Patras, Greece

### Industrial Session Chair
- Volker Zimmermann, IMC, Germany

### Publicity Chairs
- Marcela Morales, Institut Telecom, Telecom & Management SudParis, France
- Mohamed Amine Chatti, RWTH Aachen University, Germany

## Programme Committee
[List of committee members organized alphabetically]

Here's the cleaned Markdown:

## Organization

## Additional Reviewers

- Stamatina Anastopoulou
- Benjamin Huynh Kim Bang
- Michal Barla
- Scott Bateman
- Elizabeth Brown
- Roman Brun
- Wenli Chen
- Manuela Delfino
- Hendrik Drachsler
- María Blanca Ibáñez Espiga
- Raquel M. Crespo García
- George Gkotsis
- Israel Gutierrez
- Zoe Handley
- Yusuke Hayashi
- I-Han Hsiao
- Eva Hudlicka
- Raija Hämäläinen
- Nikos Karousos
- Sebastian Kelle
- Tom Kirkham
- Styliani Kleanthous
- Kouji Kozaki
- Barbara Kump
- Danielle H. Lee
- Vignollet Laurence
- Derick Leony
- Sarah Lewthwaite
- Tobias Ley
- David Maroto
- Sze Ho David Moh
- Vlad Posea
- Francesca Pozzi
- Andreas S. Rath
- Traian Rebedea
- Riad Saba
- Olga C. Santos
- Hans-Christian Schmitz
- Stefano Tardini
- Jozef Tvarozek
- Manolis Tzagarakis
- Elizabeth Uruchurtu
- Luis de la Fuente Valentín
- Dominique Verpoorten
- Juan Quemada Vives
- Michael Yudelson
- Sam Zeini
- Sabrina Ziebarth

## Table of Contents

### Keynotes

1. Making Sense of Sensemaking in the Digital World  
   Peter Pirolli

2. Towards an Interdisciplinary Design Science of Learning  
   Mike Sharples

3. Use and Acquisition of Externalized Knowledge  
   Friedrich W. Hesse

### Adaptation and Personalisation

1. LAG 2.0: Refining a Reusable Adaptation Language and Improving on Its Authoring  
   Alexandra I. Cristea, David Smits, Jon Bevan, and Maurice Hendrix

2. The Conceptual and Architectural Design of a System Supporting Exploratory Learning of Mathematics Generalisation  
   Darren Pearce and Alexandra Poulovassilis

3. Experience Structuring Factors Affecting Learning in Family Visits to Museums  
   Marek Hatala, Karen Tanenbaum, Ron Wakkary, Kevin Muise, Bardia Mohabbati, Greg Corness, Jim Budd, and Tom Loughin

4. Personalisation of Learning in Virtual Learning Environments  
   Dominique Verpoorten, Christian Glahn, Milos Kravcik, Stefaan Ternier, and Marcus Specht

5. A New Framework for Dynamic Adaptations and Actions  
   Carsten Ullrich, Tianxiang Lu, and Erica Melis

6. Getting to Know Your User – Unobtrusive User Model Maintenance within Work-Integrated Learning Environments  
   Stefanie N. Lindstaedt, Günter Beham, Barbara Kump, and Tobias Ley

7. Adaptive Navigation Support for Parameterized Questions in Object-Oriented Programming  
   I-Han Hsiao, Sergey Sosnovsky, and Peter Brusilovsky

8. Automated Educational Course Metadata Generation Based on Semantics Discovery  
   Marián Šimko and Mária Bieliková

9. Searching for "People Like Me" in

## Table of Contents

## Remote Hands-On Experience and Collaboration
- Remote Hands-On Experience: Distributed Collaboration with Augmented Reality (226)  
*Matthias Krauß, Kai Riege, Marcus Winter, and Lyn Pemberton*

- A Comparison of Paper-Based and Online Annotations in the Workplace (240)  
*Ricardo Kawase, Eelco Herder, and Wolfgang Nejdl*

- Learning by Foraging: The Impact of Social Tags on Knowledge Acquisition (254)  
*Christoph Held and Ulrike Cress*

- Assessing Collaboration Quality in Synchronous CSCL Problem-Solving Activities: Adaptation and Empirical Evaluation of a Rating Scheme (267)  
*Georgios Kahrimanis, Anne Meier, Irene-Angelica Chounta, Eleni Voyiatzaki, Hans Spada, Nikol Rummel, and Nikolaos Avouris*

## Learning Communities and Communities of Practice
- Facilitate On-Line Teacher Know-How Transfer Using Knowledge Capitalization and Case Based Reasoning (273)  
*Celine Quenu-Joiron and Thierry Condamines*

- Edushare, a Step beyond Learning Platforms (283)  
*Romain Sauvain and Nicolas Szilas*

- Design in Use of Services and Scenarios to Support Learning in Communities of Practice (298)  
*Bernadette Charlier and Amaury Daele*

- Creating an Innovative Palette of Services for Communities of Practice with Participatory Design: Outcomes of the European Project PALETTE (304)  
*Liliane Esnault, Amaury Daele, Romain Zeiliger, and Bernadette Charlier*

## Learning Contexts
- NetLearn: Social Network Analysis and Visualizations for Learning (310)  
*Mohamed Amine Chatti, Matthias Jarke, Theresia Devi Indriasari, and Marcus Specht*

- Bridging Formal and Informal Learning – A Case Study on Students' Perceptions of the Use of Social Networking Tools (325)  
*Margarida Lucas and António Moreira*

- How to Get Proper Profiles? A Psychological Perspective on Social Networking Sites (338)  
*Katrin Wodzicki, Eva Schwämmlein, and Ulrike Cress*

- Collaborative Learning in Virtual Classroom Scenarios (344)  
*Katrin Allmendinger, Fabian Kempf, and Karin Hamann*

- Review of Learning in Online Networks and Communities (350)  
*Kirsti Ala-Mutka, Yves Punie, and Anusca Ferrari*

- Self-profiling of Competences for the Digital Media Industry: An Exploratory Study (365)  
*Svenja Schröder, Sabrina Ziebarth, Nils Malzahn, and H. Ulrich Hoppe*

- PPdesigner: An Editor for Pedagogical Procedures (379)  
*Christian Martel, Laurence Vignollet, Christine Ferraris, Emmanuelle Villiot-Leclercq, and Salim Ouari*

- Ontology Enrichment with Social Tags for eLearning (385)  
*Paola Monachesi, Thomas Markus, and Eelco Mossel*

## Problem and Project-Based Learning, Inquiry Learning
- How Much Assistance Is Helpful to Students in Discovery Learning? (391)  
*Alexander Borek, Bruce M. McLaren, Michael Karabinos, and David Yaron*

- A Fruitful

## Table of Contents

## Model and Tool to Clarify Intentions and Strategies in Learning Scenarios Design
Valérie Emin, Jean-Philippe Pernin, and Viviane Guéraud

## Users in the Driver's Seat: A New Approach to Classifying Teaching Methods in a University Repository
Susanne Neumann, Petra Oberhuemer, and Rob Koper

## Motivation, Engagement, Learning Games

### Generating Educational Interactive Stories in Computer Role-Playing Games
Marko Divéky and Mária Bieliková

### CAMera for PLE
Hans-Christian Schmitz, Maren Scheffel, Martin Friedrich, Marco Jahn, Katja Niemann, and Martin Wolpers

### Implementation and Evaluation of a Tool for Setting Goals in Self-regulated Learning with Web Resources
Philipp Scholl, Bastian F. Benz, Doreen Böhnstedt, Christoph Rensing, Bernhard Schmitz, and Ralf Steinmetz

### The Impact of Prompting in Technology-Enhanced Learning as Moderated by Students' Motivation and Metacognitive Skills
Pantelis M. Papadopoulos, Stavros N. Demetriadis, and Ioannis G. Stamelos

### Creating a Natural Environment for Synergy of Disciplines
Evgenia Sendova, Pavel Boytchev, Eliza Stefanova, Nikolina Nikolova, and Eugenia Kovatcheva

## Human Factors and Evaluation

### Informing the Design of Intelligent Support for ELE by Communication Capacity Tapering
Manolis Mavrikis and Sergio Gutierrez-Santos

### Automatic Analysis Assistant for Studies of Computer-Supported Human Interactions
Christophe Courtin and Stéphane Talbot

### Real Walking in Virtual Learning Environments: Beyond the Advantage of Naturalness
Matthias Heintz

### Guiding Learners in Learning Management Systems through Recommendations
Olga C. Santos and Jesus G. Boticario

### Supervising Distant Simulation-Based Practical Work: Environment and Experimentation
Viviane Guéraud, Anne Lejeune, Jean-Michel Adam, Michel Dubois, and Nadine Mandran

## Posters

- Designing Failure to Encourage Success: Productive Failure in a Multi-user Virtual Environment to Solve Complex Problems
- Revisions of the Split-Attention Effect
- Grid Service-Based Benchmarking Tool for Computer Architecture Courses
- Supporting Virtual Reality in an Adaptive Web-Based Learning Environment
- A Model to Manage Learner's Motivation: A Use-Case for an Academic Schooling Intelligent Assistant
- Supporting the Learning Dimension of Knowledge Work
- User-Adaptive Recommendation Techniques in Repositories of Learning Objects: Combining Long-Term and Short-Term Learning Goals
- Great Is the Enemy of Good: Is Perfecting Specific Courses Harmful to Global Curricula Performances?
- Evolution of Professional Ethics Courses from Web Supported Learning towards E-Learning 2.0
- Towards an Ontology for Supporting Communities of Practice of E-Learning "CoPEs": A Conceptual Model

## Table of Contents

- Using Collaborative Techniques in Virtual Learning Communities
  - Francesca Pozzi

- Capturing Individual and Institutional Change: Exploring Horizontal versus Vertical Transitions in Technology-Rich Environments
  - Andreas Gegenfurtner, Markus Nivala, Roger Säljö, and Erno Lehtinen

- A Platform Based on Semantic Web and Web2.0 as Organizational Learning Support
  - Adeline Leblanc and Marie-Hélène Abel

- Erroneous Examples: A Preliminary Investigation into Learning Benefits
  - Dimitra Tsovaltzi, Erica Melis, Bruce M. McLaren, Michael Dietrich, Georgi Goguadze, and Ann-Kristin Meyer

- Towards a Theory of Socio-technical Interactions
  - Ravi K. Vatrapu

- Knowledge Maturing in the Semantic MediaWiki: A Design Study in Career Guidance
  - Nicolas Weber, Karin Schoefegger, Jenny Bimrose, Tobias Ley, Stefanie Lindstaedt, Alan Brown, and Sally-Anne Barnes

- Internet Self-efficacy and Behavior in Integrating the Internet into Instruction: A Study of Vocational High School Teachers in Taiwan
  - Hsiu-Ling Chen

- Computer-Supported WebQuests
  - Furio Belgiorno, Delfina Malandrino, Ilaria Manno, Giuseppina Palmieri, and Vittorio Scarano

- A 3D History Class: A New Perspective for the Use of Computer Based Technology in History Classes
  - Claudio Tosatto and Marco Gribaudo

- Language-Driven, Technology-Enhanced Instructional Systems Design
  - Iván Martínez-Ortiz, José-Luis Sierra, and Baltasar Fernández-Manjón

- The Influence of Coalition Formation on Idea Selection in Dispersed Teams: A Game Theoretic Approach
  - Rory L.L. Sie, Marlies Bitter-Rijpkema, and Peter B. Sloep

- How to Support the Specification of Observation Needs by Instructional Designers: A Learning-Scenario-Centered Approach
  - Boubekeur Zendagui

- Using Third Party Services to Adapt Learning Material: A Case Study with Google Forms
  - Luis de la Fuente Valentín, Abelardo Pardo, and Carlos Delgado Kloos

- Virtual Worlds for Organization Learning and Communities of Practice
  - C. Candace Chou

- A Methodology and Framework for the Semi-automatic Assembly of Learning Objects
  - Katrien Verbert, David Wiley, and Erik Duval

- Search and Composition of Learning Objects in a Visual Environment
  - Amel Bouzeghoub, Marie Buffat, Alda Lopes Gançarski, Claire Lecocq, Abir Benjemaa, Mouna Selmi, and Katherine Maillet

- A Framework to Author Educational Interactions for Geographical Web Applications
  - The Nhan Luong, Thierry Nodenot, Philippe Lopistéguy, and Christophe Marquesuza

- Temporal Online Interactions Using Social Network Analysis
  - Álvaro Figueira

- Context-Aware Combination of Adapted User Profiles for Interchange of Knowledge between Peers
  - Sergio Gutierrez-Santos, Mario Muñoz-Organero, Abelardo Pardo, and Carlos Delgado Kloos

- ReMashed – Recommendations for Mash-Up Personal Learning Environments
  - Hendrik Drachsler, Dries Pecceu, Tanja Arts,

## Making Sense of Sensemaking in the Digital World

Peter Pirolli
Palo Alto Research Center
3333 Coyote Hill Road, Palo Alto, CA, USA
pirolli@parc.com

In this keynote presentation I discuss some of the exciting phenomena and challenges that are emerging as the digital universe evolves to become a more social medium that supports more complex information-seeking and learning activities. This discussion emerges from attempts to extend previous work on Information Foraging Theory [1] to address these new trends in online information-seeking and sensemaking. Information Foraging Theory is a theory of human-information interaction that aims to explain and predict how people will best shape themselves to their information environments, and how information environments can best be shaped to people. The theory has mainly focused on information seeking by the solitary user, but as the Internet and Web have evolved, so too must the theory, and so I will discuss recent studies of sensemaking and the social production, sharing, and use of information in areas such as wikis, social tagging, social network sites, and social search. The opportunity (and challenges) are enormous for developing a scientific foundation to support online groups and communities that are engaged in creating, organizing, and sharing the knowledge produced through social sensemaking.

Sensemaking is a natural kind of human activity in which large amounts of information about a situation or topic are collected and deliberated upon to form an understanding that becomes the basis for problem solving and action. It goes beyond simply finding information. It is also involved in learning about new domains, solving ill-structured problems, acquiring situation awareness, and participating in social exchanges of knowledge. Sensemaking involves collecting, organizing and creating representations of complex information sets, all centered on the formation and support of mental models involved in understanding a problem that needs to be solved. Examples of such problems include understanding a health problem to make a medical decision, understanding the weather to make a forecast, intelligence analysis to identify strategic threats, and the collaborative collection and understanding of an emergency by first responders. Seminal papers on this topic emerged quasi-independently in the fields of human-computer interaction [2], organizational science [3], and macrocognition [4].

Making sense of challenging domains of knowledge using the Internet has become a ubiquitous activity in the digital era. For those who have access, the Internet has become the primary resource for learning about science, technology, health and medicine, and current events [5]. As the information environment has become richer, it has become a place to explore and learn over longer periods of time. The Internet and the Web have also become much more social [6] with a variety of technologies to exploit or enhance social information foraging. The Web, blogs, email, Internet groups, collaborative tagging, wikis, recommender systems, and other technologies are all aimed at supporting cooperative information sharing and their success implies their effectiveness. The utility of such systems typically depends on having large user bases and higher rates of contribution by individuals. With respect to sensemaking, the utility of such sites additionally depends on such factors as how readily people can judge the credibility of the sources and authors of user-generated content, how knowledge produced by one individual transfers to another, and how well specific tools support content learning. In this presentation, I will discuss research addressing some of these needs. I will also discuss some social phenomena that arise from many interacting users including: the effects of diversity and social brokerage, the standing-on-the-shoulders-of-giants effect, the effects of social interference, and the role of user interface interaction costs.

Given the increased ease with which it is possible to study social networks and information flow in the electronic world, it is likely that there will be more studies of the effects of technologies on social structure and social capital, hence a need for a suitable theoretical framework. The efflorescence of online social interaction and collective action raises fundamental questions about the conditions and interaction architectures that shape the social and cognitive machinery of people. We need a theoretical framework that is rich and encompassing enough to provide practical guidance on how to design online communities across the space of possible purposes and activities. The framework must be rich and complex enough to produce integrated models that support (a) decomposition of macroscale phenomena

## Towards an Interdisciplinary Design Science of Learning

Mike Sharples  
University of Nottingham, Jubilee Campus, Wollaton Road  
Nottingham NG8 1BB, UK  
mikesharples@nottingham.ac.uk

In a world of increasing complexity, confronting global environmental and social challenges, there is an urgent need to enable people of all ages to learn about themselves, their society and their environment. Yet, there is a surprising lack of attention to what this involves. The study of human learning does not form a major part of teacher education programmes and is disappearing from university Psychology courses. It is as if human learning is just too diffuse and difficult a topic to be studied and taught.

A central problem with the study of learning is that it is inherently interdisciplinary. Learning as the process of effecting permanent changes to the brain is an aspect of neuroscience; as the acquisition of skills and knowledge, learning forms part of cognitive psychology; as an activity of social and cultural development, it falls under social sciences; as a process of systemic adaptation to societal changes it could be part of history, business or economics. All of these disciplines are essentially descriptive, in that they attempt to understand people and their world. To enable people to learn more effectively also involves the disciplines of design and engineering.

Such complexity has traditionally been simplified, so that researchers can understand or influence one aspect, such as change in behaviour, cognitive development, or the design of teaching machines. The time has now come to put all the pieces together, to form a composite picture of how we learn as individuals, groups and societies, and how to create the conditions for more effective learning, across contexts, throughout a lifetime.

If this seems like a daunting task, then much of the groundwork has been or is being done. In addition to studying facets of learning, we need to develop new methods to integrate this knowledge and to harness it for the benefit of learners and society. The suggestion is to extend educational psychology and learning science research towards a design science of large complex systems. Such an enterprise needs be international, to build on expertise across many research centres. It should be cross-cultural, respecting and celebrating the diversity of settings and approaches to learning. It needs to be design-based if it is to not only describe how learning is currently achieved, but also to develop new methods for enabling and supporting productive learning. It must embrace multiple technologies, including digital media, traditional media and human knowledge, not just as resources for learning, but as integral parts of a complex learning system. It needs to be multi-level and multi-method, seeking to integrate the neural, cognitive, social and cultural aspects of learning. Methods for design and evaluation of human-technology systems, such as socio-cognitive engineering [1], can provide a basis of complex systems design, and these need to be complemented with design-oriented theories of technology-enabled learning.

Some immediate consequences of such an agenda are that this cannot be done be one researcher, or one lab, alone. Just as the Human Genome project required a cooperation of many research labs, a long timescale, a shared infrastructure and ethical framework, and a common set of tools, so the development of an Interdisciplinary Design Science of Learning needs a shared effort to integrate facilities for the co-design of technology-enabled learning and cross-cultural studies of learning effectiveness. Such studies are already underway. For example, the Group Scribbles technology developed at SRI (http://groupscribbles.sri.com/) and the Eduinnnova method from Pontificia Universidad Católica de Chile (http://www.eduinnova.com/english/) are being developed and tested across multiple sites in a worldwide collaboration. The Kaleidoscope and ProLearn networks have already made substantial advances towards forming a cross-national infrastructure and shared understanding for research in technology-enabled learning. The STELLAR network is ideally placed to take on this challenge.

## Reference

1. Sharples, M., Jeffery, N., du Boulay, J.B.H., Teather, D., Teather, B., du Boulay, G.H.: Socio-cognitive engineering: a

## Use and Acquisition of Externalized Knowledge

Friedrich W. Hesse  
Knowledge Media Research Center  
at the University of Tuebingen  
Konrad-Adenauer-Str. 40, 72072 Tuebingen  
f.hesse@iwm-kmrc.de

Knowledge acquisition is no longer mainly restricted to classical institutions and formal learning (as in schools and universities) but is also connected to informal learning settings at home in leisure time or at the workplace. Thus, the interplay between formal and informal learning is developing in a new way, mainly in connection with the development of Web 2.0 and the appearance of "social software". Within these new social software environments different developments are especially interesting, as they offer new ways of learning, knowledge building and use of knowledge. A very special feature has to do with the possibility of externalizing knowledge. Even more, social software (e.g. bookmarking) makes not only externalized knowledge available, but together with the externalized knowledge of other people, resources can be created which are most meaningful for oneself.

For cognitive psychologists and learning researchers, social software offers an interesting new demand for further study. Since the beginning of learning research, one can observe some paradigmatic changes which have had a strong impact on which learning processes have been investigated. In the very beginning, research was interested in the process of learning with regard to the manipulation of observable and measurable behavior, for example in learning by heart by Ebbinghaus [1], in classical conditioning by Pavlov [2] or in the highly influential operant conditioning by Skinner [3]. Around 1960 there was a paradigm shift from "learning" to "knowledge", the so called "cognitive turn" (Neisser [4]). From then on researchers were interested in investigating the internal mental processes, like organization, acquisition, storing and retrieval of knowledge (e.g. Baddeley [5]). This led to a new type of theory and new results. A more recent paradigm shift moved interests from "knowledge" to "externalized knowledge". Wegner [6] introduced the theory of transactional memory, where people don't have to know everything themselves, but can use the knowledge of other people.

Connected to some of the ideas of Wegner, a lot of developments and activities around Web 2.0 in the years from 2000 on allowed researchers to follow his perspective, especially in connection with features like having quick and easy storage of and access to "(externalized) knowledge". However, from a research perspective we only understand partly the nature and mechanism of these activities. They are mostly related to tools which are associated with terms like "Social Networks" and "Social Software Tools". Using a wider scope, such tools can be categorized into at least three groups: those which are primarily concerned with the social exchange between people (like Facebook), those which also address a knowledge exchange (like bookmarking systems) and those which are mainly interested in constructing shared knowledge bases (like Wikipedia).

When we take a closer look at the category "knowledge exchange" and especially at the bookmarking systems, we will discover in detail the potential of this social software tool in taking over processes which normally have to be carried out by ourselves, so that there is a new division of labor between the human cognitive system and the social software tools. How is this possible? The processes behind the bookmarking are mainly based on tags which allow all users to assign keywords individually to information or resources (e.g. picture, website, videos). These tags can help to structure, classify and filter individual collections of information and resources. These resources can – at the same time – be saved and filled in different categories. Thus information storage and retrieval is becoming very easy. But there is still the question, what is "social" in social tagging? On the one hand, the individual tags for respective resources are available for all users. On the other hand, all tags can be created by all other users and then aggregated. For a concrete resource this leads to a common description/classification in a bottom-up process, reflecting important connotations and concepts of the resource. In addition, frequently used tags of a resource are weighted more strongly.

Here's the cleaned Markdown:

## LAG 2.0: Refining a Reusable Adaptation Language and Improving on Its Authoring

Alexandra I. Cristea¹, David Smits², Jon Bevan¹, and Maurice Hendrix¹

¹ Department of Computer Science, University of Warwick, Coventry, CV4 7AL, United Kingdom  
² Faculty of Mathematics and Computer Science, Eindhoven University of Technology, PB 513, 5600MB, Eindhoven, The Netherlands

## Abstract

Reusable adaptation specifications for adaptive behaviour has come to the forefront of adaptive research recently, with EU projects such as GRAPPLE, and PhD research efforts on designing an adaptation language for learning style specification [1]. However, this was not the case five years ago, when an adaptation language for adaptive hypermedia (LAG) was first proposed. This paper describes the general lessons learnt during the last five years in designing, implementing and using an adaptation language, as well as the changes that the language has undergone in order to better fulfil its goal of combining a high level of semantics with simplicity, portability as well as being flexible. Besides discussing these changes based on some sample strategies, this paper also presents a novel authoring environment for the programming-savvy adaptation author, that applies feedback accumulated during various evaluation sessions with the previous set of tools, and its first evaluation with programming experts.

**Keywords**: Adaptive Hypermedia, Adaptation Language, LAG, LAOS.

## 1 Introduction

Adaptation and personalization are considered to be both useful and desirable, and came to the fore with user modelling [2] and adaptive hypermedia [3] research. However, adaptive environments are notoriously difficult to author [4] for. Amongst all the components in adaptive environments, about which much has been modelled and written [5][6][7][8][9][10][1], the most difficult part is the specification (authoring) of the adaptive behaviour [8][12][13][14][1].

Hence, reusability is desirable especially for the adaptive behaviour specification, in the sense of 'write once, use many' [12]. Since 2003-2004 a few adaptation languages have been proposed; LAG [15] is, as far as we know, the first such language, followed by LAG-XLS [16] that caters for Learning Styles. Ideally, a single common accepted standard would be best, similarly to content descriptions in the educational domain (e.g., LOM, SCORM). In the GRAPPLE project, such an endeavour is being targeted. However, this is beyond the scope of the current paper.

Making a language a common standard and reusable is only the first step, the next is to allow different levels of access to the creation process. This targets the different types of authors that will be able to use the language (e.g., computer savvy or not). One such version of different access levels is given by the LAG framework [17]:

- adaptation strategy – accessible for all authors, via laymen-level descriptions
- adaptation language – accessible mainly to computer savvy authors
- adaptation assembly language – only accessible to 'hard core' computer savvy authors

Another dimension is brought about by using visualization (e.g. the Graph Author developed for AHA! [18] is using visualisation in order to support authors) and handling support. In previous versions of the LAG language implementation, handling support was envisioned as not allowing an author to insert any wrong constructs [13][17]. In the GRAPPLE project, additionally to this restriction, the ultimate language to be used by the non programming-savvy author will be purely graphical [20]. Whilst this will hide most of the difficulty for the high-level author, it will also need to reduce the flexibility to some degree.

When major changes are needed, or when system-system interaction is required, underlying programming languages will support this. Currently, we consider supporting multiple adaptation language output as a desirable feature, besides developing new languages targeted at

Here's the cleaned Markdown:

## LAG 2.0: Refining a Reusable Adaptation Language and Improving on Its Authoring

## The Updated LAG Grammar, via Scenarios for Adaptation

### The LAG Grammar History and Lessons Learnt

The LAG language concept was first introduced in [17], together with the LAG framework (hence, the similarity in name between language and framework, although they are distinct entities). As sketched in section 1, the LAG framework distinguishes between adaptation strategy – accessible for all authors, via laymen-level descriptions; adaptation language – accessible mainly to computer savvy authors; an example of such a language is the LAG language, although any adaptation language fits at this level; adaptation assembly language – only accessible to 'hard core' computer savvy authors.

From the moment it has been proposed, the LAG language was supposed to fill in the 'missing link': it had to be and adaptation language, thus at a higher level than what the LAG framework called 'adaptation assembly language': it had to be reusable, whereas adaptation assembly languages at the time were not. To give an example, it was possible then to write:

(a) IF Concept ('The Night Watch') has been visited
THEN show Concept ('Rembrandt')

However, it was not possible to write:

(b) IF Concept (title) has been visited
THEN show Concept (author)

Thus, even such simple generalizations were not easily available to authors, who would have to manually connect all concepts, instead of writing reusable rules.

Brusilovsky's taxonomy [3], used for defining the types of adaptation possible, also refers to such an assembly language level[^4]. Take for instance the decision of showing a concept by stretchtext, versus showing it by regular text; or hiding it by removing, or by graying out. These are decisions which may be dependent on the capabilities of the adaptation and rendering engine. A given engine may allow for showing concepts or not, but not for applying strechtext (e.g., the AHA! engine [18]).

Using such low-level requirements might make an adaptation strategy impossible to be used by different engines. Moreover, such a low-level requirement may have little to do with the pedagogy involved in teaching a course, for instance. A teacher author might decide that a certain piece of information is necessary for a student or not, but may leave the rest to the engine.

Thus, another condition for a language to be an adaptation language was that it had to be able to be converted to lower level assembly language, as per Brusilovsky's taxonomy, but that this exact conversion is to be left to the interpretation and specifics of the given adaptation engine (hence, the similarity with a programming language which is compiled into assembly language in order to run on a certain system). For the example above, any structure (b) as above, applied to a certain domain, could become something similar to (a). However, an adaptation language may not necessarily have IF-THEN constructs, as they themselves are relatively low level.

Still, for compatibility with the engines of the time, the initial LAG language allowed for IF-THEN constructs, corresponding to assembly language constructs. Supplementary, however, it also defined higher level constructs, specific to the adaptation functionality, which are part of the adaptation language level within the LAG framework. Beside this important distinction, and essentially offering an instantiation of adaptation language ideas, it also defined what such a language should have: it should make use of the application domain (adaptive hypermedia) by:

1. allowing it to be simpler and with fewer constructs than a regular programming language or a logic-based language (thus lowering the authoring threshold); Thus, elements were included in LAG only when considered necessary; and by
2. using constructs specific for the adaptive hypermedia domain, or assumptions that can be safely made in that domain. For instance, at the time it was safe to assume that most adaptive hypermedia applications have an underlying tree-like structure (as they were mainly designed for the educational domain, and, to some extent, inherited the organization into chapters

Here's the cleaned and normalized Markdown:

## LAG 2.0: Refining a Reusable Adaptation Language and Improving on Its Authoring

### Domain-Based Adaptation Requirements

iii. domain-concept type-based adaptation: frequently, domain concepts have types (or other attributes). These also can be used in the adaptation process, thus should be accessible via the adaptation language.

### Goal-Related Adaptation Constructs

Adaptive hypermedia goals can be related to the pedagogy involved, if an educational application is envisioned, or to a business goal, in an e-commerce application, for instance. These goals can determine how domain concepts can be used. A simple way of adding such information is via labels and weights overlayed over the domain concepts they refer to. For example, the concept 'The Night Watch' can be labelled 'visual' to be used in a strategy involving visual versus verbal presentation, could be labelled 'advanced' if it is to be used in a drawing and painting class, or 'beginner' if it is to be used in a class on famous paintings and painters. Thus, whilst this information is added to concepts in the domain model, it is independent to the domain. This type of independence between domain and goal (or pedagogic) model was proposed as a basis for adaptation language construction [8] and has found recognition as one of the design concepts in the GRAPPLE project.

i. label-based adaptation: see above.
ii. weight-based adaptation: an alternative to label-based adaptation, numeric values can be used to label concepts with respect to the goal. This alternative is not used very frequently currently.

### Adaptation Program Structure

#### Constructs defining the 'adaptation loop':
Unlike regular procedural programs, the concept-driven adaptation in adaptive hypermedia happens in a loop. Users can visit the same concept several times. It may be that similar, or evolving behaviour is needed at successive visits. Thus, similar to the collection of rules in expert systems, the programming constructs in adaptation languages can be triggered repeatedly, and in different orders. An adaptation language should allow for an 'adaptation loop', that defines the continuous interaction between user and system, and for mechanisms to ensure that the correct constructs are triggered at the correct time.

#### Constructs allowing for an 'entry point':
As adaptive hypermedia content is often based on the Web, it suffers from the same draw-back as regular Web hypermedia: first time users may visit the site. Thus, an adaptation language needs to be able to define what these users will be seeing. This is different from the 'adaptation loop' above, where users already have some history of recorded behaviour in the system[^1]. The most important difference between the 'entry point' and the 'adaptation loop' is that the 'entry point' is a one-off event. Constructs will be executed here only once.

High level language thus means here a language created from an authoring perspective: an author is concerned about how the content, as well as the goal description for the particular application, can be used to model adaptation. The actual particulars of how the adaptation engine searches, retrieves, and renders each of these actions is of lesser relevance to the author, and could potentially add to the authoring complexity[^2].

[^1]: It is possible for this history of recorded behavior to be imported from a different application. In this case, direct entry into the 'adaptation loop' should be enabled.
[^2]: This statement is based on previous evaluation experiments and interviews.

### Hierarchy-Based Constructs for Adaptation

As previously discussed, domain models in adaptive hypermedia often have a hierarchical structure. The generalize-specialize constructs initially proposed in LAG have been replaced with simpler ones, that can be used as attributes of the concept, such as parent, child and level, order (as inspired by XPath[^3], in the spirit of using constructs of accepted standards where possible). The strategy shown below is a depth-first strategy, which shows the concept labelled as 'start' first, then the rest of the content in a depth first

## LAG 2.0: Refining a Reusable Adaptation Language and Improving on Its Authoring

## Relation Based Constructs of Adaptation

Domain models have been presumed to be hierarchical. However, more complex domains can have many types of relationships, next to, or instead of the hierarchical ones. To illustrate the use of related concepts, the LAG language supports a generic 'relatedness' relation between two concepts. Here, only an excerpt of the strategy is shown. The exact meaning of the constructs is given as comments below:

```
// for advanced learners show the related concepts
if enough(GM.Concept.access // if a concept is accessed
    UM.GM.stereotype == adv , 2) // and the concept is labelled as
                                 // 'advanced'
then PM.DM.Concept.Relatedness.Concept.show = true // than show the
                          // concept related to the current concept
```

## Type Based Constructs for Adaptation

Domain concepts are defined in LAG as having attributes, which can have predefined types, or author-created types. Examples of predefined types are: introduction, explanation, conclusion, keywords, text, image, video. These types are intrinsic to the domain, and thus are not changed via the goal model. However, they can be used to guide the adaptation. This implementation only shows 'introduction' concepts and doesn't show the other concepts of type 'conclusion', till the introductions are read.

```
// DESCRIPTION: show first introductions, than conclusions;
initialization(
 while PM.GM.Concept.type != conclusion // make only introductions
  (       PM.GM.Concept.show = true )  // readable
 UM.GM.showall = 0)

implementation ( // if a concept is accessed and it is an introduction:
if enough (PM.GM.Concept.type == introduction  
         UM.GM.Concept.access == true, 2)  
// then increase the showall counter:
then ( UM.GM.showall += 1 )
// if the showall counter is greater than a threshold – here, 3,
// because we had three questions –
// and the type of the current concept is 'conclusion':
 if enough (UM.GM.showall > 3 PM.GM.Concept.type == conclusion, 2)
// then show the current concept:
 then ( PM.GM.Concept.show = true ) )
```

## Weight and Label Based Constructs for Adaptation

This strategy shows concepts based on their weights and labels. The idea in the LAOS framework is that weights and labels are added in a separate layer from the domain map, in the goal and constraints map (GM), where they, for educational applications, represent pedagogic knowledge. Thus, a typical pedagogical division is to label concepts as beginner-intermediate-advanced. Labelling these concepts outside the domain model means that a different labelling is possible for the same domain model concepts, but a different instance of the goal map. Thus, some matrix multiplication concepts can be labelled as beginner concepts for maths students, but as advanced concepts for music students, for instance. The same strategy can be applied to both, as below.

```
implementation ( // count visits for each type of label:
    if UM.GM.Concept.access == true then (
    if (UM.GM.Concept.beenthere == 0) then (
      if (GM.Concept.label == beg) then ( UM.GM.begnum -= 1)
      if (GM.Concept.label == int) then ( UM.GM.intnum -= 1)
      if (GM.Concept.label == adv) then ( UM.GM.advnum -= 1))
    UM.GM.Concept.beenthere += 1
  ) // --------------------------------------------------------
  // Change stereotype beg -> int -> adv when appropriate

Here's the cleaned Markdown:

## LAG 2.0: Refining a Reusable Adaptation Language and Improving on Its Authoring

A more complex condition, such as the one using 'enough' in the type-based adaptation, can look as below. Obviously, the XML format is more verbose and shouldn't be used in direct programming by hand.

```xml
<if>
   <enough number="2">  
       <condition>  
           <attribute> UM.GM.showall </attribute>
           <operator> &gt </operator> <value> 3 </value>
      </condition>
      <condition>
           <attribute> PM.GM.Concept.type </attribute>
           <operator> == </operator> <value> conclusion </value>
      </condition>
   </enough>
   <then>
       <attribute> PM.GM.Concept.show </attribute>
       <operator> = </operator> <value> true </value>
   </then>
</if>
```

## PEAL Environment for Authoring

### The Problem

A previous online editor had been created [15][17] (Fig. 1). It allows insertion of only predefined authoring constructs, thus providing handling help, as mentioned in Section 1 (in Fig.1, left side, the [add statement] link event only allows predefined constructs, such as the generalize construct below; the generalize construct in turn only allows condition insertion, via the [add condition] input; clicking this allows the [attribute][operator][value] construct to appear, which can only be populated by generic concepts, such as the 'UM.Concept.type==expert' on the left side of Fig.1, or by specific concepts – not shown here). Moreover, for the specific concepts, the environment allows direct database access to a domain model and goal and constraints model database, permitting selection of appropriate specific concepts directly from the respective instances. Thus, it provides ample support for the authors, lowering the authoring threshold. Also, in terms of flexibility, it allows definition of both adaptation strategies and adaptation procedures (section 2.1).

However, this environment is not currently up-to-date with the current LAG grammar. Most importantly, the environment does not allow for the separation of the interaction into initialization (what the user sees at the first interaction with the system, when nothing else is known about him) and the interaction part (called 'implementation' in the LAG language; this describes the loop of interaction between the user and the system, and, like a rule list, is triggered as long as the conditions of the rules hold). The environment also does not directly support types of domain concepts, as in section 2.4, relatedness relations, as in section 2.3, and other minor extensions of the LAG language. For instance, the update rule for Fig.1, right side should read: `PM.DM.Concept.exercise_expert.show = true;` thus marking the fact that the 'show' variable (determining if to show or not something to the user) is part of the presentation model (PM), and the 'exercise_expert' is an attribute in of the current concept in the domain model (DM).

Currently, due to the differences in grammar in the old on-line environment and the actual specification, we actually use simple text editors as adaptation language creation environments. However, this has several drawbacks, as for instance, the fact that errors are only spotted at compilation time; that the authors receive no help or support whatsoever whilst editing; that authors themselves need to keep track of the version of the language they use, and thus may be working with a version where some of the programming concepts are obsolete.

### Objectives

Thus, the PEAL development set out with the following objectives:

- Develop an online, AJAX based Programming Environment for the LAG language, based loosely upon the existing online editor, and developed from an existing open source project entitled CodeMirror.
- Save (to database or to files) and export (to file/database)

## LAG 2.0: Refining a Reusable Adaptation Language and Improving on Its Authoring

## Programming Environment for Adaptation Language (PEAL)

The Programming Environment for Adaptation Language (PEAL) is shown in Fig. 1.

![Programming Environment for Adaptation Language (PEAL)](Fig. 2)

The following components have been realized:
- User Access and File Storage
- Basic Template for Strategies
- Strategy Creation Wizard
- Tokenizer/Parser Design
- Reserved Word Storage
- Configuration File
- Production of an CAF file for each strategy

The major focus of this project was to create a parser for the LAG language which would recognise and colour correct syntax and grammar, and highlight incorrect syntax and grammar. This is a different take than previously of providing handling help, better known to the programmer communities: language constructs are identified and coloured respectively. In case the construct cannot be identified, the colour is bright red, signalling an error. The storage system with which the strategy document structure is stored has been provided by the CodeMirror system in the form of a simplified DOM structure, so we have been working from that basis when designing grammar recognition.

A detailed design of the user access and file storage system, including the database design to hold user details, a security system to ensure that passwords cannot be obtained and files cannot be accessed by any unauthorised users has been set up.

We have also designed a method by which errors in the code can be easily highlighted. This may be further developed by supplying messages for the user by which they can more easily determine the problem. Currently the design for Reserved Words in the LAG language requires their storage in the parser and tokenizer. However, for greater extensibility, we will design a method using the Object-Orientation techniques provided by Javascript to store keywords externally to the parser and tokenizer in their own 'class'.

Moreover, we have implemented:
- Predictive Word Completion
- MOT2AHA Integration Support
- Drag-and-Drop Coding

Predictive Word completion will be used in the wizard and also the editor.

## PEAL Evaluation

PEAL was evaluated on a small scale, with the help of five programming-savvy persons, as they represent the type of author at which this tool is targeted at. Non-programmers are supposed to be using ready-made, reusable strategies, without getting into the details of programming. Nielsen [22] showed that 95% of the usability problems can be detected with just five users.

Users were asked to identify the strengths and weaknesses of PEAL. Amongst strengths, the following were mentioned:
- "element suggestion and possible variables"
- "syntax highlighting"
- "Coloured keywords"
- "Simple screen"
- "Use of other strategies"
- "completion suggestions"
- "code highlighting and indentation"
- "save and reuse code fragments"
- "highlighting and word completion"
- "reusable code snippets"

Amongst weaknesses, the following were mentioned:
- "Sometimes lines of code jump - automatically indented when the cursor moves"
- "No search function (or search and replace)"
- "If there are multiple errors only one is displayed in the status bar"
- "Some display-size bugs exist with text entry box"

The programmers were also asked to state which editor they would prefer to use to edit the LAG language, between regular text editors (used previously for editing the language) and PEAL. Without exception, they all voted for PEAL. These initial evaluations highlight the usability of PEAL, the fact that such an environment is needed, as well as immediately pointed to some bugs that are to be fixed in the near future.

## Related Work

The level of abstraction of semantics we envision in our work, that can lead to reuse of the adaptation strategies, is expressed in our paper via an adaptation language. An alternative to this is to express such sequences and interaction via workflow languages[^1]. However, workflow languages have previously been shown to be insufficient to express personalization at a level of expression

Here's the cleaned and normalized Markdown:

## LAG 2.0: Refining a Reusable Adaptation Language and Improving on Its Authoring

A popular current growing competitor to adaptation languages and adaptive hypermedia expressivity is IMS-LD[^17]. Research has shown however that IMS-LD is still not yet capable of delivering all adaptation functionality as defined by adaptation hypermedia [1], [10], and also has serious limitations when it comes to adaptively supporting collaborative learning [13].

The main question is how this contribution can be beneficial for other members of the community since LAG introduces various restrictions stemming from the assumptions on how several models need to be structured. Logic based languages or meta-modelling seems to offer a bit more flexible option for doing this.

Other approaches, such as other adaptation languages exist (see, e.g., LAG-XLS [16]). The later language caters for learning styles, but it would need further extensions to cater for more extensive personalization as well as collaborative aspects.

Adaptation languages are based on the rule-based approach. Alternatively, reasoning mechanisms can be used to express the adaptive behaviour (e.g., description logic). Currently, logic-based languages are too broad, with a multitude of constructs that are not of use in current adaptive hypermedia, thus contradicting the first constraint as in section 2.1. The new developments in the Semantic Web offer new vehicles for reasoning such as RDF, OWL[^18] (used also by adaptive learning systems, such as the Personal Reader [19]). They may provide viable alternatives for the future, but currently systems based on such mechanisms have serious performance problems when compared to other rule-based systems. Furthermore, whereas such approaches are very good in expressing modelling information, interrelations, etc., they lack direct and simple support for programmatic constructs required to express most of the behaviours we have discussed in this paper.

Meta-modeling, the process of designing languages through meta and meta-meta notations, such as DTD (document type definition) on top of XML, etc. are useful approaches for describing the domain content, and the different overlay structures (such as the goal structure). They are less useful however for defining adaptation.

Yet another direction of adaptation representation is the family of "assembly-level" adaptation languages, such as used in systems as AHA! [18], Interbook (Word-document-based) [25], WHURLE (LP: lesson plan) [25]. The problem with such languages is that, not only do they lack many of the required features as outlined in previous sections, but they are also extremely verbose and difficult for non-experts as well as experts alike to express high-level, reusable adaptation strategies in, rendering them a questionable choice for employing as the basis of adaptive specifications They may, nevertheless, serve as an appropriate "end-of-line representation", in essence serving as a possible "output format" for higher level languages such as LAG. The same is true for specifications such as IMS LD already mentioned above.

Our approach is also related to Pattern languages [1]: extracting snippets of adaptive behaviour (here, for collaborative adaptation) that are to be reused in different context (e.g., by different learners, teachers; groups of learners or teachers; with different course materials, etc.).

## Conclusion and Future Work

In this paper, we have described the current developments of the LAG adaptation language, one of the first adaptation languages, discussed in the context of use and application of adaptation languages in general. We have sketched also an XML equivalent of LAG, which can be used for enhanced portability. Moreover, we have shown current progress in the design, implementation and small-scale evaluation of PEAL, a new environment for LAG language specification, which builds upon lessons learnt from previous implementations.

Other Lessons learnt, which can be of use to the research community at large, and connected to future work are as follows:

1. Authors expect the authoring environment to be online, same as their environments for domain and other static map editing; they do not expect to have to install systems on their own computer. This is

Here's the cleaned Markdown:

## LAG 2.0: Refining a Reusable Adaptation Language and Improving on Its Authoring

## References
1. Brusilovsky, P.: Developing adaptive educational hypermedia systems: From design models to authoring tools. In: Murray, T., et al. (eds.) Authoring Tools for Advanced Technology Learning Environment, pp. 377-409. Kluwer Acad. Publishers, Dordrecht (2003)
2. Berlanga, A., et al.: Modelling adaptive navigation support techniques using the IMS learning design specification, Hypertext, Salzburg, Austria, pp. 148-150 (2005)
3. Cannataro, M., et al.: Modeling Adaptive Hypermedia with an Object-Oriented Approach and XML. In: Proc. of WebDyn 2002, Honolulu, Hawaii (May 2002)
4. Ceri, S., et al.: Web Modeling Language (WebML): a modeling language for designing Web sites. Computer Networks 33(1-6), 137-157 (2000)
5. Cristea, A., De Mooij, A.: LAOS: Layered WWW AHS Authoring Model and their corresponding Algebraic Operators. In: WWW 2003, Budapest, Hungary (2003)
6. Koch, N., Wirsing, M.: Software Engineering for Adaptive Hypermedia Applications? In: AH workshop at UM 2001, Sonthofen, Germany, July 13-17 (2001)
7. Specht, M., Burgos, D.: Modeling Adaptive Educational Methods with IMS Learning Design. Journal of Interactive Media in Education (2007)
8. Cristea, A.I., et al.: Towards a generic adaptive hypermedia platform: a conversion case study. J. of Digital Info. (JoDI), Spec. Iss. on Personalis. of Comp. & Services 8(3) (2007)
9. Cristea, A.I.C., Stewart, C.D.: Automatic Authoring of Adaptive Educational Hypermedia. In: Ma, Z. (ed.) Web-based Intelligent E-Learning Systems: Technologies and Applications, pp. 24-55. Info. Science Publishing (IDEA group) (2006)
10. Ohene-Djan, J.: A Formal Approach to Personalisable, Adaptive Hyperlink-Based Interaction. PhD thesis, Dept. of Computing, Goldsmiths College, Univ. of London (2000)
11. Stash, N., et al.: Adaptation languages as vehicles of explicit intelligence in Adaptive Hypermedia. IJCEEL journal 17(4/5), 319-336 (2007)
12. Cristea, A.I., Verschoor, M.: The LAG Grammar for Authoring the Adaptive Web. In: ITCC 2004, Las Vegas, US. IEEE, Los Alamitos (2004)
13. Stash, N., et al.: Adaptation to Learning Styles in E-Learning: Approach Evaluation. In: Proceedings of E-Learn 2006 Conference, Honolulu, Hawaii (2006)
14. Cristea, A.I., Calvi, L.: The three Layers of Adaptation Granularity. In: Brusilovsky, P., Corbett, A.T., de Rosis, F. (eds.) UM 2003. LNCS, vol. 2702. Springer, Heidelberg (2003)
15. De Bra, P., et al.: The Design of AHA! In: Proceedings of the ACM Hypertext Conference, Odense, Denmark, August 23-25, p. 133

Here's the cleaned Markdown:

## The Conceptual and Architectural Design of a System

The students will be undertaking exploratory rather than structured tasks, teachers need to be assisted in monitoring students' activities and progress by appropriate visualization and notification tools. These will assist the teacher in focusing her attention across the class and will inform her own interventions to support students in reflecting on their constructions, on the system's feedback, in setting and working towards goals, and in communicating and working with others [9].

Designing, developing and evaluating a system such as this poses both pedagogical and technical challenges, demanding an interdisciplinary approach. The MiGen project team comprises researchers from the mathematics education, AI in Education, and computer science disciplines. The pedagogical and technical challenges that we are currently addressing in the project are:

1. Understanding and modeling the mathematics generalisation domain, the tasks to be undertaken by learners and the learners themselves
2. Identifying the information about learners' constructions that needs to be captured in order to underpin the provision of effective feedback by the system to learners and to the teacher
3. Designing the feedback for the learner, and trialling and deploying appropriate intelligent techniques to generate such feedback
4. Similarly, investigating, trialling and deploying appropriate visualisation techniques for the presentation of feedback to the teacher
5. Designing and developing an extensible, scalable client-server architecture which will support multiple concurrent users (students and teachers) in a classroom setting, and will readily allow the incremental development and evaluation of the various components of our system during the course of the MiGen project, and beyond.

This paper focuses primarily on (v), including also some aspects of (i) and (iv). We refer the reader to [10,11] for discussion of possible techniques underpinning (iii), and to [9] for discussions of (i) and (ii). This paper is structured as follows. Section 2 sets the scene by giving an overview of the envisaged context and functionalities of the MiGen system. Section 3 discusses the Conceptual Model of the system and the methodology we have adopted in developing this. Section 4 presents our overall system architecture, which aims to encompass the system functionalities presented in Section 2 while also meeting the necessary requirements in respect of extensibility, performance and easy installation within schools. Section 5 gives technical details of an architectural proof-of-concept prototype, motivating the technologies and approaches chosen to implement the necessary functionality. We also discuss how this prototype will be used in the coming months as the basis for developing the first full version of the MiGen system. We give our concluding remarks in Section 6.

## The MiGen System Context and Functionalities

The MiGen system will be deployed in classrooms within schools. During a lesson, students will be working on mathematics generalisation problems as selected by their teacher and presented to them by the system. Students may be working (individually or in groups) on different variants of the same problem or on different problems. During the lesson, the teacher may wish to view real-time representations of the students' activities and progress. At other times, teachers may also wish to access historical information about their students' activities and progress as maintained by the system.

The MiGen system will comprise a number of tools:

1. An Activity Design and Activity Management Tool. This supports the visual design, storage and enactment of activity sequences targeting maths generalisation. These activity sequences typically include phases such as: introduction to a task; undertaking a task (using the eXpresser tool — see below); reflecting on a task; and discussing constructions with other students (using the Discussion Tool — see below). We are considering using the LAMS system² to provide this kind of functionality (excluding the construction and discussion functionality provided by the eXpresser and Discussion Tool). Currently, activity sequences are being designed by members of the research team. In the longer term, we expect that teachers will reorganise existing activities and create new ones.

2. The eXpresser. This is a mathematical microworld [12,13] supporting students in undertaking maths generalisation tasks which have been specified using the

Here's the cleaned Markdown:

## The Conceptual and Architectural Design of a System

## Figure 1
(a)–(b) Instances of an example pattern and (c)–(g) several possible general constructions where each expression specifies the number of green tiles in terms of b, the number of blue tiles:

- (c) 5b + 3
- (d) 3 + 5b
- (e) 2(2b + 1) + b + 1
- (f) 3(b + 1) + 2b
- (g) 6 + 2(2b − 1) + b − 1

## System Components

### The eGeneraliser
This is a suite of intelligent components which take as their input information from the eXpresser as students are undertaking tasks, as well as information stored in the MiGen database relating to students (their learner model) and to tasks. These components generate real-time feedback for students and update their learner model attributes as appropriate. The eGeneraliser will provide different types of feedback, e.g. prompts to help students start a task, identify errors in their solutions, generalise their solutions, seek help from the teacher, etc. Information about what feedback has been given to each student will be stored within the MiGen database (in the Feedback Log). This will be used by the Teacher Assistance Tools to allow the teacher to see how the system is interacting with her students (as well as for analysis purposes by the research team).

### The Teacher Assistance Tools
This is a suite of tools aiming to assist the teacher in monitoring students' activities and progress, and intervening with additional support for students as she decides appropriate. In the first instance, these tools comprise a Classroom Dynamics (CD) Tool and a Student Tracking (ST) Tool. The CD tool will provide a visual overview of students' locations in the classroom and their progress with respect to ongoing tasks so that the teacher can view different facets of their activities and use this to inform her choice of interventions within the classroom. The teacher will be able to select from a range of information to visualise, some of which will be derived from the eXpresser Session Log and some from the Feedback Log and Learner Model data generated by the eGeneraliser.

## The MiGen Conceptual Model

As stated in Section 1, the pedagogical and technical challenges posed in designing, developing and evaluating a system such as MiGen necessitates an interdisciplinary approach. An iterative methodology has been adopted on the project, comprising successive cycles of:

1. pedagogical and technical research
2. requirements elicitation within the domains of mathematics generalisation and intelligent support
3. requirements analysis and specification in collaboration with students, teachers and teacher educators
4. development of activity sequences and tasks to underpin evaluation of the technical deliverables
5. development (design, implementation and testing) of technical deliverables
6. evaluation of the technical and pedagogical environment, both within the research team and with groups of students and their teachers
7. analysis of evaluation results, elicitation of pedagogical and technical outcomes, and planning of the next cycle

### Users and Learner Models
Figure 2 shows the entities relating users and learner models and the relationships between them. There are three types of user of the MiGen system: student, teacher and researcher. For each task undertaken by a student, the eGeneraliser maintains information within a TaskShortTermModel on the student's ongoing progress through the task.

Here's the cleaned Markdown:

## The Conceptual and Architectural Design of a System

## Students' Constructions and Learner Models

The TaskShortTermModel is subsequently used (by the eGeneraliser) to derive a longer-term model of the student's strategies and outcomes in relation to this task — the TaskLongTermModel. This, in turn, is used to derive a model of the learner's general understanding of the domain of mathematical generalisation (their DomainLongTermModel). This links with the overall DomainModel of the MiGen system (there is only one instance of this entity) which includes concepts such as 'constants', 'variables', 'constructions' and 'expressions'. (Thus, a student's "learner model" consists of their TaskShortTermModels, TaskLongTermModels and DomainLongTermModel).

In interacting with the eXpresser, the student generates a sequence of StudentActions, arising from creating patterns and changing the attributes of patterns. This data is used by the eGeneraliser to derive and update the student's TaskShortTermModel (introduced above), and StudentActions contribute to the student's overall solution to the task (the TaskStudentSolution). Solutions may include TaskExpressions, which are part of the task specification and require the learner to answer algebraic questions about their constructions.

During the task, the learner implicitly transitions through a number of TaskStates as they create and manipulate their construction. Examples of task states are: 'student is currently constructing a specific instance of the pattern', 'student is currently constructing a general solution' and 'student is creating an algebraic expression'.

## Tasks, Activities, Learning Objectives, and Landmarks

Each ExpresserTask is a member of a TaskFamily, which is a conceptual grouping of tasks along various dimensions, such as the number of variables students need to create for the task, and the nature of the algebraic rule. TaskFamilies are addressed by ActivitySequences, each of which consists of a number of ExpresserTasks that the learner progressively works through. Both ExpresserTasks and ActivitySequences have LearningObjectives associated with them. LearningObjectives are expressed in student-oriented language, and each of them is related to a corresponding TeachingObjective.

LearningObjectives of tasks and activity sequences correspond to system-specified EpistemicObjectives which capture objectives in the domain of mathematical generalisation, e.g. 'appreciation of the use of variables'. OperationalisedObjectives (also system-specified) serve to contextualise EpistemicObjectives in the context of the MiGen system. For example, an OperationalisedObjective such as 'can use a variable to create a link between two patterns' would contribute to the EpistemicObjective 'appreciation of the use of variables'. PragmaticObjectives correspond to affordances of the eXpresser that are independent of any epistemic basis, e.g. 'can drag a tile onto the screen'. Both OperationalisedObjectives and PragmaticObjectives can be pre-requisites for OperationalisedObjectives.

As a student constructs a solution, the eGeneraliser may infer and create InferredLandmark entities, which indicate events such as the student starting to construct generally rather than specifically. The student's actions may also generate landmark entities — ExplicitLandmarks — as a result of completing or highlighting points in their construction process that they may wish to reflect on later, or to discuss with their peers or teacher. Both these types of landmarks provide evidence for OperationalisedObjectives and PragmaticObjectives, as well as for LearnerInconsistencies — these are system-specified stumbling blocks, e.g. using more variables than needed.

## The MiGen System Architecture

The MiGen system architecture has been iteratively designed from ongoing identification and specification of the tools that will comprise the system and of the context of how the system will be

Here's the cleaned Markdown:

## Architectural Proof-of-Concept

We now present a proof-of-concept implementation of the above architecture which focuses on the communication between the client-side components and the server-side components. It constitutes a significant first step towards building the infrastructure to support the first full version of the MiGen system in the coming months.

The context of usage of the system is very specific: the system will be deployed in schools. During the lifetime of the project, we anticipate running a single server instance within our university's IT infrastructure, facilitating data gathering and iterative development. Once the project has finished, however, we intend to provide the system to schools so that they can run it locally within their own IT infrastructure since sustainability is an important project aim. These considerations constrain the server-client architecture in a number of ways. Perhaps the most serious constraint is that there is often not sufficient technical administrative support within schools. Indeed many system administrators are teachers with a technical background who have volunteered for the role. Regardless, they are typically very reluctant to expose the school systems to any more risks than are strictly necessary. This is a potential issue both when running the server centrally since it would not be feasible to open up a new 'MiGen Server' port within school firewalls, as well as when the schools later run the servers locally since provision of technical support, complex server installation and/or maintenance would be highly problematic. These considerations serve to preclude possibilities such as Glassfish and other J2EE-based application servers, as well as servlet containers such as Tomcat and JBoss; the networking architecture needs to be lightweight using a port that is already open.

In view of these constraints, a simple solution would therefore be a lightweight server-client technology that works over HTTP. An obvious candidate is RPC over XML or SOAP. However, a compelling alternative is to build an architecture based on Representational State Transfer (REST) [17]. REST has many advantages over RPC-based approaches: it is (more) cacheable and scalable and is also easier to performance-tune and debug. Within a RESTful architecture, all data resources within the system can be made available at their own unique URL. In the context of our system, this has the additional advantage that students would be able to make a construction publicly available at its URL. This would then be accessible not only within the MiGen system but also using standard web browsers (with suitable content negotiation) thus allowing, for example, the student's parents to view the work. Given these advantages, we have chosen to use Restlet, a lightweight Java REST framework.

### Implementation Overview

The aim of our proof-of-concept implementation is to design and develop sufficient server-client infrastructure so as to demonstrate that it can fulfil the requirements of the architecture of Fig. 5. At this stage therefore, the intention is not to have a complete architecture, and the following discussion of the proof-of-concept implementation focuses on the core of the necessary functionality.

Our prototype implements a simple server-client architecture where each client can post textual messages to the server. Fig. 6 provides a UML class diagram showing the salient server-side classes which utilise Restlet. The server-side functionality of the prototype is managed by an instance of the ServerApplication class which consists of a set of AbstractRestlets. An AbstractRestlet provides some convenience functionality for calling the appropriate abstract Java method given the HTTP request method. For the purpose of our prototype, only GET and POST request methods are handled, calling getRepresentation() and addRepresentation() respectively. The ClientsRestlet manages the data resource located at /clients, which lists the clients using the system. The MessagesRestlet manages the data resource located at /clients/{id}/messages, where id corresponds to the (numeric) id of an existing client; this lists the current set of messages for the given client (GET) and allows posting of new messages (POST). Finally, the RegisterRestlet provides a mechanism for each client to register their own server location to facilitate server-initiated client communication. The DataModel class manages and provides access to the underlying data of the prototype.

The UML class diagram for the core

Here's the cleaned Markdown:

## UML Diagrams and System Architecture

Figure 7 presents a UML class diagram of the core client-side architecture.

Figure 8 presents a UML sequence diagram illustrating the interaction between the client-side and server-side classes. When the MessagesRestlet is first created by the server, it attaches itself as a listener to events coming from the DataModel (message 1). When the client initialises, it creates its ClientServer (2) which registers with the RegisterRestlet (3) which in turn stores the location of the client server for the particular client (4). The client then creates ResourceListManager (5) and uses it to obtain a ResourceList (6, 7). This concludes the initialisation messages; the remaining messages within the diagram illustrate interaction that happens at various points in response to client activity. 

In this example, this activity consists of the client posting a new message (8) to the MessagesRestlet. The restlet in turn posts the message to the underlying DataModel (9) which notifies the MessageRestlet's listener (10). In response to this event, the MessagesRestlet asks the DataModel to notify all connected clients that its representation has now changed (11). The client's server is subsequently notified (12) and requests an update to the appropriate ResourceList using the ResourceListManager (13, 14). At this stage, the client's ResourceList has not been updated; all that has happened is that the server has notified the ResourceList that it must re-check with the server to find out the latest state of its data resource. It therefore asks the MessagesRestlet for the latest representation of its data resource (15). The MessagesRestlet contacts the DataModel (16) in order to obtain the updated data resource content (17). This is returned as plain text which is subsequently parsed by the ResourceList (18). The ResourceList then determines which elements have been added or deleted from the list, synchronising with the version of the list held on the server. In this example, a single element has been added so the client is notified appropriately (19).

This demonstrates how a client is able to post new information and receive updates to the existing information in real time. The example shows how a client posting new information only sees it once the server has been notified (which in turn then notifies other clients as illustrated). In the full system, infrastructure will be further developed so that the client will be able to function to some extent without assuming the presence of the server. This will allow local manipulation of a ResourceList directly, synchronising in the background with the server as and when it is available.

It is important to note here that — consistent with RESTful principles — it is the client not the server that is responsible for calculating the difference between the server data resource content and the content of its own local copy; the server maintains no client state. This necessarily places a higher computational load on the client but leads to a scalable architecture: computational power increases with the number of clients. As implemented in this prototype, comparison of a server data resource with a local copy requires bandwidth proportional to the size of the data resource since each time a client is notified of changes, it downloads the entire resource. This scalability issue can be mitigated RESTfully by providing query-able data resources on the server that return the sequence of changes applied to the resource from a certain time onwards. Clients can maintain the timestamp of their last synchronisation and access this data resource as required, thus reducing network load as well as the synchronisation effort. Moreover, in the context of the MiGen system, the data resources that are necessary to support the CD/ST and eGeneraliser clients will be relatively small (of the order of 1-100K).

## Realising the MiGen System Architecture

It is now possible to illustrate how the various components presented in Section 4 can communicate using the infrastructure described above. Figure 9 begins with a student manipulating their constructions and expressions within their eXpresser User Interface, which updates the data structures managed by the corresponding eXpresser Information Layer (1). This posts these events to the MiGen server (2),

Here's the cleaned Markdown:

## The Conceptual and Architectural Design of a System

### System Sequence and Interface

Figure 9 shows the system sequence diagram. The student (by creating a ResourceList pointing at the appropriate URL), is then notified, updating its corresponding user interface as appropriate.

Figure 10 shows two functional representations for the CD/ST User Interface which have been implemented as part of our proof-of-concept. Figure 10a shows a CD representation based on a layout of the classroom in which the position of each student is shown, and each student is accompanied by a 'traffic light' graphic indicating the status of some aspect of their learner model, as selected by the teacher to view. In this example, it may be the TaskShortTermModel attribute 'is the student on-task?', which can take one of three values — yes/no/maybe; these values are visualised as red for 'no', green for 'yes' and amber for 'maybe' (the latter indicating uncertainty on the part of the system).

Figure 10b provides an informationally-richer ST representation which displays the progress of a set of students with respect to a set of landmarks, as selected by the teacher. Both of these representations update in real-time in response to information posted to the DataModel via the clients. For the purposes of the prototype, the representations are based on messages that clients submit. Despite our prototype not yet encompassing the functionality of the eGeneraliser and MiGen Data Server, the communication mechanism will be identical with these components in place.

Our prototype provides crucial functionality required by the architectural design of the MiGen system: implementing the 'data accessor' API using Restlet and the ResourceList infrastructure. Following on from the development of this prototype, the next steps are to extend the Restlet-based architecture so as to implement the full server-client architecture of the MiGen system. This will involve determining the overall set of data resources that will be required, designing and implementing the underlying MiGen database and implementing the various tools' servers. This will be followed by integration of the existing eXpresser UI and Information Layer with the eXpresser server, and development and integration of the other UIs and Information Layers.

### Conclusions

We have described the conceptual modelling and architectural design of the MiGen system, which aims to support 11–14-year-old students' learning of mathematical generalisation. MiGen is aiming to provide students with personalised feedback based on their recent actions rather than just on their knowledge levels, aiming to balance students' freedom to explore and discover with sufficient support to foster progressive building of knowledge. Teachers will be assisted in monitoring their students' activities and progress by appropriate visualisation and notification tools, in order to support the teacher in focussing her attention across the class and in formulating her interventions.

The Conceptual Model presented in Section 3 has been derived after a considerable requirements elicitation effort and represents a significant step towards the development of a common vocabulary and understanding for the multiple disciplines engaged in the MiGen project. It also underpins the ongoing logical design of the MiGen database. The System Architecture presented in Section 4 is simple, modular and scalable, aiming to meet the project's objectives of incremental development and evaluation of the various tools of the system, and also easy deployment in schools. In Section 5 we described a working proof-of-concept implementation of the architecture and we discussed how this prototype will be extended in order to implement the first full version of the MiGen system. In the coming months, the project team will continue with iterative design, development and evaluation of the various tools of the system, continuing to follow the methodology outlined in Section 3 and aiming for the first full system evaluation to take place in Autumn 2009 with groups of students and their teachers.

### Acknowledgements

The MiGen project is funded by the ESRC/EPSRC Technology-Enhanced Learning programme (RES-139-25-0381). We thank the other members of the MiGen team for our ongoing collaborative research on the project and for many stimulating

Here's the cleaned Markdown:

## References

1. Geraniou, E., Mavrikis, M., Noss, R., Hoyles, C.: A learning environment to support mathematical generalisation in the classroom. In: Proceedings of CERME 6, Lyon, France (2009)

2. Lesh, R., Kelly, A.E.: A constructivist model for redesigning AI tutors in mathematics. In: Laborde, J. (ed.) Intelligent learning environments: The case of geometry. Springer, New York (1996)

3. Kynigos, C.: Insights into pupils' and teachers' activities in pupil-controlled problem-solving situations. In: Information Technology and Mathematics Problem Solving: Research in Contexts of Practice, pp. 219-238. Springer, Heidelberg (1992)

4. Hoyles, C., Sutherland, R.: Logo Mathematics in the Classroom. Routledge, New York (1989)

5. Kirscher, P., Sweller, J., Clark, R.E.: Why minimal guidance during instruction does not work: An analysis of the failure of constructivist, discovery, problem-based, experiental and inquiry-based learning. Educational Psychologist 41(2), 75-86 (2006)

[References 6-17 continue...]

## Experience Structuring Factors Affecting Learning in Family Visits to Museums

### Authors
Marek Hatala, Karen Tanenbaum, Ron Wakkary, Kevin Muise, Bardia Mohabbati, Greg Corness, Jim Budd, and Tom Loughin

Simon Fraser University, Canada  
Emily Carr University of Art and Design, Canada

### Abstract
This paper describes the design and evaluation of an adaptive museum guide for families. In the Kurio system, a mixture of embedded and tangible technology imbues the museum space with additional support for learning and interaction, accessible via tangible user interfaces. Families engage in an educational game where family members are assigned individual challenges and their progress is monitored and coordinated by the family member with a PDA. After each round of challenges, the family returns to a tabletop display to review their progress. In this paper we present the overall evaluation result of Kurio and, using the model discovery approach, we determine which experience structuring factors have a substantial influence on the learning experience.

### Introduction
The Kurio system facilitates social interaction in the museum by giving museum visitors personalized tasks and unique tangible user interfaces that they use in coordination with other family members to complete group activities. A mixture of embedded and tangible technology as part of an educational game facilitates novel learning and interaction opportunities in the museum space. By modeling both individuals and the group, an adaptive reasoning engine attempts to intelligently guide the flow of the visit to suit members on a personal as well as aggregate level. The main goal of the system is to select tasks for the individual family members that are the most appropriate for their knowledge level and will contribute the most to their experience and learning about the museum.

The Kurio system extends our own prior research on the use of adaptivity and tangible user interfaces within a museum environment in a project known as ec(h)o. Museums and cultural heritage spaces have provided fertile ground for a number of projects investigating how to engage people with electronic guides or audio tours aimed at augmented information retrieval, novel museum visit interactions, and new approaches to learning in museums.

## Experience Structuring Factors Affecting Learning in Family Visits to Museums

## Learning in the Museum

Family groups comprise more than half of all visitors to museums [3]. One common interaction pattern is that in many groups, individual members will go off to explore the museum on their own for periods of time, and then return to the group and share what they have found [3]. This return-and-share strategy is frequently enacted by younger family members exploring and then coming back to talk with a member of an older generation. Several studies have noted that parents tend to informally take on the role of a teacher within the museum, guiding the learning of the children in the group, often in subtle, almost unnoticeable ways. Hilke's 1989 study of family behavior in the museum revealed that children and adults alike spent a lot of time exploring their own interests, with children taking the lead slightly more than adults [4]. In another study, discussion with adult family members revealed that they often cited their children as a reason for spending time in the museum [5]. However, Hilke's study showed that if parents do undertake a teaching role for their children, they do it "with such subtlety that the spontaneous pursuit of individual agendas to learn and share was not visibly disrupted" [4]. Woodruff et al. in their study of the use of an electronic guidebook, noted that dyads of parent-child tended to share a guide, whereas adult dyads took individual guides. In the parent-child groups, the children controlled the guide and made the choices for the most part, with the parents looking on and offering suggestions [6].

Some recent museum systems have taken this group dynamic into account and created guides that are meant to be shared. The Sotto Voce system by Aoki et al [7] is one of the first museum guide system to actively support group interaction. Sotto Voce contains an audio sharing application called eavesdropping that allows paired visitors to share audio information related to the exhibit with each other via PDA devices. This system allows for open-ended interaction, as visitors are free to follow whatever path they like and share as little or as much as they want to. The CoCicero project implemented in the Marble Museum in Carrera [8] is a group guide system which introduces a goal state that encourages group interaction. The visit is structured through a series of games, including multiple-choice questions that require visitors to gather clues from the exhibits within the museum. Each member of the group has a personal digital assistant (PDA) on which they can complete individual games or answer questions that contribute to the completion of a shared puzzle. There are also stationary large displays in the space, which can be shared by more than one person instead of using the PDAs. A final example of a museum system addressing the issue of social interaction is the ARCHIE system at the Gallo-Romano Museum in Belgium [9]. ARCHIE is a PDA-based trading game that invites small groups to play a game that helps them learn about social differentiation and exchange in West Europe around the year 825 BC. Within each group, one person is designated as the "leader" and the others are "farmers". By exploring the museum and answering multiple choice questions, the farmers earn resources like cattle and sheep while the leader attempts to balance goods across the farmers and trade for other resources. Each of these systems encourages the kind of group interaction that can support the natural learning behaviors of families in the museum.

## User Modeling for Groups

While the systems described above encourage family members to interact and share information, none include any sort of adaptive component to tailor the situation to a particular group. Many individual guide systems have intelligent components containing user models which can adapt the system's responses to suit the user better, allowing them to accomplish their task more efficiently, steering them in the right direction if they are unsure how to proceed, or recommending things that the user is likely to want or need based on past experience. To do this, the system might extract assumptions about the user that are not explicit in the individual's own data or use the data to make predictions about the user's likely preferences or future actions. This task becomes even more difficult when dealing with one user

## Experience Structuring Factors Affecting Learning in Family Visits to Museums

## The Kurio System

In Kurio, a family imagines themselves as time travelers from the future whose time map is broken, stranding them in the present. Family members complete a series of challenges that encourage them to learn certain concepts from the museum in order to fix the map and continue their time travels. The interactive guide itself is comprised of a tangible user interface that is distributed over several tangibles with different functions, a tabletop display, and a PDA. A constructivist-learning model was used to guide decisions for the interaction, user model, and system content. A discussion of the design strategies used in developing the system can be found in [14].

### Technical Details

The Kurio system has four main components: the handheld tangibles, a tabletop system, a PDA, and a server containing the reasoning engine. Fig. 1 shows the information that is exchanged between all of these parts of the system. The tangibles, PDA and table system all communicate wirelessly with the server using an XML-based message exchange protocol.

![The information flow between Kurio system components](Fig. 1.)

The tangible user interfaces or tangibles are custom designed devices with shells produced on a 3D printer. Inside the shells, the processing is done on a Gumstix prototyping board programmed in Python and running a Linux OS and a Mini-Arduino using the Arduino programming language. Multi-colored light emitting diodes (LEDs) were used for confirmation and feedback to the user. The tangibles identified objects in two ways depending on the device. The pointer, listener, and finder used infra-red (IR) sensors that detected IR beacons placed next to museum artifacts. The reader incorporated an embedded radio frequency identification (RFID) reader that read RFID tags we encased in a small icon that was fastened to the didactics in the museum.

The monitor was an HP iPAQ running MS Windows Mobile 5.0. The tabletop display was designed by our team and was connected to a Mac Mini. Both the monitor and tabletop applications were developed in mobile and desktop versions of Adobe Flash. The rule-based reasoning engine was implemented in Jess (embedded Java reasoning engine). The rules operated on the ontological conceptual model in Web Ontology Language (OWL) representing the learning and user models, challenges, game, and artifacts.

### Example Experience

The flow of the Kurio experience is best described by narrating a prototypical account of a family's interaction. The family begins at the tabletop display, where they are introduced to the time-travel narrative of the game and view a video that introduces each of the tangible user interfaces and the PDA. From there, they view the broken time map and select the first mission. There are five possible missions, each of which relate to a specific exhibit area, and each family needs to complete three of the five possible missions to fix the time map. When the first mission is selected, the table sends a message to the server and receives back the first set of individual challenges.

The server is preset with each member's age and name, allowing it to select the appropriate starting level of the challenges. For example, Kim, age 9, has been assigned a challenge with the listener, while Simon, age 7, has a pointer challenge. Each tangible has a specific function in terms of the information it can access: the pointer selects museum artifacts, the reader selects text from museum didactics, the listener plays audio clips in different locations in the exhibit, and the finder provides directional information for particular exhibits. When tangibles are assigned to each child, the tangibles glow green, indicating that they are ready to be used. The children's mother, Sheila, is asked to collaborate with and help her children for the duration of the first mission. She is given the PDA and her role is to coordinate and facilitate the completion of the challenges by the other group members.

Once everyone has been assigned a role for the mission, the family leaves the table and heads out into the museum space. Simon's challenge asks him to "Find objects

## Experience Structuring Factors Affecting Learning in Family Visits to Museums

## Scenario Description
M. Hatala et al.

Sheila selects the "review" button at the bottom of Kim's challenge screen. She answers two quick questions about how difficult Kim found the question and whether anyone helped her answer it. Kim is assigned a new challenge and goes back to the table to exchange the listener device for the reader.

Kim and Simon continue doing challenges until the monitor informs them that they should return to the table. Once there, they can view the results of their work. Challenges that were completed successfully are displayed on one side of the screen while objects that are incorrect are displayed on another, along with the correct answer. The family can review this information and discuss their progress. Next, the system either assigns a new round for the same mission, or moves them on to the selection of the next mission, depending on how much time they have spent so far. At the end of each mission, they are able to view a short "reward" video that gives them more information about the area of the museum they just finished exploring. When the next mission begins, the monitor is switched over to Kim and Sheila gets to try out the tangibles. In this manner, they complete three missions, fix their time machine, and are able to continue on to the future.

## Modeling Family and Its Members

The above scenario gives a flavor of how the Kurio experience progresses. The reasoning engine on the server is what guides the course of the game, keeping track of everything that happens and making decisions based on that information. We had two main goals in mind in terms of how to customize the game experience for each family:

1. To find the appropriate challenge level for each individual
2. To manage the length of the mission rounds to suit the pace of the group

At its core, the reasoning engine is a rules-based expert recommender system, supported by a knowledge base consisting of an ontology of the available missions and challenges. A set of individual models as well as group model is maintained throughout the course of each family's interaction with Kurio. Because of space limitation here we provide only an overview of user and group models.

### Individual Models

The individual models consist of some basic demographic information (name, age, family name) and a set of values for specific learning-related skills. To structure the learning model, we used Bloom's taxonomy [15], which progresses through 6 levels of learning: Remember, Understand, Apply, Analyze, Create and Evaluate. Each individual challenge is categorized according to which level of the taxonomy it relies on most. The age of the individual participant is used to set the starting values for the skills. When a new challenge is to be assigned, the reasoning engine ranks all possible challenges and chooses from amongst the ones that are the best fit. Three criteria are used to automatically rule out certain challenges:

1. Current mission: If the challenge is not part of the current mission, then it is not considered for assignment. The missions have between 18-24 challenges in total.
2. Tangible user interface availability: Any challenges requiring a tangible that is already in use is discarded from the pool of candidates. In each mission, there are between 3-7 challenges for each device.
3. Age: The listener device was more difficult to use than the others, both in terms of interface and in terms of the cognitive requirement to listen to and extract information from the audio. Therefore, an age limit was set so that children under the age of 9 did not get assigned challenges using that device.

Once these hard criteria have narrowed the pool to challenges from the current mission whose device is available, a ranking algorithm assigns each candidate a value based on 3 other factors:

1. Skill progression: If the new challenge is one skill higher than the last challenge the person completed, then it is given a high ranking. If it is more than one skill higher, it is given a low ranking. If it is the same skill or lower, it is given a neutral ranking. This factor creates a pull towards increasing the level of challenge.
2. Skill Reinforcement: The skill of the challenge compared to the current value of the skills in

## User Studies of Kurio in a Local History Museum

## Study Overview

In our evaluation, families tested Kurio in a local history museum. The study included 58 participants (18 families), with family sizes ranging from 2-4 people. Most groups had one parent with children, though one family had two parents. The participants included:

- 35 children ages 7-12 (20 boys, 15 girls)
- 4 children ages 13-17 (2 boys, 2 girls) 
- 19 parents ages 24-57 (15 mothers, 4 fathers)

The evaluation occurred in two phases three months apart using the same protocol. Phase 2 featured a more robust system with minor device adjustments and updated user modeling parameters.

Families were recruited through local mailing lists, schools, and homeschooling groups. Each session included:

- System tutorial
- Pre-session interview and questionnaire
- Game completion (~45 minutes)
- Post-session questionnaires and semi-structured interview
- Optional follow-up audio interviews 2-4 weeks later

## Results

### Questionnaire Data for Ages 7-12

Results were converted to a 1-5 scale (5 being best). Key findings:

- Fun with Kurio: 3.93 average across phases
- System usability: 3.27 average
- Challenge difficulty: 3.39 average
- Significant improvements in Phase 2 for:
  - Excitement about next challenge
  - Learning helpfulness
  - Family enjoyment

### Questionnaire Data for Ages 13+

The adult questionnaire used a 5-point Likert scale. Notable results:

- Fun factor improved significantly from 3.7 to 4.58 between phases
- High confidence in system use (4.28 average)
- Moderate learning effort required (3.54 average)
- Significant improvements in Phase 2 for:
  - Museum exploration
  - Exhibition learning
  - Overall enjoyment

Statistical analysis showed negligible intra-family correlations for both age groups.

Here's the cleaned Markdown:

## Experience Structuring Factors

Table 2. (continued)

| Question | Values (Mean, SD, N) |
|----------|---------------------|
| B.4 How well did Kurio let you learn together with your family and or friends about the museum exhibition and the artefacts? | *3.55, 1.5, 9 <br> *4.66, 0.49, 12 <br> 4.19, 1.16, 21 |
[Table continues with all entries...]

### Experience Structuring Factors

In addition to the interview and questionnaire data, we also saved the system log data for every study session. The log captured the fine grained interaction activities of each individual and family, including the challenge assignments, selection and de-selection of objects, activity at the tabletop, and responses to the post-challenge feedback questions.

Table 3. Experience structuring factors extracted from log data

| Factor | Description |
|--------|-------------|
| Number of Challenges | Number of successfully completed challenges |
| Number of Quits | Number of challenges the user quit. As this was the way to overcome some technical glitches, its semantics represents failures of the system. |
| Being helped | Number of challenges where user responded that s/he received help. |
| Relative Time Helping Others | A ratio of time without an assigned challenge when user was asked to help other family members to time spent on solving their own challenge. |
| Average of Difficulty | Five last challenges were used with the latest challenge weight set at 5 and weight going backwards to 1. |
| Deviation From Just Right | Ratio between challenges rated Easy and Hard and total number of challenges. |
| Difficulty Sequential Change | Average change in difficulty between subsequent tasks measured in absolute values (e.g. change from Hard to Easy is 2) |

### Assessing Importance of Experience Structuring Factors

We wish to identify experience structuring factors that have strong associations with each of the questionnaire response variables. In this context, bivariate correlations between response and explanatory variables are of limited utility, as they do not adequately account for multicollinearity (hidden multivariable correlations) among the explanatory factors [18]. Also, model-selection procedures such as stepwise selection are inappropriate on several levels: they select a single combination of variables that may not be best by any objective measure and they ignore the effects of random variability on the model selection process [19]. We do not seek to use a model for predicting responses. Instead, we use a variable-selection approach that considers all explanatory factors simultaneously and assesses their relative importance in explaining variability in the response variables.

Method. For each response variable we fit models consisting of all possible combinations of explanatory variables, including the empty model, and calculated a model-assessment criterion, the corrected Akaike Information Criterion (AICc), on each model. We converted the AICc values to model weights so that the relative sizes of the weights reflect the relative fit of the model: good-fitting models have large

## Experience Structuring Factors Affecting Learning in Family Visits to Museums

The weights were normalized to sum to 1 over the set of all models. Factor weights were calculated for each explanatory factor by summing the weights corresponding to all models in which the factor appears. Factors consistently part of the best-fitting models have weights close to 1, while those not generally included in good-fitting models have factor weights near zero. Details on this factor weighting procedure can be found in [19]. Finally, we applied a strict threshold (0.95 out of 1 for '++' or '--' ranking and 0.90 of 1 for '+' rank or '-', with the sign determined by the sign of the corresponding regression coefficients) to consider the factor as important to explain the variability in the questions and worth paying attention to in further research and design of systems like Kurio.

## Model for ages 8-12

Factors found as important using the method above are listed in Table 4. For other questions from the questionnaire for 8-12 year olds (Table 1), no other variables came out as sufficiently important. In those cases, the mean and standard deviation as listed in Table 1 provide the best guidance for future research.

### Table 4. Experience Structuring Factors Model for ages 8-12

Question | Factors
---------|----------
E. Was Kurio helpful in learning about things in the museum? | Number of challenges completed (--)
F. Was Kurio fun to use with your family? | Difference from just right (--), Relative time to help others (--)

The first finding is very surprising. It indicates that with increasing number of challenges completed, we can expect children to judge the Kurio's ability to help them learn about things in museum less. To put this into perspective, the average number of challenges completed in this age group was 4.22 (SD=2.16, N=31) with maximum number of challenges being 10 and minimum 1. This is a strong indicator that although they had fun with the system and considered Kurio to be a good way to visit museum (Table 1), the actual learning can be hindered by excessive number of challenges. As a guideline, the pace of interaction has to be carefully tested before any serious deployment of the system.

The second finding indicates that the two factors negatively influence the fun factor in the context of the family visit. First, difference from just right is a good confirmation that if system assigns challenges at the right level, this increases the value of the visit as a family.

The relative time to help others factor is a relative measure of the time without challenges against time spent solving their challenge in each mission. As rounds of challenges were wrapped up, individuals who completed their individual assignments were not given new ones and were instead asked to help the others in their family. Depending on how quickly they did their challenge and how long their family members took, they could spend a significant amount of time without anything specific to do.

The interpretation of the finding is fairly straightforward; when individuals have nothing to do, they become bored and start to feel negatively about the experience, or helping others learn is less valued than learning themselves.

Although a high amount of time helping others may have caused boredom for some users, others commented explicitly in the interviews that they enjoyed working together to complete the missions. In one of the self-administered interviews completed a couple weeks after the Kurio interaction, one family had the following exchange in response to the question "What did you like best about Kurio?"

Jenna: I liked trying to help other people do it. I don't know why.
Sharon: I know, that's a good reminder, I liked that too, working together…
Jenna: Not just, oh it's all about me, I can only do it.
Sharon: Yeah, the problem solving was kind of fun, I liked figuring it out together.

No one in the interviews complained that the Kurio system isolated them from their family members or inhibited social interaction, so in that regard at least the system was successful in correcting issues observed in individually focused systems.

##

Here's the cleaned and normalized Markdown:

The attitude towards Kurio is higher with number of challenges completed, which is an expected result. However, the positive view is negatively affected relative to the time spent to help others, i.e. the more time spent with others. The previous explanation presented in the paragraph above seems to apply in this case as well. Another aspect that negatively affects positive attitude toward the system is being helped, meaning that adults do not like it when they are being helped. This aspect is interesting and we plan to further investigate this issue.

There is also a significant finding with respect to learning in the question E.5 that reflects the similar finding in the model for the age group 8-12.

## Conclusions

We presented a system, Kurio, which supports family visits in museums with a mixture of technology including specialized tangible devices, a personal digital assistant, and a tabletop computer. The families engage in an educational game where family members are assigned individual challenges and their progress is monitored by coordinated by the family member with PDA. After each round of challenges, the family returns to the tabletop computer to review their progress, obtain rewards, and is guided to the next round of challenges.

We have evaluated the Kurio with 18 families (54 participants) in a local museum. In addition to the session using Kurio that lasted on average 45 minutes, the participants filled in pre and post-test questionnaires, provided post-session structured interviews, and also self-administered audio interviews 2-4 weeks after the session. The evaluation was organized in two phases.

In this paper we reported the questionnaire results for age groups 8-12 and 13+. The evaluation of the Kurio overall was very positive. We also extracted several factors from the log data. We applied a model discovery method to determine which factors play important roles in determining users' perception about the Kurio system and support learning in the museum.

## References

1. Hatala, M., Wakkary, R.: Ontology-Based User Modeling in an Augmented Audio Reality System for Museums. User Modeling and User Adaptive Interaction 15, 339–380 (2005)
2. Wakkary, R., Hatala, M.: Situated Play in a Tangible Interface and Adaptive Audio Museum Guide. Journal of Personal and Ubiquitous Computing 11, 257–301 (2007)
3. Ellenbogen, K.M.: Museums in Family Life: An Ethnographic Case Study. In: Leinhardt, G., Crowley, K., Knutson, K. (eds.) Learning Conversations in Museums. Erlbaum, Mahwah (2002)
4. Hilke, D.D.: The Family as a Learning System: An Observational Study of Families in Museums. In: Butler, B.H., Sussman, M.B. (eds.) Museum Visits and Activities for Family Life Enrichment. Haworth Press, New York (1989)
5. Hooper-Greenhill, E.: Museums and their Visitors. Routledge, New York (1994)
6. Woodruff, A., Aoki, P., Grinter, R., Hurst, A., Szymanski, M., Thornton, J.: Eavesdropping on Electronic Guidebooks: Observing Learning Resources in Shared Learning Environments. In: Proc. of Museums and the Web, pp. 21–30 (2002)
7. Aoki, P., Grinter, R., Hurst, A., Szymanski, M., Thornton, J., Woodruff, A.: Sotto Voce: Exploring the Interplay of Conversation and Mobile Audio Spaces. In: Proc. SIGCHI, pp. 431–438 (2002)
8. Dini, R., Paternò, F., Santoro, C.: An Environment to Support Multi-

Here's the cleaned and normalized Markdown:

## Personalisation of Learning in Virtual Learning Environments

Dominique Verpoorten, Christian Glahn, Milos Kravcik, Stefaan Ternier, and Marcus Specht

CELSTEC, Open University of the Netherlands, Valkenburger Weg 177, 6411AT Heerlen, The Netherlands

## Abstract

Personalization of learning has become a prominent issue in the educational field, at various levels. This article elaborates a different view on personalisation than what usually occurs in this area. Its baseline is that personalisation occurs when learning turns out to become personal in the learner's mind. Through a literature survey, we analyze constitutive dimensions of this inner sense of personalisation. Here, we devote special attention to confronting learners with tracked information. Making their personal interaction footprints visible contrasts with the back-office usage of this data by researchers, instructors or adaptive systems. We contribute a prototype designed for the Moodle platform according to the conceptual approach presented here.

**Keywords**: Personalisation, self-regulation, VLE, learner support, learner tracking.

## 1. Introduction

Good pedagogy is commonly assumed to be related to individualized learning. This perspective sees learners as separate entities with unique learning goals and needs requiring customized support. In contrast to individualized learning, personalised learning emphasizes the notion that learners consider given settings for learning as personally relevant. The personal perspective implies that learners take ownership and responsibility of their learning processes and of the tools which they use. This perspective allows developing courses and services for personalised learning without taking the individual differences of each learner as a starting point. Personalised learning relies on three interrelated theories:

- Constructivism understands learning as the process in which persons actively construct knowledge, concepts, and competences through interacting with their environment [1]
- Reflective thinking stresses that instructional practice should not simply aim at engaging learners at the level of presenting information for understanding and use, but also direct them at meta-levels of learning [2]
- Self-regulated learning focuses on the cognitive and communication processes through which learners control their learning [3]

One key concept of self-regulated learning is motivation [4, 5]. Therefore, supporting the learners' motivation is a goal of personalised learning. Motivation rests on three key factors: perceived controllability, perceived value of the learning task and perceived self-efficacy for it [6, 7]. These aspects depend critically on learners' understanding of their own process of learning and their personal situation in the learning task. Therefore, it is necessary to support the learners' awareness of the learning goals, their progress, and the context in which their learning is situated. Feeding back personal tracked data is a way to enhance the appraisal of these personal dimensions of learning. However, such an approach of autonomous learning support has not retained much attention from research so far. Mining learners' interactions is a common concern of adaptive system improvement. Such systems harness the tracking of various parameters to the production of adaptive presentation, learning paths, content selection [8]. In all cases, the process entails a backstage treatment of personal tracked data but seldom involves presenting it to their owners.

Central to this paper is an analysis of the use of this data for personalising learning experiences and supporting self-regulation in virtual learning environments (VLEs). The analysis is preceded by and grounded in a review of concepts of personalisation coming from education and technology related domains. It is followed by the description of a prototype, developed for the Moodle platform, which starts giving concrete expression to the reconsidered perspective on personalisation outlined here.

## 2. Background

Personalisation of learning has become prominent in the educational field, at various levels: social [9], government policy [10, 11], school management [12, 13] and course/lesson design [14, 15, 16]. Definitions of personalisation greatly vary [17] from the perfectly acceptable but vague "antithesis of impersonal" to the technical and hyper-focused "automatic learning paths structuring

Here's the cleaned and normalized Markdown:

## Personalisation of Learning in Virtual Learning Environments

### Personalised Learning and Control

Control is a central aspect for personalisation. In virtual learning environments (VLEs) four types of control can be distinguished:

- System control occurs while designing a VLE and is represented by the design decisions of the architects and developers of a VLE. This includes the look and feel of a VLE as well as its functions and the workflows that it enforces;
- Organizational control includes all restrictions, customizations and regulations that are specific to an instance of the VLE. This includes the reflection of the organizational identity as well as the tools and functions that are available to all users of the VLE's instance;
- Teacher control defines the actual educational structure of learning units. This includes the type and availability of learning material, the availability of tools learners can use, as well as the arrangement of these tools that also encompasses their intended usage. This type of control is often called instructional design;
- Learner control reflects the ways through which learners can take control over their learning processes.

As this typology shows, learners' personal initiatives (lowest level of control) do not take place in a vacuum. Formal learning usually occurs thanks to externally pre-structured elements combined with a space of possibilities opened up only in the actual moment of learning. Personalised learning does not require that learners have all control over their learning environment, but it requires some control for the learners [22]. This can be as simple as providing explicit, updated and understandable information useful to monitor and analyze one's learning (see section "Tracking for Mirroring").

### Dimensions of Personalised Learning

Several dimensions are interconnected in the notion of personalised learning experiences. These dimensions can be structured as follows:

- Ownership [10]
- Participation [23]
- Diversity [24]
- Regulation [4, 25]
- Reflection [26, 27]

These dimensions reflect different aspects of control and determine what is possible in the learning process. Personal information can provide contextual beacons and support successful management of these aspects.

### Personalised Learning and Personal Information

Personal information is not only information about the learner. It also comprises contextual information that characterizes the learners' situation. This includes basic learner information (such as name or student number), information resulting from monitoring a learner's activity, achievement of predefined learning goal, etc. Based on the considerations made for context aware systems [28] and context adaptive learning support [29], the control over personal information can be analyzed on the following five levels: data collection, information selection, arrangement, application, presentation. It is suggested that the decisions, the levels of control, and the availability of personal information at these levels influence the learners' control of and commitment to their own learning. In the so called personal learning environments (PLEs) [30, 31, 32], learners are supposed to have full control over their personal information, while in VLEs learners have often limited or no access and control over it. This is particularly the case for tracked information.

### Tracking for Mirroring

Mirroring, i.e displaying tracked interaction footprints to the benefit of learners [33] is not a trivial task. It raises pedagogical, interface-related and technical issues. One of them relates to tracking facilities. User tracking is a key process for user and learner modeling [34] that involves recording user interactions with the intention to store them for further processing. This information is exploited to develop assumptions about the user, to generalize interaction histories into patterns, to classify or cluster these patterns.

Many VLEs create interaction histories as part of their standard functionality. Such monitoring of personal learning actions is usually only accessible to lecturers, tutors, administrators or researchers. Furthermore, the related monitoring functions are often detailed but complex transcripts of the learner activity. Therefore, many approaches exist for better structuring and presentation of this information in order to support teaching staff in controlling the activities in the online environment. An extensive overview of the different approaches is provided by Romero & al. [35]. There are only a

## Personalisation of Learning in Virtual Learning Environments

## Prior Research and Framework

Prior research has suggested that learners depend on external information on their own activity to analyze, organize, and orientate their actions in complex environments [4, 25]. The personal information represented in a learner's interaction history might be related to personalised learning experiences. Previous work [39, 40] suggests that personal information can serve as feedback that helps learners to reflect on the learning process. Therefore, it can be assumed that information from user tracking supports learners to examine their position in the learning process and to regulate their learning activity.

This conceptual claim guides the whole work presented here. In concrete terms, personal tracked data can be harnessed to various instructional purposes that must be analyzed in the specific learning contexts. However, both the abstract and the down-to-earth levels presuppose the availability of personal learning footprints. In order to resolve justified privacy concerns and the need for personalisation it is crucial to understand the structure and organization of personal information across the five levels of personal information control.

### Architecture and Personalisation Levels

Table 1. Comparison of architectural layers and personalisation levels

Architecture layers | Personalisation level
---|---
1. Sensor layer | Data collection
2. Semantic layer | Information selection  
3. Control layer | Information arrangement
3'. Control layer | Information application
4. Indicator layer | Information presentation

The levels "arrangement" and "application" are two types of the architecture's control layer. Arrangement refers to the organization of personal information sets from a learner's interaction history. The level "application" describes higher level processing of the personal information. Examples of such higher level processing are recommendation systems or adaptation engines.

## Mirroring for Personalising

The view on personalisation examined in this paper focuses on learner's control. It is asserted that one of its influencing factors is the availability of personal information and the ways that enable the stakeholders of the learning processes to use this information according to their needs. The personal information, properly fed-back to the persons they come from, can document their development of knowledge and skills in a learning environment and their course of actions at task level. Viewed in this manner, personalised learning quite often implies the development of different kinds of organizing and presenting information about:

- Situation-related aspects: they concern the fixed components of the learning tasks (targeted learning goals, available learning resources, mandatory and optional tasks, needed and trained skills, time allocations, marks, etc.)
- Self-related aspects: they relate to learning behaviors and achievements and personal learner information in general (teacher's marks and remarks, tasks completed, achieved learning goals, resources consulted, time spent, skills self-assessment, note-taking tools like journals or learning diaries, etc.)
- Social-related aspects: they cover social awareness clues (including comparison processes with data coming from peers or from an expert). As Web 2.0 gains momentum, this social information increases in quantity and availability, inviting to a systematized observation of its potential for promoting self-regulated personalized learning.

Agents depend on this personal and contextual information [4] to organize, orientate and navigate through complex environments. By exerting their understanding on these three sources of information, in order to support decision-making for self-regulation, learners personalize their learning.

### Tracked Data for Adaptive Systems

The design of tools stimulating the appraisal of contextual and personal information is highly dependant on the system's capacity to track interaction footprints and to feed them back to the learner in appropriate presentation modes. This presentation to individual end-users of what the system has captured from their learning episodes is called "mirroring". In the type of personalisation exposed here, tracking tools and techniques are oriented towards this mirroring and receive their value from it. Personalising learning flows therefore partly from an appropriate integration of personal information in the learner's environment.

This might sound obvious but a literature review shows it is not. A few articles exhibit interest for learning traces but they usually see learners as indirect benefactors of their treatment. Direct users are systems, instructors or researchers. Adaptive systems make use

Here's the cleaned and normalized Markdown:

## Tracked Data for Instructors and Researchers

Some authors expressed interest for the exploitation of different kinds of interaction footprints by researchers [48, 49]. Others speculated about its benefit for instructors [50]. Among them, Nagi & Suesawaluk [51] recommended tutors to make use of the students data tracked by the Moodle eLearning platform in order to better regulate their courses. With a tool called CourseVis, Mazza & Dimitrova [52] took student tracking data collected by content management systems and generated graphical representations useful to instructors to gain an understanding of what is happening in distance learning classes. This work lead to the production of Gismo, a tool managing the visualization of data tracked in Moodle [53]. In a similar vein and on the same platform, Zhang et al. [54] developed a VLE log analysis tool, called Moodog, to track students' online learning activities. The goals of Moodog were twofold: first, to provide instructors with insight about how students interact with online course materials, and second, to allow students to easily compare their own progress to others in the class. The latter objective sounded congruent with the approach defined in this article. However the authors eventually postponed its achievement to a subsequent study. Scheuer and Zinn [55] developed an interesting tracking system called the Student Inspector. In their conclusion, they only evoked the possibility to open the tool to students.

The presentation of personal data to learners in a context of self-regulated learning do not preclude a parallel use of user tracking data by instructors. Azevedo's [56] findings show that external regulation using human tutors enhances learning via hypermedia. However increased awareness (making learning an object of attention/reflection) of the learning process obtained, on the learner's side, by mirroring personal information, is desirable as well. It has also the potential to boost the relevance of tutor action.

## Tracked Data for Learners

Attempts to place learning traces in the hands of lifelong learners who therefore turn to be agents and researchers in their own learning processes [3] are not numerous. In addition, they give contrasted results [57]. For instance, in StudyDesk [58] and ACE [59] systems, the use of available personal footprints by the learners appears to remain close to zero. It means that the mere presence of such tools is not enough to improve personalised self-regulated learning, unless students are somehow motivated to use it. Johnson & Sherlock [60] also observe that self-analytics tools can be unwelcome because they represent an incentive to change learning habits, which is hard for many learners. Nevertheless, they conclude that this kind of personal data mirroring amplify conversations about learning, which might be a condition for initiating the self-changing process. But aside from these exploratory studies, the benefits that mirroring interaction with the course might yield for the student is not an object of high attention.

Glahn & al. have notwithstanding initiated a systematic investigation of the use of personal traces. They analyzed the support of self-directed learning with Web2.0 services [29, 39, 40]. These studies focused on how the presentation of recorded user activity supports reflection and engagement in personal learning. The finding of these studies is that mirroring of personal learning activity depends on two design principles:

- Perspective of learners in their current learning context
- Contrasting information that allows the learner to evaluate the own actions

These results suggest that appropriate tooling can support personalization of learning through information that is suitable to reflect on the learning process. One tool, coined by the authors "smart indicators" displays contextualized indicators about achievements, incentives, progress.

## Personalisation in Virtual Learning Environments – A Prototype

Based on the system architecture for context aware systems [28], a prototype for personalisation in virtual learning environments is being developed. This prototype instantiates concepts, concerns, requirements and design principles conveyed by the different view on personalisation elaborate

Here's the cleaned Markdown:

## Personalisation of Learning in Virtual Learning Environments

Firstly, it implements the different levels of personal information processing as independent services. Secondly, it is fully integrated into the Moodle platform. For the prototype three additional requirements were formulated. First, it has to be possible to add new perspectives on personal information. This defines that new ways of information selection can be easily added without much effort. In the terminology of the underlying architecture this means that new aggregation rules for the user tracking can be added at any time. Second, it has to be possible to create new arrangements of the selected information. Finally, a flexible information visualization approach is needed that allows adding new and replace existing visualizations, without concerning the underlying data. This requirement defines that different visualizations can be used of the same personal information as well as that the same visualizations can get used for different types of personal information. The tight integration into the Moodle platform assures that all system functions for authentication and authorization are appropriately applied for the role of the current user. Moreover, it assures that the prototype framework uses the same data as other components of Moodle. This is an advantage compared to the approaches of the systems for visualizing user tracking information for Moodle that have been discussed earlier in this paper. Instead of using a proxy repository for analyzing the learner activity the framework uses Moodle's internal learner tracking and can provide live information on the learning activity. In addition to the shared data, the prototype framework is part of the Moodle system and can therefore use the Moodle interfaces for authentication and authorization of incoming data requests. The four system layers of the architecture are reflected by the framework as following.

### The Sensor Layer
The purpose of this layer is to collect and to store traces of actions. These traces can be accesses to a learning resource, writing a forum posting, or the results of a test. Moodle implements a detailed action logging that is automatically integrated into the different plug-ins of the system. Additionally, some Moodle plug-ins allow a more detailed view on the learners' activities. Therefore, it is not necessary to implement a separate sensor layer for tracking learner actions in Moodle.

### The Semantic Layer
This layer processes the data collected by the sensor layer into semantically meaningful information. At the level of the semantic layer several aggregation rules can be active to process the traces of learning activity. The current system implements the sensor layer as a REST service through which the different aggregation rules have unique names and can be directly accessed through an URL. At this stage each aggregation rule of the semantic layer represents an SQL statement that processes Moodle's user tracking. Each aggregation rule returns the result data to the JSON format that can be easily interpreted by web-frontends. XML output of the data is planned for future releases. Each aggregation rule can be limited to different social contexts of the learner and to a specific course. So far the social context self, course fellows and contacts are implemented. The context "self" includes only the data of the learner who is currently logged in while accessing the Moodle system. The context "course fellows" includes the data of all other learners who are enrolled in the same courses as the learner. The context "collaborators" includes all learners who were directly collaborating with the learner in at least one of the different collaboration tools of Moodle.

### The Control Layer
This layer defines the arrangement of the aggregators and the visualization that are used for mirroring. The control layer is implemented as a plug-in that provides several widgets that can be independently integrated into the user interface of a course. Each widget contains a set of aggregators and visualizations, which can be configured by the instructor of a course.

### The Indicator Layer
This layer provides different presentation modes for the data of the semantic layer. The indicator chooses the presentation mode based on the configuration of the indicator layer and receives the data from the semantic layer. The indicator layer is embedded into the user interface of Moodle through a JavaScript module. It fetches the data from the semantic layer through service requests.

### Personal Information Management

The aggregation rules of the semantic

Here's the cleaned Markdown:

## Validation of the Approach

This research emphasizes interaction traces in order to inspect to what extent their feedback to the learner can be beneficial to him and to the design of his learning environment. Main benefits from this personal history of learning begins with the mirroring of personal information. Sometimes or with some learners, contemplating it will be enough to generate some kind of diagnosis (for instance: "the assignment requests from me that I post 12 messages in the forum and I have only 3 so far") and to self-administer appropriate remedial. But in other occasions, the way to achieve the improvement will not be so straightforwardly inferred from mirroring even if it brings valuable information (for instance: "Compared to the number of learning activities performed by my peers, I am slower"). It means that students must be prepared to interpret their personal data and, in some cases, must receive help for this.

An underpinning hypothesis for this approach is that making learning processes explicit and comparable, through their mirroring, can affect student attributions of learning (locus of control) and increase what is advocated by all promoters of lifelong learning: the responsibility and ownership of one's own learning. Tracking might be related to self-efficacy aspects. A number of studies indicate that high-mastery students are more successful overall because they persevere, experience less anxiety, use more strategies, and attribute their success to controllable causes. It means that the others could benefit from an explicit, reified view of their actions and realize they are in control. Additionally, it is hypothesized that the provision of personal info can play the role of an involvement factor.

## Conclusion

This paper delineated and documented a perspective on personalisation based on the mirroring of personal tracked data. This approach advises to not merely use personal tracked data for backstage adaptation but to mirror it back to the learner. It therefore entails the availability of tools that automatically collect and aggregate selected information on the personal learning activities and interactions and make it visible to the user. In its last part, the article contributed a prototype which instantiates concepts, concerns, requirements and design principles conveyed by this different view on personalisation. Further elaboration of the prototype as well as experimental settings meant to substantiate the pedagogical value and possible benefits of the approach are on their way.

### Acknowledgements

This paper is sponsored by the TENCompetence project (www.tencompetence.org), funded by the European Commission's 6th Framework Programme and by the GRAPPLE (www.grapple-project.org) project funded by the European Commission's 7th Framework Programme.

### References

1. Terhart, E.: Constructivism and teaching: a new paradigm in general didactics? Journal of Curriculum Studies 35(1), 25–44 (2003)
2. Ertmer, P.A., Newby, T.J.: The expert learner: Strategic, self-regulated, and reflective. Instructional Science 24(1), 1–24 (1996)
3. Winne, P.: A Perspective on State-of-the-art Research on Self-regulated Learning. Instructional Science 33(5-6), 559–565 (2005)
4. Butler, D.L., Winne, P.H.: Feedback and self-regulated learning: a theoretical synthesis. Review of Educational Research 65(3), 245–281 (1995)
5. Ley, K., Young, D.B.: Instructional principles for self-regulation. Educational Technology Research and Development 49(2), 93–103 (2001)
6. Ryan, R.M., Deci, E.L.: Self-determination theory and the facilitation of intrinsic motivation, social development, and well-being. American Psychologist, 68–78 (2000)
7. Viau, R.: La motivation: condition au plaisir d'apprendre et d'enseigner en contexte s

Here's the cleaned Markdown, preserving the reference list format while normalizing the formatting:

## References

17. Noss, R.: Foreword. In: Magoulas, G., Chen, S. (eds.) Advances in Web-based Education: Personalised Learning Environments. Information Science Publishing (2006)

18. Schmoller, S.: FE White Paper - the personalisation virus is spreading (2006), http://fm.schmoller.net/2006/04/fe_white_paper_.html

19. Primus, N.J.C.: A generic framework for evaluating Adaptive Educational Hypermedia authoring systems - Evaluating MOT, AHA! and WHURLE to recommend on the development of AEH authoring systems, doctoral dissertation. University of Twente, Twente (2005)

20. Waldeck, J.H.: What Does "Personalised Education" Mean for Faculty, and How Should It Serve Our Students? Communication Education 55(3), 345-352 (2006)

21. Waldeck, J.H.: Answering the Question: Student Perceptions of Personalised Education and the Construct's Relationship to Learning Outcomes. Communication Education 56(4), 409-432 (2007)

22. Dron, J.: Controlling learning. In: Kinshuk, K.R., Kommers, P., Kirschner, P., Sampson, D.G., Didderen, W. (eds.) 6th IEEE International Conference on Advanced Learning Technologies, pp. 1131-1132. IEEE The Computer Society, Los Alamitos (2006)

23. Lave, J., Wenger, E.: Situated learning. Legitimate peripheral participation. Cambridge University Press, Cambridge (1991)

24. Wilson, S., Liber, O., Johnson, M., Beauvoir, P., Sharples, P., Milligan, C.: Personal Learning Environments: Challenging the Dominant Design of Educational Systems. In: Tomadaki, E., Scott, P. (eds.) Proceedings of the workshop Innovative Approaches for Learning and Knowledge Sharing at the EC-TEL 2006, pp. 173-182 (2006)

[References 25-51 continue in same format...]

Here is the cleaned Markdown:

## References

52. Mazza, R., Dimitrova, V.: Visualizing student tracking data to support instructors in web-based distance education. In: 13th International World Wide Web Conference (WWW 2004) - Educational Track, New York (2004)

53. Mazza, R., Botturi, L.: Monitoring an Online Course With the GISMO Tool: A Case Study. Journal of Interactive Learning Research 18(2), 251-265 (2007)

54. Zhang, H., Almeroth, K., Knight, A., Bulger, M., Mayer, R.: Moodog: Tracking Students' Online Learning Activities. In: ED-MEDIA, Vancouver (2007)

55. Scheuer, O., Zinn, K.: How did the e-learning session go? - The Student Inspector. In: 13th International Conference on Artificial Intelligence in Education (AIED 2007), Los Angeles (2007)

56. Azevedo, R.: Computer Environments as Metacognitive Tools for Enhancing Learning. Educational Psychologist 40(4), 193-197 (2005)

57. Perrenoud, P.: Le désir de ne pas savoir - Ambivalences et résistances face à la posture réflexive. In: Troisième journée pédagogique de l'IFRES. "Innovations pédagogiques dans les pratiques réflexives", Liège, Belgium (2009)

58. Narciss, S., Proske, A., Koerndle, H.: Promoting self-regulated learning in web-based learning environments. Computers in Human Behavior 23, 1126-1144 (2007)

59. Specht, M., Oppermann, R.: ACE - adaptive courseware environment. The New Review of Hypermedia and Multimedia, 4 - Special Issue on Adaptivity and user modeling in hypermedia systems 1, 141-161 (1998)

60. Johnson, M., Sherlock, D.: Personal Transparency and self-analytic tools for online Habits. In: TENCompetence Workshop Stimulating Personal Development and Knowledge Sharing, Sofia, Bulgaria (2008)

61. Verpoorten, D., Poumay, M., Delcomminette, S., Leclercq, D.: From Expository Teaching to First e-Learning Course Production: Capture in a 17 Online Course Sample of a Pedagogical Pattern Facilitating Transition. In: 6th IEEE International Conference on Advanced Learning Technologies (ICALT 2006), Kerkrade, The Netherlands (2006)

62. Seel, N.M.: Epistemology, situated cognition, and mental models: 'Like a bridge over troubled water'. Instructional Science 29(4), 403-427 (2001)

## A New Framework for Dynamic Adaptations and Actions

Carsten Ullrich¹, Tianxiang Lu², Erica Melis²

¹ Shanghai Jiao Tong University, Haoran Building, 6/F
ullrich_c@sjtu.edu.cn

² German Research Center for Artificial Intelligence
{Tianxiang.lu,Melis}@dfki.de

## Abstract

Adaptive course generation is more flexible if it includes mechanisms deciding just-in-time which exercises, which external resources, and which tools to include for an individual student. We developed such a novel delivery framework (called Dynamic Items) that is used by the web-based platform ActiveMath. We describe the framework and discuss several new applications of Dynamic Items for an individual student.

**Keywords**: User-adaptive systems and personalization, Course generation and adaptation.

## Introduction

ActiveMath [9,10] is a Web-based intelligent learning environment for mathematics whose course generator, Pa

Here's the cleaned and normalized Markdown:

## A New Framework for Dynamic Adaptations and Actions

## Overview on the Dynamic Item Framework

The result of the course generation is a table of contents that contains references to learning object as well as Dynamic Items. Dynamic Items are abstract learning objects which are instantiated at presentation time by a component in Dynamic Item Framework. The Dynamic Item Framework consists of three stages: generation stage, adaptation stage and presentation stage. Either fetched from a persistent pre-authored content repository or generated by different learning services introduced (see §3), the Dynamic Item elements serve as intermediate objects before the presentation takes place. At the time the user opens a page that contains Dynamic Item, the Dynamic Item Transformer renders the Dynamic Items and transforms them into standard learning objects, taking into account up-to-date user information. The resulting learning objects are then transformed into the presentation format selected by the user, e.g., html.

## Applications of Dynamic Item

In this section, we illustrate the applications of Dynamic Items in ActiveMath.

### Dynamic Tasks

The most frequent application of Dynamic Item is the dynamic course generation based on dynamic task expansion. Course generation can stop at a level that (abstractly) specifies what kind of learning objects should be selected, dynamic task, but does not specify which ones.

Later, at presentation time, when the learner first visits a page that contains a dynamic task t this is passed to the course generator that then assembles the sequence of resources that achieve t. The resulting identifiers of learning objects replace the dynamic task in the course structure with those learning objects. Hence, when the page is revisited, the elements do not change. This means a course is partly static, partly dynamic and, thus, the goal of presenting the complete course to the learner while preserving dynamic adaptivity.

One advantage of dynamic tasks is that they can be used by authors as well. They can manually compose courses, where parts of the course are predefined and others dynamically computed. In this way, an author can use the best of both worlds: she can compose parts of the course by hand and at the same time profit from the adaptive capabilities of the course generator. This also addresses situations in a classroom, where a teacher mostly wants to provide the same material (e.g., definitions, examples) for every student (important for communication about the material with and among students) and at the same time wants to take advantage of individually selected exercise sequences at places (for more or less training as well as for adjusting the difficulty of problems). This is something a teacher can hardly manage for 20-30 students in parallel, but is easily realized with Dynamic Item.

### Learning Services

Within advanced learning environments such as ActiveMath, the student is able to use external services embedded in the course. When involving the external tools, the system should be able to parameterize the call according to the current performance of the student. This is achieved by Dynamic Item in the following way.

When the learner visits a page that contains a Dynamic Item for a learning-support service, the presentation system converts it into a link and displays it. The link is generated based on the information enclosed in the Dynamic Item element and on values obtained from the student model.

The following describes how three services were integrated using the service Dynamic Item: an Exercise Sequencer, a Concept Mapping tool and an Open Learner Model.

#### Exercise Sequencing
The Exercise Sequencer presents to the learner a dynamically selected sequence of exercises whose selection strategy is parametrized, e.g., as mastery learning that leads the student towards a higher competency level.

This functionality differs from the exercise selection of Paigos because the Exercise Sequencer selects an exercise at the time of first visit, presents it to the learner in a separate window, provides information about the learner's problem-solving progress and terminates or selects a new exercise for a new cycle. The selection algorithm is based on competency levels [7].

Within this interactive sub-environment, the learner can interact with a dynamically selected sequence of exercises until he/she reaches a set learning goal.

#### External Learning Tools
External learning tools are also integrated into the courses generated by ActiveMath using Dynamic Item. An example is the interactive Concept

## A New Framework for Dynamic Adaptations and Actions

## Overview
This is connected to his previous study. These texts cannot be authored manually, since it is practically impossible to cater for all possible choices and histories of students. Therefore, ActiveMath includes a template-based dynamic generation of bridging texts, which:

1. Explain the purpose of a course or a section at an abstract level. They make the intent of sections and the structure of a course explicit, they provide cues that the learners can use to remember and set the stage for the learning processes.
2. By connecting neighboring sections they provide coherence that a mere sequence of educational resources might lack.

In the case of Dynamic Items of type text, the service uses parameters to determine the adequate text template t and returns an OMDoc element whose text body consists of t. If a template is available in several languages, a specific text body is generated for each language (in case that the user changes their language profile any time later). Based on a template of a bridging text a controller responsible for the presentation calls the service specified in the Dynamic Item and passes the remaining attributes and sub-elements as parameters.

Fig. 1 shows a type of bridging texts after html transforming. The text is highlighted by a frame box in order to convey to the learner that the text is on a different level of abstraction than the remaining content displayed on the page.

## External Resources
In order to provide an opportunity of self-regulated learning, a student should be able to include additional learning objects on demand in his personal course.

Since Dynamic Items can provide automatically generated text according to given parameters including hyperlinks, Dynamic Item can also be used to include external learning resources referenced by a link.

A student can easily add external resources (e.g. entries in Wikipedia) and add it to the current course. ActiveMath's assembly tool uses this functionality to add user-selected content. This includes not only texts but also multimedia content (e.g., videos) dragged link from internet. The technological means for this functionality are Dynamic Items for generating text including hyperlinks.

## Related Work
Previous course sequencing such as the Dynamic Courseware Generator selects the next page dynamically at the time the student requests it. While this allows better reactivity, the learner cannot see and use the structure of the complete course for learning.

Our work is different from Adaptive Hypermedia systems such as AHA! which focuses on adapting an individual hypertext document. Whenever the user accesses a concept, a set of rules adapts the resulting document. Our approach uses a book metaphor: a complete course is generated and navigation is unrestricted so that the user can visit each page of the course any time. In such a setting, our mechanism can add parts dynamically to a previously generated course.

Selector first determines the skills/concepts to be taught and then selects or constructs the required learning object. This is very similar to our approach, with the exception of dynamic tasks which allows Paigos to interrupt the planning process and select the specific learning objects at a later.

KnowledgeTree and its extension ADAPT2 is a distributed architecture for adaptive e-learning that integrates different learning services. A teacher can author a course and add references to static and dynamic learning objects (service calls). Our framework allows the automatic generation of courses, including the selection of such services. Automatic generation in KnowledgeTree might be possible, too, but to our knowledge has not been investigated.

Compared to existing work, our approach focuses on an abstract representation of service invocation that is easily authorable and that can be created manually by human authors and automatically during course generation.

## Conclusion
This paper describes how Dynamic Item are used to provide just-in-time adaptivity to a student in a technology-enhanced learning environment. The idea is to separate the generation of appropriate constraints from the inclusion of the actual learning material.

The course generator decides where a Dynamic Item should be added and what kind of Dynamic Item should be added, its type and further constraints. Dynamic Items enable a persistent storage of information about pedagogical goals and constraints processed during course generation.

Usually, pedagogical information is available at generation time only and lost afterward. Dynamic Items can

Here's the cleaned Markdown:

## References

3. Brusilovsky, P.: Knowledgetree: a distributed architecture for adaptive e-learning. In: Proceedings of the 13th international World Wide Web conference on Alternate track papers & posters, pp. 104-113. ACM Press, New York (2004)

4. De Bra, P.: Pros and cons of adaptive hypermedia in web-based education. Journal on Cyber Psychology and Behavior 3(1), 71-77 (2000)

5. Homik, M.: Assembly Tool. Deliverable D37, LeActiveMath Consortium (June 2006)

6. Keeffe, I.O., Brady, A., Conlan, O., Wade, V.: Just-in-time generation of pedagogically sound, context sensitive personalized learning experiences. International Journal on E-Learning 5(1), 113-127 (2006)

7. Klieme, E., Avenarius, H., Blum, W., Döbrich, P., Gruber, H., Prenzel, M., Reiss, K., Riquarts, K., Rost, J., Tenorth, H., Vollmer, H.J.: The development of national educational standards - an expertise. Technical report, Bundesministerium für Bildung und Forschung / German Federal Ministry of Education and Research (2004)

8. Melis, E., Kärger, P., Homik, M.: Interactive Concept Mapping in ActiveMath (iCMap). In: Haake, J.M., Lucke, U., Tavangarian, D. (eds.) Delfi 2005: 3. Deutsche eLearning Fachtagung Informatik, Rostock, Germany, September 2005. LNI, vol. 66, pp. 247-258. Gesellschaft für Informatik e.V, GI (2005)

9. Melis, E., Andrès, E., Büdenbender, J., Frischauf, A., Goguadze, G., Libbrecht, P., Pollet, M., Ullrich, C.: Activemath: A generic and adaptive web-based learning environment. International Journal of Artificial Intelligence in Education 12(4), 385-407 (2001)

10. Melis, E., Goguadze, G., Homik, M., Libbrecht, P., Ullrich, C., Winterstein, S.: Semantic-aware components and services of ActiveMath. British Journal of Educational Technology 37(3), 405-423 (2006)

11. Ullrich, C.: Courseware Generation for Web-Based Learning. LNCS (LNAI), vol. 5260. Springer, Heidelberg (2008)

12. Vassileva, J., Deters, R.: Dynamic courseware generation on the WWW. British Journal of Educational Technology 29(1), 5-14 (1998)

## Getting to Know Your User – Unobtrusive User Model Maintenance within Work-Integrated Learning Environments

Stefanie N. Lindstaedt1,2, Günter Beham1,2, Barbara Kump1,2, and Tobias Ley2,3

1 Knowledge Management Institute, TU Graz  
Inffeldgasse 21a, 8010 Graz  
{slind,gbeham,bkump}@tugraz.at

2 Know Center  
Inffeldgasse 21a, 8010 Graz  
{slind,gbeham,tley}@know-center.at

3 Cognitive Science Section, University of Graz  
Universitätsplatz 2,

## Getting to Know Your User – Unobtrusive User Model Maintenance

## Introduction

Work-integrated learning (WIL) support utilizes 'real' content from organizational memory and repurposes it for learning. WIL is a learning concept developed for supporting continuous competence development at the workplace. It assumes users have basic domain knowledge and can guide their own learning processes [2]. The WIL concept has been applied to requirements engineering, software simulations, innovation management, and intellectual property rights management [3].

Consider a scenario within requirements engineering: Laura is a software engineer creating human activity models based on past user interviews. She uses various applications like MS Word, Visio and Requisite Pro. Though unsure about human activity modeling, she prefers WIL services that work silently in the background over dedicated eLearning systems. These services identify knowledge gaps and recommend relevant learning content, examples, and experienced colleagues for collaboration.

We propose an adaptive approach to supporting WIL. Adaptive systems help users find information, support learning, and enable collaboration [4]. Adaptivity requires a user model - a representation of "the knowledge about the user, either explicitly or implicitly encoded, that is used by the system to improve the interaction" ([5], p.6).

This paper presents our conceptual approach to user model design and maintenance addressing WIL-specific challenges (Section 2). Section 3 introduces a reference implementation developed within the APOSDLE project (www.aposdle.org). After discussing related work (Section 4), we report on pilot evaluation results in Section 5.

## WIL User Models and User Model Services

Several design and usability challenges must be addressed for adaptive systems. Key challenges include predictability & transparency, controllability, unobtrusiveness, privacy, and breadth of experience [4]. For WIL environments, unobtrusiveness and privacy are particularly critical.

Obtrusiveness refers to system demands on user attention that reduce focus on primary tasks [4]. The main source of obtrusiveness relates to how user information is acquired and maintained. While testing is common in learning systems, it is highly obtrusive and unsuitable for WIL where most work tasks lack single correct solutions.

Privacy presents another major challenge for WIL adaptive systems, requiring appropriate organizational and technical measures. Enhancing privacy in adaptive systems is complex, depending on organizational environment, data collection, and regulations [6].

A third challenge is seamlessly integrating adaptive learning support into existing work environments. Unlike typical adaptive systems that adapt based on interactions within the system itself, WIL must utilize interactions across multiple applications to provide relevant learning support.

### Designing a WIL User Model

User skills can be diagnosed and modeled through explicit elicitation or implicit acquisition [7]. Implicit acquisition involves tracking naturally occurring actions [8] - actions performed without the express purpose of revealing user information, from contacting experts to scrolling pages.

Various approaches have been developed in adaptive systems. Research in adaptive hypertext navigation has produced methods to analyze navigation actions to infer interests and suggest shortcuts [9]. [10] developed an unobtrusive approach for learning user interest profiles through observation.

## Getting to Know Your User – Unobtrusive User Model Maintenance

The problem with traditional approaches is that they cannot easily be re-used for adaptive work-integrated learning. We therefore suggest tackling the challenge of user model maintenance by observing naturally occurring actions of the user [4] which we interpret as knowledge indicating events (KIE). KIE denote user activities which indicate that the user has knowledge about a certain topic. In the context of Laura's scenario the repeated execution of a task user interviews can be seen as a KIE for domain concepts such as structured interviews and card sorting. Another KIE for card sorting could be that Laura has been contacted repeatedly about this topic in the role of an expert. KIE thus are based on usage data.

Our approach is similar to [11], who suggest using attention metadata for knowledge management and learning management approaches. It is also related to the approach of evidence-bearing events (e.g. [12]). So far both approaches have been discussed from a rather technical point of view, e.g. the technological infrastructure necessary to identify and collect attention metadata. Our work provides a holistic framework for the use of KIE for the maintenance of WIL user models: starting with the identification of relevant KIE, their use for updating a WIL user model, and its technical realization through WIL user model services.

In order to interpret KIE an underlying model is needed in the WIL user model which allows relating user actions to knowledge and skills and drawing conclusions on the user's knowledge level. Research into organizational structures identified that many companies create and maintain different types of formal models, so called enterprise models of their work domain [13]. The three most popular models are work domain models (typically represented as an ontology), process or task models (typically represented as a workflow or process model), and competency (or skill) structures (typically represented as a simple list or matrix). Such models provide a comprehensive representation of the whole domain. Based on these insights, we propose to structure the WIL user model as an overlay (for a definition see [5]) of existing enterprise models of the application domain in question.

## Designing WIL User Model Services

Integrating learning support into work practices does not only mean running a WIL system and applications already deployed in organizations side by side, but also the possibility to extend and enrich existing applications. In order to meet this requirement, we propose a service oriented architecture (SOA) approach to WIL user model design and maintenance based on the OASIS reference model[^1]. Firstly, the paradigm of SOAs allows us to split a kaleidoscope of adaptive functionality into different subgroups (services) that can be used independently from each other. Secondly, services can easily be integrated in existing applications which make them especially attractive for the WIL situation. In Laura's scenario their functionality could include: Predicting Laura's performance in the (for her novel) task stakeholder analysis which involves previously mastered domain concepts such as structured interviews; detecting Laura's current learning need based on her missing experience in human activity modeling; and recommending a learning path for how to acquire skills in human activity modeling which is optimized based on her prior experiences. The latter has been seen as a crucial function in the context of work-integrated learning [14].

Despite their advantages, the main limitation of KIE is that they are imprecise and hard to interpret [4]. In order to draw meaningful conclusions based on KIE we propose to use a hybrid approach – utilizing available semantic structures (such as enterprise models) as well as scruffy methods (e.g. heuristics) to interpret the user's actions. These challenges are met with the design of hybrid WIL user model services [15] which maintain and interpret the WIL user model. We have identified four core types of services, covering the basic needs of an WIL environment:

- **Logging services** are responsible for updating the WIL user model with new observed KIE, and thus provide the basis for all other services. Sensors within the WIL environment send detected user activities to logging services to be added to the user model. Pre-processing of incoming user activities are

Here's the cleaned and normalized Markdown:

## The Second APOSDLE Prototype

The aim of the adaptive WIL system APOSDLE is to improve knowledge worker productivity by supporting learning situations within everyday work tasks. The understanding of a user's knowledge level and her learning goals is a central part of the APOSDLE environment. A comprehensive overview of APOSDLE and its functionality has been given in [16]. In this contribution, we only describe the mechanisms that are related to the user model and user model services.

## APOSDLE Enterprise Models

As mentioned above we suggest designing a WIL user model as an overlay of existing organizational models. Within APOSDLE we have chosen to implement three organizational models for one and the same application domain, the domain model, task model and learning goal model. In order to build these models, we have developed a Modeling Methodology [17] which supports the creation of integrated models (instead of separate ones). All three models and the meta-schema are represented in OWL and are stored within a component referred to as the knowledge base.

The purpose of the domain model is to provide a semantic and logic description of the work domain (e.g. requirements engineering) which also constitutes the learning domain of an APOSDLE deployment environment. The domain is described in terms of concepts (e.g. requirements) and relations (e.g. is part of) that are relevant for this domain. Technically speaking the domain model is an ontology that defines a set of meaningful terms which are relevant for the domain and, which are used to classify and retrieve knowledge artifacts.

The objective of the task model is to provide a formal description of the tasks (e.g. human activity modeling) the knowledge worker can perform in a particular domain. The task model identifies and groups tasks and their interdependencies and determines a formalization of patterns and procedures occurring in a business domain. The very core of a process model is a control flow. For the sake of consistency with the domain model, we have also translated the control flow into an OWL ontology.

The learning goal model establishes a relation between the domain model and the task model. It maps tasks of the task model to concepts of the domain model. A learning goal describes knowledge and skills needed to perform a task, with respect to a certain topic in the domain model. For example, the learning goal 'apply card sorting to task user interviews' means that in order to perform user interviews Laura needs to know how to apply the card sorting method. In other words, each learning goal refers to one topic in the domain model. This formalism is necessary for a number of functionalities provided by the APOSDLE user model services. For example, it enables the determination of user skills from past task executions (task-based knowledge assessment, see people recommender service below), or the identification of a user's learning need within a certain task (see learning need service below). Within APOSDLE, the formalisms employed for achieving these functionalities are based on competence-based knowledge space theory (e.g. [18]) which is based on Doignon & Falmagne's knowledge space theory [19]. Competence-based knowledge space theory is a framework that formalizes the relationship between overt behavior (e.g. task performance) and latent variables (knowledge and skills needed for performance) and that has several advantages for WIL environments. One such advantage is that the mappings afford the computation of prerequisite relationships between learning goals (see e.g. [20]). This allows us to identify learning goals which should be mastered by the user on the way to reaching a higher level learning goal.

## APOSDLE Workflow

In the second APOSDLE prototype, recommendations of learning goals, (learning) material, and knowledgeable colleagues are always provided depending on a user's current work task. Since here we do not have a learning system as the central application but integrated into the work environment, we need a way of observing what users are doing in order to identify their current task (and potentially other KIE). In APOSDLE, this task detection is realised by a specialized agent [21]. This agent observes the user interactions (e.g

Here's the cleaned Markdown:

## APOSDLE User Model Services

The APOSDLE system provides service implementations for all types of WIL user model services proposed previously. Figure 1 presents an overview of APOSDLE user model services and how data is exchanged with the user model and corresponding APOSDLE client applications.

The APOSDLE system implements two different logging services. The work context logging service is dedicated to collect executions of tasks corresponding to the task model (delivered from the task detection agent). Logging information consists of a user identifier, a task identifier and an optional timestamp (depends on privacy settings). The second logging service, resource activity logging service collects all activities related to resources presented to users. Such actions are reading documents, engaging in learning events, or contacting another user. Both services receive their data from work context observation components running on the APOSDLE client Applications. Incoming data is transferred into the required format of the APOSDLE user model and stored in a database backend. Taking the scenario introduced in Section 1, the work context logging service would update the user model with Laura's current task (human activity models). Other actions she might do while performing the task are logged by the resource activity logging service.

In order to allow users to examine the information WIL services have gathered, APOSDLE offers two production services. The usage data history service delivers a history of task executions and all resource-based actions. The output of this service is basically a history of all events including all KIEs. Another feature is that relations between events are also preserved. It provides a way to visualize which steps users have undertaken when executing a certain task. It also features a more in depth view into data generated by different services. The usage data history service can for example provide an overview how learning goals evolved over time based on tasks users have executed. The usage data history service in our scenario provides Laura with an overview about the knowledge the user model assumes she has acquired about her current task. It could also help her to get to know people who have been recommended to her by an inference service (by showing her a top ten list of performed tasks for a recommended user).

The evaluation service is another kind of production service. It is specially designed to export different aspects of usage data for evaluation outside the APOSDLE system. In APOSDLE this service generates files containing detailed information about task executions, system usage, and information from inference services.

As one of the most important inference services the learning need service allows computing a learning need for a user. Its design is driven by the goal to support knowledge workers based on their knowledge level. A user's learning need is inferred in three steps:

1. Starting with the user's current task, the user model is queried to retrieve the required learning goal vector r for this task. The vector r represents for all learning goals of the domain whether or not they are required to perform certain task. The user model is again queried with the required learning goal vector as parameter to retrieve the current knowledge levels vector k for the user. The vector k consists of numeric counters for all learning goals of the domain. Each counter represents the knowledge gained by a user for a learning goal. The higher the count the more knowledge has been gained.

2. Step two calculates the knowledge gap a user might have for a certain task. A knowledge gap vector g is obtained by normalizing the current knowledge levels vector k and subtracting it from the required learning goal vector r. The resulting vector g provides knowledge levels ranging from 0 (learning goal might have been reached, great experience) to 1 (learning goal was not addressed until now, less to no experience).

3. The third step generates the learning need based on the knowledge gap calculated in step two. The less experience a user has acquired for a learning goal (low value in g), the higher the rank of the learning goal. The 'most required' learning goal is therefore listed on the top of the learning need. The learning need is used by the APOSDLE system in two ways. An application running in the working environment of the user visualizes the result as a ranked list. The first learning goal is automatically pre-selected, which invokes an information retrieval service to find resources relevant for the learning nee

Here's the cleaned Markdown:

## Getting to Know Your User – Unobtrusive User Model Maintenance

The Learning Need Service recommends learning goals helping her to accomplish the task human activity modelling. Based on these learning goals an information retrieval system provides her with resources previously created within the organization. The Learning Need Service also provides other services with current knowledge levels of users. This feature is utilized for example by the people recommender service described below as basis for its inferences.

The people recommender service aims at finding people within the organization which have expertise related to the current learning goal of the user. This service provides similar functionality as the expert finding systems described in [22]. Users specialised in certain topics are represented in the user model with high knowledge levels for these topics. Other users can now individually be provided with colleagues having equal or higher experience. Compared to the MetaDoc system [23] this service uses a more dynamic way of identifying experts. Knowledgeable users are identified by comparing the current knowledge levels vectors of all users with the knowledge level vector of the user who will receive the recommendation. To infer knowledgeable users, the people recommender service utilises the Learning Need Service to retrieve current knowledge levels vectors for all users. The next step removes all users with lower knowledge levels compared to the user receiving the recommendations. The remaining users are then ranked according to their knowledge levels in the current knowledge level vectors. The most knowledgeable user will be ranked highest. The service can be configured to use the availability status of users as ranking criteria. This setting allows recommending only users currently available. Moving back to the scenario the people recommender service recommends a list of people within Laura's organization who are more experienced in human activity modelling than the service assumes Laura currently is.

APOSDLE implements two control services. The usage data control service allows users to modify and delete any usage data. APOSDLE clients present users with a task history provided by usage data history service, and invoke the usage data control service to delete task executions selected by users. A dedicated privacy component (part of the APOSDLE server) also accesses this service to enforce certain privacy policies on usage data.

The APOSDLE environment is implemented as a Java client-server architecture applying the SOA paradigm to structure the server functionality into services. A dedicated component on the server exposes all services as web services. Client applications [24] can connect to one or more services depending on the features needed. Within in the server, all services are connected to one or more components implementing the actual functionality. All user model services run independently and communicate with the user model or other services using their exposed interfaces. In the second APOSDLE prototype orchestration is done by manually specifying for each service, where other services are located.

## Related Systems

Throughout the previous sections we have discussed related research with respect to our research approach. In this section we provide a short overview of other research projects dealing with related user modelling architectures. As we are not aware of any adaptive learning systems specifically dedicated to WIL, we shortly discuss similar approaches in the area of adaptive e-learning and compare them to APOSDLE.

KnowledgeTree [12] is a distributed architecture for adaptive e-learning separating its functionality into different servers and services. As APOSDLE, KnowledgeTree utilizes a centralised, event-based user model to track student activities. Adaptations of functionality and content are separated from the user model into servers (similar to the APOSDLE user model services). A main difference exists in the way how user events are collected. KnowledgeTree collects usage data from users interacting with web sites (portals) providing, e.g. learning courses about programming. APOSDLE does not provide dedicated sites to record data, but focuses on collecting usage data from the users' working environments. Following this approach APOSDLE is open to a large set of data sources (applications) providing input to refine user models.

ELENA [25] is another architecture providing personalized support for learners by following the paradigm of a service-oriented architecture. ELENA describes its services very detailed in an ontology and uses several interoperability standards. ELENA integrates all services into a

Here's the cleaned Markdown:

## Knowledge-Intensive Experience (KIE) Studies

The outcomes of these studies, while not generalizable due to several limitations, provide valuable input for further development of the APOSDLE user model and the KIE approach. Limitations include:
- Questionable validity of external criteria in study (i)
- Non-authentic user behavior in study (ii)
- Low number of participants in study (iii)
- Use of students in lab settings rather than workers in workplaces for studies (i) and (iii)

### Study I: Algorithm Comparison

A paper-based lab study was conducted with 17 students in requirements engineering to compare different user model updating algorithms based on task performance. The study used three criteria:
- Self appraisal
- Supervisor appraisal
- Personal learning need assessment

Self-appraisal was included to evaluate its potential use in realistic Work-Integrated Learning (WIL) settings where performance tests are impractical. Results showed low correlation between predicted and self-assessed task performance, though this might be due to the criterion variable's low validity. No definitive conclusions could be drawn about the algorithms' usefulness for the APOSDLE user model.

### Study II: Learning Goal Rankings

The second APOSDLE prototype suggests ranked learning goals based on current work tasks, offering different learning activities (reading text, performing learning events, or contacting people). The study analyzed log data from 35 users across four application domains, with at least 8 users per domain.

The hypothesis predicted correlation between a learning goal's rank position and learning activity frequency - higher-ranked goals should see more frequent activity. Results showed low correlations, but this may be due to non-authentic user behavior as participants explored the system rather than using it regularly for work.

Key findings:
- Task-based user model maintenance is sensitive to misuse
- Casual system exploration or unintentional clicks can lead to inappropriate user models and rankings
- Future development should use more reliable input data beyond simple task clicks
- Suggested improvements include:
  - Adding time conditions between task clicks (e.g., 10-second minimum)
  - Incorporating additional KIE indicators like learning activity completion

### Study III: User Observation

The final study observed and interviewed 5 students learning statistical data analysis with APOSDLE.

## Getting to Know Your User – Unobtrusive User Model Maintenance

## Effects of Learning Goal Ranking

The aim was to investigate the effects of the learning goal ranking on the actual performance of users in realistic tasks which they were not able to solve before the study (pre-test). In the pilot study, control groups were used to compare three different versions of the ranking algorithm:

- The ranking algorithm as designed for APOSDLE (taking into account both the requirements of the task and the knowledge of the user)
- A shuffled list of learning goals required for the task at hand (taking into account the requirements of the task but not the knowledge state of the user)
- A set of randomly selected learning goals (neither taking into account requirements of the task, nor the knowledge state of the user)

Each participant had to solve three different tasks, one for each version of the algorithm. With versions (a) and (b), the previously unknown tasks could be solved by all participants, whereas the task could be solved by none of them when algorithm (c) was applied. Additionally, a slight difference in the users' behavior was found between versions (a) and (b): In case of version (a), users by tendency selected less learning goals and more frequently carried out learning activities for learning goals on the top of the list in comparison with version (b) of the ranking algorithm. This serves as a first indicator that the ranking algorithm is useful. Of course, further experimentation with larger samples is needed.

## Conclusion and Outlook

This contribution presents our approach to user model design based on KIE for WIL environments in which unobtrusive assessment of user's knowledge levels is essential. A variety of hybrid user model services operate on this user model in order to add observed KIE, to provide its information (possibly in a filtered and aggregated manner) to other WIL applications, to infer knowledge levels and learning needs, and to allow users to examine and adapt their user model data. The APOSDLE environment serves as a reference implementation of the concepts proposed.

In APOSDLE's first and second prototypes, the maintenance of the user profile was solely based on past tasks performed. While there is some evidence that in fact most learning at the workplace is connected to performing a task, and that task performance is a good indicator for available knowledge in the workplace, this restriction to tasks performed certainly limits the types and number of assessment situations that are taken into account. It is evident that a user's knowledge and skills do manifest themselves through other types of user interactions with the WIL system. For example, a user who seeks help while performing a task might be in a different knowledge state than a user who provides help to others. Additionally, the tasks a user performs may be driven by organizational constraints or simply by task or job assignments and they may therefore only draw a partial picture of the knowledge and skills a user has available. Moreover, in study (ii) the approach of using task as the only basis for user model maintenance has turned out to be extremely error-prone and vulnerable to fallacious user behavior, such as accidentally clicking on tasks, or 'playing around with the system'. In order to improve the knowledge level assessment of the APOSDLE environment we are currently working on including a variety of different KIE such as collaboration events and document creation. In addition, we also plan to incorporate negative KIE, such as unsuccessful task executions. In doing so, instead of inferring the minimum competency state, i.e., competencies a worker has available at the minimum, the 'real' competency state of a worker could be approximated.

## Acknowledgements

APOSDLE is partially funded under the FP6 of the European Commission within the IST Workprogramme (project number 027023). The Know-Center is funded within the Austrian COMET Program - Competence Centers for Excellent Technologies - under the auspices of the Austrian Federal Ministry of Transport, Innovation and Technology, the Austrian Federal Ministry of Economy, Family and Youth and by the State of Styria. COMET is managed by the Austrian Research Promotion Agency FFG.

## References

1. Lindstaedt, S.N., Ley, T.,

## Adaptive Navigation Support for Parameterized Questions in Object-Oriented Programming

I-Han Hsiao, Sergey Sosnovsky, and Peter Brusilovsky  
School of Information Sciences, University of Pittsburgh, USA  
{ihh4,sas15,peterb}@pitt.edu

## Abstract

This paper explores the impact of adaptive navigation support on student work with parameterized questions in the domain of object-oriented programming. In the past, we developed QuizJET system, which is able to generate and assess parameterized Java programming questions. More recently, we developed JavaGuide system, which enhances QuizJET questions with adaptive navigation support. This system introduces QuizJET and JavaGuide and reports the results of classroom studies, which explored the impact of these systems and assessed an added value of adaptive navigation support. The results of the studies indicate that adaptive navigation support encourages students use parameterized questions more extensively. Students are also 2.5 times more likely to answer parameterized questions correctly with adaptive navigation support than without such support. In addition, we found that adaptive navigation support especially benefit weaker students helping to close the gap between strong and weak students.

**Keywords**: adaptive navigation support, parameterized quizzes, self-assessment, object-oriented programming.

## 1 Introduction

Parameterized questions and exercises emerged as an active research area in the field of E-Learning. This technology allows generating many objective questions from a relatively small number of templates created by content authors. Using randomly generated parameters, every question template is able to produce many similar, yet sufficiently different questions. As demonstrated by a number of projects such as CAPA, WebAssign, EEAP282, Mallard, parameterized questions can be used effectively in a number of domains allowing to increase the number of assessment items, decrease authoring efforts, and reduce cheating.

The work of our research group focused on exploring the value of parameterized questions in the area of computer programming. We have developed and explored QuizPACK, a system which is able to generate and assess parameterized questions for C programming. Unlike the majority of modern system for automatic assessment of programming exercises, which focus on program-writing exercises, QuizPACK focused on program-tracing questions. This kind of questions is known as very important, however there are almost no question generation and assessment

[References section appears to be incomplete in the original text]

## Adaptive Navigation Support for Parameterized Questions

Systems like QuizPACK can work with parameterized questions. QuizPACK was evaluated in classroom studies that confirmed the educational value of this technology [1, 10]. We found that parameterized questions can be successfully combined with adaptive navigation support. Using adaptive navigation support to guide students to the most appropriate questions increased their ability to answer correctly and encouraged more extensive system use, which positively impacted their knowledge [11].

While we confirmed the value of adaptive navigation support for parameterized questions in several studies, our earlier research left some questions unanswered. First, parameterized questions in C programming were not as diverse in complexity as questions in other areas like physics [2]. It remained unclear whether adaptive navigation support could work across a broader range of question difficulties. Second, due to decreased C programming class sizes, we couldn't separately assess this intelligent guidance technology's impact on stronger versus weaker students, an important research question.

To address these questions, we expanded our work to the more sophisticated domain of object-oriented Java programming, now the language of choice in most introductory programming classes. This domain allows us to introduce questions of broader complexity and explore our ideas in larger classes. Building on our QuizPACK experience, we developed QuizJET (Java Evaluation Toolkit) to support authoring, delivery, and evaluation of parameterized Java questions [12]. A preliminary evaluation showed parameterized questions work well in this domain - we found significant relationships between:
- Student work amount in QuizJET and their performance
- QuizJET usage and improved weekly quiz scores
- Success rate in QuizJET and final exam scores

This paper presents results from our second study of parameterized questions for object-oriented Java programming. The study aimed to assess the added value of adaptive navigation support for parameterized questions in this domain. Beyond exploring this technology combination in a new domain, we specifically examined:
- The impact of adaptive navigation support on student work with questions of different complexity
- The technology's impact on weaker versus stronger students

We compared parameterized questions' impact in two introductory Java programming classes with the same instructor, syllabus, and student cohort (undergraduate information science students at the University of Pittsburgh). One class used QuizJET while the other used JavaGuide - QuizJET enhanced with adaptive navigation support service QuizGuide [13, 14]. The following sections present the QuizJET and JavaGuide systems and report our classroom study results, concluding with a summary and discussion of future work.

## QuizJET: Parameterized Questions for Object-Oriented Programming in Java

QuizJET was developed to explore parameterized questions in the challenging domain of object-oriented programming. It supports authoring, delivery and evaluation of parameterized questions for Java programming language, covering topics from Java basics to advanced concepts like objects, classes, polymorphism, inheritance, and exceptions.

[Figure 1: The presentation (top) and the evaluation results (bottom) of a QuizJET question]

## Adaptive Navigation Support for Parameterized Questions

## QuizJET Delivery Component
The delivery component of QuizJET allows students to access each question pattern through a Web browser using a unique link (in original QuizJET, these links were included into the course portal). Once a link to the question is accessed, QuizJET generates a unique instantiation of the question (Figure 1), which features a small Java program. The student's challenge is to mentally execute the program and answer a question such as: "What will be the final value of the specific variable?" or "What will be printed in the console window?" 

A tabbed interface design supports straightforward access to the full code of the problem, one Java class per tab. The driver class named Tester Class, containing the main function, is presented on the first tab, while other tabs show supporting classes (such as BankAccount in Figure 1). The tabbed arrangement uniquely characterizes object-oriented programming where even simple object-oriented program may require one or more imported classes.

To answer a question, students fill the answer in the input field and hit Submit. The system immediately reports the evaluation results and the correct answer (Figure 1, bottom). Whether their results were correct or not, students can hit the Try Again button to assess the same question pattern with different parameters. This function helps students achieve mastery of the topic. While it looks relatively simple from user's point of view, this functionality is supported by sophisticated authoring (performed with a separate authoring component), generation, and evaluation mechanisms, which are described in [12].

## JavaGuide: Adaptive Navigation Support for QuizJET Questions
JavaGuide is an adaptive hypermedia system, which provides adaptive navigation support for QuizJET questions. It is not a part of QuizJET, but an independent system, which simply hosts links to QuizJET questions and guides the students to most appropriate links using adaptive link annotation. In this sense, JavaGuide offers an alternative ways for students to access the same set of QuizJET questions. A student may choose to go through a regular course portal, select one of the lectures, and choose one of the questions, which a teacher posted to this lecture. Alternatively, a student can go to JavaGuide and select a question with the help of adaptive navigation support. The question presentation and evaluation processes are the same in JavaGuide and "plain".

The interface of JavaGuide consists of the quiz navigation area and the quiz presentation area (Figure 2). Navigation area provides the hyperlinks to QuizJET questions, which are grouped into topics. By clicking on the topic name, a user can expand or collapse questions for the topic. A click on a question loads the question into the quiz presentation area. To assist students in navigating to the appropriate topics and questions the links to each topics are annotated with an adaptive icon.

JavaGuide uses "target-arrow" annotations mechanism of QuizGuide [13], which has been successfully used in a number of C-programming courses [13, 14]. Each adaptively generated target icon expresses two layers of meanings: knowledge adaptation and goal adaptation. For knowledge adaptation, a topic-based modeling is adopted. Each topic contains several educational activities which identified by the course instructor. Student progress with these activities defines the user understanding of the topic. The number of arrows in the target represents the growth of student knowledge of the topic. Goal adaptation is supported by a time-based mechanism which presents the relevant topics according to course lecture sequence. The color of the target expresses the relevance of the topic to the current course goal. The icon for the current topic is shown as bright blue, its prerequisites are light blue, while target icons for other earlier topics are gray. A crossed icon indicates that the student is not ready for the topic yet.

It is easy to notice that JavaGuide annotation approach integrates prerequisite-based adaptation that advises whether an item is ready or not ready and progress-based annotation that displays the amount of knowledge already acquired by the student. Both approaches are relatively popular and well explored in adaptive educational hypermedia. For example, prerequisite-based approach is used in AHA [15], ELM-ART [16] and KBS

Here's the cleaned Markdown:

## Adaptive Navigation Support for Parameterized Questions

## Basic Statistics

In both classes, student work with the systems was analyzed on two levels: overall and within a session. On each level we explored following performance parameters: Attempts (the total number of questions attempted by the student), Success Rate (the percentage of correctly answered questions) and Course Coverage (the number of attempts by the student for each distinct topic; the number of distinct questions attempted by the student). In addition, we decided to examine all performance parameters separately for students with weak and strong starting knowledge of the subject. This decision was guided by the results of earlier research [19, 20], which demonstrated that the starting level of knowledge of the subject may affect the impact of adaptive navigation support on student performance. To achieve this separation, the students were split into two groups based on their pre-test scores (ranging from a minimum of 0 to a maximum of 20).

Table 1 compares student performance in QuizJET and JavaGuide. Strong students scored 10 or higher points in the pre-test and weak students scored less than 10 points. The table shows active use of the JavaGuide by both strong and weak students. It also indicates a remarkable increase of all performance parameters in the presence of adaptive navigation support. These results confirm that the impact of adaptive navigation support on student performance, which was originally discovered in the domain of C programming, is sufficiently universal to be observed in a different domain and with a larger variety of question complexity.

### Table 1. System Usage Summary

|   | parameters | JavaGuide (Fall 2008) | | | QuizJET (Spring 2008) |
|---|------------|----------------------|-------|-------|-------------------|
|   |            | Strong (n=5) | Weak (n=17) | All Users (n=22) | All Users (n=31) |
| Overall User Statistics | Attempts | 131.2 | 123.82 | 125.50 | 41.71 |
|  | Success Rate | 58.87% | 58.20% | 58.31% | 32.15% |
|  | Distinct Topics | 11.00 | 12.00 | 11.77 | 4.94 |
|  | Distinct Questions | 41.60 | 47.53 | 46.18 | 17.23 |
| Average User Session Statistics | Attempts | 29.82 | 30.51 | 30.34 | 21.50 |
|  | Distinct Topics | 2.50 | 2.95 | 2.85 | 2.55 |
|  | Distinct Questions | 9.45 | 11.71 | 11.16 | 8.88 |

## The Impact of Guidance on Student Work with Questions of Different Complexity

Our next goal was to explore the significance of the obtained data and to explore the impact of adaptive navigation support on user work with questions of different complexity. To do that, all questions were categorized into 3 complexity levels (Easy, Moderate and Hard) based on the number of involved concepts (which in ranged from 4 to as far as 287). A question with 15 or less concepts is considered to be Easy, 16 to 90 as Moderate, and 90 or higher as Hard. In total, both systems included 41 easy, 41 moderate, and 19 hard questions. We conducted two separate 2 × 3 ANOVA to evaluate student performance measured by Attempts and Success Rate within two different systems and three complexity levels. The means and standard errors for each group are reported in Table 2.

### Table 2. Means and standard error of Attempts and Success Rate, by system and complexity level

| DV | Complexity Level | QuizJET (2008Spring) (n=31) | JavaGuide (2008Fall) (n=22) |

Here's the cleaned and normalized Markdown:

## Adaptive Navigation Support for Parameterized Questions

## Impact Analysis of Different Complexity Levels

Fig. 3 shows the total Attempts (left) and the Success Rate (right) of two systems on different complexity levels.

The prerequisite-based guidance of JavaGuide prepared students to face complex questions by exploring easier ones, with attempts more than three times larger in the JavaGuide group.

## The Impact of Guidance on Weak and Strong Students

Students were categorized as strong if they had 10 or more points on pre-test and as weak otherwise. Strong students had a significantly higher Success Rate with the QuizJET system than weaker students, F(1, 87) = 4.760, p = .032, partial η2 = .052. However, no significant differences were found between strong and weak students' Success Rate with the JavaGuide system, F(1, 60) = .007, p = .931, partial η2 < .001.

With adaptive navigation support, both strong and weak students achieved similar performance on each complexity level of quizzes. Without such support, there was a greater gap between strong and weak students. Analysis of Attempts per question revealed that weak students using JavaGuide had significantly higher Attempts on easy questions compared to QuizJET, F(1, 147) = 7.658, p = .006, partial η2 = .050, while stronger students using JavaGuide had significantly higher Attempts on harder quizzes, F(1, 147) = 4.089, p = .045, partial η2 = .028.

Figure 4 shows the pattern of differences between strong and weak students on various complexity levels for the two systems. The means and standard errors for each group are reported in Table 3.

## Subjective Evaluation

End-of-semester questionnaires revealed:
- 97.37% strongly agreed or agreed the system should be used again
- 91.12% considered self-assessment quizzes contributed to their learning
- 71.71% thought online self-assessment quizzes provided useful feedback
- 23% requested future systems for handheld computers

## Summary and Future Work

The results demonstrated that adaptive navigation encourages more extensive use of parameterized questions and significantly increases success rates. Students were 2.5 times more likely to answer correctly with adaptive navigation support. The system effectively guided both strong and weak students to appropriate quizzes, contributing to uniformly high success rates.

Students perceived the online self-assessment quizzes as helpful, though about a quarter considered feedback lacking. Future work will investigate differences between C and Java self-assessment quizzes and conduct more exhaustive system evaluations.

### Acknowledgments

This material is based upon work supported by the National Science Foundation under Grant No. 0447083.

### References

1. Brusilovsky, P., Sosnovsky, S.: Individualized Exercises for Self-Assessment of Programming Knowledge: An Evaluation of QuizPACK. ACM Journal on Educational Resources in Computing 5(3) (2005)
2. Kashy, E., Thoennessen, M., Tsai, Y., Davis, N.E., Wolfe, S.L.: Using networked tools to enhanse student success rates in large classes. In: 27th ASEE/IEEE Frontiers in Education Conference, Pittsburgh, pp. 233-237 (1997)
3. Titus, A.P., Martin, L.W., Beichner, R.J.: Web-based testing in physics education: Methods and opportunities. Computers in Physics 12, 117-123 (1998)
4. Merat, F.L., Chung, D.: World Wide Web approach to teaching microprocessors. In: Frontiers in Education Conference, Pittsburgh, PA (1997)
5. Graham, C.R., Swafford, M.L., Brown, D.J.: Mallard: A Java Enhanced Learning Environment

Here's the cleaned Markdown:

## References

8. Ala-Mutka, K.M.: A survey of automatic assessment approaches for programming assignments. Computer Science Education 15(2), 83-102 (2005)

9. Lister, R., Adams, E.S., Fitzgerald, S., Fone, W., Hammer, J., Lindholm, M., McCartney, R., Moström, J.E., Sanders, K., Seppälä, O., Simon, B., Thomas, L.: A multi-national study of reading and tracing skills in novice programmers. ACM SIGCSE Bulletin 36(4), 119-150 (2004)

10. Sosnovsky, S., Shcherbinina, O., Brusilovsky, P.: Web-based parameterized questions as a tool for learning. In: World Conference on E-Learning, pp. 309-316. AACE (2003)

11. Brusilovsky, P., Sosnovsky, S., Yudelson, M.: Addictive links: The motivational value of adaptive link annotation in educational hypermedia. In: Wade, V.P., Ashman, H., Smyth, B. (eds.) AH 2006. LNCS, vol. 4018, pp. 51-60. Springer, Heidelberg (2006)

12. Hsiao, I., Brusilovsky, P., Sosnovsky, S.: Web-based Parameterized Questions for Object-Oriented Programming. In: E-Learn 2008. AACE, Las Vegas (2008)

13. Brusilovsky, P., Sosnovsky, S., Shcherbinina, O.: QuizGuide: Increasing the Educational Value of Individualized Self-Assessment Quizzes with Adaptive Navigation Support. In: Nall, J., Robson, R. (eds.) World Conference on ELearning, E-Learn 2004, Washington, DC, USA, pp. 1806-1813 (2004)

14. Brusilovsky, P., Sosnovsky, S., Yudelson, M.: Adaptive Hypermedia Services for E-Learning. In: Proceedings of Workshop on Applying Adaptive Hypermedia Techniques to Service Oriented Environments at the Third International Conference on Adaptive Hypermedia and Adaptive Web-Based Systems, Eindhoven, the Netherlands (2004)

15. De Bra, P., Calvi, L.: AHA! An open Adaptive Hypermedia Architecture. The New Review of Hypermedia and Multimedia 4, 115-139 (1998)

16. Weber, G., Brusilovsky, P.: ELM-ART: An adaptive versatile system for Web-based instruction. International Journal of Artificial Intelligence in Education 12(4), 351-384 (2001)

17. Henze, N., Nejdl, W.: Adaptation in open corpus hypermedia. International Journal of Artificial Intelligence in Education 12(4), 325-350 (2001)

18. Grigoriadou, M., Papanikolaou, K., et al.: INSPIRE: An INtelligent System for Personalized Instruction in a Remote Environment. In: Third workshop on Adaptive Hypertext and Hypermedia, Sonthofen, Germany, Technical University Eindhoven (2001)

19. Merat, F.L., Chung, D.: World Wide Web approach to teaching microprocessors. In: Frontiers in Education Conference, Pittsburgh, PA (1997)

20. Brusilovsky, P.: Adaptive navigation support in educational hypermedia: the role of student knowledge level and the case for meta-adaptation. British Journal of Educational Technology 34(4), 487-497 (

## Automated Educational Course Metadata Generation

## Introduction

Our goal is to support the adaptive educational course authoring by the means of knowledge discovery techniques. In this paper we propose a method of automated metadata generation by revealing semantics hidden within the text. We show that generated metadata are useful for e-learning needs, especially for recommendation. Furthermore, the teacher's effort is reduced since we are able to create promising number of concepts and relationships automatically.

The work related to metadata generation in the area of adaptive e-learning by means of knowledge discovery is presented in [5]. Concept similarities are computed based on the comparison of concept's domain attributes. In contrast to our meaning, the concept in [5] also holds textual representation. This should be considered as intentional description, but then the reusability of such concepts is arguable. We are not aware of any other approaches to automated concept relationship generation in the adaptive e-learning field.

Finding relations between concepts is a subtask of the ontology learning field. Relations are induced based on linguistic analysis relying on preceding text annotation [2], incorporating formal concept analysis [3] or using existing resources such as WordNet [4]. The drawback of the approaches is the dependency on precise linguistic analysis. They rely on lexico-syntactical annotations, powerful POS taggers, existing domain ontologies, huge corpuses or external semantic resources. Such knowledge is often not available during e-course authoring. The solution for content authors should involve unsupervised approaches to unburden them from additional work. This need we address in the method we propose.

The task of structuring the concept space is also present in the area of topic maps. In this field the topics can be consider analogical to concepts. Authors in [6] generate relations between topics by analyzing the HTML structure of Wikipedia documents. Categorization methods are used in [8] where similar topics are discovered by latent semantic indexing (LSI) and K-means clustering. Unsupervised methods serve as guidance in topic ontology building. A similar approach is missing in the area of adaptive e-learning. Hence, our method is based on statistical unsupervised text processing and knowledge discovery.

## Method Description

The goal of the proposed method is the automated creation of the domain model. The metadata are created automatically under the adaptive course author's (i.e., teacher's) supervision. Thus, his effort in the authoring process is reduced. Automated steps include concept extraction and relationship discovery.

### Learning Objects Preprocessing

At the beginning we create the representation of learning objects relevant for further processing. We utilize a vector space model (VSM) based on the so-called term relevance which is the degree of importance of the term in the text (learning object). Beside the term frequency it comprises also other qualitative characteristics of the term. Learning objects preprocessing steps are as follows:

- Vector representation composition. In this step we perform a lexical analysis of learning objects. Lexical units – tokens – are identified. We remove stop words having almost no semantic significance. Then we retrieve token's lemmas – canonical forms. From lemmas we compose vectors containing term frequencies. In this moment we have the standard bag-of-words model.

- Vectors adjustment. In this step we tune up the actual vectors weights (relevance) considering factors not related to the learning object content. The adjustment consists of two steps: (1) available index processing, (2) formatting processing. An index of domain keywords is often available in a learning environment (in textbooks, as course outcomes, etc.). We increase the relevance of such terms by multiplying it with coefficient empirically set to 5.0. Formatting processing covers the relevance adjustment according to formatting in source document. We utilize the rules similar to ones presented in [6] in this step.

### Pseudoconcepts Extraction

After the preprocessing step the representation allowing concept candidates – pseudoconcepts extraction is prepared. This step consists of three substeps:

- Relevant domain terms (RDT) selection. From the set of all learning object terms we select only those whose relevance exceeds a particular threshold k, empirically set to be equal to coefficient increasing the relevance of domain keyword. This way we find terms that represent certain semantic potential

Here's the cleaned Markdown:

## Concept-to-concept similarity computation

For this step we proposed and experimented with three concept-to-concept similarity computation variants: vector approach, spreading activation and PageRank-based analysis. Each variant of similarity score computation provides a unique view of the actual domain model state and employs a specific approach to knowledge discovery. Detailed description is beyond the scope of this paper and can be found in [9].

## Most relevant neighbors selection

Finding the appropriate number of relevant neighbors is important for the generated domain model quality. In our experiments we select neighbors that accumulate m% of the sum of all neighbors' similarity scores to a given concept.

## Experimental Evaluation

We evaluated the proposed method in the domain of programming learning on the functional programming course. We performed the adaptive e-course creation process using the CourseDesigner authoring tool which implements the automated metadata generation method. The subject of experiment was a half-term course consisting of 70 learning objects on the functional programming paradigm and programming techniques in the Lisp language. Learning objects were organized hierarchically and represented using the DocBook language.

The resulting course structure was compared to functional programming metadata created manually by a randomly chosen sample of 2007/08 course students. Manual creation of metadata comprised the assignment of weighted values to concept relationships. As assigning continuous values from interval ⟨0; 1⟩ is a non-trivial task, weight values were from {0, 0.5, 1} implying:

- 0 – concepts are not related to each other (no relation)
- 0.5 – concepts are partially (maybe) related to each other ("weak" relation)
- 1 – concepts are highly (certainly) related to each other ("strong" relation)

There were 366 relationships created, 216 were weak and 150 were strong.

Prior to the method application we assumed that the learning objects were loaded into a newly created course. The dictionary of domain keywords was also provided. During the concepts extraction step 76 concepts were extracted. The relationship discovery step was performed separately for each similarity computation variant. Between the 76 concepts 420, 442, and 316 relationships were retrieved respectively (see Fig. 1). To evaluate the obtained results we tracked the number of correct relationships retrieved by the method in relation to the total number of relationships retrieved (precision) and the number of correct relationships retrieved in relationship to the total number of relevant relationships defined manually (recall). To compare the results, we combined both into F-measure which is the weighted harmonic mean of precision and recall.

In order to gain more accurate evaluation, we extended the original recall measure to involve the manually constructed domain model relationship types:

R* = retrieved ∩ (relA ∪ relB) / relA ∪ (relB ∪ retrieved)     (2)

The experiments yielded best results with PageRank-based analysis (F* = 0.652). The analysis of the generated relationships highlighted common NLP problems. None of the relationship discovery variants was able to significantly overcome natural language ambiguities. Less suitable results were obtained among concepts represented by terms occurring frequently, in more than one meaning or diffused over the whole course. A similar problem affected the concepts associated with a small, relatively independent group of learning objects as they were unable to create relevant connections with other semantically related concepts.

A legitimate question is what exactly does the F*-measure indicate in our experiment? We interpret it as the "completeness" of the generated metadata. Throughout the experiment, generated relationships not contained in the manually created relations were considered incorrect. Although manual relationship creators made their best effort to match real-world relations, relationships retrieved automatically need not to be irrelevant. They might represent bindings which were not explicitly realized even by the most concerned authors.

## Conclusions

In this paper we presented an approach to the automated creation of a semantic layer over learning objects in an adaptive educational course. Our goal is

Here's the cleaned Markdown:

## Searching for "People Like Me" in a Lifelong Learning System

Nicolas Van Labeke, George D. Magoulas, and Alexandra Poulovassilis

London Knowledge Lab, Birkbeck, University of London
23-29 Emerald Street, London WC1N 3QS, UK
{nicolas,gmagoulas,ap}@dcs.bbk.ac.uk

### Abstract

The L4All system allows learners to record and share learning pathways through educational offerings, with the aim of facilitating progression from Secondary Education through to Further Education and on to Higher Education. This paper describes the design of the system's facility for searching for "people like me", presents the results of an evaluation session with a group of mature learners, and discusses outcomes arising from this evaluation.

**Keywords**: lifelong learning, learning communities, personalisation.

### 1 Introduction

Supporting the needs of lifelong learners is increasingly at the core of learning and teaching strategies of Higher Education and Further Education institutions and poses a host of new challenges. In particular, face-to-face careers guidance and support has been found to be uneven [1], leading some to consider the role of online support in providing some form of careers guidance [2,3]. Communication and collaboration tools provide new opportunities for exploring the role that social networks and factors play in making career decisions, and for supporting educational choices [4]. The need for better support for lifelong learners, the patchy provision of careers and educational guidance at critical points, and the potential of ICT to support these needs provided the rationale that underpinned the development of the L4All system. We refer the reader to [5] for details of the aims, research and development methodology, technical approach and evaluation of the original system.

In brief, the L4All system aims to support lifelong learners in exploring learning opportunities and in planning and reflecting on their learning. It allows learners to create and maintain a chronological record of their learning, work and personal episodes – their timeline. Learners can share their timelines with other learners, with the aim of encouraging collaborative formulation of future learning goals and aspirations. The focus is particularly on those post-16 learners who traditionally have not participated in higher education. Among this group, social factors are found to have a significant influence on educational choices and career decisions [5].

The L4All user interface provides screens for the entry of personal details, for creating and maintaining a timeline of past and future learning, work and personal episodes, and for searching over courses and timelines made available by other users.

Here's the cleaned Markdown:

## Searching for "People Like Me" in a Lifelong Learning System

This paper describes the design of a new facility which supports personalised searching for timelines of "people like me" (Section 2), summarises the results of an evaluation session held with a group of mature learners (Section 3), and discusses outcomes arising from this evaluation (Section 4).

## Search for Timelines of "People Like Me"

The initial prototype of the L4All system supported several search functionalities over users and their timelines. However, searching over timelines returned matches based solely on the occurrence of specified keywords in one or more episodes of the timeline and did not exploit the structure of the timeline; also, the search results were not personalised to the user performing the search. An alternative approach was needed that could take into account both these issues i.e. some form of comparison between a user's own timeline and the other timelines in the L4All repository.

Similarity metrics offer such a possibility. They have been widely used in information integration and in applied computer science [6,7]. In Intelligent Tutoring Systems, they have been used to compare alternative sequences of instructional activities produced by authors [8]. In our context, our starting point was to encode the episodes of a timeline into a token-based string, and we refer the reader to [9] for details of our encoding method. We also report in [9] on a comparison of ten different similarity metrics that we considered for trialling in the system. For the version of the system that we evaluated as discussed below, four of the metrics were deployed: Jaccard Similarity, Dice Similarity, Euclidean Distance, NeedlemanWunch Distance – see www.dcs.shef.ac.uk/~sam/stringmetrics.html. These are identified as Rule1 – Rule 4, respectively, together with a brief description, in the user interface.

A dedicated interface for the new search for "people like me" facility was designed, providing users with a three-step process for specifying their own definition of "people like me" – see Figure 1. In the first step, the user specifies those attributes of their own profile that should be matched with other users' profiles; this acts as a filter of possible candidates before applying the timeline similarity comparison. In the second step, the user specifies which parts of the timelines should be taken into account for the similarity comparison, by selecting the required categories of episode (there are several categories of episode; some categories of episode are annotated with a primary and possibly a secondary classification, drawn from standard U.K. occupational and educational taxonomies). In the final step, the user specifies the similarity measure to be applied, by selecting the "depth" of episode classification to be considered by the system and the search method i.e. one of Rules 1-4 above.

Once the user's definition of "people like me" has been specified, the system returns a list of all the candidate timelines, ranked by their normalised similarity. The user can select one of these timelines to visualise in detail, and the selected timeline is shown in the main page as an extra strip below the user's own timeline (see Figure 2). The two timelines can be synchronised by date, at the user's choice. Episodes within the selected timeline that have been designated as being public by its owner are visible, and the user can select these and explore their details.

## Evaluation

The aim of this first design of a personalised search for "people like me" was to gather information about usage and expectation from users of such functionality. An evaluation session was undertaken with a group of mature learners on the Certificate in IT Applications at Birkbeck College, organised around three activities.

Activity 1 was a usability study of the extended system, focusing on participants building their own timelines and exploring also other aspects of the system. Activity 2 was an evaluation of the new searching for "people like me" functionality, focusing on participants exploring different combinations of search parameters and reporting on the usefulness of the results returned by the system. Activity 3 was a post-evaluation questionnaire and discussion session.

## Searching for "People Like Me" in a Lifelong Learning System

## Study Design and Implementation
We decided to use the profile and timeline participants had created during Activity 1. Since we couldn't predict participants' profiles and timelines in advance, we provided them with avatars - artificial identities with pre-made profiles and timelines. This allowed us to generate a database of comparable timelines with varying degrees of similarity.

Of the 10 recruited participants, 9 attended (referred to as bbk1-bbk9). They represented diverse learner backgrounds:
- Gender: 3 female, 6 male
- Age: 1 in 20s, 3 in 30s, 4 in 40s, 1 in 50s
- Mean episodes: 3 educational (SD 1.7), 2.75 occupational (SD 2.0), 2.1 personal (SD 1.2)

Activity 1 showed overall satisfaction with core system functionality while identifying usability issues ranging from interface inconsistencies to access difficulties, most of which have been addressed.

## Results and Discussion
Activity 2 fell short of identifying user-centered definitions of "people like me." Most participants simply executed searches without exploring parameter combinations, as initial results seemed adequate. Self-reported satisfaction was low (58% Poor/Mostly Poor). Participants struggled to see the benefits, as noted by bbk3:

> "You need to convey the benefit of finding people with similar timelines; this is CRUCIAL: what does it tell me if I find someone who is like me, based on criteria provided? Can I conclude anything from this? Need to create a set of examples to demonstrate how this timeline comparison is useful"

Two main factors impacted outcomes negatively:
- Limited variability in the generated timeline database
- Difficulty understanding search parameters, especially classification levels and search methods

However, post-activity discussion revealed greater appreciation for the functionality's potential in real contexts. Post-evaluation responses showed only 8% Poor/Mostly Poor ratings, suggesting participants' perspectives evolved after reflection.

## Outcomes and Conclusions
Lifelong learners need support in reflecting on learning and planning future goals. Our evaluation highlighted the need for better support in utilizing similarity search results. While our visualization approach - displaying timelines side-by-side with scrolling and episode access - aids exploration, more proactive support is needed.

Users specifically need help understanding why timelines are deemed similar. Metrics like Needleman-Wunsch enable backtracking similarity computations and showing episode alignments between timelines. This opens possibilities for more contextual timeline matching that could explicitly identify future learning and professional opportunities.

Here's the cleaned Markdown:

## Searching for "People Like Me" in a Lifelong Learning System

Episodes of the target timeline have no match within the user's own timeline and therefore potentially represent episodes that the user may be inspired to explore or may even consider for their own future personal development. We will discuss such a contextualised usage, and its evaluation with two groups of mature learners, in a forthcoming paper.

## Acknowledgments

This work was undertaken as part of the MyPlan project, funded by the JISC Capital e-Learning programme.

## References

1. Bimrose, J., Hughes, D.: IAG Provision and Higher Education. IAG Review: Research and Analysis Phase. Briefing Paper for DfES. University of Warwick (2006)
2. Cogoi, C. (ed.): Using ICT in Guidance: Practitioner Competencies and Training. Report of an EC Leonardo project on ICT Skills for Guidance Counsellors. Outline Edizone, Bologna (2005)
3. Cych, L.: 'Social Networks' in Emerging Technologies for Learning. Coventry. Becta, 32-40 (2006)
4. de Freitas, S., Yapp, C. (eds.): Personalizing Learning in the 21st Century. Network Continuum Press, Stafford (2005)
5. de Freitas, S., Harrison, I., Magoulas, G.D., Mee, A., Mohamad, F., Oliver, M., Papamarkos, G., Poulovassilis, A.: The development of a system for supporting the lifelong learner. British Journal of Educational Technology 37(6), 867-880 (2006)
6. Cohen, W.W., Ravikumar, P., Fienberg, S.E.: A comparison of string distance metrics for name-matching tasks. In: Proc. IIWeb 2003 - Workshop on Information Integration on the Web, at IJCAI 2003, pp. 73-78 (2003)
7. Gusfield, D.: Algorithms on Strings, Trees, and Sequences. Computer Science and Computational Biology. Cambridge University Press, Cambridge (1997)
8. Ainsworth, S.E., Clarke, D.D., Gaizauskas, R.J.: Using edit distance algorithms to compare alternative approaches to ITS authoring. In: Cerri, S.A., Gouardéres, G., Paraguaçu, F. (eds.) ITS 2002. LNCS, vol. 2363, pp. 873-882. Springer, Heidelberg (2002)
9. Van Labeke, N., Poulovassilis, A., Magoulas, G.D.: Using Similarity Metrics for Matching Lifelong Learners. In: Woolf, B.P., Aïmeur, E., Nkambou, R., Lajoie, S. (eds.) ITS 2008. LNCS, vol. 5091, pp. 142-151. Springer, Heidelberg (2008)
10. Van Labeke, N.: Preliminary Evaluation Report, MyPlan Project Deliverable 5.1 (August 2008), http://www.lkl.ac.uk/research/myplan/

## Metadata in Architecture Education - First Evaluation Results of the MACE System

Martin Wolpers¹, Martin Memmel², and Alberto Giretti³

¹ Fraunhofer Institute for Applied Information Technology, Schloss Birlinghoven, D-53754 Sankt Augustin, Germany  
martin.wolpers@fit.fraunhofer.de

² Knowledge Management Department, DFKI GmbH, Trippstadter Str. 122, D-67

## Metadata in Architecture Education

Within the European project MACE (Metadata for Architectural Contents in Europe), we enable to search through and find learning resources that are appropriate for their context in a more discovery oriented way. By automatically and manually linking related architecture learning resources of various non-related repositories with each other, we establish relations among them, that in turn are used to enable new, simple and unified access to architectural learning resources scattered throughout repositories world-wide. Consequently, users are provided with the ability to discover new learning resources that can serve as additional sources of inspiration.

In order to ease the access to relevant learning resources, and to create new connections between learning resources from various repositories, MACE also draws on the communities that use the MACE portal. In particular, users can annotate learning resources with tags, comments and ratings, they can build up personal portfolios, and they participate by contributing new learning resources. This allows for richer descriptions of resources and enables 'social browsing', i.e., new ways to navigate the learning resources. Furthermore, the user's activities are analyzed to establish new relations between learning resources.

This paper reports how the MACE system has evolved over time and the results of first evaluations. Section 2 introduces the MACE system with its new features in the front- and backend, focusing on the relation of learning resources across repository boundaries and cooperative learning through the usage of Web2.0 community features. Section 3 outlines the experimental setup and evaluation. First results indicate that the combination of explorative and cooperative learning significantly improves architectural education at university level.

## The MACE System

This section describes the MACE system in general. It builds on a distributed service oriented architecture with a three-tier structure. The frontend with its graphical user interfaces and widgets support forms the client tier. The business logic that is responsible for the provision of functionalities is organized in the application-server tier while the metadata stores form the data-server or backend tier. Moreover, the MACE system incorporates the ALOE system. While the MACE system is responsible for the overall portal, storage of metadata and basic business logic, the ALOE system specifically deals with participation facilities for end users and the respective data that is generated. The overall architecture and functionality of the MACE system has already been described in [4]. We therefore present here the extensions and reasons thereof to explain the system basis on which the evaluation was carried out.

We highlight the filtered search facility in the frontend, the introduction of a social layer with ALOE, and the distributed backend structure before outlining the evaluation and its results in the following chapter.

### Filtered Search in the MACE Frontend

The MACE portal is online and publicly accessible at http://portal.mace-project.eu/. The portal offers several means to access the contents in MACE, e.g., users can Browse by Classification and conduct a Social Search or Filtered Search.

Figure 1 shows the filtered search portal of the MACE system. Here, the user is able to qualify the keyword search with several additional facets: the repositories in which to search, the language of the results, the resource mediatype, the resource classification, and the associated competency. When choosing a respective facet, the interface is dynamically changing, providing the numbers of results for each facet that match the selected criteria. The results of a submitted query are displayed at the bottom of the page. A small overview for each result is

## Metadata in Architecture Education

## Presenting Search Results and Details
The system presents search results with basic information including resource title, short description, and repository source. Users can either access results directly or view additional metadata on MACE detail pages.

## Introducing a Social Layer with ALOE
MACE focuses on both architectural content and user engagement. Users are encouraged to contribute through:
- Tags, comments, and ratings
- New resources (via MACE bookmarklet)
- Formal classifications
- Community building around content

ALOE is a web-based social media sharing platform that enables:
- Contributing and sharing digital resources
- Uploading or bookmarking via URL
- Social features (tagging, rating, commenting)
- Collection creation and group participation
- Additional metadata association
- Access via UI or Web Service API

### Integrating ALOE in MACE
A dedicated ALOE instance was set up for MACE at DFKI, with components interacting via the ALOE Web Service API. Key integration points include:

- User Management: Synchronized signup/login between MACE and ALOE
- Resource Annotation: Social metadata storage and retrieval
- Resource Contribution: Bookmarklet for user submissions
- Social Search: Tag clouds and keyword search through user content

## The MACE Backend
The backend consists of:

### Application Tier
- Business logic for front-end applications and widgets
- Filtered search, communication, user management
- ALOE system integration

### Data Server Tier
- Metadata stores for learning resources
- MACE domain metadata store using OAI-PMH protocol
- Focus on metadata rather than content storage

The system emphasizes metadata management to provide simplified access to architectural learning resources across repositories.

Here's the cleaned Markdown:

## Metadata in Architecture Education

M. Wolpers, M. Memmel, and A. Giretti

metadata including for example the title, the abstract, the location of the learning resource, but also information about the classification of the learning resource within the MACE classification, relations with other learning objects or competences associated with the learning resource. The complete storage mechanism is described in [7].

### MACE usage metadata store
In addition to the MACE domain metadata store, the MACE system also stores how the users have interacted with the system. The observations, captured as usage metadata, include search and access as well as communication activities. Usage metadata is stored in the contextualized attention metadata (CAM) format [8]. We use usage metadata for a variety of purposes, including support for self-regulated learning, context learning path elicitation.

For self-regulated learning approaches, one main tool is the reflection of learning activities [9] to the learner (and possibly the learning resource author as well.) Within MACE and using usage metadata, we provide a simple time-based overview of activities to enable the support of reflection on the learning path. The learner is able to analyze which learning resources she accessed when, how she found them and which topics have been relevant to her and when. These reflective information can then be used to make learning paths more explicit, e.g. to modify and control them to make learning activities better targeted to the respective learning goals.

Following the ideas on context and context elicitation in [10], we use usage metadata in combination with learning resource domain metadata to identify the context in which a learning resource has been used. Reusing ideas from discourse and text processing [11] we define the pre-context of an action as the (currently time-based) sequence of actions before the respective actions. The post-context is respectively defined as the (currently time-based) sequence of actions after the respective action (see also [12].) The lengths of these sequences as well as the sequence defining element (currently the time) are subject to further experiments.

### MACE application profile
The metadata description is based on an extension of the Learning Object Metadata (LOM) standard [13], thus forming an application profile [14] of LOM. We call it the MACE application profile. Extending the application profile described in [4], we now include classifications, competences, locations and relations. We briefly outline the modifications and reasons thereof in the following paragraphs.

### MACE classifications of learning resources
The (mostly manually conducted) classification of the MACE learning resources enables the intelligent aggregation and linkage of information about them through the classification terms. Expert architects assigned the respective terms from the MACE classification vocabulary [15] to the appropriate learning resources. The group of expert architects will continuously classify new learning resources through an incentive-generating process that continuously motivates the participation and contribution. Incentives are, for example, reputation or revenue, depending on the business model of the MACE system.

The MACE system also allows for competence classifications in addition to the architectural classification. The competence classification distinguished between competences for engineering and architecture, also following the European Qualification Framework. The definition of the Engineering Competences has been based on Dublin Descriptors elaborated by the Joint Quality Initiative network and based on the results of the EUCEET II - European Civil Engineering Education and Training II project that is part of the Tuning Project (2005 - 2006). The definition of the Architecture Competences has been based on Directive 2005/36/EC of the European Parliament and the Council on the recognition of Professional qualifications and Architects' Directive 85/384/EEC.

### Real world objects in MACE
Architectural education relies, apart from theoretical knowledge, on the examination and analysis of buildings and projects realized in the real world. Therefore, the MACE system also needs to be able to represent physical manifestions that we call real world objects (RWO). They are realized as non-information resources (following the W3C recommendation [16]) and therefore are used to bind together learning resources about one specific object or physical manifestation

Here's the cleaned Markdown:

## Metadata in Architecture Education

## Performance Figures

In order to identify the system features that can be related to the learning process a comprehensive scenario analysis was carried out. Seven MACE usage scenarios were identified and a detailed protocol analysis was implemented. The analysis of this amount of data made clear that from the standpoint of the learning support MACE key system features are:

**Searching Tools**: the availability of a variegated set of searching tools allowing for quick searching on topics directly related to the current design focus, providing alternative knowledge paths that reflect the structure of the relevant issues related to the project focus. In a typical fragment, for example, the student notices that the project is located in Paris and decides to search for other buildings in the same city... He uses the location map/widget for his search. The availability of the map widget lets the student straightforwardly enrich the search focus (i.e. Villa dall'Ava) with spatially related projects. From the cognitive perspective, interactions such as this foster the learner's construction of problem oriented knowledge networks, that are at the basis of any learning process. The same can be said for the MACE hierarchy browser, which provides visual cues on semantically related information, allowing the learner to selectively address information sources, and easily access alternatives and/or similarities.

**Focused and structured contents**: the quality (i.e. appropriateness, consistency, soundness, correctness) and the quantity of the provided contents. It is well known that distracting information is one of the main causes hindering the delicate approach to knowledge as it happens on personal e-learning tools. Therefore the availability of focused information in any step of the user-system interaction is mandatory to qualify any information provider as a learning support system.

**Usability**: the effectiveness, the efficiency and the satisfaction with which end-users can reach specific goals in the MACE environment.

**Learning**: the quality of the learning results of common educational tasks supported by MACE compared with the learning results of the same educational tasks, supported by traditional web searching tools.

On this basis an evaluation framework was designed including both subjective and objective analysis:

1. A student profiling questionnaire was administered in order to get the basic information for qualifying the student in terms of the progress in the course of studies, his/her mastery of the English language and of the Internet technology.
2. An evaluation of the system quality perceived by students was implemented by means of questionnaires encompassing the first three points of the analysis.
3. A learning assessment process, comparing students using MACE vs. student working with traditional means in a design task was established to get objective data for pointing out the impact of MACE on the architecture design learning process.

## Evaluation the Perceived Quality of MACE

The model we adopted is based on 4 basic features describing the quality of a learning supporting web environment: content; functionality; usability; accessibility [19]. Hereafter we will detail each of these features, specifying their meaning in the MACE context.

1. **Functionality**: We have evaluated the functionality in terms of students' general interest, information retrieval, usefulness of the special functions, perceived effectiveness in learning support. This feature sums up all the aspects concerning the interaction between MACE and its end-users and reflects the system's functional and conceptual structure.
2. **Content**: We have evaluated the perceived quality of the provided contents in terms of quantity, adequacy, completeness and soundness: Is the quality of the information provided by MACE adequate to users' learning goals? Is the information content of MACE relevant, is it complete, is it reliable?
3. **Usability**: We have evaluated these features in terms of the perceived quality of the information retrieval process, effectiveness of interface design and of the special functions.
4. **Accessibility**: This aspect concerns several points like: Is connectivity adequate? Are availability and power of the server adequate? Is the product browser-dependent or not? Is the web address easy to recall? Is it accessible through the more common search engines? and so on.

The surveying was performed by administering a questionnaire

Here's the cleaned and normalized Markdown:

## The Kiviat Graph Analysis

The Kiviat graph shows that 'usability', which relates mainly to the interface design, scores the highest value. On the contrary, 'contents' scores the lowest value. The 'functionality', that concerns the conceptual structuring of the content organization and of the navigation tools, scores approximately two decimals more than 'contents' and one less than 'usability'. This means that the perceived value of the conceptual structuring of the application domain (i.e. Architecture), that was the principal strategy for supporting meaningful learning during user-system interaction, emerges as one of the most positive values. The lowest score of the 'contents' feature is mostly due, we believe, to the current development status of the project, which in this phase doesn't offer an amount of contents covering all the information need of a typical student design task.

These evaluations reflect a general trend of the MACE system which is independent of the students' affiliation, nationality and, consequently, language. The same Kiviat graphs for the two groups of students of different universities, from Spain and Italy, show that the only significantly varying feature is 'accessibility', which is related to contingent technical parameters like bandwidth etc.

## Assessment of MACE in a Real Learning Process

The third step of the experimentation phase is to quantify and qualify the impact of the MACE system on learning performance. The proposed assessment methodology concerns the project's outcome in terms of the improvement (support and enrichment) of common learning processes in real educational environments.

It is evident that to accomplish this goal, we needed to define experimental strategies and methodologies which were suitable to obtain consistent and useful data. Since MACE is not a complete e-learning platform, but it is limited to information access, the assessment procedure and the impact evaluation was focused on knowledge acquisition rather than on the achievement of a whole competence.

### Experimentation Setup

The proposed MACE assessment methodology is basically an ex-post evaluation. It follows four steps:

1. To present students with real design tasks requiring them to apply relevant knowledge and skills
2. To capture objective usage data of user-system interaction during the information gathering phase through direct observation and system logs
3. To accurately evaluate learning degree by examining the learners' work results
4. To analyze and compare the data logs to correlate the diverse system features to the learning performance

The students were assigned a task that concerns, depending on the course nature and needs, either the investigation of a given subject or the development of a design fragment. In the first case, the students had to prepare of a Power Point presentation (5-10 slides) which illustrated the results of the research/investigation carried out in the classroom. In the second case, the students had to produce a set of drawing and technical documents of their solution.

Both tasks were to be performed in a well defined time span. Timings was defined by the teacher on the basis of the task difficulty and scope. A preliminary questionnaire aimed at evaluating the learners' entry level of competence and experience was filled in by all students before starting the assignment. The evaluation of the students' work was carried out for the whole class, in a blind way, and was based on an evaluation grid made of six items:

- The focus of the work
- The richness of the content
- Consistency of the contents
- Structure of the contents (interrelationships)
- Originality and elaboration level
- Variety of the origins of the contents (repositories)

MACE experimentation started on September 1st, 2008 and will last up until June 30th, 2009, encompassing two semesters organized in three groups of students belonging to three different universities in two European countries.

### Preliminary Results

The results presented in this section concern 40 students belonging to two universities of two different EU countries.

Here's the cleaned Markdown:

## Metadata in Architecture Education

Despite its simplicity, the model allows us to conclude that the MACE students performed better than the reference group. The MACE students' average performance grade is 4.14 while reference group students' is 3.65.

In the following, we will examine if the usage of the MACE system was the strongest conditioning factor or whether other student qualities played a relevant role unintentionally despite students were selected randomly. In order to clarify this aspect, the basic Bayesian model was extended including other key aspects of the students' profile we recorded in the questionnaire administered at the beginning of the experimentation. More specifically the following aspects were taken into account:

1. Student's English level of practice: to test whether the foreign language was an access barrier.
2. Student's domain competences: this is expressed as the number of exams that is proportional to the progress in the curriculum and, on the average, to the competences acquired by the student.
3. The usage level of internet: this capture the students' familiarity with Internet navigation
4. The number of search engines more frequently used: this further specifies the Internet node focusing on searching and browsing

Based on the sensitivity analysis, we can conclude that the positive trend on students' performance observed in the previous model depends essentially on the fact that the students used MACE.

We finally discuss in what sense the MACE system affects students' performance. In order to discuss this, a more complex model that correlates the student's TYPE with the more specific evaluation figures: Consistency, Clearness, Focus, Originality, Structure and Richness of the work and number of Sources used was built. The interpretation is straightforward. There is a positive increment on all parameters' expected values.

In particular the Consistency, the Clearness and the Structure of the work appear to be the qualities that were more affected. The focus of the work is not as affected because it is already close to the maximum of the scale so it is 'saturated'. Sources and Richness register lower increments.

One plausible conclusion, that confirms the results of the previous analysis, is that the MACE information structuring (search interface, taxonomy, visual aids, etc.) performs well, and significantly helps students' meaningful learning. But the MACE system is still lacking a sufficient content base to boost the richness of the students' work.

## Conclusion

This paper briefly presents the new extensions to the MACE system and portal in which we enable access to learning resources from various, highly heterogeneous repositories. Explorative learning styles used in architecture education are supported through new ways of access to learning resources through the unified fully enclosing description of the learning resources. In addition, the MACE social layer enables social browsing and Web2.0 style community functionality.

The evaluation of the MACE portal and subsequently of the MACE system clearly indicates that the targeted provision of learning resources increases the quality of results produced by university students. We conclude that by improving the access to learning resources by addressing the students' needs, students are able to focus on the activity of learning instead of wasting time in finding appropriate learning resources tailored to their needs.

### References

1. Beckmann, J.: Virtual Dimension: Architecture, Representation, and Crash Culture. Princeton Architectural Press (1998)
2. Condotta, M., Ponte, I.D.: Digipolazione architettonica, nuovi software convertiti. Master's thesis, Universita IUAV di Venezia (2002)
3. Marchionini, G.: Exploratory search: from finding to understanding. Commun. ACM 49(4), 41–46 (2006)
4. Stefaner, M., Vecchia, E.D., Condotta, M., Wolpers, M., Specht, M., Apelt, S., Duval, E.: Mace - enriching architectural learning objects for experience multiplication. In: Duval, E., Klamma, R., Wolpers, M.

Here's the cleaned Markdown:

## References

7. Prause, C., Ternier, S., de Jong, T., Apelt, S., Scholten, M., Wolpers, M., Eisenhauer, M., Vandeputte, B., Specht, M., Duval, E.: Unifying learning object repositories in mace. In: Massart, D., Colin, J.N., Assche, F.V. (eds.) LODE. CEUR Workshop Proceedings, vol. 311. CEUR-WS.org (2007)

8. Wolpers, M., Najjar, J., Verbert, K., Duval, E.: Tracking actual usage: the attention metadata approach. International Journal Educational Technology and Society 10(3) (2007)

9. Moon, J.A.: Reflection in learning & professional development. Routledge (1999)

10. Zimmermann, A., Lorenz, A., Oppermann, R.: An operational definition of context. In: Kokinov, B.N., Richardson, D.C., Roth-Berghofer, T., Vieu, L. (eds.) CONTEXT 2007. LNCS (LNAI), vol. 4635, pp. 558-571. Springer, Heidelberg (2007)

11. Kamp, H., Reyle, U.: From Discourse to Logic: Introduction to Model-theoretic Semantics of Natural Language. In: Formal Logic and Discourse Representation Theory (Studies in Linguistics and Philosophy). Springer, Heidelberg (1993)

12. Manning, C., Schuetze, H.: Foundations of Statistical Natural Language Processing. MIT Press, Cambridge (1999)

13. of Electrical, I., Committee, E.E.L.T.S.: IEEE standard for learning object metadata (draft). IEEE standard 1484.12.1 (2002)

14. Duval, E., Hodgins, W., Sutton, S., Weibel, S.L.: Metadata principles and practicalities. D-Lib Magazine 8(4) (April 2002)

15. Niemann, K., Wolpers, M.: Modeling vocabularies in the architectural domain. In: ICDIM, pp. 314-319. IEEE, Los Alamitos (2008)

16. Jacobs, I., Walsh, N.: Architecture of the world wide web, vol. 1, w3c recommendation (2004)

17. Cunningham, H., Maynard, D., Bontcheva, K., Tablan, V.: GATE: A framework and graphical development environment for robust NLP tools and applications. In: Proceedings of the 40th Anniversary Meeting of the Association for Computational Linguistics (2002)

18. Kirkpatrick, D.L.: Evaluation Training Programs: The Four Levels. Better-Koehler Publishers (1998)

19. Fresen, J.W.: Assurance of web-supported learning: Processes, products and services. In: Proceedings 6th Annual Conference on World Wide Web Applications, WWW (September 2004)

20. Korb, K., Nicholson, E.A.: Bayesian Artificial Intelligence. Chapman & Hall, New York (2004)

## Phantom Tasks and Invisible Rubric: The Challenges of Remixing Learning Objects in the Wild

David E. Millard1, Yvonne Howard1, Patrick McSweeney1, Miguel Arrebola3, Kate Borthwick2, and Stavroula Varella3

1 School of ECS, University of Southampton  
{dem,ymh,pm5}@ecs.soton.ac.uk

2 School of Humanities, University of Southampton  
K.B

## Phantom Tasks and Invisible Rubric: The Challenges of Remixing Learning Objects

## Introduction

The Open University in the UK and other institutions are embracing a more open lightweight approach, with Open Educational Resources (OER) emerging as a term for this type of shared content [2].

We have been involved in developing a repository for OER content for the Language Learning community. The Language Box is a lightweight repository based on the EPrints platform; it encourages users to share their everyday teaching resources without the overhead of complex meta-data or structures [3].

The Language Box includes mechanisms to support the reuse and remixing of content, allowing users to create and share collections of resources, and augment each other's materials with new activities. We hoped to see new types of lightweight Learning Objects emerge from community interaction, as users grouped together useful content with instructions for its use. However, although the mechanisms are well received in workshops, they are underused in practice, and we have seen users struggle to express their resources in anything other than the most simplistic way.

This paper describes how the Language Box supports resource reuse and remixing, and explores why users seem unable to take advantage of these systems.

## Background

The IEEE describes a Learning Object as "any entity, digital or non-digital, that may be used for learning, education or training" [4]. This broad definition is supported by formal specifications of how to describe digital Learning Objects in the IEEE LOM standard [5].

Despite interest from educational and educational research communities Learning Objects have not been as successful as their proponents hoped. Learning Objects have been criticized for using complex terminology that is not meaningful to ordinary practitioners [6], and their sophisticated structure (for example, using packages with manifests to describe their contents) has also meant that ordinary practitioners do not usually have the skills to create a formal Learning Object that could be deployed on a VLE [7].

Those Learning Objects that have been created can be difficult to find. Learning Object repositories are a way of storing Learning Objects in an open and accessible way [8] so that they can be easily browsed and deployed [9]. Research on Learning Object repositories has explored how they might be standardized [10], and also how graphical browsing interfaces might help users find Learning Objects that match their requirements more quickly [11].

As well as formal Learning Objects, teaching and learning repositories can deal with tutor created content, and shared resources that have been discovered on the wider web [12]. For example, Merlot is a repository of several thousand online resources that have been peer-reviewed for quality [13].

Some repositories allow their users to create virtual structures to help manage the Learning Objects, for example the ResourceCenter allows users to collect resources together into SCORM compliant structures [14]. However, the Web has evolved a much more lightweight remix culture, that encourages users to be flexible with authorship and experiment with each others content [15]. It has been argued that this attitude could be successfully extended to teaching materials, and might help create a culture of sharing that is more successful that the Learning Object economy [16].

## The Language Box

The Language Box is an attempt to re-imagine a Learning Object repository in a Web 2.0 way. We have embraced a lightweight sharing and remixing approach and have opted for a simple repository that allowed users to store their everyday materials, view them online in a browser, leave feedback and suggestions, and use simple collection and extension mechanisms to help evolve new resources over time.

### Motivation and History

We have been involved in creating teaching and learning repositories for several years. Our early work focused on providing a repository for Learning Objects for the Language Teaching Community. This repository, which was called CLARE, was evaluated with teachers and lecturers, and although they appreciated the repository as a way of obtaining learning resources, it was clear that there was a mismatch between the sophistication of Learning Objects and their own digital assets and skills.

Our workshops highlighted four key problems with the Learning Object approach:

1. Complex Metadata - the complexity of the deposit process was a significant barrier to practitioners, the problem is in the need to specify a large number of meta-data fields. CLARE used a variation of the UK LOM Core, a schema which includes

Here's the cleaned and normalized Markdown:

## Lack of Contextual Information and Design Evolution

4. Lack of Contextual Information – despite the amount of metadata on each Learning Object, they still lack contextual information about how they have been used by other practitioners. Unstructured feedback from other users, such as simple comments, is far more important to teachers and lecturers in terms of helping them decide if a resource will be useful than the formal descriptions created by the Learning Object author.

We concluded that the requirement for simplicity outweighed other needs, such as cross-indexing and quality control. When we revised CLARE into the Language Box, we wanted to make it as cheap as possible to add materials to the repository, and wanted complexity and detail to emerge through use, rather than being specified up front.

### Design Methodology

When designing the Language Box we turned to popular Web 2.0 sharing sites such as YouTube and Flickr for inspiration. We concluded that whereas traditional repositories (as typically used for research publications) are about Archiving content, a sharing-style repository is more about Hosting materials online with the minimum overhead to the user (such as YouTube's inline video tool), allowing users to Organise their own materials alongside others (such as Flickr's albums) and creating a Community of users (through profiles, tagging, statistics and commentary mechanisms that can be found on both sites).

We found it interesting that Sharing is not the key service; users place content online with a specific audience in mind, but often this is an act of communication rather than sharing (for example, someone uploading holiday photographs may be trying to reach their extended family, they are not placing photos online for others to repurpose). Sharing in the greater altruistic sense seems to be a side effect of more pragmatic selfish motives.

We listed 3 key objectives for the Language Box based on the services of Hosting, Organisation and Community:

1. Hosting: Ability to preview online
2. Organization: Ability to create public collections and extensions
3. Community: More prominent user presence through profiles

We concentrated on simple atomic resources with no content packaging, and used a minimum set of manual metadata to describe them (only the title is a required field). Because we have an inline preview tool, users can use resources from within their web browser without having to download them. We also encourage users to make their materials as public as possible through the use of Creative Commons licenses.

### Implementation

The Language Box is based on the EPrints repository platform, heavily modified through client-side Javascript and a Flash-based preview tool (Figure 1).

### Simple Remixing – The Language Box Model

As part of our efforts to support organisation and build community we wanted to include some simple remixing tools into the Language Box. Some sharing sites, most notably video editing sites such as Jumpcut[^1], include quite sophisticated remixing tools that allow audio, video and images to be layered together in complex ways; for the Language Box we needed something that was simpler and more granular, but which fitted the sort of pedagogical activities that our users would be interested in.

Early in our project we undertook an extensive co-design process with a number of language teachers and e-learning specialists in order to create an appropriate remix model. Very early on we identified the need for Activities, instructions on how to use a resource for a particular teaching or learning task. Initially we modeled these as a type of comment, but it quickly became apparent that many teachers see activities not as ethereal instructions, but as concrete items in their own right, often with files directly related to them (for example in the form of a task sheet). As a result in our later iterations Activities became explicit items in the repository with their own page. This way they can have additional files uploaded to support them, and their URL can be circulated independently of the resource that they are based on.

Figure 2 shows the data model that came out of this process. It consists of three types of EPrint (objects in the repository): Resources, Activities and Collections.

The key item in the repository is a Resource; this is an atomic unit of teaching material such as a set of slides or a video.

## Phantom Tasks and Invisible Rubric: The Challenges of Remixing Learning Objects

## Resource Organization and Activities

A Collection page on the Language Box can contain both Resources and Activities. Resources can be extended with an Activity, which is a set of instructions describing one potential use of a specific Resource. For example: "Read the article and then answer the questions on this worksheet".

Resources can have multiple Activities, and while Resources can only be edited by their authors, anyone can annotate a Resource with their own Activity. Activities have their own independent pages in the repository that link to the original resource. This allows teachers to create pages for their own activities, even when based on others' resources.

Resources and Activities can be organized into Collections. Users can create collections containing both their own material and items uploaded by others. The Language Box doesn't make assumptions about collection usage - they could gather topic-related items or organize course resources.

## Challenges for Practitioners

We conducted workshops with the Language Teaching community to understand their technology use, attitudes, and responses to the Language Box. Despite high technology adoption, many practitioners struggle with digital asset management and adapting practices for online environments.

### Digital Resource Use

Our initial community survey (n=201) revealed:

- Practitioners proactively locate resources, with less than half relying on traditional sources like books
- Wide use of multimedia types, likely due to language teaching requirements for video and audio
- Most generate digital activities themselves, primarily using VLE and Hot Potatoes

While the Language Box received 200 deposits in its first few months, users created only 22 activities. All activities were created by the original resource depositors, with no instances of users creating Activities based on others' deposits.

A subsequent usability workshop (n=11) showed:
- Users rated terminology ("Activity" and "Resource") between "OK" and "Very Clear"
- 8/10 users found creating an Activity "Easy" or "Very Easy"

This indicated the low activity creation rate was not due to usability issues.

## Phantom Tasks and Invisible Rubric: The Challenges of Remixing Learning Objects

## Resources vs. Activities

At our most recent workshop we spent some time discussing the issue of Activity creation with participants, we suspected that the issue may be because participants were unable to decide whether something should be uploaded as a resource or an activity, so we ran a small exercise (12 participants) to see if they could match up materials that they might use with our terms. The results are shown in Table 1.

Table 1. Classification of Items by Practitioners as either a Resource or an Activity

| No. | Description of Item | Resource | Activity | Both | Other |
|-----|-------------------|----------|----------|------|--------|
| 1 | Video of a conversation between two French students about university life | 10 | | 2 | |
| 2 | A selection of images of Polish food | 11 | | 1 | |
| 3 | A transcript of an audio recording of a lecture on Spanish history | 9 | | 2 | 1 (Resource Exploitation) |
| 4 | A Hot Potatoes activity (html web page) which practices an element of grammar | | 9 | 3 | |
| 5 | A powerpoint file which accompanied a lecture on British politics | 12 | | | |
| 6 | A handout explaining how to write a literature review, including some revision questions | 6 | 2 | 4 | |
| 7 | A set of exam questions for first-year Italian | 4 | 1 | 7 | |
| 8 | A set of guidelines on how to produce a podcast | 7 | 1 | 3 | 1 (Reference) |
| 9 | Some teaching notes to accompany a video of bull-fighting in Spain, which you found on the Language Box | 7 | 1 | 3 | 1 |
| 10 | An audio file containing discussion questions for a seminar on linguistics | 6 | 3 | 3 | |
| 11 | A quiz sheet on the environment, inspired by a powerpoint file you found on Language Box | 2 | 5 | 5 | |
| 12 | A reading list for a first-year Russian course | 9 | 1 | 1 | 1 |
| 13 | A poster advertising a Language-learning café | 7 | | 1 | 4 (advert) |
| 14 | A grammar exercise website with lots of interactive grammar games | 4 | 2 | 6 | |

If it were clear how to classify activities then we would expect to see all 12 practitioners classifying in the same way, but instead we see a great deal of variation. We followed the questionnaire with a discussion session in order to understand the reasoning behind some of their choices. We discovered that the problem lies in practitioners' ability to abstract activities from the resources that they use.

### Phantom Tasks

A key issue is that many resources have activities that are not specified in an explicit way, but are heavily implied by the resource, we call these Phantom Tasks. This is clearest in items 1-3 of Table 2, which are straightforward resources with no explicit tasks. Despite this several practitioners identified them as both an activity and a resource and later told us that this was because the resource implied an activity – for example, a video of a conversation implies a simple comprehension task.

Phantom Tasks exist for many types of resources, but for resources that strongly imply a task they can become overpowering, and become confused with the resource itself. For example, item 4 is a Hot Potatoes page, strictly speaking this is a resource that could be used in a number of different activities, but because of its structure it strongly implies that students should work through the exercises on the page on their own (perhaps as a revision or personal study task) an

Here's the cleaned Markdown:

Through community engagement workshops we have discovered that the problem is not with practitioners abilities to create digital content, nor with the usability of the tool, but in the level of abstraction that we ask of them. Teachers and Lecturers already have a level of abstraction that they are familiar working with, they talk at a business object level about 'exam scripts', 'PowerPoint presentations' and 'lecture notes', and if we require them to further dissect these items and upload the parts separately then this is an additional overhead that confuses some users and is a disincentive to all.

Our intention is to simplify the Language Box data model so that users do not have to make an explicit choice as to whether something is a Resource or an Activity. Instead they will be able to upload anything as a resource, and then create variations that the system will link with the original. Rather than an item type, an activity then becomes a relationship between two resources.

If we want practitioners to use teaching and learning repositories then we not only have to streamline the depositing process and make using the system as easy as possible, but we also have to make sure that the object types in the repository match up with people's everyday experiences. Reuse and remixing of educational resources is possible, but only if we support it in the same messy and inconsistent way that it occurs in real life. We cannot all be information engineers; Phantom Tasks do exist, some Rubrics are Invisible, and our systems must be able to support them.

## Acknowledgements

The work described in this paper was part of the JISC funded Faroes project. The authors would like to thank the extended Faroes team, including Julie Watson, Marcus Ramsden and Adam Field, and also the Language Teaching Community.

## References

1. Downes, S.: Learning Objects: Resources for distance education worldwide. The International Review of Research in Open and Distance Learning 2(1) (2001)
2. Caswell, T., Henson, S., Jensen, M., Wiley, D.: Open educational resources: Enabling universal education. The International Review of Research in Open and Distance Learning 9(1) (2008)
3. Millard, D., Howard, Y., McSweeney, P., Borthwick, K., Arrebola, M., Watson, J.: The Language Box: Re-imagining Teaching and Learning Repositories. In: International Conference on Advanced Learning Technologies, Riga, Latvia, July 14-18 (2009)
4. IEEE LTSC, IEEE standard for learning technology-learning technology systems architecture (LTSA), IEEE Std 1484.1-2003, pp. 1-97 (2003)
5. IEEE LOM, The learning object metadata standard, IEEE, Tech. Rep. (2005)
6. Morrison, I., Currie, M.: What is a learning object, technically? In: Proceedings of WebNet (2000)
7. Bratina, T., Hayes, D., Blumsack, S.: Preparing Teachers To Use Learning Objects. The Technology Source (November/December 2002)
8. Nash, S.S.: Learning objects, learning object repositories, and learning theory: Preliminary best practices for Online Courses. Interdisciplinary Journal of Knowledge and Learning Objects (2005)
9. Neven, F., Duval, E.: Reusable learning objects: a survey of LOM-based repositories. In: Proceedings of the Tenth ACM international Conference on Multimedia, Juan-les-Pins, France, December 1-6, pp. 291-294. ACM, New York (2002)
10. Hatala, M., Richards, G., Eap, T., Willms, J.: The interoperability of learning object repositories and services: standards, implementations and lessons learned. In: Proceedings of the 13th international World Wide Web Conference (2004)
11. Klerkx, J., Duval, E., Meire, M.:

Here's the cleaned Markdown:

## Can Educators Develop Ontologies Using Ontology Extraction Tools: An End-User Study

Marek Hatala¹, Dragan Gašević², Melody Siadaty¹, Jelena Jovanović³, and Carlo Torniai⁴

¹ Simon Fraser University, Canada  
² Athabasca University, Canada  
³ University of Belgrade, Serbia  
⁴ University of Southern California, USA

## Abstract

The recent research demonstrated several important benefits in the use of semantic technologies in development of technology-enhanced environments. The one underlying assumption for most of the current approaches is that there is a domain ontology. The second unspoken assumption follows that educators will build domain ontologies for their courses. However, ontologies are hard to build. Ontology extraction tools aim to overcome this problem. We have conducted an empirical study with educators where they used current ontology tools to extract ontologies from their existing course material. The results are reported for the IT and non-IT educators.

**Keywords**: ontology building, domain ontologies, ontology extraction, end-user study.

## Introduction

The Semantic Web technologies seem to be a promising technological foundation for the next-generation of e-learning systems [1]. Many authors have proposed the usage of ontologies in different aspects of e-learning, such as adaptive educational hypermedia, adaptive content authoring, personalization, user model sharing, and context capturing [2, 3, 4, 5]. This is an expected reaction, since e-learning is highly dependent on effective mechanisms for knowledge management capable of integrating various activities that e-learning involves, such as course authoring and adaptation and provision of reliable and timely feedback to both students and teachers.

Actually, in European Union (EU) and Canada, a lot of investments have already been put into research projects aimed at enhancing e-learning environments with Semantic Web technologies, such as LUISA (http://luisa.atosorigin.es), REWERSE (http://rewerse.net/), ProLearn (http://www.prolearn-project.org/), and Kaleidoscope (http://www.noe-kaleidoscope.org/). In Canada, the leading project addressing the use of ontologies in eLearning was LORNET Research Network (2003-2008, http://www.lornet.org).

In our previous research, we have proven and exemplified the advantages of ontology supported e-learning systems. In particular, in [6] we demonstrated how a combined use of content structure ontology, content type ontology and domain ontology leads to significant improvements in searching repositories with learning content. In addition, we have also shown in [7] that if these three kinds of ontologies are complemented with a user model ontology and an ontology formally specifying the learning path to be followed by a student, then advanced levels of learning content personalization can be achieved as well. Finally, in our most recent research efforts [8, 9] we demonstrated the relevancy of the integrated use of these different kinds of e-learning ontologies for providing online educators with reliable, fine grained and semantically rich feedback about the learning process. However, the main problem with all approaches that have shown the benefits of ontology adoption in e-learning systems is that they are assuming that required ontologies are available. However, this is not a realistic assumption, at least not for domain ontologies, i.e. ontologies that formalize the subject matter of learning courses. The lack of these ontologies is to be attributed to their creation process which is overly difficult and time consuming for educational practitioners.

Based on the experience of the knowledge capture and learning technology communities, and our experience from the abovementioned projects, the major obstacle for widespread use of ontologies in e-learning systems lies in the complexity of the ontology development process, especially when considered from the perspective of teachers and content authors who are typically unaware of ontology existence and relevancy altogether. Although, in the recent years, the Semantic Web community has been showing a constantly increasing interest in automating the process of ont

Here's the cleaned Markdown:

## Can Educators Develop Ontologies Using Ontology Extraction Tools

## Study Description

In this section we describe the main components of the study and the processes used in the preparation and execution of the study. The third section is focused on analysis of the results and discussion.

### Tool Selection

Being aware of the complexity of conventional ontology editors (used for building ontologies from scratch) for non-ontology-savvy users, we put our focus on exploring the available ontology learning tools and online ontology libraries. Information about the current state-of-the-art tools for the selected approaches was collected by exploring the literature on ontology learning [13, 18, 19]. However, out of almost a dozen tools mentioned in research papers, only four of them were publicly available on the Internet:

- OntoGen (http://ontogen.ijs.si/)
- Text2Onto (http://ontoware.org/projects/text2onto/)
- TextToOnto (http://sourceforge.net/projects/texttoonto)
- OntoLT (http://olp.dfki.de/OntoLT/OntoLT.htm)

Those were the tools that we managed to download and install. We decided to use two of them for evaluation purposes (the other two were discarded either for being outdated or depending on another proprietary tool): Text2Onto [14] and OntoGen.

**Text2Onto.** Text2Onto is an ontology learning framework which supports the automatic or semi-automatic generation of ontologies from textual documents. It combines machine learning approaches with basic linguistic processing for learning atomic classes, class subsumption as well as object properties. The framework provides a Graphical User Interface form which the user can define the corpus (the collection of text documents) form which the ontology will be created, select the available algorithms to be applied for generating concepts/relations, and review the generated ontology. The main problem with the tool is that is not clear how the available algorithms and their combination will affect the generation of the ontology, forcing the users to try all the available options and review for each of them the generated ontology.

**OntoGen.** OntoGen is more oriented towards semi-automatic ontology construction. It is an interactive tool that aids a user during the ontology construction process by suggesting concepts, automatically assigning instances to concepts and providing visual representation of both the ontology and the corpora it is built upon. To build an ontology a user has to supply a set of documents that reflects the domain for which the ontology is to be built. The tool creates the root concept of the ontology and suggests names for it using the extracted keywords. In every step of the hierarchy development, OntoGen suggests subtopic of the currently selected topic thus helping users to build a hierarchical organization of domain concepts.

### Study Scoping

The survey aimed at two well defined groups of teachers having low level of variability among their members. The groups belong to two completely opposite domains: Computer Science/Software Engineering/Information Technology and non-Computer Science/Software Engineering. The members of the former group are representatives of those who are in general very familiar with complex software tools utilization and may have some notions related to ontologies (group labeled as IT later), whereas the latter group (labeled nonIT) represents educators who are not aware of ontologies and knowledge representation and are less familiar with complex software tools.

When designing the evaluation study we carefully tailored the procedure for conducting the survey and for formulating and formalizing the questionnaire used in the study. We conducted a simulation with the goal to estimate the sample size that, given the expected answers and variability of the population, can maximize the statistical power of the experiments. The target number of participants was set to 15 people for each group since it was a reasonable tradeoff between statistical power (generally at least 80% for expected outcomes) and the actual capability of recruiting a great number of participants. The simulations assumed a latent normal distribution beneath the Likert-scale measurement and used Analysis of Variance (ANOVA) for comparing the tools and were performed using SAS software.

###

Here's the cleaned and normalized Markdown:

## Study Procedure

Participants submitted their course material to the research team upfront. The research team converted the materials into the plain text format that was an accepted format for both tools. To avoid problems with tools installation on participants machines the specific remote server has been prepared with all the tools installed and the course material in the text format made ready. The server was accessible via remote desktop and assistance[^1] was available via installed Skype communication software during the whole session. A step-by-step instructional package was made available to the participants a few days ahead of their scheduled session. The first section of this guide provided instructions on how to connect to the remote server and control the test environment. The other two sets included information about and instructions on how to use the selected ontology building tools: Text2Onto and OntoGen.

During the session the participants were asked to build an ontology describing their subject of expertise from the course material they had provided, and using the tools selected for the survey. No time constraints were imposed for the ontology creation process, with the majority of the sessions lasting between 2 and 3 hours. After the task has been completed, the participants were asked to fill in a three-part questionnaire: first part related to the evaluation of the experiment itself (not reported in this paper), second part was a 5-value Likert scale questionnaire used for each tool, and qualitative part with 6 open ended questions. The results are discussed in the following section.

## Results and Discussion

Total of 28 participants were recruited and retained for the study, 18 with the information technology background, and 10 with non-IT background. None had prior experience in the ontology development. We originally aimed at 50-50 split but some participants from the departments that indicated nonIT background were categorized as IT due to their prior education in the computing science.

### Course Material and Ontologies Produced

Before the beginning of the session the research team produced the plain text documents from the course material provided by the participants. Using the OntoGen and Text2Onto tools the participants produced the ontologies. The basic descriptive statistics are provided in Table 1. Evaluation of the quality of produced ontologies is beyond the scope of this paper and reported elsewhere [20].

Table 1. Descriptive statistics of course material and produced ontologies

| | N | Min | Max | Mean | SD |
|---|---|---|---|---|---|
| Number of words | 25 | 4,345 | 293,555 | 59,372 | 78,000 |
| Concepts (OntoGen) | 22 | 3 | 26 | 8.6 | 5.9 |
| Relations (OntoGen) | 22 | 0 | 13 | 3.2 | 4.0 |
| Concepts (Text2Onto) | 22 | 228 | 4,602 | 1,494.0 | 1,015.0 |
| Relations (Text2Onto) | 19 | 0 | 155 | 53.4 | 44.4 |

### Tool Evaluation

Both tools were used by each participant to accomplish the same task: to build an ontology from the course material the participant provided for the study. No training was provided for the tools. After completing the task with the first tool (Text2Onto) the participants were asked to fill in the questionnaire that consisted of a section of questions with respect to the tool itself and another section related to the developed ontologies. Both sections used 5-value LIKERT scale. Next, having used the second tool (OntoGen) for ontology development, the participants evaluated it as well. Finally, they filled in a questionnaire with qualitative questions for both tools.

In Table 2 we report the user evaluation for both tools and their comparison from the tool usability perspective and support they provided during the ontology building process. The majority of the findings is negative. Question A.1 for both tools

Here's the cleaned Markdown:

## Text2Onto and OntoGen Tool Comparison Study

### Questionnaire Results

Table 2. Text2Onto and OntoGen comparison based on participants' answers to the questionnaire. Both IT and nonIT participants are included. Values reported are from 5-value Likert scale (1-Completely Disagree, 2-Disagree, 3-Neutral, 4-Agree, 5-Completely Agree). (M, SD, N) values represent mean, standard deviation, and sample count.

| Question | Text2Onto (M, SD, N) | OntoGen (M, SD, N) | 2-sample t-test |
|----------|---------------------|-------------------|-----------------|
| A.1 I prefer to participate in the process of creating an ontology | 4.11, 1.01, 27 | 3.76, 1.05, 25 | - |
| A.2 I felt in control of the process while obtaining the ontology | 3.21, 1.06, 28 | 2.33, 1.03, 27 | t(52.9)=3.10, p=0.003 |
| A.3 I am happy with the resulting ontology | 2.96, 1.03, 28 | 2.44, 0.93, 27 | - |
| A.4 I found the process of obtaining the ontology easy to accomplish | 3.14, 1.07, 28 | 3.00, 1.51, 27 | - |
| A.5 Visual representation of ontology helps the creation process | 4.17, 0.90, 28 | 3.44, 1.15, 27 | t(49.2)=2.61, p=0.011 |
| A.6 Being able to manipulate the generated ontology would improve my work | 4.25, 0.96, 28 | 3.88, 1.25, 27 | - |
| A.7 It would have been good to have guidance during the creation process | 4.17, 0.98, 28 | 4.55, 0.84, 27 | - |

Having guidance during the process is important (Question A.7). Especially in case of OntoGen with mean at 4.55 participants were very uncertain how to proceed.

### Influence of Participants Background on Tool Evaluation

We were interested in whether participants' background influences tool effectiveness perception. Data was processed independently for each tool, comparing means of IT and nonIT groups using 2-sample t-test. Though no differences between groups were statistically significant, several cases showed background-related response shifts.

Table 3. Comparison of tools' evaluation based on participants' background. For question text and Likert scale values refer to Table 2.

| Question | Text2Onto-IT (M, SD, N) | Text2Onto-nonIT (M, SD, N) | OntoGen-IT (M, SD, N) | OntoGen-nonIT (M, SD, N) |
|----------|-------------------------|----------------------------|---------------------|------------------------|
| A.1 | 4.17, 1.07, 17 | 4.00, 0.94, 10 | 3.80, 1.14, 15 | 3.70, 0.94, 10 |
| A.2 | 3.27, 1.07, 18 | 3.10, 1.10, 10 | 2.23, 0.97, 17 | 2.50, 1.17, 10 |
| A.3 | 2.88, 1.02, 18

Here's the cleaned Markdown:

## Influence of Participant's Background on Produced Ontology

We have also analyzed the results for ontology produced by both tools separately to find out whether the participants' opinions are influenced by their background. Although the average opinions between the IT and nonIT groups differ in some cases none of these differences proved statistically significant using the 2-sample t-test (see Table 5).

Table 5. Evaluation of produced ontologies based on participants' background. Answers were compared separately for Text2Onto and OntoGen. 2-sample t-test did not show any statistically significant differences between the IT and nonIT groups. For the question text and Likert scale values refer to the caption of Table 4.

| Question | Text2Onto-IT (M, SD, N) | Text2Onto-nonIT (M, SD, N) | OntoGen-IT (M, SD, N) | OntoGen-nonIT (M, SD, N) |
|----------|-------------------------|----------------------------|---------------------|------------------------|
| B.1 | 3.22, 0.94, 18 | 2.90, 1.28, 10 | 2.29, 0.91, 17 | 2.80, 0.91, 10 |
| B.2 | 3.77, 1.00, 18 | 3.22, 0.83, 9 | 3.70, 0.77, 17 | 3.10, 0.99, 10 |
| B.3 | 2.27, 1.07, 18 | 2.33, 0.86, 9 | 2.87, 1.45, 16 | 3.60, 1.42, 10 |
| B.4 | 2.38, 0.97, 18 | 2.70, 0.82, 10 | 2.06, 0.85, 16 | 2.30, 1.25, 10 |

For both tools (Text2Onto and OntoGen) the IT group would prefer to have more relationship identified in the ontology. In case of the ontology produced by OntoGen, the nonIT group considered the number of concepts generated to provide more detailed description than the IT group.

## Qualitative Evaluation of Tools

After completing the tasks with both Text2Onto and OntoGen the participants were asked to provide answers to open ended questions and judge tool intuitiveness, ease of interaction, pros and cons of each tool, and whether tools met their expectation.

Based on the answers we have developed a separate coding scheme for each of the questions. Three raters tested the scheme by applying it to five randomly selected questions and fine-tuned the coding manual. In the next step, the three raters applied the scheme independently to rate the answers. In the final step all the differences were resolved through the discussion during the meeting of the three raters.

The results were evaluated using cross tables with identifying differences between tools and IT/nonIT groups. The results for each question are presented below. In the tables presenting these results for each code the percentage of answers is given for IT group, nonIT group, and total number of the code occurrence for the tool. More than one code could be assigned to a single answer. We tested for significance of the difference between the groups using chi-square statistics. If there is a significant difference in code occurrence between IT and nonIT group it is explicitly indicated in the table and the table caption and we address the issue explicitly in the discussion text.

### Intuitiveness of the ontology building approach

In Table 6 the four codes address intuitiveness explicitly: INT, LI, NVI, and GI. Although 25.9% of users found OntoGen to be intuitive and 37% found Text2Onto intuitive the scores for negative comments are even higher. Text2Onto is much less

## Can Educators Develop Ontologies Using Ontology Extraction Tools

## Tool Interaction and Manipulation

Table 7. The ease of interacting with and manipulating the tool. The codes have the following meaning: Easy- easy to use, NVE- not very easy to use, VP- hard to manipulate the visualization, LF- lack of feedback, NC- user has no control over the process. The values with star show statistically significant difference between IT and nonIT groups.

|      | OntoGen |        |        | Text2Onto |        |        |
|------|----------|--------|--------|------------|--------|--------|
|      | IT       | nonIT  | Total  | IT         | nonIT  | Total  |
| Easy | 41.2%    | 40%    | 40.7%  | *52.9%    | *90%   | 66.7%  |
| NVE  | 29.4%    | 50%    | 37%    | 29.4%     | 10%    | 22.2%  |
| VP   | 29.4%    | 10%    | 22.2%  | -         | 20%    | 7.4%   |
| LF   | -        | 20%    | 7.4%   | -         | 10%    | 3.7%   |
| NC   | 11.8%    | -      | 7.4%   | 5.9%      | -      | 3.7%   |

The participants in 22% cases described OntoGen's visualization as hard to manipulate against 7.4% in case of Text2Onto. A small number of nonIT participants found both tools lacking feedback, while number of IT participants felt they had no control of the process (11.8% for Text2Onto).

Overall, the opinions on this question are split and the matter of usability of ontology building tools should be studied more carefully. An interesting pattern can be observed from this and previous question for the Text2Onto tool. With its simpler interface that hides the structural aspects of the ontology, the nonIT group have found it easy to use (90%), although 40% reported that it was not intuitive or become gradually intuitive (20%).

## Positive Aspects of the Tools

Table 8. Pros of the tools. The codes have the following meaning: Ease-Ease of use because/automatic generation of ontology, Viz- Visualization, UC- User control, Nthng-nothing good, Rnk- ranking of concepts. The values with star show statistically significant difference between IT and nonIT groups.

|      | OntoGen |        |        | Text2Onto |        |        |
|------|----------|--------|--------|------------|--------|--------|
|      | IT       | nonIT  | Total  | IT         | nonIT  | Total  |
| Ease | 23.5%    | 30%    | 25.9%  | *41.2%    | *80%   | 55.6%  |
| Viz  | 70.6%    | 80%    | 74.1%  | -         | -      | -      |
| UC   | 17.6%    | 30%    | 22.2%  | 11.8%     | -      | 7.4%   |
| Nthng| -        | -      | -      | 23.5%     | 10%    | 18.5%  |
| Rnk  | -        | -      | -      | -         | 20%    | 7.4%   |

Over 55% of participants thought that the biggest strength of Text2Onto is its ease of use mainly because of automatic generation of large number of concepts and relationship. Again, a

Here's the cleaned and normalized Markdown:

## Can Educators Develop Ontologies Using Ontology Extraction Tools

## Meeting Expectations

Table 10. Meeting Expectations. The codes have self-evident meaning. The values with star show statistically significant difference between IT and nonIT groups.

|           | OntoGen |        |        | Text2Onto |        |        |
|-----------|---------|--------|--------|-----------|--------|--------|
|           | IT      | nonIT  | Total  | IT        | nonIT  | Total  |
| Yes       | 29.4%   | 30%    | 29.6%  | -        | 30%    | 11.1%  |
| No        | 35.3%   | 20%    | 29.6%  | *82.4%   | *40%   | 66.7%  |
| Partly    | 23.5%   | 30%    | 25.9%  | 5.9%     | 20%    | 11.1%  |

## Conclusions

This paper presented an empirical study of educators using two ontology building tools: Text2Onto and OntoGen. The educators used the tools to build ontology from the course material they provided for the study. Twenty eight educators participated in the study between September 2008 and March 2009. The educators group came from the Computer Science/Software Engineering/Information Technology background (18 participants) and the non-Computer Science/Software Engineering background (10 participants).

The results show that the current state of the tools for developing domain ontologies by educators is unsatisfactory. However, several conclusions can be made with respect to the approaches and desirable features of the tools as well as with respect to the educators background.

There is an appeal of the approach which generates large amount of suggestions for ontology concepts and relationships that is than 'weeded out' by the user. This approach, applied by the Text2Onto tool, was especially favored by the non IT group. However, after examining the produced ontologies from the perspective of the requirements of advanced eLearning technologies their utility is rather minimal as users tend to keep extremely large number of concepts. On the other side, the interactive approach used by OntoGen produces rather small ontologies where users stop the building process too soon.

Secondly, there is a clear need for a good ontology visualization capability that can be easily manipulated by the users.

Finally, although some of the differences between the two groups become visible in the survey data, the results demonstrate that both groups were equally dissatisfied with the both tools. The group with IT background was more critical of the aspects of the tools where they perceived the tool did not apply strong enough methods such as eliminating unimportant results etc.

## Acknowledgment

We would like to thank Prof. Thomas M. Loughin who helped us define the procedure for conducting the experiment and to properly formulate and formalize the questionnaire for the study. This study is funded in part by Athabasca University's Mission Critical Fund, Athabasca University's Associate Vice President Research's special project, and NSERC.

## References

1. Devedžić, V.: Key issues in next-generation Web-based education. IEEE Transactions on Systems, Man, and Cybernetics, Part C 33(3), 339–349 (2003)
2. Dicheva, D., Aroyo, L.(eds.): Special Issue on Application of Semantic Web Technologies in E-learning. International Journal of Continuing Engineering Education and Life-Long Learning 16(1/2) (2006)
3. Naeve, A., Lytras, M.D., Nejdl, W., Balacheff, N., Hardin, J. (eds.): Special issue on Advances of the Semantic Web for e-learning: expanding learning frontiers. British Journal of Educational Technology 37(3) (2006)
4. Henze,

Here's the cleaned Markdown:

## Sharing Distributed Resources in LearnWeb2.0

Fabian Abel, Ivana Marenzi, Wolfgang Nejdl, and Sergej Zerr  
L3S Research Center, Leibniz University Hannover, Germany  
{abel,marenzi,nejdl,zerr}@L3S.de

## Abstract

The success of recent Web 2.0 platforms shows that people share information and resources within their social community and beyond. The use of these platforms in an e-learning context has been limited, though. One reason for this is the fact that most of these platforms only support specific media types, and teachers trying to assemble learning resources have to login to and use several Web 2.0 tools at once to access all relevant resources. In this paper, we present LearnWeb2.0, an integrated environment we implemented for sharing Web 2.0 resources, which improves support for learners and educators in sharing, discovering, and managing learning resources distributed across different platforms. LearnWeb2.0 integrates ten popular resource sharing and social networking systems, and provides advanced features for organizing and sharing distributed learning resources in a collaborative environment.

**Keywords**: resource sharing, distributed learning resources, knowledge management, LearnWeb2.0.

## 1 Introduction

The success of Web 2.0 and specific platforms such as YouTube, Flickr, and Delicious demonstrates that people are willing to share knowledge and resources with other people. Popular resource sharing systems allow users to upload and share content, but do not focus on educational resources. In [1], Petrides et al. point out that there is a need for platforms, which allow us to share open educational resources and inspire a culture of continuous improvement of these resources. In addition, sharing of educational material requires an environment, which permits the storage of resources in different formats. Typically, different Web 2.0 infrastructures focus only on particular media types, videos in YouTube, pictures in Flickr, or bookmarks in Delicious, even if these resources belong to one and the same context [2]. Thus, despite the variety of available resource sharing systems, linking distributed educational resources related to the same context is still difficult.

In this paper, we present LearnWeb2.0, an environment for sharing educational resources by integrating existing Web 2.0 systems. In line with the findings presented in [3], which discusses how the integration of popular Web 2.0 services into learning processes can foster active participation, LearnWeb2.0 integrates popular resource sharing systems and social networking systems to provide an environment that improves support for learners and educators in sharing, discovering, and managing learning resources. Our main contribution is the LearnWeb2.0 platform and system, which integrates ten popular Web 2.0 services to enable sharing, discovery, and management of distributed learning resources. LearnWeb2.0 provides various innovative features:

1. A personal learning space offering a seamless overview of the entire set of learning resources distributed across various Web 2.0 repositories
2. Sharing through standing queries, where users are notified whenever a new learning resource matches the query
3. Collaborative aggregation of different learning resources via an intuitive drag-and-drop interface
4. Integration of the user's social networks from different Web 2.0 services
5. A browser plug-in that enables users to easily share learning resources via drag-and-drop operations

## 2 LearnWeb2.0: Architecture and Functionalities

### 2.1 Architectural Design

LearnWeb2.0 consists of a Web application, the LearnWeb2.0 platform, and the LearnWeb2.0 Browser Plug-in (Fig. 1). The Web application provides a Personal Learning Space which supports users in discovering, sharing, and organizing distributed resources. LearnWeb2.0 uses existing Web 2.0 services as storage infrastructure, which means that core functionalities implemented by the following modules are mapped to the services preferred by the individual user.

The Search and Exploration module

Here's the cleaned and normalized Markdown:

## LearnWeb2.0 Architecture and Functionality

The LearnWeb2.0 platform integrates various modules to handle resources that are distributed across integrated Web 2.0 services:

- The Annotation and Aggregation module enables users to organize learning resources through tagging and grouping
- The Upload and Sharing module allows users to store and share resources from their local Desktop or the Web into appropriate Web 2.0 systems
- These modules are available both through the platform and as web services for authorized applications like the browser plug-in
- The Browser plug-in enables easy upload by dragging resources onto its icon

The functionality is supported by three additional modules:

1. The Web 2.0 Service Adapter module maps LearnWeb2.0 functions to specific Web 2.0 services, with adapters for 10 services and easy addition of more
2. Single sign-on authorization allows users to access preferred services without multiple logins
3. The Authorization component handles third-party application access using OAuth and REST principles

### LearnWeb2.0 Implementation Details

The system is implemented using PHP and CakePHP framework with MVC support. Key technical aspects include:

- Custom API implementations for GroupMe! and Slideshare
- Encrypted credential storage for services without token-based authentication
- Caching mechanism to reduce API calls
- Workarounds for API usage constraints

### Core Functionality

#### Search and Exploration

LearnWeb2.0 provides:

- Generic search interface across Web 2.0 services
- Integrated view of search results from all services
- Advanced search filtering by tags, file types, timestamps
- RSS atom feed for search results
- Automatic resource annotation with search terms
- Social network integration for resource discovery

#### Annotation and Aggregation

- References stored in LearnWeb2.0 repository
- Dublin Core metadata annotation support
- Context-specific resource references
- GroupMe! integration for resource aggregation

Table 1. Core features of LearnWeb2.0 and Web 2.0 services used to realize the features
[Table content preserved but not visible in excerpt]

Here's the cleaned and normalized Markdown:

## Related Work

### Web 2.0 and Education
The authors of [3] discuss how the integration of popular Web 2.0 services into education can stimulate active participation of learners in the learning process. In line with these findings and based on requirements identified in [4], LearnWeb2.0 integrates various Web 2.0 services to provide an environment for sharing educational resources. The demand of platforms that allow users to share open educational resources is discussed in [1]. LearnWeb2.0 provides such a platform but goes one step further as it supports (i) both kinds of users, educators and learners, and (ii) both traditional educational resources and resources originally not intended for education. As resources come in different formats, LearnWeb2.0 supports all appropriate media types, and does so in an integrated way, in contrast to mashUps such as Netvibes or iGoogle, which provide access to different Web 2.0 services in a single environment, but keep these services separated [5]. The need for assistance in multiple, flexible filing and searching facilities to offer enhanced attributes in users' desktops was identified in [6]. LearnWeb2.0 expands this concept into a virtual desktop, spread over a number of Web 2.0 services that manage these resources.

### Search and Sharing
Recent studies have shown that social search techniques can improve the effectiveness of the Web search. SearchTogether [7] is such an interface for collaborative search. In LearnWeb2.0 we enable users to store, rate, comment, tag and reuse the most successful queries. By representing the search result page as an RSS feed, LearnWeb2.0 implements a standing query mechanism, useful for collaboration on common tasks. LearnWeb2.0 also enables users to share queries and other resources, and collaboratively organize and use them in groups [8].

## Conclusions and Future Work

In this paper we presented the LearnWeb2.0 environment, which supports learners and educators in sharing, discovering, and managing learning resources that are spread across different Web 2.0 platforms. LearnWeb2.0 aggregates resources and uses functionalities from ten different Web 2.0 services and propagates LearnWeb2.0 actions back to these services. LearnWeb2.0 thus provides a personal learning environment offering a seamless overview of the entire set of relevant resources distributed over the different platforms. Collaborative aggregation of learning resources into groups is supported via simple drag-and-drop operations. Next steps include the evaluation of LearnWeb2.0 at our university, and the implementation of new features focusing on access control and notification of users as regards interesting resources, all of which improves awareness during collaborative search.

### Acknowledgments
The work on this paper has been partially sponsored by the TENCompetence Integrated Project. Contract 027087.

### References
1. Petrides, L., Nguyen, L., Kargliani, A., Jimes, C.: Open Educational Resources: Inquiring into Author Reuse Behaviors. In: Dillenbourg, P., Specht, M. (eds.) EC-TEL 2008. LNCS, vol. 5192, pp. 344–353. Springer, Heidelberg (2008)
2. Demidova, E., Kärger, P., Olmedilla, D., Ternier, S., Duval, E., Dicerto, M., Mendez, C., Stefanov, K.: Services for knowledge resource sharing & management in an open source infrastructure for lifelong competence development. In: Intl. Conference on Advanced Learning Technologies (ICALT), Niigata, Japan (2007)
3. Ullrich, C., Borau, K., Luo, H., Tan, X., Shen, L., Shen, R.: Why Web 2.0 is good for learning and for research: principles and prototypes. In: Proc

Here's the cleaned and normalized Markdown:

## SWeMoF: A Semantic Framework to Discover Patterns in Learning Networks

Marco Kalz¹, Niels Beekman², Anton Karsten², Diederik Oudshoorn², Peter Van Rosmalen¹, Jan Van Bruggen¹, and Rob Koper¹

¹ Open University of the Netherlands, Center for Learning Sciences and Technologies, PO Box 2960, 6401 DL Heerlen, The Netherlands  
² Open University of the Netherlands, Faculty of Informatics, PO Box 2960, 6401 DL Heerlen, The Netherlands

{marco.kalz,peter.vanrosmalen,jan.vanbruggen,rob.koper}@ou.nl,  
{cg.beekman,as.karsten,dj.oudshoorn}@studie.ou.nl

## Abstract

In this contribution we introduce SWeMoF, a semantic framework to discover patterns in learning networks and the blogosphere. Based on a description of the state of the art in data mining, text mining and blog mining we discuss the architecture of the Semantic Weblog Monitoring Framework (SWeMoF) and provide an outlook and an evaluation perspective for future research and development.

**Keywords**: weblogs, social software, text mining, data mining, RSS, clustering, classification, Latent Semantic Analysis.

## 1. Introduction

In the past we have concentrated on the evaluation of Latent Semantic Analysis (LSA) to approximate the prior knowledge of learners in learning networks. We could show that Latent Semantic Analysis (LSA) is a promising method to support this process [1]. Several other examples show that semantic services and language technology have the potential to help to reduce tutor load and to increase efficiency in technology-enhanced learning [2]. We expect that the application of such approaches can help in personalization processes, the automatic generation of metadata and the discovery of structural patterns in learning networks. On the other hand we made the experience that the effort to develop and evaluate learner support services based on text- and data-mining methods is a very challenging task since a lot of different tools and sources are involved and manually processing of data is needed. Based on this aspect and the need to extend our research to other methods and approaches we have developed a prototypical solution that can help to find semantic patterns in learning networks. In this contribution we present the Semantic Weblog Monitoring Framework (SWeMoF). The prototypical framework that we discuss in this article employs feed parsing techniques and data- and text-mining algorithms for several types of experiments and prototyping scenarios.

A similar framework as proposed here has been described by Joshi & Belsare as BlogHarvest [3] and Chau et al. [4]. The BlogHarvest framework is a conceptual framework for opinion and sentiment analysis that employs part-of-speech tagging, association rules and several miners for clustering and classification. The second proposal by Chau et al. consist of a blog spider to collect content, a blog parser to extract information, a blog analyzer and a blog visualizer. On the other hand this is a very general framework without any prototype or a detailed architecture.

## 2. Data Mining, Blog Mining and Text Mining

Data Mining is a process to find patterns in large numbers of data [6]. While data mining is applied most of the time to numerical data in large databases the application of techniques from data mining to textual data is called text mining. Inside the text mining research the application of text mining to weblogs is called blog mining.

The target of data mining is to discover meaning in a vast amount of data and to find patterns that are not recognizable by traditional statistical measurement and direct visual inspection. Witten and Frank refer to an increasing gap in today's society between the generation of data and the understanding of it [6]. In this sense data mining does not have the target to generate new data but to use existing data and to find structures which have not been explored before. Fayy

Here's the cleaned and normalized Markdown:

## Architecture of the Semantic Weblog Monitoring Framework

SWeMoF is an object-oriented, web-based application designed for semantic experiments on the basis of content produced from weblogs and other text-based applications which offer an RSS-feed. Within this framework several data mining/natural language processing experiments are possible. Every experiment takes the content of one or more weblogs as input, applies one or more algorithms/miners to the content and gives an output which can be downloaded. The level of input can be the whole content of a weblog (set level), content from a dedicated category in a weblog (category level) or even only dedicated postings (document level).

The prototype has implemented 5 example algorithms/miners for three different experiments: Semantic Similarity, Classification and Clustering. The prototype is written in Java and makes use of an integrated database and the Echo framework for the interface. The example algorithms are implemented using the Weka framework, but the SWeMoF framework does not depend on it. Both filters and text mining algorithms can be written from scratch or by using any available components and libraries. For the design of the system the following use cases have been defined:

- **Corpus Creation**: A corpus has to be defined before an experiment can be created. This corpus can be constructed from several RSS-Feeds and/or OPML files. Besides this functionality, the domain corpus can be combined with a general language corpus which has been discussed as an important option in several information retrieval scenarios. For classification experiments several examples need to be classified manually before an experiment can be executed. In the classification experiment these 'gold standard' examples are needed to allow a semantic comparison between the classified documents and the unclassified documents. This step can be done by inspecting the corpus directly or during the creation of an experiment.

- **Experiment Creation**: In the experiment creation phase the parameters for a text mining experiment can be configured. These parameters consist of a corpus, an optional general language corpus, filters and a text mining algorithm. Further, the level on which the experiment is conducted (set, category or document) must be configured. It is also possible to disable a part of the corpus on any level: set, category or document. After an experiment has been created it can be executed. This division between experimentation and execution allows for repeating experiments and comparing results with different settings.

- **Result Presentation & Download**: After the execution of an experiment the results are presented to the user and the user can download the results.

- **Adding of additional miners**: In the current prototype the following miners have been implemented: Naive Bayes Classifier, IB1 Classifier, EM Clusterer, Simple K-Means Clusterer and a similarity rater using LSA. In addition, LSA can be combined with the miners implemented. But it is easy to add additional miners into the system.

The SWeMoF Framework allows the user to either create new experiments or retrieve and execute older experiments that have been stored. The parameters of an experiment (corpus, general language corpus, filters, miner, mining level) are saved in an experiment configuration. The following figure shows how a text mining experiment is conducted with SWeMoF.

![Overview of the components of the SWeMoF system](Fig. 1)

The Input module is responsible for the import of text. Single texts (e.g. single web posts) are organized in groups to create a hierarchy. Single text documents must be grouped in a document category, document categories must be grouped in document sets. Since SWeMoF's main focus is on web feeds, this design has been chosen to reflect the structure of these feeds. Even when only a single text document is imported it will have to be placed inside a document category, and the document category inside a document set. It is important to note that the corpus is not created by the Input module but by the Corpus module. For the feed parsing we have used the ROME library. ROME is a set of open source Java tools for parsing, generating and publishing RSS and Atom feeds.

The Corpus module is responsible for the aggregation of documents generated from the input text by the input

## SWeMoF: A Semantic Framework to Discover Patterns in Learning Networks

The SWeMoF framework can be extended in several areas. The framework focuses on weblog monitoring and thus the focus for the prototype has been on implementing RSS and OPML as the document source. The input module however is designed in such a way that it can easily be extended with other input sources by implementing the appropriate interfaces. The second more important part where SWeMoF can be extended is in the filters and miners. To add a new filter or text mining algorithm all that needs to be done is implement the interface Filter or Miner and create a descriptor. The descriptor will tell the GUI what the Filter or Miner does and which options can be set. After this has been done, the descriptor can be added in to the registry. SWeMoF will then automatically make this filter or miner available to the end user.

### Discussion, Outlook and Future Work

At the current stage of the development we could conduct several tests related to code functionality and result quality. After the components have been tested alone the integrated system has been tested to see if the system supports the use cases for which it was designed for. In addition we have compared the system results with the results of using Weka directly. The integration testing confirmed that the system is able to support the use cases and the comparison to Weka was successful as well. A real end-user and usability testing could not be conducted yet, but we are planning to present the system to researchers and learning technology developers with different levels of prior knowledge about data and text mining. For this purpose we are planning to combine traditional usability testing with the hedonic and pragmatic approach developed by Hassenzahl [13]. In this framework the "hedonic quality" aspect covers non-task-oriented quality aspects like innovativeness or originality and takes appealingness of a software system into account as well.

As a next step we will conduct an end-user testing with colleagues in the field. Based on the feedback of the potential end-users we will improve the system. The full code of the framework has been released under a GPL license [14] and a demonstration of the framework is available [15]. Depending on the reaction of end-users of the system we might improve the storage and presentation of the results. In addition we are going to extend the system with more miners from Weka and use it as an evaluation instrument for the development of several semantic web-services in the future.

### Acknowledgements

The work presented was partially carried out in the by the TENCompetence Integrated Project that is funded by the European Commission's 6th Framework Programme, priority IST/Technology Enhanced Learning. Contract 027087 (www.tencompetence.org) and partially carried out as part of the LTfLL project, which is funded by the European Commission (IST-2007-212578) (http://www.ltfll-project.org).

### References

[1] Kalz, M., Van Bruggen, J., Giesbers, B., Waterink, W., Eshuis, J., Koper, R.: Where am I? – An Empirical Study about Learner Placement based on Semantic Similarity (manuscript submitted for publication, 2009)

[2] Van Rosmalen, P.: Supporting the tutor in the design and support of adaptive e-learning. Doctoral Dissertation. SIKS Dissertation Series 2008-07. Open University of the Netherlands, Heerlen (2008)

[3] Joshi, M., Belsare, N.: BlogHarvest: Blog mining and search framework. In: Lakshmanan, L.V., Roy, P., Tung, A.K. (eds.) Proceedings of the 13th International Conference on Management of Data (COMAD), Delhi, India. Computer Society of India (2006)

[4] Chau, M., Xu, J., Cao, J., Lam, P., Shiu, B.: A Blog Mining Framework. IT Professional 11, 36–

Here's the cleaned Markdown:

## Social Network Analysis of 45,000 Schools: A Case Study of Technology Enhanced Learning in Europe

**Ruth Breuer¹, Ralf Klamma¹, Yiwei Cao¹, and Riina Vuorikari²**

¹ RWTH Aachen University, Informatik 5 (Information Systems)  
Ahornstr. 55, D-52056 Aachen, Germany  
{breuer,klamma,cao}@i5.informatik.rwth-aachen.de

² European Schoolnet, eTwinning  
Rue de Trèves 61, 1040 Brussels, Belgium  
riina.vuorikari@eun.org

## Abstract

Social networks make an essential contribution to knowledge sharing in our fast moving and changing world. However, it is difficult to apply new techniques to the complex, firm and Europe-wide differing educational systems. And this process for technology enhanced learning is still evolving and challenging. This paper presents the research results of applying social network analysis methods to a real and lively social network which intends to enhance the cooperation and knowledge sharing among over 45,000 European schools within the eTwinning network. We developed a web-based tool for network analysis and the visualization of various network views and data mining results as proof of concept. This prototype is evaluated on the educational social network eTwinning coordinated by the European Schoolnet, with special regard to its network structure and collaboration activity.

**Keywords**: Social Networks, Knowledge Sharing, Social Network Analysis, Network Visualization, Data Mining, Information and Communication Technologies, Technology Enhanced Learning.

## Introduction

Unknowingly internalizing fundamental knowledge in infancy, we never stop learning in our whole life. This learning process is mandatory to keep pace in a constantly and more and more rapidly changing world. Nowadays it is supported by numerous organizations. In 2000 the European Council postulated policies and actions for an European Lifelong Learning as part of the Lisbon Strategy [Com01]. Essential components are firstly skills and usage of Information and Communication Technologies (ICT), and secondly access to learning opportunities for people of every age group.

Europe consists of numerous countries having diverse educational systems, long histories and old traditions. The different environments complicate cooperations between European teachers as well as evaluating their competences in comparison to other schools in other countries. Moreover, teachers should be assisted by ICT for their lifelong learning process. Since 2005, the European Schoolnet (EUN) coordinates the eTwinning initiative¹, which is part of the European Commission's Lifelong Learning Programme and intends an advancement of cooperations between European schools by the usage of ICT. eTwinning is a web-based social network of thousands of European schools, which can form partnerships to work on projects integrated in the curriculum of their pupils.

Although creating, managing and handling school networks implicate their own problems [BGJ+07], they are indispensable for integrating both ICT and European culture in the educational system and curriculum. However, improving the daily routine in schools in this way is a more and more important challenge in an Europe growing together. Educational networks are social networks consisting of different actors and their relationships. But beside the opinions of the actors, various traditions and values as well as proceedings and educational directives may have influence on their behavior. Thus, it is not easy to reconcile all these factors in one direction for Europe.

In addition, social network structure is crucial for its working, because separated actors are not able to learn from each other. Hence, structural knowledge may increase the efficiency by selectively enhancing the connectivity of rather isolated actors. However, the density of interdependencies is one reason for the complexity of social network analysis (SNA). Another measure is the network dimension which often receives an unmanageable size. eTwinning is a very large and complex network with over 45,000 actors, and its structure was completely unknown up to this approach. But in social networks, the rather technical knowledge of the structure is not the only difficulty.

Further problems arise from unt

Here's the cleaned and normalized Markdown:

## Social Network Analysis of 45,000 Schools

The relationships between the nodes contain statements about connections, exchange of resources or even acquaintances, influence and trustfulness in a social network.

## Social Network Analysis

Before an extensive network like eTwinning can be analysed, we need the methodological instruments to describe and explore it. In the 1980s, Bruno Latour and Michael Callon introduced the Actor Network Theory (ANT) [Lat96, SS00]. A network starts with isolated nodes, hardly comparable, which join by-and-by through own actions as well as being a receiver for external actions. Beside human beings abstract actors are considered as nodes, and the network develops due to changes in characteristics and relationships of these actors. Thus, the state of the constantly changing network is only a snapshot of the current result of actions. The Actor Network Theory will help us to describe the eTwinning network and to figure out its different network views, characteristics and relationships.

Although eTwinning consists of over 45,000 schools and teachers, the graph theory is well suited to enhance the network analysis. It is also the groundwork for visualizations, because the intuitive recognization of graphical structures is much better than in adjacency matrices, for example. Hence, basic concepts of the graph theory are an essential precondition for our approach. We are interested in exploring a social network, whose structure provides a significant insight into its activity and efficiency. Therefore, the structure qualities must be inspected. Beside the measurements of network sizes, measurements for computing connectivity and distances are required.

The social network analysis goes far beyond the scope of graph theory. A detailed introduction to SNA concepts can be found in [WF94]. The analysis of the eTwinning network concentrates on the behaviour and influence of its actors. Thus, clusterings [LN05, BE05] and centralities [Fre79, BKW03] are of special interest. Beside these rather mathematical aspects, there exist some phenomena observable in social networks. A typical network characteristic is the small world phenomenon ("Six Degrees Of Separation") discovered by Stanley Milgram [Mil67] in the 1960s. Most of the nodes are linked on a path with only a few nodes in-between, which has a direct impact on a network efficiency and is a good criterion for its structural quality. With this fundamental methodology, a meaningful and detailed analysis of a social network comes into reach. But the analysis is not the only task. The visualization makes its own demands go far beyond the Formal Sciences.

Barely sufficient for the structure, the graph theory does not provide communicating further details concerning the element attributes. Actually, this topic is challenging and there is no general solution. The positioning within the graph structure is a main problem. The size of a large network considerably reduces the visual clarity if the nodes and edges are not well arranged. On the other hand, a visual representation provides a very intuitive understanding of networks and their characteristics, even if they are both large and complex [Kre05]. However, applying new properties to the elements creates further structures in the network, hence, the balance between clear arrangements and the amount of additional information must be well deliberated. In general, three visual concepts exist to realize complex data in a way that structures can be detected intuitively: sizes, colors and shapes. It is even a challenging task to only look at color shades. Although the human eye can distinguish about seven million distinct shades under certain conditions [WM97], it is difficult to distinguish hundreds of colors in a large network, which take an area of just a few millimeters.

## Social Networks

Now we will consider common social networks of today and their realization of analysis. Today social networks are used to find old friends from the school, to exchange resources of every description and so on. Networks like Xing conduce to get occupational contacts. Others like Facebook allow users to present themselves and exchange resources with friends. The efficiency of these networks arises from the network structure and the number of involved persons. But without any methodical analysis, the coordinators can hardly get an idea of the network.

| Network  | Purpose | Existing S

Here's the cleaned Markdown:

## Social Network Analysis of 45,000 Schools

## Toolkits

Visone is very easy in handling [BW04b]. This tool could rather fit our demands. For example, new attributes can be applied to the network and represented by customizable visual aspects. Furthermore, common social network analysis functions can be used and displayed. Unfortunately, Visone cannot handle very large networks, and the layout algorithms leave a lot to be desired. There are other tools providing good analysis or visualization functionalities, for example Pajek or even yEd, a tool based on the same yFiles library as our prototype. But as for Visone and the Network Workbench, they hardly fit our requirements which demand easy handling and interactive exploration based on not editable network data.

Beside these toolkits created for every kind of network, two applications are of interest, which explicitly inspect particular networks. The major task of Nexus is visualizing the individual network of a Facebook member, not including himself (Figure 1 shows screenshots of all four tools.). All direct friends (connections) are shown, including the relationships in-between. It yields no information about the Facebook network in general, thus, it is impossible to conclude anything about the overall network from the small extraction for one single member. Moreover, accurate or detailed analysis factors like centralities are missing. Although StudiAnalyse provides more features for analysis and visualization, it wants for general information as well. Again, the visualization only contains the direct neighbours of the registered member and the connections between them, this time including himself. Even though StudiAnalyse supports generating the corresponding network of a chosen node, the whole network is not transparent. Including the attributes university, sex and liaison state is a good beginning for a detailed network visualization, but extending to further data would be desirable.

## Analysis of 45,000 Schools

In our prior research we have applied SNA onto different social networks. We analysed conference participation networks to recommend computer science researchers interesting academic events [KPC09]. We focused on the dynamic evolvement of Wiki networks [KH08] and identified patterns for digital social networks [KSD06]. All this work helps us analyse the eTwinning network in an appropriate and systematic way.

### Requirement Analysis

Our approach addresses to several user groups with different motivations. The coordinators of eTwinning are interested in exploring the network structure. They want to find out in what kind of network the projects results, and how the participants behave after the registration. The visualization shall give the required substantial overview. Especially participating teachers who do not have any experience in online collaborations, or who for the first time concern themselves with eTwinning, can be motivated to join. Additionally, finding themselves to be at an isolated location in the network may inspire the participants to improve their connection. At last, advancing the knowledge about social networks is commendable altogether, not only for eTwinning users. Table 2 contains a comparison of realized functionalities. We concretize the aims for the prototype "eVA" (eTwinning Network Visualization and Analysis) listed beside Table 2.

Beside those functions, there are other necessary aspects to be considered. First, because eTwinning is realized as a web portal, the prototype should also be web-based. Whereas the lack of experience makes some constraints on handling and help functionalities, it also requires an easy access to social network analysis. Therefore, there should be predefined, already interpreted analysis questions. The large extent of the network necessitates the possibility of regarding the network graph as a whole as well as in detail. Furthermore, to deal with networks always necessitates an explicit model where all of the individual network elements are well-defined in meaning and coverage. The requirements of our prototype eVA is summarized in Table 3.

Overall, this approach works by the following steps. The exported data sets from the original eTwinning database must pass an extensive preprocessing and be stored in a new database. The network models are the base for the visualization and analysis functionalities. These must include the possibility of changing the element properties, searching nodes, layouting the network with different algorithms. Furthermore, predefined questions, the expert

Here's the cleaned Markdown:

## Requirements and Functionality

1. The tool must represent the eTwinning network appropriately in the visualization.
2. Relevant characteristics must be displayed (for example using colors).
3. The analysis must contain common SNA aspects.
4. The application aims not at creating an editor for the network graph, but at giving a detailed overview over eTwinning. Hence, the customization should only be possible up to a certain degree. Experience and expertise of the prospective users are quite unknown, so user interface and functionalities should therefore be simple.

### Functionality Comparison

| Functionality | Nexus | StudiAnalyse | eVA |
|--------------|-------|--------------|-----|
| Visualize the whole network | ✓ | ✓ | ✓ |
| Filter nodes/edges | ✓ | ✓ | ✓ |
| Change layout | ✓ | ✓ | ✓ |
| Show node labels | ✓ | ✓ | ✓ |
| Show edge labels | ✓ | ✓ | ✓ |
| Cluster nodes | ✓ | ✓ | ✓ |
| Cluster edges | ✓ | ✓ | ✓ |
| Legend for clustering | ✓ | ✓ | ✓ |
| SNA concepts | ✓ | ✓ | ✓ |
| Statistics | ✓ | ✓ | ✓ |
| Zooming and moving | ✓ | ✓ | ✓ |
| Search nodes | ✓ | ✓ | ✓ |

### Requirements

#### Modelling
- M1: Represent eTwinning and fit visualization and analysis demands

#### Database
- D1: Avoid redundant and noisy data, optimized for our tasks

#### General
- G1: Client-Server architecture
- G2: Intuitive and simple user interfaces
- G3: Search function for nodes
- G4: Help function

#### Visualization
- V1: Different layout algorithms, optimized for the created networks
- V2: Zoom, navigation and overview function
- V2: Cluster nodes and edges by size and color to display further data
- V2: Browsing function to show evolution of eTwinning

#### Analysis
- A1: General statistics about eTwinning
- A2: SNA statistics and predefined questions

### The Data Models for eTwinning

We want to win an overview of a network which consists of thousands of varying nodes and diverse types of nodes with complexity. Furthermore, we intend to discover characteristics, similarities, coherences and differences of the network elements, in behaviour or attributes. eTwinning consists of the three obvious entities schools, teachers and projects, and moreover, of the entity country. The latter is not integrated in the original database, but of great importance for the goal of eTwinning. To make comparisons between the participating countries possible, this entity has been added as model. It is easy to see that modeling one network with all entities enlarges the already challenging network size extremely. The visual clarity would be lost completely, because different types of nodes must be integrated aside from different characteristics. Therefore, the network is split into four parts. The main model for the overview consists of schools as nodes. Two schools are connected, if they have worked on a project together. And the teacher network is quite similar. In the country network two country nodes are connected, if at least two of their schools worked together. And in the project network two project nodes are connected, if they have been submitted by the same teacher.

### Data Preprocessing and Data Cleaning

At the moment, there are over 45,000 registered schools, even more teachers and over 8,000 projects. For every entity, numerous attributes hold much more information, for example the number of pupils

Here's the cleaned Markdown:

## Social Network Analysis of 45,000 Schools

## System Architecture

The application server communicates with the web client through synchronous and asynchronous protocols. The client holds the graphical user interface (GUI) only, and this comprises all visual representations of the diverse functionalities.

## Implementation of eVA

Handling large networks, modifying and visualizing them requires complex methods. The yFiles package has been employed, which has been developed for graph visualizations and adaptations and includes a huge amount of functions for generating graph structures, transforming them to displayable elements and editing them. But because this library is not intended to be web-based, a second package, the yFiles Ajax library must be used. A great advantage is the asynchronous communication with the application server, because the returned images of the graphs are very large and the layout computation is very time-consuming.

However, the data in the database is not sufficient to generate the networks without any further processing. Consider for example the edges in the school network. A project between two schools is represented by an edge, but an edge represents all corresponding projects. Beginning with the underlying data, a graph must process several realization steps. First, the empty graph and realizers for nodes and edges must be initialized. These are essential for rendering the visual representation of the elements. Then, the data must be requested and corresponding nodes and edges must be created in the graph - including a unique identifier.

When properties are added to the current network graph, the needed data is requested from the database and the corresponding realizer properties are modified for each element. To ensure distinguishable properties and to enhance the reusability, particular color and line sets have been created. If labels have been applied, the graph is re-layouted.

The parameters for the layout algorithms have been empirically tested to generate the arrangements as well as possible. The circular layout can be divided into two algorithms by setting the parameters. The first locates all connected nodes on a single circle. This positioning is useful for dense and symmetric networks. The second results more in a disc. The circles are adapted considering the connections of the nodes. The third algorithm is called smartorganiclayout. It takes the connections of nodes as well as overlappings of elements into consideration and is therefore very good for complex network structures.

In general, there are two different approaches of analysis realized in the eVA prototype. The first is of course the social network analysis, and the second yields some basic statistic about the eTwinning network, partially adapted to the modeling.

These statistics can completely be deduced from the database and are shown in a new window as a table. The statistic function computes amongst others frequently used units like project themes or languages, taught subjects or school types. Applying the corresponding characteristic to the network, the distribution of the values within the network can be seen. Other interesting aspects are activities like summarized by countries and cooperation aspects like the year of the last collaboration.

The social network analysis is divided into two aspects due to varying knowledge and experience of users. As mentioned above, beside usual SNA methods already interpreted questions give an easier introduction. A predefined question replaces the current network with one answering the question; e.g. "Which schools are the most active?" as well as "which have done the most projects?"

The other social network analysis results are computed on the currently presented network. They include the degree, closeness and betweenness centralities. As mentioned in Section 2, some methods can only be applied to completely connected networks. As we do not expect this applicable within eTwinning, we use the other concept for exploring its structure and evolution, the bottom-up approach. With this we can examine increasing structures, beginning with the smallest one composed of two connected nodes. A priori unknown, but of exceptional interest is the distribution of the various structures and what size the largest may achieve. Hence, the network is tested for connectivity, and the distribution of nodes to the components of different sizes are computed. Note, that also the closeness centrality can not be computed, if the network is not completely connected. Like the statistics, the outcomes are shown in a table in a new window. The reason for keeping the results for each single node and edge out of the

Here's the cleaned and normalized Markdown:

## Social Network Analysis of 45,000 Schools

The connectivity for the teacher network is very little, and the school network looks similar. Over 75% of nodes are not connected, even in the networks in 2005-2008. Note, that the networks for the single years indeed consist of all actors registered in this year, but the edges resulting from projects are independent of the date of the cooperation. The low values for 2008 arise from the fact that the export has been made in July. The results show clearly, that the amount of active schools and teachers is very little in comparison to the number of registered ones.

In the complete school network the largest component has a diameter of 20, with 2783 nodes in all. The complete teacher network has a diameter of 19 in the largest component with 4965 nodes. Otherwise, the networks grow constantly (cf. Figure 6). But while the number of new teachers is increasing, in 2007 just one-fifth of schools joined, compared to the year before.

Looking at the project network, where projects are connected if they have been submitted by the same teacher, the connectivity is surprising (cf. Figure 3 (b)). You would think that the initiators of projects are distributed to the whole number of participants, but the half of all projects share the initializing teacher with at least one other project. Thus, the initiative of the teachers differs a lot. However, the country network is very close to the best case. Here, only four edges are missing in the largest component to be a complete graph.

Additional to the implemented SNA methods, we computed further results on a particularly chosen substructure (cf. Figure 7): In the teacher network of 2008, the largest component consists of 65 nodes and 213 edges, and yields several interesting characteristics. First, there are 22 complete substructures - a complete substructure means that all included teachers have worked together on the same project. Other interesting aspects can be found in Figure 8.

Beside the analysis itself, the prototype must be evaluated, too. For this, we submitted an evaluation form to a group of students of the lecture "Web Science" at RWTH Aachen University, and to a group of German teachers participating at eTwinning. The results were quite interesting even though only few teachers participated.

As expected, the previous knowledge of the teachers about social networks and graphs, and the students' knowledge about eTwinning was very low. The estimation of the handling complexity was surprisingly good, though the teachers did hardly dare to test difficult functionalities (cf. Figure 9). Again this understanding argues for the intuitive communication of knowledge via visual representations.

One of the most interesting outcome of the evaluation arise from the questionnaires. What would people do, if they find themselves at a rather isolated position in the network, far from the core. Here, the difference in the knowledge is reflected very strongly. Except one, none of the teachers understood the consequences from this fact. Being well connected means having better opportunities to exchange knowledge or resources. And the contrary is neither good for oneself, nor for the whole network (cf. Figure 10).

## Conclusion and Outlook

In this paper, we have seen the concept and realization of a prototype concerning the analysis and visualization of a certain educational network: eTwinning. Some remarkable outcomes of the analysis concern the connectivity: the only network that is well connected is the country network. All others consist of about 70% of unconnected nodes. This means that the most of the registered teachers or schools are inactive in terms of being involved in projects. On the other hand, several projects are done by many teachers in large cooperations, partially beyond one single school type. eTwinning exists for four years now, and every year, the number of involved teachers grows rapidly, whereas the number of new schools decreases. This can be regarded as positive sign of growth where the expansion of eTwinning happens at the local level involving more teachers within a given school, an outcome of a "back to school" campaign.

There were much more aspects and results of particular interest, but of course, there are still opportunities for improvement

## References

[Com01] European Commission. Communication from the Commission: Making a European Area of Lifelong Learning a Reality, Bruxelles (November 2001), http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=COM:2001:0678:FIN:EN:PDF

[Fre79] Freeman, L.C.: Centrality in social networks: Conceptual clarification. Social Networks 1(3), 215-239 (1979)

[JRW97] Jobson, D.J., Rahman, Z., Woodell, G.A.: A multiscale retinex for bridging the gap between color images and the human observation of scenes. IEEE Transactions on Image Processing 6(7), 965-976 (1997)

[KCD+07] Klamma, R., Chatti, M.A., Duval, E., Fiedler, S., Hummel, H., Hvannberg, E.T., Kravcik, M., Law, E., Naeve, A., Scott, P.: Social Software for Life-Long Learning. Journal of Educational Technology & Society 10(3), 72-83 (2007)

[KH08] Klamma, R., Haasler, C.: Dynamic Network Analysis of Wikis. In: Tochtermann, K., et al. (eds.) Proceedings of I-Know 2008 and I-Media 2008, International Conferences on Knowledge Management and New Media Technology, Graz, Austria, September 3-5. Journal of Universal Computer Science, J.UCS (2008)

[KPC09] Klamma, R., Pham, M.C., Cao, Y.: You Never Walk Alone: Recommending Academic Events Based on Social Network Analysis. In: Proceedings of the First International Conference on Complex Science (Complex 2009), Shanghai, China, February 23-25 (2009)

[Kre05] Krempel, L.: Visualisierung komplexer Strukturen. Grundlagen der Darstellung mehrdimensionaler Netzwerke. Campus Verlag, Frankfurt/Main (2005)

[KSD06] Klamma, R., Spaniol, M., Denev, D.: PALADIN: A Pattern Based Approach to Knowledge Discovery in Digital Social Networks. In: Tochtermann, K., Maurer, H. (eds.) Proceedings of I-KNOW 2006, 6th International Conference on Knowledge Management, Graz, Austria, September 6-8, pp. 457-464, J.UCS. Springer, Heidelberg (2006)

[Lat96] Latour, B.: On actor-network theory: A few clarifications plus more than a few complications. Soziale Welt 47, 369-381 (1996)

[LN05] Liben-Nowell, D.: An Algorithmic Approach to Social Networks. PhD thesis, MIT Computer Science and Artificial Intelligence Laboratory (2005)

[Mil67] Milgram, S.: The Small World Problem. Psychology Today, 60-67 (1967)

[Nik07] Nikolov, R.: Towards web 2.0 schools: Rethinking the teachers professional development. In: Joint IFIP Conference (June 2007), http://dspace.learningnetworks.org/handle/1820/1064

[SS00] Schulz-Schaeffer, I.: Akteur-Netzwerk-Theorie. Zur Koevolution von Gesellschaft, Natur und Technik. In: Weyer, J. (ed.) Soziale Netzwerke. Konzepte und Methoden der sozialwissenschaftlichen Netzwerkforsch

Here's the cleaned and normalized Markdown:

## Analysis of Weblog-Based Facilitation

## Introduction

Social software tools are indispensable for supporting online facilitation. Among such tools, weblogs (or blogs) are playing a more and more important role. Weblog is a type of website that is usually maintained by an individual with regular entries being commonly displayed in reverse chronological order. Weblog has emerged as a popular social software tool in recent years, and blogging as a web-based form of communication is becoming mainstream [4]. In Higher Education Institutions (HEIs) worldwide, we can witness the broad dissemination and adoption of this tool. This increasing trend suggests that learners tend to circumvent the constraints of centralized authorship [5].

Furthermore, weblog meets the need for instant communications in a knowledge-building community [6] because it enables self reflection, student-facilitator and peer communications. Indeed, a salient quality of weblog is its effectiveness and ease-of-use for publishing one's thoughts that invite further intellectual as well as social dialogues. Weblogs provide the space where the decentralized authorship can be realized and create a flexible environment where students can be motivated to reflect and discuss [7].

Being able to engage in sustainable constructive discourses is imperative for motivating students to continuously participate in a web-based learning course. With appropriate design and guiding strategies, weblogs have great potential to become a powerful tool that supports web-based learning in academic institutions and workplaces [8, 9].

Given the foregoing observations, in our project we are motivated to develop better understanding of how facilitators use weblogs as an educational instrument to support the students' activities in a complex multi-national collaborative learning setting, and whether facilitation style plays a role in influencing learners' working styles and performance in a setting where weblogs have been heavily used. We are also very interested in identifying viable approaches to analyse weblog activities for the evaluation of online collaborative learning/facilitation. This issue is very important as a theoretically sound and practically usable content analysis scheme for making sense of usually voluminous weblog contents is still lacking.

Our project aimed to create an open virtual learning space for HEIs in Europe and to advance learners' self-directed learning competence [10]. The validation of these goals was realized through Trials (or field studies). We adopt mixed methods approach to capture data from different sources, actors and perspectives to triangulate the findings.

## Related Literatures on Online Facilitation

In online education, facilitation is an integral part of as well as a critical success factor for group interactions and communications, which take place mostly in some communication media. The correlation between tutors' experiences as well as qualifications and the students' performance in traditional education have been found in many studies (e.g., [11], [12]). However, to the best of our knowledge, no existing papers examine in detail the online facilitation as well as the impact of facilitation styles on the students' learning styles and performance in a cross-cultural collaborative learning environment.

Such learning context has its own features that might influence the students' performance, such as:
- The context of learning (online learning mediated by technology, group-mates coming from different backgrounds and cultures, and learning activities facilitated by facilitators who might also come from different cultures)
- Learning methods (different than those used in classrooms)
- Supports (hardware, software and the like)
- Other matters raised by the cultural differences or time management (different time zones)

Furthermore, facilitators in the online environment are required to be active and experienced in the subjects to be taught [13]. An online facilitator should also be able to adapt to the lack of physical presence in an online environment by creating a supportive environment where students feel comfortable and where they know that their facilitators are accessible.

In reviewing the existing CSCL literature, three points are noteworthy:
1. Target groups are mostly (if not only) students, in other words, there exist only a limited number of studies investigating how facilitators and students interact over time
2. Studies on deploying weblogs for facilitation and on the

Here's the cleaned and normalized Markdown:

## Analysis of Weblog-Based Facilitation

From eight European countries registered for the course. The other eight external facilitators were compensated with some monetary rewards. A face-to-face meeting was held where all facilitators were introduced to the related pedagogical concepts, the Trial scenarios and the tools to be deployed. They also discussed various issues such as student recruitment, course outline, and assessment schemes. This bootstrapping event enabled the facilitators to know each other, thereby laying the groundwork for subsequent collaborations. The physical meeting was followed by a series of regular videoconferences where the facilitators could share some practical experiences and strategies for resolving issues such as passive students.

The participating students were under- and postgraduates majored in different fields of information science and social sciences. They were divided into 10 different groups, designated as Group1, Group2 and so forth. Each group was supervised by a facilitator. The course lasted 14 weeks. To facilitate establishing collaborative relationships, all the students and facilitators were required to create their own personal weblogs to introduce themselves. Each group was required to develop an online course on the topic of their choice. For each week, there was a specific e-learning topic, and the students were required to read a list of related learning materials and to write their reflections on their individual as well as group learning activities by using a pre-defined template in their weblogs. Besides weblog, which was used as the main tool of the Trial, the students could also use other recommended open source social software to support different activities.

Furthermore, our project aimed to form a "distributed collaborative learning space" [10], in which the facilitators and students were allowed to easily share, exchange, search and browse weblog data without moving back and forth among several weblogs. A feed mechanism was the technical solution. It enables the creation of the mashed team feed to monitor weblog postings and comments, i.e. making team members aware of each other's postings. This mechanism allows a user to reply to other users' postings not in their weblogs but in their own one. A user can also keep on their weblog aggregated contents of all "subscribed" weblogs. The technical team of the project has developed a WordPress Feedback plugin to support the feed management, enabling the user to activate and deploy the feed mechanism easily [14]. The proposed feedback mechanism complements the existing feed standards, including RSS 2.0 or Atom. Furthermore, the students were asked to categorise their weblog messages with some pre-defined tags (e.g. groupXXreflection). The tagging scheme enables efficient search for specific messages in a weblog.

## Data Analysis and Results

### Blog Analysis Scheme

To analyse weblogs effectively, we have developed a weblog analysis scheme originally inspired by France Henri's [15]. In her scheme, the transcripts are analysed according to five dimensions, which are participative, interactive, social, cognitive and metacognitive. Her approach is grounded in a cognitive view of learning, focusing on the level of knowledge and skills evident in the learners' communications and has been applied widely for evaluating (mostly) forum discussions in many online learning courses, e.g. [16, 17, 18]. Henri's approach, however, much focuses on forum-based communications, where everybody uses the same instrument provided. It also lacks detailed classification of electronic messages [17]. The cognitive and metacognitive dimensions defined in Henri's scheme are very hard to measure and the inter-rater reliability [19] tends to be very low.

We have much extended and adapted Henri's scheme to the context of using weblogs in an online cross-cultural collaborative learning environment. We have combined content analysis and social network analysis (SNA) techniques [20] to analyse and visualise the collaborative learning and interaction patterns derived from the weblog messages. The proposed analysis scheme has been deployed to evaluate the Trial, which is a very complex web-based multi-national collaborative learning context. In the Trial, we focus on evaluating the learning and interaction activities taken place in a collection of individual and group weblogs.

### Analysis Results

To facilitate the evaluation, the whole

## Analysis of Weblog-Based Facilitation

## Facilitator Activity Analysis

The facilitators showed varying levels of engagement. fa1 and fa2, who co-designed the course, were among the most active facilitators. fa1 posted 39 messages in her weblog and commented extensively in both her Group1 and other groups' weblogs. fa2 had the highest number of posted comments and was very active in initiating discussions. fa3 and fa5 were also very active, while fa4, fa7 and fa10 were more passive with only seven, seven and twelve weblog posts respectively.

The "distributed collaborative space" concept was not effectively implemented, with limited participation. Eight facilitators activated the feedback plugin but only six (fa1, fa4, fa5, fa7, fa8, fa10) received student feeds in their weblogs. Others simply added hyperlinks to student weblogs. While four facilitators (fa1, fa4, fa5, fa6) provided tagging instructions, only fa1 and fa5 applied the pre-defined scheme. Student participation in tagging was minimal - only two students used the prescribed tags, though some used their own meaningful tags.

Of 51 students who activated the feedback plugin, only 28 received feeds from facilitators/group members, mostly viewing rather than replying to messages. Group1, led by fa1, showed the most effective use of the feeding/tagging mechanism due to strong encouragement and demonstrated benefits.

## Content Analysis

### Message Unit Types
Messages were classified into four types:
- TA: Task-related content
- CO: Coordination content (e.g., organizing meetings)
- SO: Social-related units
- TE: Technical issues

SO units dominated Phase1 and Phase3, while Phase2 saw slightly more TA units. TE units remained low throughout all phases.

### Message Categories
Messages were classified into two core categories:

1. Course Design
- About 71% of facilitator statements expressed interest in learning new things
- Expectations included learning social software tools and gaining international experience
- Other expectations: meeting people, sharing ideas, establishing cooperation

2. Groupwork
- SO messages primarily focused on encouragement
- Other SO messages covered health issues and greetings
- Facilitation and groupwork strategy messages were also prominent

### Groupwork Strategies
Cooperation was the predominant working style, though collaboration was encouraged. Students typically worked separately on sub-tasks of the main course design project, occasionally switching to collaborative mode using synchronous tools. Tool selection was heavily influenced by facilitator guidance.

### Facilitation Styles
Facilitators demonstrated diverse approaches:
- fa1 and fa2 were highly engaged with thorough reflections and research questions
- Some facilitators (fa1, fa2, fa3, fa5) viewed the Trial as a mutual learning opportunity
- Posting styles ranged from formal to social-focused
- fa1 particularly emphasized being "part of the group" and actively promoted the feeding/tagging mechanism

Here's the cleaned and normalized Markdown:

## Analysis of Weblog-Based Facilitation

Some facilitators like fa2, fa3, or fa5 were more informal. The active facilitators fa1, fa2, fa3, fa5, fa8 followed their groups' progress closely. They regularly provided feedback and guidance to students and helped with collaborative learning activities. Furthermore, fa1, fa2 and fa5 actively raised questions for further discussions or research, e.g. "What do you think about our group work according to the principles [...]...". In contrast, fa4, fa7 and fa10 were quite passive in posting to their weblogs, mostly sharing generic Trial-related instructions. While fa9 posted frequently, most messages were generic instructions or encouragement without active involvement in student activities.

Passive members were one of the Trial's biggest problems. Despite high registration numbers, only a small number of students in each group actively contributed and benefited. There seemed to be no optimal solution to motivate passive members. Facilitators tried various approaches:

- Sending individual and group emails
- Posting messages and comments in passive students' weblogs
- Organizing group chat meetings
- Local facilitation

As fa1 posted: "...We can't stop to wait the others to catch up because we're having a rather tight schedule with our other studies as it is...." They also noted that "...local facilitators and local peer help was helpful to figure out why people are missing...". This proved effective as local facilitators had stronger influence on local students. Many facilitators, including fa5, fa6 and fa8, organized regular face-to-face meetings with local students from various groups to discuss the Trial and groupwork.

### Social Network

Social network analysis of weblogs plays a crucial role in our analysis scheme. Typically, a single user (the blogger) writes a weblog that is closely identified with them. Weblog interaction may emerge when:

1. A user explicitly posts a comment on an original message
2. A new message implies or refers to an idea from a previous message (though this is harder to track)

Our analysis addresses both interaction cases. First, we construct interactions amongst weblog users, considering both intra-group and inter-group interactions. This reveals:

- Learning community structure
- Participant activeness and contributions
- Interactions and relationships developed over time

Second, we analyze and visualize unit connectivity, investigating questions like "Were there references between units from same or different weblogs?" and "What was the complexity of connected message chains?"

### Participant Interactions

During Phases 1 and 2, there were many connected participants. Phase 1 saw exchanges of social messages and welcome comments, plus discussions of previous course experiences. Phase 2, the working phase, required individual and collaborative work to design an online course, increasing connected participants. However, some groups like Group 7 showed decreased connections as the course progressed. Phase 3, being the final phase, saw significantly reduced interactions as only active members remained and tasks required fewer interactions.

The whole course learning community analysis showed varying interaction patterns across groups. The sociogram in Fig. 1 displays the social structure of Phase 2 interactions, with facilitators as larger blue nodes and students as smaller red nodes. Groups showed different interaction densities:

- Dense interactions: Groups 1, 3, 5, and 8
- Few interactions: Groups 4, 6, 7, and 10
- All groups had "isolated" nodes representing non-interacting students

Closer examination of Group 1 in Phase 2 revealed seven cliques, defined as maximal complete sub-networks containing three nodes.

Here's the cleaned and normalized Markdown:

## Analysis of Weblog-Based Facilitation

## Message Interaction Analysis

Several cliques were found in the interaction analysis, each composed of three participants. fa1 was found in six cliques, implying their activeness or centrality in group activities. The calculated Freeman's centrality degree confirmed this, with fa1 having a very high centrality degree (OutDegree: 39, InDegree: 13). In contrast, Group7, a passive group in Phase2, had only one clique which did not contain the group facilitator fa7. g7st2 was the most active student of Group7 with both Freeman's OutDegree and InDegree being only 5.

Several inter-group interactions were found, many originating from fa2 or between facilitators and students from the same country. fa2 played a central role in community interactions, interacting with students across all ten groups, though interactions within Group2 were not particularly strong. Another interesting case was fa8, a Finnish facilitator who had strong interactions with local Finnish students. All inter-group interactions were with Finnish students, who demonstrated high technical skills and good communication.

## Message Connectivity

The message connectivity analysis revealed several patterns:

- During Week1/Phase1, star-pattern links appeared in almost all weblogs, attributed to facilitators and students commenting on self-introduction messages
- Group working approaches depended heavily on facilitator and active member suggestions
- Group1 showed strong message interactions on the facilitator's weblog
- Group5 adopted Google group for discussions in Week4
- Group9 had only two active students who preferred working through individual weblogs
- Group10's facilitator (fa10) was passive, resulting in weak message interactions
- "Weak" groups like Group7 had few posted messages and connected messages during Phase2

## Discussions

### How facilitators use weblogs as an educational instrument

The Trial required facilitators to possess:
- Subject-matter and pedagogical knowledge
- Competence in enabling technologies
- Ability to monitor international students
- English language proficiency
- Motivation for timely feedback across time zones

Despite most facilitators being education experts, their abilities varied significantly. Some were highly motivated and active, while others were passive. Their weblog-based facilitation approaches differed, with active facilitators using weblogs as important communication channels while passive facilitators used them only for generic instructions.

### The influence of facilitation styles on the students

The facilitator's approach to organizing and using their weblog strongly impacted student usage. The feeding mechanism proved practical for collecting data from different weblogs in one place.

Here's the cleaned and normalized Markdown:

## Analysis of Weblog-Based Facilitation

## Findings on Facilitation Styles and Impact

A pre-defined tagging scheme could greatly support the formation of a "distributed collaborative learning space" by making browsing/searching in weblogs easier. However, only in Group1, where facilitator fa1 strongly encouraged students to use the proposed feeding/tagging mechanism, were the feed functions used as expected. The fact that only half of the students who activated the feedback plugin exploited the feeding features implies some misconceptions about feeding concepts. Facilitators needed to use this mechanism effectively to demonstrate and encourage usage, strictly following the tagging scheme to set examples. They should have provided clear instructions about the basic ideas to avoid misunderstandings about 'standardised' tags.

The analysis shows that facilitators' activeness in posting messages and comments impacted how students used their weblogs. More active facilitators corresponded with more active student weblog use. In groups where facilitators actively raised discussions or research questions, student postings were high and interactions were dense. With passive facilitators, interactions were rarely found.

No significant correlation emerged between students' grades and facilitators' facilitation styles. In all groups, there were both active and passive students. Active students completed the Trial even with limited facilitator intervention, while even in groups with very active facilitators, many students dropped out quickly. Motivation, self-directed learning competence and cultural features appeared more influential in weblog usage effectiveness.

Cultural differences in student readiness for self-directed learning were apparent. Finnish students consistently outperformed southern European students in activeness, leadership, motivation, autonomy, and critical thinking. Students from countries where autonomy is less encouraged tended to be less self-directed. As facilitators noted in interviews, "there was some cultural problem between different people in understanding their roles and the way they have to perform their joint projects."

## Analysis of Weblog Activities for Evaluation

The analysis demonstrated weblogs as a rich evaluation source for studying group interactions and collaborative learning activities. The proposed weblog analysis scheme proved useful in analyzing large amounts of weblogs efficiently. Combining qualitative, quantitative and SNA approaches allowed comprehensive understanding of complex qualitative data. Visualization of interactions at both people and message levels revealed learning community structure and weblog connectivity intuitively.

However, drawbacks include:
- Subjective message classification and categorization
- Difficulty tracing message connectivity across weblogs
- Time-consuming data extraction and analysis
- Need for further development of the cognitive process dimension

## Concluding Remarks

Weblogs serve as powerful tools in web-based learning, enabling student self-reflection, thought expression, and peer exchange. They provide communication channels for facilitators to guide online collaborative learning activities. Future research questions include:

1. Feasibility of automating weblog content analysis using software like Atlas.ti, NUD.IST, and NVivo
2. Alternative approaches to weblog content analysis, including pattern analysis
3. Exploration of e-learning patterns in weblog data

Here's the cleaned Markdown:

## Analysis of Weblog-Based Facilitation

Our future work may contribute to this question:

- Third, differentiating active from inactive weblogs relies on some arbitrary, non-validated metrics and thresholds [28]. A one-message weblog is clearly a passive one. However, given the wide variety of posting behaviours, it is very hard and impractical to apply a consistent threshold to all users. The weblog content analysis and the social networks construction would help reveal the quality of the postings as well as the activeness and the participation in the group and community activities of the weblog user, but the processes involved are extremely time-consuming. We plan to develop and validate a mechanism that streamlines this process.

### References

1. Howell-Richarson, C., Preston, T.: Introduction. Reflecting Education 1, 1–2 (2005)
2. Salmon, G.: E-moderating: the Key to Teaching and Learning Online. Kogan Page (2000)
3. Friedman, P.G.: Upstream facilitation: A proactive approach to managing problem-solving groups. Management Communication Quarterly 3, 33–50 (1998)
4. Nardi, B., Schiano, D.J., Gumbrecht, M.: Blogging as social activity, or, would you let 900 million people read your diary? In: CSCW conference, Chicago (2004)
5. Karger, D., Quan, D.: What would it mean to blog on the Semantic Web? In: McIlraith, S.A., Plexousakis, D., van Harmelen, F. (eds.) ISWC 2004. LNCS, vol. 3298, pp. 214–228. Springer, Heidelberg (2004)
6. Divitini, M., et al.: Blog to support learning in the field: lessons learned from a fiasco. In: IEEE conference on Advanced Learning Technologies, Taiwan (2005)
7. Lin, W.-J., et al.: Blog as a tool to develop e-learning experience in an international distance course. In: 6th International conference on Advanced Learning Technologies, The Netherlands (2006)
8. Alexander, B.: Web 2.0: A New Wave of Innovation for Teaching. Educause Review 41 (2006)
9. Jackson, A., Yates, J., Orlikowski, W.: Corporate blogging: Building community through persistent digital talk. In: 40th Annual Hawaii International conference on System Sciences (2007)
10. Fiedler, S., Kieslinger, B., Ehms, K., Pata, K.: D1.3: iCamp educational intervention model. Technical report (2009)
11. Darling-Hammond, L.: Teacher quality and student achievement. Education Policy Analysis Archives 8(1) (2000), http://epaa.asu.edu/epaa/v8n1.html
12. Foster, G.: Teacher influence on student performance and selection in broad-spectrum tertiary education. Working paper, University of South Australia (2007)
13. Illinois Online Network: Educational Resources Web, http://www.ion.illinois.edu/resources/tutorials/pedagogy/instructorProfile.asp
14. Wild, F. (ed.): An interoperability infrastructure for distributed feed networks. Technical report (2007)
15. Henri, F.: Computer conferencing and content analysis. In: Kaye, A.R. (ed.) Collaborative learning through computer conferencing. Springer, Berlin (1992)
16. Hara, N., Bonk, C.J., Angeli, C.: Content analysis of online discussion in an applied educational psychology. In: Center for Research on Learning and Technology. Indiana University, Bloomington (1998)
17. McKenzie, W., Murphy, D.: I hope this goes somewhere: Evaluation of an online discussion

Here's the cleaned and normalized Markdown:

## Sharing Corpora and Tools to Improve Interaction Analysis

Christophe Reffay and Marie-Laure Betbeder

LIFC: Computer Science laboratory of the University of Franche-Comté  
16 Route de Gray  
25030 Besançon cedex, France  
{Christophe.Reffay,Marie-Laure.Betbeder}@univ-fcomte.fr

## Abstract

A very wide range of online interaction analysis staying in the hands of researchers, and tools being implemented in research prototypes, often used only in non-replicated experimentations, we point out the need for TEL research community to reach large scale validation for its results. This paper is a concrete step in this direction. For a deeper collaboration in our community, we suggest to share structured data collections. The Mulce project aims at proposing a structure for teaching and learning corpora (including pedagogical and research context), and especially for interaction tracks. Two main corpora are built according this structure. This paper defines a teaching and learning corpus, shows its main structure and browses some parts of the structured interaction data. We also describe the platform that enables the community to browse and analyze a shared corpus.

**Keywords**: e-research, corpora sharing, interaction analysis.

## 1. Motivation

In the last twenty years, we saw the emergence of an incredible number of tools, services and platforms. One technology quickly replaced the previous one, offering more and more potential for interaction analysis. Some voices in our communities are pointing out the problem of little impact of our research outcomes on real learning situations: our very intelligent tools and services often stay in the researchers' hands and rarely go beyond the prototype stage. The time rate for technology innovation is too high, comparing to the time needed by social science to validate some of our prototypes.

In this paper, in order to propose to the community a way to access, share, analyze and visualize learning and teaching corpora, we propose a new formalism which defines, describes and structures data provided by on-line training. Before presenting our proposal, in this section, we come back to the validation of indicators and tools for Technology Enhanced Learning and present other works related to this contribution.

The study of collaborative online learning, whether aimed at understanding this form of situated human learning, at evaluating relevant pedagogical scenarios and settings or at improving technological environments, requires the availability of interaction data from all actors involved in such learning situations, including learners and teachers.

We can find a lot of technical proposals for indicators for social or cognitive process monitoring especially in the TEL, Intelligent Tutoring System and Computer Supported Collaborative Learning communities of the last decade. If some of these indicators are very specialized, i.e. strongly related to a given tool or activity, we find also very general purpose indicators taking their raw data from widely used communication tools like text chat, text conferencing or e-mail.

These technical implementations for indicators conceptually provide a large range of possibilities and make this research area very creative. The very most part of these indicators (including ours) are designed in a given context, where they show some interesting properties and even promise usefulness for the various actors involved in real situations. Unfortunately, these indicators often stay in the researchers' hands and are rarely used by real actors of the situation. As far as we know, none of them have been validated or at least evaluated by real/concrete actors. The need of validation for these indicators, at least in a given context, becomes crucial if we want this domain to contribute to the real world distance learning area.

These indicators are also rarely reused in other situations or contexts. We argue in this paper that our research community should be able to widen the validity of an indicator by testing it on different situations.

In their work on coding and counting analysis methodology, the authors already pointed out the weakness of our research domain. Replicability, reliability and objectivity need to be improved in our work.

The main idea of research collaboration is already well expressed in the following terms:

> "There is urgent need of putting together complementary strengths and contexts and combining our insights as rapidly as possible to make a

Here's the cleaned Markdown:

## Sharing Corpora and Tools to Improve Interaction Analysis

The JEIRP-IA focused on Interaction Analysis and reported in [10] a template describing IA tools and a common format. This common format should be automatically obtained from Learning Support Environments (by an XSL transformation) and either directly processed by new versions of Interaction Analysis tools, or automatically transformed in their original data source format to be processed by previous versions of these tools. The resulting common format focused more on technical interoperability than on learning context or human readability. The context is given for fine grain interaction.

A very interesting experience in the CSCL community has been initiated by the Virtual Math Team [11]. Multimodal Chat sessions (namely teams B and C of the 2006 Spring Fest) in the Virtual Math Forum have been collected and delivered to numerous (28) external collaborators coming from 11 countries, 18 institutions and 8 different research fields. Every collaborator applied his/her own analysis methods and tools processing these interaction data in order to see what came up. The result is reported in [12]. The same data set has been used also for a pre-Workshop of the last CSCL conference in Rhodes. In this context, we showed how this data set can be structured in a Mulce structure and a new collaboration is currently building this data set as a fully documented corpus to be available in the Mulce repository.

In the Mulce structure, the learning situation and the research context are described as wholes possibly in different formats (IMS-LD, LDL, MotPlus, simple text document, etc.) If they conform to IMS-LD, their identified included objects can be referred to by the workspace elements structuring acts' lists that are recorded in the instantiation part. The nature of sharing perspectives is very different: in the JEIRP, the goal is to share a schema structure, whereas the Mulce platform's main objective is to share the data collections.

For this last issue, an impressive work has been done in the Dataverse Network project [13] described in [14]. We agree with the members of this project on the fact that datasets have to be made available, or at least identified and recorded in a fixed state in order to make sure that data used for a given publication are the same as those identified and (hopefully) made available for other researchers. We also consider that such a (data) publication, when connected to a traditional paper published in a journal or conference, would increase the value of this article and of the related journal (or conference proceedings).

In the Mulce project, we provide a technical framework to describe an authentic situation, described by a formal or informal learning design or detailed guidelines, with a representative number of actual participants, according to a research protocol. We also:
- define a "Learning and teaching Corpus"
- provide a technical XML format for such a corpus to be sharable
- are currently developing a technical platform for researchers to save, browse, search, extract and analyze online interactions in their context

The main idea of the Mulce project is to provide contextualized interaction data connected to published results.

Considering today's available technology, Lina Markauskaite and Peter Reimann drew an ideal research world in [15] where grid computing, middleware services, tools managing remote resources, open access to publications and data repositories, open and interactive forms of peer review process, constitute great potential for e-research. We globally share the same vision for the future of research. Even if we consider that the way to reach this ideal vision is rather long, the main contribution of this paper can be considered as a modest but concrete step in this direction by giving a definition and the data structure of a teaching and learning corpus as well as the associate platform to share such corpora.

Availability of data should enable deeper scientific discussion on previously published results. Other researchers may be able to verify or replicate the methods proposed. It becomes possible to compare methods on the same data and then discuss the result or the efficiency of the methods. This way, different analyses can be done on the same set of interaction data. The Mulce platform currently plans to

Here's the cleaned Markdown:

## Sharing Corpora and Tools to Improve Interaction Analysis

For metacognitive or guiding tools currently designed and implemented for further learning sessions, a set of representative interaction data collections would be very useful (if available) for a calibration step. In such a case, these tools could be tested in the design process by using available (shared) data collections and be applied and evaluated directly by real actors during the first experiment.

We can quote [20] as a good example of experiment where mirroring tools are actually tested by learners to get a bird-eye on their ongoing collaboration in a long-term project using a wiki. In their paper, the authors conclude that this first step of tool evaluation showed its usefulness especially for group leaders, and had a positive effect on collaboration management. A better understanding of the representation seems to be needed by learners to improve their interpretation. The authors plan to give more control to users to choose what and how information should be visualized in order to get a better appropriation of the tool. As wiki has become popular in our research experiments, we could imagine that other researchers have similar tools or analysis methods that run on such data. Their availability could help to compare these tools if they have the same goal, or to enrich the analysis if they give a complementary point of view.

For computer scientists, it could be enough to put the raw data of the wiki logs and contents on a shared repository, but for the major part of our communities that would analyze the content and draw some interpretations of these analyses, the format of the data should be understandable and the context of the situation readable.

Either we can keep developing more and more prototypes giving intelligent feedback to their (hypothetic) users. This way implies that a great part of our force is dedicated to the construction of new experiments for most of our new prototypes. We can try to reuse a very interesting analysis tool in a slightly different context, but, in the worse case, with very different data formats.

Or we could try to share some representative authentic learning sessions, for a wider use in a test-bed platform, involving researchers from a wider range of sciences, sharing their complementary analysis. Even if some innovative experiments will remind necessary, a lot of time for a lot of us could be dedicated to deepen understanding, to compare and to validate thresholds values, analysis methods and tools, and to build large scale validation of them.

In other words, the questions behind are: What is more efficient between sharing data and sharing format or tools (without data)? Whom for?

The rest of this article is a proposal of "how to share" such a data collection. The next section defines the learning and teaching corpus and describes the structure of its main components.

### Proposal

Our proposal consists in:
1. A formalism to describe learning and teaching corpora
2. A platform to share these corpora [1]

The formalism defines the information which can be contained in a corpus and the structure of the data. Through the platform, researchers can share their corpora with the community and access the data shared by other members of the community.

To share a corpus, a researcher has to provide metadata describing the corpus' components and upload a file describing each component. While accessing a corpus, an identified researcher is provided with a variety of tools to browse the corpus components, to navigate through the contextualized interaction data, to visualize and to analyze them.

### Proposal 1: Learning and Teaching Corpus Formalism

In the many fields involved in computer mediated interaction analyses, we can find different research methodologies that result in different needs and especially different ways to save and describe the data. If the definition of "learning and teaching corpus" necessarily depends on the way research experimentations are conducted, we claim that our definition is general enough to fit this variety and a crucial point for the concrete structure is to make explicit the methodological choices for a given experiment.

In this section, we first present the main phases involved in this methodological process. Then, we give the derived definition of a "learning and teaching corpus" and explore the structure of its main components.

#### Building and recording interaction in an online training

A general organization for an online experiment is illustrated on figure 1.

Here's the cleaned and normalized Markdown:

## Learning and Teaching Corpus: Definition and Structure

Both documentations of the design phase describe the context of the experimentation. This information often stays in the head of the researchers involved in the experimentation. Instantiation phase produces the core data collection that is analyzed in the third stage. Having the context in mind, these researchers can interpret properly their results during the analysis phase.

As a consequence, in order to make this data collection sharable with external researchers, we show how the various phases presented above become the main components of the corpus defined in the next section.

### Learning and Teaching Corpus: Definition

We define a Learning & Teaching Corpus as a structured entity containing all the elements resulting from an on-line learning situation, whose context is described by an educational scenario and a research protocol. The core data collection includes all the interaction data, the training actors' production, and the tracks, resulting from the actors' actions in the learning environment and stored according to the research protocol. In order to be sharable, and to respect actor privacy, these data should be anonymised and a license for its use be provided in the corpus. A derived analysis can be linked to the set of data actually considered, used or computerized for this analysis. An analysis consisting in a data annotation/transcription/transformation, properly connected to its original data, can be merged in the corpus itself, in order for other researchers to compare their own results with a concurrent analysis or to build their complementary analysis upon these previous shared results.

The definition of a Learning & Teaching Corpus as a whole entity comes from the need of explicit links, between interaction data, context and analyses. This explicit context is crucial for an external researcher to interpret the data and to perform its own analyses.

The general idea of this definition intends to grasp the context of the data stemming from the training to allow a researcher to look for, understand and connect this information even though he has not attended the training course.

### Corpus composition and structure

The main components of a learning & teaching corpus are:

- The Instantiation component, the heart of the corpus, which includes all the interaction data, production of the on-line training actors, completed by some system logs as well as information characterizing actors' profile.
- The Context concerns the educational scenario and the optional research protocol.
- The License component specifies both corpus publisher's (editor) and users' rights and the ethical elements toward the actors of the training. A part of the license component is private, held only by the person in charge of the corpus. Only this private part may contain some personal information regarding the actors of the training.
- The Analysis component contains global or partial analysis of the corpus as well as possible transcriptions.

The Mulce structure aims at organizing the components of the corpus in a way that enables linking the components together. For example a researcher, while reading a chat session (which belongs to the instantiation component), must be able to read the objectives of the activity (which belongs to the pedagogical context).

Moreover, it is important for the Mulce format to allow, digging the component data on the platform. A standard exchange format is also required to download the whole corpus.

Considering these constraints, we chose the IMS-CP formalism [21] as the global container. This XML formalism fits these constraints by expressing metadata, different levels of description, and an index pointing to the set of heterogeneous resources.

Each corpus is thus archived as a Content Package [21], including metadata, descriptions and related resources used in each of the components.

### Instantiation component: Actors and environment description

This component consists in describing:
1. The actors
2. The technological environments
3. The tools used during the learning activity
4. The groups and their members

We consider that the pedagogical scenario can describe the generic activity of a group by specifying the roles without assigning them to actors and declaring only the type of the involved tools. For example, in the abstract pedagogical scenario, one can define a negotiation activity for the production of a collective document that has to be performed by each group using a chat and a forum. In the instantiation part of the corpus, we have to define all actors involved and concrete environment use

Here's the cleaned Markdown:

## Sharing Corpora and Tools to Improve Interaction Analysis

### Institution and Profile Attributes
Institution and some cultural or cognitive profile attributes if needed (country, mother tongue, etc.) When more specific information is required, the structure may be extended by a specific XML schema.

### Instantiation Component: Workspace Concept
The hierarchical structure of the learning stage is captured in the workspaces element, i.e.: a sequence of workspace elements (see Fig. 3).

![Extract of the XML Schema](Fig. 3)

A workspace is generally linked to a learning activity (of the pedagogical scenario). It encompasses all the events observed during this activity, in the tool spaces provided for this activity, for a given (instantiated) group of actors. As shown on figure 3, a workspace description includes its members (references to the actors registered in the learning activity), starting and ending dates, the provided tools and the tracks of interaction that occurred in these tools. In order to fit the hierarchical structure of learning and support activities, a workspace can recursively contain one or more workspace elements.

The lists of places, sessions, descriptors, contributors and sources defined in the workspaces element can be referenced by workspace, contribution, or act elements. For example, descriptors may list identified categories so that each act of the acts element list could refer to one or more of these categories. This principle enables to browse the interaction data in many different ways, independent to the concrete storage organization in the XML document.

Our specification describes communication tools and their features with a great level of precision. The corpus builder can specialize/particularize the schema (i.e., restrict it) to fit the specific tools and features proposed to the learners in a specific learning environment. In the meantime, if a tool cannot be described with the specification, one can augment the schema by adding new elements, in order to take into account the tool's specificities. Both of these mechanisms offer two ways, the specification can be extended to fit the tools specificities or analysis needs.

Moreover, recursive workspace description enables the corpus descriptor to choose the grain at which he needs to describe the environment. Thus, a workspace can be used to describe a complete curriculum, a semester, a module, a single activity or a work session (a concept generally related to synchronous learning activities). The workspace concept represents the space and time location where we can find interaction with identified tools. This notion has the same modularity as the EML learning units [22], [23].

Devices and tools within which interaction occurs can be as different as a forum, a chat or collaborative production tools (e.g., a conceptual map editor, a collaborative word processor, a collaborative drawing tool).

![Extract from the XML Schema – the act concept](Fig. 4)

Interaction tracks are stored according to the act's structure presented on figure 4. All actions, wherever they come from, are described by an act element. An act necessarily refers to its author identifier (defined in the members list – Fig. 3), and a beginning_date. Depending on the nature of the act (act_type), an optional endind_date can be specified. The act_type element is a selector. The actual content (or value) of the act depending on its type, is stored in the appropriate structure.

For example, a chat act (see Fig. 5) can have the type in/out (actor entering/leaving), it may contain a message, can be addressed to all the workspace members or to a specific one (e.g. if it is a private message). A chat act can contain an attached document (file) which in turn is described by a name, a type and a date. Optional element comment contains a sequence typed text of any type and can be used to store researchers' annotations. The last optional element of the act's structure (any) leads to any extension not provided in our schema.

Here's the cleaned Markdown:

## Sharing Corpora and Tools

### XML Schema and Data Structure
This XML Schema defines the storage structure for many act types, e.g.: forum message, chat act, transcribed voice act, and more. For lack of space, this paper only gives some of the main ideas of this schema, but the complete schema for structured information data is available online [24].

The definition, composition and structure of a Learning & Teaching Corpus have been presented in the sections above. The next one explains how these data structures can be shared and computerized on the Mulce platform.

### A Platform for Corpus Sharing

#### Sharing corpora
Once data have been collected, structured and described by metadata, we are ready to share them on the Mulce platform. Being connected with other Open Archive Initiative repositories [25] [26], the Mulce platform deals with sharing metadata and our corpus objects become visible for the whole community. Two mains corpora (Simuligne and Copeas) are already uploaded. About twenty related corpora containing analyses are also in our repository. This paper is also an invitation for all researchers to prepare their corpora in order to share them on the Mulce platform, keeping them readable.

The deposit of a corpus consists in declaring it, describing it by means of general metadata, and uploading its components (described previously). Each component has a specific formalism. These can either be standard formalism such as Learning design [27] (used for the context components: educational scenario and research protocol), or the specific formalism described here above for structured interaction data. If these recommended formalisms are used to describe the various components of the uploaded corpus, the researchers will fully benefit from all the tools provided one the Mulce platform to navigate and analyse the entire corpus. Otherwise, the corpus will be downloadable as is by other researchers. Each component is described by its specific metadata. On the Mulce platform, these metadata can be used by a researcher to find corpora that fit particular constraints. For example the researcher can select the corpora pertaining to its own research interests, either in terms of used tools, of targeted audience or logged tracks.

### Browsing and analyzing corpora
The second part of the platform proposes the visualization, the navigation and the analysis of structured interaction data. Corpora or selected parts of corpora can be downloaded by identified researchers. In this part, two distinct aspects are considered: the navigation / visualization aspect, and the analysis aspect of corpora.

The interest of the navigation / visualization aspect is twofold. Firstly, the corpus becomes independent to the (evolving) software, where originally interaction took place. This is a major benefit for data longevity and reusability. Secondly, because of the main attention paid on the context of interaction in the Mulce project, the interaction navigator makes explicit links between interactions and their surrounded context. Finally, the researcher can select a part of a corpus by means of requests. He can, for example, select all the interactions of an actor using a specific communication tool.

We are currently developing a user interface enabling navigation through different corpora. A first form provides a selection of corpora according to the following criteria: participants (students, tutors, native speakers), technologies (asynchronous LMS, audio-graphic conference, discussion forum, chat, …), pedagogical dimensions (global simulation, intercultural scenario, English and ICT, …), learning fields (French as foreign language, English for ICT, …), analysis tools (forum analysis, synchronized multimodal layouts, social networks analysis, …) language used, interactions and modalities (spatial-, spoken-, textual-, iconic-, multimodal scaffolding language, ..) The result of this request is a list of corpora matching the criteria, with synthetic information. Once selected, a corpora can be described (metadata), browsed (each component with its specific interface), or scanned in order to select or highlight particular acts.

The analysis aspect of corpora concerns the use of tools based on the instantiation component formalism. As an example, patterns of interactions can be detected by a pattern discovery tool [28]. The XML format being defined, we hope that different analysis tools (including indicator synthesis),

Here's the cleaned Markdown:

## Conclusion

Joining the voice of other researchers, this paper deals with the problem of TEL research impact and focuses on the methodology to validate indicators and analysis tools provided by our communities. Because research (not only learning) also could benefit from collaboration tools on the Internet, we think that a more collaborative research could have a greater impact on indicators and then, on real world online learning. Due to the fact that experiments in online learning involve human beings, embarking their specificities and cultural context, the replication is very hard to achieve. This problem prevents two essential validation processes. Two concurrent indicators, used in two different contexts, cannot be compared. And, because original interaction data are not available for other researchers, none of the indicators can be tested on external experiments. This leads to a lack of large scale evaluation for each indicator or tool.

In order to concretize a first step towards e-research, the Mulce project aims at sharing contextualized interaction data in a Learning & Teaching Corpus. Sharing corpora means building a test-bed to compare our indicators and analysis tools on fixed data. This paper proposes a definition, a composition and a structure for such a corpus. A related platform is currently implemented to share, browse and analyze shared corpora.

## References

1. Reffay, C., Chanier, T., Noras, M., Betbeder, M.-L.: Contribution à la structuration de corpus d'apprentissage pour un meilleur partage en recherche. STICEF Journal (Sciences et Technologies de l´Information et de la Communication pour l´Éducation et la Formation) 15, 25 (2008)

2. Rourke, L., Anderson, T., Garrisson, D.R., Archer, W.: Methodological Issues in the Content Analysis of Computer Conference Transcripts. IJAIEd 12, 8–22 (2001)

3. Chan, T., Roschelle, J., Hsi, S., Kinshuk, S.M., Brown, T., Patton, C., Cherniavsky, J., Pea, R., Norris, C., Soloway, E., Balacheff, N., Scardamalia, M., Dillenbourg, P., Looi, C., Milrad, M., Hoppe, U.: One-to-one technology-enhanced learning: An opportunity for global research collaboration. Research and Practice in Technology Enhanced Learning 1(1), 3–29 (2006)

4. Mulce: French national research project 2006-2010 (ANR-06-CORP-006), coordinated by Chanier, T., http://mulce.univ-fcomte.fr/axescient.htm#eng

5. The Pittsburgh Science of Learning Center (PSLC) DataShop, https://pslcdatashop.web.cmu.edu/

[References 6-21 continue in same format...]

Here's the cleaned Markdown:

## References

22. EML: Educational Modelling Language, Open University of the Netherlands (OUNL) (2000), http://www.learningnetworks.org/?q=EML 

23. Koper, R.: Modelling Units of Study from a pedagogical perspective: The pedagogical metamodel behind EML. Technical Report OUNL (June 2001)

24. Mce_sid: Full schema for the structured information data (instantiation component) of a Mulce corpus (2008), http://mulce.univ-fcomte.fr/metadata/mce-schemas/mce_sid.xsd

25. Nelson, M., Warner, S.: The Open Archives Initiative Protocol for Metadata Harvesting. In: Lagoze, C., Van de Sompel, H. (eds.) Version 2.0 (2002), http://www.openarchives.org/OAI/2.0/openarchivesprotocol.htm

26. Simons, G., Bird, S.: OLAC: Open Language Archives Community (2007), http://www.language-archives.org/, http://www.language-archives.org/OLAC/metadata.html

27. IMS-LD: Learning Design Specification of the IMS consortium, version 1.0 (January 2003), http://www.imsglobal.org/learningdesign/ldv1p0/imsld_infov1p0.html

28. Betbeder, M.-L., Tissot, R., Reffay, C.: Recherche de patterns dans un corpus d'actions multimodales. In: Nodenot, T., Wallet, J., Fernandes, E. (eds.) EIAH 2007 Conference: Environnements Informatiques pour l'Apprentissage Humain, Switzerland, June 2007, pp. 533–544 (2007)

29. Calico: French national research project coordinated by E. Bruillard (ERTÉ: Technical Research Team in Education) (French homepage) (2008), http://calico.inrp.fr/

30. Bruillard, E.: Teacher development, discussion lists and forums: issues and results. In: McFerrin, K., Weber, R., Carlsen, R., Willis, D.A. (eds.) Proceedings of Society for Information Technology and Teacher Education International Conference, SITE 2008, pp. 2950–2955. AACE, Chesapeake (2008)

31. Giguet, E., Lucas, N.: Creating discussion threads graphs with Anagora. In: Proceedings of the 9th Computer Supported Collaborative Learning conference (CSCL 2009), Rhodes, Greece, pp. 616–620 (2009)

32. Corbel, A., Girardot, J.-J., Lund, K.: A method for capitalizing upon and synthesizing analyses of human interactions. In: van Diggelen, W., Scarano, V. (eds.) Workshop proceedings Exploring the potentials of networked-computing support for face-to-face collaborative learning, EC-TEL 2006, Crete, October 2006, pp. 38–47 (2006)

33. Dyke, G., Lund, K., Girardot, J.-J.: Tatiana: an environment to support the CSCL analysis process. In: Proceedings of the 9th Computer Supported Collaborative Learning conference (CSCL 2009), Rhodes, Greece, pp. 58–67 (2009)

34. Dyke, G.: Tatiana: Trace Analysis tool for interaction ANAlysts, European LEAD project outcome (2008), http://www.lead2learning.org/projectsite/pagina.asp?

## Distributed Awareness for Class Orchestration

## Introduction

Students complain that they have to wait long for receiving help. Moreover, students often complete only the first exercises of the series while exam items have a difficult level closer to the last exercises of the series. These management problems which make some recitation sections less than optimal will be quantified in our study.

During its two first decades, research on computer-supported collaborative learning (CSCL) focused on the interactions within a team. For a few years, scholars stated to pay attention to the integration of teamwork [1] within broader scenarios or scripts that also include individual activities and class-wide activities (lectures, debriefing, etc.). The notion of "orchestration" refers to [2] the teacher's activity in managing the flow of activities across different social planes (solo, group, class). In CSCL scripts, the orchestration is partly offloaded by 'macro-scripts' [3] which manage this flow of activities. In recitation sections, orchestration is more complicated since there is no predefined flow (but the exercises series). Students working individually or in teams; they move along the series at different speed and have different needs. Teaching assistants (TAs) have to decide who should receive help or, in some cases, if a short collective explanation would be more efficient. In other words, the orchestration of recitation sections is a challenging topic of research.

In this contribution, we model the interactions between students and TAs based on the observations we made in classrooms. Using this model, we analyze the shortcomings of recitation sections, namely how the teaching assistant distributes her time to the different groups of students. In order to address these shortcomings, we designed two awareness tools. We have experimented them in recitation sections to see to what extent it changes the dynamics of recitation sections.

The rest of this paper is structured as follows. Section 2 gives a review of the related works. Section 3 describes the empirical study we have done on several recitation sections, including the observation as well as the qualitative and quantitative analyses which led us to a model of orchestration in this context. In Section 4, we propose two awareness tools designed to resolve the shortcomings. Section 5 describes our second empirical study in which we use these tools in some other recitation sections.

## Relevant Research

Our work has been influenced by contributions from three different fields:
1. CSCL research on tools for regulating teams' interactions
2. The Computer Supported Cooperative Work (CSCW) research on awareness tools
3. The work of ambient interface in human-computer interaction (HCI)

In CSCL, Jermann et al. [4] provided a framework that categorizes collaborative learning supporting systems into three classes:
- Mirroring systems, which display raw indicators to collaborators
- Metacognitive tools, which monitor the interactions, process the collected data and represents the state of interaction via a set of high-level indicators
- Coaching systems, which offer advice based on an interpretation of those indicators

We make use of this framework to compare our work against the others.

The tools we propose fits in the first category as they mirror the state of student groups to the groups themselves and to the TAs without any pre-processing. In contrast, Chen [5] designed a tool, called Assistant, which should be put in the third category (coaching systems). Assistant monitors the collaboration, visualizes the processed data and provides advice to the teacher. It can also learn from teacher's feedback to improve its performance. However, Assistant is basically tailored for the context of distance collaborative learning, while our tools are designed for co-present settings. The difference between our two tools is precisely about how they exploit the physical layout of the classroom.

In the middle category (metacognitive tools), Avouris et al. [6] developed a collaboration environment called Synergo, for collocated and distance learning. Synergo monitors the activity, makes analyses and visualizes quantitative parameters like density of interaction, symmetry of partner's activity etc. While the Orchestration is not the primary goal of Synergo,

Here's the cleaned and normalized Markdown:

## Initial Observations

We observed and recorded 12 recitations sections at our university. They involved three first-year calculus courses given by three different lecturers and groups of teaching assistants. Each course was dedicated to the students from Chemistry, Electrical Engineering or Material Sciences. Each course encompassed a series of weekly lectures as well as recitation sections. We watched and videotaped the recitation classes for four consecutive weeks, each lasting 90 to 120 minutes. Observations were done silently, that is, we tried to retain the classes intact and to observe the dynamics of recitation sections as they take place normally. We videotaped the sessions. An analysis on the videos shows that students and TAs did not pay attention to us after a few minutes of the first session. Table 1 shows the basic parameters of the sections we have observed in four consecutive weeks. (The second week of the Materials class was holiday.) In all classes, grouping was free, i.e. students formed groups ranging from 1 to 6 students.

Table 1. Observed Recitation Sections

Materials | W1 | W2 | W3 | W4
---|---|---|---|---
## of students | 15 | - | 7 | 7
## of TAs | 1 | - | 1 | 1
Duration (min) | 100 | - | 90 | 100

Chemistry | W1 | W2 | W3 | W4
---|---|---|---|---
## of students | 21 | 21 | 22 | 23
## of TAs | 1 | 1 | 1 | 1
Duration (min) | 90 | 100 | 108 | 90

Electrical Eng. | W1 | W2 | W3 | W4
---|---|---|---|---
## of students | 22 | 34 | 26 | 28
## of TAs | 1 | 1 | 1 | 1
Duration (min) | 100 | 90 | 105 | 105

## Qualitative Analysis

For the rest of this paper, we refer to a group of students working collaboratively as a team. A team could consist of only one student. The interactions between teams and the teaching assistant seem to simply follow four steps:

- If a team needs help, it raises hand.
- If the TA is free, she comes to the team and answers the question.
- If the TA is busy, the team waits until she becomes free.
- When the TA finishes answering a question, she becomes free for the other questions.

However, a deeper look at the process of questioning and answering shows that many subtle but important points are not considered in the above sequence:

- The TA does not come to all the raised hands, but only to those she notices.
- The order of answering does not follow the order of help request in a fair way.
- The teams do not raise their hand as soon as they need help, but wait for the moment they can get the attention of the TA. They devote quite a lot of attention to monitoring the TA's availability.
- Conversely, even when the TA is answering a question, she continuously monitors the room to check new raised-hands, which also takes some attention.

Here we try to give a more precise model of teams-TA interaction. According to our observations, we separate teams' activities into two categories:

1. Problem solving: It is the effort that a team put to solve the exercises. It includes individual and group work, exploration, and thinking.
2. Self regulation: While being involved in problem solving, each team builds a dynamic understanding of (1) how much it needs TA's help and (2) the possibility of catching the TA's attention and ask for help. We argue that these two questions are highly interrelated. For example, when a TA is passing by, several teams

Here's the cleaned Markdown:

## Distributed Awareness for Class Orchestration

## Quantitative Analysis

In this section, we quantitatively report the following parameters captured from the observed recitation sections: the waiting time, the while-waiting productivity (the fraction of waiting time used for problem solving), the number of occasions in which the TAs poorly schedule their time in terms of fairness (question n+i is answered before question n) and never-noticed questions. Unfair answering and unnoticed questions are a sign of poor monitoring but also sometimes a sign of adaptive rescheduling (e.g. giving priority to students who are late).

Let us formally define some concepts which we use in our quantitative analysis: A Demand D_i identifies a help request from a team. The function t_raise returns the time when the team raises hand to show the demand D_i, and the function t_start returns the time when the TA starts to answer the demand D_i. A set D = {D_1..D_n} includes all the demands that occur in a certain recitation section, sorted in ascending order with respect to t_start. (i.e. D_i+1 is the demand gets answered right after D_i.)

## Waiting Time

Considering the fact that teams do not raise hand as soon as they need help, hand-raising is not an accurate sign for the beginning of the waiting period. In the following we show (1) how significant this fact is, and (2) how we compute the beginning of the waiting period. Figure 2 splits a recitation section into the periods in which the TA is continuously busy (answering a question for another team) or continuously free. Two consecutive Busy and Free periods form BF iteration.

Figure 3 shows the cumulative distribution of hand-raisings within a single BF episode. For example, one point at (0.5, 0.1) tells that 10% of the teams raise hand during the first half of the BF. This curve is obtained by normalizing the length of all the BF iterations of the observed sections into a same unit of time. The fast growing slope of the curve at the end of the BF illustrates the fact that, in so many cases, the teams prefer to raise hand at the end of the BF, when the TA is free or looks to become free shortly. Figure 3 reveals that teams self-regulate: they refrain to ask questions when there is low probability to receive help. This self-regulation implies that teams devote significant attention to monitoring the TA's availability.

Let us suppose that, within a BF, the number of questions is uniformly distributed in time, i.e. for any team, the probability of facing a difficulty at any time of a BF is uniform. Based on this assumption, we compute the beginning of each waiting period, and consequently waiting time as:

[equations 1-3 preserved as in original]

## While-Waiting Productivity

According to our observations, when teams have to wait for the TA they decide between (1) keeping hand up and still do some problem solving or (2) chasing the TA to capture her attention and minimize the waiting time. We define While-Waiting Productivity as the fraction of the waiting time that is not spent on chasing the TA. We use this parameter as an indicator of the efficiency during the time teams have to wait for the TA. On all 235 questions we have observed, in average, 62% of the waiting time is spent on chasing (38% while-waiting productivity). Section 5 shows how our awareness tools improve while-waiting productivity to 95%. We estimate the chasing time in the following way. For each demand, the difference between the time at which the hand-raising happens and the time we consider as the beginning of waiting period.

## Distributed Awareness for Class Orchestration

## Analysis of Waiting Time Productivity

The fraction of waiting time spent chasing the TA is calculated using the following formula for average while-waiting productivity:

[Original equation 4]

Questions answered immediately are eliminated since productivity of very short waiting periods is almost zero. Averaging the remaining questions gives 38% while-waiting productivity.

## Scheduling Analysis

Table 3 shows instances where TA answers demand dj earlier than di while di was posed before dj. Formally counting all demands di where:

[Original equation 5]

Table 3 also shows demands never answered by TAs.

### Table 3. Unfairness and Non-answered Cases
|                  | Materials | Chemistry | Electrical Eng. |
|-----------------|-----------|-----------|-----------------|
| Week            | W1 W2 W3 W4 | W1 W2 W3 W4 | W1 W2 W3 W4 |
| Unfairness cases| 0 - 0 0 | 0 1 1 0 | 6 0 3 7 |
| Non-answered    | 0 - 0 0 | 0 0 1 0 | 8 3 5 2 |

In summary, analyses confirm initial hypotheses about orchestration quality during recitation sections. Main problems include:

- On average 62% of waiting time is spent chasing the TA for attention, while waiting times are considerably long in many sessions
- TAs sometimes miss raised hands entirely
- TAs frequently answer demands in incorrect order

## Technological Solutions

Two tools were designed to address these shortcomings:

1. Shelf - centralized display
2. Lantern - distributed classroom lamps

Both solutions use the same visual grammar:
- Color: Corresponds to specific exercise
- Intensity of color: Indicates time spent on current exercise
- Blinking: Indicates help request
- Frequency: Faster blinking means longer wait time since request

### Lantern

Lantern is a portable device with:
- Five LEDs on PCB covered by blurry plastic cylinder
- Microprocessor control
- User interactions:
  - Turn to select exercise
  - Press to call TA

### Shelf

Shelf consists of:
- Wide screen display
- Infrared remote controls for teams
- Progress bars labeled by team
- Teams indicate exercise number and help requests via remote

Lantern offers advantages over Shelf for tasks like:
- Identifying help requests through direct classroom observation
- Facilitating semi-public explanations to nearby teams with similar issues

## Performance Evaluation

The awareness tools were tested in two Physics II courses with different teachers and TAs. Test conditions matched initial observation settings regarding team tasks and TA interactions.

## Distributed Awareness for Class Orchestration

## Study Implementation
Three weeks of baseline were followed by four weeks using Lantern. Each week included one two-hour recitation section. Total observation time was 26 hours (12 hours Shelf, 14 hours Lantern, with one cancelled session). This was not a controlled lab experiment, so not all statistical comparisons between sections would be valid.

We present a quantitative comparison of while-waiting productivity across three conditions: no awareness tools, using Shelf, and using Lantern. This metric was chosen as it reflects orchestration process effects while being independent of uncontrolled variables like exercise difficulty or student numbers. We also provide qualitative observations based on observations and questionnaires.

## While-Waiting Productivity (Quantitative Comparison)
Using Formula 4, average while-waiting productivity was calculated:
- Shelf: 84%
- Lantern: 94%

Table 4 compares productivity across conditions:

| Condition | Avg while-waiting productivity |
|-----------|------------------------------|
| No Awareness | 38% |
| Shelf | 84% |
| Lantern | 94% |

The productivity increase stems from reduced attention needed for capturing TA attention. Lantern's superior performance may be due to its high visibility when blinking, reassuring students about getting TA attention.

## Qualitative Comparison

- **Fairness**: Both tools help TAs answer questions in proper order, considering both timing and urgency of requests.

- **Unanswered questions**: Teams using Lantern or Shelf often solve problems while waiting, likely due to higher while-waiting productivity.

- **No late/never demanding**: TAs can notice teams hesitant to ask for help by seeing bright, non-blinking indicators.

- **Progression Awareness**: Students can see other teams' progress (more prominent in Shelf than Lantern).

- **Similar questions**: Tools help TAs identify when multiple teams struggle with the same exercise, enabling group explanations.

- **Overview of the section**: Tools provide quick status overview for visitors/teachers regarding class progress and resource needs.

## Conclusions
Initial study revealed recitation section orchestration issues. While the decentralized version appears more effective, preliminary findings show no major differences between tools. The key finding is that these tools allow students to focus on exercises rather than seeking TA attention. This changes help-seeking dynamics, enabling students to continue problem-solving while waiting and potentially resolve issues independently. The study demonstrates a distributed orchestration model with active student participation.

## Distributed Awareness for Class Orchestration

## Acknowledgments
We would like to thank Prof. Ambrogio Fasoli, Prof. Jean-Philippe Ansermet, the teaching assistants and the students who helped us to conduct this study. In addition to the authors, Olivier Guédat has had a remarkable contribution especially in the hardware development.

This project is funded by NSF grant PDFMI-118708.

## References
1. Tewissen, F., Lingnau, A., Hoppe, H.U., Mannhaupt, G., Nischk, D.: Collaborative Writing in a Computer-integrated Classroom for Early Learning. In: Proceedings of the European Conference on Computer-Supported Collaborative Learning (Euro-CSCL 2001), Maastricht, The Netherlands, pp. 593-600 (2001)

2. Dillenbourg, P., Fischer, F.: Basics of Computer-Supported Collaborative Learning. Zeitschrift für Berufs- und Wirtschaftspädagogik 21, 111-130 (2007)

3. Dillenbourg, P., Hong, F.: The mechanics of CSCL macro scripts. International Journal of Computer-Supported Collaborative Learning 3(1), 5-23 (2008)

4. Jermann, P., Soller, A., Mulenbruck, M.: From mirroring to guiding: a review of state of the art technology for supporting collaborative learning. In: Proceedings of European Perspectives on Computer-Supported Collaborative Learning (ECSCL 2001), Maastricht McLuhanInstitute, Maastricht, the Netherlands, pp. 324-331 (2001)

5. Chen, W.: Supporting Teachers' Intervention in Collaborative Knowledge Building. Journal of Network and Computer Applications 29(2-3), 200-215 (2005)

6. Avouris, N., Margaritis, M., Komis, V.: Modelling interaction during small-group synchronous problem solving activities: The Synergo approach. In: 2nd Int. Workshop on Designing Computational Models of Collaborative Learning Interaction, ITS 2004, 7th Conf. on Intelligent Tutoring Systems, Maceio, Brazil, pp. 13-18 (2004)

7. Beaudouin-Lafon, M., Karsenty, A.: Transparency and Awareness in a Real-time Groupware System. In: Proceedings of the ACM Symposium on User Interface Software and Technology - UIST 1992, Monterey, CA, November 15-18, pp. 171-180. ACM, New York (1992)

8. Shen, H., Sun, C.: Flexible Notification for Collaborative Systems. In: Proceedings of the ACM 2002 Conference on Computer-Supported Cooperative Work - CSCW 2002, New Orleans, LO, November 16-20, pp. 77-86. ACM, New York (2002)

9. Ishii, H., Kobayashi, M., Arita, K.: Iterative Design of Seamless Collaboration Media. Communications of the ACM 37(8), 83-97 (1994)

10. Shen, H., Sun, C.: Flexible Notification for Collaborative Systems. In: Proceedings of the ACM 2002 Conference on Computer-Supported Cooperative Work - CSCW 2002, New Orleans, LO, November 16-20, pp. 77-86. ACM, New York (2002)

11. Wisneski, C., Ishii, H., Dahley, A., Gorbet, M., Brave, S., Ullmer, B., Yarin, P.: Ambient Displays:

Here's the cleaned Markdown:

## Remote Hands-On Experience: Distributed Collaboration with Augmented Reality

**Authors:** Matthias Krauß¹, Kai Riege¹, Marcus Winter², and Lyn Pemberton²

¹ Fraunhofer IAIS, Schloss Birlinghoven, 53754 Sankt Augustin, Germany  
{matthias.krauss,kai.riege}@iais.fraunhofer.de

² University of Brighton, School of Computing, Mathematical and Information Sciences,  
Lewes Rd, Brighton BN2 4GJ, East Sussex, UK  
{Lyn.Pemberton,Marcus.Winter}@brighton.ac.uk

## Abstract

One claim of Technology-Enhanced Learning (TEL) is to support and exploit benefits from distance learning and remote collaboration. On the other hand, several approaches to learning emphasize the importance of hands-on experience. Unfortunately, these two goals don't go well together with traditional learning techniques. Even though TEL technologies can alleviate this problem, it is not sufficiently solved yet - remote collaboration usually comes at the cost of losing direct hands-on access. The ARiSE project aimed at bringing Augmented Reality (AR) to School Environments, a technology that can potentially bridge the gap between the two goals mentioned. The project has designed, implemented and evaluated a pedagogical reference scenario where students worked hands-on together over large distances. This paper describes the AR learning approach we followed and discusses its implementation and its future potential. It shows a simple and successful distributed AR learning approach and suggests features for improvement.

**Keywords:** Augmented Reality, Collaboration, Remote Presence, Virtual Reality, Technology-Enhanced Learning, Human Computer Interaction.

## 1 Introduction

One major claim of the Technology-Enhanced Learning (TEL) domain is to foster collaborative learning processes. Thanks to electronically conveyed media and the Internet, collaboration is supposedly no longer limited to co-located work, but can be extended over long distances. Remote collaboration has been a vivid and fruitful topic of the Computer-Supported Collaborative Learning (CSCL) research community. Several different types of communication and collaboration have been developed, evaluated and implemented in everyday learning practice.

In most of these settings, collaboration is centered around the concept of shared spaces – i.e. places to work together. In traditional co-located collaboration, multiple contributors can work jointly on one physical object and talk directly to each other. For remote collaboration, these means of communication are partially replicated: virtual shared spaces allow collaboration through multiple, technologically synchronized views on a common object. The choice of communication channels and synchronized aspects opens new types of cooperation, but interaction limitations impose new problems and challenges.

So far, the vast majority of remote collaboration tools for learning have been limited to desktop PC settings, using the WIMP (Windows, Icons, Menus, Pointing) interaction paradigm – for example, web-based learning applications. This type of interaction is simple to implement and its requirements are easy to meet. Due to its abstraction, tools can be designed to be generic and application-independent. However, due to its generic and limited interaction paradigm, WIMP interaction comes at the cost of limited graspability, with the learner's experience remaining indirect. Recently, the TEL domain has increased efforts to extend e-learning experience from PCs to other platforms, allowing perceptually richer experiences and more direct interaction.

Augmented Reality (AR) is one possible alternative. In Augmented Reality applications a certain part of the real world is combined with a virtual one. The user interaction within such an environment is usually characterized by a very direct means of manipulating references, i.e. physical objects with optically tracked markers, resulting in the adaptation of the corresponding virtual parts. This supports building scenarios in which a user can interact directly with his or her hands. This resembles learning-by-doing far more than moving a pointer on a screen by moving a computer mouse on a table. Because of this directness of experience, AR is claimed to open up new ways of learning. AR comes in several technological varieties, ranging

## Remote Hands-On Experience: Distributed Collaboration with Augmented Reality

## Related Work

Collaboration is a central aspect of the TEL and CSCL domains. As a consequence, various remote collaboration scenarios, most based on traditional PC interfaces, have been developed and evaluated. Mixed and Augmented Reality technologies have recently entered the e-learning research domain.

Earlier research in AR collaboration was mostly focused on co-located collaboration, i.e. multiple users sharing the same physical space. Reitmayr and Schmalstieg [3], Ohshima et al [5] as well as Regenbrecht and Wagner [6] describe typical set-ups. More recently, different approaches have been taken to solve or circumvent the problem of distributing partially physical realities. Müller and Erbe [7] discuss various challenges of distant collaboration within mixed physical-virtual labs. Bruns' Hyper-bonds approach [8] proposes synchronisation of physical objects through remote force-feedback, using networked sensors and actuators. This approach can provide physical remote synchronisation, but is inherently limited to specific physical set-ups and, due to its implementation requirements, only feasible for a low number of synchronized aspects. A different technique that resembles the approach taken in our studies is to share only virtual aspects while maintaining independent physical half-worlds for each participant, resulting in a rather virtual experience with directness of augmented reality interaction. Among others, Chastine et al [9] used this approach in their studies and highlight the problem of referencing in AR collaboration.

## Pedagogical Reference Scenario

AR has a range of affordances that support learning, including the ability to present objects in 3D, which helps in the development of spatial abilities [10], and the ability to combine real and virtual objects in tangible user interfaces, which may be more suitable for certain kinds of learning activities [11]. In addition, AR has the ability to offer different views on the same object or situation, which aids cognitive development [12], promotes knowledge transfer [13], and facilitates extrapolation by helping learners to go beyond the information given [14].

While these learning affordances have been exploited in previous prototypes [15, 16], the pedagogical reference scenario described here focuses on Spinnstube's support for remote collaboration in a shared workspace.

Collaborative learning is based on social constructivist ideas of learning that emphasise learning through active knowledge construction [12, 14], communication and social interaction [17, 18]. The exchange of ideas amongst peers engaged in the same activity helps learners to develop a deeper understanding of the subject [19] and to reflect upon and conceptualise their experiences as they explain findings, e.g. the meaning of words [20]. In addition, collaborative settings often lead to situations involving peer tutoring [21], which according to Pask's Conversation Theory [22] is a critical method of learning.

Based on these ideas, the reference scenario involved students selecting suitable topics from their local history and culture, preparing 3D digital artefacts, and then using these artefacts in a summer school project to anchor and illustrate one-to-one remote discussions with a peer from another country. The preparation phase involved local collaboration between students to select and discuss suitable topics and artefacts, and it gave them an opportunity to familiarize themselves with the AR learning platform by creating their own demonstration models. The AR application allows learners to sculpt 3D models with simple operations in free space using a light pen. At the summer school, pairs of students first communicated via a video link to get to know each other, and then they started their collaborative AR session. Besides a shared, interactive 3D workspace, the remote collaboration application provides an audio link for verbal communication. Students used this set-up to discuss their mutual local cultures, taking turns to explain customs and traditions and scaffolding their presentation with the prepared artefacts. After their presentation, students asked their counterpart questions about the presented content, both to test the partner's understanding and to enquire about similarities or equivalents in their own local culture. This part also included an exercise where the presenting student erased part of a prepared artefact, using the

Here's the cleaned Markdown:

## Remote Hands-On Experience: Distributed Collaboration with Augmented Reality

### System Overview

The Spinnstube® display system is driven by software based on the Open Source VR/AR framework Avango® [24]. We enhanced this software with modules to communicate with the Spinnstube® hardware. Avango® provides group-based communication of multiple applications on different machines via the Internet, using the Ensemble distributed communication system [25]. Each application can decide which content should be local versus distributed. In the remote collaboration application, the 3D workspace and user cursor positions are synchronized, while menu interaction, status information and users' perspectives remain local.

A fully functional stand-alone application is provided unless connected to another machine. Distribution is implemented via group management, with a gossip server managing group state and participants [25]. After joining a group, members communicate directly via UDP to minimize latency. Remote collaboration groups consist of two members.

Shared content belongs to the group rather than specific users. When a member leaves, their contributions remain. Each Spinnstube® includes headphones, and a Skype [26] connection is established when entering collaboration sessions. Partner presence is indicated through actions, visible 3D cursors, and voice.

### Evaluation Design

The remote collaboration application was evaluated in a distributed summer school project with 13-14 year old students in Siauliai, Lithuania and St. Augustin, Germany. Three independent evaluations were conducted:

- Summative pedagogical evaluation
- Usability evaluation with questionnaires and interviews  
- Formative evaluation using synchronized video observation

This discussion focuses on the formative evaluation to inform future development of collaborative learning platforms.

No established methods exist for evaluating AR displays in remote collaboration scenarios. Gutwin and Greenberg [23] distinguish between:

- Taskwork: Individual tasks unchanged by group work
- Teamwork: Added effort of working together

This enables evaluating AR aspects separately from collaboration aspects. However, literature offers limited evaluation approaches. An analysis of 266 AR publications [27] found only 8% addressed HCI with formal user experiments. Similarly, only 25% of 45 reviewed groupware evaluations [28] involved real-world settings. Key challenges include data collection logistics and complex variables [29].

Traditional single-user evaluation methods inadequately address collaboration [29, 30]. Quantitative metrics alone rarely improve collaborative systems [29], while naturalistic user-based methods show promise for formative evaluation [31, 32]. Therefore, this evaluation used naturalistic observation of remote student collaboration by usability experts.

### Data Collection

Two researcher teams video recorded the remote collaboration between summer school locations:

- Front cameras captured participant gestures and facial expressions
- Rear cameras recorded the display content

Here's the cleaned Markdown:

## Remote Hands-On Experience: Distributed Collaboration with Augmented Reality

## Data Collection

The projection surface of the AR display was recorded to understand what participants could see at any given time (Figure 3). The cameras were synchronised via a common time server on the Internet, and replicated each other's viewpoints and zoom settings.

![Synchronised video observation in two locations recording collaborative sessions](Figure 3)

Recording the remote collaboration sessions from both ends posed several challenges. The AR display is stereoscopic: With the help of shutter glasses, the AR display system produces separate images for each eye, which are then merged by a user's brain into one 3D image. While the video cameras only picked up the double image on the projection surface, but not the 3D image seen by a user, the resulting material still gave a sufficiently accurate idea of what users did actually see. Another challenge was the requirement for a semi-dark environment for the AR display due to specific requirements of the sensing mechanism. While this was not a problem for the rear view recording the projection surface, the front-view recording participants' gestures and facial expressions had to employ a special night-view mode in order to record sufficient detail.

A total of eight collaborative sessions were recorded over two days, involving 16 students in each summer school location. Collaborative sessions were between 22 and 58 minutes in length.

## Data Analysis

To prepare the video material for analysis, a combined view was produced for each collaborative session, merging the front- and rear-views from both locations into a single screen. The resulting 4-in-1 overviews (Figure 4) comprehensively document each collaborative session from both ends, offering more detail about communication and collaboration issues than traditional observation techniques, which document only one side leaving evaluators to speculate about what happens at the remote end.

![The 4-in-1 overview created from the video material for each collaborative session](Figure 4)

With a view to hardware ergonomics of the AR display, two additional videos were produced that showed for each location how students prepared for their collaborative session, taking their seat in the AR display, putting on headphones and shutter glasses, adjusting the equipment and checking the interaction devices.

The data analysis involved a panel of four usability experts from the Interactive Technologies Research Group at the University of Brighton watching the edited video material for each collaborative session. Critical scenes were reviewed and watched again as required to better understand the usability problems at hand. Notes were taken during the screening and then compared and discussed after each session.

Guiding the analysis and discussion were three sets of usability heuristics, which the evaluators had discussed beforehand, and in addition had available in printed form, in order to provide a common reference frame. Each set of heuristics covered different aspects of the formative evaluation, including remote collaboration in a shared workspace, augmented reality specific aspects, and general usability heuristics to complement the first two more specialised sets.

The heuristics relating to remote collaboration in a shared workspace were based on the assumption that small groups need to perform certain low level actions and interactions in order to collaborate effectively: these include communication, planning, monitoring, assistance, coordination, and protection [23]. As insufficient support for these mechanics of collaboration causes usability problems, groupware usability can be defined as "the degree to which a groupware system supports the mechanics of collaboration for a particular set of users and a particular set of tasks" [23]. A detailed description can be found in [33].

Guidelines relating to AR-related aspects draw on the idea that the specific hardware and software required by AR displays present usability issues relating to hardware ergonomics, software robustness, display, and interaction quality. As currently no set of common design guidelines exists for the development of AR systems [34], the guidelines used in the evaluation draw on a range of sources.

## Remote Hands-On Experience: Distributed Collaboration with Augmented Reality

## Design Guidelines and Evaluation

The evaluation was based on heuristics from multiple sources including VR usability heuristics, mixed reality visual displays taxonomy, previous Studierstube AR system evaluations, and project experience. 

### Five Design Guidelines for AR Displays

Table 1. Design Guidelines for AR Displays
1. Reproduction quality - a user should be unaware that overlaid objects are virtual. Reproduction of virtual objects should be in real-time, high-fidelity, 3D animation.
2. Registration - users should not perceive gaps or discrepancies between real objects and augmented content; virtual objects should be fully aligned with the real world.
3. Realistic feedback - the effect of users' actions on virtual objects should be instantly visible and conform to the laws of physics and the user's perceptual expectations.
4. Technical robustness - systems should be reliable and consistent, i.e. avoid freezes, crashes, and frequent need to re-calibrate
5. Hardware ergonomics - display components should not create physical discomfort for users, e.g. accommodation problems, bad fitting helmets or headphones, eyestrain, cyber sickness.

The evaluation also incorporated Nielsen's ten usability heuristics for general issues, complementing the collaboration and AR system guidelines. The evaluation took place over two days based on eight videos of collaborative sessions.

## Evaluation Results

### Remote Collaboration
- Audio-only communication led to language and awareness issues between international students
- Lack of perspective synchronization caused coordination problems
- No visibility of remote users' control/menu actions hindered collaboration

### AR Display
- Video format limited direct evaluation of reproduction quality, registration and feedback
- No reported system crashes or calibration issues suggested good technical robustness
- Hardware ergonomics issues included problems with shutter glasses, headphones, and semi-transparent mirror obstruction

### General Issues
- Lack of undo/redo functionality limited user control
- No preview functionality when loading 3D objects
- Help system was underutilized as students preferred direct assistance

### Discussion
While improvements were identified, the overall impression was positive with high student acceptance of the technology.

Here's the cleaned Markdown:

## Remote Hands-On Experience: Distributed Collaboration with Augmented Reality

The video observation showed that learners were fully immersed into discussions without significant distractions caused by the technology surrounding them.

Overall, the prototype seems well suited for remote collaboration, with some weaknesses being balanced by strong points of the platform. The combination of a 3D sculpting tool, shared interactive workspace, and additional audio channel supports most of the mechanics of collaboration [23], with particularly strong support for intentional communication (verbal, remote cursor gestures) and consequential communication based on the manipulation of shared artefacts (artefact feed-through [33]). The video analysis consistently showed that collaborative sessions became more animated, communicative and interactive when students used the sculpting tool to explain issues and complete collaborative tasks.

AR specific usability problems overwhelmingly concern hardware ergonomics. These problems suggest that the system would benefit from more user involvement in the design process, and from exploring emerging lightweight technologies as alternatives to the current display design.

There is a substantial overlap between the general usability heuristics [38] used in the evaluation and the more specialised guidelines for remote collaboration and AR specific aspects. General usability issues identified relate mainly to control and support aspects of the prototype that interface with the underlying operating system and are therefore based on standard GUI concepts. It can be expected that in the future these metaphors will be replaced by concepts more appropriate to the AR context.

While many of the described problems were observed consistently for all sessions during the video analysis, it also was evident that ultimately their impact on the collaboration was limited, as participants naturally worked around these issues in order to get on with their session, confirming similar observations in the literature [23] about the resilience of users at adapting their interactions to overcome usability issues and succeed with their task.

## Conclusions and Further Work

We have developed an Augmented Reality system that supports remote collaboration of learners through a shared virtual space. Based on a pedagogically driven reference scenario of a learning unit, we have implemented a simple prototypical AR application for using AR in schools and evaluated it in a field test under classroom-similar conditions. While summative evaluations [3] found a high acceptance rate among students and teachers and confirmed the pedagogical effectiveness of the prototype AR application, the formative evaluation resulted in a number of recommendations informing future development: sharing viewpoints could simplify referencing problems in communication (see also [9]), video-conferencing features could avoid uncertainties related to remote presence and traditional Human-Computer Interaction features such as Undo could improve ease of use. Overall however, the formative evaluation found that the prototype is well suited for hands-on remote collaboration, and that minor implementation issues are more than compensated for by students' resilience and motivation to complete their collaborative tasks in the shared AR space. As additional features increase system complexity, reducing the charm of directness and simplicity seen in the current implementation, additional research is needed to solve the trade-off between usefulness of features and directness of AR interaction.

The Spinnstube® AR system has been shown to be a useful tool and test-bed for AR applications in school environments. However, our evaluation has shown a number of usability issues of the workplace setup. These shortcomings will be solved in an upcoming design revision of the hardware infrastructure.

The evaluation shows that AR technology can be a beneficial and learner-motivating addition to classroom learning. The results also give examples of how learners can develop their own problem-solving strategies to work around existing communication shortcomings with conceptually simple basic tools at hand.

## Acknowledgements

We thank the other members of the ARiSE project. Design, development and evaluation of the work described within this paper were a joint effort of all project partners. Furthermore, we wish to thank the participating students of the Rabanus-Maurus-Gymnasium Mainz, Germany and the Juventa Basic School, Siauliai, Lithuania, for their enthusiastic participation and willingness to do extra work in their free time. The ARiSE project was co-funded by the European Commission within the Sixth Framework Programme (contract number IST-027039). Last but not least

Here's the cleaned Markdown, preserving the reference list structure while normalizing formatting:

## References

1. Chastine, J.W., Nagel, K., Zhu, Y., Yearsovich, L.: Understanding the design space of referencing in collaborative augmented reality environments. In: Proceedings of Graphics interface 2007, Montreal, Canada, May 28-30. ACM, New York (2007)

2. Seichter, H.: Augmented Reality and Tangible Interfaces in Collaborative Urban Design. In: Proceedings of the 12th International CAAD Futures Conference: Integrating Technologies for Computer-Aided Design, July 11-13. University of Sydney, Sydney, Australia (2007)

3. Billinghurst, M.: Augmented Reality in Education. New Horizons for Learning (2002), http://it.civil.aau.dk/it/education/reports/ar_edu.pdf

4. Piaget, J.: The Science of Education and the Psychology of the Child. Grossman, New York (1970)

5. Spiro, R.J., Coulson, R.L., Feltovich, P.J., Anderson, D.K.: Cognitive flexibility theory: Advanced knowledge acquisition in ill-structured domains. In: Patel, V. (ed.) Proceedings of the 10th Annual Conference of the Cognitive Science Society. Erlbaum, Hillsdale (1988)

6. Bruner, J.: Going Beyond the Information Given. Norton, New York (1973)

7. Lamanauskas, V., Vilkonis, R., Bilbokaite, R.: Pedagogical Evaluation of the Augmented Reality Platform. Appendices P1-P8 of [3] (2009), http://www.arise-project.org – downloads section

8. Pribeanu, C., Balog, A., Iordache, D.: Usability Evaluation Summer School 2007. Appendix U2 of [3] (2009), http://www.arise-project.org – downloads section

9. Bandura, A.: Social Learning Theory. General Learning Press, New York (1977)

10. Vygotsky, L.S.: Mind in Society. Harvard University Press, Cambridge (1978)

11. Salomon, G. (ed.): Distributed Cognitions: Psychological and educational considerations. Cambridge University Press, Cambridge (1993)

12. Roschelle, J., Rosas, R., Nussbaum, M.: Towards a Design Framework for Mobile Computer-Supported Collaborative Learning. In: Proceedings of the 2005 Conference on Computer Supported Collaborative Learning, Taipei, Taiwan, pp. 520-524 (2005)

13. Ryokai, K., Vaucelle, C., Cassell, J.: Virtual Peers as Partners in Storytelling and Literacy Learning. Journal of Computer Assisted Learning 19(2), 195-208 (2003)

14. Pask, G.: Conversation, Cognition, and Learning. Elsevier, New York (1975)

15. Gutwin, C., Greenberg, S.: The Mechanics of Collaboration: Developing Low Cost Usability Evaluation Methods for Shared Workspaces. In: Proceedings of the 9th International Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises, WET ICE 2000 (2000)

16. Kuck, R., Wind, J., Riege, K., Bogen, M.: Improving the AVANGO VR/AR Framework: Lessons Learned. In: Schumann, M., et al. (eds.) Virtuelle und Erweiterte Realität: 5. Workshop der GI-Fachgruppe VR/AR. Berichte aus der Informatik,

## A Comparison of Paper-Based and Online Annotations in the Workplace

Ricardo Kawase, Eelco Herder, and Wolfgang Nejdl  
L3S Research Center, Leibniz Universität Hannover  
Appelstr. 4, 30167 Hannover, Germany  
{Kawase,Herder,Nejdl}@L3S.de

## Abstract

While reading documents, people commonly make annotations: they underline or highlight text and write comments in the margin. Making annotations during reading activities has been shown to be an efficient method for aiding understanding and interpretation. In this paper we present a comparison of paper-based and online annotations in the workplace. Online annotations were collected in a laboratory study, making use of the Web-based annotation tool SpreadCrumbs. A field study was out to gather paper-based annotations. The results validate the benefits of Web annotations. A comparison of the online annotations with paper-based annotations provides several insights in user needs for enhanced online annotation tools, from which design guidelines can be drawn.

**Keywords**: Web Annotation, Online Collaboration, e-Learning, User's Behavior, SpreadCrumbs.

## 1 Introduction

Learning has become an integral part of many people's everyday working life. Due to a more knowledge-based society and rapid changes in technology, one often has to search for and read information in order to keep up-to-date. Each individual presents a set of cognitive strategies that involve the learning process: each person learns in her own way, style and pace. At the same time, the character of learning at the workplace has shifted from a solitary, paper-based activity to a Web-based activity, making use of various resources, including discussion forums and social networking sites [1]. As a result, one ends up with a large collection of scattered digital resources; due to limitations of the Web, annotations – if any – are typically made separately (in a word processor or on a paper sheet). By contrast, annotating paper documents is a natural activity that involves direct interaction with the document and that is known to support understanding and memorization [2].

The term annotation comprises several methods, including underlining and highlighting text and writing additional comments in the margin. These activities are shown to stimulate critical thinking in a process that can be called active reading [3]. All additional writing done by the reader can be considered a variety of annotation, irrespective of its form - formal or informal, implicit or explicit, permanent or transient - or its function - signaling for future attention, memory aiding, interpretation or even reflections out of the subject.

In order to understand how to better support active reading and annotations in the digital context, we carried out a study to compare how people annotate online with how people create paper-based annotations. Specific attention is given to the type of annotations, their function and perceived difficulties in creating and using these annotations. Before presenting the comparative study, we present some theoretical underpinnings. In section 2 we describe background research on annotations in the learning process – including a categorization of annotation types and a comparison of screen-based reading with paper-based reading. Specifics of annotation in the e-learning context are discussed in section 3. We continue with our comparative study, which consisted of a laboratory study making use of an online annotation tool – SpreadCrumbs – and a field study in which we investigated common annotation habits in the paper-based context. We end this paper with a discussion of the results and their implications.

## 2 Annotations in Learning

In this section we provide an overview on the role of annotations in learning. First we discuss a classification of different forms of annotation. We continue with a categorization of reasons why people annotate while learning. At the end of this section we explore various impediments for the take-up of annotation in the online context.

Based on an extensive field research on textbooks, Marshall [4] categorized the different kinds of annotations by forms and its functions. Below, we will discuss the forms of annotation that are relevant for learning proposes and their functions during the learning process:

- underlining or highlighting titles and section headings: this kind of annotation serves

Here's the cleaned and normalized Markdown:

## A Comparison of Paper-Based and Online Annotations in the Workplace

In all of these cases the value of annotations are for both annotators and future readers. Memory adding, signaling attention, problem working and interpretation annotations definitely benefit the annotator but may also benefit other readers – provided that the annotations are explicit, readable and understandable.

In collaborative group work, students typically work on the same content, but this content is extracted from different resources: for example, they all have their own copies of the obligatory textbook. This is a limitation inherent to paper-based annotations. Even though the annotations are still useful for personal use, they fail to play a role in the communicative and collaborative learning processes, which is a barrier for the leverage of learning by social constructivism [5]. Web 2.0 technologies explicitly facilitate these processes and their benefits on knowledge gathering and construction have been lately discussed [6]. Moreover, by exchange of documents, including annotations, remarks and insights, does not only serve the direct, content-related goals, but also contributes to motivation and enjoyable professional relationships [7].

Despite the many potential benefits of online collaborative environments in comparison with traditional paper-based annotation, there are quite some issues related to migrating reading and annotation to the computer. There is a vast body of research [8, 9, 10, and 11] that discuss the many issues when moving from paper-based reading to screen display reading:

- tangibility: in contrast to a text displayed on a computer screen, paper offers physical tangibility. Readers can hold the paper as they like, they can move it around to adjust their perspective and distance [9] – in order to improve legibility [8] and even to facilitate handwriting [12]. Paper is also superior to electronic devices in terms of legibility. Further, while reading one page, readers can use another page for writing notes.

- orientation: paper documents give readers a better sense of location within the text, by physical cues, such as the thickness on the sides of a book or different paper materials in a magazine [10]. These cues support text skimming and cross-reading and they are instrumental when trying to relocate some text [13, 14]. Digital documents do not hold these characteristics [8, 10], an issue that needs to be overcome by increased attention for usability in device design and interface design.

- multiple displays: paper provides a single canvas for each page of text [15]. Each one holds unique properties of physical tangibility, text content, modifications and additions from the readers. The virtual pages simulate this on the single device screen, but in some cases supporting concurrence reading from several documents turns to be an unwieldy task [10].

- cooperative interaction: by circulating a piece of paper, more than one person can interact with the content and build upon each others' annotations [11]. Whereas groupware facilitates simultaneous revisions, versioning and collaboration, it does not yet reach the intuitive interaction as provided by circulating paper-based documents [16].

In addition to these usability issues, there are several technical issues that have been examined [14] to understand the challenge of digital reading. In the context of this paper, we are mainly concerned with the implications for annotations. A major question is whether – given the required progress in terms of technology and interface design – electronic annotations will be used in the same manner as the traditional paper-based annotations. From the above there is evidence that due to inherent differences when moving from the paper-based world to electronic devices, the character of annotations will necessarily change.

Paper-based annotations have been used for centuries and can therefore be considered a highly developed activity, one that represents an important part of reading, writing, and scholarship. Annotation occurs in a wide variety of forms and it is applied for many different purposes. Annotations not only add substance to the text but also implicitly may reveal the reader's engagement with the material [4]. Previous research has verified that no matter the form or purposes of the annotations, the benefits are immediately clear to the future reader [17]. Further, some researchers state that people's needs for making annotations in the Web environment do not differ significantly from their needs in the paper environment [18]. In

Here's the cleaned Markdown:

## A Comparison of Paper-Based and Online Annotations in the Workplace

Summarizing, organizing, sharing and contributing online annotations. A rather economical view on the balance between the drawbacks and benefits has been given by [21]'s information foraging theory, in which the author described the above activities as information enrichment.

Today, both companies and academia institutions train learners to complete tasks and solve problems through project-centered learning. Since it may not be feasible for all participants involved in the projects to meet on a regular basis, they must be assisted by information and communication technology. To support this collaboration there are specific methods for Computer Supported Collaborative Learning (CSCL) provided by learning environments and other platforms can be adapted to fit this need. For the best results of the learning process, the methods should help each learner to act individually to reach her own goals and to cooperate by sharing and discussing ideas to accomplish an assignment.

As discussed in the previous section, in the same way annotations contribute for memory aiding, text interpretation and information re-finding, Web annotations provide the same functionality in the online environment. Web annotations are accessible anytime and anywhere, with diverse sharing possibilities, clearly enhancing workgroup collaboration [22] for cooperative tasks and learning processes. However it is important to remark that the full richness of paper annotations will only be achieved if the digital annotations hold the same beneficial feature of being 'in-context'. 'In-context' annotations are visible within the original resource, enhancing it with the observations and remarks of the annotator, which are likely to help in individual tasks in similar ways as is the case with paper documents [10].

Despite the limitations in terms of usability and tangibility, advantages of Web annotation tools go far beyond the advantages of regular paper annotations. In addition to the sharing capabilities within online communities, digital annotations can be indexed, ordered, rated and searched. These benefits are confirmed by several studies on annotations tools [e.g. 18], in which participants have remarked that search the annotations is a very desirable feature.

Even though there are currently systems that support annotations, studies have shown that users often resort to different strategies for simulating annotation tools, making use of e-mails and messages to self and separated text documents. The main reason for this phenomenon lies mainly in the necessary effort required for creating and organizing annotations: "If it takes three clicks to get it down, it's easier to e-mail" [2]. As users will inevitably resort to other strategies if annotation tools require too much effort, it is necessary to have a lightweight capture tool, with flexible organizational capacity, visibility and practical reminding. In particular if one takes into account that many annotations are primarily meant as temporary storage, or a means for cognitive support or as reminders, it becomes clear that these factors need to be better taken into account in annotation tools for personal information management and learning systems.

## A Comparative Study on Paper-Based and Online Annotations

In order to better understand the real use of annotations and Web annotations, we have implemented a straightforward online annotation system, SpreadCrumbs. SpreadCrumbs provides a minimalistic interface for adding post-its notes, crumbs, to any point within a Web page. Crumbs are used as personal reminders, for information re-finding and for collaboration and social navigation support [26]. With SpreadCrumbs, users can add annotations to any Web resource creating a collection of bookmarks, add comments to the resources, visualize the annotations on the page (in-context) and share these annotations. The post-it note contains the author, the other users that can see this annotation, the topic and the comments – as shown in Fig. 1. To add a annotation, the user just has to select the option "Add Crumb" from the right-click context menu. This action will pop-up a window where the user just need to fill the topic and comments. Further, the user can choose some friends from her social network to share this annotation with.

### First Study: Annotation on the Web

The experiments with our annotation tool were conducted with 18 participants, who all stated to be very proficient working with computer and internet

Here's the cleaned Markdown:

## A Comparison of Paper-Based and Online Annotations in the Workplace

At the beginning of each session, in which only the participant and the experimenter were present, the tool was introduced to the participant by giving a brief overview of the usage of it. Following the introduction, we asked the participants to answer a set of 10 questions by writing down the answer and annotating the resource. These questions were specific information finding tasks that could be solved by a brief internet search with any popular search engine. We ensured that most of the questions were very specific domain questions or numerical in nature to reduce the possibility of the participants to know the answers – an example: "What is the estimate percentage of Chinese among the population of Brunei?". The experiment setup enforced the participant to annotate useful but hard to memorize information for future reference – in fact, in a second round, we will ask the same participants to actually re-find the information by making use of the annotations provided in the first round.

During the experiment, the participants created a total of 207 annotations, covering 81 different Web resources. The average number of words per annotation was 4.1. An important observation was that the participants in general carefully positioned the annotations in the context of the Web page: from the 18 participants using SpreadCrumbs, 16 placed the annotations of each question near the text, table, or paragraph where they found the answers. This type of behavior is not supported by the simple bookmarking functionality of regular browsers.

We noticed that out of the 18 participants who used SpreadCrumbs, only six of them included the answers in the annotations while the majority opted for using keywords of the respective question. Just one participant typed explicit full sentences when annotating the pages: "There seem to be different walks - I'm not sure whether the 9.4km walk brings us to the top, but I think so."; ".. made 35 homeruns in 2005. Yes, I think this should be the right answer."

Although the participants were very proficient with the computer, all of them stated that they regularly print digital documents for reading, even when these documents are relatively short (up to 8 pages). All of them confirmed that they usually annotate those printed documents in one way or another, by means of highlighting text and adding their own comments or insights in the margin.

This somehow contradicts a very interesting observation during the experiment. One of the answers consisted of a short passage from a book (2 sentences with less than 40 words). However, all of the participants demonstrated laziness when having to write down the quote on paper. All of them asked the same question: "Do I have to write the whole sentence?". We allowed them to write down only the reference for the passage (page and paragraph), a suggestion that was followed by all of the participants. The contradiction arises since the participants do not desire to write if they have the option of typing (or copy and paste) still they keep annotating with the pen even though several means of digital annotation exist.

None of the users demonstrated problems regarding the usage of the tool. After the short introduction, all of them performed the tasks of annotating and consulting annotated resources without any effort or mistake. The participants demonstrated enjoyment with the tool interface and functionalities. The direct manipulation and the 'in-context' features were the most appreciated. After having conducted the tasks, the participants were handed over a questionnaire in which they had to choose terms from a list of adjectives gave us a data set of the user perspective over the tool. This questionnaire[^1] measures usability and satisfaction with a list of 118 adjectives, positives and negatives. This methodology gives the participants more confidence to be critical to the system choosing negative terms. The top 10 terms chosen were: Easy to use, Usable, Useful, Collaborative, Helpful, Convenient, Connected, Friendly, Innovative, Straight Forward. These results show us that the participants would be willing to use such tool on a more regular basis.

### Regular Use of SpreadCrumbs

In addition to the laboratory study, we collected and analyzed log files from

Here's the cleaned and normalized Markdown:

## A Comparison of Paper-Based and Online Annotations in the Workplace

## Annotation Types Analysis

Table 2. Annotations found by type

| Annotation types | Percentage |
|-----------------|------------|
| Highlighting/Mark sections headings | 8.6% |
| Highlighting/Mark text | 73% |
| Problem solving | 0.1% |
| General notes (Notes in the margins) | 18.3% |

The far majority of the annotations (73%) involved the highlighting and marking of text. Some participants had the tendency to only highlight main words within a sentence or paragraph. In these cases we counted the collection of highlighted words belonging to a continuous block of text as one piece of annotation.

9% of the documents discussed with the participants turned out to be part of collaborative work in which two or more people were involved. All except two participants reported that they shared their comments via email or some online communication tool; only two participants shared the same sheet of paper, which contained annotations from both parties.

Another valuable observation is that all of the participants who share annotations said that they do annotate in a different (more careful) way when they annotate concerning another reader.

## Reading Goals and Annotation Patterns

To examine in more detail the annotation strategies, we asked our participants to classify the goal of reading the paper. We distinguished between the following categories:
- reading for writing
- reading for learning
- reviewing
- other

Reading for writing is the common activity of reading related articles to extract ideas and references specifically for propose of writing. Reading for learning includes the act of getting updated in some particular field, read about new publications or learning some new approaches to apply in some other activity, such as solving math problems or implementing algorithms. Reviewing consist exclusively of reading papers to give feedback to the author. Finally, any other type of reading was categorized as other.

Table 3. Results by reading goal

|                                    | Writing | Learning | Review | Other |
|------------------------------------|---------|----------|---------|--------|
| Articles                           | 31      | 23       | 9       | 3      |
| Articles annotated                 | 28      | 16       | 7       | 3      |
| Annotations/Page                   | 2.36    | 4.7      | 1.11    | 6.3    |
| **Annotation types**              |         |          |         |        |
| Highlighting/Mark sections headings| 10.5%   | 7.5%     | 9.4%    | 4.8%   |
| Highlighting/Mark text            | 66.0%   | 82.9%    | 40.6%   | 72.2%  |
| Problem solving                   | 0.1%    | -        | 0.9%    | -      |
| General notes (Notes in the margins)| 23.3%   | 9.6%     | 49.1%   | 23.0%  |

## Additional Observations

In addition to comments directly put on paper, three participants also used the technique of attaching annotations to the original document with post-its that were attached to the paper. From the 66 articles analyzed, 10 (15%) did not contain any annotation. One participant that did not have any annotation in any printed paper said that she keeps her annotations in a separated file in her computer for each digital article. Two other participants said that they first do a quick reading on the computer to check the relevance of the text, and if it is relevant then they print it. In their own words: "First I read on the computer to see if I really need to print".

We noticed that in many cases participants used different marking colors for highlighting with the purpose of attributing different levels of importance. From the annotations we identified many different ways of signaling important parts on the text. As an example, one participant created her own symbology for annotating:
- squares around the terms means new terminology
- underline means definitions

## A Comparison of Paper-Based and Online Annotations in the Workplace

Structure to margin notes, its scope is more comparable to highlighting where the main goal remains in signaling for future attention and facilitation for re-finding.

Within the collected data of online annotations, the average number of words (4.56) in private annotations does not cover the average length of short sentences while the shared annotations (average of 10.35 words per annotations) fit the average of short and medium sentences statistically measured in plain text documents [27]. We deduce that private annotations, in general, don't contain full sentences and as in the paper based texts they are just a perspective over the topic context or keywords and classification of a section (or resource) – in the digital environment mostly used for re-finding. The shared online annotations clearly hold more explicit meanings where the authors tend to be clearer when sharing their thoughts. This evidently shows the different behavior and concerns of the individual when writing personal or shared annotations.

Although differences have been found between paper and digital annotations, if we use the same reading goals classification for online readings and translate the annotations meanings, we find out that in-context notes annotations are the optimized form for attention signaling, summarization, interpretation and improving bookmarks search, in both personal and shared environments.

The sum of our two studies suggests some design implications for annotation systems. First of all the annotation action must be effortless in all senses – easy to access and visualize, as few interactions as possible and in-context interactions to minimize the lose focus. Online resources can be used for all sorts of reading tasks, thus annotation systems must supply all forms of annotations, not by similar representations but by providing the means to achieve the same goals. The necessary effort still requires some engagement from the user, however the benefits discussed should overcome and become in hand to the users: re-finding tools, easy manipulation and organization of the annotations and resources and sharing capabilities.

## Conclusions

In this paper we discussed the role of annotation in learning in general and in e-learning in particular. From the background research it has become clear that the act of annotating supports the learning process in paper-based situation. However, when it comes to online learning, annotation becomes an additional cognitive burden, due to the lack of suitable tools and intrinsic problems related to reading from a screen and interacting via keyboard and mouse.

From the comparison of online annotation with paper-based annotation it becomes clear that there is a difference between both types. Online annotations were typically short and had a certain purpose in terms of re-finding, sharing or commenting. The high amount of highlighting in paper-based annotations has an intrinsic value. Based on the results we conclude that emphasis in the development of annotation tools should be put on added value by better exploiting the annotations (for example for enhanced re-finding tools, visual overviews, grouping, sharing, collaborating) rather than to try and mimic the 'old-fashioned' paper-based annotation. At the same time, writing an annotation should cost as little effort as possible, as otherwise people will inevitably resort to other ways of getting their things done [2].

This poses a design challenge for the development of annotation systems and provides an explanation why these kinds of systems have not found an audience yet. Furthermore, we think that the development of added value for annotations will provide many more opportunities for personalizing the learning environment and for facilitating communication and collaboration between learners.

## Acknowledgments

The authors' efforts were partly funded by the European Commission in the EU FP7 Network of Excellence Stellar.

## References

1. Chatti, M.A., Jarke, M.: The Future of E-Learning: A Shift to Knowledge Networking and Social Software. Int. J. Knowledge and Learning 3(4/5) (2007)
2. van Kleek, M., Karger, D.: Information Scraps How and Why Information Eludes Our Personal Information Management Tools. ACM Trans. Information Systems 26(4) (2008)
3. Adler, M.J., van Doren, C.: How to Read a Book. Simon and Schuster, New York (1972)
4. Marshall

## Learning by Foraging: The Impact of Social Tags on Knowledge Acquisition

## References
19. Pirolli, P.: Information Foraging Theory: Adaptive Interaction with Information. Oxford University Press, Oxford (2007)

20. Farzan, R., Brusilovsky, P.: AnnotatEd: A Social Navigation and Annotation Service for Web-based Educational Resources. In: Reeves, T.C., Yamashita, S.F. (eds.) Proceedings of World Conference on E-Learning, E-Learn 2006, Honolulu, HI, USA, October 13-17, pp. 2794–2802. AACE (2006)

21. Kraut, R., Galegher, J., Egido, C.: Relationships and tasks in scientific research collaborations. In: Proceedings of the 1986 ACM conference on Computer-supported cooperative work, Austin, Texas, December 3-5 (1986)

22. Fish, R.: Comparison of Remote and Standard Collaborations. In: Proceedings of the Conference on Technology and Cooperative Work, Tucson, Arizona (February 1988)

23. Marlow, C., Naaman, M., Boyd, d., Davis, M.: HT 2006, Tagging Paper, Taxonomy, Flickr, Academic Article,ToRead. In: Proc. Hypertext 2006. ACM Press, New York (2006)

24. Kawase, R., Nejdl, W.: A straightforward approach for online annotations: SpreadCrumbs. In: Proceedings of the 5th International Conference on Web Information Systems and Technologies, WEBIST 2009 (2009)

25. Altmann, G.: Verteilungen der Satzlängen (Distribution of Sentence Lengths). In: Schulz, K.-P. (ed.) Glottometrika 9. Brockmeyer (1988)

## Authors
Christoph Held and Ulrike Cress
Knowledge Media Research Center
Konrad-Adenauer-Straße 40, 72072 Tübingen, Germany
c.held@iwm-kmrc.de, u.cress@iwm-kmrc.de

## Abstract
In the last few years, social tagging systems have become a standard application of the World Wide Web. These systems can be considered as shared external knowledge structures of users on the Internet. In this paper, we describe how social tagging systems relate to individual semantic memory structures and how social tags affect individual processes of learning and information foraging. Furthermore, we present an experimental online study aimed at evaluating this interaction of external and internal structures of spreading activation. We report on effects of social tagging systems as visualized collective knowledge representations on individual processes of information search and learning.

**Keywords**: Tagging, tag cloud, learning, information foraging, spreading activation.

## 1 Introduction
In only few years, the Internet has changed fundamentally: It has developed from a platform, where people simply retrieve information from few providers into an active network of Web users who frequently contribute and exchange content [1]. Millions of people use social software applications such as wikis, blogs and social tagging systems and participate in the Web 2.0 creating and providing vast amounts of information every day. This may lead to the question of how people can benefit from all this user-generated information on the Web and, furthermore, how external knowledge on the Internet and individual knowledge may cross-fertilize. Regarding this specific question only few theoretical frameworks have been developed [2,3] and, as stated by Fu in 2008 [3], surprisingly little is known about how Web 2.0 technologies may directly interact with individuals at the knowledge and cognitive level.

In this paper, we want to address this question by investigating the technology of social tagging. We focus on the question of how social tags may influence individual processes of information seeking and knowledge acquisition. Therefore, we provide a cognitive perspective on social tagging an

## Learning by Foraging: The Impact of Social Tags on Knowledge Acquisition

## Models of Social Tagging and Semantic Memory

### Social Tagging Systems
Social tagging systems allow users to assign keywords (tags) to resources, creating networks of related tags in tag clouds. These processes mirror spreading activation processes in individual semantic memory systems.

### Models of Semantic Memory
The storage and retrieval of information in semantic memory parallels challenges faced by internet and social tagging systems. Despite storing thousands of facts and concepts, humans can quickly retrieve specific information from long-term memory.

Cognitive models of semantic memory are based on knowledge units connected through associative networks where:
- Facts are represented as nodes (chunks) in a large network
- Chunks have associations of varying strengths to other chunks
- Association strength reflects co-occurrence frequency in meaningful contexts

For example, "1492" is strongly associated with "the discovery of America" due to frequent meaningful co-occurrence.

Retrieval occurs through spreading activation between chunks:
- Chunks must receive activation from connected chunks
- Activation probability depends on association strength
- Example: "red wine" and "France" more readily activate "Bordeaux" than "Loire"

Associative priming experiments support this model. Meyer and Schvaneveldt demonstrated faster word pair identification with strong semantic associations (e.g., "bread" and "butter") versus weak ones (e.g., "nurse" and "butter").

### Spreading Activation and Information Foraging on the Web
Pirolli and Card's Information Foraging Theory describes web navigation processes using the concept of information scent, based on Brunswik's lens model. Users evaluate proximal cues (links/tags) to reach desired distal resources, with high information scent indicating likely successful paths.

Information scent evaluation relies on users' semantic memory spreading activation structures. Search goals activate cognitive structures that guide link selection and navigation path choices.

Here's the cleaned and normalized Markdown:

## Learning by Foraging: The Impact of Social Tags on Knowledge Acquisition

"France" are strongly connected to "Bordeaux". Associations to other chunks, like "Loire", "Merlot" or "elegant", also exist, but have a much weaker spreading activation. On a Web site of an Internet wine dealer she has to choose a link in order to see a selection of available wines. These links may represent regions or characteristics of French wine. The link selection of the user is based on the strength of spreading activation for these available links, given the desired distal resource. The highest spreading activation will lead to a high information scent and, accordingly, to a high probability of link selection (see Figure 4).

[Figure 4. Illustration of information scent (freely adapted from Pirolli [9])]

## Interaction of Social Tagging Systems, Individual Learning and Foraging

In this chapter we address the research issue of how external knowledge of tagging communities and individual knowledge representations may interact. More specifically, we focus on the question whether the structures of spreading activation of tagging communities may have an impact on individual spreading activation structures of Web users. This process of individual learning and the change of semantic memory structures would lead to a transfer of knowledge from communities to individuals and would consequently modify the information foraging behavior of users.

Many search tasks on the Internet require browsing activities and cannot be accomplished with the help of short queries typed into search boxes [11]. In exploratory search tasks user must choose among several links and navigation paths in order to find a desired resource. Even if users have a more or less specific idea of a resource, which they want to find, the navigation path and the eventual result may still be influenced by the available links. Individual spreading activation and, consequently, link selection may change during information foraging and navigation [3,12]. These learning processes can be considered as a byproduct of information foraging behavior and are mostly non-intentional and incidental [13]. Social tagging systems may provide a browsing environment, which facilitates informal learning and may lead to an improved process of information foraging.

The framework of Cress & Kimmerle [2] describes a theoretical model for the interplay between collective knowledge structures and processes of individual learning. In this case, the user-generated social artifact of tags represents the externalized knowledge structure of a community, which emerges by the collective process of annotating resources with tags. This social tagging system interacts with an individual user in a search task. The framework is based on both a systemic as well as a cognitive approach. From a systems-theoretical point of view [14] people's cognitive systems are different from a social system, which is being represented by an artifact. Cognitive systems and social systems have different kinds of operations and because of their different modes of operation both systems cannot simply merge. But one system can affect another one in its development by irritating it. Irritation is interpreted in the sense of Piaget's cognitive conflicts [15] and it is assumed that cognitive systems develop when people solve cognitive conflicts. A cognitive conflict exists when people's prior knowledge is incongruent to the information of the external artifact. From an individual perspective, a cognitive conflict can be solved by processes of equilibration and internalizing information from the environment. People either add new information to their prior knowledge or restructure their present knowledge and adapt to the new information.

In this paper we focus on processes of internalization, and based on the model of Cress & Kimmerle [2], we assume that cognitive conflicts result from different associations and spreading activation networks of a social tagging system and an individual system of semantic memory. This irritation may lead to a process of cognitive equilibration, an adaptation to the community's knowledge and, consequently, to a change of individual spreading activation structures.

## Related Work

Research on social tagging systems and tag clouds has mainly focused on the description of regularities in social tagging systems, like frequency-rank-distributions [16,17], and the development of new tagging tools and their technical aspects [18,19]. Research in cognitive aspects of social tagging systems and the interplay between external and internal knowledge structures is reported by Fu (2

Here's the cleaned Markdown:

## Learning by Foraging: The Impact of Social Tags on Knowledge Acquisition

When the knowledge of an individual and a community is incongruent, a user may internalize the externalized structure of tags, which represents a kind of externalized spreading activation of a community, and may change the individual structure of spreading activation accordingly. This may also lead to a corresponding change of information foraging behavior. Because this spreading activation of the community is represented by the size of the tag, we expect that presenting tag clouds with weighted tags has a higher potential for changing the individual spreading activation than tag clouds with non-weighted tags where the specific strengths of external spreading activations are not visible. In the following, we address the scenario of a so-called negative bias: Subjects' prior knowledge and spreading activation contradict the information represented by the community's tag clouds.

## Navigation

Prior knowledge about a domain and the corresponding internal spreading activation network strongly influence Web navigation and information foraging behavior. Web users follow those links which are most appropriate for finding a desired goal. This assessment of links is based on their prior associations and spreading activation related to the desired goal. A user, who thinks that a link is closely related to a desired goal, will select it. When users have deficient knowledge about a domain, the process of information foraging will lead to a deficient or suboptimal search result as well.

In a browsing environment where the externalized knowledge of a community and the strength of their associations are not visible, the navigation of Web users is primarily based on their prior knowledge. Contrary to such an environment, social tagging systems provide the opportunity to visualize the knowledge of a community and, in particular, the strength of specific associations with the help of weighted tags. We assume that this visualization affects the process of information foraging: When internal and external associations contradict each other, we expect that users will consider the knowledge of the community, change their information seeking behavior and adapt to the information given by the tag cloud. Based on this, we assume the following two hypotheses for navigation:

H1: With a tag cloud of unweighted tags, people will primarily follow links which are closely related to their prior knowledge. A weighted tag cloud will reduce the focus on those links and users will follow them less frequently.

H2: With weighted tag clouds, users will select those links more frequently, which are suggested by the community (compared to an environment of non-weighted tags).

## Change of Individual Spreading Activation

Browsing and navigation may lead to a process of incidental learning and knowledge acquisition. Hence in a scenario of incongruent internal and external spreading activation, users may adapt to the knowledge of a community. The users' prior associations and semantic connections may change and attenuate, whereas associations of a community may be internalized. This may lead to a change of the subject's association strengths and a modification of the individual structure of spreading activation. For this process of incidental learning, we assume the following specific hypothesis:

H3: Users with weighted tag clouds show a higher degree of modification of association strengths in the process of navigation. This means that - compared to users without weighted tags - those of the subjects' associations, which are based on a "wrong" negative bias (the prior knowledge) become weaker and associations with tags, which were suggested by the community, become stronger. They adapt to the knowledge of the community more strongly and reduce the strength of their negative bias to a greater extent.

## Method

To test these three hypotheses, we ran an experiment in an online setting. In the following, we present sample, materials, procedure, design and dependent measures of the study.

### Participants

We tested 115 participants, who were recruited on Amazon Mechanical Turk (mturk.com), an Internet marketplace for engaging users in online micro-tasks. Of the 115 subjects who were considered for the experiment 57 were female and 58 male. The average age was 29.61 years (SD=10.22). Subjects came from 19 different countries, most of them from the United States (53.0%) followed by India (16.5%) and Canada (6.0%). Of these subjects, 93.0% spend at least

Here's the cleaned Markdown:

## Learning by Foraging: The Impact of Social Tags on Knowledge Acquisition

## Experimental Setup

Before the navigation task, subjects completed a survey on demographics and background, followed by basic information on social tagging systems, related tags and tag clouds. The subjects were informed that the tag clouds originated from a social tagging system dealing with wines (especially Georgian wines). The community members of this social tagging system were introduced as wine lovers and experts. The navigation task was preceded by a detailed task description and specifics of the task procedure. When subjects finished the navigation task, they had to complete a knowledge test. No information about the knowledge test was given before or during the navigation task, so there was no indication of a learning experiment for the subjects. There were no time limits during any part of the experiment.

## Design and Dependent Measures

As independent variable, the visualization of tag clouds was varied. In one condition all tags had the same size (non-weighted tags). In the other condition (weighted tags), the size of the tags varied and the corresponding association strengths of a community were visible. This independent variable was tested in a between-subjects design. The overall design also included varying prior knowledge on Georgian wine characteristics, like typical Georgian wine regions, grape varieties and wine aromas. The information about the Georgian wine characteristics, which represented the manipulated prior knowledge of the subjects, was given before the navigation task started.

In this paper we report on the condition of a negative bias in which subjects receive information contrary to the community's knowledge. An example of a negative bias is the prior knowledge that "Tsageri" is the most typical wine region of Georgia, although the tag cloud of the community suggests that "Kakheti" is more typical. This information was presented as a "comment from an anonymous blogger" and was provided before the navigation task started. With this information a prior knowledge was induced which led to different associations between the internal memory structure of a user and the external knowledge of the community, represented in tag clouds.

The subjects were randomly assigned to one of the conditions of tag visualization. Each participant randomly received a negative bias either for Georgian wine regions, grape varieties or wine aromas. The order of presentation for tag clouds of each wine characteristic (region, grape variety and aroma) was varied in a within-design of a Latin square. Subjects were randomly assigned to one of these orders.

We determined the navigation behavior of subjects by analyzing log-files and calculated the average percentage of how often a subject selected a specific tag when presented the 3 tag clouds of a wine characteristic. As a measure of association strength, subjects had to complete a test at the end of the experiment. They had to indicate the strength of their association for each wine characteristic (e.g., "How typical is the wine region Kakheti for Georgia?") by a rating. For analyzing the dependent variables we combined the results across all subjects of those conditions in which the subject had received a negative bias as prior knowledge.

## Results

### Navigation

In a first step we analyzed subjects' navigation behavior by t-tests. Two different kinds of tags had relevance for testing H1 and H2.

For H1 those tags were of interest, which represented the subjects' prior knowledge (e.g., the prior knowledge for wine region was a high spreading activation of "Tsageri"). This prior knowledge reflects the negative (or "wrong") bias, which was presented by the blogger before the navigation task started. On average, subjects in the environment of non-weighted tags selected these tags significantly more often (M = 71.19, SE = 4.22) than subjects with weighted tags (M = 39.29, SE = 4.58, t(113) = -5.13, p < .001).

The tags of interest for H2 were those with the highest spreading activation of the wine community (e.g., "Kakheti" as wine region). In the weighted tag clouds these tags were most prominent and reflected the externalized knowledge of the community. This externalized knowledge of the community was contrary to the prior knowledge of the subjects, which represented the individual negative bias. On average, subjects in the environment of weighted tags selected those tags, which were suggested by the

Here's the cleaned and normalized Markdown:

## Learning by Foraging: The Impact of Social Tags on Knowledge Acquisition

## Change of Individual Spreading Activation

As a next step we report on the strength of the negative bias after the navigation process, i.e., how much is the individual spreading activation of the negative bias still stronger than an association with tags suggested by the community (H3). Therefore, we subtracted the subjects' ratings of tags which represented the individual prior knowledge (e.g., "Tsageri") from those representing the contradicting externalized knowledge of the community (e.g., "Kakheti) and analyzed this difference - the strength of the negative bias - by a t-test. In line with the expectation, the results show that, on average, subjects with weighted tags have a significant lower negative bias (M = .57, SE = .30) than subjects with non-weighted tags (M = 2.20, SE = .25, t(113) = -4.17, p < .001).

## Discussion and Future Research

The results presented in this study support the hypothesis that social tagging systems can trigger learning and knowledge acquisition during processes of information seeking. Our results show that individual spreading activation can be changed by the visualized knowledge representation of a community. The externalized knowledge structure of many Web users affects the cognitive system of individuals and leads to a process of learning. Individual users may benefit from this interaction of collective and individual knowledge when foraging the Web. When people search for information they follow their prior knowledge. A deficient prior knowledge may lead to a deficient and suboptimal outcome.

Our results suggest that social tagging systems may help to improve the process of information foraging by changing the internal spreading activation of users. With the technology of tagging, users could take advantage of the wisdom of crowds [24] and use information, which is provided by thousands of other users. To find good information and resources on the Internet, users need to know, which path of navigation to select. Social tags may help to choose a successful path and to acquire knowledge while following this pathway.

Our experiment provides first results, which show the potential of social tagging systems for learning processes and for improving individual search processes. This experiment represents a first step and starting point for further research. There are some limitations of our experiment, which we have to consider, and which we hope to address in our next studies. In our scenario, the presented tag clouds were independent of previous tag selections of subjects, and no feedback on the specific steps of navigation were provided. Future experiments could be based on a more complex, dynamic and interrelated social tagging system. Additionally, digital resources could be implemented in the experimental setting as well. Further research could also address the credibility and expertise of social tagging communities, as well as the strength of users' prior knowledge or biases, and their influence on processes of learning and information foraging. The identification of important factors, which affect knowledge acquisition and information retrieval in social tagging systems may lead to a better understanding of the potential of social tagging and the challenge of how to benefit from the wisdom of crowds on the World Wide Web.

## References

1. O'Reilly, T.: What is Web 2.0?, http://www.oreillynet.com/pub/a/oreilly/tim/news/2005/09/30/what-is-web-20.html
2. Cress, U., Kimmerle, J.: A systemic and cognitive view on collaborative knowledge building with wikis. International J. of Computer-Supported Collaborative Learning 3, 105–122 (2008)
3. Fu, W.: The microstructures of social tagging: a rational model. In: Proceedings of the ACM 2008 Conference on Computer Supported Cooperative Work, pp. 229–238. ACM, New York (2008)
4. Anderson, J.R.: Language, memory, and thought. Lawrence Erlbaum, Hillsdale (1976)
5. Anderson, J.R.: Cognitive psychology and its implications. Freeman, San Francisco (1980)
6. Collins, A., Loftus

Here's the cleaned Markdown:

## References

11. Marchionini, G.: Exploratory search: From finding to understanding. Comm. of the ACM 49, 41-46 (2006)
12. Qu, Y., Furnas, G.W.: Sources of structure in sensemaking. In: CHI 2005 Extended Abstracts on Human Factors in Computing Systems, pp. 1989-1992. ACM, New York (2005)
13. Cress, U., Knabel, O.B.: Previews in hypertexts: Effects on navigation and knowledge acquisition. J. of Computer Assisted Learning 19(4), 517-527 (2003)
14. Luhmann, N.: Social systems. Stanford University Press, Stanford (1995)
15. Piaget, J.: The development of thought: Equilibration of cognitive structures. The Viking Press, New York (1977)
16. Cattuto, C., Loreto, V., Pietronero, L.: Semiotic dynamics and collaborative tagging. Proceedings of the National Academy of Sciences of the United States of America 104(5), 1461-1464 (2007)
17. Golder, S., Huberman, B.A.: Usage patterns of collaborative tagging systems. J. of Information Science 32(2), 198-208 (2006)
18. Hassan-Montero, Y., Herrero-Solana, V.: Improving tag-clouds as visual information retrieval interfaces. Paper presented at the International Conference on Multidisciplinary Information Sciences and Technologies, Merida, Spain (October 2006)
19. Hong, L., Chi, E.H., Budiu, R., Pirolli, P.: SparTag.us: a low cost tagging system for foraging of web content. In: Proceedings of the Working Conference on Advanced Visual Interfaces 2008, pp. 65-72. ACM Press, New York (2008)
20. Hutchins, E.: How a cockpit remembers its speed. Cognitive Science 19, 265-288 (1995)
21. Bateman, S., Gutwin, C., Nacenta, M.: Seeing things in the clouds: the effect of visual features on tag cloud selections. In: Proceedings of the 19th ACM Conference on Hypertext and Hypermedia 2008, pp. 193-202. ACM Press, New York (2008)
22. Rivadeneira, A.W., Gruen, D.M., Muller, M.J., Millen, D.R.: Getting our head in the clouds: toward evaluation studies of tagclouds. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems 2007, pp. 995-998. ACM Press, New York (2007)
23. Kittur, A., Chi, E.H., Suh, B.: Crowdsourcing user studies with Mechanical Turk. In: Proceedings of the Twenty-Sixth Annual SIGCHI Conference on Human Factors in Computing Systems 2008, pp. 453-456. ACM, New York (2008)
24. Surowiecki, J.: The wisdom of crowds: why the many are smarter than the few and how collective wisdom shapes business, economies, societies and nations. Doubleday, New York (2004)

## Assessing Collaboration Quality in Synchronous CSCL Problem-Solving Activities: Adaptation and Empirical Evaluation of a Rating Scheme

### Authors
Georgios Kahrimanis¹, Anne Meier², Irene-Angelica Chounta¹, Eleni Voyiatzaki¹, Hans Spada², Nikol Rummel², and Nikolaos Avouris¹

¹Human-

Here's the cleaned and normalized Markdown:

## Assessing Collaboration Quality in Synchronous CSCL Problem-Solving Activities

## Introduction

Aspects of technology-enhanced collaborative learning across different settings. In this paper, we report on the successful adaptation of an established rating scheme for assessing collaboration quality to data from a novel learning setting, demonstrating that the rating scheme's dimensions, and thus its underlying theoretical model, are capable of capturing the main aspects of collaboration quality across different technology-enhanced learning settings. The work described is part of an ongoing interdisciplinary collaboration between our two research teams at the University of Patras, Greece, and the University of Freiburg, Germany.

## Tool Adaptation

Originally, the rating scheme had been developed by the Freiburg team for the purpose of analyzing collaboration quality in the context of interdisciplinary problem-solving between medical students and students of psychology who communicated over a desktop video-conferencing system [6]. The scheme employed a multidimensional model of collaboration covering aspects of communication, joint information processing, coordination, relationship management, and motivation [1]. The scheme was adapted to suit data gathered by the Patras team in a very different CSCL scenario: dyads of first-year computer science students interacted through Synergo [7], a network-based synchronous collaborative drawing tool that includes a shared whiteboard and a textual communication facility. Students collaborated in the scope of 45'-75' laboratory sessions without having face-to-face contact. The learning domain was algorithm building in computer science. Each dyad was asked to solve an elementary algorithm exercise by developing a flow-chart representation of the algorithm described in Synergo's shared whiteboard.

The rating scheme was adapted to this specific task and setting by adjusting the number and definitions of the dimensions of the original scheme. Two main phases of adaptation were followed; the first resulted in an adapted definition of the rating scheme's dimensions, and the second served to fine-tune the rating instructions. In the first phase of adaptation a bottom-up approach, which involved identification of "best practice" examples in the sample data, was combined with a top-down process, during which the definitions of all original dimensions were reformulated taking into account constraints arising from the specific collaboration setting (e.g. chat communication; design task). In the second phase of adaptation, the dimensions' definitions were fine-tuned and illustrated with more detail, grounding each dimension's theoretical concepts in specific examples of collaboration practice from the data pool of the first round of adaptation.

## Dimensions of Good Collaboration

In the Synergo algorithm task, good collaboration can be characterized on seven rating dimensions (Table 1), covering the same five aspects of collaboration quality that had been defined in the original tool. The first two dimensions assess the aspect of students' communication in the Synergo learning environment. First of all, the success students have in achieving a seamless and efficient communication is determined by observing in how far they maintain collaboration flow, i.e. manage dialogue and actions in a way that facilitates references to earlier utterances and actions and helps students maintain a joint focus. For example, students must make sure to react to each others' messages and actions, and must coordinate between the verbal discussion in the chat and the ongoing design of the algorithm in the shared whiteboard.

Second, students need to sustain mutual understanding, i.e. work towards "common ground" [8]. For example, students should strive to make their actions and chat messages understandable for their partner, e.g. by telling them which object in the whiteboard they are referring to, by explaining the variables they are using, or by informing their partner about the purpose of their actions in the shared whiteboard. Students should also give each other feedback on their level of understanding, e.g. by sending short affirmative messages, or by asking clarifying questions.

Two further dimensions cover the aspect of joint information processing. One dimension, knowledge exchange, assesses how effectively students exchange information and give explanations. Information in this setting refers mainly to elementary knowledge of algorithm concepts and flowchart notation restrictions. For example, students typically develop small parts of the solution in the form of pseudocode notes individually, which they are expecte

Here's the cleaned Markdown:

## Assessing Collaboration Quality in Synchronous CSCL Problem-Solving Activities

The rating procedure used a scale from "very low" to "very high" collaboration quality on that dimension. A rating handbook stated the scope and purpose of each dimension, gave an operational definition in a short paragraph, and provided raters with illustrative examples.

The rating procedure was conducted by two raters, one of which had already gained experience from the first round of adaptation. One third of the data was rated by both raters jointly as a training phase for the new rater. After finishing this training phase, another 34 dyads were rated by both raters separately in order to establish inter-rater reliability. The rest of the dataset was split into two so that each rater assessed half of the remaining activities.

### Results

In the co-rated sample, absolute agreement of the ratings ranged between 65% (argumentation) to 85% (knowledge exchange); differences of more than one point on the five-point rating scale were very rare. Accordingly, measures of inter-rater reliability (intra-class correlations for absolute values) were high for all dimensions (Table 1). Thus, this part of the empirical evaluation was considered successful.

An analysis with the complete sample 101 dyads further showed that all dimensions (except the individually rated dimension of "individual task orientation") intercorrelated quite highly (r > .60). On the one hand, this shows that the rating scheme is a useful means of obtaining consistent measures of overall collaboration quality; on the other hand, lower inter-correlations would be desirable for obtaining differential assessments of specific aspects of collaboration. This is, however, only possible for dyads that show a medium level of collaboration quality overall, while the sample in which the inter-correlation results were obtained also contained many dyads who collaborated either extremely well or extremely bad and thus obtained extreme ratings on nearly all dimensions (as one would expect, inter-correlations are much lower empirically if only dyads of medium collaboration quality are considered).

| Rating dimensions | Inter-rater agreement (ICCs) in the co-rated sample (n=34 dyads) |
|------------------|---------------------------------------------------------------|
| Collaboration Flow | .88 |
| Sustaining Mutual Understanding | .92 |
| Knowledge Exchange | .96 |
| Argumentation | .91 |
| Structuring the Problem Solving Process | .96 |
| Cooperative Orientation | .96 |
| Individual Task Orientation | .92 |

### Conclusions and Future Plans

We have described how a rating scheme that had been developed to assess the quality of students' collaboration in one collaborative learning setting (involving students with complementary knowledge backgrounds engaged in medical decision-making and collaborating over a desktop-videoconferencing system) was successfully adapted to assess the quality of students' collaboration in a novel collaborative learning setting (involving students with similar knowledge backgrounds engaged in algorithm building and collaborating using the chat and shared whiteboard facilities in the Synergo learning environment). The adaptation and application of the rating scheme was successful in terms of establishing high inter-rater reliability. Although some significant modifications to the rating scheme were made, the resultant version was close enough to the original so as not to violate its core rationale. Thus, the multidimensional model of collaboration underlying the tool has been shown to be applicable across very dissimilar CSCL settings, and to be a useful basis for assessment.

The development of the adapted rating scheme has also paved the way for further research paths with both practical and methodological implications. Two studies using the rating scheme and the model of collaboration quality underlying it are currently under way. One project studies whether feedback provided based on the ratings in specific dimensions can lead to improvement of students' subsequent collaboration. A pilot study has already been conducted, in which a human tutor assessed collaboration quality using the rating scheme, and then gave feedback assembled according to a corresponding feedback scheme. Feedback that was based on a profile of high and low ratings achieved by a dyad, and thus tailored to students' specific strengths and weaknesses, was effective in improving students' collaboration [9

Here's the cleaned Markdown:

## References

3. Dillenbourg, P., Baker, M., Blaye, A., O'Malley, C.: The evolution of research on collaborative learning. In: Reimann, P., Spada, H. (eds.) Learning in humans and machines: Towards an interdisciplinary learning science, pp. 189-211. Elsevier/Pergamon, Oxford (1995)

4. Weinberger, A., Fischer, F.: A framework to analyze argumentative knowledge construction in computer-supported collaborative learning. Computers & Education 46, 71-95 (2006)

5. Suthers, D., Law, N., Rose, C., Dwyer, N.: A common framework for CSCL interaction analysis. Pre-conference workshop at the 2008 ICLS conference, Utrecht, The Netherlands (2008)

6. Rummel, N., Spada, H.: Learning to collaborate: An instructional approach to promoting problem-solving in computer-mediated settings. The Journal of the Learning Sciences 14(2), 201-241 (2005)

7. Avouris, N., Margaritis, M., Komis, V.: Modelling interaction during small-group synchronous problem solving activities: the Synergo approach. In: Proceedings of 2nd International Workshop on Designing Computational Models of Collaborative Learning Interaction, ITS 2004, 7th Conference on Intelligent Tutoring Systems, Maceio, Brasil, pp. 13-18 (2004)

8. Clark, H.H., Brennan, S.E.: Grounding in communication. In: Resnick, L.B., Levine, J.M., Teasley, S.D. (eds.) Perspectives on socially shared cognition, pp. 127-148. American Psychological Association, Washington (1991)

9. Meier, A., Voyatzaki, E., Kahrimanis, G., Rummel, N., Spada, H., Avouris, N.: Teaching students how to improve their collaboration: Assessing collaboration quality and providing adaptive feedback in a CSCL setting. Submitted as part of the symposium New Challenges in CSCL: Towards adaptive script support (Nikol Rummel and Armin Weinberger), ICLS 2008, Utrecht (June 2008)

## Facilitate On-Line Teacher Know-How Transfer Using Knowledge Capitalization and Case Based Reasoning

Celine Quenu-Joiron and Thierry Condamines

MIS Laboratory, Université de Picardie Jules Verne, 33 rue Saint-Leu
80000 Amiens, France
{celine.quenu,thierry.condamines}@u-picardie.fr

## Abstract

Case Based Reasoning (CBR) methods have been used in various domain specific applications, mainly dedicated to decision making. The aim of this paper is to present how CBR is integrated in an educative project, in order to contribute to life-long teacher training. In fact, the acquisition of professional know-how, for example in the class management domain, can constitute a major difficulty for novice teachers. Thus, the TETRAKAP project (TEacher TRAining by Knowledge cAPitalization) aims to develop a web community platform dedicated to knowledge capitalization and know-how transfer between experienced teachers and beginners.

**Keywords**: Case-Based Reasoning, teacher training, knowledge capitalization, know-how transfer.

## Introduction

Case-Based Reasoning (CBR) is a reasoning-by-analogy approach on which a part of computerized decision support systems are based, since about fifteen years [1] [2]. These systems aim at helping to solve problems using a case base. A case then represents a problem associated with its solution. To solve a new problem, the system extracts from the case base, a

Here's the cleaned and normalized Markdown:

## Facilitate On-Line Teacher Know-How Transfer

In spite of this diversity, little works in CBR are interested in the teacher training area and particularly nursery or primary school teachers[^1]. However, teaching implies the implementation of complex know-how coming from experience. The problems encountered by young teachers are concrete and numerous. The progressive acquisition of this know-how must help them to face new situations. An online platform helping to reinforce the acquisition of this know-how answers a real need. Moreover, these problems generally were already encountered and solved before by other more experienced teachers. It thus seems to us relevant to base pedagogical approach of this platform on know-how capitalization, reasoning by analogy and finally on know-how transfer between experienced teachers and novices. The design and development of this platform are the subjects of the TETRAKAP project (TEacher TRAining by Knowledge cAPitalization). The objective of this paper is to present how CBR is implemented within this project.

Thus, in the first section we will present the context of our research, the TETRAKAP project, its origin and the problems it has the ambition to answer. In the second part we will show how CBR is integrated within the TETRAKAP system. Finally, in the last section, we will conclude with some research perspectives.

## The TETRAKAP Project

The TETRAKAP project aims to design, develop and experiment a computerized knowledge capitalization platform to preserve knowledge coming from experienced teachers and make it "easily" accessible to other teachers as a training solution. It is interested in particular in the primary and nursery teacher's population and their accompaniment during the first years of their career. In this section we present the project context as well as the main functionalities aimed by the platform.

### The Context

Several reports have justified the starting of this project. Indeed, in the French context, when we follow current events of official texts, we realize that teachers' professionalization is a major concern for education managers. This is due to the fact that the act of teaching requires a thorough initial training, the control of the practical experience, autonomy and the individual and collective ethical responsibility [8]. It's not easy to control all these facets and the entry in the job is often very hard due to the fact that a young teacher must face a double learning: pupils learning and his own learning [9].

A representative example of these difficulties is undoubtedly the class management. Many studies indeed show that it's the major obsession of young teachers, at the beginning of their career, and one of the main sources of difficulty ([10], [11], [12], [13]). Several systems in higher education have been set up to try to manage these difficulties and help these teachers, in particular by means of Communities of practice [14]. In France, few experiments have been realized for primary teaching and none has been sufficiently convincing to be extended to the whole of the community.

### Functionalities and Goals of the Platform

Within the TETRAKAP platform, each teacher has a personalized space. This space include a detailed description of his activity profile which he is invited to describe at the first connection, and which he will be able to complete if necessary. This profile included a structured description of his current job context (school, class, pupils ...) as well as information on his specific competences (specialization, certificates ...) and experience (career description, special experiences ...) [16] [17].

Moreover, during interviews of novice teachers performed in 2007[^2], two main categories of problems have emerged. The first one concerns the methodology of the preparing course task. This preparing tasks are mainly performed at home and more experienced teachers could help novice to answers to questions of methodology in order to improve their practice. The second category of problems deals with the non current events that appear with children during class activities. In that case, teacher doesn't know how to solve this problem.

Consequently, starting from these two categories, TETRAKAP proposes to integrate two modules that aim to help and assist teachers in their different problem solving task, relatively to their category. Theses two modules are called TETRA-KM and TETRA-BC.

Here's the cleaned Markdown:

## Facilitate On-Line Teacher Know-How Transfer

## The TETRA-BC Module

This section aims at presenting the principles on which the TETRA-BC module is based. The first section starts with some generalities on the fundaments of CBR, necessary for the continuation of the article. The second presents the structure of a case and the third part presents the case base. Finally the last section describes the main CBR scenario used in TERTRA-BC.

### Generalities about CBR

In a CBR system, a case represents a problem solving episode. Generally, a case is divided into two parts, one representing a problem (called pb) and the other representing the solution of this problem (called sol(Pb)). The problem we search to solve is named target-case, and the case we will take as a starting point to perform it, is named source-case. Lastly, a case, its problem and its solution are described by a set of descriptors, themselves composed of couples (attribute, value).

According to [1], the CBR cycle is composed of 4 phases as shown in figure 1. The CBR cycle is organized around a case base and a knowledge base. These last are used progressively in order to help with the various tasks of the system. The first phase of the cycle, called "RETRIEVE" allows, using a pairing process, to extract from the base a source case. This source case refers to a problem near to the target case and which will be taken by the system as a starting point to solve the target problem. The second phase is the "REUSE" phase. The system adapt the solution of the source case to the context of the target case. We obtain an "adapted" target case. Then a phase called "REVISE" consists in checking, evaluating and possibly correcting the adapted case. Lastly, when the case is suited and in conformity it can be memorized in the case base, during the "RETAIN" phase.

In more recent french publications, we can find a preliminary phase, called "ELABORATE". This one established the link between a problem described by a user in a poor structured way and a structured form of the target case (using a collection of descriptors). We will see in the continuation of this document that this phase is very important in our project.

### A Case in TETRA-BC

As evoked previously, a case represents a problem solving episode characterized by a couple (pb, sol(pb)). Thus, TETRA-BC is focused on problems encountered in class by a novice teacher. The following figure 2 presents an example of such a problem.

In a teaching context, and particularly concerning the organization and management of a class, a problem can only be solved by taking into account a whole set of factors related to the context in which this problem occurred. Indeed, a problem occurring in a nursery school in a urban environment will not have the same solution as a similar problem occurred in a rural environment and a primary class. This is why, a case in TETRA-BC contains not only information concerning the problem specification itself but also information concerning the context in which this problem occurred³.

---
³ It should be noticed that most of teaching context information are include in the teacher profile.

Here's the cleaned Markdown:

## Facilitate On-Line Teacher Know-How Transfer

Thus, pb is divided into two parts: context_pb, which represents the context of this problem and specif_pb, representing the specification of this problem. For example specif_pb will contain the description of a quarrel with a pupil, whereas context_pb will contain a subset of the teacher profile such as information about its geographical environment of teaching (urban, rural) or the level of its class.

With regard to sol(pb), this solution must make it possible to represent how the teacher tried to overcome this problem in his class, characterizing the actions carried out by the teacher to solve this problem. But, as a case aims at bringing assistance to other teachers to build their own solution, the solution of this problem also integrates the effects of these actions. Lastly, we will see in the CBR scenario of section 4.4 that the experts can have to bring a qualitative evaluation of each new case. So the solution of a case also integrates a part dedicated to the result of this evaluation.

Finally, sol(pb) breaks down into three parts: sol_actions, sol_effets and sol_eval. Figure 3 synthesizes the complete structure of a case in TETRA-BC.

One part of the work in TETRA-BC consists in specifying the list and nature of descriptors. Particularly, we have to realize a conceptualization of a teaching problem, by means of a taxonomy or an ontology. The latter must be built from a model of the teacher tasks. This ontology is currently under construction.

### A Two Level Case Base

The participation of the teachers in the TETRA-BC platform is based on their wishes to share their experience and practice. Thus, it is necessary for this system to be as simple as possible to handle. Indeed, if contributing on the platform asks for a too great effort to the teachers, it will be quickly unused. To avoid that, the manner of describing a problem or a solution must rest as much as possible on the natural language. Nevertheless, to be able to make relevant pairing between cases, and in particular to use CBR techniques, it is important for cases to be represented by a collection of significant descriptors. Lastly, when a teacher explores the case base, the system can't only present this collection of descriptors to him but must give him access to a description in natural language.

This is why, as shown in the figure 4, TETRA-BC is based on a two level model of the case base. The first one, called "narrative level" aims to preserve the description of a case freely written by the teacher in a semi-structured description (called descr(Case i)) in figure 4), strongly based on the natural language. The second level, called "knowledge level", modelize the representation of a case (called Case i in figure 3), structured in the form of a set of descriptors. It is this representation of a case which is used in particular for pairing and whose structure was presented in the previous section. Consequently, each case stored in the knowledge level is associated with its description in the narrative level.

Each time a case is presented to a teacher at the conclusion of retrieval in the case base, it is the representation of the case at the narrative level that will be presented. Moreover, each time a new case is described at the narrative level, the system builds then its representation on the level knowledge. To inform the specif_pb part, the system extracts from relevant information in the description made by the teacher. The use of the ontology during this step is mast important[^4]. Lastly, it is at this time that the relative information with the context of teaching are extracted from the teacher profile to aliment the context_pb part of the case.

### The CBR Cycle of TETRA-BC

The CBR cycle of TETRA-BC aims to propose an alternative solution to direct interactions with the peers through the platform. Indeed, the peers can't be solicited systematically for the resolution of each problem, all the more for problems previously solved. The idea is to really limit traditional difficulties of discussion forums when a similar problem

Here's the cleaned Markdown:

## Facilitate On-Line Teacher Know-How Transfer

## Case-Based Reasoning Implementation

The sequence diagram and CBR cycle of TETRA-BC shows that experts discuss and try to build solutions independently to avoid influence from different opinions. Once a solution is built, the novice describes it on the platform (sol_action and sol_effects). Three experts then evaluate this solution, completing the sol_eval. An arbitration algorithm decides case memorization, registering pb, sol(pb), descr(pb) and descr(sol(pb)) simultaneously.

Each stage of the CBR cycle is well implemented:
- ELABORATE: Building target-pb from descr(target-pb)
- RETRIEVE: Pairing process between target_pb and source_pb
- REUSE: Teacher-controlled adaptation using case base or expert discussions
- REVISE: Novice describes solution (actions/effects) and experts evaluate/validate
- RETAIN: Solved cases are capitalized via arbitration algorithm

Several alternative scenarios were also modeled, all founded on the CBR cycle.

## Conclusion and Perspectives

This paper demonstrated the use of CBR techniques in the TETRAKAP platform to support teacher know-how transfer for training purposes.

Several stages remain before achieving an operational tool:
- Specifying descriptors to characterize cases from problem descriptors
- Working with teacher-provided textual cases, professional documentation, and former student reports
- Developing semantic characterization of teaching problems via ontology
- Creating interface for narrative-level case description
- Collecting new cases to link narrative and knowledge levels

## References

1. Aamodt, A., Plaza, E.: Case Based Reasoning: Fundational Issues, Methodological Variations ans System Approach. AI Communications 7(1), 39-59 (1994)
2. Kolodner, J.: Case Based Reasoning. Morgan Kaufman, San Francisco (1993)
3. Watson, I.: Applying Case Based Reasoning – Techniques for Enterprise systems. Morgan Kaufmann, San Francisco (1997)
4. Aamodt, A.: Knowledge-Intensive Case-Based Reasoning and Intelligent Tutoring. In: Funk, P., Rognvaldsson, T., Xiong, N. (eds.) SAIS-SSLS Proceedings, Västerås, Sweden, April 20-22, pp. 8-22. Mälardalen Högskola, Västerås (2005)
5. Kolodner, J., Cox, M., Gonzalez-Calero, P.: Case-based Reasoning-inspired approaches to education. The Knowledge Engineering Review, 1-4 (2005)
6. Guin-Duclosson, N., Jean-Daubias, S., Nogry, S.: The Ambre ILE: How to Use Case-Based Reasoning to Teach Methods. In: Cerri, S.A., Gouardéres, G., Paraguaçu, F. (eds.) ITS 2002. LNCS, vol. 2363, pp. 782-790. Springer, Heidelberg (2002)
7. Joiron, C., Leclet, D.: A case base model for a case based forum: experimentation on pediatric pain management. In: Artificial Intelligence in Education AIED 2001, San Antonio, Texas, USA, May 2001, pp. 111-121 (2001)
8. Lang, V.: La professionnalisation des enseignants: sens et enjeux d'une politique institutionnelle. Formation permanente – éducation des adultes, PUF (1999)
9. Saujat, F.: Spécificité de l'activité d'enseignants débutants et genre de l'activité professorale. Polifonia (8), 67-93 (2005

Here's the cleaned and normalized Markdown:

## Edushare, a Step beyond Learning Platforms

*Romain Sauvain and Nicolas Szilas*

TECFA, FPSE, University of Geneva,
CH 1211 Genève 4, Switzerland
romain.sauvain@gmail.com, Nicolas.Szilas@unige.ch

## Abstract

This papers presents Edushare, a web-based learning environment that has been designed for cognitive remediation applied to autistic children. While existing learning platforms integrate various services in a web-based environment, they meet limitation where specific software must be integrated. Their role is then mostly confined to hosting the external software, without deep integration. Therefore, Edushare a service-rich integration platform, was created. It consists in centralizing within the platform a series of services shared by many educational softwares. These services include data logging, logs visualization, media management or parameterization. As a result, software development benefits from these services and focuses on its core goal, learning activities. This approach is described with a case study concerning facial emotion recognition in autistic children.

**Keywords**: learning platforms, service-rich integration platforms, special education, cognitive remediation, educational technologies, learning software.

## 1 Introduction

### 1.1 Context

This research project is concerned with helping autistic children through the use of educational software. These children are part of a special education program in Geneva, Switzerland. During the day, they attend a specialized institution with only eight children, where they are followed by psychologists and educators. The children are severely autistic persons, with an I.Q. below 80.

The goal of the project is to develop training software based on Cognitive Remediation for the children. Cognitive remediation consists in training a specific basic skill via repeated exposition of stimuli, hypothesizing that such a remediation have a more global impact on the everyday behavior of the subject. Cognitive remediation has been used successfully with people with disabilities including ADHD [1][2], schizophrenia [3] and age related cognitive impairments [4].

Cognitive remediation is advantageously administrated via computerized exercises, which allows both a precise timing of activities and an automatic reporting of the patient activity (as far as the keyboard/mouse activity is concerned). The use of virtual environments of learning and practicing living skills has been the central point of several projects [5][6]. Furthermore, many other benefits have been observed when autistic people get trained with computers, such as the safety and predictability of the environment or the control of the interactions (see [7] pp. 91-101).

### 1.2 What Platforms Do, What They Do Not Do

Existing learning platforms, such as Moodle [9], Dokeos [10] or Claroline [11] provide various services for distance learning with the following functions [12][13][14]:

- Information exchange: page display, download and upload of any file (usually a document)
- Communication (synchronous and asynchronous): forums, chat  
- Collaboration: wiki
- Management: learner management, activity management, usage logging, time management (deadlines, calendar)

Given the above initial requirements, learning platforms and content management systems (CMS) could be used in two ways:

- activities fit into an existing authoring tool. For example, if the activities only contain simple quizzes to answer, the eXe editor [15] could be used in conjunction with Moodle, because eXe products can be integrated in Moodle as a learning object. However, content management (media modification) is restricted to people who know how to use eXe tool. Furthermore, the logs retrieved from the activities would be limited to the SCORM [16] standard. Another option consists in developing a plugin for a platform such as LAMS [14], but this requires a high degree of programming expertise.

- activities constitute a separate executable file, which is downloaded from the platform, as in the abuledu website [17]. In that case, the activity developers have total freedom in their design, but the trace

Here's the cleaned and normalized Markdown:

## Edushare, a Step beyond Learning Platforms

## Analysis of Existing Platforms

A variant of this solution consists in using a web-based development tool, such as Adobe Flash, in which case the activity is still separate but integrated within the web browser. See as an example the paraschool website [18]

It results from the above analysis that existing platforms appear insufficient to both:
- host activities that go beyond simple e-learning functions, that is beyond material presentation and quizzes
- allow various actors to "get inside" these activities, either in terms of content management or data log processing

Therefore, we chose to overcome these limitations by developing our own learning environment, that we named Edushare.

## The Concept of a "Service-Rich Integration Platform"

In order to combine the ease of use of classical e-learning platform in terms of course preparation and the richness of a specific software development, a different concept of platform needs to be invented.

This new concept is illustrated in Fig. 1. While a platform, as its name suggests, hosts autonomous complete software for activities (as an independent file), the idea is to host partial software, which reuses standard services provided by the platform. Typically, all cognitive remediation exercises need media (content), that should not be hard-coded into the software. Developing a content management interface is always a time consuming task, which is remote from the core role of the software, namely the pedagogical/educational components. It is proposed that the software delegate the content management to the platform. Similarly, other common functionalities lie inside the platform (see Section 2).

Technically, each module is developed in a development language chosen according to the specific needs of the exercises and the expertise of the development team. It can be Flash, Java, Authorware, provided that the two following conditions are met:
- the software produced by the language/tool can be played on a browser (possibly with a plugin)
- the software can connect to a MySql database, either directly or by calling php functions

Within the software, developed in a suitable language, calls to the database allow to access to the various services provided to the software. Platform's services consist in recurrent components in educational software that are not specific to the learning task. Most of these services (detailed below) benefit from the networking characteristics of the platform.

Edushare can be called a "service-rich integration platform", even if, in a way, it is no longer a platform, since it does not only host documents and exercises but provides them with common services that would otherwise be part of the software. At the same time, the goal is not to impose a specific language or tool, for the development itself, beside the conditions mentioned above. It is interesting to compare Edushare with the Educlasse website [19], which enables advanced integration features such as media management or logging of learning activities, but does not provide the means for an independent developer to add a new exercises in the website.

Note that while Edushare is devoted to special education and autism treatment via cognitive remediation, it can be used for various educational needs.

## Functionalities

Before listing the functionalities implemented within Edushare, it is relevant to identify the various roles related to the use of such an environment. In our context, 5 roles can be distinguished:

- Learners: they are the final users, faced with the educational content. In our case, they are the autistic children. A particularity of Edushare, compared to classical platforms, is that these users do not directly log in (see below).
- Accompaniers: They are the people next to the student, who are responsible for the proper execution of the learning session. They log in the platform and specify the identity of the learner. They might contribute to the session actively, either during the exercises or after, for reporting. Accompanier could be educators, psychologist, or members of the family.
- Program director: It is the person who is in charge of the learners and is responsible of their progress. She/He knows the learners outside of the computer-based learning program.
- Developers: They are the people who

## Edushare, a Step beyond Learning Platforms

## Platform Features

For educators and program directors:
- Modularity: Activities can be combined into modules and sequences for specific learning/training programs, allowing flexibility in course design.
- Content Management: Media assets (pictures, images, sounds etc.) are stored in the platform database rather than within exercises. Program directors can upload and assign assets to activities, with assets shareable across activities. This allows non-technical users to modify/customize activities.
- Parametrization: Variables attached to activities and media can be modified on the platform without programming knowledge. Like content management, this provides flexibility for non-programmers.
- Off-line communication: A simple forum enables communication between program directors, accompaniers, and analysts.

For developers:
- Development: Activities are developed outside the platform, giving developers maximum freedom while requiring: (1) use of appropriate development language, (2) use of specific functions for accessing Edushare's functionalities like data logging, media storage and parameterizable variables.

For distant analyzers:
- Log visualization: Produces visual logs of learner activity
- Log export: Raw logs can be exported for statistical analysis in specialized software like SPSS or Statistica

## Technical Development and Architecture

Edushare is a Web-based platform built with common Internet technologies:
- PHP 5 as core technology with HTML
- CSS for presentation control
- Javascript for dynamic functionalities
- Ajax for asynchronous data retrieval
- MySQL for data storage

The platform has two distinct interfaces:
1. Learner Interface: Simplified design for selecting and executing exercises, minimizing distractions for users like autistic children
2. Administration Interface: Built with Joomla CMS, offering comprehensive functionality for developers, educators, and psychologists to manage activities, media, and monitor learner progress

The data model includes several key entities:
- Activities: For creating and uploading new exercises
- Media: Managing exercise content through database integration
- Modules: Combining activities into ordered or unordered sequences
- Learners: Tracking user progress on the platform

Here's the cleaned and normalized Markdown:

## Log Management and Interface Features in Edushare

As a final point on the technical side, the opportunity to make comments should be described. From both interfaces, users can write comments about a learner, an activity or a module at any time. These comments will appear on the management section of the entity, but also directly on the home page of the administration interface for each person involved with the entity in question. For example, the user who created an activity will see the comment saying "This exercise has been appreciated by the learner but could offer several levels of difficulty" and can reply directly by writing another comment.

This technical overview highlights the fact that Edushare is more than a simple platform where you can only host exercises. We would like to further illustrate this point by describing in detail one of the main feature of Edushare, the ability to manage logs.

### Log Management

As presented before, an important feature offered by Edushare is a complete management of logs. When a learner executes an exercise, "session" logs are automatically saved in the database. Information such as the current learner, the date and time, the module and the activity are stored. In addition to these general data, the activity creators can include a simple call to a .php file that will save any desired variables and link them directly with the session logs. The following programming example works for an exercise created with Macromedia Flash 8 and stores two variables: the correct answer and the execution time of the activity.

```
loadVariablesNum("../../scripts/logs.php?correct_answer="+correct_answer_value+"&execution_time="+execution_time_value, 0, "POST");
```

This call to the logs.php file must be sent each time a learner gives an answer or finishes an exercise. Of course there is no limit to the number of variables saved as logs, but we consider that a small selection of pertinent data is better than a large amount of useless information in which it will be difficult to make a precise analysis.

Beyond the mere storing of this information, Edushare offers the possibility to extract and view them. For this purpose, a complete section of the platform is dedicated to data analysis. An extensive study was conducted during the creation of the platform to propose an optimized tool to the user. Indeed, user accesses pre-processed data that are more relevant than raw data.

A form allows selecting precisely the desired logs with parameters such as learners, modules, activities, variables, dates or sessions. After the validation of these settings, a new window appears containing the results of the query. A table containing all the data as well as a button to export them as .xls file are present, but Edushare offers directly basic analysis without using an external tool.

Depending on the type and amount of data to display, different visualization modes are offered. In case of multiple variables, a time line is generated and shows only the repartition of the sessions for each learner.

In case of a single variable, a table and a graph are generated in real time. They display the first analysis for the data. If the variable is a numeric one, the mean value and the distribution are calculated automatically for each learner and are presented in the table. The graph that accompanies the table is very useful since it allows to visualize quickly the evolution of the learners over the multiple trainings and tests they have performed.

### Example: Facial Emotion Recognition

As stated in introduction, Edushare was designed in the context of cognitive remediation for autistic children. The first phase of the project focused on the content hosted and managed by Edushare. This content consists in educational software for people with learning difficulties. In this framework, a software called "Remédion" was created, a Macromedia Flash program connected to a MySql database for media management. The purpose of this application was to exercise autistic children in order to improve their recognition of facial emotions. 

In collaboration with the Service Médico-Pédagogique of Geneva (SMP), medicinal and psychological research center, and the Centre des Amandiers (CA), center for

## Edushare, a Step beyond Learning Platforms

In the following paragraphs, we will outline a few possible routes for users of the platform who are researchers from SMP, educators from CA and the autistic children.

For a full access to different topics and to take full advantage of features offered by Edushare, it is necessary to get logged in. Users, researchers and educators but not the children, need an account in order to have the basic rights. It is necessary to complete the provided form to register and to use the link in the e-mail automatically sent by the platform to confirm the registration. Once registered, many options offered by the platform are available.

One of the common use of the platform for an accompanying person is to record learners they are in charge of and help them practicing with activities. For that, the educator starts by creating a new entity in the "Learners" topic of the administration part for the child to whom he wants to propose exercises. Once this first stage is completed, he should go to the learner interface dedicated to the use of activities, which proposes various modules currently available in the platform. The educator selects "Remedion" in the list of existing modules. This module is made of four cognitive remediation activities dedicated to facial emotion recognition (Fig. 8). He will now let the child try the exercises itself, while providing assistance and support as the children received by the center are severe autistic children and are not autonomous.

At any moment during the training, the educator can make a comment about the current module, activity or learner simply by clicking on the corresponding button located on the top left corner. This whole process is described in Fig. 9.

Logs have been automatically generated during the use of the activities by the child. Let us consider the case of a psychological researcher of SMP who wishes to examine them in order to monitor the progress of a child. After logging in, he will go to the section dedicated to the extraction and visualization of logs and select the options corresponding to the logs he wants to extract. The first possible parameter will certainly be the name of the specific child he wants to follow. Then he can be interested in choosing an activity built for a special purpose (Fig. 11), like Remédion for facial recognition. Defining a start and end date could be relevant too, in order to view the results starting from the last check (Fig. 12). Having validated the selection, the results window opens, showing precisely the logs for this child, following one activity between the selected dates. The diagram below (Fig. 10) details each step in order to select and visualize logs using the platform's user interface.

The use of Edushare within this context was appreciated by educators and cognitive remediation researchers, particularly the ability to change the media and log comments. But a full experiment with the platform is still to be performed to systematically assess its strengths and weaknesses.

## Conclusion and Future Work

We have proposed a novel approach for combining the flexibility of specific educational software development with the advantages of learning platforms in terms of integration and communication. In the current implementation, services performed by the platform include user management, data logging management, media management and simple parameterization.

Among these services, much effort has been put on data logging because it moves educational software towards more openness. Indeed, if laboratory initiated cognitive remediation activities obviously logs the learner activity, it is far from being the case for other educational software. Typically, learning and edutainment products are usually designed as "black boxes": the learner uses them but the other actors – the parents, the teachers – have a quite limited feedback on what has happened, beyond the mere percentage of completion of the software. We believe that this closeness is one of the reasons for their limited usage. Adapting such software to be used within a service-rich integration platform such as Edushare should increase the usage of the software.

Other services could be developed to help integration and openness of educational software. We will mention here two of them. Firstly, in case of a complex software (for example a learning game), it is not easy for the potential user (a teacher) to get a clear view on the content of the software, in terms of both general learning goals an

Here's the cleaned Markdown:

## Edushare, a Step beyond Learning Platforms

"detailed overview" of his/her product, without executing the whole product, similar to the walkthrough available (often via "cheat codes") in some video games. Secondly, the current parameterization capability offered by the platform is limited to modifying variables. We would like to extend this to advanced parameterization interfaces that would allow a non programmer to gain more authorial control of the final educational activity. The platform would make available templates of parameterization graphical user interfaces that could be used by developers to make their product more visible. Given its current and future possibilities, it appears that Edushare and its underlying approach, initially designed for special education and cognitive remediation, could be of interest for a much wider population, in terms of both learners and trainers.

## Acknowledgements

Authors would like to thank the Service Médico-Pédagogique in Geneva, for initiating this project on cognitive remediation, in particular Stephan Eliez and Martin Debanné. Also, the authors thank the Centre des Amandiers and its staff, for allowing us to work with the autistic children in their institution.

## References

1. Stevenson, C.S., Whitmon, S., Bornholt, L., Livesey, D., Stevenson, R.J.: A cognitive remediation programme for adults with Attention Deficit Hyperactivity Disorder, Australian and New Zealand. Journal of Psychiatry 36, 610–616 (2002)
2. Klingberg, T., Fernell, E., Olesen, P.J., Johnson, M., Gustafsson, P., Dahlström, K.: Computerized training of working memory in children with ADHD — A randomized, controlled trial. Journal of the American Academy of Child and Adolescent Psychiatry 44, 177–186 (2005)
3. Medalia, A., Richardson, R.: What Predicts a Good Response to Cognitive Remediation Interventions? Schizophrenia Bulletin 31, 942–953 (2005)
4. Ball, K.K., Wadley, V.G., Vance, D.E., Edwards, J.D.: Cognitive skills: Training, maintenance, and daily usage. Encyclopedia of Applied Psychology 1, 387–392 (2004)
5. Cobb, S.V.G., Neale, H.R., Reynolds, H.: Evaluation of virtual learning environments. In: Proc. 2nd Euro. Conf. Disability, Virtual Reality & Assoc. Tech., Skövde, Sweden (1998)
6. Beardon, L., Parsons, S., Neale, H.: An interdisciplinary approach to investigating the use of virtual reality environments for people with Asperger syndrome. Educational and Child Psychology (2001)
7. Grynszpan, O.: Multimedia Human Computer Interfaces: designing educational applications adapted to high functioning autism. Phd Thesis, University of Paris-Sud (2005), http://www.risc.cnrs.fr/detail_memt.php?ID=875 (accessed April 17, 2009)
8. E-Prime, http://www.pstnet.com/products/e-prime/ (accessed April 17, 2009)
9. Moodle, http://moodle.org (accessed April 17, 2009)
10. Dokeos, http://www.dokeos.com (accessed April 17, 2009)
11. Claroline, http://www.claroline.net (accessed April 17, 2009)
12. Peraya, D.: De la correspondance au campus virtuel: formation à distance et dispositifs médiatiques. In: Charlier, B., Peraya, D. (eds.) Technologie et innovation en

Here's the cleaned Markdown:

## Design in Use of Services and Scenarios to Support Learning in Communities of Practice

Bernadette Charlier¹ and Amaury Daele²

¹University of Fribourg, Centre de Didactique Universitaire, Boulevard de Pérolles, 90, 1700 Fribourg, Switzerland  
²University of Lausanne, Centre de Soutien à l'Enseignement, Quartier-UNIL, Bât. Unicentre, 1015 Lausanne, Switzerland  
bernadette.charlier@unifr.ch, amaury.daele@unil.ch

## Abstract

This paper presents a research realised in the framework of the PALETTE project (FP6-TEL) which aimed at observing and analysing the design in use of web services and tools in the context of Communities of Practice (CoPs). Design in use consists in trialling the prototypes and their scenarios of uses and to observe the instrumental genesis carried out by the CoPs services.

We first present our conceptual framework based on the instrumental genesis theory. We then present our methodology for the generation of data and the analysis. Results of a cross-case analysis done on seven cases of design in use of PALETTE services and scenarios by CoPs are then described and analysed. The discussion provides reflection that may inform the use of PALETTE services by other CoPs in other contexts. Finally, in the conclusion, we reflect on our methodological approach and results, and provide guidelines for further research.

**Keywords**: Community of practice, participatory design, instrumental genesis, uses of services and scenarios to support learning in CoPs.

## 1. Introduction

This paper presents a research realised in the framework of the PALETTE project (FP6-TEL)¹ that aimed at observing and analysing the design in use of web services and tools in Communities of Practice (CoPs). The services provided by PALETTE are classified into three categories: information management, knowledge management and collaboration. These three types of services aimed at supporting three types of CoPs activities that we called 'generic scenarios':

- Knowledge reification focusing on document production, retrieval and reuse
- Collaboration: debate and decide concentrating on the exposition of opinions, their comparison with others and the selection of the most salient ones
- Animation and moderation: identity building specialising in the development of a feeling of membership and the evolution of the group

They have been designed and developed through a participatory design methodology which included three main steps:
1. Analysing the CoPs contexts and needs
2. Designing for use through the elaboration of scenarios of uses of technological services
3. Designing in use carrying out trials of both scenarios and services and making appropriate modifications to scenarios and services if necessary

Seven CoPs have been involved in this process. All were involved in the training or education domains. In this paper we report a research aiming at understanding how these CoPs have appropriated the services and scenarios we developed with them.

## 2. Conceptual Framework

This section presents the main concepts used in the research: instrument, instrumental genesis, instrumental genesis in groups and mediation of the instrument. The instrument-mediated approach is based on one fundamental concept: the instrument. An instrument is not only an object, an artefact – or a tool (material or symbolic) – that is used by an actor in order to carry out an activity. It is a "mediator" between the actor and his/her activity [1, p.175]. As a mediator, the instrument is able to act on the activity of the actor and on the actor him/herself to change his/her relation with the purpose of the activity. In return, the actor can act on the instrument in order to better support his/her activity.

This twofold influence is called "instrumental genesis" which is the progressive construction of uses of an artefact by an actor and depends of course on the social environment of the actor and his/her purpose. The action of the instrument on the actor and his/her purpose is called instrumentation and the action of the actor on

## Design in Use of Services and Scenarios to Support Learning

## Methodology
The trials of the services with the CoPs have been organised into six stages:

1. Selecting activities of the CoPs to be observed.
2. Describing the initiation/familiarisation processes of the CoPs with the PALETTE services in order to understand the contexts of use of the PALETTE services.
3. Observation of PALETTE services in use. Data were collected through direct observations of online or face-to-face CoPs activities and coded with a common grid of analysis focused on the highlight of the instrumental genesis lived by the CoPs.
4. Data analysis through content analysis methods: thematic analysis (information content), category analysis (frequency characteristic grouped in significant categories), and evaluation analysis (judgements: frequency, direction -positive or negative-, intensity). A reflection is also conducted about the possibility to generalise the results of the analysis in some ways.
5. Reporting to CoPs and developers of the services in order to inform the evolution of the CoP activities and providing feedback to the developers
6. Realising a cross-case analysis [4] that was dedicated to several questions: In what extent the produced analysis propose developments of the scenarios? By considering the seven analysed cases, what are the common conditions so that they are useful and consistent for other CoPs? How could we inform other CoPs in their process of development on the basis of our analysis?

Concretely, in order to carry out our cross-case analysis, we proceeded as follows:
- We wrote the analysis of each individual case based on the same conceptual framework and general questions of research
- We combined the analysis of each case into a common matrix so that the cases can be compared following common questions
- We finally wrote a general synthesis

For each scenario, we then identified three main questions that could be of interest for other CoPs:
- What are the conditions of use of the services: need, purpose, training of members, mastery of the tools, process of negotiation of use, habit of carrying out such activities, etc.?
- What are the changes (in CoP activities, communication, social interactions, etc.) that occurred through the use of the services?
- What are the perspectives of development of uses after the first experience?

## Results
First, here is a brief introduction to the context of the seven CoPs. The description of the services used is available on the PALETTE website (http://palette.ercim.org).

- Did@cTIC, a CoP of young university teachers in Switzerland who regularly meet face-to-face in order to discuss pedagogical issues and needs they face in their daily practice. Their main aim was to report (to reify) their practices and oral discussions in order to share them. This has been done through the use of a HTML editor (Amaya) with a template to take notes during the meetings and a web service (DocReuse) supporting semi-automatic and automatic reuse of parts of different documents in order to produce new ones with other purposes.

- ePrep, a CoP of Higher Education teachers in the domain of Sciences in France in collaboration with the French Grandes Ecoles across the world. Their main goal was to produce course (multimedia) documents and share them to the whole community of French-speaking teachers in the world. They used a multimedia open source editor (LimSee3) and a Wiki service.

- Learn-Nett, a CoP of tutors involved in a distance course for student teachers in the domain of the use of ICT for education. Their students form international groups aiming at producing a course sequence based on the use of ICT. The aims of the tutors were to share the pedagogical issues they face when supporting collaborating groups at a distance and to collect useful documents for them. They used a semantic Wiki (SweetWiki) and a web-based repository able to classify documents on the basis of a ontology (BayFac).

- CoPe-L, a CoP of e-learning trainers who aim at sharing resources on e-learning in companies and Higher Education through the use a web-based repository able to classify documents on the basis of a ontology

Here's the cleaned and normalized Markdown:

## Design in Use of Services and Scenarios to Support Learning

- Reification changes the way to work within a CoP through the passage from oral to written expression and descriptions of practice (Learn-Nett, Did@cTIC)
- Reification is a way to present the CoP to an external audience (Learn-Nett, CoPe-L) or to motivate peripheral members to participate in the core activities (ePrep)

In order to carry out these changes, at least two conditions seem to be common to the CoPs we have worked with:

- Training: it can take different forms (at a distance, in face-to-face, through individual or collective activities, etc.) and concern different objectives (mastery of tools, reification of one's practices, basic notions such as ontology, structured documents, etc.). However, its main purpose beyond the training of the CoP members is to develop a sense of belonging and getting involved in a common project in a wide sense. Training together is also an opportunity to meet, to discuss the points of the CoP, to debate the projects, to negotiate the next activities, etc.
- Continuing analysis of needs and reflection on CoP purpose and activities: again this can take different forms (reflection with a focus group, discussions with external experts, etc.). However the point here is to never think that CoP needs are static. Once they have highlighted their needs and main processes, the CoPs continue to reflect on their activities. They are dynamic in order to be consistent and up-to-date with their domain and members' needs and personal objectives. This continuing reflection also comprises development of uses of tools and curiosity about new tools and uses.

A third condition could be highlighted but is peculiar to the PALETTE project. It is the presence of mediators between the CoPs and the PALETTE developers. This condition has been very important for accompanying the activities and processes of change within the CoPs. As external experts, the mediators have closely participated in the development of the CoPs.

When one of these conditions was missing, the CoPs experienced issues in implementing new activities and new tools with their members. It is then not surprising that in their perspectives, the CoPs were willing to continue the development of training activities and reflection on their internal processes of reification, debate, decision making and identity building.

## Conclusion and Perspectives

In conclusion, and regarding the uses of the PALETTE services, the analysis of our seven cases comes out onto a picture with sharp contrasts. Some CoPs trialled PALETTE services and will clearly continue to develop their uses. Some others concluded that the PALETTE services are not necessarily the most suitable for their purpose and either will use other tools or change their activities. However the fact remains that all have developed their ways to reify their members' practices, organise debates and decision making, and develop their identity through better description of their purpose or activities. In other words we could say they all learned, changed and developed. This is the lesson we learn from our within-case and cross-case analysis.

Proposing general advices from individual contrasted cases is a difficult exercise [4]. However, on the basis of our analysis, we could try to propose some important points to other CoPs:

- Evaluate the members' mastery of ICT and attitudes towards ICT. If they are used to work with ICT, new tools could be tested then accepted or rejected. If they are not used, common training is crucial.
- Analysis of needs and objectives is important: negotiation of meaning of the CoP activities allows developing CoP identity and members' sense of belonging.
- Elaborate short and concrete activity scenarios with clear added-value from the members' point of view and outcomes easy to evaluate.
- To keep connected even at a distance in order to keep the members involved in the processes of change.

If we consider our participative methodology (participating observations, interviews, questionnaires, etc.), it probably influenced the CoP members in the sense that we paid real attention to them. We also were closely involved in the CoP processes of development. During 3 years we have worked with them and they very well know our objectives and methodologies.

Here's the cleaned Markdown:

## Creating an Innovative Palette of Services for Communities of Practice with Participatory Design: Outcomes of the European Project PALETTE

Liliane Esnault, Amaury Daele, Romain Zeiliger, and Bernadette Charlier

EM LYON (France), University of Lausanne (Switzerland), Gate-CNRS (France), University of Fribourg (Switzerland)

esnault@em-lyon.com, amaury.daele@unil.ch, zeiliger@gate.cnrs.fr, bernadette.charlier@unifr.ch

## Abstract

The paper aims at presenting and analyzing the implementation of a Participatory Design Methodology within the large multidisciplinary European Project PALETTE. This methodology successfully enabled and supported the development and implementation of a "palette" of interoperable services dedicated to Communities of Practice in order to manage their knowledge asset, support collaboration, communication and decision making, and help to better animate the community life. Finally, it presents some lessons learnt that could be of interest for other multidisciplinary project in the Technology Enhanced Learning community.

**Keywords**: Communities of Practice, Participatory Design, Actor-Network Theory, Web services, widgets, scenarios, mediators, instrumentation, boundary construction, boundary objects.

## 1. Introduction

The objectives of the paper are to: (i) present how Participatory Design was implemented in a large European project called PALETTE, in order to help communities of practice (CoPs) enhance their practice and learning; (ii) explain the elaboration of the participatory design methodology that was developed for this purpose; present the rationale, principles, main steps and instruments, and analyze key aspects such the role of mediators and scenarios as boundary constructions; (iii) share some lessons learnt that seemed of interest for future projects linking multidisciplinary teams of users, researchers, developers, which seems particularly relevant to the Technology Enhance Learning community.

The successful unrolling of the PALETTE project and the quality of its findings and outcomes is mostly due to the conjunction of four factors: (i) the choice of working with a dozen real life Communities of Practice (CoPs), scattered among different areas of interest, and displaying a range of different practices and behaviors; (ii) the choice of providing a broad span of software elements as interoperating services available through widgets within a customizable interface; (iii) the choice of a Participatory Design based methodology and organizational process, relying on an approach of rich scenarios, enabling a strong commitment on the part of all the stakeholders throughout the project phases; and (iv) the choice of a longitudinal, formative evaluation process, which supported a continuous reflective and self-analysis attitude.

## 2. Rationale for Using Participatory Design in PALETTE: The PALETTE Actor-Network

The PALETTE project aimed at both developing socio-organizational knowledge by researching on CoPs functioning, learning and knowledge processing; and developing technical knowledge by researching on the interoperability of social software intended to sustain and support the functioning of Communities of Practice. According to the nature of PALETTE and taking into account its main goals, Participatory Design seemed to be the best framework within which to develop a suitable project methodology [1]. The Participatory Design approach was considered as a process of negotiation of usefulness to be achieved through reconciling the contrasting perspectives of various stakeholders, including users, designers and other researchers or trainers [2]. In PALETTE, Participatory Design was used together with Actor Network Theory [3].

The PALETTE actor-network - an actor–network being any kind of element, person, object, theory, organization, device, etc., which has an influence and all the interactions between them [3] comprised the following elements:

- Researchers from education science with a common constructivist perspective
- Researchers from computer sciences, such as Knowledge Management, mediation tools, multimedia authoring, document management and structuring, awareness, collaborative editing, etc.
- Twelve CoPs implied in PALETTE as external partners
- Applications or tools, more or less previously developed, as well

Here's the cleaned Markdown:

## Creating an Innovative Palette of Services

## Organization, Implementation and Documentation of the Participatory Design

The key elements to operationalize Participatory Design in PALETTE comprise: (i) the process followed; (ii) the participative activities, illustrated by the work of the mediators; (iii) the scenarios; and (iv) the instruments.

### The Process: Design-for-Use and Design-in-Use

Three main processes have been followed [8]:
- Analysis was related to the first stages of analysis of the PALETTE tools and CoPs activities, context and needs, to their modeling, and to the characterization of tools and services. This was done through interviews and discussions with CoPs members;
- Design-for-use concerned the development of the services and related scenarios, as well as the validation of the scenarios for each CoP. This was done through first tests of services by CoPs, common elaboration of scenarios, analysis of services usability, training of CoPs members, etc.;
- Design-in-use was related to the ongoing development of services and scenarios with a continuous trialing by the CoPs. This was done through "playing" the scenarios into real activities of the CoPs and ongoing discussions and negotiation between the CoPs and the developers.

### The Activities, as Illustrated by the Mediators

The PALETTE project was a distributed project from three points of view [8]:
- Interdisciplinarity: the PALETTE researchers were from different fields, and the CoPs covered different domains;
- Time: participative activities were scattered among different moments and stages throughout the project;
- Space: the PALETTE researchers and the CoP members were from 5 countries. Some CoPs were even themselves distributed in space.

This involved working at a distance with distributed teams. The organization of participative activities had to cope with this situation. In order to improve them, PALETTE introduced the "mediators" who played a role as representatives, spoke persons, and interconnectors. The mediator facilitated the participation of the different actors, especially by organizing participative activities where the collaboration process could take place. In PALETTE there were two kinds of mediators: the CoP mediator, a researcher who builds a bridge between a CoP and some of the PALETTE services, and the Service mediator, also a researcher, but acting as 'spokesperson' of a service and its developers.

Example of participative activities including CoP members, CoP mediators, service mediators, and other researchers are: design and writing of generic scenarios; organization of trainings around different services and their possible uses; organization of the trialing of the generic scenarios; effective trials of generic scenarios and debriefing; validation of the generic scenarios; elaboration and trials of Learning and Organizational Resources (LORs); PALETTE plenary meetings; etc.

### The Scenarios

Scenarios are tools for envisioning the future. They convey stories that happen in the real world, as well as stories we imagine happening in possible worlds. According to Caroll [9] scenarios describe key situations of use, in terms of actors, goals, context, tools, actions and events. Here lies a first valuable aspect of scenarios: they do not come with a strong semantic. In the design process their vagueness is an affordance. A second important aspect of scenario descriptions is that - in a Participatory Design process - most stakeholders would understand them, even though they shed different perspectives on them. They are thinking tools [9] [10].

Scenarios are not requirements – they are deliberately incomplete and easily revised. They facilitate the innovative exploration of design possibilities. For users, scenarios are meaningful because "the elements of the envisioned system appear embedded in the interactions that are meaningful for them to achieve their goals. They describe the future system in terms of the work that people will have to achieve".

The initial state of the methodology used in the project was based on the writing of scenarios of use, called "specific scenarios" because they were specific to each different CoP, and different uses of separate tools. There was an "attraction effect" from the current existing tools and current existing uses, preventing a real boundary construction to take place

## Creating an Innovative Palette of Services

## Main Achievements of PALETTE Regarding Participatory Design

At the end of the PALETTE project, there are some interesting achievements regarding the Participatory Design domain that come out of the project.

There is a common vocabulary, which is strongly influenced by Participatory Design and even by Actor Network Theory. Words such as "participatory design", "heterogeneity of the network of actors", "boundary objects", are commonly used. A common ground is build and appropriated by all the stakeholders. Everybody systematically refers to the generic scenarios, to describe some functions of services, or some specific features of the user interface, or the activities in such or such CoP, or in the design of learning resources or unrolling of training sessions, etc. Though the notion of generic scenario is still fuzzy, this very fuzziness enables the wide use of them as the most powerful boundary concept and methodological tool. The "Participatory Design culture" is seen as a distinctive value of the project.

CoPs, though still external to the project organization stricto sensu are fully engaged in participating in the project activities (scenarios, trials, validations, trainings, etc.). They agree with the Participatory Design process, they use the common vocabulary, at least to some extent, they share a good part of the common ground for understanding, they use the palette of Services. They provide the embryos of the future PALETTE services users' community.

The process of "negotiation of usefulness" leads to efficient outcomes: the innovative palette of Services is available, usable and used. It is ready to help CoPs not only to perform their current activities, but, hopefully develop and enhance them and find ways to innovate in their own practice.

## Conclusion: Lessons Learnt and Further Developments

The main lesson learnt from the three years of implementing Participatory Design in PALETTE is that participation is not given by the simple fact that persons and things are declared to be "in" or part of the project. Participation has to be constructed during the whole process. Considering the Participatory Design methodology as a boundary object, the boundary construction process lasts until the last minutes. A constant will (and good will) is necessary to permanently associate actors in participative activities, enroll new actors (the PALETTE Portal, the on-line training modules, new CoPs, new researchers, new instances of the generic scenarios, etc.).

Pitfalls are numerous, but learning from the challenges is a constant rewarding process. Eventually, we were able to build a common language (though the discussion about the use of the word "needs" is still pending). We were able to agree upon common representations, common instruments. We were able to cope with time issues; though sometimes it seemed that Participatory Design was "a waste of time", at the end it proved to be a gain in efficiency.

The Key Success Factors in the project were clearly the general good will and open-mindedness of all participants; the role of mediators and scenarios as key actors of the process; and also the key role played by a multiple level reflective evaluation process that enabled and sustained the successful achievement despite the pitfalls and provisional disagreements.

We tried to document the Participatory Design process as careful and as thoroughly as possible, so that it could be useful for further uses in further projects.

## References

1. Esnault, L., Zeiliger, R., Vermeulin, F.: On the Use of Actor-Network Theory for developing Web Services Dedicated to Communities of Practice. In: Tomadaki, E., Scott, P. (eds.) EC-TEL 2006. First European Conference on Technology Enhanced Learning, Crete, Greece, vol. 213, pp. 298–306. CEUR (2006), http://ftp.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-213/paper42.pdf

2. Abreu de Paula, R.: The Construction of Usefulness: How Users and Context Create Meaning with a Social Networking System – Dissertation (2004), http://www.ics.

Here's the cleaned and normalized Markdown:

## NetLearn: Social Network Analysis and Visualizations for Learning

**Mohamed Amine Chatti¹, Matthias Jarke¹, Theresia Devi Indriasari¹, and Marcus Specht²**

¹ Informatik 5 (Information Systems), RWTH Aachen University  
{chatti,jarke,indria}@dbis.rwth-aachen.de

² Open University Heerlen, Netherlands  
marcus.specht@ou.nl

## Abstract

The most valuable and innovative knowledge is hard to find, and it lies within distributed communities and networks. Locating the right community or person who can provide us with exactly the knowledge that we need and who can help us solve exactly the problems that we come upon, can be an efficient way to learn forward. In this paper, we present the details of NetLearn; a service that acts as a knowledge filter for learning. The primary aim of NetLearn is to leverage social network analysis and visualization techniques to help learners mine communities and locate experts that can populate their personal learning environments.

## Introduction

One of the core issues in Technology Enhanced Learning (TEL) is the personalization of the learning experience. Learners have a variety of learning styles, which are mirrored in the way they learn. There is a shared belief among TEL researchers that TEL models require a move away from one-size-fits-all models toward a learner-centric model that puts the learner at the centre and gives her the control over the learning experience.

Moreover, learning and knowledge are fundamentally social in nature, as has been emphasized by many researchers [1,2,3,4]. At the heart of learning and knowledge lie people. This requires a change in focus from technology-push to people-driven models of learning. New social skills become increasingly important for better performance and thus have to be learned and continuously improved. Learn-what referring to the high-quality learning resource that has to be acquired has to be supplemented with learn-who referring to the person or the entire community/network with the required know-how that can help achieving better results. Learn-who also involves the ability to navigate on one's own through a constantly shifting network of assistance. Siemens [5] stresses that the challenge today is not what you know but who you know and states that knowledge rests in an individual and resides in the collective. The author introduces connectivism as a new learning theory that presents learning as a connection/network-forming process [6].

## Personal Learning Environments

Self-organized learning provides a base for the establishment of a model of learning that goes beyond curriculum and organisation centric models, and envisions a new learning model characterized by the convergence of lifelong, informal, and ecological learning within a learner-controlled space. In recent years this way of learning is increasingly supported by responsive, open, and personal learning environments, where the learner is in control of her own development and learning.

The Personal Learning Environment (PLE) concept translates the principles of self-organized learning into actual practice. PLE is a relatively new term, first introduced in 2004 [7]. van Harmelen [7] describes PLEs as:

> Systems that help learners take control of and manage their own learning. This includes providing support for learners to
> - set their own learning goals
> - manage their learning; managing both content and process
> - communicate with others in the process of learning
> and thereby achieve learning goals.

A PLE-driven approach to learning suggests a shift in emphasis from a knowledge-push to a knowledge-pull learning model. In a learning model based on knowledge-push, the information flow is directed by the institution/teacher. In a learning model driven by knowledge-pull, the learner navigates toward knowledge. One concern with knowledge-pull approaches is knowledge overload. Therefore, there is a need for knowledge filters to help learners find quality in the Long Tail [8]. These knowledge filters can be services that support learners in locating valuable knowledge nodes. A distinction that is often cited in the literature is made

Here's the cleaned and normalized Markdown:

## Knowledge Types and Expert Finding

Explicit and tacit knowledge exist as distinct forms. Explicit knowledge (or information) is systematic knowledge that is easily codified in formal language and objective. In contrast, tacit knowledge is hard to formalize, difficult to communicate and subjective [3]. Tacit knowledge resides in people. Hence, tacit knowledge nodes are people performing in diverse, frequently overlapping social domains, who act together and help each other see connections. In the KM literature, there is a wide recognition that only a small fraction of valuable knowledge is explicit and there is a huge mass of high-quality knowledge embedded in people, which is not easily expressible and cannot be recorded in a codified form [9]. Thus, searching for information (explicit knowledge node) becomes a matter of searching the social network for an expert (tacit knowledge node) who might provide that information. This situation - in addition to the view of learning as the creation of meaningful connections - implies a need for effective community/network mining and expertise finding systems.

Community mining systems attempt to extract useful and reliable information from communities [10]. Expertise finding systems are a type of recommendation systems, which are designed in order to facilitate the finding of people with specific knowledge in a certain problem domain [11,12,13]. The process of finding an expert can be viewed as a search through the network of social relationships between individuals [14]. Social network analysis and visualization methods provide one powerful means for mining communities and finding expertise.

## Social Network Analysis and Visualization

Social networks often represent groups of people and the connections among them. Social Network Analysis (SNA) is the quantitative study of the relationships between individuals or organizations. In SNA, a social network is modeled by a graph G = (V, E), where V is the set of nodes (also known as vertices) representing actors, and E is a set of edges (also known as arcs, links, or ties), representing a certain type of linkage between actors. By quantifying social structures, we can determine the most important nodes in the network. One of the key characteristics of networks is centrality, which relates to the structural position of a node within a network and details the prominence of a node and the nature of its relation to the rest of the network [15]. Three centrality measures are widely used in SNA: degree, closeness, and betweenness centrality. The degree centrality finds the node with the most influence over the network. The degree centrality of a vertex v ∈ V is simply the degree of that vertex,

CD(v) = dG(v),

i.e. the number of incident edges [16].

Closeness centrality focuses on how close an actor is to all the other actors in the network. Closeness centrality is defined as inverse closeness, i.e., the sum of the distances to all other vertices [16],

CC(v) = 1/∑t∈V dG(v, t),

where dG(v, t) is the distance between v and t, that is, the number of edges to traverse in their shortest path.

Betweenness centrality finds nodes that control the information flow of the network. Betweenness centrality is defined as the sum of the fractions of shortest paths between other actors that an actor sits on,

CB(v) = ∑s≠v≠t σst(v)/σst,

where σst is the number of shortest paths between vertices s and t and σst(v) is the number of shortest paths between s and t passing through v [16].

Visualization also plays a major role in SNA. By representing a social network visually, interesting connections could be seen, explored and communicated at a glance. Node-link diagrams and matrix-based visualization are the most common visualization techniques in social networks. A detailed discussion of possible social network visualizations and their application is provided in [17].

## Case Study

Online bibliographies provide a rich source of relationships using the co-author relationship [14]. The effective visualization and analysis of large complex co-authorship networks is often a means of finding a community or

## NetLearn: Social Network Analysis and Visualizations

## NetLearn Design

NetLearn is built upon a three-Tier architecture. An overview of the NetLearn architecture is provided in Figure 1.

The Data Storage Tier is an IBM DB2 database which provides persistent storage for publications and authors. In the Web Tier, servlets and JavaServer Pages (JSP) are used to generate the front-end. The Business Tier encompasses a collection of modules, that enable to construct, visualize, cluster, filter, and analyze the co-authorship network, in order to mine communities and locate experts around a given topic. These modules are initiated in response to learner queries.

The visualization modules use the graph model of the yFiles programming toolkit. yFiles[^3] is a Java class library that provides efficient analysis and visualization algorithms for viewing, editing, optimizing, laying out, rendering, and animating network graphs. yFiles also provides implementations of important measures and algorithms used in social network analysis.

We differentiate between two types of analysis modules, namely community mining modules and expertise finding modules.

[Figure 1. NetLearn Architecture]

## Community Mining Modules

Typically, a learner is only aware of her own personal knowledge network. By visualizing, analyzing, clustering, and filtering the larger network, the learner can discover connections to people and information that would otherwise be outside her own network. The two community mining modules in NetLearn, namely author mining module and keyword mining module, help learners explore the large co-authorship network, so that they can find potential communities working on particular topics. These communities are in general bound by shared interests among their members. The author mining module clusters researchers based on co-authorship ties, whereas the keyword mining module clusters the scientific network based on keywords.

NetLearn uses a community mining approach based on the active mining model. Active mining focuses on active information gathering and data mining in accordance with the purposes and interests of the users [19]. The basic concept of active mining is to utilize spiral interactions between the user and the computer [20]. Community mining in NetLearn is performed in two steps. The first step is user-centered mining in response to a user query, based on graph mining and network clustering techniques. The second step a refinement of the mining result according to the user interaction/reaction with the system.

## Expertise Finding Modules

One of the aims of NetLearn is to match learners looking for expertise with individuals likely to have this expertise. In NetLearn, we consider two approaches for expertise finding in scientific co-authorship networks. The first is locating a person with some specific expertise or knowledge based on keywords and topics of interests (who knows what?). The second is an automatization of the small world effect [21], and is used for finding a path to an expert, when he or she is known in advance (who knows who knows what?). The expertise finding modules in NetLearn include the local author module, the keyword community module, the interest community module, and the referral chain module.

The local author module enables a learner to interactively explore a graphic representation of an author's egocentric network, that is the portion of the network around that author. Each ego network consists of the author, the ties to other authors he or she interacts with directly, and interactions between those authors.

The keyword community module enables a learner to search for an expert by specifying a keyword. In general, the centrality measures of an author in a keyword community network is highly correlated with his or her expertise. That is, highest degree nodes in a keyword community network are potential experts in a research area around a specific keyword. Moreover, we surmise that if an author has a high number of publications associated with a given keyword, it is often the case that he or she has high expertise in the research field around that keyword.

The interest community module helps a learner identify researchers who are likely to have expertise in a specified area. Frequent publishing on a given topic is a good source of evidence of a researchers interests and areas of expertise. The interest community module differs from the keyword community module in that the former accepts query input from learners on keywords, title, and abstract.

## NetLearn: Social Network Analysis and Visualizations

## NetLearn Implementation

The following sections illustrate NetLearn in action. In order to demonstrate how the system works, we show the functionalities of the different modules using actual examples.

### Author Mining Module

The author mining module provides a graph visualization of the global co-authorship network. In this graph, each node represents an author, and each edge models a co-authorship of a published paper. An example of a global visualization of the co-authorship network is shown in Figure 2. The learner can browse the graph interactively by zooming in/out, switching between the different layouts (i.e. circular, hierarchic, organic, orthogonal layouts), and setting an edge betweenness clustering threshold. The author mining module implements graph clustering based on edge betweenness centrality. The algorithm is iterative, at each step it computes the edge betweenness centrality and removes the edge with the highest betweenness centrality from the graph when it is above the given threshold. The algorithm terminates, if there are no more edges to remove. Figure 2 illustrates the result of a clustering of the initial graph, with an edge betweenness centrality threshold set to 170. The figure clearly shows that the co-authorship network is a reflection of the Long Tail phenomenon [8]. In fact, the majority of nodes are each connected to just a handful of neighbors, but there are a few hub nodes that have a disproportionately large number of neighbors. This is a common feature of many known complex networks, such as Web pages, forum, and open source software development networks [13].

The author mining module computes centrality statistics (i.e. degree-, closeness- and betweenness-centrality), as discussed in Section 3, for all nodes in the result graph. The module also enables to select a node in the graph to see the egocentric network of the researcher represented by that node. This visualization is suitable for finding communities that are built around a researcher. The learner can also filter the co-authorship network graph by specifying a publication year.

### Keyword Mining Module

The aim of the keyword mining module is to mine communities around specific keywords. This module provides an interactive graph visualization of keyword communities in the co-authorship network. A keyword community is a cluster that is densely connected by the same keyword. In a keyword mining graph, each node represents an author, and each edge models a shared keyword. Figure 3 shows network clusters that have their edges labeled by the keywords "E-Learning", "knowledge management", "social software", and "Web 2.0", highlighted by different colors. The learner can then navigate through the keyword community that he or she is interested in, and browse the publication list of the same community.

### Local Author Module

The local author graph models the ego-centric network of the author. Figure 4 depicts the local author graph of M. Jarke.

The size of each node in the graph represents the number of publications co-authored by the author modeled by that node. It is defined by a weight as follows:

weight(ai) = |pi|/|pG|

where ai is the author whose size of node is being calculated, pi represents the publications of ai, and pG represents all distinct publications by authors in the graph.

The thickness of the edge between two authors represents the number of joint papers, which can also be an indicator for the strength of the relationship between the two authors. The tie strength between two authors is calculated by a weight as follows:

weight(ai → aj) = |pi ∩ pj|/|pG|

When a particular edge is selected from the graph, a list of publications, co-authored by the two authors at the ends of the edge, is shown. To note that these are common features for all graphs produced by NetLearn.

### Keyword Community Module

The keyword community module enables expertise finding based on keywords. It does not only support locating researchers working on a specific topic, but also researchers working on topics closely related to that topic. The module consists of four components:

## NetLearn: Social Network Analysis and Visualizations

## Overview
The system provides several visualization components and modules for analyzing research networks and finding experts.

## Keyword Module Components
- **Keyword Graph View**: Shows relationships between keywords and their combinations. Clicking edges reveals publications tagged with both connected keywords.
- **Keyword Chart View**: Displays keyword trends over time.
- **Keyword Community View**: Explores communities around "knowledge management" and related keywords. Shows graph representation of co-author sub-networks with:
  - Author nodes
  - Keyword nodes
  - Interactive selection to highlight connections
- **Keyword Table View**: Lists publications for specified keywords in tabular format.

## Interest Community Module
Enables users to:
- Identify researchers in particular research topics
- Find relevant publications
- Group researchers based on mutual interests
- Rank researchers using structural centrality measures
- Query the network based on publication title, abstract, keyword, or combinations

## Referral Chain Module
- Finds chains between two given researchers
- Uses shortest path algorithm from yFiles
- Computes shortest distance from a given node to all other nodes

## Related Work

### Community Mining
- **Flink**: Extracts and visualizes Semantic Web researcher networks using multiple data sources, but lacks expert finding capabilities
- **Ichise et al.**: Developed systems for finding research communities and identifying topics, but limited to title keywords
- **Chan et al.**: Focuses on visualization and clustering of author networks, but lacks expert finding features

### Expertise Finding
- **Expertise Recommender (ER)**: 
  - Assists with expertise location
  - Recommends potential answerers
  - Uses social network matching without visualization
  
- **ReferralWeb**:
  - Mines co-authoring and co-citation relationships
  - Provides referral chains
  - Lacks topic-expertise association mechanisms
  - Limited in determining author network positions

## NetLearn: Social Network Analysis and Visualizations

NetExpert [26] also addresses the problem of finding people with expertise in communities and the paths to reach them. The system allows to search for an expert through names and expertise areas, based on knowledge profiles. NetExpert, however, does not provide means to discover potential experts in the whole network through clustering, filtering, and interactive visualization.

In summary, NetLearn offers several advances over previously existing community mining and expertise finding systems. Table 1 provides a detailed feature comparison of the studied systems.

Table 1. System Comparison

| Features | Flink [22] | Chan et al. [23] | Ichise et al. [20,10] | ER [24] | Referral Web [14] | NetExpert [26] | NetLearn |
|----------|------------|-----------------|-------------------|---------|------------------|----------------|-----------|
| **Community Mining Features** |
| author clustering | + | + | + | - | - | - | + |
| keyword clustering | - | + | + | - | - | - | + |
| network filtering | + | - | + | - | - | - | + |
| interactive visualization | - | - | + | - | - | - | + |
| centrality measures | + | - | - | - | - | - | + |
| **Expertise Finding Features** |
| search by keyword | - | - | + | - | - | - | + |
| search by name | - | - | + | - | - | + | + |
| search by research interest | - | - | - | + | - | + | + |
| ego network | + | - | + | - | - | + | + |
| referral chain | - | - | - | - | + | + | + |

## Conclusions

In this paper, we presented the details of NetLearn, an interactive learning service that leverages social network analysis and visualizations techniques to aid in the search for information and expertise in complex social networks, thus enabling learners to enhance their personal knowledge networks with valuable knowledge nodes. We demonstrated how the proposed system works, based on a co-authorship network of TEL researchers. We also provided an overview of prior systems that support community mining and expertise locating, and compared them to NetLearn. We showed that NetLearn has a number of important functionalities and features that sets it apart from such systems. The results of this project have been used at the PROLEARN final review, mainly to track and analyze the evolution of PROLEARN network of researchers over the last four years of the project. All of these efforts have been made available on the NetLearn project homepage. We welcome feedback from colleagues and users on both their experiences with the system and new ways they would suggest to harness social network analysis and visualization methods to help learners locate communities of interest and experts.

[References section omitted]

## Bridging Formal and Informal Learning – A Case Study on Students' Perceptions of the Use of Social Networking Tools

Margarida Lucas and António Moreira  
Department of Didactics and Educational Technology  
University of Aveiro, Portugal  
{mlucas,moreira}@ua.pt

## Abstract

Social networking tools have been enthusiastically heralded as a means to support different learning types and innovative pedagogical practices. They have also been recognized as potential tools to promote informal learning. In this paper we describe work carried out using the synergy of social web tools, learning models and innovative pedagogical practices across a Masters Degree Course. Findings suggest that the use of these tools as a means to distribute an open and flexible learning environment fosters informal interactions and such interactions are perceived by students to have a significant impact over their formal learning outcomes.

**Keywords**: Social Web, informal learning, distributed cognition, connectivism, case study.

## 1. Introduction

Although it has been around since individuals started to organize and communicate with each other, informal learning has gained considerable relevance within the knowledge-based society and lifelong learning. The awareness and the increasing importance of a personalized, learner-centred approach have led policy makers and educational agents to look at ways of harnessing the benefits of informal learning.

Recent reports and guidelines [1][2][3][4] recommend the adoption and the integration of communication technologies (CT) as a means to offer flexible, comprehensive and tailored learning opportunities to all individuals at all stages of their lives. As a result, the open and distance learning paradigm has been increasingly recognized as a requisite for all educational systems that wish to assure the acquisition and development of lifelong learning skills by their students.

In the past few years, the evolution of the Internet applications, now called social web or web 2.0, has transformed the web from a place for telling into a place for talking, where emphasis is put upon sharing, participating and collaborating. The web has become a social platform where we can interact, experiment, create and learn. In it, we all are 'prosumers', managers and knowledge builders, we share meanings, [re]build knowledge and [re]define ways of working and learning.

## References

16. Brandes, U., Kenis, P., Wagner, D.: Communicating centrality in policy network drawings. IEEE Transactions on Visualization and Computer Graphics 9(2), 241-253 (2003)

17. Bertini, E.: Social networks visualization: A brief survey (2005)

18. Chatti, M.A., Muhammad, N.F., Jarke, M.: ALOA: A web services driven framework for automatic learning object annotation. In: Dillenbourg, P., Specht, M. (eds.) EC-TEL 2008. LNCS, vol. 5192, pp. 86-91. Springer, Heidelberg (2008)

19. Motoda, H. (ed.): Active mining: new directions of data mining. IOS Press, Amsterdam (2002)

20. Ichise, R., Takeda, H., Ueyama, K.: Community mining tool using bibliography data. In: Proceedings of the 9th International Conference on Information Visualisation, IV 2005, London, UK, July 6-8, pp. 953-958. IEEE Computer Society, Los Alamitos (2005)

21. Travers, J., Milgram, S.: An experimental study of the small world problem. Sociometry 32, 425-443 (1969)

22. Mika, P.: Flink: Semantic web technology for the extraction and analysis of social networks. Journal Web Semantics 3(2-3), 211-223 (2005)

23. Chan, S., Pon, R.K., Cardenas, A.F.: Visualization and clustering of author social networks. In: 2006 Distributed Multimedia Systems Conference, Grand Canyon, Arizona

Here's the cleaned and normalized Markdown:

## Bridging Formal and Informal Learning

This dynamic platform, comprised by the integration of several tools, applications and services, has been used as a potential and suitable alternative for the support of different innovative pedagogical practices and different types of learning. From an informal perspective, we can describe it as a 'land of opportunities' for the exploration and harnessing of informal learning, due to the interaction and connections it enables, the non-linearity it bases on, the multiple paths it affords and the learner empowerment it provides.

The use of social web tools, such as wikis, blogs, social bookmarking sites, etc., to distribute learning environments is known to foster and promote the development of learning communities or learning networks, in which learning can happen unexpectedly as a result of the connections and interactions of their members [5][6][7][8]. Thus, informal learning can become a product of social knowledge through distributed, yet context situated and highly connected learning sustained by a collective practice. But how can informal interactions be incorporated into formal learning contexts without becoming formal as well? Can the social Web and the social tools it provides be explored to foster informal learning? What are the benefits brought by such tools to formal learning contexts? And what are students' perceptions about the informal learning opportunities that derive from the use of these tools?

However, and although there is a range of studies that have been exploring the use of social networking tools and participation in social networking environments [9][10][11][12] as well as the importance and processes of informal learning [13][14][15][16] evidence of such learning as a complement of formal education is scarce and research exploring the students' perceptions about the use of these tools for learning within formal instructional contexts does not abound.

The present work is an attempt to present data on students' experiences of using social networking tools to support learning in both formal and informal domains. The study presented is by no means comprehensive due to its limited duration and scope, but it provides data on how the use of these technologies impacted learning outcomes and on students' perceptions of their use.

The case study was conducted in the Multimedia and Cognitive Architectures (MAC) course, which is one curricular component of the Masters Degree Course on Multimedia in Education (MMEdu) of the University of Aveiro. We will present the theoretical scope of the work, followed by a description of the study and the methodology applied. After presenting the findings, we put forward some thoughts that stem both from the researchers' reflections and from the students' feedback.

## Informal Learning and the Social Web

Despite a lack of agreement related to its definition and to what exactly distinguishes formal from informal learning, the fact is that the latter, in the various forms it can assume, be it self-directed, incidental, intentional, non-intentional or social, is perceived today as a fundamental element in the life of all individuals. It is typically described as being "undertaken on our own, either individually or collectively, without either externally imposed criteria or the presence of an institutionally authorized instructor" [17]. Thus, whereas formal learning can be characterized as "typically institutionally sponsored, classroom-based, and highly structured", informal learning is "not typically classroom based or highly structured, and control of learning rests primarily in the hands of the learner" [18], with obvious impacts on the evaluation of that same learning [19][20].

Informal learning may be intentional, for example, through intensive, significant and deliberate learning 'projects' as Tough puts it [21], or it may be accidental, by acquiring information through conversations, reading or watching TV, observing the world or even experiencing an accident or embarrassing situation. Livingstone [17] established a clear distinction between explicit informal learning and tacit informal learning, which is incorporated into other social or ad hoc activities. Both forms of learning result in the acquisition of new knowledge or skills; however, only the explicit informal learning project is motivated by some immediate problem or need as defined in Tough's definition of informal learning.

Our assumption about informal learning is that it is a vital and continuous process, along which people gain skills, attitudes and knowledge that derive from their daily

## Bridging Formal and Informal Learning

## Introduction
The notion of connectivism, presented by Siemens as the "new theory for learning based on network structures, complex changing environments and distributed cognition" [26], draws from various fields including education, neurology, mathematics, sociology and physics.

The concept of distributed cognition within connectivism is particularly relevant as it challenges the idea that cognition solely "resides in the heads of individuals" [27]. Distributed cognition views tools, artifacts and social interactions as "vehicles of thought" rather than mere stimuli - learning occurs not just in the "person-solo" but in the "person-plus", the whole system of interrelated factors [28].

When discussing learning in networked structures, we refer to cognitions distributed across network entities: people, artifacts, tools and contexts. Siemens [29] defines networks as free, non-sequential but organized connections between entities forming an integrated whole. Networks derive their power from their ability to expand, grow, react and adapt through connections with other nodes - whether entities, people, contents or other networks.

The network structure is dynamic, distributed and decentralized, without requiring central control. Individuals control their network connections, and learning occurs through building, organizing, expanding and recognizing patterns that help interpret knowledge found along the way. Siemens emphasizes that today's challenge lies not in what one knows but who one knows, as others' experiences become surrogates for knowledge. The more diverse connections we make, the more we benefit from collective knowledge. Context is also crucial, as it "brings as much to a space of knowledge connection/exchange as do the parties involved in the exchange" [26].

## Background of the Study and Methodology
The Masters in Multimedia in Education (MMEdu) at the University of Aveiro included a course on MAC delivered in b-learning format, with two face-to-face sessions bookending four weeks of distance work. The course objectives for students (mainly in-service teachers) included:

- Deepening knowledge of cognitive systems
- Reflecting on learning theories related to knowledge building
- Exploring social networking tools' potential for augmented interaction  
- Developing and implementing an interaction-focused classroom activity using social networking tools
- Reflecting on activity outcomes

The course aimed to develop professional competencies including:
- Integrating CT into teaching practices
- Promoting interaction in pedagogical activities
- Harnessing informal learning from CT use
- Developing collaborative work
- Building research and information management skills

The course structure embraced connectivist principles, with teachers acting as environment managers and guides. The learning environment was distributed across multiple tools:

Table 1. Tools chosen to distribute the course learning environment and uses

| Tools | Uses |
|-------|-------|
| Course Blog | - Share f2f session content<br>- Publish articles/links/teasers<br>- Support student-teacher-content interaction<br>- Share reflections and questions<br>- Upload bestofpdi management scale |
| BestofPdi Blog | - Discuss project work and technology-enhanced learning |
| Group Blogs | - Support intra/inter group interaction<br>- Publish PDI-related content |
| Slideshare | - Publish f2f session content |
| Ma.gnolia | - Share community bookmarks |
| Wiki | - Collaborative report writing and reflection |
| Blackboard | - Provide course organization info<br>- Direct to alternative platform<br>- Survey PDI technology use |

Teachers initiated engagement by posting a bibliography-related challenge on the course blog before start. While Blackboard provided initial course materials and guidelines, it subsequently served mainly administrative purposes as learning activities moved to the distributed environment.

Here's the cleaned Markdown:

## Bridging Formal and Informal Learning

After the first face-to-face session, and besides participating actively in the discussions/tasks launched in the course blog, students, divided into 10 groups (of 5-6 members each), started developing their projects, working collaboratively, sharing proposals and ideas in order to plan and prepare the in-classroom activity that used social networking tools to promote interaction for their students (first and second course week).

During the third week of the course and on a daily rotating basis, each of the groups was also responsible for the administration and dinamization of the blog http://bestofpdi.blogs.ca.ua.pt, in which they presented ideas for different interaction activities, discussed issues related to the project works being developed and share concerns related to technology enhanced learning and their teaching practices. Also during this week, students started to implement the planned activities in their schools with their own students. 

Conclusions and results regarding the implementation of the activities planned during the third and fourth week of MAC (the majority of which extended beyond the time span of the course) suggest that they were enthusiastically embraced by both teachers and students and that they contributed for high levels of motivation and engagement. Activities included for instance:

- The creation of an online "radio station" to support the teaching of History topics
- The use of online games to promote problem solving and critical thinking skills
- An online journal to account for a contest of popular sayings aiming at developing oral and language skills in primary school pupils
- The use of Second Life to discuss Biology topics
- A blog to call the school's community attention about a disease affecting pine trees in the school area, among others

All activities enjoyed the participation and interaction of different students and different teachers from different schools. Results are worth a deeper analysis and they will be the object of a future communication. Links to and detailed information about the activities/projects developed can be found in the final reports available at http://wikimmed.blogs.ca.ua.pt.

For the projects developed in MAC and the implementation of the PDI, students were free to explore and use other tools that best served their purposes. From the inquiry done, we know that students used a wider range of tools, which we present in the following table.

We adopted the case study methodology to allow greater insight of the process and practice that the students were engaged in and to provide an analysis of the students' experiences. Drawing on the characteristics of a case study a range of research methods were used [30] and involved both quantitative and qualitative methods:

1. Direct observation
2. Content analysis from the online interactions
3. Analysis of the participation dynamics 
4. Survey through questionnaire, which was submitted to students 4 months after MAC ended

The questionnaire, which used closed questions and an open one, sought to:
- Characterize the students' professional situation
- Acknowledge students' motivation for the enrolment in the course
- Identify and quantify the use of different tools used during MAC and in the development of the project
- Identify the skills, attitudes and competences developed by students
- Acknowledge the students' perceptions about the course itself and the importance afforded to informal learning in the context of formal education

The closed questions were statistically treated and the open one was subjected to a content analysis. The reason why we chose to submit the questionnaire four months after the conclusion of the course relates to the fact that we wanted students to have the opportunity to reflect upon and internalize attitudes, practices and skills that they may not have been aware of by the time MAC ended, such were the demanding and time consuming project works proposed and developed.

The data collected and presented in this paper refers specifically to the students' perceptions of the course organization and of the use of social networking tools as a means to promote and foster informal learning.

### Tools used and purposes assigned by students in the development and implementation of the PDI

| Tools | Uses |
|-------|-------|
| Email | - to exchange information, files and bibliography among group elements. |
| MSN, GoogleTalk, Skype | - to communicate synchronously<br>- to share and exchange ideas and files<br>-

Here's the cleaned Markdown:

## Findings

From the 56 students enrolled in MAC, 42 (75%) answered the questionnaire; 39 were teachers and only one was not working at the time the questionnaire was submitted. By the time MAC started, all students felt confident in using social networking tools and used them on a regular basis. 50% of the students stated they used social networking tools very often, 24% used them always, another 24% used them sometimes and only 2% referred a rare use of them. The choice of the tools referred to in table 1 was classified as being good by 52% of the students and as being very good by 43%. Only 5% of the students mentioned the choice as being reasonable. The most pointed reason by students for the enrolment in the course was the personal desire to learn more, followed by personal interest and professional perspectives it could imply.

Results found suggest that the use of social networking tools prove successful in the development of skills/attitudes related to the social, professional and technological area; there were 85% of students referring the development of skills/attitudes within the referred areas, 7% referring they did not develop them and 8% opting for a 'no opinion' answer [31].

The following findings are related to a set of statements presented to students. They had to position themselves according to an agreement scale in which SA stood for strongly agree, A for agree, N for neutral, D for disagree and SD for strongly disagree. Statements included aspects about the instructional design applied, the learning model underlying it, the environment created and the impact of the projects developed. Statements presented in Figure 1 are the ones from which the answers to our research questions emerge.

[Figure 1 content omitted - contains statistical data about students' positions on various statements]

On the whole there was an average of 51.3% answers within the agree option and 34.7% within the strongly agree one. These (SA and A) account for 86% of the total options pointed out by students. 12.7% is the average of the neutral answers and 1.3% is the average for disagree answers. There were no strongly disagree answers.

The already mentioned idea that using social networking tools to foster dynamic learning communities seems to be suggested by the findings. Almost 86% (SA plus A answers) of the students sensed a spirit of community in MAC and nearly 93% (SA plus A) felt that the social networking tools chosen for MAC - described in table 1 – fostered a collective able to distribute and build shared knowledge. These findings are also consistent with students' opinions collected in the blogs during the course: "The tree of collective knowledge grows with the sharing among the members of the community"[^1] or "(...) this community seems to have a life of its own enabled by the dynamics of discussing and sharing"[^2].

The notion of a networked community based on a dynamic, open and decentralized structure, in which members feel motivated to participate and share and find ways to [re]build knowledge is consistent with the total percentage of positive answers 95.2% (SA and A) found in the statement referring the openness and flexibility of the learning environment as an incentive for participation and the integration of new and diverse perspectives, i.e. the construction of new ones. However, we found 4.8% of the students disagreeing with this statement, which despite being a relatively low percentage, seems to be incoherent with, for instance, the statement in which it is referred that the distribution of the learning environment and the tools used fostered a collective able to distribute and build shared knowledge, which obtained no disagreeing answers.

There were 50% of students referring to having developed their learning skills and contributed towards other members' learning, while nearly 24% strongly agreed. Also in relation to the participation within the community, circa 67% agree but only 4.8% strongly agree that their participation was valued and that it added value to the community's expertise. Interestingly there is in both statements a percentage of 26.2% students referring a neutral opinion and 2.4% disagreeing

## Bridging Formal and Informal Learning

## Learning Through Interaction

"Learning emerges from interaction and even in a formal context it is possible to create a collective awareness of knowledge seeking based on interaction."

Students were asked to reflect upon learning outcomes that, from an informal point of view, had contributed towards enriching their formal learning. They were also asked about the importance of social web tools in fostering informal spaces and contexts for learning.

Although only 26 out of 42 students answered this question, all responding students recognized informal interactions as a way "to learn without people having that immediate notion". They noted that the dynamics created around the learning environment and informal interactions contradicted the compulsory ones usually associated with institutionalized and "formatted" learning delivery. For this reason, it was easier and more pleasant to achieve "with less consciousness but more clarity" the formal learning objectives outlined for the course.

Students shared the opinion that the social networking tools used to distribute the MAC learning environment, and particularly the freedom to explore and use whichever tools they felt comfortable with, enabled collaborative work to develop more easily and increased motivation. Furthermore, this free control afforded new learning outcomes – "I realized I had been learning alone only by exploring all the tools I came to know during the course", suggesting informal learning is fostered by giving up control rather than tightening it.

## Student Perspectives

The notion of learning as a self-controlled activity and its present-day importance was suggested by one student: "informal interactions are even more valuable than the ones considered formal, because they account for positive consequences as far as motivation and learning outcomes are concerned. Learning derives from almost every informal interaction; if the outcome is considered formal or informal content is a second matter issue. What matters is that learning happens."

Almost every student mentioned the openness of the learning environment based on social web tools as one of the main reasons for their participation and willingness to share knowledge, which they felt contrasted with face-to-face environments. Another student noted feeling more at ease and motivated to engage in interactions because she could "participate at her own pace, without feeling pressured or ashamed and with the possibility to reflect."

Two students referenced the impact of "the pedagogy merged with technology" in diluting traditional hierarchies, as "the social web embodies the absence of formality and annuls the social status and the professional labels." As one student noted: "uno inter pares. (...) Each person can gain presence and importance in the global world and from the interrelations that one establishes or the networks one creates, informal interactions emerge and become as relevant as any others."

## Conclusions

In alignment with other studies, these findings suggest that when merged with new pedagogies and innovative methods – transfer of responsibility to students, autonomous learning, context-situated problem-based learning, intra and inter-group collaborative work – social networking tools support the distribution of learning environments where knowledge building and sharing can emerge informally.

Students' perceptions indicate that informal learning outcomes and interactions fostered by social networking tools helped support formal learning activities.

Despite growing interest in educational uses of the social Web, few studies examine its use in promoting informal learning. Further reflection and evaluation of such learning environments is needed.

The use of social networking tools appears to blur the lines between formal and informal settings, potentially bridging gaps where formal learning falls short. However, the key starting point is changes in pedagogy. The challenge lies in introducing new technologies that reflect current educational models' pedagogical principles.

While formalizing informal practices may negate the benefits of informal learning, understanding how informal tools and processes could support formal learning remains important.

*Acknowledgments: The authors thank the Portuguese Foundation for Science and Technology (FCT) for supporting the study under Contract No. SFRH/BD/41797/2007.*

Here's the cleaned Markdown, preserving the reference list while removing page numbers and normalizing formatting:

## References

1. Gan, Y., Zhu, Z.: A Learning framework for Knowledge Building and Collective Wisdom Advancement in Virtual Learning Communities. Educational Technology and Society 10, 206–226 (2007)

2. Price, S., Rogers, Y.: Let's get physical: the learning benefits of interacting in digitally augmented physical spaces. Computers and Education 43(1-2), 137–151 (2004)

3. Paulus, T.: CMC modes for learning tasks at a distance. Journal of Computer-Mediated Communication 12(4), article 9 (2007)

4. Ducate, L.C., Lomicka, L.L.: Adventures in the Blogosphere: From Blog Readers to Blog Writers. Computer Assisted Language Learning 21, 9–28 (2008)

5. Alexander, B.: Web 2.0: A new wave of innovation for teaching and learning. Educause Review, 33–40 (March/April 2006), http://www.educause.edu/ir/library/pdf/ERM0621.pdf

6. Eraut, M.: Non-formal learning, implicit learning and tacit knowledge. In: Coffield, F. (ed.) The Necessity of Informal Learning. Policy Press, Bristol (2000)

7. Calvani, A., Giovanni, B., Antonio, F., Maria, R.: Towards e-Learning 2.0: New Paths for Informal Learning and Lifelong Learning – an Application with Personal Learning Environments. In: Proceedings of the EDEN Annual Conference 2007, Naples, Italy (2007)

8. Pettenati, M., Ranieri, M.: Informal Learning Theories to Support Knowledge Management in Distributed CoPs. In: Tomadaki, E., Scott, P. (eds.) Innovative Approaches for Learning and Knowledge Sharing, EC-TEL 2006 Workshops Proceedings, pp. 345–355 (2006)

9. Sefton-Green, J.: Literature Review in Informal Learning with Technology outside School, NESTA Futurelab Report No. 7 (2004), http://www.futurelab.org.uk/research/reviews/07_01.htm

10. Livingstone, D.: Exploring the Icebergs of Adult Learning: Findings of the First Canadian Survey of Informal Learning Practices. Ontario Institute for Studies in Education. University of Toronto, Toronto (2000)

11. Marsick, V., Watkins, K.: Informal and Incident Learning. New Directions for Adult and Continuing Education 89, 25–34 (2001)

12. Iadecola, G., Piave, N.: Evaluating Informal Learning in a Virtual Context. Paper presented at the fourth International Scientific Conference, eLSE, Bucharest (2008), http://adl.unap.ro/else/papers/085.-794.1.%20Iadecola%20e%20Piave%20-%20Evaluating%20informal.pdf

13. Selwyn, N.: Web 2.0 Applications as alternative Environments for Informal Learning - a Critical Review. Paper presented at the OECD-KERIS expert meeting. Cheju Island, North Korea (2007)

14. Tough, A.: The adult's learning projects, 2nd edn. Ontario Institute for Studies in Education, Toronto (1979)

15. Schugurensky, D.: The forms of informal learning: Towards a conceptualization of the field, NALL Working Paper 19 (2000)

16. Downes, S.: E-Learning 2.0. eLearn Magazine, 10 (2005)

17. Cross, J.: Informal Learning: Redisc

Here's the cleaned Markdown:

## How to Get Proper Profiles? A Psychological Perspective on Social Networking Sites

Katrin Wodzicki, Eva Schwämmlein, and Ulrike Cress

Knowledge Media Research Center, Konrad-Adenauer-Str. 40,
72072 Tübingen, Germany
{k.wodzicki,e.schwaemmlein,u.cress}@iwm-kmrc.de

## Abstract

Research on transactive memory systems has shown the importance of knowledge about who knows what. Going beyond the issue of work group settings, the article underlines the importance of such knowledge for finding one's way through today's knowledge society. We discuss how social networking sites can be used to manage individual knowledge networks. Therefore, we describe characteristics of social networking sites resulting in the conclusion that user profiles serve as a base for an external transactive memory system. Furthermore, we discuss guiding propositions for self-presentation in user profiles that could promote the establishment of an useful external transactive memory system.

**Keywords**: social networking, transactive memory, profiles.

## 1 Introduction

People are important knowledge resources, for example, underlined in research on transactive memory systems (TMS). Social networking sites (SNS) provide new opportunities to establish and maintain access to people from different domains of expertise and to use them as knowledge resources. These new possibilities may also be utilized for processes of formal and informal learning. In this paper, we will demonstrate how user profiles on SNS can be used as base for an external TMS, and propose ways to guide self-presentation in user profiles.

## 2 Applying Transactive Memory Systems to Social Networking Sites

### 2.1 Transactive Memory Systems (TMS)

The psychological theory of transactive memory [1] makes clear that not only individuals have an individual memory system, but that groups also develop a group memory, referred to as a transactive memory system. A transactive memory system is defined as a specialized division of labor that develops with respect to encoding, storage, and retrieval of knowledge from different domains [2]. As we know from research on TMS, people not only have knowledge about specific domains, but also about external knowledge resources. These external knowledge resources may be external storage media (e.g., books or digital resources), but also other people.

Work groups often distribute domains of expertise among their members. This specialization can be formally assigned or informally evolves over time by interaction and negotiation between members [2]. Consequently, incoming information is subject to transactive encoding and storage, guided by the group members' responsibility for a specific domain of expertise. Transactive retrieval is based on knowledge about what items of information are needed (i.e., label) and where they can be found (i.e., location) [1]. The development of a well working transactive memory takes time for learning the others' expertise, and is supported by interdependence between group members and an incentive structure that rewards specialization [3]. Individuals gain from being part of a smoothly functioning transactive memory in several ways: First of all, a transactive memory reduces an individual's cognitive load, because that person will not need to learn every detail of a knowledge domain. It is sufficient to know who knows what and who has to be consulted to obtain further information. Second, a transactive memory results in successful attainment of group goals which is satisfying for the individual as well. Third, a transactive memory dramatically expands an individual's expertise. Finally, it provides the opportunity to specialize in a specific domain of knowledge [1].

Previous research on transactive memory systems has mainly concentrated on couples [4], interdependent small group situations [3], or organizations [5]. But beyond that, it becomes more and more important to have elaborated networks of people from different professional domains on which to draw on demand. SNS support the establishment and maintenance of such networks. This is possibly one of the reasons why they are so popular. The theory of TMS might also apply in the context of such broader networks, and may be useful to define optimal conditions under which user profiles in SNS can function as an external TMS.

## How to Get Proper Profiles? A Psychological Perspective on SNS

## Common-Bond vs Common-Identity Groups

Common-bond groups are characterized by interpersonal attraction between members, while common-identity groups are based on members' identification with the group's purpose or common goal. The affective attachment to these groups is based on the attraction of the group itself. Such groups are very stable over time, because the coming and going of other members do not carry weight. Moreover, these groups mostly develop strong group norms which might be supportive for cooperation and exchange.

Applied to SNS, a site might be characterized as a common-bond group if its users are strongly connected with each other (e.g., Facebook.com). It would be characterized as common-identity group if it is addressed to a specific target group or aims at attaining a common goal (e.g., Researchgate.net). When considering existing SNS, it is obvious that common bonds between its members are always relevant to some degree – this is inherent in supporting networking. Thus, they cannot easily be categorized as either of the two groups; they rather mix some features of both [9].

Common identities, however, are not always relevant in this context. But when considering the consequences of the different attachments to groups, it becomes obvious that establishing a common identity or a common goal enhances the stability of group as well as the orientation on common norms and common interests. Accordingly, for promoting information exchange and learning with the help of SNS, it might be advantageous to do so, too. The common identity or common goal might be given by focussing on a specific target group or specific topic of interest. However, operating such an SNS is a real challenge, because establishing a common identity is most successful if information provided about SNS users concentrates on identity-related items. But users are also interested in establishing common bonds which is promoted by providing personal information. So, operators of SNS will need to control the information provided by users, bearing in mind its relevance to the community and the common goal.

## Profiles within SNS as External TMS

Through their profiles, users provide personal and contact information as well as information about their professional background or private concerns. Depending on the type of SNS, the amount of different kinds of information varies. Profiles of other users within a SNS (or, under restricted access, other users' profiles of established contacts) can be considered as an external TMS. Then, the processes of transactive encoding, storage and retrieval are also relevant, but might differ from previously investigated settings.

Transactive encoding and storage in SNS is different from transactive encoding and storage in previously considered contexts. SNS usually have a large number of users. On the one hand, this is an advantage, because more than one individual can be responsible for one domain of expertise. Such a distribution of responsibilities eliminates the risk that knowledge gets lost for the collective when one user leaves the group. On the other hand, in contrast to work groups or organizations with clear-cut boundaries and - in most cases - interdependencies between group members, users within a SNS are rather independent from each other. The larger the size of a SNS is the less clearly defined are the responsibilities of single members. To face this problem, a narrow scope and a common goal can help to establish interdependencies among the users, to allocate responsibilities between them, and to promote cooperation and exchange by group norms.

Because of the large number of users, optimizing processes of transactive encoding and storage might not be so central on SNS. However, optimizing processes of transactive retrieval in SNS is even more important: In general, members of a group or organization have to learn the location and the label of an item of information (who knows what). In SNS, knowledge about location is no longer necessary, because each user is represented with a profile. Consequently, the label is really important: Only if users agree on labels for relevant fields of expertise and use these labels to describe their own expertise within their profiles, searching for locations (i.e., people) with the help of these labels will be successful.

SNS then substitute personal experience and conversation between members to some degree: Users will not need to

Here's the cleaned Markdown:

## Recommendations based on Profile Entries

Moreover, providing recommendations of possible interesting information owners or experts within SNS can encourage members to provide useful profile information in order to get these recommendations. These recommendations can be based on different types of profile entries: Concerning some types of profile entries, similarities between information seekers and owners are important and, consequently, information seekers should get recommendations about information owners with similar entries. In other cases, differences between information seekers and owners are important and, consequently, information seekers should get recommendations about information owners with different entries. For example, if information seekers try to obtain information that is specific to an organization, they will try to find users from the same organization. But if they look for cooperation partners, they will rather search for users from other organizations whose profiles match on the item of cooperation. Because users differ in information they are seeking for, SNS operators could leave the decision about the kinds of recommendations up to the users themselves. Technically this could be implemented by providing an individual recommendation page on which each user can select from a list of possible recommendations.

## Conclusion

The paper applies the theory of TMS to the context of SNS. SNS profiles can function as external TMS, if some preconditions are met. The most important one is a common labeling for relevant domains of expertise. Only if generally accepted labels are used, the search for relevant information owners can be successful. Then, users will no longer need to know the location of information (i.e., who knows), but can effectively search using these labels. However, the usage of common labels has to be supported. Therefore, two of different guiding mechanisms are proposed. However, research is needed on how different guiding mechanisms affect self-presentation. Such research would give the basis for deducing additional guiding propositions that could further support self-presentation, information exchange and learning.

## References

1. Wegner, D.M.: Transactive memory: A Contemporary Analysis of the Group Mind. In: Mullen, B., Goethals, G.R. (eds.) Theories of Group Behavior, pp. 185–208. Springer, New York (1986)
2. Hollingshead, A.B., Fulk, J., Monge, P.: Fostering Intranet Knowledge Sharing: An Integration of Transactive Memory and Public Goods Approaches. In: Hinds, P., Kiesler, S. (eds.) Distributed work, pp. 335–355. MIT Press, Cambridge (2002)
3. Hollingshead, A.B.: Communication, Learning and Retrival in Transactive Memory systems. Journal of Experimental Social Psychology 34, 423–442
4. Wegner, D.M., Erber, R., Raymond, P.: Transactive Memory in Close Relationships. Journal of Personality and Social Psychology 61, 923–929 (1991)
5. Brandon, D.P., Hollingshead, A.B.: Transactive Memory Systems in Organizations: Matching Tasks, Expertise, and People. Organization Science 15, 633–644 (2004)
6. Boyd, D.M., Ellison, N.B.: Social Network Sites: Definition, History, and Scholarship. Journal of Computer-Mediated Communication 13(1), article 11 (2007), http://jcmc.indiana.edu/vol13/issue1/boyd.ellison.html
7. Prentice, D.A., Miller, D.T., Lightdale, J.R.: Personality and Social. Psychology Bulletin 20, 484–493 (1994)
8. Ren, Y., Kraut, R., Kiesler, S.: Applying Common Identity and Bond Theory to Design of Online Communities. Organization Studies 28, 377–408 (2007)
9. Sassenberg, K.: Soziale Bindungen von Usern an Web 2.0-Angebote. In: Hass, B.H., Walsh

Here's the cleaned and normalized Markdown:

## Collaborative Learning in Virtual Classroom Scenarios

**Authors:** Katrin Allmendinger¹, Fabian Kempf², and Karin Hamann³

¹acontrain, Koberleweg 8, 78464 Konstanz, Germany  
²vitero GmbH, Nobelstr. 15, 70569 Stuttgart, Germany  
³Fraunhofer IAO, Nobelstr. 12, 70569 Stuttgart, Germany

## Abstract

Possibilities are described to affect the feeling of social presence and group awareness in desktop collaborative virtual environments, also known as virtual classrooms. Social presence is the feeling of being present with another person in a virtual environment. Awareness information of the activities of other group members serves as a background for one's own activities. In general, virtual classrooms allow various kinds of verbal and nonverbal communication between tutors and learners. The communication channels can be adapted according to the needs of the users in a specific collaborative learning situation. The article provides an overview of the representation of users (avatars) and the available communication channels in virtual classrooms. In particular, the possibility of conveying nonverbal information is addressed as it has the potential to affect the feeling of social presence and group awareness in learning situations.

**Keywords:** nonverbal signal, avatar, social presence, group awareness, collaborative virtual environments, virtual classroom.

## 1. Introduction

The concept of learning as an interactive and collaborative process has gained attention within the last years [1]. Learning as a fundamentally social phenomenon is also perceived in the domain of computer-supported learning, especially in the growing research area of computer-supported collaborative learning.

Computer-supported collaborative learning scenarios offer many opportunities, for instance by overcoming specific barriers of place and time. But they also lead to new challenges: Learners and tutors have to construct "meaning" mutually, structure social interaction and establish and maintain motivation in learning situations [2]. This article deals with possibilities of overcoming the "structure barrier" and the "motivation barrier" in synchronous computer-supported collaborative learning scenarios, also known as real time, virtual classroom or online learning scenarios.

The term "social affordances" was coined for social-contextual facilitators relevant for social interaction [3]. These facilitators aim at overcoming specific aspects of the "structure barrier" and the "motivation barrier" by various communication media accompanied by awareness information that help users to feel present in a virtual environment with other users. This article describes possibilities to influence the feeling of social presence and group awareness in virtual classrooms. We especially focus on the possibility to convey nonverbal information since it is often reported as being connected to the feeling of social presence and group awareness (e.g., [4], [5]).

## 2. Avatars and Communication Channels in Virtual Classrooms

Virtual classrooms can be defined as computer-based environments that provide the possibility to synchronously communicate, collaborate and learn in a computer-mediated context with other users. Virtual classrooms can include multiple communication channels (e.g., text, audio, nonverbal signals) and external representations (e.g., shared software applications). Users are represented in virtual classrooms as virtual images, also called avatars. In learning situations, humanoid avatars are often used (e.g., [6], [7]).

In synchronous computer-mediated contexts verbal signs can be sent via text chat and audio channel. Using keyboard symbols to display facial expressions or emotional states ("emoticons") and using text (e.g., bold letters, exclamation marks) to display intonation make it possible to give additional nonverbal background information to text chat contributions (e.g., [7], [8]).

As already mentioned, social interaction in computer-supported collaborative learning situations needs structure. Such structure can be provided, for example, by adapting the technology used according to the needs of the learning situation. The following section will provide an overview of aspects that can be adapted prior to or, circumstances permitting, during a synchronous learning session in a virtual classroom. For this purpose, we will focus on a particular virtual classroom, the virtual team room (vitero)

## Collaborative Learning in Virtual Classroom Scenarios

## Virtual Team Room

The users are represented by avatars based on uploaded digital photos, but the tutor can also permit the use of video avatars in vitero. In this case, the users sit in front of their respective webcam and their video image is displayed at their virtual chair. One factor influencing the tutor's and learner's decision regarding video avatars is the perceived requirement of achieving a certain level of social presence within the learning setting.

## Social Presence and Group Awareness

Social presence was originally defined as a quality of the communications medium representing the capacity to transmit nonverbal information [9]. The representation of users plays an important role in achieving a feeling of social presence: "At a very basic level, bodies root us and make us present, to ourselves and to others" ([10], p. 41). In general, the main functions of avatars in virtual environments are identification (e.g., who is tutor, who is learner) and interaction support ([6], [11]). To ensure an easy identification in learning contexts, avatars resembling the user and name tags displayed near the avatars are often used (e.g., [6], [7]). Concerning interaction support, two components can be distinguished: avatars give us cues for perceiving the actions of other users and they facilitate communication. Being aware of the activities of others, and thus having "group awareness," serves as a background for own activities [12].

## Nonverbal Signs and Their Influence on Social Presence

The evaluation studies were conducted in preliminary versions of the already-introduced vitero system. These communication modes were available: audio channel, text chat, and nonverbal signs ("thumb up", "thumb down", "hand raising", "applause", "question mark" for signalling to have a question or general bewilderment, "wave hello", as well as a virtual microphone and participants' arrows to refer to, e.g., information on the slides). All the nonverbal signs required conscious use. User studies had revealed them as the most relevant signs for collaborative situations.

Our first study is based on the communication data of five groups with two to five employees [13]. Altogether, 19 people participated and filled out a questionnaire after their learning sessions. On average 0.32 nonverbal signs per minute were displayed by user's avatar. The "thumb up" sign as well as the arrows were used most often. The questionnaire data show that the participants liked the sessions and felt that they were able to communicate successfully in the virtual environment.

Our second evaluative study was conducted during a seminar, with 21 university students participating in at least 4 of 6 vitero sessions [14]. In a randomly chosen session objective communication data were observed on the basis of logfiles: 1.28 text chat contributions were made by the group per minute and 5.96 nonverbal signs per minute were displayed within the course of the session (the number is similar to the first evaluation study, where the score is mentioned per individual). In particular, the signs "thumb up" (2.63 signs per minute), "applause" (2.50 signs per minute) and "thumb down" (0.60 signs per minute) were used often. The questionnaire data show that the students liked the sessions in general (M = 6.1, scale from 1 "absolutely not" to 7 "very good"). They said that the text chat (M = 6.1, scale from 1 "absolutely not" to 7 "very much") as well as the nonverbal signs (M = 6.1, same scale) contributed to convenient communication. The signs for "thumb up" (M = 6.8), "thumb down" (M = 6.7) and "hand raising" (M = 6.0, scale from 1 "very unimportant" to 7 "very important") were in particular rated as important. The students and the lecturer were represented in the desktop virtual environment by photo avatars. They indicated approval of the sensibility of using avatars for representation

Here's the cleaned and normalized Markdown:

The text appears to be part of a larger academic paper. I'll format it maintaining the apparent section structure:

## Discussion

In general, it is evident, that user representation and choice of communication channels depend highly on the envisioned collaborative learning situation (e.g., number of learners, computer literacy of the learners etc.). The empirical studies show that relatively basic avatars, for example, photo avatars, can contribute to favourable perceptions of a virtual setting [14]. This is in line with other studies (e.g., robotic heads displaying gender and name had the same affect [16]).

The assessment of subjective measures has practical significance, because acceptance of a virtual classroom and positive interaction experiences are basic preconditions influencing how learning takes place. Moreover, emotional and motivational aspects are highly connected to successful learning. Future research attempts are necessary to fully understand what level of user representation is needed for specific types of learning situations and how user representation influences learning outcomes and processes as well as subjective variables. Another open question remains concerning the trade-off between enriching avatar communication and reducing the cognitive capacity necessary for sending and receiving signals from multiple channels. Future research will have to show which amount of enrichment in synchronous virtual settings is feasible for the users as well as positive for social presence and group awareness.

## References

1. Gulz, A., Haake, M.: Design of animated pedagogical agents – A look at their look. International Journal of Human-Computer Studies 64, 322–339 (2006)
2. Bromme, R., Hesse, F.W., Spada, H.: Barriers, biases and opportunities of communication and cooperation with computers: Introduction and overview. In: Bromme, R., Hesse, F.W., Spada, H. (eds.) Barriers and biases in computer-mediated knowledge communication, pp. 1–14. Springer, New York (2005)
3. Kirschner, P.A., Kreijns, K.: Enhancing sociability of computer-supported collaborative learning environments. In: Bromme, R., Hesse, F.W., Spada, H. (eds.) Barriers and biases in computer-mediated knowledge communication, pp. 169–191. Springer, New York (2005)
4. Hesse, F.W., Garsoffky, B., Hron, A.: Interface-Design für computerunterstütztes kooperatives Lernen [Interface design for computer-supported collaborative learning]. In: Issing, L.J., Klimsa, P. (eds.) Information und Lernen mit Multimedia, pp. 252–267. Psychologie Verlags Union, Weinheim (1995)
5. Schweizer, K., Paechter, M., Weidenmann, B.: Sozial wahrnehmbare Merkmale von Agenten in virtuellen Lernumgebungen aus Rezipientensicht [Socially perceivable features of agents in virtual environments from the recipient's perspective]. Künstliche Intelligenz 2, 22–27 (2000)
6. Allmendinger, K.: Passung von Medium und Aufgabentyp: Der Einfluss nonverbaler Signale in desktop-basierten kollaborativen virtuellen Umgebungen [Fit between medium and task type: The influence of nonverbal signals in desktop-based collaborative virtual environments] (2005), http://w210.ub.uni-tuebingen.de/dbt/volltexte/2005/1658
7. Peterson, M.: Learner interaction management in an avatar and chat-based virtual world. Computer Assisted Language Learning 19(1), 79–103 (2006)
8. Walther, J.B., Tidwell, L.C.: Nonverbal cues in computer-mediated communication, and the effect of chronemics on relational communication

## Review of Learning in Online Networks and Communities

Kirsti Ala-Mutka*, Yves Punie, and Anusca Ferrari

Institute for Prospective Technological Studies (IPTS),  
European Commission, Joint Research Centre,  
Edificio Expo, C/Inca Garcilaso 3,  
41092 Seville, Spain  
{Kirsti.Ala-Mutka,Yves.Punie,Anusca.Ferrari}@ec.europa.eu

*The views expressed in this article are the sole responsibility of the authors and do not necessarily reflect the views of the European Commission.

## Abstract

This paper reports on a review of learning opportunities that are emerging in online networks and communities. Participation in these new virtual spaces is not mandatory, but rather motivated by an interest to know, share, create, connect and find support, and these activities lead to a range of learning outcomes. New technologies offer the tools and means for people to participate in online networks and communities in a personally meaningful way. However, not all individuals are necessarily equipped with the skills or knowledge to benefit from these opportunities for their lifelong learning. It is suggested that educational institutions should find ways to connect with and get inspiration from these new learning approaches and settings in order to bring about their own transformation for the 21st century, and also to support competence-building for new jobs and personal development with a learner-centred and lifelong perspective.

**Keywords**: Online Communities, Learning Networks, Lifelong Learning, Social Computing, Key Competences, Informal Learning.

## 1 Introduction

Lifelong learning plays a crucial role in contemporary society where jobs and required skills are changing [1], [2], [3]. Cedefop [4] forecasts that the qualification structure of jobs in Europe will change significantly by 2020 and that the new generation entering the labour market will not be able to fulfil all the demands for qualified employees. New ways to support, value and acknowledge learning are therefore needed in order to provide high-quality learning opportunities for all, and foster skills for innovation and lifelong learning.

At the same time, there is an increase in the use of social computing applications, which provide new platforms where people can connect, share and create together. Already two-thirds of the world's Internet population visit social networking or blogging sites [5]. A great variety of different collaborative initiatives exists and more are continuously emerging and being used for work, leisure, learning, and civic activities [6]. Furthermore, online networking and collaboration not only attract young people, but also workers and older people [5], [7].

The Institute for Prospective Technological Studies (IPTS) launched a project in collaboration with DG Education and Culture of the European Commission to study the innovative approaches to learning that are emerging in the various new ICT-enabled online spaces and communities. The main research questions of the study are: what contributes to the emergence and success of learning in ICT-enabled communities, and how can they promote quality and innovation for lifelong learning and education systems in Europe? The study combines desk research, literature review, case studies and expert consultations. This paper elaborates on the results of the literature and online resource review, focusing on how learning opportunities are emerging in these online settings.

The paper is structured as follows. After the introduction, Section 2 reviews theoretical perspectives for considering and discussing informal learning in online collaborative settings. Section 3 gives an overview of different types of online networks and communities, approaching them through the drivers for participation in them. Section 4 discusses how learning in these settings is emerging in different ways from traditional classroom education, and Section 5 raises challenges for learning through informal collaboration. Finally, Section 6 concludes the paper by pointing out messages for educational institutions from these emerging learning settings.

## 2 Relevant Theories and Concepts

Learning in communities and technology mediated learning are not new phenomena. The current novelty is the variety of new learning opportunities which are now becoming available. The new learning environments are no longer restricted by physical distances and the traditional ways of connecting with and getting to know people. This section reminds the reader about the new ways in which

## Review of Learning in Online Networks and Communities

## Learning Theories and Social Context

In networked learning literature, learning is seen as a social activity that takes place through a social process of knowledge construction, highlighting the importance of discussion, the creation of shared meanings and opportunities for reflection with others [11]. Each learner has a 'zone of proximal development' (ZPD) describing knowledge that can be learned with the guidance of an expert [12], and shared cultural artefacts and language are important mediators of the process. Externalizing ideas is essential for communicating with others as it is possible to negotiate meaning only through tangible forms [13]. Bandura [14] emphasizes the importance of observing and modelling the behaviors, attitudes, and emotional reactions of others. People do not need to learn everything by trying it out themselves, they can learn from observing others.

Situated learning literature [15] emphasizes that learning occurs in a function of the activity, context and culture. Learning is not necessarily deliberate but it can happen in unintentional ways. Participation itself can be seen as a process of appropriation and transformation, with social and cultural aspects of learning [16]. Learners participate in a wide variety of joint activities which provide the opportunity for synthesizing several influences into the learner's modes of understanding and participation. By internalizing the effects of working together, the novice acquires useful strategies and crucial knowledge [17].

In informal settings, the responsibility of learning often falls on the shoulders of the learner, emphasizing the need for specific personal skills. Self-regulated learning is guided by metacognition (thinking about one's thinking), strategic action (planning, monitoring, and evaluating personal progress against a standard), and motivation to learn [18]. It is important to take into account learners' personal goals, which play an important role in learning and may conflict with the goals imposed from outside [19]. Strong individual interests can even help to overcome low ability and/or perceptual disabilities [20]. However, a certain level of understanding of the topic is needed for developing further interest and curiosity in it.

## Approaching Learning in Online Networks

The availability of ICT and internet gives new opportunities for finding, forming, managing and participating in networks and communities with members from different locations and with diverse characteristics. Siemens [21] argued that the traditional learning theories were developed in a time when learning was not impacted by technology. According to him, the network itself is the basis of the learning processes. As the knowledge society requires the individual to continuously update his knowledge, this cannot happen as a process of progressive "knowledge accumulation", but through building, maintaining and utilizing connections.

Community of Inquiry (COI) is a framework developed for modelling online collaborative learning processes based on Dewey's problem-based learning cycle [22]. The framework consists of three elements – social, cognitive and teaching presence. Evidence shows the importance of all the elements and that care needs to be taken to encourage social interaction and to provide structure and support early on [22]. Although socio-emotional communication is an important aspect of learning, it is not enough for educational purposes, as reflective discussions are needed to develop towards real inquiry.

Another relevant framework for approaching online collaboration and work is the activity theory, which provides a means to study actions and interactions with artefacts within a historical and cultural context [23]. Activity systems are composed of actors, community and objects, which through labour division, rules and mediating artefacts (instruments) engage in a transformation process. Analysing the elements and the relationships between them aids the understanding and development of the overall activity system.

## Emerging Online Networks and Communities

Information and Communication Technologies (ICT), and especially social computing (SC) applications, have brought with them a large number of networking opportunities and collaborative initiatives, with both looser and tighter relationships between network members. Preece [24] defines an online community as a place where:
- people interact socially
- people have a shared purpose that provides a reason for the community to exist
- there are policies for interactions
- there are mediating computer systems

Collective activities also follow on from individual intentions [25]. In these cases, there is not necessarily an overall 'sense of togeth

## Review of Learning in Online Networks and Communities

## Drivers for Participation

Based on literature review and surveys on online networks, platforms and communities, there are three major drivers for participation in online networks and communities:
1. A common interest
2. A common task or production
3. A social connection

Furthermore, some online communities are driven by an organizational setup (educational institution, workplace, associations), while others connect and invite members horizontally in an open manner.

## A Common Interest

Topic-driven participation gathers together people who have a common knowledge or interest in sharing and learning from each other's experiences. Sometimes, they also share a common background. For example, communities relating to specific professions or tools provide interaction and collaboration platforms for professionals within and between different organizations, and for novices learning about these issues. In addition to job-related interests, various communities have formed around topics like personal well-being, health, culture, leisure and also specific learning interests, such as LiveMocha (www.livemocha.com) for social language learning.

Participation in these communities is motivated by the desire to connect with others in a similar situation, and to receive and give support and knowledge. In professional communities not only novices learn new skills and concepts, but also experts, who learn new aspects of their work and develop their professional identities through interaction with each other [27]. Participation in a professional community can provide opportunities to learn situated and current knowledge, to make more informed decisions about professional practices and to keep abreast of the latest changes in their specialty areas [28]. In the personal sphere, health-related communities, such as TuDiabetes (www.tudiabetes.com) can help people to learn about managing their health condition with targeted and on-demand support.

## A Common Task or Production

Some communities have an explicit goal or production activity to which community participants jointly contribute, although participants with only a spectator function are also accepted. In these communities, situated and social learning results when interaction tools link members working on a joint task, and serve as a means of negotiation for creating and building the collaborative product or resource. For example, Wikipedia and open source software development gather people together around a larger production goal and allow task-specific communities to form.[^1]

The motivation to participate in production-driven activities can be both intrinsic (usefulness of the product, enjoyment in accomplishing tasks) or extrinsic (participation is part of, or supports, work tasks). In these communities, the members learn the skills needed for the joint activity and also the negotiation and collaboration skills necessary to be a part of the productive community. Furthermore, in this social context they can learn from the experts involved in the collective production by observing their practices and getting feedback and comments on their own work. In open source software communities, the main reasons for contributing are participation in an intellectually stimulating project (44.9%) and improvement of one's own programming skills (41.8%) [29].

## Social Connection

New tools, technologies and the internet allow people from different places to gather online in order to interact asynchronously and in real-time with each other. Socially-oriented participation in communities arises from people's need to express themselves and to connect with others, in ways not always related to certain work objectives, topics or joint contexts. Platforms for media sharing, social networking, gaming communities and the blogosphere allow people to pursue their personal goals as well as support the formation of groups and communities around common interests.

Research shows that the motivation for using social media is often linked to expressing oneself, having fun, achieving fame through one's creations, or sharing knowledge [6], [30]. Young users appreciate social networking and media especially because 'it is fun', and 'friends do so', whereas for the 50+ year-old users, the most common motivations were 'it is useful', and 'to be part of community' [31]. Social computing empowers users to develop and share their knowledge with others and for the benefit of others. For example, blog writers are more active when they receive feedback and sometimes even spend more time responding to comments than on writing the blog posts [25].

## Closed and Open Communities

Many online platforms are established by organisations

## Review of Learning in Online Networks and Communities

## Learning in Online Networks and Communities

The literature and data reviewed show that the motivations for participation in informal online networking and collaboration are not dominated by an explicit desire to learn, although examples of work- and profession-related communities show this motivation as well [27], [29]. However, the literature suggests that people are learning a variety of topics and skills in these settings. Online networks and communities often support learning and meaning-making processes in ways which differ from traditional instructional approaches. Connecting with others and participating in online networks provide important emotional and cognitive support for learning, not only replacing face-to-face interaction or enhancing access to information resources but also increasing effectiveness and allowing personalisation of learning.

Online networking and collaboration can facilitate learning related to all the key competences for lifelong learning[^1] [35]. These new collaborative approaches can also promote several transversal skills, such as collaboration and critical thinking, which are important elements of lifelong learning competences. In addition to topic-specific and transversal competences, participation in a community enables members to learn how to be a part of it, which entails various skills and knowledge relating to the values, practices and attitudes developed in the community, thus contributing to one's own identity as a practitioner and a person.

ICT is crucial for online networks and communities, as it allows them to form and provides specific affordances for learning by enabling new ways of encouraging reflection, experimentation, and creativity. It supports a social experience which is different from face-to-face settings, and provides tools for personalising learning paths and knowledge management. Furthermore, ICT provides new ways of gathering and tracking explicit and implicit knowledge which comes from online interactions and activities.

## New Ways and Skills to Learn

ICT and, in particular, social computing tools allow easy creation and sharing of a variety of media materials, which develop personal creativity and give the learner a sense of ownership and responsibility with regards to learning. Multimedia opportunities and the diverse availability of resources and connections can help individuals use their imagination, make new connections, draft and explore ideas and creations [36], thereby personalising the inquiry and discovery processes. Creating and sharing photos, videos or podcasts, or writing a blog, enable users to practice skills such as using one's mother tongue, or a foreign language, and writing and media production, through creating and discussing with others. Blogs and community profiles are also tools for building professional identities and for showing skills and competences acquired via individual learning paths.

Blogs, wikis and online writing can also enable one to learn important transversal competences such as critical and reflective thinking, active participation, and metacognition [37], [38]. Participating in a global community with members from different cultures allows the participant to learn and to become aware of cultural expressions and differences. Furthermore, evidence shows that certain virtual environments, like the blogosphere, enhance the ability to participate in social and civic activities. 61% of blog writers want, to a greater or lesser extent, to motivate people to take action [30], and on average two in ten people have been spurred into action as a result of reading a blog [39].

Online profiles and identities provide young people with a new tool for identity exploration and development [40]. Young people use social networking sites in the micro-management of their social lives, as an arena for social exploration and to develop social networking skills [41]. Sharing stories enables learning through narratives situated in different contexts, providing new sources for reflection. For example, 52% of teenagers surveyed said that they had thought about moral issues during social online gaming [42]. Adults too find learning opportunities online, as even 62% of the adults participating in online social networking reported learning related activities, such as reflection, sustaining social bonding, acquiring specific knowledge, and cultivating a constructive life [43].

## Different Social Contexts for Learning

Social computing tools enable collaboration with large scale and reach, allowing experts and novices to connect, discuss and work together. Online communities of practice empower the practitioners to communicate and share knowledge, and let novices learn from their expertise. Furthermore, global communities make it possible to quickly connect with someone to ask for advice.[^2] 75% of the IT professionals who are using IT

Here's the cleaned Markdown:

## New Ways to Access and Structure Learning

New availability of a broad range of multimedia resources enables learning that is based on inquiry and exploration, where users are free to select the resources, communities and activities that match their interests and learning styles. Following a broad diversity of online networks and weak ties provides exposure to new information, opinions, and ideas different from our own, and new approaches to problem-solving [46]. Availability and participation in the various networking opportunities also supports developing personal knowledge management and skills for further learning. Students are already appropriating networked technologies in multiple ways to support their personal and school-related needs [47].

Communities with established policies aid newcomers to learn to participate according to the norms and objectives of the community. For example, Wikipedia provides a context where, through the guidance and comments by more experienced members, newcomers learn about quality requirements for contributions, negotiation and collaboration. New contributors may then become committed wikipedians themselves, taking responsibility for the initiative as a whole [49]. Learning and skills obtained are recognized by the community, and can lead to more responsibilities and a 'higher' position, which is acquired through the contributions and not by official external certificates. This is happening, for instance, in the Englishforums community (www.englishforums.com), where there are hundreds of 'trusted users', i.e. regular users who have taken on more responsibility for answering questions posted on the site [45].

In addition to active productive participation, users also learn by observing and following the experts and activities in the communities [50], [51]. Although often the majority of community members are 'lurkers', studies show examples where actually around 40% of community members were 'active lurkers', who did not contribute to discussions, but were propagating and transferring knowledge developed in the community [52]. Furthermore, freedom to participate through observing is an important route to active participation [28].

## Challenges

Major barriers for learning in online social environments relate to a series of prerequisites, i.e. access, interest, previous knowledge, skills and awareness of the new learning opportunities (see Fig. 1). Not all individuals have the necessary skills for self-regulated learning, and they need support and structure. The internet is creating new opportunities to become informed, to raise issues for discussion, to connect and learn; it is thus important that everyone gets a chance to develop the capability to participate in communities and benefit from the information, resources and connections available. Furthermore, in order to encourage and to nurture lifelong learners, educational institutions themselves should be able to transform and develop their practices, taking into account these new opportunities for learning.

### Access and Skills for Digital Participation

Access to ICT and internet is still a concrete barrier for many in European society. According to 2008 Eurostat surveys, 62% of the EU27 population on average had accessed the internet in the previous three months [53]. However, there are large differences between and within countries, especially in rural and poor areas, where internet penetration can be low. As a lot of internet content exists only in the English language, this may hinder participation for people with other native languages and/or low English proficiency. Furthermore, there are different social groups at risk of exclusion, such as older people, the less educated or the unemployed. In 2008 in the EU27, 63% of 55-74 year olds surveyed had never used internet as opposed to only 7% of 16-24 year olds. The level of education also has a strong impact. The percentage of people with no internet experience was 33% for the total population aged 16-74, but only 8% for the highly educated and 55% for those with low or no education [53].

Effective participation and learning in online communities requires that users acquire advanced digital competence with critical evaluation skills in producing and using resources and collaborating with others. These advanced digital skills do not result automatically from basic ICT usage skills [54]. Critical skills are required to ensure awareness of unaccountable quality of content, privacy and security aspects, and respect for intellectual property rights. User-generated content that has not gone through traditional quality checks may reflect ill-informe

Here's the cleaned and normalized Markdown:

## Review of Learning in Online Networks and Communities

### Communities and Knowledge Construction Risks

Communities run the risk of becoming static, as knowledge that supports the identity and current practices of its members is likely to be adopted more readily than knowledge that challenges current identity and practice [62]. Online community studies often bring up the need for moderating discussions in order to facilitate knowledge construction [63], [64]. Evaluating and ensuring the quality of a community as a place for learning is difficult, and in the longer term, the communities might need dedicated facilitators to maintain the knowledge construction.

Studies show those benefiting most from online collaborative activities are the ones who already have previous knowledge and skills on the topic [65] [66]. Furthermore, a lot of what happens in the offline world cannot be learned or expressed through online interaction. Therefore, it is important to study further which types of learning are well supported in networked online environments, and which skills should be ensured for enabling people to benefit from these opportunities. Overall, there is need for more research on how to nurture communities in order to enable them to renew their content and structure and to develop effective models for guiding newcomers, encouraging observers to become active members and existing members to engage as bottom-up leaders.

### Implications for Education and Training

It is clear that online networking is becoming an important part of the activities related to work, leisure, learning and citizenship in the knowledge society. Educational institutions need to prepare people for taking part in these activities, and focus on the skills that are needed for lifelong learning. Students should be encouraged to participate in relevant communities during their studies, and, furthermore, educational institutions should aim to develop learners' digital and self-regulated lifelong learning skills throughout all levels of their educational path. Research shows that these skills can be practised from early on, even in primary and secondary school [67], [68].

Examples reviewed demonstrate that online communities enable the learning of important transversal competences, such as collaboration, critical thinking, personal knowledge management and identity development. These are important skills for everyone, and institutions should look at what they could learn from informal online communities about providing learning opportunities for these – or whether they should encourage participation in the communities as part of self-directed learning activities during formal education. Both for the initial education and lifelong learning, there is a need to change the assessment systems, which should move from assessing traditional knowledge on an individual basis to recognizing the new competences acquired in different ways.

### Conclusions

ICT applications are enabling a large variety of communities to emerge, along with new ways for people to reach them and to collaborate in them. These online social contexts are becoming increasingly important among students in schools and universities, workers in the workplace, and citizens in society, supporting the learning of contemporary and relevant skills and knowledge. Furthermore, they provide environments for learning vital transversal skills for future jobs and personal development through collaboration with others. As a result, educational institutions need to prepare learners for acquiring and developing the capability to participate in them.

The literature reviewed and discussed in this paper suggests that efforts are needed:
- to close the digital gaps by fostering basic and advanced digital competence
- to support people with low initial skills and a low perception of their learning capabilities to start participating in networked learning opportunities
- to improve the awareness and appreciation of the different forms of learning available in the emerging settings
- to support and encourage developing networks and communities with effective community models that also guide the learning of newcomers
- to study further the limitations and opportunities of learning in online networks and communities
- to acknowledge the vital role of these informal online networks for learning, employment, participation and self-development

Currently, online communities typically exist separately from learning institutions, although they often provide spaces for the learning of similar topics. Integrating learning in these informal environments with recognised educational systems would call for innovative transformation of practices through new technologies as well as encouraging, valuing and acknowledging different forms of learning. This would require a paradigm shift in the objectives, management, and funding of organizations and educational institutions. Teachers play a key role in changing education and training practices, and special attention should be paid to professional communities which support their work and professional development. By tapping into the knowledge of the various experts, communities can provide many important innovations

Here's the cleaned Markdown:

## References

9. Bruner, J.S.: The act of discovery. Harvard Educational Review 31(1), 21–32 (1961)
10. Kolb, D.A.: Experiential learning: experience as the source of learning and development. Prentice-Hall, Englewood Cliffs (1984)
11. Allan, B., Lewis, D.: The impact of membership of a virtual learning community on individual learning careers and professional identity. British J. of Educational Technology 37(6), 841–852 (2006)
12. Vygotsky, L.: Mind in Society: The Development of Higher Mental Processes. Harvard University Press, Cambridge (1978)
13. Ackermann, E.K.: Constructing knowledge and transforming the world. In: Tokoro, M., Steels, L. (eds.) A learning zone of one's own: Sharing representations and flow in collaborative learning environments, pp. 15–37. IOS Press, Amsterdam (2004)
14. Bandura, A.: Social Learning Theory. Prentice Hall, Englewood Cliffs (1977)
15. Lave, J., Wenger, E.: Situated learning: Legitimate peripheral participation. Cambridge University Press, Cambridge (1991)
16. Rogoff, B., Paradise, R., Mejía Arauz, R., Correa-Chávez, M., Angelillo, C.: Firsthand learning through intent participation. Annual Review of Psychology 54, 175–203 (2003)
17. John-Steiner, V., Mahn, H.: Sociocultural approaches to learning and development: A Vygotskian framework. Ed. Psychologist 37(3/4), 191–206 (1996)
18. Zimmerman, B.J.: Self-regulated learning and academic achievement: An overview. Ed. Psychologist 25(1), 3–17 (1990)
19. Boekaerts, M., Niemivirta, M.: Self-regulated learning. Finding a balance between learning goals and ego-protective goals. In: Boekarts, M., Pintrich, P.R., Zeidner, M. (eds.) Handbook of self-regulation, San Diego, CA, pp. 417–450. Academic Press, London (2000)
20. Hidi, S.: Interest: A unique motivational variable. Ed. Research Review 1, 69–82 (2006)
21. Siemens, G.: Knowing Knowledge (2006), http://www.knowingknowledge.com/
22. Garrison, D., Arbaugh, J.: Researching the community of inquiry framework: Review, issues, and future directions. The Internet and Higher Education 10(3), 157–172 (2007)
23. Engeström, Y.: Learning by expanding: An activity-theoretical approach to developmental research. Orienta-Konsultit, Helsinki (1987)
24. Preece, J.: Online Communities: Designing Usability, Supporting Sociability. Wiley, Chichester (2000)
25. Cardon, D., Aguiton, C.: The Strength of Weak Cooperation: an Attempt to Understand the Meaning of Web 2.0. Communications & Strategies 65, 51–65 (2007)
26. Ryberg, T., Larsen, M.: Networked identities: understanding relationships between strong and weak ties in networked environments. J. Comp. Assisted Learning 24, 103–115 (2008)
27. Gray, B.: Informal Learning in an Online Community of Practice. Journal of Distance Education 19(1), 20–35 (2004)
28. Hew, K.F., Hara, N.: An online listserv

Here's the cleaned Markdown:

## Self-profiling of Competences for the Digital Media Industry: An Exploratory Study

Svenja Schröder, Sabrina Ziebarth, Nils Malzahn, and H. Ulrich Hoppe

Collide Research Group, Department for Computer Science and Applied Cognitive Science,
University of Duisburg-Essen, Forsthausweg, 47057 Duisburg, Germany
{schroeder,ziebarth,malzahn,hoppe}@collide.info

## Abstract

The IT and media sector is characterized by rapid changes in market relevant competences. These include "creative", technical as well as other competences. In an ongoing R&D project, we study the interrelation of competence development and innovation in this field. In this context, a study of different interfaces for self-profiling has been conducted with students from two related but different study programs as subjects. The aim was to find dependencies between personal characteristics (especially creativity), self-profiling behavior and the perception of matched job offers with respect to innovativeness, attractiveness and overstrain. Although the different student groups (interactive media and computer science) do not show differences on the personal creativity scale they differ considerably in their competence preferences. More flexible options in the profiling interfaces are not used for a stronger differentiation between competences.

**Keywords**: self-profiling, creativity, competences, ontology, matching.

## 1 Introduction

Competence modeling and assessment are important issues in vocational education and training [1]. Especially in the emerging field of the digital economy, job requirements change rapidly. New trends and the continuing convergence of technologies in this sector create a need for ongoing competence development [2]. Avoiding issues of operationalization, competences can be considered as the central terms describing the abilities and skills of potential applicants should possess [3]. We assume that the development of competencies will become a key issue for innovativeness and thus form a critical success factor in this field, especially for small and medium sized companies.

Against this background, the project KoPIWA, which is funded by the German BMBF (01FM07067-72), aims at developing a comprehensive model for software supported competency management in the IT and media industry. Specific requirements are derived from the dynamics of "open innovation" developments. One fundamental part of this approach is the creation of user competence profiles. Conventional self-profiling interfaces often provide lists of competences to be rated on a pre-defined scale and therefore lack an amount of freedom for creating individual profiles.

[References section omitted for brevity but preserved in original format]

Here's the cleaned and normalized Markdown:

## Self-profiling of Competences for the Digital Media Industry

In this paper, we report on our findings regarding user interfaces for self-profiling. We focus on dependencies between personality characteristics (especially creativity), self-profiling behavior and the perception of matched job offers with respect to innovativeness, attractiveness and overstrain. Additionally we have a deeper look on the impact of the students' study programs.

The study itself consists of two parts: a questionary asking for demographical data, study program and creativity indicators, and the creation of a competence profile with our profiling system.

The profiling system design used in this study allows examining the profiling behavior of the participants. They were asked to create a profile from competences considered relevant by them concerning their job interest. Then their profiles were matched against all job profiles in a database. The three most relevant profiles according to the matching were then presented and several feedback measures were collected.

The profiling system consists of several parts:

- Profiling interfaces: Each user is provided with one of the three profiling interfaces differing in the degrees of freedom
- Job database: A sample of 152 job offers originating from the online job portal of the Federation of German Digital Economy (BVDW)[^1]
- Matching algorithm: The matching of user and job profiles considers the user's weighted choice of competences and the taxonomic relations of the competences resulting in a list of ranked job offers
- Job offer presentation: The three job offers with the highest rank are presented to the user
- Feedback: The user is asked to characterize the presented job offers with regard to innovation (Does this job deal with innovative tasks?), attractiveness (Does this job offer fit my interests?), and demands (Am I able to comply with the job offer's requirements?)

## Tools and Interfaces

### Interfaces for Profiling

The interfaces for competence profiling provide different degrees of freedom to the user with regard to the possibilities during profile creation. Competence profiles consist of at least one and at most seven competences. The competences are chosen from an underlying competence ontology consisting of 225 competences of the digital media sector.

The user interface for profiling consists of two parts: the first part shows a list of all competences available for profiling (see figure 2.1). The list on the left shows the general concepts of the ontology (categories) and is used for filtering. The specific competences are listed on the right.

Depending on the provided interface, there are different ways how the user can express their individual order of importance of the chosen competences.

The first interface arranges the selected competences in an ordered list (see figure 2.2). Therefore, the competences have to be strictly prioritized forcing the user to decide which competence matters most to the user for the job search.

The second interface allows the user to assign a limited number of 28 ranking points to the selected competences (see figure 2.3). The user can freely spend the points on the competences. Thus, the user has more possibilities to weight the competences according to their preferences, but is still bounded by the overall total.

The number of ranking points in the third interface (see figure 2.4) is not limited, so the user can assign as many points as he wants to each competence. The visualization shows the ranking of each competence relative to the other competences according to the assigned points.

Table 2.1 shows the users' freedom degrees where the first interface (Sorted) has the fewest degrees of freedom according to weighting and the third interface (Relative) has the most.

| | Forced order | Flexible weighting interval steps | (Nearly) unlimited possibilities |
|---|---|---|---|
| 1) Sorted | Yes | No | No |
| 2) Bounded | No | Yes | No |
| 3) Relative | No | Yes | Yes |

### Ontology-Based Matching

Job offers contain several terms describing the same competences. For instance, the terms "team work", "team player", "work in teams" and "team

Here's the cleaned and normalized Markdown:

## Self-profiling of Competences for the Digital Media Industry

The competence concepts have been arranged in a taxonomy to represent the relations (generalization/specialization) between the single competences. The root concept of "competence" divides into the concepts of "professional competence", "conceptual competence", "personal competence" and "social competence", which again have sub concepts. Because most of the extracted competences were professional competences, this taxonomy-branch has the deepest hierarchy.

The controlled vocabulary and its taxonomic layout relieve the creation of the user profiles, because the number of available competences is constrained and the meaning of the competences is defined by their semantic environment avoiding the problems of synonymy and polysemy.

Additionally the taxonomic relations of the competences can be used for matching.

## Example of user and job profiles

| User Profile | Job Profile 1 | Job Profile 2 |
|-------------|---------------|---------------|
| Object oriented Programming (0,5) | Scripting | Data bases |
| Scripting (0,3) | Java | SQL |
| Data bases (0,1) | PHP | teamwork |
| Ability to work in teams (0,1) | | |

A standard boolean matching only compares the appearance of terms in documents, so in the example user profile and job profile 1 share two of four terms and thus give a 50% match. On the other hand, user profile and job profile 2 share no terms resulting in a 0% match. Boolean matching does not consider that there are relations between the terms, e.g. Java is an object oriented programming language, or that there are term meaning the same like "ability to work in teams" and "teamwork". Thus, the matching between user profile and job profile 2 should be much better than 0%. This can be achieved by including the taxonomy and its instances to improve the matching.

Our algorithm maps the competence concepts of the user profile to their instances in the job offers. If the job offer contains one of the instances, it is considered to contain the competence. The taxonomy is involved by also considering all of the instances of the sub competences of the user profile's competences (term expansion). This leads to a match of 100% in example 2.

The users weight their competences by assigning ranking points or sequencing them according to their importance. To avoid the need for different ranking functions interface variant 1 (sorted order) is mapped to equidistant weights, i.e. the first competence in the list gets as many points, as there are competences in the profile and the last one point. If the user e.g. chooses seven competences, the first competence gets seven points, the second six etc., if the user chooses only three competences, the first gets three points, the second two points and the last one point. The weighting of a competence is the fraction of its ranking points compared to the total amount of ranking points in the profile. Considering the weightings our ranking function is:

Let U be a user profile containing competence concepts uc with the weighting wu∈[0,1] and J be a job profile consisting of competence instances. Furthermore containsCompetence(J,uc): is a function, which returns, if an instance of a given competence uc from U is contained in J:

containsCompetence(J,uc) = {1, if uc or a sub concept of uc has an instance included in J
                            0, else

Then the ranking of a J according to a given U is calculated by rank(U,J):

rank(U,J) = ∑(uc∈U) wu * containsCompetence(J,uc)

## Hypotheses and Research Questions

The study examines the profiling behavior of people with different degrees of creativity and from different courses of studies. How do participants from the media and IT sector model their competence profiles when they search for a job?

Do creative minds have other requirements or needs when it

Here's the cleaned and normalized Markdown:

## Self-profiling of Competences for the Digital Media Industry

## Measuring Methods

Use of several different measuring methods [4], e.g. personality test procedures, biographical interviews and simulations to provoke typical creative behavior. In this study, only personality test procedures were used. Therefore the outcome of those test procedures is referred to as 'creativity indicators', as it is not possible to determine the exact creativity of the participants. A questionnaire was adopted that consists of three factors to measure indicators of creativity. The three factors assessed the degree of "investigative interest", "artistic interest" and "work interest". The first two factors were derived from the General Interest Structure Test - AIST [5], which is based on the RIASEC model by Holland [6]. It is a standard instrument in the area of career counseling. According to Schuler [4] the two factors 'investigative' and 'artistic' of the AIST can be seen as creativity indicators. Additionally a third factor was developed to determine specific work interest according to whether a person prefers to work creatively or to deal with routine tasks. All three factors use a five point Likert scale where "1" represents "not interested at all" and "5" represents "very interested".

Table 4.1. Reliability analysis of the scales AIST-I ("investigative"), AIST-A ("artistic"), "work interest"

| Scales | Number of items | Cronbach's Alpha |
|--------|----------------|------------------|
| AIST-I | 10 | 0.848 |
| AIST-A | 10 | 0.826 |
| Work interest | 9 | 0.850 |
| All 3 scales together | 29 | 0.717 |

Those scales measure different aspects of creativity. The results of the three scales were then combined in an overall score since the internal consistency (Cronbach's Alpha) of all three scales together was 0.717. The combined value is then an indicator for the creative potential of the person.

## Profiling and Job Offer Evaluation

During the second phase of the study, the students were randomly assigned to one of the three profiling interfaces to create their personal interest profile. They were asked to specify their profile with up to seven competences. These competences represented their requirements concerning the search for suitable job offers. The competence profiles were saved for further examination.

A list of the three highest rated job offers was presented to every user, who had to read the job offers thoroughly. Afterwards she or he was asked to assess each offer with respect to attractiveness, innovativeness, and overstrain of this job offer. These factors use a five point Likert scale where "1" represents "not at all true" and "5" represents "very true".

Table 4.2. Reliability analysis of the scales "result attractiveness", "result innovativeness" "result overstrain"

| Scales | Number of items | Cronbach's Alpha |
|--------|----------------|------------------|
| Attractiveness | 5 | 0.943 |
| Innovativeness | 4 | 0.734 |
| Overstrain | 6 | 0.745 |

After the participants finished the assessment of the job offers, they had to answer questions concerning the needed effort for creating their personal profile with the profiling interface. Those questions used a five point Likert scale ranging from "very easy" (1) to "highly demanding" (5).

Table 4.3. Reliability analysis of the scale "mental effort"

| Scale | Number of items | Cronbach's Alpha |
|-------|----------------|------------------|
| Mental effort | 5 | 0.943 |

## Results

The competence preferences in both student groups were different. Table 5.1 shows the most frequent competences in the users' profiles.

Table 5.1. Most frequent competences overall

| Place | Competence | Frequency of occurrence |

Here's the cleaned Markdown:

While the students of Interactive Media split in nearly equal parts in the two clusters, almost all students of Computer Science are in cluster 1. Thus, cluster 1 contains profiles of both groups. Because the profiles are clustered by their competences, there seems to be an overlap in the self-perception of both groups.

Cluster 1 highlights technical surface level competences like image editing, (web) design but also programming, data base systems and operating systems. Profiles in cluster 2 emphasize on the one hand social and personal competences and on the other hand non-technical competences like marketing and (project) management.

These results reflect the profiles of the two courses of study. Computer Science focuses on technical competences from computer and electrical engineering, math and physics. Interactive Media combines technical aspects from computer science with psychology, business studies and additional courses for art, design and languages. Thus, both courses have a certain overlap in basic technical competences from computer science like modeling and programming.

A Pearson correlation revealed that the answers for attractiveness, innovativeness and overstrain positively correlate on a medium level. High values in perceived attractiveness go along with high values in innovativeness, etc.

Table 5.5. Pearson correlation between perceived attractiveness, perceived innovativeness and perceived overstrain

| Value | Correlation |
|-------|------------|
| Attractiveness - Innovativeness | 0.436 |
| Innovativeness - Overstrain | 0.463 |
| Overstrain - Attractiveness | 0.483 |

The participants' creativity indicator values have a mean of M = 3.32, SD = 0.41 where the lowest value is 2.31 and the highest value is 4.52. To have a deeper look at how the creative persons differ from the less creative persons, the participants were split into three groups: a lower quarter (with creativity values below 3.04), an upper quarter (with creativity values higher than 3.56) and the medium range, which was left out to pinpoint the effects.

People with high values in the creativity indicator tend to have higher values in perceived attractiveness and perceived innovativeness of the job offers (see table 5.6). This was analyzed using an independent t-test which showed significance with t(90) = -3.36 with p < .05 (for attractiveness) and t(90) = -3.32 with p < .05 (for innovativeness)[^1].

Table 5.6. Job offer evaluation values according to creativity

| Value | Group | Mean | Std. Deviation | N |
|-------|-------|------|----------------|---|
| Attractiveness | More Creative | 3.51 | 1.16 | 48 |
| | Less Creative | 2.71 | 1.12 | 44 |
| Innovativeness | More Creative | 3.37 | .50 | 48 |
| | Less Creative | 3.00 | .57 | 44 |

There is also a positive relationship between the participants' creativity indicator value and the ratings of the job offers in perceived attractiveness and perceived innovativeness, as the values correlate on a medium level (see table 5.7).

Table 5.7. Correlation between perceived attractiveness, perceived innovativeness and creativity

| Value | Correlation r |
|-------|--------------|
| Creativity - Attractiveness | 0.320 |
| Creativity - Innovativeness | 0.384 |

Although students of interactive media are said to be more creative than students of computer science a comparison revealed that both groups show almost identical levels of creativity according to our scale (see table 5.8). This was not significant with t(64) = -.39 with p > .05.

Table 5.8. Creativity mean according to student groups

| Student group | Mean Creativity | Std. Deviation | N |
|------------

Here's the cleaned and normalized Markdown:

## Self-profiling of Competences for the Digital Media Industry

## Profile Weight Ranges Analysis

| Profiling Interface | Min | Max | Mean Range | Std. Deviation | N |
|-------------------|-----|-----|-------------|----------------|---|
| 1) range "sorted" | 0.208 | 0.238 | 0.210 | 0.006 | 22 |
| 2) range "bounded" | 0.0 | 0.393 | 0.144 | 0.087 | 24 |
| 3) range "relative" | 0.0 | 0.625 | 0.136 | 0.139 | 18 |

The weighting ranges for profiling interface 2 ("bounded") and profiling interface 3 ("relative") do not differ significantly since both range means are on the same level (interface 2 range M = 0.14, interface 3 range M = 0.14). The range for profiling interface 3, which provided the most degrees of freedom, has the lowest range value, which underlines unused affordances by the participants. Thus, we can say that the participants did not utilize the provided degrees of freedom.

To examine whether the profiling behavior of the more creative participants differs from the one of the less creative, the weight ranges were analyzed using an independent t-test. The test results showed that there is no significant difference between both groups t(29) = -.35, p > .05; this means that creative people do not differ in their profiling behavior in general. To have a closer look on how the more creative participants used their possibilities in the third profiling interface the ranges were analyzed using an independent t-test. There was no significant difference between the ranges of both groups t(7) = -.3, p > .05. On the other hand creative persons were slightly more hampered by the profiling interfaces (M = 4.36, SD = 0.64 on perceived mental effort) than the less creative people (M = 2.74, SD = 0.66). This difference is significant t(30) = -7.06, p < 0.5.

Finally, the effects of the perceived attractiveness regarding the matched job offers were examined. There was no positive correlation between the values of the matching and perceived attractiveness (r = -.10). Some descriptives of the job offer matching values are provided in table below. Accordingly, there was also no significant difference of perceived attractiveness between the different profiling interfaces. This was analyzed using an independent ANOVA (F(2, 189)=0.70, p > .05).

| Value | Min | Max | Mean | Std. Deviation | Range | N |
|-------|-----|-----|------|----------------|--------|---|
| Matching values | 0.214 | 1.000 | 0.552 | 0.161 | 0.827 | 192 |

## Discussion

Since perceived attractiveness, perceived innovativeness and perceived overstrain correlate on a medium level it might be assumed that innovative job offers are often also perceived as attractive. Since overstrain and attractiveness correlate in a positive way, it is also possible that the applicants are searching for challenges. Nevertheless, both assumptions are to be made with caution since the participants are students in introductory courses who may be overstrained by job offers in general. Furthermore, the sample size was relatively small (N=66).

Notably, students from interactive media and computer science show on average very similar levels on the creativity scale. This appears to contradict the classification of "creative jobs" in the media industry, especially in media design. Indeed, the verbal labeling of such jobs does not coincide fully with a psychologically plausible notion of creativity, which would indeed also include programming aptitudes and not only design skills.

Astonishingly, the more creative participants do not have another profiling behavior than the less creative participants although their

Here's the cleaned Markdown:

As stated in section 6 we plan to make use of user tracks and semantic relations between competences. Therefore, we built a framework for the evaluation of algorithms for matching competence profiles based on different (combined) data sources. This framework uses the open source library SimPack[^5], which already provides similarity measures for the use in ontology based matching.

Furthermore we are developing a user interface that does not comply with the traditional form-based profiling approach, but tries to offer the user a two-dimensional "workspace" that allows the user to specify their attitude towards the selected competences considering dimensions like "already known and interesting" and "interested to learn". This interface shall help to incorporate the user's tendency to perceive those jobs attractive that demand more than what is already known without overstraining him at the same time.

## References

1. Burke, J.W.: Competency Based Education and Training. Routledge (1989)
2. Draganidis, F., Chamopoulou, P., Mentzas, G.: An ontology based tool for competency management and learning paths. In: Proceedings of I-KNOW 2006, Graz (2006)
3. Ziebarth, S., Malzahn, N., Hoppe, H.U.: Using Data Mining Techniques to Support the Creation of Competence Ontologies. To be published in proceedings of AIED 2009, Brighton, England (2009)
4. Schuler, H., Görlich, Y.: Kreativität. Ursachen, Messung, Förderung und Umsetzung in Innovation. Hogrefe, Göttingen (2007)
5. Bergmann, C., Eder, F.: Allgemeiner Interessen-Struktur-Test / Umwelt-Struktur-Test. Manual (AIST/UST), 2nd edn., Göttingen (1999)
6. Holland, J.L.: Making vocational choices: A theory of vocational personalities and work environments. Psychological Assessment Resources, Odessa (1997)
7. MacQueen, J.B.: Some methods for classification and analysis of multivariate observations. In: Proceedings of 5th Berkeley Symposium on Mathematical Statistics and Probability, pp. 281-297. University of California Press (1967)
8. Field, A.: Discovering Statistics Using SPSS, 2nd edn. SAGE Publications, London (2005)
9. Rebedea, T., Trausan-Matu, S., Chiru, C.-C.: Extraction of Socio-semantic Data from Chat Conversations in Collaborative Learning Communities. In: Dillenbourg, P., Specht, M. (eds.) EC-TEL 2008. LNCS, vol. 5192, pp. 366-377. Springer, Heidelberg (2008)
10. Ziebarth, S., Malzahn, N., Hoppe, U.: Using Data Mining Techniques to Support the Creation of Competence Ontologies. To be published in the Proceedings of the 14th International Conference on Artificial Intelligence in Education (AIED 2009), Brighton (July 2009)
11. Rada, R., Mili, H., Bicknell, E., Blettner, M.: Development and Application of a Metric on Semantic Nets. IEEE Transactions on Systems, Man and Cybernetics 19(1), 17-30 (1989)
12. Maedche, A., Staab, S.: Measuring Similarities between Ontologies. In: Gómez-Pérez, A., Benjamins, V.R. (eds.) EKAW 2002. LNCS (LNAI), vol. 2473, pp. 251-263. Springer

Here's the cleaned Markdown:

## PPdesigner: An Editor for Pedagogical Procedures

One of the reasons for this difficulty is that the existing modeling languages integrate concepts that are very abstract, and the associated authoring tools, though offering graphical interfaces, are based on the manipulation of these concepts. The current instrumentation of the design phase thus seems to be inadequate for instructional designers: the languages and concepts to handle are too far from their "world" [5].

In order to provide an actual and effective support during this phase, we have worked with a team of instructional designers at defining a new modeling language, based on concepts that are meaningful and eloquent for them. First of all, we have considered a reduced set of scenarios: the Pedagogical Procedures (PP). They are scenarios that are commonly known and used by instructional designers. Then, we have defined a language dedicated to the description of theses particular scenarios. This language can be considered as a Domain Specific Language (DSL). It is described in this paper, together with the associated graphical editor developed to support the design of PP using this DSL. In carrying on this work, we have made the hypothesis that defining such domain languages can be a solution to the problem of the appropriation and dissemination of the LD approach in eLearning companies. This hypothesis still has to be validated with a larger instructional designers population.

## The Pedagogical Procedures

Pedagogical Procedures are specific scenarios that are distinguishable from others by their relatively codified character and the degree to which they are shared in the teacher community. They can be defined in the following way:

> A Pedagogical Procedure is a particular scenario which contributes to the organisation of the learning activity. It is not linked to one particular subject or domain. It includes a set of instructions given to the future participants of the activity which describes what they have to do. Considering learning objectives, the application of these instructions leads to a quasi-certain result as only scenarios validated by teachers' experience can be considered as Pedagogical Procedure.

When observing actual learning situations, several pedagogical procedures can be easily identified as they are frequently used within these situations [6]. It is impossible to establish an exhaustive list of PPs, in particular because they are regularly revised and modernized. As an example, you may compare the very first description of the La Martinière PP, which dates from 1951 [7], with the one currently in use, produced in 2007 [8]. For convenient and methodological reasons, we have selected eight PPs to be part of a reference list of PPs: "Case Study", "Guided Case Study", "Debate", "Treasure Hunt", "Controversy", "Conduct a Survey", "Give a Talk", "Role-Playing Game". Of course, making an inventory of these PPs together with their description in terms of participants, phases, instructions and artifacts is not enough. They have to be described formally if we want them to be usable within a LD approach in which they are supposed to become computational objects.

The meta-model of the PPs (represented in figure 1) is built from the definition of a PP, which is the result of the exchanges between the instructional designers and the computer scientists involved in the project.

As described in figure 1, a PP can involve several participants (learners, teachers, tutors, etc.). Each participant contributes to the PP by way of her or his score. Thus, a PP is defined by all the participants' scores. As in music, a score can be divided into "movements". For instance, in the pedagogical context, such movements correspond to a selection, a search, etc.. The instructional designers involved in this project prefered to call them phases. A phase is composed of, at least, one instruction (collect information, analyse information, etc.). An instruction is in fact the transformation of one artifact to another.

This meta-model is the basis of the development of the editor of Pedagogical Procedures: PPdesigner.

## PPdesigner

In order to transform these descriptions into formal models via an editor, we have analysed the way in which an instructional designer could build a PP by manipulating the

Here's the cleaned and normalized Markdown:

## PPdesigner: An Editor for Pedagogical Procedures

PPdesigner has been co-designed by the computer scientists and the instructional designers involved in the project. The Model Driven Engineering methods and tools have been used to specify the interface following the method described in [] and also to develop the editor. For that purpose, the EMF/GMF Eclipse plugins have been used. The figure 2 gives a hardcopy of the editor.

![PPdesigner interface](Fig. 2.)

The next objective is to be able to transform PPs into computational scenarios so that the corresponding learning activity can be deployed and performed. As the language of the PP is not a computational one, there is a need to transform the formalisation of a PP in another language, computational. LDL has been chosen as the targeted language. The resulting description will then benefit from the LDL environment: the operationalisation module and the execution engine.

## Discussion

The term "Pedagogical Procedure" can be bracketed with several other terms that have long been used in the field of educational technologies: tested "educational strategies" [10] [11], "pedagogical formula" [12], "teaching techniques" or "educational tactics" [1] [13]. For all these authors, these various terms indicate some kind of routine used by teachers and identified according to their more or less strict degree of codification. The codification is above all useful for their memorization and their use in specific learning contexts. In this perspective, the codification differs from pedagogical pattern codification [14] which captures and expresses expert knowledge in a domain through patterns based on pedagogical problems and solutions.

The pedagogical procedures proposed in this paper have similar characteristics, but we define a more precise and more "formal" codification. Indeed, we consider that the codification has to take into account not only the characteristics of the PPs but also the fact that these PPs are going to be used within digital collaborative learning situations that need to be instrumented in order to run in virtual learning environments.

Other research works have introduced the codification of collaborative learning situations. For instance, Hernández-Leo & al [15] propose various types of design patterns, called "Collaborative Learning Flow Patterns" (CLFPs) which correspond to winning practices identified from the practioners. They aim at helping the teachers in their design process by providing them a set of reusable, adaptable and combinable patterns (Jigsaw, Brainstorming, etc.). These collaborative patterns differ from the Pedagogical Patterns in several aspects:

1. They aim at structuring and at organizing the learning situation (learning activity, roles, resources organization), while the pedagogical procedures support the four pedagogical pilars (organisation, learning, evaluation, observation) [16] of the pedagogical situation
2. The proposed CLFPs come from the socioconstructivist approach while the PP allow to support various educational approaches
3. The CLFPs can be considered as guidelines while the PPs are codified and shared scenarios
4. Considering evaluation, new patterns are proposed that have to be combined with the original CLFPs whereas in the PP approach, the evaluation is expressed in the PP itself when necessary
5. Finally, number of CLFPs is fixed while, in the PP approach, the designer could add new PPs to be shared with others

## Conclusion

The design aspect is more than ever at the center of the process of production of eLearning trainings. This orientation, followed now by instructional designers, is promising in that it improves the reusability and the sharing of the corresponding scenarios produced. This helps to increase the supply of existing scenarios and thus the dissemination of the eLearning approach.

At the same time, the instructional designers should more clearly participate in the conception of the tools dedicated to the design of these training modules. In this paper, an initiative for a participatory design of a tool of this family has been presented. This joint working highlighted the necessity of clarifying the means by which the instructional designer tries to build a scenario since s/he relies on a precise definition of this scenario and on some simple objectives [17].

Here's the cleaned Markdown:

## Ontology Enrichment with Social Tags for eLearning

Paola Monachesi, Thomas Markus, and Eelco Mossel  
Utrecht University, Utrecht, The Netherlands  
p.monachesi@uu.nl, f.t.markus@uu.nl, e.mossel@gmx.net

## Abstract

One of the objectives of this paper is to verify whether it is possible to extract meaningful related tags from a limited set of tagged resources and from resources tagged by only few users. This is the expected situation in a learning community. An additional goal is to assess whether the related tags extracted can be a useful source for enriching an existing domain ontology. A user centered evaluation has been carried out to analyze the effect of the enriched ontology in supporting a learning task in comparison with clusters of related tags. The experiment has been carried out both with beginners and advanced learners.

**Keywords**: e-learning, ontology enrichment, social tagging, delicious, informal learning.

## Introduction

One of the objectives of the Language Technology for LifeLong Learning project is to develop services that facilitate learners in accessing formal and informal knowledge sources in the context of a learning task. To this end, a Common Semantic Framework (CSF) is being developed. Its purpose is to support the learner through a personalized knowledge discovery path.

Ontologies constitute the core of the Common Semantic Framework. They can play an important role within eLearning, as concluded in [4]. However, this formalization might not correspond to the representation of the domain knowledge available to the learner which might be more easily expressed by the tags emerging from communities of peers via available social media applications. It is for this reason that we want to complement the formal knowledge, represented by domain ontologies, with the informal knowledge emerging from tagging, as well as the social networks which emerge from social media [5]. Our goal is to improve the retrieval of appropriate learning material and to allow learners to connect to other people who can have the function of learning mates and/or tutors. Thus, it will be possible to provide a more personalized experience able to fulfill the needs of different types of learners.

More specifically, we relate social tags, given by learners to organize learning objects or by other communities of users within social media applications, to the

[References section removed as it appears to be from a different paper]

Here's the cleaned and normalized Markdown:

## Ontology Enrichment with Social Tags for eLearning

## Case Study: Extracting Data from Delicious for Ontology Enrichment

With around five million users, Delicious is one of the biggest social bookmarking/social tagging websites on the internet. It seems thus appropriate to use this social media application to carry out our case study.

Various aspects of social tagging have been described in the literature in the last years. A good overview of the basic characteristics of social tagging systems is given by [2]. In our case study, we have taken the work of [1] with respect to similarity measures as starting point as well as [6] and [7] for what concerns the relation between tagging and the labels of ontology concepts.

Our main goal is to identify how many users and how many resources are necessary to find relevant related tags to a given one which can be employed to enrich an existing ontology. To this end, we have crawled Delicious to create our data set which consists of 598379 resources, 154476 users and 221796 tags.

In order to find related tags to a seed concept, we have employed the standard coocurrence measure but with a restriction on the number of resources and users considered in the calculation. Tags need to coocur on a user-resource pair instead of just the resource itself, meaning that each user needs to have added at least the seed term and one additional tag to be taken into consideration. For each resource n users are picked randomly that meet this criterium. The specified limits on users and resources determines the results from the coocurrence measure.

We have performed experiments on common and less common types of tags. The common tags used are: linux, tools, design, blog, software, music, programming, politics, science. The uncommon tags used are: java, touchscreen, xml, xhtml, tex, standards, html5, text-to-speech, gwt, django, mortgage. They have been used as seed tags to get corresponding coocurring tags. We have run experiments considering 2, 3, 4 5, 10, 15, 20 and 25 users in combination with 10, 15, 20, 30, 40, 50 100, 150, 200, 300, 400, and 500 resources.

Our hypothesis is that it is easier to find related tags for common tags than for uncommon tags because they are more frequent. Therefore, fewer users and resources would be required to acquire them adequately.

### Analysis of the Data

Delicious offers a list of the top-11 related tags for a given tag. This list has been considered as our gold standard, and we have compared the related tags found with this list, measuring thus precision and recall. The underlying assumption being that this gold-standard provides an acceptable basis to asses whether or not a specific number or users and resources can provide related tags.

Analysis of the resulting data shows that for common terms 10-15 users and between 200 to 300 resources provide relevant tags with an average precision of about 0.7 compared to the gold standard. For the less common terms, the precision drops to 0.45 for 5 to 10 users and 100-150 resources. In this case, we have taken less users and resources into consideration since increasing their number doesn't noticeably improve performance.

Some examples of seed tags and their associated outputs compared to the gold standard (in bold) are given below:

- software: tools, web2.0, free, design, opensource web, development, freeware, programming, windows, online
- linux: software, opensource, tools, ubuntu, windows, howto, backup, programming, unix, tutorial, free
- html5: html, webdesign, web, webdev, w3c, google, canvas, standards, markup, xhtml, reference
- django: python, programming, webdev, development, web, framework, opensource, tutorial, blog, scalability, rest

The next step is to relate the found tags to the concept

## Ontology Enrichment with Social Tags for eLearning

## Domain Knowledge and Social Tags

Social tags can represent additional lexicalizations of existing concepts (synonyms) or new concepts entirely. When a related tag is found that isn't in the ontology, a new concept can be added with this tag as lexicalization, connected to the seed concept by a basic relation (e.g. "related to"). While this doesn't place the new concept in the hierarchical structure, the related tags could also be used to create clusters rather than ontologies.

Tags extracted from social media applications efficiently enrich existing ontologies with new concepts and lexicalizations. They also add a user dimension to expert-validated domain knowledge.

## Evaluation in eLearning Context

A preliminary experiment compared support provided by:
- An ontology enhanced with social tagging
- Clusters of related tags (lacking ontological structure)

The hypothesis was that learner expertise might affect information-seeking behavior:
- Beginners might benefit more from informal tagging
- Advanced learners might benefit more from structured ontologies
- An ontology enriched with social tagging might be optimal

The evaluation used a quiz solvable with both an enriched ontology and tag clusters. The experiment included:
- 6 beginners (no computer science background)
- 6 advanced learners (computer science background)
- All participants were regular internet users
- Each group answered 3 questions using each visualization type
- Multiple-choice questions designed for the visualizations
- Follow-up questionnaire (10 questions) and interviews

### Results

The enriched ontology proved valuable for beginners due to explicit concept relations, though individual preferences varied between visual and textual orientations.

Scores given by learners (1 = strongly disagree, 5 = completely agree):

Beginners:
- Ontology-based: documents (4.4), social tags (3.6), structure (2.8)
- Tag-based: documents (3.4), social tags (2.8), structure (1.8)

Advanced:
- Ontology-based: social tags (4.33), structure (3.17), documents (3.17)
- Tag-based: documents (3.5), structure (3.0), social tags (3.0)

Key findings:
- Beginners relied heavily on documents, especially with the enhanced ontology
- Social tags were most useful when combined with conceptual structure
- Advanced learners found answers quickly using the enriched ontology
- Advanced learners used fewer documents and rated structure higher
- Both groups benefited from clear ontology structure, though not always explicitly acknowledged in questionnaires

Here's the cleaned Markdown:

## How Much Assistance Is Helpful to Students in Discovery Learning?

The majority of users recognized that structuring information through an ontology enriched with social tags has significant potential for knowledge discovery, as it would allow them to find new topics more effectively and in a more structured way than via search engines. Users saw more potential in the ontology enriched with tags than in simple tag visualization, particularly for learning tasks.

### Conclusions

The approach described in this paper can be employed to extract related tags, not only from Delicious, but more generally from any collection of tagged resources, such as Youtube or Flickr. It constitutes a valuable method to enrich an existing ontology with new concepts and add a social dimension to it, even if few people have tagged the resource, which might be the case within a community of learners. The ontology enriched with social tags constitutes a useful approach in the context of a learning task. Both beginners and advanced learners agreed that it can be a valuable tool in knowledge discovery tasks since it can provide structure to the heterogeneous list of documents which constitutes the output of search engines.

### References

1. Cattuto, C., Benz, D., Hotho, A., Stumme, G.: Semantic Analysis of Tag Similarity Measures in Collaborative Tagging Systems. In: 3rd Workshop on Ontology Learning and Population (OLP3), Patras, Greece (2008)

2. Golder, S., Huberman, B.A.: The Structure of Collaborative Tagging Systems (2005), http://arxiv.org/ftp/cs/papers/0508/0508082.pdf

3. Monachesi, P., Lemnitzer, L., Simov, K.: Language Technology for eLearning. In: Nejdl, W., Tochtermann, K. (eds.) EC-TEL 2006. LNCS, vol. 4227, pp. 667–672. Springer, Heidelberg (2006)

4. Monachesi, P., Simov, K., Mossel, E., Osenova, P., Lemnitzer, L.: What ontologies can do for eLearning. In: Proceedings of The Third International Conferences on Interactive Mobile and Computer Aided Learning, IMCL 2008 (2008)

5. Posea, V., Trausan-Matu, S., Mossel, E., Monachesi, P.: Supporting Collaborative Learning Across Social Media Applications. In: Proceedings of the 8th International conference on Computer Supported Collaborative Learning 2009, CSCL 2009 (2009)

6. Specia, L., Motta, E.: Integrating Folksonomies with the Semantic Web. In: Franconi, E., Kifer, M., May, W. (eds.) ESWC 2007. LNCS, vol. 4519, pp. 624–639. Springer, Heidelberg (2007)

7. Van Damme, C., Hepp, M., Siorpaes, K.: Folksontology: An integrated approach for turning folksonomies into ontologies. In: Proceedings of the ESWC Workshop Bridging the Gap between Semantic Web and Web 2.0, Innsbruck, Austria (2007)

### Abstract

How much help helps in discovery learning? This question is one instance of the assistance dilemma, an important issue in the learning sciences and educational technology research. To explore this question, we conducted a study involving 87 college students solving problems in a virtual chemistry laboratory (VLab), testing three points along an assistance continuum: (1) a minimal assistance, inquiry-learning approach, in which students used the VLab with no hints and minimal feedback; (2) a mid-level assistance, tutored approach, in which students received intelligent tutoring hints and feedback while

Here's the cleaned Markdown:

## How Much Assistance Is Helpful to Students in Discovery Learning?

Although the "assistance dilemma" is a relatively new term, it describes a central issue in the learning sciences that has been debated for some time. The extreme position of assistance giving is usually called direct-instruction or guided learning. Supporters of this position (e.g. [2,3,4]) argue that higher assistance (direct instruction and/or tutoring of basic skills) leads to better learning results because it provides information that students cannot create on their own. Supporters of the opposing position (e.g. [5,6,7,8]) advocate a much lower assistance approach (i.e., assistance withholding), often called discovery or inquiry learning. They argue that assistance withholding lets students construct knowledge on their own.

Other researchers have suggested that the optimal instructional design depends on the students' level of understanding [9,10]. For instance, it has been suggested that giving full instructions to novices, and then fading support as the novices' knowledge improves, is best for learning [9]. On the other hand, this work has not precisely identified the amount or timing of assistance that should be provided.

More recently, some researchers have suggested that the assistance dilemma can be viewed along various "dimensions," such as timing of feedback and example study vs. problem solving, and that it may be possible to develop predictive models of the right level of assistance necessary for optimal learning along these dimensions [11,12]. In general, this work, while still preliminary, suggests that a mid-level assistance approach is usually optimal. For instance, McLaren, Lim and Koedinger [12] investigated the example-problem dimension of the assistance dilemma in three studies in stoichometry, and a mid-level assistance approach, i.e., alternating worked examples and tutored problems, led to the most efficient learning.

In the work reported in this paper we investigate the optimal amount of assistance in a discovery-oriented domain. In contrast to many domains in which problems are more structured, discovery-learning problems usually involve more open-ended experimentation and thus may require a different level of assistance. Our interest in this work is in taking a first step at identifying the optimal amount of assistance in such discovery learning domains. Our approach focuses on three dimensions of assistance that have been explored in more structured and formalized domains, i.e.:

1. Should immediate yes/no feedback be given to students?
2. What type of feedback content should be given to students?
3. When, how much and what kind of hints should be given to students?

In our experiment we used a virtual chemistry laboratory [13], which we integrated with an intelligent tutor built with the Cognitive Tutoring Authoring Tools (CTAT), an authoring system for cognitive and example-tracing tutors [14]. We tested three widely varying points along a assistance continuum in a real classroom setting: from minimal assistance, in which only very basic feedback was provided, to medium assistance, in which help was given upon request or on incorrect steps, to high assistance, in which students were coaxed to take an optimal problem-solving approach. Our goal was to determine which level of assistance leads to the best learning outcomes in a discovery-learning environment. To our knowledge, there has been no prior study that has compared these three (quite different) levels of assistance in a discovery-learning context.

A secondary aim of the work was to experiment with CTAT in building intelligent tutors for domains involving simulation and discovery learning. The work we have done and the results we have obtained, although still preliminary, indicate that CTAT can be successfully employed in such a discovery-like domain.

## The Technology

The virtual chemistry laboratory, called the VLab for short, is a computer-based learning environment that simulates an actual chemistry laboratory [13]. The VLab was developed to support introductory level chemistry learning and can be used to perform virtual experiments in various branches of chemistry, such as thermo chemistry and stoichiometry. To design and run experiments, students choose from various tools and substances (e.g. beakers, pipets, flasks, foam cups, bunsen bur

Here's the cleaned and normalized Markdown:

## How Much Assistance Is Helpful to Students in Discovery Learning?

## Method

### Design

The study compared three conditions in which students used different versions of the VLab to solve problems in thermochemistry:

1. The Inquiry-learning Condition, in which students worked with a version of VLab with no hints and minimal feedback
2. The Tutored Condition, in which students could request hints and received feedback only when they were severely off track[^1]
3. The Direct-instruction Condition, in which students were directed to follow a prescribed problem-solving path

Students were given the "discovery" task of mixing chemical solutions that lead to a desired final temperature. This goal was posed in the context of a real world task: preparing food while on a camping trip. The VLab contained solutions of two chemical species, X and Y, that react to form Z via the reaction X + Y → Z. The reaction releases heat that goes into the water and raises the temperature of the solution. The central conceptual basis for solving this problem is the realization that the change in temperature is proportional to the concentration of the initial solutions, where concentration is the number of molecules per unit volume (1 M = 1 mole of particles per liter of solution). The student's task was to discover this concept through experimentation with different concentrations.

In the following, we take a closer look at how the assistance differed for each of study conditions as students solved this task (and related subtasks) in the VLab.

### Inquiry-learning Condition

This condition used the base version of the VLab. Students were given the general problem description and received no hints, and minimal feedback, on how to solve a particular problem, as outlined in Table 1. The only feedback provided was on the correctness of the final solution (i.e., the concentrations of the solutions mixed together), prompting to continue after completing subtasks, and provision of the final solution if the student reaches an incorrect solution. After solving, students were asked to type an explanation of their observations into a textbox, but no feedback was given on the explanation.

### The Tutored Condition

Students in the tutored condition (see Table 2) were provided with the extended version of the VLab, which used example-tracing CTAT tutors in unordered mode, i.e. students could perform actions in any order. They received no instruction before or after a step unless they explicitly asked for help. By clicking on the help button, the first level of hint appeared, which gave an implicit instruction, for instance, reminding the student of the goal of the current task, e.g. "Your goal is to mix 10 mL of 1M X with 10 mL of 1M Y in a foam cup" or a leading question used to steer the student in the right direction, e.g. "What else do you need to make the solution?"

### Tables

**Table 1. The three dimensions of assistance in the Inquiry-learning Condition**

| Assistance Dimensions | Inquiry-learning Condition |
|----------------------|---------------------------|
| Immediate yes/no feedback | No immediate yes/no feedback on intermediate steps, but feedback given on the correctness of the final solution. |
| Feedback content | Only two types of basic feedback content are provided: (1) Student is told to move on to the final solution after completing three explanatory tasks, (2) If student provides incorrect final solution, the correct solution is given. |
| Hint content and timing | No hints available. |

**Table 2. The three dimensions of assistance in the Tutored Condition**

| Assistance Dimensions | Tutored Condition | Examples |
|----------------------|-------------------|-----------|
| Immediate yes/no feedback | Immediate feedback on incorrectness only when student is far off track. No feedback on correct steps. | |
| Feedback content | Feedback says which step is wrong but does not provide explanation why it is wrong. | "No, this was not the right amount of water." |
| Hint

Here's the cleaned and normalized Markdown:

## The Direct-instruction Condition

In the direct-instruction condition (see Table 3) students also used the extended version of VLab, but had to follow a specific solution path in a specific step order (ordered mode). A message was given before each step telling the students the precise action they should perform next. Depending on the current step, an explanation of the goal and why the step is sensible was additionally given to the student, e.g. "The goal is to mix 10 mL of 1M X with 10 mL of 1M Y." If students did not follow the instruction, even if they took an action on an alternative correct path, an immediate feedback message would be displayed requesting the expected step be taken, e.g., "No, this is wrong. Please reconnect 1 M Reagent Y to the foam cup!" The pedagogical rationale for this form of direct instruction was to ensure that students learn and stay on the optimal solution path.

### Table 3. The three dimensions of assistance in the Direct-instruction Condition

| Assistance Dimensions | Direct-instruction Condition Examples |
|----------------------|-------------------------------------|
| Immediate yes/no feedback | Immediate yes/no feedback on every correct and incorrect step. |
| Feedback content | Explicit instructions and explanations for each incorrect step. "No, this is not correct. Remove this item from the workbench and take out the foam cup. A foam cup is better, because it is insulated and will prevent the heat generated by the reaction from escaping into the surroundings." |
| Hint content and timing | Content: Explicit instruction before each action, containing an explanation of the goal. One additional explicit hint is also available upon request, specifying the instruction in more detail. Timing: Explicit instruction is given automatically before the student takes each step. One additional hint available upon request only. Explicit instruction before each action, given automatically: "The goal is to mix 10 mL of 1M X with 10 mL of 1M Y. To begin, select the flask labeled '1 M Reagent X' in the stockroom and drag it to the workbench." Additional hint upon request: "Take out the foam cup, which is in the glassware cabinet, and drag it to the workspace. A foam cup is used because it is insulated and will prevent the heat generated by the reaction from escaping into the surroundings." |

## Hypothesis

Our hypothesis was that students would learn most effectively when assistance giving and withholding are balanced, i.e., in the Tutored Condition.

## Participants and Condition Assignment

Participants were 87 undergraduate students in a "Modern Chemistry II" course given during the spring term of 2009 at Carnegie Mellon University (U.S.A.). Most students were in their freshman year and had either science or engineering as a major. The materials were presented to students as an optional exercise, with the score on the activity replacing the lowest of the student's quiz grades. (The average of 10 quizzes counts as 20% of the final course grade.)

Students were randomly assigned to one of the conditions by pulling a number, either "1," "2," or "3." Altogether there were 47 students in the Inquiry-learning Condition, 16 in the Tutored Condition, and 23 in the Direct-instruction Condition. Each student worked alone on his or her own machine using the version of VLab appropriate to the assigned condition, as described above. All students were unaware of the experimental design and the existence of other conditions.

### Table 4. Activities during the study

| Activity | Time | Medium | Same in all conditions |
|----------|------|---------|----------------------|
| Introduction and Consent | 4 min | Instructor + Paper-based | Yes |
| Pretest | 6 min | Paper-based | Yes |
| Intervention (different per condition): Camping Problem in the VLab | 40 min | Computer-based (VL

## How Much Assistance Is Helpful to Students in Discovery Learning?

## Introduction and Consent
Before the study started students were asked to read a document describing the study. They were then allowed to decide whether or not to participate. No students elected not to participate.

## Pretest
The study began with a pretest, which was the same for all conditions. The pretest consisted of a reaction equation and an example reaction; students were asked to solve four tasks on their own based on these items in six minutes. These questions probed the direct proportionality between the change in temperature and the enthalpy of reaction (an underlying concept covered in the course lectures) and the direct proportionality between the change in temperature and solution concentration (a concept that had never been explicitly discussed in the course).

## Intervention: VLab "Camping Problem"
Next, the students were presented with the "Camping problem" (see Table 5) and a paper explaining how to use the VLab. They then worked on the "Camping Problem" in the VLab, which differed for each condition according the level of assistance provided, as described above. In each condition, the intervention began with an exploratory phase designed to focus student attention on the relationship between the change in temperature and the concentrations. In the exploratory phase, students were asked to make the following mixtures and measure the resulting change in temperature (as shown in Table 5):

- Mixture A: 10 mL 1.0 M X + 10 mL 1.0 M Y
- Mixture B: 5 mL 1.0 M X + 5 mL 1.0 M Y  
- Mixture C: 10 mL 0.5 M X + 10 mL 0.5 M Y

Mixtures A and B lead to identical final temperatures. Reducing the volume by one-half also reduces by one-half the amount of X and Y that react and thus halves the amount of heat generated. However, the amount of water that must be heated is also halved such that the final temperature is the same for mixtures A and B. For mixture C, the temperature change is half that of mixture A, since the amount of X and Y that react are cut in half while keeping the amount of water to be heated fixed. Since halving the concentration halves the temperature change, students should infer that the temperature change is proportional to the concentration. This direct proportionality may then be used to determine the concentration required to reach the target temperature.

Following this exploratory phase, students were given the task of creating solutions that would give the desired final temperature for the "Camping Problem." In the Inquiry-learning Condition, only the problem was presented and the students had to find solutions on their own. In contrast, students in the Tutored Condition and Direct-instruction Condition were guided through the camping problem by four subtasks (see Table 5: Solution approaches 1 and 2 a,b,c), which demonstrate two different problem approaches. In solution approach 1, the proportionality relation was used to explicitly calculate the concentration needed to achieve the target concentration. Creating solutions of the desired concentrations required an additional set of dilution computations. In solution approach 2, explicit mathematical computations were avoided by designing experiments that achieve the same goal. First, equal volumes of the starting X and Y solutions (1 M each) were mixed together, leading to a solution that exceeded the target temperature. Water was then added until the temperature reduced to the target temperature. This amount of water was then used to determine the required concentrations.

## Table 5. Intervention: "Camping Problem" in the VLab

Problem Name | Short problem description
-------------|------------------------
Explanatory Task 1 | Mixture A: Mix 10 mL 1 M Reagent X with 10 mL 1 M Reagent Y in a foam cup. Type in the change in temperature of the created solution.
Explanatory Task 2 | Mixture B: Mix 5 mL 1 M Reagent X

Here's the cleaned Markdown:

## How Much Assistance Is Helpful to Students in Discovery Learning?

## Results

We first scored and ran an ANOVA on students' pretests, to assure equality between conditions, with conditions as a between-subjects factor. Tasks had only one acceptable solution and were graded by a program. As there was no significant difference in the pretest between the three conditions, F(2,77)=0.292, p=.748, we assume that students in the three conditions started with a similar level of knowledge.

Next, we evaluated the posttest scores. Tasks in the near-transfer part of the posttest also had only one acceptable solution and were scored by a program. Three reviewers (i.e., authors 1, 3, and 4 of this paper) graded the conceptual-understanding tasks of the posttest, answered in free-form text, using the same rubric to ensure objectivity. In approximately 90% of cases there was agreement by at least two graders, in the other 10% the average of all three grades was taken. We removed seven outliers from the population – students who scored less than a quarter of the maximal reachable points in the posttest. Fig. 2 shows the means of the overall posttest scores, as well as the means of the individual components of the posttest (i.e., the near-transfer scores and conceptual-understanding scores).

We then ran ANCOVAs on the posttest scores, using the pretest scores as the covariate, to evaluate differences in the posttest scores between the conditions. Although the mean scores were higher in the Tutored Condition for both the overall score and the near-transfer score, the differences were not significant, F(2,77)=2.035, p=.138; F(2,77)=0.057, p=.944. However, we did find a significant result on the conceptual-understanding part of the posttest: Students in the Tutored Condition did better on conceptual-understanding tasks than students in the other two conditions, F(2,77)=3.783, p=.007. These results support our hypothesis: Students in the Tutored Condition – the mid-level assistance approach – showed better learning results than students in the other two conditions.

Finally, we segmented students into strong (best 50%) and weak (worst 50%) groups based on their pretest scores. In another ANCOVA, again using pretest scores as the covariate, students in the Tutored Condition who did better on the pretest benefitted more regarding conceptual understanding than students in the other conditions, F(2,37)=4.699, p=.015. Weaker students in the Tutored Condition also did better on the conceptual-understanding part than weaker students in the other conditions, but not significantly, F(2,37)=1.193, p=.315.

## Discussion

In summary, we observed differences between the three conditions in conceptual understanding, where students in the Tutored Condition scored higher than students in the other conditions. In addition, stronger students in the Tutored Condition had better results than stronger students in the other conditions on the conceptual questions.

So why did students in the Tutored Condition achieve greater conceptual understanding? One possible explanation is that the tutored students were able to make more active decisions, leading to higher motivation. At the same time, they received help when they needed it, which may have prevented frustration. Both of these aspects may, in turn, have led to more learning. In contrast, students in the Direct-instruction Condition may have been demotivated, unable to make their own decisions; that is, they may have received too much assistance for learning. This was hinted at by some comments in the feedback questionnaire, e.g. "I disliked having to follow the instructions. It's like communist chemistry." Students in the Inquiry-learning Condition, on the other hand, may have gotten frustrated when they did not know what to do and did not work as hard at learning; that is,

## How Much Assistance Is Helpful to Students in Discovery Learning?

## Introduction and Background

The assistance dilemma is concerned with the subtle choices involved in offering assistance to students as they engage in problem-solving activities and how to make choices that will optimize learning. The assistance dilemma becomes especially cogent when students engage with a software environment, such as the chemistry VLab, focused on inquiry and discovery. By integrating the VLab with an intelligent tutor, we were able to experiment with different levels of assistance, varied along different dimensions (i.e., timing, content, and type of feedback and hints).

## Discussion

Students may not have understood they were supposed to explicitly follow the instructions. In the Inquiry-learning Condition, lack of information may have led to extraneous load [19]. That is, there may have been insufficient cognitive resources available for learning, given the variety of tasks the students had to do simultaneously (i.e., trying to solve the problem, navigate an unfamiliar environment, choose the next substance, etc., all without guidance), thus explaining the lower learning outcomes compared to the Tutored Condition.

Furthermore, the differences in conceptual learning were larger and significant for stronger students than weaker students compared to other conditions. We have two possible interpretations for this finding:

1. Stronger students are likely to have a higher metacognitive awareness than weaker students [20] and thus may have used the available hints and feedback of the Tutored Condition more effectively.

2. Stronger students, who tend to be more independent learners, may have simply been more motivated to learn since they were allowed to make their own decisions and construct their own knowledge, asking for help only when they really felt they needed it.

Finally, why were differences only observed for conceptual questions? This can be explained by the nature of the camping problem, which is focused on conceptual aspects of thermochemistry. That is, the camping problem, and use of the VLab to solve it, focused students on running experiments to learn concepts, rather than procedures or calculations. The procedure and calculations necessary to solve the near-transfer problems were done outside of the VLab in all conditions; thus, we would not (necessarily) expect that any of the conditions would do better than the others in the near-transfer part of the posttest.

## Conclusion

The study presented in this paper was conducted in a real science classroom setting using three conditions that span the assistance continuum of discovery learning. We found that students in a Tutored Condition (mid-level assistance) learned better on conceptual tasks than students in both a greater- and lesser-assistance condition. That is, it appears that the Tutored Condition provided the best balance of giving and withholding assistance. Moreover, stronger students benefited more from the Tutored Condition than weaker students. The results support the notion that the optimal level of assistance lies between the extremes of direct instruction and pure discovery, and that the learning gains from a given level of assistance vary based on student characteristics, such as student pre-knowledge. Furthermore, the results suggest that assistance should be given only when students are far off track or in response to student requests for help (as opposed to being offered immediately at each step, as in the direct instruction condition).

On the other hand, our study was of a limited duration (60 minutes), with a single student pool in a single domain of science, and did not include any measure of long-term retention (sometimes argued as the only real learning measure [21]). In addition, a process analysis of student activities during the intervention was not possible due to technical problems. Log data may have revealed how students utilize assistance, as well as the origins of the learning effects.

Nevertheless, the work presented here, i.e., the merging of an open-ended discovery-learning environment with an intelligent tutor and achieving hypothesized learning results in a controlled study with variations on this system, is encouraging. We intend to replicate this experiment in more chemistry classrooms during the next school year. In addition, we believe the results may extend to other areas of science in which discovery learning is often used (e.g., "discovering" Darwin's theory of evolution) and intend to apply this experimental model

Here's the cleaned Markdown:

[11] Koedinger, K.R., Pavlik Jr., P.I., McLaren, B.M., Aleven, V.: Is it Better to Give than to Receive? The Assistance Dilemma as a Fundamental Unsolved Problem in the Cognitive Science of Learning and Instruction. In: Love, B.C., McRae, K., Sloutsky, V.M. (eds.) Proceedings of the 30th Annual Conference of the Cognitive Science Society, Austin, TX, pp. 2155–2160. Cognitive Science Society (2008)

[12] McLaren, B.M., Lim, S., Koedinger, K.R.: When and How Often Should Worked Examples be Given to Students? New Results and a Summary of the Current State of Research. In: Love, B.C., McRae, K., Sloutsky, V.M. (eds.) Proceedings of the 30th Annual Conference of the Cognitive Science Society, Austin, TX, pp. 2176–2181. Cognitive Science Society (2008)

[13] Yaron, D., Evans, K., Karabinos, M.: Scenes and Labs Supporting Online Chemistry. Paper presented at the 83rd Annual AERA National Conference (2003)

[14] Aleven, V., McLaren, B.M., Sewall, J., Koedinger, K.R.: Example-Tracing Tutors: A New Paradigm for Intelligent Tutoring Systems. International Journal of Artificial Intelligence in Education (IJAIED), Special Issue on Authoring Systems for Intelligent Tutoring Systems (2009)

[15] Yaron, D., Freeland, R., Lange, D., Milton, J.: Using Simulations to Transform the Nature of Chemistry Homework. In: CONFCHEM (CONFerences on CHEMistry): On-Line Teaching Methods. Online-Conference: American Chemical Society (2000), http://www.ched-ccce.org/confchem/

[16] Lieberman, H. (ed.): Your Wish is My Command: Programming by Example. Morgan Kaufmann, San Francisco (2001)

[17] VanLehn, K.: The Behavior of Tutoring Systems. International Journal of Artificial Intelligence in Education (IJAIED) 16, 227–265 (2006)

[18] Koedinger, K.R., Anderson, J.R., Hadley, W.H., Mark, M.A.: Intelligent tutoring goes to school in the big city. International Journal of Artificial Intelligence in Education (IJAIED) 8, 30–43 (1997)

[19] Sweller, J., Van Merriënboer, J.J.G., Paas, F.G.W.C.: Cognitive Architecture and Instructional Design. Educational Psychology Review 10, 251–296 (1998)

[20] Bransford, J.D., Brown, A.L., Cocking, R.R. (eds.): How People Learn: Brain, Mind, Experience, and School. National Academy Press, Washington (2000)

[21] Schmidt, R.A., Bjork, R.A.: New Conceptualizations of Practice: Common Principles in Three Paradigms Suggest New Concepts for Training. Psychological Science 3(4), 207–217 (1992)

## A Fruitful Meeting of a Pedagogical Method and a Collaborative Platform

Bénédicte Talon, Dominique Leclet, Grégory Bourguin, and Arnaud Lewandowski

## Abstract

This publication describes the work done to allow the instrumentation of a pedagogical method named MAETIC on a collaborative tailorable platform named CooLDA. MAETIC facilitates the apprentic

Here's the cleaned and normalized Markdown:

## A Fruitful Meeting of a Pedagogical Method and a Collaborative Platform

Even if collaborative environments dedicated to learning (Ganesha, Moodle, Claroline, etc.) [4] already exist and offer sets of collaborative tools (forums, chat, wiki, etc), we found that these platforms lacked the flexibility needed for their adaptation to the variety of different teaching and learning situations found in Higher Education. This lack of flexibility seems to result from the fact that these platforms are constructed mainly around the course resources rather than around the actors' activities. According to Britain and Liber [5], adopting a single Virtual Learning Environment (VLE) across the institution may often not be appropriate as different departments and/or modules may have radically different demands from their e-learning tools. Many institutions surveyed in 2003 reported using two or more VLEs in their institution. Moreover, the high level of in-house developments strongly suggests [5] that commercial systems were not always appropriate to learning and teaching needs. Metaphors such as noticeboard and common room are derived from traditional campus-based situations without questioning whether these are still appropriate.

Indeed, if teachers want to use an existing environment in order to support their own approaches, they have to adapt to the framework of the underlying platform. This appears to be inadequate since it seems that it is the platform that should be adapted to support the teacher's pedagogical method and organization.

Centered on the competence acquisition, MAETIC has voluntarily been built without any consideration about its future technical support. The wish is that the instrumentation remains left to the teacher's appreciations since we think that teachers do not willingly adapt to too much formatted environments. However and from our point of view, none of the many existing platforms currently seems to be able to easily support the teachers' creativity fostered in the MAETIC approach.

The other two authors of this paper have been working for many years in the Computer Supported Collaborative Work (CSCW) research field while trying to create better software environments supporting collaborative human activities [6]. This work has been strongly inspired by results coming from Social and Human Sciences (SHSs) that have demonstrated that human activity is reflective and continuously evolves. Thus, a 'good' environment supporting collaborative activities should be generic, tailorable and flexible enough to support dynamic adaptation according to its users' emerging needs. This approach has been synthesized into the co-evolution concept.

The CooLDA platform has been created while trying to support this concept. This is why CooLDA does not rely on a model dedicated to specific activities, but rather tries to offer a generic framework able to support any kind of collaborative computer mediated activity. The aim of this paper is to present how a very generic approach like CooLDA can bring a solution in an educational context while supporting a project based pedagogical method like MAETIC.

In the following, we first describe the key points of the CooLDA platform and its generic activity model. We then introduce the MAETIC method, explain how it has been modeled it in the CooLDA platform, and present the resulting pedagogical environment. We introduce the experiment started in January 2008 to validate this work and finally conclude with the current work and the resulting perspectives.

## What Is CooLDA?

CooLDA is a platform designed to support Computer Supported Cooperative Work (CSCW). This work has been strongly inspired by the results coming from the Activity Theory [7]. In this paper, we are only focusing on some principles that constitute the bases of the environment. However, further information about this approach and the results we obtained can be found in [6].

A key point of our approach in designing a CSCW environment is to consider that many tools useful in supporting some activities we are interested in already exist. Thus, our goal is not to (re)create such tools, like a new discussion tool, or a new text processor. Rather, we want to offer an environment able to integrate and articulate them. From our point of view, inherited from the Activity Theory [7], each tool supports one kind of activity. When several tools are used in parallel by a

## What is MAETIC?

MAETIC is a pedagogical method which organizes a project-based pedagogy. MAETIC is independent of the learning domain and has been built to develop and acquire professional skills. In the project-based approach, learners build up their knowledge and know-how thanks to the project [10]. Students have to identify and formulate the problems themselves [11]. MAETIC describes activities managed by a group of students and directed towards a concrete production. The teacher activities consist in animating, not deciding. MAETIC induces a set of activities in which all the students are implied and play an active role.

MAETIC lays on some principles like the regular management by the group of students of a project logbook (to work the communication skill), the management by the teacher of a unit logbook (to instigate the activity), the realization of session assessments (to give a progress report on acquisitions and to evaluate the delay taken), a regular control of the students logbook by the teacher to analyze the encountered problems and make students aware. These principles are integrated into procedures that the actors have to respect. MAETIC so describes a procedure (project cycle: Fig. 1) that the group must respect.

The project rests on 5 steps which are traditional activities of project management. These 5 steps are the launching, the framing, the planning, the piloting and the assessment. During each step, students work on sub-activities and produce deliverables. Five technical booklets bring them accurate information on the working techniques to adopt and offer models of documents. Students are responsible for distributing the roles, planning the tasks, organizing the internal and external communication of the project, producing the deliverables according to a planning, etc.

For example, the launching step requires 4 activities:

1. role definition
2. graphic charter realization
3. log book opening
4. answer to demand writing

Activities require deliverables to be produced and are described in technical booklets given to students to help them to do their activities.

The student's procedure has been described in a pedagogical guide. The students find in it a detailed description of activities and models of documents.

MAETIC also describes a teacher procedure consisting of 3 steps. Each step requires activities to be realized and deliverables to be produced. These activities are directed towards the students' activities organization. For example, the preparation step needs activities like logbook opening, tasks planning, scenario writing and resources preparation.

The teacher's procedure has not been formalized yet and stays at this moment of the order of our know-how.

It is possible to practice MAETIC without Communication and Information Technologies (CITs). But CITs can bring many advantages for students [12] such as the work at distance, the distribution of an on-line documentation, communication facilities and traceability. CITs also present many advantages for the teacher such as the centralised control and at distance, the communication with students, the regular follow-up, and so on.

A device that makes use of Weblogs has been produced and evaluated from 2005 to 2007 on different publics. A first experiment [1] (including the presence of a control group who did not use the MAETIC device) has to demonstrate the value of the initial method coupled to a device using Blogs to promote the learning of project management skills.

A second experiment was used to validate the ability of MAETIC to train other skills. Our desire was to test the genericity of the guide (its ability to be used in various fields) as well as to validate the relevance of Weblogs to support the log activity. We tested the application of the MAETIC method in various areas of education such as professional seminars, databases design, learning scenarios design, etc. These evaluations [1][13] have shown the interest of MAETIC for the development of varied competences but also highlighted certain difficulties. Evaluations have brought to light an important workload for the teacher to regularly control the student work via Weblogs. On the other hand, it is not easy for a teacher to adapt MAETIC to existing platforms such as Moodle, Gane

Here's the cleaned Markdown:

## Modeling MAETIC in the CooLDA Platform

## The Model of the MAETIC Pedagogical Method

The model of the MAETIC method is synthesized in the Figure 2. In this model, we have removed all concepts related to organization and instrumentation. We have only kept what is generic – i.e. what will be applied whatever the sector of training formation or the selected mode of instrumentation will be.

Actually, this model contains concepts that must be respected to use the method, as described in the previous section. During the early organization phase, the teachers are responsible for adapting this model to their teaching unit by adding specific objects (instances of organization classes) such as the dates of the sessions, the meeting rooms, the resources related to the training area, etc. The instrumentation phase corresponds to the definition of the tools that each activity will exploit during the remote and in presence sessions. It must also be concerned with the way in which the resources (of MAETIC and of the training area) and deliverables will be placed at the disposal of the actors to exercise their activities.

[Figure 2. UML model of MAETIC method]

## Mapping CooLDA and MAETIC

The major part of the work has consisted in 'translating' the MAETIC method into the CooLDA's activity model. Actually, this has been done by representing the MAETIC method by five inter-connected activity models (also called tasks) corresponding to the five steps of the method.

Each activity model describes a particular step of the process. In order to be as little constraining as possible, the five steps have been modeled as being sub-tasks of a main (system) task. Inside this main task, we have identified two roles, namely 'teacher' and 'student'. Playing one of these roles in the main task may imply another particular role (MAETIC role of the figure 2) in the sub-tasks (each step of the method). In this kind of platform, designed to offer tools, the users choose the activity they want to join (among the five activities of the method). The sequential cycle of MAETIC is the responsibility of the group of students and has to be controlled by the teacher in this regular control activity.

According to the specification of MAETIC, we have identified existing tools that could suit the needs of the activities bound to each phase of the method. These tools had to be pluggable in CooLDA, which relies on the Eclipse platform. That is the reason why, due to inter-activities approach, we mainly use existing Eclipse plug-ins. For instance, we choose Office Integration Editor plug-in that integrates OpenOffice.org tools in Eclipse. We have also chosen to use Eclipse's integrated CVS (Concurrent Versioning System) client, in order to offer document sharing and versioning functionalities. We have also adapted Eclipse's integrated web browser, and developed a chat plug-in allowing users to discuss synchronously. Other tools fostering collaboration are provided by CooLDA itself (awareness view, perspectives sharing facility, etc.).

These tools have then been 'inscribed' in the different activity models (that correspond to the five MAETIC steps). The contextualization of a tool is realized through the creation of a particular sub-activity (describing the use of this tool) in each MAETIC step it is involved in. Indeed, an activity model actually describes the use of one tool that is mapped by a Resource. In order to finely integrate these tools, we have identified (by introspection on the tools themselves) which methods could be of use for their integration and for their piloting. These methods have been wrapped into Operations in the activity models. Finally, specific Actions have been defined for each role, in order to determine how these tools should be configured and piloted. This fine-grained modeling is the key to being able to create a highly configurable environment able to manage the links of the inter-activities.

## Experimenting CooLDA-MAETIC

To validate the genericity of CooLDA on the one hand and to measure the interest of this type of instrumentation for MAETIC on the other

Here's the cleaned Markdown:

## A Fruitful Meeting of a Pedagogical Method and a Collaborative Platform

## Screenshots
- Screenshot of a MAETIC student environment (after connection)
- Screenshot of a MAETIC student environment (planning Activity activated)

## Environment Description
A user's name is used to configure the environment through activity modeling: CooLDA 'reads' the activity model of the 'planning' step and its sub-activities models (one model per integrated tool), and 'runs' the many start actions tied to the role of the user in this specific activity. This is totally transparent for the user.

The environment has been modeled for students having to realize a software test project. Several tools are identifiable:
- A Teacher's logbook that automatically opens showing the latest learning unit information
- A chat for communicating with group members or teacher
- A project explorer for sharing different documents (MAETIC deliverables, Project deliverables and learning unit lectures)
- Additional tools

The choice to join an activity in the activity manager starts the activation of tools necessary for that activity. For example, activation of the Planning Activity starts the open office sheet tool and opens the planning sheet. At project start, document models are placed in the CVS in the MAETIC Documentation Repository for students to use as templates.

## The Protocol

### Assumptions
1. CooLDA is a platform which presents capacities of adaptation to the activity of collaborative learning.
2. MAETIC may be instrumented in different technological environments (without changing the guide).
3. The malleability offered by CooLDA supports the adoption of the device (methods, tools, procedures, principles of action, actors) by its users.

### Data Collection Methods
- Observations during sessions
- Collection of students' slides from project conclusions
- Collection of posts on student Weblogs
- Collection of tracks from the server
- Teachers' interviews

### Target Population
- Promo A: 10 Professional License students (2 groups of 5)
- Promo B: 61 first-year Technological Certificate students (10 groups of 5-7)

The platform was installed on classroom computers with a downloadable version available for students' personal computers.

Promo A used the platform for a 24-hour project management unit creating a website following MAETIC phases. This initial experiment revealed technical difficulties that were quickly addressed.

Promo B used the improved platform in a 12-hour software test unit, testing C programs while following MAETIC phases. The environment included additional CDT perspective for C program execution and editing, plus teacher-uploaded resources.

## Results

### Assumption 1 Results
Teachers formalized needs through interface specification based on 3 years of MAETIC experience. They collaboratively designed the environment with required tools and activities including Document Management Activity and log book management. The platform showed adaptation capability though server robustness needs improvement.

### Assumption 2 Results
Educational scenarios maintained MAETIC Method integrity. Teachers used the existing MAETIC guide without adaptation, only requiring organizational context definition (6 weeks for project management, 8 weeks for software testing).

### Assumption 3 Results
Analysis of teacher interviews, logs, posts, and slides indicates positive results regarding system malleability and adoption.

## A Fruitful Meeting of a Pedagogical Method and a Collaborative Platform

## Student and Teacher Reactions

Extracts from slides show numerous reactions confirming the method adoption:

> "The MAETIC method allows us to be in the same conditions as those of a professional project. It prepares us to professional world"

> "MAETIC method requires great rigor"

Many comments confirm the interest for the platform:

> "The means placed at our disposal made it possible to be implied in the project. With all these tools of communication at our disposal, it was easy to be invested to try to produce a suitable result"

> "The platform has an unquestionable advantage which makes it very useful, even essential: the fact to be able to publish documents and that they are visible by any member wherever he/she is allows to know how advanced each one is in the project"

> "It is really a practical tool for the whole of the members of the group because it makes it possible to maintain up to date the various documents with the good versions of all these documents"

> "The platform provides a common space of work (space of storage) to the group and also allows us to communicate (chat)."

However:

> "for me the platform is as a deer which should be drawn up. Even if publishing a file is not very complex, how to do it should be learned. In the same way, it is not easy to navigate through various menus: no explanation is given by the platform on its use. A user guide would have been quite useful".

## Usage Analysis

The logs analysis enabled us to note that the platform was used remotely. The teacher left no instructions requiring work at home. The project can be completely realized during sessions in the classroom. He had however asked the students to download a version of the environment on their machine if needed.

Some students connected remotely (29 out of 75). They were essentially the project managers or the communication responsible. Sometimes connections were short, certainly for a files recovery or a deposit on the CVS. Sometimes, these connections were longer (3h00) in particular at the end of the project when many deliverables were to be delivered. At the end of the project, remote connections were most frequent with numerous connections between 10 pm and 12 pm.

We noticed a regular and rather long connection of the teacher each week in order to control the progress of the work (between 1h40 and 3h00 each week and 8h00 for the final evaluation).

## Conclusion and Perspectives

The portability of MAETIC on CooLDA was rather easily done. Logs allow us to verify that the students worked outside the classroom sessions and thus downloaded the platform on their computer, which would tend to prove its usability. However, inspection of the data already shows that the students did not modify their working environment but rather adapted to the proposed environment. Document sharing through CVS during the activities of the project was a much-appreciated feature. The teachers have strongly appreciated the centralization, in their environment of the follow-up of the groups: availability of documents and log books, integrated into the same environment offered them an easier follow-up of the activities of the groups and consequently an easier assessment.

Demands of improvements are outlined by the teachers with notably the will to integrate new tools like an asynchronous tool to leave messages to the students as well as a centralized tool of notation and a tool of comments to leave information on the evaluation.

We plan in particular to focus our attention on the malleability of the platform: will users adapt the environment to their use and if so, how will they make this adjustment?

Until now, the platform has been tested on an audience of Information Technology specialists. It will be interesting to also test it on the non IT specialists (teachers and students) to determine their suitability for this tool.

It is therefore necessary to adjust the tools, in particular by facilitating access to CVS.

A second wave of testing has been delayed until September to complete the ongoing adjustments and incorporate features requested by teachers.

## References

1. Talon, B., Leclet, D., Quénu-Joiron, C.:

Here's the cleaned and normalized Markdown:

## A Model of Retrospective Reflection in Project Based Learning Utilizing Historical Data in Collaborative Tools

## References
- Gibson, S.: Group Project Work in Engineering Design Learning Goals and their Assessment. International Journal of Engineering Education 17(3), 261–266 (2001)
- Barr, R.B., Tagg, J.: From Teaching to Learning - A New Paradigm for Undergraduate Education. Change, 13–25 (November/December 1995)
- Garbay, R.: The role of Information Science in Interdisciplinary Research: A Systemic Approach, Rethinking Interdisciplinarity (2003), http://www.interdisciplines.org/interdisciplinarity
- Leclet, D., Talon, B.: Binding the gap between professional context and university. In: International Conference in Interactive Computer Aided Learning, ICL 2008, Villach, Austria, September 24-26 (2008)

## Abstract
In project based learning, learning from experience is vital and necessitates reflection. Retrospective reflection is as a conscious, collaborative effort to systematically re-examine a process in order to learn from it. In software development student projects it has been empirically shown that project teams' retrospective reflection can help the teams collaboratively construct new knowledge about their process and that historical data in collaborative tools used in daily project work can aid the teams' recall and reflection on the different aspects of project work. In this paper, we draw on these results as well as other findings on the use of collaborative tools in a similar setting. We use the framework of distributed cognition to develop a model of retrospective reflection in which collaborative tools used as cognitive tools for daily project work are utilized as cognitive tools in retrospective reflection, aiding the creation of individual and shared representations of the project process.

**Keywords**: project based learning, reflection, distributed cognition, cognitive tools.

## 1 Introduction
In project based learning [1] learning from experience is essential [2-4]. To achieve this learning, reflection is necessary, both during day-to-day work and with some distance to the activity reflected upon [4]. In this paper, we will focus on what we will call retrospective reflection, a form of reflection-on-action in which participants in a collaborative process systematically re-examine their process.

There exist many techniques and tools to support reflection in project based learning. Examples include the writing of diaries and reflection notes, and user annotation of information in the collaborative tools used to support their work. Computerized tools can be specifically introduced to support learning. Reflection supporting tools comprise tools showing users their learning process and its result, tools providing guidance for users' monitoring of their learning process, and tools providing scaffolding for comparison with expert thinking [5]. In an organizational setting, advanced collaboration platforms may include knowledge management functionality [6], but such tools are untypical in formal education.

The project based learning to be focused in this paper is that which is based on project work involving the development of artifacts and aided by lightweight collaborative tools. The latter includes tools frequently associated with Web 2.0, e.g. wikis, instant messaging tools, and discussion forums. Today's students regularly use such tools to coordinate and perform their activities, whether imposed by school or not [7, 8]. Adding to the picture, students in higher education generally expect to have flexibility of time and place for work. From the point of view of course organizers, lightweight tools are inexpensive options providing flexibility of use and functionality well known to students and course staff.

A core argument in what follows is that by supporting various aspects of work throughout a project, lightweight tools collect historical data with a potential value to help the students recall what happened in the project and reflect on it.

The objective of the research in this paper is to provide a general account of retrospective reflection in the above described type of project based learning setting. We draw on empirical research on software development (SD) student projects: mainly published work [9-11] and some additional findings. We provide a substantial new contribution by situating the results in a theoretical framework, generalizing to project based learning

Here's the cleaned Markdown:

## A Model of Retrospective Reflection in Project Based Learning

## Shared Timeline Reflection Workshop

Individual satisfaction curves were drawn along a whiteboard timeline (see Fig. 1) and explained by each participant. Next, participants individually answered questions about tasks, roles and lessons learned and presented their answers. After the workshop, the teams made reflection notes.

The study showed that individual timelines and satisfaction curves reflected different perspectives on a project process. Fig. 1 illustrates how experience curves may differ within a team. The study also showed that shared timelines often reflected views of the project not found in any individual timeline. Closer examination of the individual timelines used in the creation of the shared timeline in Fig. 1 revealed that most of the events from the individual timelines had been included in the shared one, and some had been transformed through the co-constructive effort. For instance, the event 'a bit ineffective work' in an individual timeline was modified into an event marking a point in the project process when the team realized that they had to work more efficiently ('insight: need to work more efficiently'). The study [10] concludes that the satisfaction curves gave the students new insights, that the workshop helped them take new perspectives on important issues, and that they considered it useful.

## Retrospective Reflection Aided by Historical Data in Collaborative Tools

In SD industry it is acknowledged [14] that project retrospectives would benefit from better data to help participants create a shared understanding while avoiding oversimplification and time-consuming examination of unimportant information. This was addressed in a study of SD student projects in which historical data in project wikis, used as lightweight project management tools by several teams [15], were used to aid project participants' reflection on their project process [9]. In retrospective interviews with project members, wiki contents were chronologically examined, and particular types of information was seen to trigger recall of and reflection on project events, project phases, and collaboration within the team and with other stakeholders.

In [11] it was shown that historical data in an issue tracking tool, a lightweight tool for SD project management, was useful to aid retrospective reflection. Historical data was accessed by traversal of a timeline showing team members' updates to development artifacts. The reflection effort was organized in line with the approach of creating timelines and satisfaction curves [10], but conducted as a two day, video recorded workshop with one team to investigate in depth the use and role of historical data in the reflection process. Examination of the historical data helped team members individually identify project events that had not been included in the timelines made from (individual) memory alone and that were later included in the collaboratively constructed timeline and accounts of lessons learned. Historical data in the issue tracker were also used by the team to adjust details in the shared timeline.

Some features for navigation and retrieval of historical data were found to be important in retrospective reflection [9, 11]. These features included chronological overview and traversal, and the possibility to switch between overview and details.

Interviews with the 2007-2008 teams and examination of their reflection notes showed that the collaborative tools used were generally lightweight. The teams were clear about what tools were used for what purpose. While the specific tool selection and usage differ among teams, we see a general pattern:

- Lightweight project management tools (typically project wikis or issue tracking tools) are used for managing team-internal coordination of tasks, e.g. create and follow up on a project plan, and define, assign and track the status of tasks. The tool provides links to project documentation.
- Development tools are used to write, test and integrate source code.
- The storage and versioning of project artifacts are managed in a file versioning system that may or may not be integrated with the project management tool.
- Email is used for formal and documented communication internally and in communication with other stakeholders. Typically, the project team has its own mailing list.
- Instant messaging chat is used for informal, team-internal messages and substitute face-to-face conversation over synchronous, distributed work. Less often, it is used for communication with other stakeholders.
- Internet sites are used to get information.

Here's the cleaned and normalized Markdown:

## A Model of Retrospective Reflection in Project Based Learning

B.R. Krogstie

Information about technology; in most cases, simple web search or FAQ lists provide answers, but occasionally project members participate in discussion forums [16]. These patterns of use, combined with the functionality of tools, imply that data resulting from various types of project work is generally logged. Wiki revisions are automatically stored and the email clients store all mail unless otherwise specified by the user. It is tacitly expected that an email user keeps an archive of work-related email. With instant messaging, team members frequently choose to enable logging. On an internet forum, postings remain as long as the community hosting the forum wants to keep them. Looking into the historical data stored in these tools, they can be seen as a trace of the work undertaken with the aid of the tools. The studies investigating reflection aided by historical data [9, 11] showed that data in tools used for project management and coordination reminded participants of events related to those aspects of project work and thus helped them reflect on that type of issues.

To examine the potential for historical data to shed light on other types of issues, we started out by issues that, according to the teams' own reflection, had been of great importance in their projects (e.g. misunderstandings in team-customer collaboration, problems of getting timely information from a service provider). Examining historical data in collaborative tools used by those teams, including email archives, instant messaging logs, and discussion forums, we looked for historical data that could shed light on those issues. The data found were, as seen by the researcher, rich enough to have such a potential, partially because the data shed light on the use of the collaborative tool itself, which was often at the core of the project challenge.

We end this section by outlining some more characteristics of the SD projects relevant to our agenda of understanding and supporting retrospective reflection in the teams. Work in the projects is typically diversified, project participants having different roles, dividing work and using different tools to address different tasks. Team members' roles affect their day-to-day use of collaborative tools. Consequently, historical data in a tool typically reflects work in which some team members have been more involved than others. Project artifacts (e.g. requirements specifications and project plans) frequently play a role in collaboration with project stakeholders (e.g. customer [17] and course staff) having different goals for their project involvement. Project artifacts in various states can be seen as more or less well defined versions. These may be deliberately saved by the user (as when a text document is renamed and saved) or automatically stored in a tool. A file versioning system stores the contents of and differences between every file version 'checked in' by the users. In our studies of retrospective reflection aided by historical data in collaborative tools, going into detail often meant exploring specific artifact versions.

## Theoretical Background

Taking the view of constructivism, seeing learning as integral to activity that is basically social and situated, and focusing on the role of tools, several theories [18, 19] may shed light on project based learning. They include activity theory (AT), actor network theory (ANT), symbolic interactionism, situated learning, and distributed cognition [20, 21]. In [11] it was shown that distributed cognition is an adequate framework for understanding retrospective reflection in SD student projects. It has been used to analyse learning in educational [22-24] as well as work [25, 26] settings.

In the present study, the main reason for choosing distributed cognition among the candidate frameworks is its focus on transformation between representations. Such transformations can be seen as a core element in a process of retrospective reflection incorporating construction of timelines and examination of historical data. The concept of cognitive tools [23, 27] can shed light on how such representations aid work and learning. Selecting distributed cognition as a framework we focus on its descriptive power and what we want to achieve by applying it [18].

We want to develop a model which not only descriptively accounts for the elements and dynamics of retrospective reflection in project based learning but which also informs its organization. To this end we augment our theoretical framework with theory addressing how

## A Model of Retrospective Reflection in Project Based Learning

## Concepts and Terminology
We clarify our use of some concepts: Activity is used as a generic, commonsense term and not as a reference to activity theory. By project artifact we mean something used and produced in project work, e.g. a diagram or a report. In distinguishing between work and the retrospective reflection on that work, we deliberately 'hide' the reflection and learning in day-to-day project work inside the concept of project work. This is not to pretend that project based learning only happens in 'chunks' of retrospective reflection, but it is our agenda to shed light on the latter.

We proceed with an analysis of retrospective reflection on the above theoretical basis, from the empirical grounding described in Section 2 and with the objective of developing a model. With a sidelong glance at the work on organizational memory in [25], we structure our analysis in terms of retrospective reflection being socially distributed, temporally distributed, and involving transformation of representations.

## Analysis

We use findings from the research on SD teams outlined in Section 2 to shed light on how retrospective reflection may be supported in similar settings of project based learning from the perspective of distributed cognition.

### The Social Distribution of Cognition in Retrospective Reflection

The social distribution of the cognition involved in retrospective reflection can be seen as having two main components: the social distribution of the process reflected upon, and that of the retrospective reflection activity itself. The social distribution of the process reflected upon in the case of SD student projects was largely described in Section 2 and illustrates the complexity of the experience to be returned to in retrospective reflection. We noted that tasks relating to different aspects of work were distributed in the teams, resulting in a distribution of tool use. Historical data were generally being stored in the tools as a result of the work. The data reflected aspects of project work in which the tool has played a role, including the tool use itself. E.g., in Fig. 2, the historical data reflects software development work, more specifically coding. Crucially, in our context, a new version of a project artifact stored in the tool represents different data than the previous version, this distinction serving to capture the temporal and partially also the social distribution of the project work.

We now take a closer look at the social distribution of the retrospective reflection with reference to the SD students teams. The timelines in [10] (see Fig.1) were drawn with the aid of simple physical tools; paper and pencil, whiteboard and pens. These tools had a flexibility in the situation of knowledge sharing appearing to make them adequate for externalizing and transforming participants' representations.

When historical data in collaborative tools were introduced in similarly organized retrospective reflection [11], particular tool features for retrieving and navigating data were found to be important to the utility of the tool. For instance, the view in Fig.2 allows easy chronological traversal with direct access to project artifacts in there-and-then versions. The likelihood of being able to retrieve interesting data from a specific tool also depends on the actual tool usage in the team's work. Further, what is worthwhile examining retrospectively depends on what the team considers important issues. These might have been identified prior to retrospective reflection, but may also emerge from the examination of the historical data as seen in [11] and Fig.2.

Synchronous, distributed work among pairs of SD team members is frequently supported by instant messaging chat. Such conversation has an oral flavor, often combining there-and-then problem resolution with social chit-chat. Instant messaging logs exemplify historical data that for privacy reasons may be inadequate for retrospective reflection even if the contents are of potential interest to the team.

The social distribution of retrospective reflection is also about which participants are involved, e.g. whether reflection is done individually or by the whole team together. In the SD teams, recall of events was essential in the construction of individual and shared timelines [10, 11]. Research on transactive memory, "a set of individual memory systems in combination with the communication that takes place between individuals" [34], shows that in collaborative remembering, comparing groups of people who have a

Here's the cleaned and normalized Markdown:

## A Model of Retrospective Reflection in Project Based Learning

## The Temporal Distribution of Cognition in Retrospective Reflection

Retrospective reflection in project based learning is part of a trajectory of project based learning spanning the entire project, but also constitutes a separate sub-activity within the overall project. The distributed cognition of retrospective reflection can thus be seen as situated in two different contexts with different objectives for the ongoing activity: There-and-then project work focused on completing project tasks, and here-and-now retrospective reflection focused on making sense of there-and-then work in the light of knowledge of the entire process.

Events of there-and-then work may be interpreted as belonging to different sub-trajectories, and can be seen as the core of what is reflected upon. We illustrate this by going into some detail about the findings reported in [11] and illustrated in Fig.2. In the retrospective reflection workshop of the team in question, there was a project event not remembered by any team member in the individual reconstruction of the project trajectory based on memory alone, i.e. not included in any individual timeline. The event marked the onset of an activity in the project, more specifically coding work done to get familiar with technology to be used later in the real development. As such, the event could be seen both as a turning point in the trajectory of the entire development activity and as the starting point of a sub-trajectory: that of the early-investigation of technology.

The team members' individual examination of historical data in the issue tracking tool made two of them recall the event as important to the project (Fig.2) and include it in their timelines. Later, as the team created a shared project timeline, the event was included and brought up into the discussion of how things might have been done differently in the project. The event was discussed in the light of the specific activity for which it marked the starting point and in the light of the entire development project. The trajectory of the project as represented in the shared timeline was compared to a process described in SD literature as ideal for a certain type of development work. These findings illustrate that comparing trajectories is at the core of the retrospective reflection process.

Considering retrospective reflection as part of a trajectory of project based learning we see a possible effect on tool usage if it is known to the team that historical data will later on be systematically examined. The dual role of the tool may lead project members to adjust their day-to-day tool usage, e.g. by providing more frequent or elaborate comments associated with ongoing tasks, which may affect project work in a positive way. However, changes may have adverse effects, e.g. if participants cease to communicate issues in a tool because the logged data may give an unfavourable impression in retrospect. Adjusting tool use to meet the needs of both retrospective reflection and day-to-day work may be seen as part of project based learning itself.

We conclude from this section that the 'return to experience' of retrospective reflection involves examination and comparison of sub-trajectories of project work and that retrospective use of tools may affect project work through participants' awareness of the dual role of the tools.

## Transformations of Representations and the Use of Cognitive Tools

Looking at the timeline technique as used in [10], and illustrated in Fig.1 we see many examples of use of representations as cognitive tools. The internal, individual representations of the project process were transformed into externalized individual timelines on paper. Both types of representations were used in the collaborative session through which the knowledge captured in the representations was transformed into a shared, external representation in the form of a timeline, a process likely to make the individual, internal representations change. The internal and external representations created and modified through retrospective reflection served as cognitive tools for the teams' later writing of collaborative reflection notes. The experience curve helped participants reflect on a particular sub-trajectory corresponding to the 'attending to feelings' in the reflective process [31].

The above outlined transformations were achieved by use of the timeline as a cognitive tool. The successful use of timelines in the study indicates that it is a good form of representation to aid both individual and collective recall and reflection.

Salomon [24

Here's the cleaned and normalized Markdown:

## A Model of Retrospective Reflection in Project Based Learning

By combining historical data and timelines, using historical data as a means for transforming the timeline and the timeline as a means for making sense of the historical data [11], we can leverage existing tools in new ways.

By reusing a computerized tool from one context (like day-to-day project work) as a cognitive tool for retrospective reflection, the expertise from the original tool usage may transfer to reflection. This utilizes the expertise of the joint learning system [23] of day-to-day work in transitioning to retrospective reflection on that work.

There are limits to insights gained from a single representation type like a timeline, even with sophisticated additions like individual experience curves. Not all aspects of project work fit a temporal/linear perspective. Some aspects may be better expressed through:

- Textual descriptions
- Diagrams 
- Role play

For example, a representation showing artifact structure and contributor roles may aid process reflection. Some synthesized project information likely exists in collaborative tools' historical data, like project plans. The timeline should be viewed both as a valuable representation itself and as a starting point for identifying and creating other representations by providing context and overview.

In the studies from Section 2, retrospective reflection occurred when projects were mostly complete. Students were expected to apply their experience to future projects, though this was assumed to happen through individual learning. Revisiting the reflective process model [31], outcomes include:

- New perspectives on experiences
- Behavioral changes
- Readiness for application
- Commitment to action

A successful retrospective reflection process should incorporate these into participants' internal representations and express some in external representations. However, actual experiential learning is best seen in subsequent project work, with retrospective reflection as part of a learning cycle [30]. For process improvement, lessons learned should be captured in representations applicable to future projects - a core challenge in organizational learning and knowledge management.

Many types of representational transformations may enhance retrospective reflection, achieved through both daily work tools and tools introduced specifically for reflection.

## Retrospective Reflection in Project Based Learning: A Model

Based on the previous analysis, we outline a model of retrospective reflection in project based learning and briefly illustrate with examples from Section 2.

The model in Fig. 3 illustrates retrospective reflection incorporating the main elements elaborated in Section 4, serving as a generic description of retrospective reflection utilizing individual and shared timeline representations as well as historical data from various collaborative tools used in the project. The rectangles represent internal or external representations, while ovals show transformation processes where new knowledge is constructed. Representations with outgoing arrows to processes serve as cognitive tools. Bidirectional arrows indicate representations that both inform and are changed by learning processes. Dashed arrows show historical data use in identifying events and sub-trajectories.

In detail:

1. Daily project work uses collaborative tools as cognitive tools, generating historical data. Tools contain continuously updated project representations, while participants develop internal project representations.

2. Individual retrospective reflection creates external timeline representations, potentially including sub-trajectories like satisfaction curves. Collaborative tools and their historical data can serve as cognitive tools.

3. Collaborative reflection uses individual timelines as cognitive tools to create shared timelines, mediated by internal representations. Historical data may still be referenced. Teams may create additional representations like reflection notes, some serving as cognitive tools in future work, completing the learning cycle.

The model simplifies the number of representations and transformations, implicitly including elements like oral timeline presentations and retrospective tool data transformation.

This model outlines main elements in distributed cognition during retrospective reflection and their dynamics. It can guide project-based learning reflection organization, though not all elements are required. Teams should consider tool features, daily usage patterns, and important reflection topics when deciding which collaborative tools to incorporate.

## A Model of Retrospective Reflection in Project Based Learning

## Conclusion

We have used empirical data from SD student projects to analyse retrospective reflection in the context of project based learning and develop a model outlining its elements and dynamics. On basis of distributed cognition, the model describes retrospective reflection as a set of transformations of representations of the project process, internal and external. A timeline of events is used as a cognitive tool. It fits the idea of process trajectories, is good for situating historical data in context, and is good for being shared and combined into a collaboratively constructed representation.

The scope of our analysis and model is project based learning in which lightweight collaborative tools are used to support various aspects of work. While the domain of our empirical studies is software development, the model may be used to aid the organization of retrospective reflection in project based learning within any domain.

Taking a constructivist view of knowledge, there is no single, 'real' story of a project that can be revealed through the use of timelines and collaborative tool history. Our approach can help participants unveil issues of importance to them and aid individual and collective sense making of various aspects of the project. We believe that the systematic approach, the explicit incorporation of individual contributions into collective, co-constructive learning activity, and the utilization of available resources in the form of historical data together result in reflection outcomes that are likely to be useful with respect to the learning objectives and valid in the sense that more stones have been turned.

The analysis presented in this work would have benefited from empirical data on the use of more types of lightweight collaborative tools in retrospective reflection in SD student projects or similar settings of project based learning. Further research should examine the use of different collaborative tools within the framework of the model. Results of this research can be used to validate the model.

## References

1. Blumenfeld, P.C., et al.: Motivating Project-Based Learning: Sustaining the Doing, Supporting the Learning. Educational Psychologist 26(3 & 4), 369–398 (1991)
2. Boud, D., Keogh, R., Walker, D.: Reflection: Turning Experience into Learning. Routledge Falmer (1985)
3. Dewey, J.: Democracy and education - an introduction to the philosophy of education. The Free Press, New York (1997) (1916)
4. Schön, D.: Educating the Reflective Practitioner. Jossey-Bass, San Fransisco (1987)
5. Lin, X., et al.: Designing Technology to Support Reflection. Educational Technology, Research and Development 47(3), 43–62 (1999)
6. Edwards, J.S., Shaw, D., Collier, P.M.: Knowledge management systems: finding a way with technology. Journal of Knowledge Management 9(1), 113–125 (2005)
7. Garrett, R.K., Danziger, J.N.: IM=Interruption Management? Instant Messaging and Disruption in the Workplace. Jnl. of Computer-Mediated Communication 13(1) (2008)
8. Grinter, R.E., Palen, L.: Instant Messaging in Teen Life. In: CSCW 2002, New Orelans, Louisiana, USA. ACM, New York (2002)
9. Krogstie, B.R.: Using Project Wiki History to Reflect on the Project Process. In: 42nd Hawaii International Conference on System Sciences, Big Island, Hawaii. IEEE, Los Alamitos (2009)
10. Krogstie, B.R., Divitini, M.: Shared timeline and individual experience: Supporting retrospective reflection in student software engineering teams. In: CSEE&T 2009, Hyderabad (2009)
11. Krogstie, B.R., Divitini, M.: Collaboration tools as a resource for retrospective reflection (submitted, 2010)

Here's the cleaned Markdown:

## References

20. Hutchins, E.: Cognition in the Wild. MIT Press, Cambridge (1995)
21. Salomon, G.: Distributed Cognitions. Cambridge University Press, New York (1993)
22. Karasavvidis, I.: Distributed Cognition and Educational Practice. Journal of Interactive Learning Research 13(1/2), 11-29 (2002)
23. Kim, B., Reeves, T.C.: Reframing research on learning with technology: in search of the meaning of cognitive tools. Instructional Science, 35, 207-256 (2007)
24. Salomon, G.: No distribution without individuals' cognition, in Distributed Cognitions. In: Salomon, G. (ed.) Psychological and educational considerations. Cambridge Univ. Press, Cambridge (1993)
25. Ackerman, M.S., Halverson, C.: Organizational Memory as Objects, Process, and Trajectories: An Examination of Organizational Memory in Use. Computer Supported Cooperative Work 13(2), 155-189 (2004)
26. Sharp, H., Robinson, H.: A Distributed Cognition Account of Mature XP Teams. In: Abrahamsson, P., Marchesi, M., Succi, G. (eds.) XP 2006. LNCS, vol. 4044, pp. 1-10. Springer, Heidelberg (2006)
27. Kirschner, P.A., Erkens, G.: Cognitive tools and mindtools for collaborative learning. Journal of Educational Computing Research 35(2), 199-209 (2006)
28. Dewey, J.: How we think. A restatement of the relation of reflective thinking to the educative process (Revised edn.). D. C. Heath, Boston (1933)
29. Kim, D., Lee, S.: Designing Collaborative Reflection Support Tools in e-project Based Learning Environment. Journal of Interactive Learning Research 13(4), 375-392 (2002)
30. Kolb, D.A., Fry, R.: Towards an applied theory of experiental learning. In: Cooper, C.L. (ed.) Theories of Group Processes, pp. 33-58. John Wiley, London (1975)
31. Boud, D., Keogh, R., Walker, D.: Promoting Reflection in Learning: a Model. In: Boud, D., Keogh, R., Walker, D. (eds.) Reflection: Turning Experience into Learning, pp. 18-40. Routledge Falmer (1985)
32. Strauss, A.: Continual permutations of action. Aldine de Gruyter, New York (1993)
33. Stahl, G.: Building collaborative knowing. In: Strijbos, J.-W., Kirschner, P.A., Martens, R.L. (eds.) What We Know About CSCL And Implementing It In Higher Education, pp. 53-85. Kluwer Academic Publishers, Boston (2002)
34. Wegner, D.M.: Transactive memory: A contemporary analysis of group mind. In: Mullen, M.B., Goethals, G.R. (eds.) Theories of group behaviour, pp. 185-208. Springer, New York (1987)
35. Hollingshead, A.B.: Retrieval processes in transactive memory systems. Journal of Personality and Social Psychology 74, 659-671 (1998)
36. Wegner, D.M., Guiliano, T., Hertel, P.T.: Cognitive interdependence in close relationships. In: Ickes, W. (ed.) Compatible and incompatible relationships

## Problem-Based Learning and Virtual Worlds

Problem-based learning involves applying knowledge to problems or scenarios within professional or clinical settings through interactive collaboration with colleagues, replicating real-life contexts. It has become influential across various curricula and subject areas. The growth of both problem-based learning (PBL) and online learning reflects a shift from teaching as information transmission toward supporting student-generated learning activities.

While PBL has traditionally been seen as a stable learning approach with specific characteristics, most explanations have focused on cognitive perspectives rather than the learner's ontological position. Facilitating collaborative participation becomes more challenging in self-directed and distance learning contexts due to geographical separation between learners.

Combining PBL with immersive virtual worlds (IVWs) brings additional challenges. Research has explored students' experiences with virtual learning environments and discussion forums, with findings indicating these experiences are more complex than initially thought [1][2][3]. There is growing interest in using immersive worlds for learning, particularly for workplace and competency-led courses, as case-based scenarios effectively develop knowledge and decision-making skills [4][5].

PBL involves students working in teams to solve problems [6], guided by a tutor to share knowledge and determine learning needs. While medicine and healthcare education have used PBL since the mid-1980s, recent years have seen movement toward online and immersive spaces [7][8]. Virtual environments offer advantages including exposure to diverse scenarios and flexible timing for learners.

### Informing Literature

Cyberspace has led to multiple identities and new forms of embodiment, with platforms like Second Life challenging assumptions about anonymity and presence. Traditional face-to-face PBL was popularized by Barrows and Tamblyn [9] following research at McMaster Medical School in Canada, where they found students struggled to apply knowledge in practical situations despite learning content.

PBL online involves teams of 4-6 students working collaboratively on problem scenarios, either synchronously or asynchronously. Key elements include:

- Collaborative problem-solving
- Synchronous collaboration tools (chat, whiteboards, video conferencing)
- Negotiated learning objectives
- Facilitation through tutor oversight
- Web-based learning materials

The PREVIEW project exemplifies this approach, investigating implementation of virtual worlds with interactive PBL online to create immersive collaborative tutorials.

Virtual environments offer several advantages:
- Exposure to diverse scenarios
- Flexible timing for learners
- Safe space for mistakes without real-world consequences
- Consistent feedback

## Fortress to Demi Paradise?

New learning spaces and emerging technologies such as wikis and podcasts offer new possibilities in terms of communication in distance learning, but also present limitations and barriers in terms of the presentation of the self, meaningful synchronous interaction, and team-building. For these reasons, caution must be exercised when making claims for their equivalence to the communicative modalities of the face-to-face setting. When seeking to implement PBLOnline, purpose-built educational virtual learning environments (VLEs) such as Blackboard may also be limited and limiting. These digital spaces (VLEs) have prompted concerns about both containment and exteriorisation in online environments [10]- containment is particularly evident in VLEs, inherent in their structuring and management of learning.

However, in order to facilitate meaningful engagement in PBL in the online environment, the need for creative and authentic self-representation, a sense of co-presence, immediacy, and rich multimodal communicative spaces should also be addressed. This will provide an environment in which a pseudo-authentic feel, complexity and a sense of 'messy' decision-making that occurs in real time can be achieved. Although resources and environments for PBLonline have been developed, they have not hitherto provided this degree of immersion.

With these issues in mind, the PREVIEW (Problem-based learning in virtual interactive educational worlds) project was initiated, in order to investigate the feasibility of using a virtual world to deliver problem-based learning to distance learning students, and to better understand the potential of participation in this environment and the benefits and challenges it offers collaborative working and learning. The project team, led by Coventry University and its partner St George's University of London (SGUL) implemented and evaluated a user-focused approach to developing problem-based learning environments and 'good practice' materials.

This was achieved by linking the emerging technologies of virtual worlds with interactive PBL online to create immersive, collaborative tutorials in the virtual world of Second Life (SL), which allows distance learners from the geographically distant institutions to meet 'in-world' and collaborate around a case. This environment differs radically from the VLE in that it draws on a primarily visual set of semiotic resources with each participant having an online presence, or avatar, to aid their communication.

The aims of the PREVIEW project were to:
1. deliver problem-based learning in Second Life
2. develop eight interactive PBL scenarios
3. guide development and evaluation alongside users
4. develop guidelines and best-practice on delivering PBL in virtual environments
5. share outputs and technology

A variety of problem-based learning scenarios were developed within SL for distance-learning students at the two institutions. The project was introduced to the part-time MA in Health and Social Care Management, a distance online programme for students across the midlands of England. The project was also implemented on the second year of the Paramedic Foundation Degree at Coventry University. This is a three-year in-service blended learning programme, with 70% of its materials provided via Blackboard, to practice-based students based in London and various locations in the south of England. The PBL scenarios were categorised in two ways: information-driven scenarios via machinima videos, and avatar-driven scenarios using artificially intelligent SL avatars, otherwise known as chat bots.

PBL scenarios were developed for use within Second Life. For each course, two avatar-driven scenarios were to be developed, as well as two information-driven scenarios.

**Avatar-Driven:** The PBL was set in appropriate surroundings (e.g. at the patient's home, in the hospital ward) and the patient or staff member was represented by a non-player character (NPC). Initial information was given by the NPC or pre-recorded avatars, such as (an avatar discussion in) a machinima, and the students would then discuss how to proceed, as in any PBL. Additional information was presented on display screens (via text, image, video, animation or external links), notecards, touchable objects or sound streams or through

## Implementing and Evaluating Problem-Based Learning in Virtual Worlds

## Project Outcomes and Future Possibilities

It was anticipated that the technological demands and initial lack of user friendliness of SL would be a barrier to participation. However, when the PREVIEW project underwent testing by staff and students, few access barriers were reported, although this may become more of an issue with wider implantation of this approach. However, students who were beginners to the SL environment needed more time than anticipated to explore and experiment with the virtual world, and familiarize themselves with the new environment; mock scenarios became an important strategy in this process. This suggests that a degree of initial strangeness and discomfort may have been experienced by the participants, which is significant when considering that they would need a tolerable degree of conformity with the visual/kinetic/semiotic resources of the world and their avatar identity, before they could devote meaningful attention to group collaboration around a problem.

Preliminary results from the project indicate that SL holds a great deal of potential for PBL. Students seemed able to use their avatars to communicate, collaborate and problem solve effectively. The level of realism and immersion of the scenarios seemed to be enhanced by the virtual world environment, including the option to use voice in addition to text-based communication, and students reported that it felt like a more 'authentic' learning environment than PBL based in VLEs. Students responded enthusiastically to the environment, interestingly tending to initially treat it as a 'game'. This (common) association of the look and feel of SL with online gaming may arguably be a limitation in the educational setting - in that it could encourage individualism rather than collaboration, and may simplify scenarios in which more nuanced critical engagement is required and no one clear solution is available. However, it is likely to also be an advantage in that it may increase student enjoyment and motivation via memorably novel forms of participation.

This project developed an innovative approach to address problems faced by courses which wish to use collaborative scenario-based learning as a tool for the learning of competency, but are restricted in their opportunities for face to face learning. The approach took advantage of the new opportunities offered by immersive, 3-dimensional multi-user virtual environments (MUVEs) which provide the authenticity of a simulated real-world environment, and the open-ended nature of in-world activity. This may not be the first time that an attempt has been made to develop immersive scenarios, however we believe this may be the first use of PBL in immersive worlds in this way. Furthermore we believe this work goes some way to engaging with the taxonomy suggested by Schmidt and Moust[11] for using problems in order to acquire different kinds of knowledge, rather than solving problems or covering subject matter. The importance of the work undertaken by Schmidt and Moust is not only the way they provide and explicate different problem types, but also their exploration of the way in which the questions asked of students guide the types of knowledge in which students engage.

A particular strength of Second Life as a learning environment is that it provides a variety of communication tools which are particularly important for PBL. Furthermore to date problem-based learning has been seen as a relatively stable approach to learning, delineated by particular characteristics. Using PBL in Second Life embraces issues connected with complex curriculum design and the need for complex PBL scenarios to be developed. All the planned scenarios were delivered, and significant changes were made during development to take most advantage of Second Life's strengths. Students appreciated the value of Second Life as a collaborative environment, but also viewed such practice-based simulations as valuable for individual work.

An interesting consequence of the richness and authenticity of the Second Life scenarios is the large amount of detail provided, much more than is usual in paper-based face-to face PBL sessions. Second Life can provide a more authentic learner environment than classroom based PBL and therefore changes the dynamic of facilitation, but at this stage it is not clear how such detailed virtual reality impacts on the way the scenario is used and facilitated. While the facilitators expressed the view that the scenarios produced were appropriate and fit for purpose, it is revealing that none would currently

Here's the cleaned Markdown:

## Project-Based Collaborative Learning Environment with Context-Aware Educational Services

Teaching and learning software design patterns (DPs) is not an easy task. Apart from learning individual DPs and the principles behind them, students should learn how to apply them in real-life situations. Therefore, to make the learning process of DPs effective, it is necessary to include a project component in which students, usually in small teams, develop a medium-sized software application. Furthermore, it is necessary to provide students with means for easy discovery of relevant learning resources and possible collaborators.

This project has a user-centered approach and has provided a strong pedagogical underpinning to the use of virtual worlds in higher education. Developing open source pedagogically driven PBL scenarios such as these may offer a new liquidity to learning, combining technology with pedagogy in ways that are mutually beneficial not only in distance education, but also as a means to enrich the face-to-face learning environment. However, these environments must be examined not only in terms of the new freedoms they may afford, but also in recognition of their intermittently strange and 'troubling' nature, which may in itself provide potential for creativity[13]. In doing so, we may extend the scope of our enquiry - not only considering what 'learning' means in such spaces, but also addressing more fundamental questions raised, such as the nature of emergent modalities of educational communication, practices and identities in the 'digital age'. Such a vision however, will require that we stop seeing the curriculum as a predictable, ordered and manageable space, but instead re-view it as an important site of transformation characterised by risk, uncertainty and radical unknowability.

### References

1. Sharpe, R., Benfield, G., Lessner, E., DeCicco, E.: Learner Scoping Study: Final Report (2005), http://www.jisc.ac.uk/index.cfm?name=elp_learneroutcomes
2. Creanor, L., Trinder, K., Gowan, D., Howells, C.: LEX. The learner experience of e-learning final report (2006), http://www.jisc.ac.uk/uploaded_documents/LEX%20Final%20Report_August06.pdf
3. Conole, G., de Laat, M., Dillon, T., Darby, T.: JISC LXP Student experiences of technologies – final report. JISC report (November 2006)
4. Scalese, R.J., Obeso, V.T., Issenberg, S.B.: Simulation technology for skills training and competency assessment in medical education. J. Gen. Intern. Med. Suppl. 1, 46–49 (2008)
5. Bergin, R., Fors, U.: Interactive Simulation of Patients – an advanced tool for student-activated learning in medicine & healthcare. Computers and Education (40/4), 361–376 (2003)
6. Savin-Baden, M.: Problem-based Learning in Higher Education: Untold Stories. Open University Press/SRHE, Buckingham (2000)
7. Conradi, E., Kavia, S., Burden, D., Rice, D., Woodham, L., Beaumont, C., Savin-Baden, M., Poulton, T.: Virtual patients in Virtual World: Training paramedic students. Medical Teacher (2009)
8. Savin-Baden, M.: A Practical Guide to Problem-based Learning Online. Routledge, London (2007)
9. Barrows, H.S., Tamblyn, R.M.: Problem-based Learning, an approach to Medical Education. Springer, New York (1980)
10. Land, R.: Paradigms Lost: academic practice and exteriorising technologies. E-Learning 3(1), 100–110 (2006)

## Project-Based Collaborative Learning Environment

## Project Background and Approach

All the specificities of learning software DPs indicate the need for the social constructivist approach in SE education, as well as educational services that provide students with right in time advices about learning resources and possible collaborators. In particular, an active learning paradigm is needed which recognizes that student activity is critical to the learning process [3]. Following this paradigm, we have developed DEPTHS (Design Patterns Teaching Help System) [4] - a learning environment for project-based and collaborative learning of DPs. DEPTHS integrates an existing Learning Management System (LMS), a software modeling tool, diverse collaboration tools and relevant online repositories of software DPs. The integration of these different learning systems and tools into DEPTHS environment is achieved by using ontologies. We have also built context-aware educational services that are available throughout the DEPTHS environment. These services enrich and foster learning processes in DEPTHS in two main ways:

1. By recommending appropriate learning content (i.e., Web page(s), lessons or discussion threads)
2. By recommending peers (students, teachers or experts) that are currently dealing with or have experience in the same or a similar software problem

## Project-Based Learning in DEPTHS

Having in mind that effective learning of software DPs requires a constructivist approach to be applied in the teaching process, we have identified two most important theories in this field: Project-based learning (PBL) and Engagement theory. PBL is a teaching and learning model that organizes learning around projects. Projects comprise complex tasks and activities that involve students in a constructive investigation that results in knowledge building. 

The engagement theory is based upon the idea of creating successful collaborative teams that work on tasks that are meaningful to someone outside the classroom [5]. Its core principles are:

- "Relate": emphasizes characteristics such as communication and social skills involved in team effort
- "Create": regards learning as a creative, purposeful activity
- "Donate": encourages learners to position their learning in terms of wider community involvement

Later research inspired by this approach suggests a generic framework called "Genex framework" [6], that describes four phases a creative process will most likely pass through: "Collect" (regarding searching and browsing digital libraries, visualizing data and processes), "Relate", "Create" and "Donate". Based on the guidelines for teaching SE to students (e.g., [1]), and our own teaching experience, we believe that the presented theories provide a solid base for effective learning of software DPs. Accordingly, we based the DEPTHS framework on them.

A typical scenario for learning software patterns with DEPTHS assumes a PBL approach with collaborative learning support. In particular, a teacher defines a specific software design problem that has to be solved in a workshop-like manner by performing several predefined tasks: brainstorming, creating and submitting solutions, evaluating solutions etc. These activities enable and even foster active learning that has strong foundation in the engagement theory and Genex's framework.

Brainstorming has foundation in two Genex's phases, collect and relate. First, a student is asked to present his ideas about possible ways for solving the problem under study and to discuss and rate his peers' ideas. In order to get enough information to perform this task, he needs to search online repositories about software DPs and other related course content. DEPTHS makes this search more effective by providing semantically-enabled context-aware learning services for finding related online and internally produced resources. Moreover, to get some initial directions on the performing task, the student uses semantically-enabled peers finding service to find people who have shared interests and are engaged in similar problems.

Genex's phase create is found in several DEPTHS activities, namely exploring earlier works on similar problems, creating design artifacts using software modeling tool or evaluating peers' solutions. Having acquired the required knowledge, students should complete the deliverable using the software modeling tool. This kind of learning activity requires students to externalize their knowledge, to analyze possible solutions and to provide a design rationale. After completing the project, students are asked to evaluate their own and other students' projects. Students reflect critically on their own and others' contributions, an

Here's the cleaned and normalized Markdown:

## Educational Services in DEPTHS

During the last couple of years context-aware learning has gained a constantly increasing attention of the e-learning research community. Despite different interpretations of the term 'context' by different authors, researchers seem to agree that a learning context is about the environment, tools, resources, people (in terms of social networking), and learning activities. Being more specific, context in learning systems is mostly characterized by the learners, learning resources and a set of learning activities that are performed in the light of a specific pedagogical approach [7].

In order to provide effective, context-aware learning in DEPTHS we have developed supporting services: Semantic Annotation and Context-aware Learning Services.

Semantic Annotation Service is used for annotating online resources in publicly accessible repositories of DPs, as well as software models created by students. It analyses the text of each resource, recognizes specific domain topics (i.e., software DP's name), creates the semantic-rich metadata (based on the ontology of software DPs) and stores them in the DEPTHS's repository of LO.

Context-aware learning services are accessible to all systems and tools integrated in the DEPTHS framework and are exposed to end users (students) as context-aware learning features. They are based on Semantic web technologies, and include:

- Web resource finding. Based on the student's current learning context, this service generates a list of recommended Web resources from publicly accessible repositories of software DPs. To do this, it computes the relevance of each resource (i.e., Web page) available from these repositories for the student's current learning context and selects the most relevant pages for the student. The computation of relevancy of a Web resource is based on two kinds of semantic metadata: 1) the semantic metadata assigned to the resource by the Semantic Annotation Service and 2) the formal (i.e. ontology-based) representation of the student's current learning context.

- Discovery of relevant internally produced resources. This service suggests internally created resources (e.g., discussion threads, comments…) that could be useful for a student to solve a problem at hand in the given learning context. The computation of relevance is done in a similar manner to the one applied for external, Web resources.

- Experts, teachers and peers discovery. Based on the current learning context, this service suggests other students or experts as possible collaborators. Collaborators are selected and sorted using an algorithm which considers their competences on three different levels: same content (i.e. current software problem), similar or related learning content (i.e. similar software problem) and broader content (i.e. software problem in the same course). Estimation of the peer's competence on each level is performed through assessing three types of competence indicators: 1) participation in learning activities, 2) knowledge level estimated by the teacher and through peers' evaluations and 3) social connections with the peer asking for help.

We have implemented DEPTHS by leveraging open-source solutions and extending them with Semantic web technologies. Specifically, we have integrated Moodle (http://moodle.org) LMS, ArgoUML (http://argouml.tigris.org) software modeling tool, OATS (Open Annotation and Tagging System) tool for collaborative tagging and highlighting (http://ihelp.usask.ca/OATS) and LOCO-Analyst tool to provide teachers with feedback regarding students' activities [7]. Moreover, we have extended both Moodle and ArgoUML with the above described context-aware educational services and developed a Moodle module for project-based collaborative learning.

## Evaluation

The evaluation of DEPTHS was conducted in February 2009, in the context of a course on software development taught at the Department of Computer Science of Military Academy in Belgrade, Serbia, with a group of 13 students of the fifth year of the computer science program. The students were divided into 4 groups (3 groups with 3 students and 1 group with 4 students), based on the teacher's subjective opinion about their knowledge and their grades in courses

Here's the cleaned and normalized Markdown:

## Semantic Web Technologies for Learning Software Design Patterns

Aiming to develop a learning environment that would allow for effective learning of software DPs, we leveraged semantic technologies to integrate several existing learning systems and tools, and develop context-aware educational services. Our present implementation and first evaluation results convince us that this environment could significantly contribute to effective teaching and learning of DPs. Semantic Web technologies facilitate development of beneficial educational services that makes search for relevant resources and possible peers fast and effective.

We are encouraged with the results of the initial evaluation study that show very positive students' attitude toward learning in DEPTHS learning environment. Students' perception of system's usefulness is valuable and encouraging for our further research. However, the results we got still do not have a statistical power, as the participants' sample was too small. Further research is required that would include sufficient participants to ensure the general applicability of the findings. In addition, in our future work we intend to do a more precise evaluation of each specific educational service as well as a quantitative evaluation of the students' learning effectiveness.

### References

1. Jazayeri, M.: The Education of a Software Engineer. In: Proc. of the 19th IEEE Int'l Conf. on Automated Soft. Eng., pp. xviii-xxvii (2004)
2. Gamma, E., Helm, R., Johnson, R., Vlissides, J.: Design Patterns: Elements of Reusable Object-Oriented Software. Addison-Wesley, Reading (1995)
3. Warren, I.: Migrating to a Teaching Style that Facilitates Active Learning. CiLTHE Stage 1 Dissertation, Lancaster University (2002)
4. Jeremic, Z., Jovanovic, J., Gasevic, D.: Towards a Semantic-rich Collaborative Environment for Learning Software Patterns. In: Dillenbourg, P., Specht, M. (eds.) EC-TEL 2008. LNCS, vol. 5192, pp. 155–166. Springer, Heidelberg (2008)
5. Kearsley, G., Schneiderman, B.: Engagement theory: A framework for technology-based learning and teaching (1999), http://home.sprynet.com/~gkearsley/engage.htm
6. Shneiderman, B.: Creating Creativity: User Interfaces for Supporting Innovation. ACM Trans. on Computer-Human Interaction 7(1), 114–138 (2000)
7. Jovanović, J., Gašević, D., Brooks, C., Devedžić, V., Hatala, M., Eap, T., Richards, G.: Using Semantic Web Technologies for the Analysis of Learning Content. IEEE Internet Computing 11(5) (2007)
8. Baghaei, N., Mitrovic, A., Irwin, W.: Supporting collaborative learning and problem-solving in a constraint-based CSCL environment for UML class diagrams. International Journal of CSCL 2(2-3), 150–190 (2007)
9. Ghidini, C., Pammer, V., Scheir, P., Serafini, L., Lindstaedt, S.: APOSDLE: Learn@work with semantic web technology. In: I-Know 2007, Graz, Austria (2007)
10. Yanlin, Z., Yoneo, Y.: A Framework of Context Awareness support for peer recommendation in the e-learning context. British Journal of Educ. Techn. 38(2), 197–210 (2007)

## Constructing and Evaluating a Description Template for Teaching Methods

Michael Derntl¹, Susanne Neumann², and Petra Oberhuemer²

¹ University of Vienna, Research Lab for Educational Technologies  
Rathausstrasse 19/

## Constructing and Evaluating a Description Template for Teaching Methods

Because of the slow uptake of the IMS LD specification, several initiatives have begun to foster distribution and reuse of teaching methods resulting in a great number of competing formats for describing teaching methods. None of the formats, however, has yet reached a wide acceptance (compare e.g. [4]).

In the context of the ICOPER project[^1], which is co-funded by the European Commission in the eContentplus programme, the two abovementioned efforts with respect to the documentation of teaching methods and the use of the standardized modeling language IMS LD will be brought together. This is achieved by first developing a fit for purpose teaching method description template, and second, by examining the potential of the IMS LD specification's concepts and language to model the teaching methods described that way. This paper describes development efforts and evaluation results regarding the teaching method description template. The use of a template-based approach to describing teaching methods as opposed to freeform or narrative approaches is grounded in the fact that a structured template provides a scaffold for more effective and efficient authoring, communication, searching, and comparison of descriptions, particularly when descriptions are provided by a multitude of practitioners and authors. This is aligned with the current trend towards more consistent and common ways of documenting teaching methods [5].

## Structure

The next section introduces the methodology behind the construction of the description template and the resulting template. Section 3 details the process and outcome of collecting teaching methods from instructors using the new template; it also presents the process of evaluating the description template and discusses the outcomes of the evaluation. Section 4 concludes the paper and gives an outlook on further research.

## Constructing the Teaching Method Description Template

### Methodology

To approach the task of constructing a new teaching method description template, fourteen existing description schemas for teaching methods were reviewed including pattern catalogs (e.g. [6]), learning design repositories (e.g. [7]), and pedagogic scenario collections (e.g. [8]). These collections employed different descriptive elements (e.g. title, objectives, learning outcomes, activities, etc.) for describing teaching methods. In a first step, we analyzed the frequency of occurrence of descriptive elements. The process of distilling elements from the collections was executed as follows:

1. Extract the elements that are used to describe teaching methods in the collection;
2. Match each element to either a previously identified element of another collection or define a new element that is distinct from existing ones.

While the frequency of occurrence of an element in existing collections is certainly useful information, it cannot reasonably be used as the exclusive criterion for creating a new description template. Therefore, a method for the final selection of elements was established. The foundation for this process was the JISC funded Mod4L project [9], where information needs of instructors during browsing, selecting, developing, and implementing teaching methods were investigated. The Mod4L researchers collected those information needs during practitioner workshops. They identified over 60 information elements and collected practitioner "requests" for these elements during the four phases mentioned above.

Since the outcomes of this project were obtained through practitioner involvement, we decided to rely, as a first step, on a selection of those elements that were requested most frequently. However, we discovered that after this step some elements, which were prominently included in the collections we analyzed, were still missing. So we complemented in a second step these elements of the Mod4L workshop with frequently occurring elements in our aggregation matrix and necessary elements like copyright.

### Results

As a result of the above methodology we identified more than forty distinct elements from existing collections of teaching practice. The top ten elements were: sequence/activities (14 occurrences), delivery context (13), educational approach (12), learner profile (12), name/title (9), group size (9), author (8), resources (8), goals/aims (7), and tools (7). After the second step, in which the identified elements were complemented and adapted based on findings from the Mod4L project, the resulting set of description elements was split up into two sections: a "teaser" section offering essential information for browsing and selecting,

Here's the cleaned and normalized Markdown:

## Constructing and Evaluating a Description Template for Teaching Methods

## Template Elements

### Teaser Section
- Subject/discipline: In what (topical) area of study can this teaching method be used (Example: Civil engineering, geo-technology and hydraulic engineering)
- Learning outcomes: The intended goals for learning (Example: Learners are able to calculate forces on dams.)
- Group size: The approximate number of participants suitable for this teaching method (Example: The method is ideal for 15-20 participants, max. 30 participants.)
- Duration: The amount of time it takes to complete the teaching method when it is being used/implemented (Example: 2 hours, if it is a large group 3 hours)
- Learner characteristics: Description of the "target group" of this teaching method, i.e. the learners' age, level within the curriculum, previous knowledge, special attributes, or qualities (Example: 15-35 years of age, introductory stage in college, high knowledge of technology)
- Type of setting: The setting in which the teaching method is intended to be implemented (Example: Distance learning, blended learning, face-to-face)

### Detailed Information Section
- Graphical representation: A depiction of the teaching method. (Example: flow chart, activity diagram, swim lanes). The template included here an example screenshot of an activity diagram, and a hyperlink to the Graphical Learning Modeler, an open source tool for IMS Learning Design compliant modeling of teaching methods and units of learning.
- Sequence of activities: Detailed description of all activities (including assessment) performed by the participants as part of the teaching method as well as the activities' temporal sequence (Example: 1. [Presenter] Present the concepts to be learned for ten minutes; 2. [Learner] Share and reflect together with another learner what has been presented in the last ten minutes; 3. [Presenter] Repeat steps 1 and 2 as necessary.)
- Roles: Name and short description of roles that the participants take within the teaching method (Example: tutor, moderator, discussion participant, expert)
- Type of assessment: The intended method for assessing learners' progress and learning outcomes (Example: portfolio, multiple-choice test, oral exam)
- Resources: Detailed description of the requirements for implementing the teaching method including room equipment, IT infrastructure, software, virtual learning environment, personnel resources, learning materials, and other supports (Example: flip chart, projector, forum or chat, at least 5 tutors, facilitator's toolkit, study guide)
- Alternatives: Description of possible variations of the teaching method (Example: To ensure that all participants contribute ideas during brainstorming, you may use note cards for collecting ideas instead of contributing ideas by shouting. Each participant writes their ideas on note cards and then shares them publicly.)
- Teacher reflection: Description of experiences that teachers have had when implementing the teaching method, benefits and opportunities, risks and threats (Example: Method works well when learners are active contributors. Preparatory effort of this method is high.)
- Student feedback: Description of feedback that students have given when they learned with the teaching method (Example: Students liked the active participation during this method. Some students were afraid of the ill-structured nature of the method, because a lot of the responsibility is shifted to the students' side. This may cause discomfort.)
- Peer review: Evaluation of the quality of the teaching method by a qualified peer or a colleague instructor (Example: The teaching method fulfills five of the seven principles of good teaching practice.)
- Comments: Any comments from people who have read or applied the teaching method.
- References: Any references to the original source of the teaching method, background literature, or to resources used within the method (Example: Reigeluth, C.M. (1999). Elaboration Theory. In Reigeluth: Instructional Models – The New Paradigm. Mahwah, NJ: Lawrence Erlbaum.)

## Evaluating the Template

## Constructing and Evaluating a Description Template for Teaching Methods

## Evaluation Criteria and Method
The descriptions were derived from Lambe [12] among others. Participants (n = 22) rated the following criteria on a five-point Likert scale from strongly agree (5) to strongly disagree (1):

- Completeness: the template covers all relevant aspects of a teaching method; there are no descriptive elements missing.
- Clarity: it was clear, what the descriptive elements in the template meant.
- Allocation: it was easy to allocate information regarding the teaching method within the descriptive elements of the template.
- Understandability: the descriptive elements in template support the reader's understanding of the teaching method.
- Distinctiveness: the descriptive elements of the template are distinctive, i.e. they do not overlap.
- Appropriateness: a structured template (compared to, for instance, a narrative) is an appropriate instrument for representing teaching methods to support readers in browsing, selecting and implementing teaching methods.
- Reusability: the template supports reusability of described teaching methods for myself as well as for others.
- Added value: filling out the template provides added value for my own work/teaching (e.g., it fosters personal reflection, supports documentation, fosters exchange with colleagues, etc.)
- Durability: the template seems durable, i.e. it seems unlikely that it needs to be changed in the (near) future.

## Results
We collected 34 diverse teaching method descriptions, including common methods like role play, brainstorming and reflection, as well as less common ones like resource-based analysis and online reaction sheets. Most methods had durations under one day, with blended and online methods typically lasting longer. The majority included online elements, while about one-third were primarily face-to-face.

The evaluation ratings showed that five criteria scored an average of at least 4 points: completeness, clarity, allocation, understandability and reusability. These also had the lowest standard deviations, indicating strong agreement among participants.

The template was considered complete (M = 4.05, SD = .79), though some participants suggested additions like more detailed activity descriptions and theoretical linkages. Clarity received the highest rating (M = 4.32, SD = .66), showing the template elements had meaningful titles and purpose. Correlation analysis revealed clarity had significant positive correlations with distinctiveness (r = .753, p < .01) and appropriateness (r = .552, p < .01).

[Figure 1 showing evaluation results histogram omitted]

Here's the cleaned Markdown:

## Constructing and Evaluating a Description Template for Teaching Methods

The template proved to be easy for most participants (M = 4.05, SD = .79). This criterion has a positive correlation with understandability (r = .440, p < .05), appropriateness (r = .481, p < .05) and added value (r = .576, p < .01), indicating that people who find it easy to allocate information to descriptive elements in the template also perceive added value (e.g. supporting reflection and documentation) in filling out the template. It also seems reasonable to assume that people who find it easy to allocate information to elements of a structured description tend to expect that this description will be easy to understand by readers.

The most controversial criterion was the distinctiveness of the template's elements, having the lowest average value (M = 3.32) and the highest deviation (SD = 1.25). However, low distinctiveness is not necessarily a negative property of a set of description elements. For example, the elements describing roles, sequence of activities, and graphical representation were deliberately designed to be non-distinctive in the sense that they view the same concepts from different perspectives. As one comment reads, "there is some overlap but I think that may be inevitable."

The appropriateness of using a structured description template for describing teaching methods was rated fairly high (M = 3.91, SD = 1.02). Participants who gave high ratings for clarity, allocation, distinctiveness and added value, also tended to give a high rating to the appropriateness (p < .05, respectively).

Reusability of teaching method descriptions using the template was rated high (M = 4.00, SD = .76). However, as one participant commented this judgment is "based on expected benefit, not on real experience." Another participant stated that it might help her reuse the teaching method but may not help others. The actual reusability of teaching method descriptions needs to be tested in practice.

The added value perceived during the writing of the teaching method received a moderately high average rating with considerable deviations (M = 3.55, SD = 1.10). The comments were controversial. For instance, one participant mentioned that "working on activity descriptions is [hard but] this is the core of reflecting on learning situations." Others mentioned that "there's no particular incentive" in filling out the template and that "reflecting and sharing might be quite different processes [needing] quite different types of descriptions and templates." Rating data showed that judgments of added value correlate with easy allocation of information to template elements (r = .576, p < .01) and with perceiving structured templates as an appropriate description format for teaching methods (r = .428, p < .05).

Finally, the durability of the template was rated moderately high (M = 3.41, SD = 1.05), with some hoping for changes ("I hope the order of presentation changes"), and some simply stating that this would be "difficult to predict."

### Evaluation Phase II

#### Methodology

The purpose of phase II was to evaluate the effectiveness of the template in regard to transferring a teaching method described by someone else into one's own teaching context. Evaluators received for this phase an evaluation form that consisted of three parts:

1. A teaching method description that was written by another evaluator
2. A continuous rating scale ranging from "very confident" to "not at all confident" for judging how high evaluators estimate their ability to transfer the described teaching method into their own teaching contexts
3. A form that asked evaluators to choose up to three description elements (like duration or group size) they would remove from the template, and to specify up to three description elements they would add to the template. This part also included a text box to justify each of the suggestions for adding or removing elements in the template.

Of the 34 teaching methods collected in phase I, three were selected to be included in the phase II evaluation. These three teaching methods were selected because they were described using extensive and cohesive information, and because they represented a range of teaching methods differing especially in terms of duration, type

## Constructing and Evaluating a Description Template for Teaching Methods

## Elements Proposed for Removal

Table 1. Elements proposed by evaluators to be removed from the description template including number of nominations and example comments

| Element | # | Extracts from comments |
|---------|---|----------------------|
| Peer review | 9 | "Usually empty" — "It seems interesting, but not available" — "Not useful in any of the three cases" — "I do not understand what that is" — "Might be very subjective" |
| Graphical representation | 7 | "Is repeated in sequence part" — "Too complicated for rather self speaking methods" — "I am used to other graphical representation, so I do not consider the current one very helpful or intuitive" — "Sketch or situation photo might be more helpful" |
| Alternatives | 5 | "Not very important" — "I cannot see how one can find alternatives – maybe variations" — "I should be able to find my own alternatives for my own settings" |
| Roles | 5 | "Do not need to be redefined separately if you already describe the activity first" — "Already described in the sequence of activities" — "The introduction makes it quite clear which roles are taken by whom, thus I think this point is just not necessary" |
| Comments | 4 | "Redundant to teacher reflection" — "Usually empty" |
| Duration | 4 | "Depending on the target group" (3x) — "The duration can be roughly estimated [by the reader]" |

As evident from Table 1, "peer review" received the most nominations (9) for removal. The problem with this element was that it was empty in all of the three selected teaching methods. Accordingly, some evaluators who suggested removing this element commented that "it was usually empty." If provided, this can be a useful element to have opinions of colleagues on the teaching method, e.g. regarding criteria of good teaching practice. One evaluator made a suggestion to rename this element to "evaluation of the method", which might be a more intuitive title for the element. Similar feedback was given regarding the elements "comments" and "student feedback" since they were also mostly empty in the teaching methods. Naturally, empty description elements are not seen as helpful.

The frequent votes for "graphical representation" to be removed came as a surprise, since this element was intended as a complementary visual representation of the "sequence of activities" to help readers get a quick overview and keep the overview while developing the teaching method. The frequent nominations for removal of this element may have been caused by the visualization using the software Graphical Learning Modeler³: All three of the selected teaching methods had a visualization using this software. Evaluators often mentioned that they could not interpret this particular activity diagram (e.g. they did not understand the icons used in the activities), which is specific to the software environment and not targeted towards general teaching method depictions. On a positive note, the evaluations of the teaching methods frequently contained comments in which evaluators mentioned that the graphical representation helped them to a better understanding by visualizing the sequence of activities, explaining the method and providing a quick overview.

## Elements Proposed for Addition

Table 2. Elements proposed by evaluators to be added to the description template including number of nominations and example comments

| Element | # | Extracts from comments |
|---------|---|----------------------|
| Examples | 14 | "Briefly described, it would clarify the method" — "Image of a real setup: to get it fast explained" — "Useful to have a comparison with a real case" — "Would make it easier to understand the teaching method" — "The general description helps to understand the idea [...], but an example is very useful for the fine tuning" |
| Potential problems | 5 | "Key Issues: A section with main clues and critical issues" — "Threats/weaknesses of the teaching methods: To know, what could be a possibility for 'failure'" — "Liabilities/drawbacks: Is there anything that could go wrong?" |
| Backgroun

Here's the cleaned and normalized Markdown:

## Constructing and Evaluating a Description Template for Teaching Methods

Almost half of the evaluators suggested descriptions of concrete examples to be included in the template. The teaching methods are described in a generic way, since it is important to distil properties of teaching practice that are transferable to other contexts [14]. However, it is often difficult to imagine the method in practice without having concrete examples, and some studies found that practitioners prefer to implement teaching methods based on concrete examples rather than generic descriptions [15,16]. We have deliberately not included an example section in the template. Our plan is to provide examples as units of learning alongside the generic teaching methods. A unit of learning refers to a contextualized, complete, self-contained unit of education or training that consists of a teaching method and associated content (adapted from [17]).

The suggestions to include "potential problems", also referred to as "key issues" or "threats" by some evaluators, would help in giving useful hints for practitioners during implementation of the teaching method. The call for "background" on theory and foundations of a teaching method to be included in the template is certainly meaningful. The problem with such an element may be that it would presumably be empty in most teaching method descriptions, because collecting and presenting theoretical background information is a challenging and time-consuming task for authors. Also, the background information could be integrated into the summary, rationale, and other existing elements to support the description.

Information on "preparation" for implementation was suggested by three evaluators. This seems to fit into the "teacher reflection" element. The fact that two evaluators suggested to add "student skills" as a separate element may either suggest that not all evaluators have read the teaching method descriptions carefully or that this information was missing in the "learner characteristics" or "learning outcomes" element of the teaching method they have read depending on what evaluators referred to prerequisite or target skills by suggesting this additional element.

### Discussion of Different Views During Phase I and II

A look at the results of the two evaluation phases reveals an interesting observation: even though the template was considered highly complete by authors during phase I of the evaluation, readers in phase II provided numerous suggestions for modifying the template. Of the 22 participants, who provided evaluations of the appropriateness of the description template along with their description of a teaching method in phase I, 16 also participated as evaluators in phase II. As one would expect, those participants who judged the template to be complete in phase I had fewer suggestions for extension of the template in phase II: there is a significant negative correlation between the rating of completeness and the number of nominations for elements to be added to the template (r = −.544, p < .05).

Nevertheless, the high number of suggestions by evaluators to extend the template in phase II clearly points to the fact that understanding teaching method descriptions written by someone else can be a very difficult endeavor. One explanation could be that authors are using the template to provide "their own" teaching method, while the readers are confronted with a representation provided by someone else, and thus may require additional information on issues that were clear or not worthy of mention to the author. Put another way, authors seem to be more likely to perceive a "lossless" transformation of their mental representation of a teaching method into written form than readers trying to recreate a mental representation of the teaching method from the written descriptions. This could be due to the fact that authors closely connect the implementation context of the teaching method in their mental representation, even if they describe the method in a generic way. Readers, however, just have the generic description and lack the information on the implementation context, making it harder to create a vivid representation. The unit of learning accompanying a generic teaching method may be able to resolve this conflict as the example could serve to aid the buildup of the mental representation. Also, offering additional representations of the teaching method in formats outside the currently propagated structured description may be able to remedy this issue. Such formats could be storyboards, case study descriptions, or even videos allowing multiple access points to the teaching method. A similar argument was brought forward by Falconer and Littlejohn [4,15], who concluded that multiple perspectives on the teaching method are necessary, since different user groups

Here's the cleaned Markdown:

that were missing in their opinion and should therefore be added. We discussed that this supports existing claims in literature, suggesting that we may need different forms of representation for different target groups.

The construction and evaluation of this template was the initial step of a broader research agenda aiming to evaluate the usability of IMS LD with end users, i.e. instructors, instructional designers and learning designers. Based on the collected teaching methods and the description template, the next step will be the definition of a method for providing concrete examples of the teaching methods in the form of units of learning. Further steps include:

1. the definition of a metadata schema for teaching methods based on the description template and evaluation results presented in this paper and the integration of the template into a web based teaching method repository
2. the specification of a methodology for transforming teaching methods and examples into IMS LD units of learning

These steps will enable us to identify and collect evidence for the strengths and weaknesses of IMS LD in supporting practitioners documenting, sharing and reusing teaching methods and units of learning.

## Acknowledgments

This paper was written in the context of the ICOPER Best Practice Network (http://icoper.org), which is co-funded by the European Commission in the eContentplus programme, ECP 2007 EDU 417007.

## References

1. Beetham, H.: Review: Developing e-learning models for the JISC practitioner communities (2004), http://tinyurl.com/jisc-review-models
2. IMS Global: IMS Learning Design Specification (2003), http://www.imsglobal.org/learningdesign/index.cfm
3. Griffiths, D., Blat, J.: The role of teachers in editing and authoring units of learning using IMS Learning Design. Advanced Technology for Learning 2(4), 1-9 (2005)
4. Falconer, I., Littlejohn, A.: Designing for blended learning, sharing and reuse. Journal of Further and Higher Education 31(1), 41-52 (2007)
5. Agostinho, S.: Learning design representations to document, model, and share teaching practice. In: Lockyer, L., Bennett, S., Agostinho, S., Harper, B. (eds.) Handbook of Learning Design and Learning Objects: Issues, Applications, and Technologies, vol. I, pp. 1-19. Information Science Reference, Hershey (2009)
6. Voigt, C., Swatman, P.M.C.: Describing a design pattern: Why is it not enough to identify patterns in educational design? In: 23rd ASCILITE Conference, Sydney, Australia, pp. 833-842 (2006)
7. Learning Designs Project: Learning Designs (2003), http://www.learningdesigns.uow.edu.au/
8. Flechsig, K.H.: Kleines Handbuch didaktischer Modelle. Neuland, Eichenzell (1996)
9. Falconer, I., Beetham, H., Oliver, R., Lockyer, L., Littlejohn, A.: Mod4L final report: Representing learning designs (2007), http://tinyurl.com/mod4l-final
10. Neumann, S., Oberhuemer, P.: Supporting instructors in creating standard conformant learning designs: the Graphical Learning Modeler. In: World Conference on Educational Multimedia, Hypermedia and Telecommunications 2008, Vienna, Austria, pp. 3510-3519. AACE (2008)
11. Chickering, A.W., Gamson, Z.F.: Seven principles for good practice in undergraduate education. AAHE Bulletin 39(7), 3-7 (1987)
12. Lambe, P.: Organising Knowledge: Taxonomies, Knowledge

## Model and Tool to Clarify Intentions and Strategies in Learning Scenarios Design

Valérie Emin¹,², Jean-Philippe Pernin¹,², and Viviane Guéraud¹

¹ Laboratoire Informatique de Grenoble  
² EducTice - Institut National de Recherche Pédagogique

## Abstract

For several years some researches have concerned the process modelling of learning situations integrating digital technologies. Educational Modelling Languages (EML) aim at providing interoperable descriptions of learning scenarios. In order to generalize the use of EML, it is necessary to provide authoring environments allowing users to express their intentions and requirements. This paper presents the core concepts of one of these, called ISiS (Intentions, Strategies, and interactional Situations), a conceptual framework elaborated to structure the design of learning scenarios by teachers-designers. The framework is based on a goal-oriented approach and proposes a specific identification of the intentional, strategic, tactical and operational dimensions of a scenario. This paper also presents how these concepts have been implemented within ScenEdit, a specific authoring environment dedicated to teachers-designers based on the ISiS goal-oriented framework.

**Keywords**: technology enhanced learning, learning scenarios, authoring approach, requirements engineering, goal oriented approach.

## 1 Introduction

Since the beginning of the 2000s, certain research in the field of Technology Enhanced Learning has been concerned with Learning Design: the process modelling of learning situations integrating digital technologies. Its purpose is to produce a description (called "learning scenario") of the organization and the time scheduling of learning situations where many actors are involved (students, teachers, tutors, designers, etc.). At the international level, various Educational Modelling Languages (EMLs) have been proposed such as IMS-LD or LDL. The main challenge of EMLs is to propose a neutral and shared formalism, capable of expressing the widest range of learning situations and to be implemented more or less automatically towards specific Information Systems (called Learning Management Systems). An EML allows the definition of relationships between learning goals, the roles of staff and learners in the learning process, performed activities, the environment and resources necessary in a learning situation. Specific research works consist today of the analysis of the expressiveness of these languages (for example to express complex collaborative learning situations) or in the solution of the problems raised by the deployment of learning scenarios towards technical platforms.

As pointed out by IMS-LD authors themselves, an EML, which mainly aims at expressiveness and interoperability, is not intended for a direct manipulation by human users (teachers, engineers…). Specific authoring systems must be provided in order to help designers to design their own scenarios at a lower cost.

Two main authoring contexts can be identified. In the first case, a structured team is in charge of the requirements analysis, solution design, and the encoding of the solution into an EML language. In the following step, the EML code can be interpreted in a target LMS integrating an adapted "player". This first type of context can basically be found in an industrialization perspective of distance learning, handled by instructional engineering methods. In this case, design strategies are based on a stage of requirements extraction, often proceeding from narrative texts written by teachers. Authoring tools proposed to this kind of designers are based on mastering conceptual models, which are very close to the targeted modelling languages.

In the second case, which we focus on in this paper, the teacher himself designs the scenario: he is potentially conducted to integrate digital resources and tools as part of the training he provides. Economic constraints do not allow a team of designers or developers to assist each teacher: it becomes necessary therefore to provide authoring tools which allow teachers to express their requirements based on their own business-oriented languages and shared practices.

Two combined goals can be reached: to provide a "computable" description to be translated into an EML like IMS-LD or LDL and to be understood and shared by experts and practitioners sharing a common vocabulary, knowledge of the discipline and pedagogical know-how.

This authoring approach aims to further consider learning

## Model and Tool to Clarify Intentions and Strategies in Learning Scenarios Design

## Context of Research

The research works presented in this paper were conducted in collaboration between the Laboratoire Informatique de Grenoble and the INRP[^1]. This collaboration closely associates panels of teachers in charge to co-elaborate and experiment models we want to implement. This work led us to study existing practices of sharing scenarios.

In parallel with the work concerning formalization based on EMLs presented above, some international initiatives aim to propose scenarios databases in order to favour sharing and reuse practices between teachers, such as the IDLD [9]. Their goal is to disseminate innovative practices using digital technologies in the field of education. These databases for teachers-designers, such as that proposed by the French Ministery of Education: EduBase and PrimTice, list scenarios indexed with different fields depending on the domain or subject. Their descriptions are very heterogeneous: from practice narrations to more structured formalizations. This diversity has led us to question the ability of these representations to be understood and shared between several practitioners.

Our research is at the intersection of the two approaches previously identified: proposing scenario databases in order to favour sharing practices for the integration of technology by practitioners and proposing computational interoperable formalisms (like IMS-LD) to describe scenarios. Based on empirical results obtained in previous research conducted with groups of teachers [10] our first hypothesis (H1) is: a structuring formalism is more favourable to reuse than a narrative or a computational formalism provided that it is in accordance with the vocabulary of the stakeholders concerned.

The research questions we address is to facilitate teachers' task in designing and implementing learning scenarios using Information and Communication Technology by providing them formalisms and tools satisfying criteria of understandability, adaptability and appropriability. In other words, provide a common formalism which elicitates intentions and strategies to give a better understanding and context adaptation of learning scenarios within a community of practice. In this context, we aim to provide models, methods and tools allowing teachers-designers belonging to communities of practice to design their scenarios expressing intentions and educational strategies they will adopt.

The context of our research is the CAUSA project at INRP and the specific type of designers we focused on are teachers who are called to integrate digital technologies in an academic context, more precisely in the French secondary educational system (pupils from 11 to 18 years). We organized our work into four phases in order to propose adapted formalisms and tools[11]. After a preliminary phase where we defined the targeted audience precisely, the first phase consisted of analyzing current uses of share and reuse of scenarios. It appeared that for a given scenario, it required a very precise analysis to identify the general objectives and the strategy or pedagogical approach although it would have been for them an important criterion of choice. After this work, teachers suggested that the design task could be facilitated by providing libraries of typical strategies, scenarios, or situations of various granularities. Each of these components were to be illustrated by concrete examples.

## Proposition of a Conceptual Framework

Instead of proposing an alternative solution to EMLs, our observations [10, 11] led us to complete them by offering models, methods and tools to sustain design and reuse by non computer specialists of learning scenarios using digital technologies.

### Theoretical Background

Our research is concerned with teacher-designer activity and we base our approach on a set of complementary theoretical works concerning the theory of activity:

- The organization of activity, proposed by Russian psychologists such as Leontiev [12], defines hierarchical levels (activity, action, operation) which distinguishes intentional, strategic and tactical dimensions in activity
- The importance of routines or schemata, which represents typical solutions given to recurrent problems in specific contexts. These features have been particularly studied by Schanck and Abelson in the context of teaching activity [13]

We also take into account the recent works in Business Process Engineering and Goal-Oriented Requirements Engineering [7] where the elicitation of goals is considered as an entry point of the specification of software systems as in the Rolland and Prakash MAP model [8] an

Here's the cleaned Markdown:

## MAP and ISiS Models for Learning Design

MAP and ISiS are both models dedicated to the design process in a goal oriented perspective. MAP is a more generic model defined to sustain the design process than ISiS which is dedicated to a specific learning "business-process" and aims to imply actors themselves in the design of the process. To reach that goal, it is necessary to provide users with sufficiently accessible conceptual terms. In our experimental context, we confronted French teachers-designers with the concepts of intentions and strategies. For those teachers, the concepts of "pedagogical intention", "learning strategy", and "learning situation" belong to common vocabulary. By linking them to their regular uses, they were able to define two different articulated levels: first a "didactical" level dealing with domain specific knowledge and second a "pedagogical" level dealing with organizing learning situations. For each level, they were able to define intentions and strategies.

The concepts of intention and strategy in MAP and ISiS are quite close. When MAP considers a strategy as a way of linking two goals, ISiS proposes to sequence two intentions where the first intention is linked to the strategy. Implicitly the model assumes that the second intention will be invoked after that the first strategy has been implemented. Concerning intentions, ISiS proposes to gather two or more intentions of different kinds in the same group. This enables the same strategy to be linked with several intentions, which is an explicit demand of some teachers-designers. In ISiS, alternatives are represented by a specific distribution strategy, which allows one to distinguish several sub-strategies linked to sub-intentions which refines the main one. The concept of variability [15] with MAP may be declined in ISiS in two ways: by choosing different strategy or by associating different operational solutions to a same strategy. ISiS manages a "tactical level" refining the modelling of strategies by linking them to their typical solutions.

After evaluation of different authoring solutions in learning design [5, 6], we chose to develop a graphical environment ScenEdit [14] based upon the ISiS model.

### Intentions and Strategy in the Context of Learning Scenarios

We illustrate our model with an example based on a collaborative learning scenario, the LearnElec Scenario [16] dedicated to the concept of "the power of a light bulb" in the domain of electricity at secondary school. In this scenario, the teachers' first didactical intention is "to destabilize" a frequently encountered "misconception" of students in electricity which is that "proximity of the battery has an influence on current intensity". After having defined his intention, the teacher-designer can choose the appropriate strategy he wants to use to reach the goal.

In our example, the didactical intention is implemented with a specific didactical strategy called the "scientific inquiry strategy" composed of four phases: hypothesis elaboration, solution elaboration, hypothesis testing and conclusion as you can see in figure 1.

Each phase can be performed through various pedagogical modes and can be refined by another intention according to the type of activity, the availability of computer services, etc. the teacher wants to use. In our example, the first didactical phase, the "hypothesis elaboration" is refined by a pedagogical intention called "increase the ability to work in a collaborative way" as shown in figure 2.

This intention is implemented with a strategy called "elaborating a proposal by making a consensus" composed of two phases: "Make an individual proposal" and "Confront proposals. Obtain a consensus". For each phase, an interactional situation can be defined: "Individual proposal on a MCQ" and "Argued debate on a forum with consensus". During these two phases the teacher is involved in an activity of "Group management" symbolized by an interactional situation called "Group management".

### Our Proposal: The ISiS Model

From our first hypothesis (H1), we co-elaborated the ISiS model [11]: a conceptual framework elaborated to structure the design of learning scenarios by teachers and to favour sharing and reuse practices between designers. The ISiS model is based on three complementary hypotheses:

Here's the cleaned and normalized Markdown:

## Model and Tool to Clarify Intentions and Strategies in Learning Scenarios Design

## Overview of the ISiS Model

The model structures a scenario into different phases or cases by means of intentions and strategies. Each phase or case can be either recursively refined by a new intention or linked at a tactical level to a suitable interactional situation. An interactional situation can be itself described by a more low-level interactional scenario which defines, in an operational way, the precise organization of situations (in terms of activities, interactions, roles, tools, services, provided or produced resources, etc.). Interactional scenarios are the level typically illustrated with EML examples of implementation.

![An overview of the ISiS model](Fig. 3.)

Figure 3 provides an overview of the ISiS model which proposes to structure the design of a scenario describing the organization and planned execution of a learning unit.

- the I level (Intention) describes the designer's intentions. In our field, intentions are closely linked to the knowledge context which defines targeted knowledge items (concepts, notions, competencies, know-how, abilities, conceptions or misconceptions, etc.). The intentions for the designer can be, for example, to reinforce a specific competence in electricity, to favour a notion discovery, to destabilize a frequent misconception, etc;

- the S level (Strategy) is related to strategic features. In order to reach goals related to the intentions formulated at I level, the designer opts for the strategy he considers to be the most appropriate. Two main kinds of strategies can be distinguished: sequencing strategies which organize the arrangement of logical phases (for example a scientific inquiry strategy can be modelled as a series of four phases), distribution strategies which plan different solutions for identified cases (for example, a differentiation strategy takes into account three possible levels of mastering). Strategies can be combined by successive refinements: for example, a sequencing strategy may specify one of the cases of a distribution strategy;

- the iS level (interactional Situation) represents the tactical level, i.e. the proposed solution to implement the formulated intentions and strategies. We consider that, for a new problem, a teacher-designer does not rebuild a new specific solution from scratch. As underlined in works on schemata and routines in teaching activities [14], the teacher bases his planning or his adjustments upon a library of mastered solutions, which are triggered by specific events. In the same way, we assume that a scenario designer selects situations which are appropriate for his intentions and strategies, from a library of components. Each component, an "interactional situation", is made up of a collection of interactions with a specific set of roles, tools, resources, according to the situational context. The situational context is characterized by a set of variables such as resources that can be manipulated to support the activities (document, tools, services), locations where activities can take place, planning elements in which activities must be scheduled or the number of learners, roles which can be distributed.

## Implementation of the ISiS Model

### Towards Flexible and Continued Design Processes

The ISiS framework is not properly a method as it does not propose a specific order to combine design steps. The ISiS is based on the hypothesis that all dimensions of a scenario (intentions, strategies, situations, activities, resources) must be elicited and interlinked in order to facilitate the design, appropriation, sharing and reuse. In our experimentations, we analyzed the tasks undertaken by teachers-designers [10]. Several design processes as shown by different studies involving teachers-designers were considered. Some teachers were able to choose a top-down approach by hierarchically organizing their design.

Here's the cleaned and normalized Markdown:

## Model and Tool to Clarify Intentions and Strategies in Learning Scenarios Design

## Design Approaches and Initial Implementation

Our observations showed that some designers preferred a top-down approach by defining their intentions, strategies, situations, etc., while others preferred to adopt a bottom-up approach by "rebuilding" a scenario from resources or patterns that they wanted to integrate. Consequently, one of our hypotheses is that the design of learning scenario cannot be modelled as a linear process without significantly reducing designers' creativity. According to the designer type, according to the uses within a precise community of practice, several kinds of objects or methods are shared. As a result, resources, pedagogical methods and typical situations could constitute an entry point from which design steps will be combined.

From this entry point (for example typical interactional situations), the designer may alternatively and recursively perform design tasks. On these principles, the ISiS model was implemented successively using different kinds of tools (diagram designing or mind mapping software). In a first step, we elaborated paper forms to express the different dimensions of the design (knowledge context, situational context, intentions, strategies, interactional situations, activities, etc.).

We also adapted mind mapping software where each node represents a concept (e.g. strategies, phases, interactional situation) and can be edited with a specific electronic form. These first tools based on the ISiS model were experimented in a secondary school with a group of five teachers in technological subjects: these teachers were associated to the INRP institute. Each "teacher-designer" had one month to model a learning sequence that he had to implement during the school year, by using the tools provided.

All teachers accomplished the required task in the prescribed time, and the different sequences which were produced had a duration varying between two and six hours. One teacher actually covered the complete process by:
1. describing his scenario in paper form
2. encoding the designed scenario with a specific editor (LAMS)
3. implementing the result automatically towards Moodle, a learning management system
4. testing the scenario with his pupils

After this first experimentation, the teachers were questioned about their design activity. The answers given by the teachers-designers have shown the benefits of the model for the improvement of the quality of the scenarios created, for illustrating the importance of the elicitation of intentions and strategies by users themselves, for the better understanding of the scenarios created by others and for simplifying the design process by reducing the distance between users' requirements and the effectively implemented system.

Finally, the following points can be raised:
- The elicitation of intentions and strategies allowed the teacher-designer to better understand a scenario designed by a peer
- Teachers expressed the need to be provided with reusable components allowing (a) a significant decrease in the design duration and (b) an exploration of solutions, proposed by peers, for a renewal of practices
- The complete implementation on a LMS by one of the teachers was considered to be facilitated by using the ISiS model
- The provided tools (paper forms and mind mapping tools) were considered as too costly to be integrated into regular professional use

These first results show the capabilities of the ISiS model to encourage an efficient authoring approach. The main restriction formulated by users refers to the provision of adapted graphical tools.

## A Step Towards Graphical Tools: ScenEdit

As a solution to this restriction, we have co-elaborated with panels of users a specific graphical authoring environment named ScenEdit based on the ISiS Model. This environment proposes three workspaces to edit a structuring scenario.

The first Scenario Edition workspace structures the scenario by logically linking elements previously defined in the components workspace or directly defined in the Edition window to compose a graphical representation of the scenario. The Context workspace defines the two different types of context in which a learning unit can be executed: the knowledge context and the situational context.

The Components workspace is dedicated to manage the three main components of the ISiS model:
- Intentions
- Strategies
- Interactional Situations

For each type of component, the author can either create a new element or import and adapt an existing element

## Model and Tool to Clarify Intentions and Strategies in Learning Scenarios Design

## Communities of Practice and Pattern Design
We have worked with teachers to formalize and design patterns of learning scenarios, pedagogical approaches and recurrent interactional situations. With this environment, users will be able to feed databases by exporting fragments of their own scenario, in order to share them with others or reuse them further in similar or different contexts.

## Results of Recent Experimentations
We have conducted several experiments since the beginning of our research work in order to adopt a user-oriented or authoring approach.

### Context and Methodology
The experimentation took place in November 2008 during a training session to design scenarios using ICT. The 18 participants were teachers, pedagogical engineers, trainers and had the common characteristics that they were not familiar in learning scenario design and techniques and not involved in our researches. The complete results of this experiment were presented in a francophone conference on TEL: EIAH 2009 in Le Mans June 2009 [17].

The experimentation consisted in confronting individually each of the 18 subjects with a same scenario expressed with a formalism chosen among the three types we wanted to compare: narrative, computational and structuring. We formed 3 experimental groups of 6 subjects, where the members of one group assessed a particular formalism. We made sure we had an homogeneous representation of each profiles within each group.

The chosen scenario was LearnElec Scenario [16] we presented above. It describes collaborative situations, alternating questionnaires, votes, synthesis and debate. The three different descriptions of the scenario were produced in 2006 and 2007 regardless of this experiment. The narrative description was developed by teachers and researchers at the beginning of the project. The computational description, expressed with activity diagrams (by actors) proposed by IMS-LD, represents graphically the course of the scenario in play, actions, partitions, structured activities and basic activities. The structuring description, based on ISiS concepts, proposes a graphical arrangement of intentions implemented through strategies divided into phases, each phase being associated with one or more interactional situations. IMS-LD and ISiS descriptions were produced by researchers with a high degree of expertise in the field. The results of each formalization were given to subjects as paper prints.

During a 45-minute session, each subject had to read the scenario expressed in one formalism and then to evaluate it using an online questionnaire. The latter had two sets of questions, one concerning the notion of pedagogical scenario in general (Q1 to Q5) and the other specifically relating to the given formalism Q6 to Q9). The questions were either multiple choice or open-ended questions to gather precise information from the subject and compensate for the relatively small sample of subjects.

### Results and Interpretation
The analysis of collected data was done as follows: frequency table for questions dealing with the concept of pedagogical scenario in general, and cross tabulation for the questions specific to one of the 3 formalisms in a way so as to isolate possible variations of answers. A series of 5 general questions were asked, and each question could give rise to five different types of answer (cf. table 1).

[Table 1 content preserved as in original]

From this first series of questions, we can draw the following lessons:
- As expected, it is essential for the scenario to describe the major phases of the learning situation. However, the precise description of the activities seems essential to a small majority of respondents (10 over 18). This could be an indication as to the fear of over-scripting [18] which may be detrimental to the effectiveness of the situations to be established;
- The answers to questions Q3 to Q5 show that some elements, absent today from computational formalisms, are of significant importance in the eyes of the respondents: at least two thirds of them consider it as important or essential to explain the pedagogical approach, the notions of the program and the articulation between knowledge and activities.

A second series of questions Q6 to Q9 were in relation to the

Here's the cleaned and normalized Markdown:

## Experimentation of the ScenEdit Environment

A new experimentation of our graphical online tool ScenEdit has been done in April 2009 during two days in a French secondary school. The subjects were a group of five teachers in Industrial Sciences and Techniques fields (electronics, mechanics and physics). Two teachers had worked with us before on the definition of reusable components inside our tool ScenEdit and the three others had never heard about ISiS model or learning scenario design before this experiment. This study is qualitative and is used to help us improve the model and tools we are developing. We are only presenting here the main results, and especially the ones where Hypothesis H4 has being tested through.

The preliminary analysis of this experiment shows the interest of having reusable components in the context of designing for the teachers' own ordinary work in their classroom or for a collaborative work with other teachers. Table 2 shows their answers as regards collaborative work with other teachers.

Table 2. Breakdown of the answers to questions about re-use for collaborative work between teachers

| As regards collaborative work with other teachers, evaluate the fact of having components / patterns, | No answer | totally useless | quite useless | quite useful | absolutely useful | Total |
|---|---|---|---|---|---|---|
| implemented previously by the designers of ScenEdit is... | 0 | 0 | 0 | 3 | 2 | 5 |
| implemented previously by other teachers is... | 0 | 0 | 0 | 3 | 2 | 5 |
| implemented previously by yourself is... | 0 | 0 | 0 | 3 | 2 | 5 |
| Total | 0 | 0 | 0 | 9 | 6 | 15 |

More precisely the elements provided with ScenEdit (knowledge items, intentions, strategies, interactional situation patterns...) are useful as can be seen in table 3.

Table 3. Breakdown of the answers to questions about the presence of suggestions

| Evaluate the presence of suggestions | No answer | totally useless | quite useless | quite useful | absolutely useful | Total |
|---|---|---|---|---|---|---|
| knowledge items | 0 | 0 | 0 | 4 | 1 | 5 |
| intentions | 0 | 0 | 0 | 4 | 1 | 5 |
| strategies | 0 | 0 | 0 | 4 | 1 | 5 |
| interactional situations | 0 | 0 | 0 | 3 | 2 | 5 |
| Total | 0 | 0 | 0 | 15 | 5 | 20 |

To the question "Would you say that the presence of components and patterns is..." (two possible choices), the associated terms were "advantage"(4 answers), "help" (4 answers). One of the experimented teachers said, it was an "advantage" and a "constraint", and he explained that "at first sight I found the choices were not wide enough, I was a little embarrassed to be unable to put whatever I wanted... and finally it's another advantage of ISiS thinking of words that everybody can accept and then speak the same language" so he was convinced of the necessity to have a definite number of possibilities in the list if the vocabulary chosen is relevant for their users.

Some of the comments suggested improvements of the visual representation of the model ISIS: in particular more precision is required for the temporal dimension which is not represented on the actual simple tree version, as mentioned before. Moreover they pointed out that making the phases and the activities more explicit helped them as "the scenario can be appropriated more rapidly".

Finally, the issue of the complementarity of the formalisms was raised. Practitioners probably prefer having several complementary formalisms at their disposal with each one contributing to the precision

Here's the cleaned Markdown:

## Users in the Driver's Seat: A New Approach to Classifying Teaching Methods in a University Repository

## References

1. Martel, C., Vignollet, L., Ferraris, C., David, J.P., Lejeune, A.: Modelling collaborative learning activities on e-learning platforms. In: 6th IEEE ICALT Proceedings, Kerkrade, pp. 707-709 (2006)

2. Koper, R.: Current Research in Learning Design. Educational Technology & Society 9(1), 13-22 (2006)

3. Murray, T., Blessing, S.: Authoring Tools for Advanced Technology Learning Environment, Toward Cost-Effective Adaptive. In: Ainsworth, S. (ed.) Interactive and Intelligent Educational Software, p. 571. Kluwer Academic Publishers, Dordrecht (2003)

4. Botturi, L., Cantoni, L., Lepori, B., Tardini, S.: Fast Prototyping as a Communication Catalyst for E-Learning Design: Making the Transition to E-Learning: Strategies and Issues. In: Bullen, M., Janes, D. (eds.), Hershey (2006)

5. Van Lamsweerde, A.: Goal-Oriented Requirements Engineering: A Guided Tour. In: Fifth IEEE International Symposium on Requirements Engineering, p. 249 (2001)

6. Rolland, C., Prakash, N., Benjamen, A.: A Multi-Model View of Process Modelling. Requirements Engineering 4(4), 169-187 (1999)

7. Lundgren-Cayrol, K., Marino, O., Paquette, G., Léonard, M., De La Teja, I.: Implementation and deployment process of IMS Learning Design: Findings from the Canadian IDLD research project. In: Proc. Conf. ICALT 2006, pp. 581-585 (2006)

8. Emin, V., Pernin, J.-P., Prieur, M., Sanchez, E.: Stratégies d'élaboration, de partage et de réutilisation de scénarios pédagogiques. International Journal of Technologies in Higher Education 4(2), 25-37 (2007)

9. Pernin, J.P., Emin, V., Guéraud, V.: ISiS: an intention-oriented model to help teachers in learning scenarios design. In: Dillenbourg, P., Specht, M. (eds.) EC-TEL 2008. LNCS, vol. 5192, pp. 338-343. Springer, Heidelberg (2008)

10. Leontiev, A.N.: The problem of activity in psychology. In: Wertsch, J. (ed.) The concept of activity in Soviet psychology. Armonk, Sharpe, New York (1981)

11. Schank, R.C., Abelson, R.: Scripts, plans, goals and understanding. Erlbaum, Hillsdale (1977)

12. Emin, V.: ScenEdit: an authoring environment for designing learning scenarios. Poster ICALT 2008, IEEE International Conference on Advanced Learning Technologies, Santander (2008)

13. Rolland, C., Prakash, N.: On the Adequate Modelling of Business Process Families. In: Workshop on Business Process Modelling, Development, and Support (BPMDS), Trondheim, Norway (June 2007)

14. Lejeune, A., David, J.P., Martel, C., Michelet, S., Vezian, N.: To set up pedagogical experiments in a virtual lab: methodology and first results. In

Here's the cleaned and normalized Markdown:

## Users in the Driver's Seat: A New Approach to Classifying Teaching Methods

## Introduction

A two-step analysis was performed to group classifications according to their topical focus and identify their quality according to taxonomy validation criteria.

Three groups of classifications were identified:
- Narrow focus classifications (emphasis on singled-out components like learning objectives or lecturing styles)
- Holistic focus classifications (emphasis on the gestalt of teaching methods or overarching learning theory view)
- Versatile focus classifications (no particular emphasis, covering a large set of descriptors)

The second analysis revealed that few reviewed classifications fulfilled more than one of eight taxonomy validation criteria, with three being the maximum criteria met by any classification.

The literature review concluded that a new classification for teaching methods is needed, as current classifications lack sufficient quality and purpose-related extensiveness. Users were notably absent from development processes, suggesting future classifications should incorporate users' experiences and procedures to reflect their perspectives, organization methods, and language.

## Classification Foundations

Classification is defined as the meaningful clustering of experience. Classification work involves:
1. Grouping related entities
2. Making relationships between entities obvious and visible

While "taxonomy" and "classification" are interchangeable, this article prefers "classification." Classification becomes necessary when:
- Large content repositories need improved accessibility
- Stakeholder coordination needs enhancement to create synergies

Classifications exist in various fields, with notable examples in:
- Medicine (International Classification of Diseases)
- Biology (taxonomy of plants and animals)
- Chemistry (Periodic Table of Elements)

### Types of Classifications

**Lists**
- Basic building blocks of classifications
- Group related items by attributes, purpose, sequence, etc.
- Suitable for simple domains with few items
- Typically reorganized into trees or maps when exceeding 12-15 items

**Trees**
- Divide and subdivide classes based on distinction rules
- Allow multiple relation types (part/whole, cause/effect, etc.)
- Require advance knowledge for building
- Limited by consistency and depth constraints

**Hierarchies**
- Specific type of tree structure
- Features:
  - Inclusive top categories
  - Consistent relations
  - Attribute inheritance
  - Mutual exclusivity

Here's the cleaned and normalized Markdown:

## Classification Types and Knowledge Organization

states that perfect hierarchical organization has been achieved for vertebrates), but hierarchies often do not work for manufactured objects or mental concepts [6]. A difference between biology and, for instance, library hierarchies is that in biology taxonomy the animals are only classified in the lowest levels and categories, deepest down in the tree, while in library classifications, books can also be assigned at general levels that are high up in the hierarchy [6]. This effect appears because knowledge objects (products of the human mind) can be either general or specific, while physical objects can only be specific [6].

Hierarchies are well-suited for knowledge representation in those domains that are mature, meaning that the nature of the entities and the nature of their meaningful relationships are known [5]. A sign that it is premature to use hierarchy as the type of classification is that a category "miscellaneous" or "other" is needed, where items are placed that do not fit the logic of the classification as specified [5]. Hierarchical classifications do not accommodate well knowledge domains exhibiting complexity and ambiguity. This is especially true for entities that cannot easily be observed or analyzed, such as information or knowledge artifacts. Just like trees, hierarchies do not allow competing principles of organization.

### Matrices

In matrices, two or three attributes are linked together in order to reveal the presence or absence of entities or the specific nature of an entity at the intersection of the attributes [5]. Matrices are also known as typologies in social sciences (Bailey cited in [6]), or as paradigms in library science [5]. Main features of matrix representations are that they support "sense-making" (quickly getting guidance within a knowledge domain), and that they foster the discovery and creation of new knowledge [6].

For instance, classification along multiple dimensions in matrices allows for comparison, the locating of issues, problems or opportunities, the creation of inventories or checklists, the identification of gaps, and the description of complex phenomena [6]. To compare, trees subdivide only along one dimension; therefore, trees only allow the location and retrieval of items, and do not support the above mentioned functions. While trees cannot represent alternative points of view effectively, matrices do so very well, up to three alternative approaches [6].

Matrices work well with a well-defined, cohesive body of content, whereby the content must be able to be consistently described by two or three facets, which make up the dimensions of the matrix. The best reflection of knowledge in the domain is achieved when the matrix dimensions are set up using a consensual framework with common vocabulary. In fields, where the fundamental relationships of concepts are not well understood, it is difficult to build a matrix that reveals essential knowledge [5]. Above three dimensions, matrices are not appropriate classification structures, mainly because the content can no longer be visually organized, which in turn impedes easy comprehension and navigation [6]. Diverse collections of content are not easily expressed in a matrix due to the lack of common attributes. Matrices also rarely give complete pictures of a phenomenon or knowledge domain [5].

### Facets

Facets represent not merely a different type of classification, but entail a completely different approach to classification work. Facets provide a set of perspectives to have on content, whereby each facet has its own representation (one facet could be a list, while the next facet could be a tree) [6]. Each facet is mutually exclusive, i.e. the facets are orthogonal to each other. The representation in facets rests on the beliefs that there are always multiple perspectives on the world and on the entities in it, and that even seemingly stable classifications, like hierarchies, are in fact provisional and dynamic [5].

Facets and facet analysis are attributed to Ranganathan, who developed the system decades ago; however, his system of colon classification did not become popular until recently when digital objects could be saved in multiple places, contrary to the previous organization within the physical world of libraries where one book had to have exactly one place on a shelf [5]. Facets represent the predecessor of semantic taxonomies used today, and they allow post-coordination [6].

Facets neither require a strong theory

Here's the cleaned and normalized Markdown:

## Users in the Driver's Seat: A New Approach to Classifying Teaching Methods

## Knowledge Domain Complexity

The educational science domain encompasses various learning theories, pedagogical frameworks, and instructional design models, which exist in parallel and at times endorse competing positions. There appears to be a need to map these different frameworks, models, and vocabularies in order to compare, contrast and identify relationships between them (cp. recent initiatives described in [10] [11]). Although educational science aims to provide fundamental concepts that translate from theoretical assumptions to sound practical implications for teaching, the provision of such concepts has not been achieved [12] [13]. The educational science knowledge domain lacks a common consensual framework and may thus be regarded as complex and ambiguous.

Focusing just on the knowledge domain teaching methods, we recognize a range of terms used for "teaching method". Other terms used to describe similar concepts include, but are not limited to, models of teaching [14], patterns [15], scripts [16], and pedagogical, learning or educational scenarios, e.g. [17]. Finding common ground with this difference in terminology becomes difficult as supported by Beetham [18], who mentioned the lack of common terminology of instructors when talking about their teaching practice.

Next to the diversity in terminology, the uncertainty is further enhanced by the differences that individual teaching situations present and that influence the decision whether a teaching method may be appropriate or not. For instance, the adequateness of the teaching method, no matter how theoretically backed, is dependent on the persons interpreting, modifying, and implementing the teaching method as well as dependent on the learners that participate during implementation. This creates a complex setup of often unknown variables and unpredictable factors impeding common understanding and interpretation. Further, practical implications of choosing certain teaching methods over others have only been presented as vague guidelines, for instance, by loosely connecting learners' knowledge levels and the task to be learned to types of instructional strategies promoted by the different learning theories [19].

This short reflection suggests that the knowledge domain "teaching methods", both as a stand-alone knowledge domain and as part of the educational science knowledge domain, does not yet provide sufficient consensus resulting in the use of classification types that rely on firm theories and models like hierarchies or trees.

## Former Classifications' Approaches to the Knowledge Domains Educational Science and Teaching Methods

This section gives an additional view on the classifications included in the literature review described in section 1. This time, the focus is placed on the types of classifications used and how the classifications attempted to structure the knowledge domain.

The purposes of building a classification varied widely, from articulating nature and scope of different learning designs [3], to providing search mechanisms in a repository for learning objects [20], guiding teaching practitioners through decision-making [21], classifying research in instruction and learning [22], establishing connections between theory and practice of teaching [23], and classifying instructional methods [24] to name a few.

### Types of Classifications Used

Classifications of the literature review [4] were sorted according to the employed type of classification as introduced in section 2.1 above. Overall, there were 35 counts, which are distributed as shown in Table 1.

| Type of Classification | Number of Count |
|----------------------|-----------------|
| List | 3 |
| Tree | 20 |
| Hierarchy | 0 |
| Matrix | 7 |
| Facet | 5 |

Trees were the most popular classification type used. Of the 20 classifications that represent trees, fourteen featured just a single level of division (the entire tree was represented in the top level). For instance, Ramsden [25] distinguishes three theories of teaching at the top level. This single level use strikes as unusual as trees allow structuring according to multiple relations, yet, only a few trees have taken advantage of this feature. Two classifications (Fuhrmann & Weck [24], and Currier [26]) went beyond the recommended maximum depth of three levels, making the tree hard to navigate.

Matrices were also popular. The most prominent representative of this classification type is likely the revised version of Bloom et al.'s taxonomy of

## Users in the Driver's Seat: A New Approach to Classifying Teaching Methods

## Knowledge Domain Analysis

The analysis of knowledge domains like teaching methods and educational science shows they are complex and ambiguous. Despite this, most reviewed classifications used tree structures, likely due to their pragmatic nature and familiar organizing principles. However, trees require a priori knowledge and rules, making them less suitable for evolving, complex domains.

Matrices were the second most common classification type, but these work best when:
- A consensual framework with common vocabulary exists
- The domain can be described using 2-3 facets

Neither condition was fully met in these knowledge domains.

## Issues with Previous Classifications

- Empirical investigations focused only on specific teaching elements (e.g., lecturing styles, cognitive processes)
- Classifications based on authors' expertise used specialized language inaccessible to general users
- Faceted classifications often chose facets arbitrarily with limited documentation
- Development processes lacked transparency
- Target users were not involved in classification development
- Teaching methods were often organized in simple lists

## Goals for New Classification Approach

1. Apply user-driven methods to avoid expert-only language
2. Make the classification development process transparent
3. Socially negotiate classification with eventual users

## Case Study: University of Vienna

The University of Vienna (72,000 students, 6,200 scientific staff) is developing a teaching methods classification for their digital asset management system Phaidra. The system will store:
- Learning materials
- Teaching method documentation
- Publications
- Units of learning

While content will be publicly searchable, only university members can upload assets. The classification development process aims to demonstrate a user-driven approach.

[Note: Preserved DOI/URL reference to Phaidra (https://phaidra.univie.ac.at/)]

Here's the cleaned and normalized Markdown:

## Users in the Driver's Seat: A New Approach to Classifying Teaching Methods

## Method

For this case study, the underlying methodology stems from Lambe [6]. We chose this methodology of classification development, because it is highly user-oriented, and specifically aims at bringing together stakeholders from different parts of an organization, which the University of Vienna is.

For the analysis portrayed in this article, only the portion of the methodology is presented that is relevant to identifying with stakeholders the purposes that the classification will serve and the classification's scope. Later stages in the methodology involve the decision on a specific design approach (how users will be involved during the classification's development) and the actual development of the classification including series of testing and validation.

The type of classification to be developed must be chosen based on three decisive inputs: the nature and maturity of the knowledge domain, the needs of the users in relation to their tasks in the work environment, and the type of technological system, in which the classification will be used [6]. The first step to attain this information was to brainstorm with the person, who initially requested the development of a classification, who the key stakeholders of the organization are, i.e. who will benefit from the classification, as well as their activities and tasks within the organization. Stakeholders and their activities were arranged in a concept map along with resources that play a role in the activities. The concept map, and respectively updated versions of the map, served as the communication basis with the stakeholders.

At the University of Vienna, the following four main stakeholders, who have a presumed interest in the classification of teaching methods, were identified in the initial brainstorming:

1. faculties/departments, along with study program leads
2. university instructors
3. (formally established) subject-specific didactics[^1], who educate (future) school subject teachers, for instance, in chemistry or biology
4. the Center for Teaching and Learning, which supports university instructors with counseling in the use of teaching methods, and the use of technology in teaching

The concept map constructed in the initial meeting was then discussed with representatives of the main stakeholder groups in individual sessions lasting between 45 and 90 minutes. During the interviews, differences in understanding were recorded directly in the concept map along with any comments that stakeholders had. Cues regarding the purpose and scope of the needed classification were filtered from these interviews. The adjusted concept maps were later meshed to create a coherent view representing all stakeholders.

We led twelve interviews with stakeholder representatives. The distribution of interviews according to the stakeholder groups is as follows: 2 faculty/study program representatives, 5 university instructors, 2 subject-specific didactics (one each for biology and chemistry), and 3 Center for Teaching and Learning representatives.

## Interview Results

### Purposes of the Classification

Study program development teams form for the duration of a curriculum development project; once the curriculum is complete, the team ceases to exist. If documentations of these teams could be preserved in the repository, then future curriculum development teams could benefit from their knowledge, e.g. regarding how learning outcomes were formulated and how teaching methods were assigned to learning outcomes and modules.

Often, the connection between curriculum and teaching methods is not apparent to instructors, who have to translate the curriculum into specific teaching methods used within courses. A representative from the faculty notes instructors would have an easier time if the connections between teaching practice and the curriculum were documented, for instance, by explicitly capturing the experiences of the curricular development teams and reasons behind curricular setups.

Center for Teaching and Learning representatives stated that instructors could use a classification of teaching methods to make the course creation for instructors more efficient, because instructors could then use methods that were used before for similar courses. Especially new instructors would benefit from such an installation as they often require guidance in teaching method choice and application.

The formally established subject-specific didactics at the University offer continuing education courses in biology, chemistry and physics. School teachers learn about teaching methods in these courses, which must have convincing instructional concepts in order to convey credibility and to allow participants to integrate the taught concepts in

Here's the cleaned and normalized Markdown:

## Users in the Driver's Seat: A New Approach to Classifying Teaching Methods

All stakeholder groups reported that the communication about teaching methods is nearly "non-existent". Even when courses on the same topic are taught in parallel, instructors of these courses do not necessarily communicate about their teaching approaches. Stakeholders recognized that instructors possess a lot of implicit knowledge even if instructors are not necessarily keen or able to talk about teaching. This knowledge, however, is expressed in diverse documentations, such as instructional concepts prepared for lectures and seminars, course descriptions (which include learning outcomes, teaching methods, and references) as well as the implementation of teaching methods within the learning management system. Instructors and subject-specific didactics further compose publications about teaching method use. All these resources could be stored and organized within the repository to provide systematic access to a wider community – within and external to the University.

## Translating Cues into Type of Classification to Be Developed

### Needs of Stakeholders
Lambe [6] provides guidelines for translating cues from stakeholders into types of purposes and suggested classification types. An overview of these guidelines is shown in Table 2.

Table 2. Interview cues, purpose of classification, and type of classification [6], pp.137 & 158

| Sample Cues | Indication of classification's purpose | Probable classification type needed |
|-------------|--------------------------------------|-----------------------------------|
| "We have a clear workflow that everyone follows." | Structure and organize | Trees |
| "We share folders but they are a mess; everyone does their own thing, and we can't find the information we need." | Establish common ground | Trees |
| "Different divisions replicate the same information; they don't know what exists in other parts of the organization. If we shared we could be more effective." | Span boundaries between groups | Facets |
| "This is a new area for us. Our domain is changing too quickly and our specialists don't agree." | Help in sense-making, or Aiding the discovery of risk and opportunity | "Disposable" frameworks, matrix, maps |

Although stakeholders may give conflicting cues that match several categories, recurring cues that appear across stakeholder groups provide the tendency for the classification's purpose and type. We have identified the purpose "spanning boundaries between groups" from the common themes at the University of Vienna because many comments focused on helping different groups share their knowledge.

Since the purpose of the classification is to span boundaries, it is recommended to develop a faceted classification [6]. This type of classification is best suited to fulfill the need of multiple representations that have to span across several boundaries.

### Knowledge Domain
What further supports the choice of facets is that teaching methods represent a knowledge domain that lacks consensual frameworks and exhibits ambiguity. For this characteristic, a faceted classification is recommended as it does not require strong underlying theories or models [6].

### Technology
The University of Vienna's repository Phaidra features a sophisticated system of metadata that governs how entities in the repository are retrieved and organized. For this type of technological environment, classifications can be larger and more complex such as facets [6].

Overall, the information collected during the analysis suggests that the University of Vienna should develop a facets classification for use in its repository. A problem that might occur because of this decision to use facets is that the user communities represent different expert levels, namely that subject-specific didactics have expert knowledge in educational science while university instructors, who are often not formally educated in pedagogy, may not use this highly specialized expert language. A thesaurus that maps variant terminologies may thus be used in the initial phases to accommodate different user groups within the same facets classification.

## Summary and Outlook

This article presented a new, namely, user-driven method to developing a classification for teaching methods. This method was favored because none of the earlier classifications took user perspectives into account during classification development. The user-driven method was then applied within the initial development phase at the University of Vienna, where specific stakeholder needs in regard to classifying teaching methods were identified. The results showed that the needs of the users are

Here's the cleaned Markdown, which appears to be a references section from an academic paper:

## References

1. Oliver, R., Harper, B., Wills, S., Agostinho, S., Hedberg, J.: Describing ICT-based learning designs that promote quality learning outcomes. In: Beetham, H., Sharpe, R. (eds.) Rethinking Pedagogy for a Digital Age. Designing and delivering e-learning, pp. 64–80. Routledge, London (2007)

2. Neumann, S., Koper, R.: Instructional Method Classifications Lack User Language and Orientation (manuscript in preparation) (2009)

3. Kwasnik, B.H.: The Role of Classification in Knowledge Representation and Discovery. Library Trends 48, 22–47 (1999)

4. Lambe, P.: Organising Knowledge: Taxonomies, Knowledge and Organisational Effectiveness. Chandos, Oxford (2007)

5. Lakoff, G.: Women, Fire, and Dangerous Things: What Categories Reveal about the Mind. University of Chicago Press, Chicago (1987)

6. Blackwelder, R.E.: Taxonomy. A Text and Reference Book. Wiley, New York (1967)

7. Vander Wal, T.: Folksonomy Definition and Wikipedia (2005), http://www.vanderwal.net/random/entrysel.php?blog=1750

8. Mayes, T., de Freitas, S.: Stage 2: Review of e-learning theories, frameworks and models. JISC e-Learning Models Desk Study (2005)

9. Conole, G., Littlejohn, A., Falconer, I., Jeffery, A.: Pedagogical review of learning activities and use cases. LADIE project report (2005)

10. Carr, W.: Education Without Theory. British Journal of Educational Studies 54, 136–159 (2006)

11. Levin, J.R., O'Donnell, A.M.: What to do about Educational Research's Credibility Gaps? Issues in Education 5, 177–229 (1999)

12. Joyce, B., Weil, M., Calhoun, E.: Models of Teaching, 7th edn. Pearson, Boston (2004)

13. Derntl, M.: Patterns for Person-Centered e-Learning. University of Vienna, Wien (2005)

14. Dillenbourg, P.: Over-scripting CSCL: The risks of blending collaborative learning with instructional design. In: Kirschner, P.A. (ed.) Three worlds of CSCL. Can we support CSCL, pp. 61–91. Open Universiteit Nederland, Heerlen (2002)

15. Marty, J.-C., Heraud, J.-M., Carron, T., France, L.: Matching the Performed Activity on an Educational Platform with a Recommended Pedagogical Scenario: A Multi-Source Approach. Journal of Interactive Learning Research 18, 267–283 (2007)

16. Beetham, H.: Review: developing e-Learning Models for the JISC Practitioner Communities, Version 2.1 (2004), http://www.jisc.ac.uk/uploaded_documents/Review%20models.doc

17. Ertmer, P.A., Newby, T.J.: Behaviorism, Cognitivism, Constructivism: Comparing Critical Features from an Instructional Design Perspective. Performance Improvement Quarterly 6, 50–72 (1993)

18. Carey, T., Swallow, J., Oldfield, W.: Educational Rationale Metadata for Learning Objects. Canadian Journal of Learning and Technology 28 (

Here's the cleaned Markdown:

## Generating Educational Interactive Stories in Computer Role-Playing Games

Marko Divéky and Mária Bieliková

Institution of Informatics and Software Engineering,  
Faculty of Informatics and Information Technologies,  
Slovak University of Technology, Ilkovičova 3, 842 16 Bratislava, Slovakia  
markod@nextra.sk, bielik@fiit.stuba.sk

## Abstract

The aim of interactive storytelling is to tell stories with the use of computers in a new and interactive way, which immerses the reader inside the story as the protagonist and enables him to drive its course in any desired direction. Interactive storytelling thus transforms conventional stories from static structures to dynamic and adaptive storyworlds. In this paper, we describe an innovative approach to interactive storytelling that utilizes computer role-playing games, today's most popular genre of computer games, as the storytelling medium in order to procedurally generate educational interactive stories.

**Keywords**: Interactive storytelling, story generation, educational stories, computer games, role-playing games.

## Introduction

Stories and the art of storytelling have played an inevitable role in our lives ever since the earliest days of language. Historians found first records of storytelling in ancient cultures and their languages, in which stories served as the vehicle by which cultural knowledge was communicated from one generation to the next [1].

Even in today's modern times, such utilitarian use of stories has endured and their educational potential is utilized in many different areas, e.g., in business to spread knowledge amongst employees in order to help them become more productive and to collaborate with one another [2]. Stories are also used in many other ways: in policy, in process, in pedagogy, in critique and as a foundation and as a catalyst for change [3]. The reason why storytelling proves to be an effective medium for educating is that our minds are programmed much more for stories than for abstract facts [4].

Many aspects of stories have changed since the very first records of storytelling in ancient times. However, even in today's modern world, the fundamental idea behind conventional stories remains unaltered. Let us suppose that the storyteller seeks to communicate some truth or information (principle) to a desired audience. Instead of just telling the principle, the storyteller translates it into an instantiation (a story), then communicates the story to the audience, which in turn translates the instantiation back into the principle [1], as depicted in Fig. 1.

Interactive storytelling differs from conventional stories in a way that the process of transforming the principle into the instance (story) is delegated to the computer. It is best described as "a narrative genre on computer where the user is one main character in the story and the other characters and events are automated through a program written by an author. Being a character implies choosing all narrative actions for this character" [5].

In interactive storytelling, the computer transforms the principle into a storyworld, which operates on rules rather than on predefines events (see Fig. 2). A single playing of a storyworld generates a single story. In other words, when a player goes through a storyworld, he produces a linear sequence of events that makes a story. Different playing of the storyworld can yield many different stories, but all of them share one common principle [1], as depicted in Fig. 2.

In this paper, we propose an approach that enables to generate educational interactive stories in computer role-playing games. Researchers in the field of interactive storytelling often disregard computer games as a suitable storytelling medium [1]. Still, some researchers see them as the ideal form for storytelling given their practically unlimited degree of interactivity and visual attractiveness [6].

Throughout the many diverse genres of computer games available today, role-playing games (RPGs) have the most detailed and involving storyline, thus being the most appropriate genre for storytelling [7]. Moreover, computer role-playing games have originally derived from tabletop role-playing games and are considered as being one of today's most popular genres of computer games [7].

## Related Work

Despite the large amount of work that has

Here's the cleaned Markdown:

## Overview of Existing Interactive Storytelling Systems

- Systems that generate complex, but only text-based interactive stories, e.g., Storytron [8] (formerly Erasmatron) developed by Chris Crawford since 1991. Storytron utilizes a drama manager agent to direct the generated stories, which are, however, very cumbersome to define and have only text-based visualization.

- Systems that generate visually attractive, but not interactive stories, e.g., I-Storytelling [9] developed by Marc Cavazza and Fred Charles at the University of Teesside. Their solution utilizes Hierarchical Task Network (HTN) planning and Heuristic Search Planning (HSP) to generate stories via autonomous behavior of character agents. Users, however, have very limited or no means of interacting with and directly influencing the generated stories.

- Systems that generate interactive stories, but only with a single dramatic conflict, e.g., Façade [10] developed by Michael Mateas and Andrew Stern. Façade uses Natural Language Processing (NLP) to parse user-inputted actions and visualizes stories with a custom proprietary 3D graphics engine. Façade solves almost all problems that relate to interactive storytelling; however, it is able to generate only a single dramatic scene.

Consequently, our goal is to devise a new approach to interactive storytelling that not only builds on present-day techniques and formalisms in a way that eliminates the above-mentioned drawbacks of existing interactive storytelling solutions, but also enables to generate educational interactive stories in computer role-playing games.

## Overview of the Proposed Concept

The aim of the hereby-described concept is to programmatically generate educational interactive stories with computer role-playing games as their medium, therefore combining the dynamic and enthralling storyworlds created by interactive storytelling with the visual appearance, gameplay and popularity of computer role-playing games.

The presented concept can be broken into the following three logical layers:

- Character Behavior Layer describes interpersonal relationships and conditional reasoning of characters
- Action Planning Layer realizes planning and replanning of narrative actions
- Visualization Layer utilizes computer role-playing games for story visualization

All generated interactive stories initiate in the topmost logical layer named the Character Behavior Layer, since all stories are about people, despite the fact that references to them are often indirect or symbolic [1]. The behavior of characters results in creating plans and planning actions that move the story forward. The middle layer, called the Action Planning Layer, handles all the planning and replanning. All created plans eventually break down into actions that are visualized by the lowest logical layer called the Visualization Layer.

All three logical layers operate on easy-to-define rules and data structures, which are described in detail in the following sections.

### Visualization Layer

The Visualization Layer provides graphical visualization of the generated interactive stories to the players. It uses the concept of computer role-playing games as the visualization and storytelling medium. The most important aspects of computer role-playing games that are important for the scope of this paper are described below.

**Themes.** Games based on the role-playing genre are most often set in a fictional fantasy world closely related to classic mythology, or in a science-fiction world set somewhere in the future. Historical and modern themes are also common [11].

**Avatars.** In role-playing games, a player controls one in-game character called the avatar, and uses him as an instrument for interacting with the game world [12].

**Character Development.** Besides having the option to fully customize the appearance of his in-game character, the player is allowed to choose various attributes, skills, traits and special abilities that his avatar will possess. These are given to players as rewards for overcoming challenges and achieving goals, most commonly for completing quests. Character development plays, together with stories, a key role in today's computer role-playing games.

**Quests.** A quest in role-playing games can be defined as a journey across the game world in which the player collects items and talks to non-player characters "in order to overcome challenges and achieve a meaningful goal

## Generating Educational Interactive Stories in Computer Role-Playing Games

## Items, Containers and Objects

Throughout playing role-playing games, quests require the player to find, collect and properly use various items scattered throughout the game world. Special items may be equipped on the player's avatar, improving his abilities, skills or other attributes. All items can be either created from other items, or obtained from containers, i.e. objects that can hold or carry items. The player himself is an example of a container, since he can carry items in his inventory. Non-player characters and objects representing treasure chests are also examples of containers.

## Atomic Actions

We have formalized computer role-playing games from an interactive storytelling point of view into a set of atomic actions having narrative impact that a player (or a non-player character) is able to commit inside the game world. Each atomic action has the following structure:

- Name: A string concisely describing the atomic action.
- Source: The type of an in-game element that can commit the atomic action, e.g., the player, or a non-player character.
- Target: The type of an in-game element that this atomic action is committed upon, e.g., an object or a container.
- Parameter: The type of an in-game element that the atomic action operates on. The presence of the parameter is optional.
- Preconditions: A set of statements regarding the specified source, target and parameter defining the circumstances under which the atomic action can be committed in the game world.
- Effects: A set of changes to the game world that are a consequence of the atomic action having been committed.

The typical set of atomic actions that describes a common computer role-playing game is shown in Table 1.

### Table 1. Atomic actions that describe a typical computer role-playing game

| Source | Atomic Action | Target | Description |
|--------|---------------|---------|-------------|
| Character | GIVE (Item) | Container | The character specified as the source gives the item to a targeted container. |
| Character | TAKE (Item) | Container | The source character takes the item from the target container. |
| Character | USE (Item) | Element | The atomic action's source character uses the item on the targeted element. |
| Character | EQUIP () | Item | The character specified as the source equips the targeted item. |
| Character | WALK_TO () | Element | The source character walks near the targeted element. |
| Character | TALK_TO () | Character | The atomic action's source initiates a dialogue with the targeted character. |

As an example, we elaborate the second atomic action mentioned in Table 1, which is defined as follows:

- Name: TAKE
- Source: Character  
- Target: Container
- Parameter: Item
- Preconditions: Target has parameter
- Effects: 
  - Target has parameter (negation of the action's precondition)
  - Source has parameter

## Action Planning Layer

From a top-down perspective, the role of the middle logical layer is to transform character goals set by the Character Behavior Layer into plans consisting of actions that are to be executed and visualized by the bottommost logical layer – the Visualization Layer. From a bottom-up perspective, the Action Planning Layer is responsible for processing actions committed by the player and all non-player characters that were reported back from the Visualization Layer.

Since the described process is done on-the-fly while the player is playing a computer role-playing game, the hereby described layer creates new quests based on the previous actions committed by the player and seamlessly integrates them into the game, thus dynamically creating an interactive story perceived by the player.

The Action Planning Layer utilizes Hierarchical Task Network planning in a similar way as described in [15]. Our algorithm searches for appropriate actions based on recursive matching of their effects with required preconditions. In other words, the planner finds all actions resulting in the required preconditions.

The Action Planning Layer operates on simple actions, complex actions and action bindings, all of which are described below.

### Simple Actions

A simple action refines the

Here's the cleaned Markdown:

## Generating Educational Interactive Stories in Computer Role-Playing Games

Below is an example of a simple action named REPAIR that refines the atomic action USE (mentioned in Table 1) and enables the player to repair a malfunctioning computer with a spare circuit board:

Name: REPAIR  
Base action: USE  
Source: Player (a character subtype)  
Target: Computer (an object subtype, see below)  
Parameter: Circuit board (an item subtype)  
Preconditions[^1]: [Source has parameter]  
Target is "malfunctioning"  
Effects[^1]: [Source has parameter]  
Target is "malfunctioning"  

The second effect marks the target computer as "not malfunctioning," since it is defined as being an object subtype, which has a "malfunctioning" property defined. An object instance can belong to multiple object subtypes, each having defined custom properties that can be set on the object instance.

Likewise, subtypes of all other core in-game elements (described in section 0), i.e. items, containers and characters are also supported, with each subtype having its own custom properties defined.

### Complex Actions

A complex action encloses multiple actions in a sequence with atomic, simple or complex actions being its elements. Every complex action has the following structure:

- Name: A string concisely describing the complex action.
- Source: Type of an in-game element that is the source of all enclosed actions.
- Targets: Types of in-game elements that are targets of the enclosed actions.
- Parameters: A set of in-game elements that the enclosed actions operate on. Each parameter is identified by a unique name distinguishing it from the others.
- Enclosed actions: A set containing atomic, simple or other complex actions that this complex action encloses.
- Preconditions: A filtered[^2] set containing preconditions of all enclosed actions plus additional preconditions related to this complex action.
- Effects: A filtered set containing effects of all enclosed actions plus additional effects related to this complex action.

Below is an example of a complex action, with which a non-player character unlocks a locked item for the player if the particular non-player character likes the player:

Name: UNLOCK_LOCKED_ITEM_FOR_PLAYER  
Source: Non-player character  
Targets: Player  
Lockable item i (an item subtype)  
Parameters: Lockable item i  
Enclosed actions[^3]: Source : TAKE (i) → Player  
Source : UNLOCK() → i  
Source : GIVE (i) → Player  
Preconditions: [Player has i]  
[i is "locked"]  
Source "likes" player  
Effects: [Player has i]  
[i is "locked"]  

### Action Bindings

The purpose of optional action bindings is to explicitly permit or disallow bindings of atomic, simple, and complex actions to actual in-game entities. Action bindings therefore define what can or cannot be done with all defined story elements, and what exactly can or cannot the player and all non-player characters do.

For example, the action bindings given below denote that the player can steal the item "thyme syrup" from the non-player character representing an evil doctor and cannot steal it from a non-player character representing a good doctor:

- [CAN] Player : STEAL ("Thyme syrup") → "Evil Doctor"
- [CAN'T] Player : STEAL ("Thyme syrup") → "Good Doctor"

### Character Behavior Layer

The Character Behavioral Layer is responsible for generating goals of all in-game characters, i.e. the player and all non-player characters. These goals are created according to interpersonal relationships among the player and non-player characters by matching their existing values[^4] to a set of behavior patterns (see below) and picking the resulting goals from the best matching patterns. All generated characters' goals are afterwards translate

Here's the cleaned Markdown:

## Generating Educational Interactive Stories in Computer Role-Playing Games

### Description of Behavioral Patterns

- Description: An optional text concisely describing the behavioral pattern. 
- Preconditions: A set of in-game elements, including their properties and relationships among them. Also included are the preconditions of actions that represent goals. Undesirable preconditions may be explicitly excluded. 
- Goals: A set containing goals describing the change in characters' behavior as a consequence to the situation portrayed by the pattern's preconditions. Goals can be represented by actions of any type, or by changes in properties of in-game elements and in relationships among them. Each goal is bound to a character.
- Effects: A set containing effects of all identified goals. Undesirable effects may be explicitly excluded from the set.

Below is an example behavioral pattern that describes the situation in which John, a husband of Mary with a respiratory infection, cures his wife with thyme syrup that the player had given him:

Preconditions:
- Non-player characters "John" and "Mary"
- John is "husband" to Mary, Mary is "wife" to John
- Mary is "sick with respiratory infection"
- [...preconditions of the two actions that represent goals...]

Goals:
- Player : GIVE ("Thyme syrup") → John
- John   : USE  ("Thyme syrup") → Mary

Effects:
- [...effects of the two actions that represent goals...]
- Mary is "sick with respiratory infection"

This behavioral pattern contains examples of two actual interpersonal relationships, namely "is husband to," "is wife to" and an attribute "sick with respiratory infection." Following is a detailed description of all types of interpersonal relationships and attributes that the Character Behavior Layer operates on.

### NPC → Character Relationships

Interpersonal relationships oriented from a non-player character to any type of in-game character (i.e. the player or another non-player character) are identified with their unique label.

Under normal circumstances, NPC → Character relationships are either absent (the default initial value) or present. However, there are cases when two relationships are mutually exclusive (meaning that the presence of one disallows the presence of the other and vice-versa). Such pairs of relationships are merged into relationships with two complementary values. These interpersonal relationships can have only one of their two values present at a time, e.g., if the precondition "Tom likes player" is true at a given time, then the precondition "Tom dislikes player" is false at the same time.

### Character Roles

Another type of relationships between in-game characters are character roles. Unlike NPC → Character relationships, character roles can be oriented from the player, as well. Moreover, character roles can be bilateral.

Similarly to NPC → Character relationships, character roles are either absent (the default initial value) or present. If a bilateral character role is present, then preconditions testing either end evaluate to true, e.g., "John is husband to Mary" and "Mary is wife to John" are either both true, or both false in a given time.

### Character Attributes

Every in-game character, whether being the player or a non-player character can have various attributes defined. Such attributes are either unnumbered or numbered.

Unnumbered character attributes do not have any numerical value and are either absent (the default initial value) or present. An example of an unnumbered character attribute is "sick with respiratory infection" referenced in the aforementioned behavioral pattern example.

Numbered character attributes are present in every in-game character (i.e. the player and all non-player characters) and store a numerical value (individually for every character and from a custom-defined interval), unlike unnumbered attributes. An example of numbered attributes found in the majority of computer role-playing games is located in the left column of Table 2.

Table 2. Examples of various numbered character attributes

Common Attributes | Domain-specific Attributes
-----------------|------------------------
- Agility        | - C++ prof

## Generating Educational Interactive Stories in Computer Role-Playing Games

## Story Creation Process

The storyteller first defines the initial storyworld state, creating non-player characters with their attributes, roles and relationships. They can optionally add objects, containers and items throughout the storyworld.

## Story Generation Phase

After the initial state is defined, the Character Behavior Layer analyzes the storyworld and selects goals that match its current state (those with met preconditions).

The Action Planning Layer then translates all player's and non-player characters' active goals into plans using Hierarchical Task Network (HTN) planning. This process:

- Starts with each goal's effects
- Recursively finds matching actions (complex, simple, or atomic)
- Creates tree-like graphs showing paths to accomplish goals

## Plan Implementation

After plans are constructed:

- A subset of player's planned paths is chosen based on the player's user model
- The model contains records of previously successful actions
- Plans can use positive personalization (similar successful actions) or negative personalization (avoiding failed/untried actions)
- Random selection occurs if no user model exists

## Visualization and Execution

The Visualization Layer:

- Receives planned actions for both player and NPCs
- Executes NPC actions
- Presents player options via the interface
- Reports action outcomes back to the Action Planning Layer

The system then:

- Processes committed actions
- Updates or replans as needed
- Signals storyworld changes to the Character Behavior Layer
- Updates goals and continues the cycle

The story ends when either:

- The player successfully accomplishes all goals
- No possible paths remain to accomplish existing goals

[Figures and specific examples from original text preserved but reformatted for clarity]

## Generating Educational Interactive Stories in Computer Role-Playing Games

We have implemented a prototype system based on an approach that is simple to define, operates on clear rules, and enables programmatic generation of interactive stories in computer role-playing games.

The prototype system reads from an input file a set of rules and data structures (described in detail in [16]) defining a storyworld from which an educational interactive story is generated and presented to the player through a computer role-playing game (see Fig. 6). The story progresses on-the-fly by reacting to narrative actions that the player has committed.

The domain selected for prototyping relates to education in computing history and programming basics.

Our future work consists of evaluating the prototype system empirically through player questionnaires regarding various narrative and educational aspects of the generated interactive stories.

## Acknowledgments

This work was partially supported by:
- Cultural and Educational Grant Agency of the Slovak Republic, grant No. KEGA 3/5187/07
- Scientific Grant Agency of Slovak Republic, grant No. VG1/0508/09

## References

1. Crawford, C.: Chris Crawford on Interactive Storytelling. New Riders Games (2004)
2. Denning, S.: The Springboard: How Storytelling Ignites Action in Knowledge-Era Organizations. Butterworth-Heinemann (2000)
3. Sandercock, L.: Out of the Closet: The Importance of Stories and Storytelling in Planning Practice. Planning Theory & Practice 4(1), 11-28 (2003)
4. Schank, R.: Tell Me a Story: Narrative and Intelligence. Northwestern University Press, Evanston (1995)
5. Szilas, N.: The Future of Interactive Drama. In: Proceedings of the Second Australasian Conference on Interactive Entertainment, pp. 193-199. Creativity & Cognition Studios Press, Sydney (2005)
6. Murray, H.J.: From Game-Story to Cyberdrama. First Person: New Media as Story, Performance and Game, pp. 2-11. MIT Press, Cambridge (2004)
7. Rollings, A., Adams, E.: Andrew Rollings and Ernest Adams on Game Design. New Riders Games (2003)
8. Storytron, http://www.storytron.com/
9. Cavazza, M., Charles, F., Mead, S.J.: Sex, Lies, and Video Games: An Interactive Storytelling Prototype. In: Proceedings of the 2002 AAAI Spring Symposium, pp. 13-17. AAAI Press, Menlo Park (2002)
10. Façade, http://www.interactivestory.net/
11. Barton, M.: Dungeons and Desktops: The History of Computer Role-playing Games. A.K. Peters Ltd., Wellesley (2008)
12. Tychsen, A.: Role Playing Games – Comparative Analysis Across Two Media Platforms. In: Proceedings of the Third Australasian Conference on Interactive Entertainment, pp. 75-82. Murdoch University, Perth (2006)
13. Howard, J.: Quests: Design, Theory, and History in Games and Narratives. A.K. Peters Ltd., Wellesley (2008)
14. Bieliková, M., Divéky, M., Jurnečka, P., Kajan, R., Omelina, Ľ.: Automatic Generation of Adaptive, Educational and Multimedia Computer Games. Signal, Image and Video Processing 2(4), 371-384 (2008)
15. Cavazza, M., Charles, F., Mead, S.J.: Planning Characters' Behaviour in Interactive Storytelling. Journal of Visualization and Computer Animation 13(2), 121-131 (2002)
16. Divéky, M., Bieli

## Self-monitoring of Learning Activities

## Self-regulated Learning and Monitoring

Self-regulated learning is a promising way to successfully achieve learning goals and thus highly eligible with both solo and collaborative learning processes. It will be shown that self-monitoring plays an essential role when successfully learning in a self-regulated way and that computer-based self-regulated learning demands personal learning environments. Within such personalized learning environments self-monitoring has to be supported by recording the interaction of a learner with the actually used tools and services in order for her to later analyze and evaluate her learning processes.

The term self-regulated learning denotes a learning process where the learner herself decides on what to learn, when and how. Self-regulatedness is a gradable feature that does not exclude guidance by a teacher as long as this guidance does not question the autonomy of the learner. Self-regulated learners are able to meta-cognitively assess and strategically plan, monitor and evaluate their learning activities.

Over the years, self-regulated learning has been a focus for research within educational psychology. Torrano and González ([1]) give an account of current and future directions of self-regulated learning: the self-regulated learner can be characterized as a person who actively participates in learning – on a meta-cognitive, motivational and behavioural level –, motivates herself and makes use of strategies in order to achieve the desired results. According to Pintrich's learner model, the process of self-regulation comprises four phases: planning, self-monitoring, control and evaluation ([8]). These phases, in turn, are composed of a cognitive, a motivational/affective, a behavioural and a contextual area. Zimmerman ([9]) also accentuates the need for feedback, especially the self-oriented type, when learning in a self-regulated way. His loop of self-regulated learning comprises forethought, performance and self-reflection ([11]). By meta-cognitively assessing, analyzing and evaluating her behaviour, a learner can adjust her learning processes and consequently achieve better results. Thus, self-reflection is not only useful but an essential part of self-regulated learning.

In general, research agrees that self-regulated learning including self-monitoring and self-evaluation supports successful acquisition of academic (e.g. [12]) and non-academic skills (e.g. [11]) and a better understanding of the things studied. This is covered by experimental evidence: when girls learning how to throw darts were split into groups of students with present or absent self-evaluation (among other groups), those students who did not self-evaluate showed a tendency of attributing poor training outcomes to a lack of ability or insufficient effort ([11]). Those students, however, who did self-evaluate attributed poor outcomes to improper strategy use and practice. These results imply that self-evaluation and -monitoring lead to higher levels of self-efficacy and motivation to learn.

Other experiments were concerned with primary school children who had to solve the Tower of Hanoi problem with three and four discs ([13]). After setting up different training conditions (children watching themselves trying to solve the problem, children watching another child solving the problem inefficiently and children watching another child solving the problem efficiently) results show that those children watching themselves perform better than the others. With four other training conditions (video of self solving the problem inefficiently, video of self solving the problem inefficiently in a prescribed way, video of self solving the problem efficiently in a prescribed way and video of another child solving the problem in the most efficient way), the results, again, show that watching oneself produces better results than watching others. It also turns out to be much more efficient to watch non-prescribed, spontaneous, actual performance as that group achieves the best results.

Self-monitoring is also a motivator ([14]). When dividing students into different groups, either self-evaluating their learning processes or being externally evaluated while acquiring mathematical skills, the prediction is that self-monitoring is more effective than external monitoring. This hypothesis is supported by the results of Schunk ([14]). It can be concluded that self-monitoring fosters the students' motivation to learn. Monitoring their behaviour helps them to become aware of their actions and regulate them accordingly

## CAMera for PLE

## Self-Regulated Learning and Personal Learning Environments

A personal learning environment (PLE) supports self-regulated learning by recording and analyzing learner activities according to individual needs and tool choices. The environment can draw conclusions about learning behavior, particularly when the learner interprets their computer actions in relation to learning goals.

An important aspect of computer-based PLEs is allowing learners to:
- Choose from existing services
- Bring their own tools and services
- Share tools collaboratively with others
- Use familiar tools from everyday computer interaction

This makes PLEs suitable for both academic and non-academic lifelong learning as both a task and information environment.

## Tool Usage in PLEs

Browser and email client usage statistics show:

- Browser usage (Wikipedia statistics):
  - Internet Explorer: 66.82%
  - Mozilla Firefox: 22.05%
  - Safari: 8.23%
  - Google Chrome: 1.23%
  - Opera: 0.70%

- Email client usage (Fingerprint statistics):
  - Outlook: 36%
  - Mozilla Thunderbird: 2.4%
  - Web-based email (Hotmail: 33%, Yahoo! Mail: 14%)

Wakoopa tracking shows common Windows applications:
- Instant Messaging: Windows Live Messenger, Skype, Yahoo! Messenger
- Office: Microsoft Office (Word, Excel, PowerPoint), Adobe Reader, OpenOffice.org
- Other: World of Warcraft, Adobe Photoshop, iTunes, Media Players

The Centre for Learning & Performance Technologies' top learning tools:

For learners:
- Google Search
- YouTube
- Firefox
- Twitter
- Wikipedia/Delicious (tied)

For learning professionals:
- Twitter
- Delicious
- Google Reader
- Skype
- PowerPoint

## Requirements for PLE Behavior Tracking

For effective behavior analysis, tracking must:
- Record not just tool usage but specific actions
- Adapt to learner preferences, goals, background and experience
- Enable self-monitoring and self-evaluation
- Support personalization for self-regulation

## Stock-Taking

Key requirements for PLE tracking tools:
1. Run silently in background without disturbing learning
2. Record comprehensive observations across all used applications
3. Capture data at appropriate granularity for meaningful analysis
4. Present recordings in an understandable way for learner recapitulation
5. Record meaningful learning process actions (e.g., document opening) rather than low-level actions (e.g., keystrokes)

Here's the cleaned Markdown:

## CAMera and Usage Metadata Analysis

## CAMera

We call the tracing tool for supporting self-monitoring in personalized learning environments CAMera – "CAM" because its design is based on the Contextualized Attention Metadata (CAM) schema for representing user actions ([26], [27]); "camera" because, like a camera, it is basically a recording tool. The architecture of the tool is largely determined by the requirements mentioned in the previous section: the tool must continuously collect usage metadata, transfer these metadata into a well-defined format, store them and hold them ready for further analysis and the on-demand generation of usage reports.

The tool must not disturb the user from doing her actual work and, thus, it must not make use of obtrusive sensors like eye-trackers etc. The usage reports given by CAMera have to be reliable. Therefore, the reports must not be based on defeasible interpretations of the user's actions. Suppose, for example, that a user opens an email-message and replies to it. It is highly probable that she read the message or at least parts of it. It is, however, also possible that she opened the message and replied to it by accident without reading. Therefore, the CAMera tool may not store that the user read the message. Instead, the actions recorded by the tool have to be on a level of lower granularity that does not demand defeasible interpretation.

Nevertheless, the observations must not be too fine-grained as representations of actions observed and reported by the tool have to be meaningful to the user. The solution to this problem is to record the interaction of users with application programs and the file system: the tool records when text documents are opened, modified and stored with word processors, when data objects are moved or deleted, when emails are sent, chat-messages are uttered, queries are posted to search engines, and so on. Such actions can be tracked without further interpretation. At the same time representations of such actions are immediately interpretable.

Since usage metadata are captured from application programs, the CAMera tool firstly consists of a set of metadata collectors, that collect usage metadata from application programs and transfers these metadata into the CAM-schema. In most cases, it suffices to transfer existing log data into CAM; in other cases a metadata collector has to be implemented as a proper monitor component that generates usage metadata instead of just collecting them from existing log-files. At present, we possess metadata collectors for the Thunderbird email-client, the Skype chat-messenger, the Firefox browser and Microsoft Outlook. Furthermore, we have adapted the User Activity Logger developed at L3S (Leibniz Universität Hannover) for recording accesses to the file system. The ALOCOM Framework provides us with usage metadata collectors for MS Power Point and MS Word ([28], [29]). Finally, we exploit recordings of Flash Meetings ([30]).

Hence, we are provided with some metadata collectors that we can make use of and experiment with although the set of collectors is still to be extended. We aim at providing collectors for all of the most-used tools mentioned in the previous section. Also, it will be necessary to adapt existing collectors to new versions of their source applications. It will be possible for the user to switch data collectors on and off and thus to control from which applications usage data are being collected.

The metadata collectors mentioned capture usage metadata from application programs that run locally on a user's computer. Usage metadata can also be captured from remote servers with which the user interacts. In section 3.3, we will give an example on the collection of CAM-instances from server data.

Secondly, the CAMera tool consists of a database in which the CAM-instances are stored. We are performing experiments with different kinds of databases, both relational databases and xml-native databases, in particular the eXist-database ([31]). The databases provide us with interfaces for generating usage reports.

Thirdly, CAMera consists of analysis applications for the evaluation of CAM-instances, for instance in order to detect the network of people a user communicated with or the most heavily used objects over a certain time span

Here's the cleaned Markdown:

The second collector is based on the plug-in Adapted Dragontalk ([36]) that permanently records the interaction of a user with a Mozilla tool like the Thunderbird email-client or the Firefox browser. In our case, it records all events involving Thunderbird, for instance the opening of an email-message, the creation of a new folder or the moving of a message to a particular folder. The original Adapted Dragontalk plug-in generates usage metadata and writes these data into simple text files. We adapted the plug-in so that a CAM-instance is generated for each event and then stored in a database (adapted Adapted Dragontalk).

Before a user's social network can be created, the e-mail analyzer has to deal with the fact that computer users can have more than one email-address and more than one alias for these addresses. (An example for an alias-address-pair is "Jane Q. Public <jqpublic@example.org>".) A user's alias-address-pairs are to be assigned unambiguously to this individual user or her ID, respectively. To this end, we adapt the approach of Bird et al. ([38]) for computing the similarity of two alias-address-pairs according to the Levenshtein distance ([39]). If the distance is below a certain threshold, we assume that the two alias-address-pairs belong to the same user. Email-messages that have been sent to or from different email-addresses can now be assigned to the same person.

The email-analyzer evaluates email-related CAM-instances for representing a social network. Every person that occurs as sender or recipient of a message is represented by a node within the network. Two nodes are connected by an edge iff the respective persons are involved in the same message (as sender or recipient). The more email-messages two persons are jointly involved in, the stronger the edge between the respective nodes is. Figure 2 shows the CAMera tool displaying a user's social network. The network represents connections to those persons with whom the user has exchanged at least ten messages within a selected time interval.

The email-analyzer provides the user with an interface for browsing and manipulating the network: by marking a person's node, a list of email-messages in which the particular person has been involved is generated and displayed together with the keywords of these messages. Furthermore, time intervals can be specified on a time line; thereby the keywords are weighted regarding their frequencies within these intervals and thus displayed larger or smaller. By clicking on a keyword, the list of messages is reduced to the messages that contain the selected keyword.

The network itself can be manipulated in three different ways:
- By naming keywords one can highlight the nodes and edges that have been established due to messages that contain the keywords
- A user can specify a time interval and reduce the network according to the messages exchanged within this interval. This makes it possible to follow the dynamics of the network in the course of time
- A user can set the minimal number of messages that must have been exchanged so that a person and an edge to this person appear in the network. By standard, a person appears in the network, if she was involved in at least one message. By setting a higher minimal number, sporadic contacts can be filtered out in order to make the network representation more concise

The email-analyzer gives a user an insight into the structure of her social network. It depicts the persons with whom the user has been in contact and the issues of her email-exchange. Therefore, it gives an account on a specific type of communication behaviour and it supports the user in reflecting her communications. According to Viégas et al. ([40]), users are fascinated by the possibility of evaluating the social networks that are entailed in their email-conversations. (Thus, the email-analyzer arouses interest even without serving an immediate purpose.) Since communication is an integral part of collaborative learning (v.s., section 2), we assume that monitoring communication behaviour also contributes to the reflection of collaborative learning processes.

### MACE Zeitgeist

The second application we introduce here is a Zeitgeist application that is implemented as part of the MACE system. The

Here's the cleaned and normalized Markdown:

## CAMera: A Tool for Supporting Self-Monitoring in Personal Learning Environments

## Overview of the Zeitgeist Application

The Zeitgeist application is a set of web services that together provide an overview on activities within the MACE system. It gives users the possibility to reconstruct their learning paths by retracing which learning resources they accessed, how they found them and which topics have been of interest to them. This information can be used to make learning paths more explicit and to foster the learners' reflection on their activities.

Figure 3 shows the Zeitgeist dashboard that is used to give an overview on a user's MACE-related activities:
- The Usage Summary (top box) shows the user activities for January 2009 when she viewed the metadata of 136, downloaded 84, bookmarked 60 and tagged 34 learning resources. Further details on the objects that have been accessed can be viewed by following the links called "Details".
- The Usage History (middle box) shows the activities of the user per week, indicating when she viewed metadata, downloaded resources and tagged and bookmarked them. By simple statistics like these, the user recapitulates when she was looking for learning resources and when she found suitable ones. According to the graph, she constantly viewed resources during the week. Downloading and tagging, however, significantly increased after Thursday. Presumably, she started by searching for relevant data in the beginning of the week. By Thursday, she had found what she was looking for. Therefore, she downloaded these objects and tagged them.
- The Daily Content History (bottom box) lists the resources the user accessed most recently. According to the example given with Figure 3, the user viewed the metadata of "Villa dall'Ava" at 13:04:08 and downloaded the learning resource "Notre Dame du Haut" at 13:03:47. The respective titles of these data objects are linked to the objects themselves.

The Zeitgeist dashboard depicted in Figure 3 is a web-based interface. The Zeitgeist data, however, can also be requested by the local CAMera-tool and thus – although this is not yet implemented – be presented through the actual CAMera-interface. That is, MACE Zeitgeist can become a remote component of CAMera. It provides an individual user with an overview on her MACE-related activities. It can also cumulate and analyze usage metadata of different MACE users and thus present an overview on all MACE-related activities and on general trends in MACE usage.

This gives the individual learner the opportunity to compare her usage with the behaviour of the mass of MACE users. She can follow trends or, at contrary, refrain from trends and find new ways of exploring contents. An additional advantage of collecting metadata from different users is that now users can be compared regarding their usage profiles. A very simple usage profile can be defined as the set of objects that have been accessed in a certain time interval; the similarity of user profiles correlates with the cardinality of their intersection.

Therefore, the Zeitgeist component not only provides data for reflecting one's own learning behaviour but can also determine and point to similar learners which might be good cooperation partners. This is a clear advantage over a locally running component that observes and analyzes only a single user's browsing behaviour. (With the Adapted Dragontalk plug-in, we are already provided with a respective metadata collector.) The local component can collect CAM-instances about the individual user's interaction with the MACE system. However, it cannot easily integrate other kinds of metadata that are provided with MACE (LOM, e.g.), nor can it account for activities of other MACE users.

The Zeitgeist component provides the learner with an overview on her MACE-related learning paths. It lets her remember how she came to the engagement in her current issues. It helps her to maintain an overview on her activities and the development of her interests. Thus, the Zeitgeist component supports her self-monitoring.

## Conclusions

We have argued that self-regulate

Here's the cleaned Markdown:

## CAMera for PLE

## References

1. Torrano, F., González, M.C.: Self-regulated learning: current and future directions. Electronic Journal of Research in Educational Psychology 2(1), 1–34 (2004), http://www.investigacion-psicopedagogica.org/revista/articulos/3/english/Art_3_27.pdf

2. Zimmerman, B.J., Schunk, D.H. (eds.): Self-regulated learning and academic achievement: Theory, research and practice. Springer, New York (1989)

3. Schunk, D.H., Zimmerman, B.J.: Self-regulation of learning and performance: Issues and educational applications. Erlbaum, Hillsdale (1994)

4. Schunk, D.H., Zimmerman, B.J.: Self-regulated learning: From teaching to self-reflective practice. Guilford, New York (1998)

5. Boekaerts, M., Pintrich, P.R., Zeidner, M.: Handbook of self-regulation. Academic Press, San Diego (2000)

6. Zimmerman, B.J., Schunk, D.H. (eds.): Self-regulated learning and academic achievement: Theoretical perspectives. Erlbaum, Hillsdale (2001)

7. Madrell, J.: Literature Review of Self-Regulated Learning (2008), http://designedtoinspire.com/drupal/node/600

8. Pintrich, P.R.: The role of goal orientation in self-regulated learning. In: Boekaerts, M., Pintrich, P.R., Zeidner, M. (eds.) Handbook of self-regulation, pp. 451–502. Academic Press, San Diego (2000)

9. Zimmerman, B.J.: Self-regulated learning and academic achievement: An overview. Educational Psychologist 25(1), 3–17 (1990)

10. Butler, D.L., Winne, P.H.: Feedback and self-regulated learning: A theoretical synthesis. Review of Educational Research 65(3), 245–281 (1995)

11. Kitsantas, A.: Self-monitoring and attribution influences on self-regulated learning of motoric skills. Paper presented at the annual meeting of the American Educational Research Association (1997)

12. Nota, L., Soresi, S., Zimmerman, B.J.: Self-regulation and academic achievement and resilience: A longitudinal study. International Journal of Educational Research 41(3), 198–215 (2004)

13. Fireman, G., Kose, G., Solomon, M.J.: Self-observation and learning: The effect of watching oneself on problem solving performance. Cognitive Development 18(3), 339–354 (2003)

14. Schunk, D.H.: Self-Monitoring as a motivator during instruction with elementary school students. Paper presented at the annual meeting of the American Educational Research Association (1997)

15. Winne, P.H., Jamieson-Noel, D.: Exploring students' calibration of self reports about study tactics and achievement. Contemporary Educational Psychology 27(4), 551–572 (2002)

16. Gress, C.L., Fior, M., Hadwin, A.F., Winne, P.H.: Measurement and assessment in computer-supported collaborative learning. Computers in Human Behavior (in press) (Corrected Proof)

17. Wilson, S., Liber, O., Beauvoir, P., Milligan, C., Johnson, M., Sharples, P.: Personal Learning Environments: Challenging the dominant design of educational systems. In: Proceedings of the first Joint International Workshop on Professional Learning, Competence Development and Knowledge Management (

Here's the cleaned Markdown:

38. Bird, C., Gourley, A., Devanbu, P.T., Gertz, M., Swaminathan, A.: Mining email social networks. In: Proceedings of the International Workshop on Mining Software Repositories, Shanghai (2006)

39. Navarro, G.: A guided tour to approximate string matching. ACM Computing Surveys 33(1), 31–88 (2001)

40. Viégas, F.B., Golder, S., Donath, J.: Visualizing email content: portraying relationships from conversational histories. In: Proceedings of the SIGCHI conference on Human Factors in computing systems, Montreal, pp. 979–988 (2006)

41. Stefaner, M., Dalla Vecchia, E., Condotta, M., Wolpers, M., Specht, M., Apelt, S., Duval, E.: MACE – Enriching Architectural Learning Objects for Experience Multiplication. In: Duval, E., Klamma, R., Wolpers, M. (eds.) EC-TEL 2007. LNCS, vol. 4753, pp. 322–336. Springer, Heidelberg (2007)

42. ALOE-Project, http://aloe-project.de (accessed: April 19, 2009)

43. Memmel, M., Schirru, R.: Sharing digital resources and metadata for open and flexible knowledge management systems. In: Tochtermann, K., Maurer, H. (eds.) Proceedings of the 7th International Conference on Knowledge Management (I-KNOW), pp. 41–48. Journal of Universal Computer Science (2007)

44. Memmel, M., Schirru, R.: Aloe white paper. Technical report, DFKI GmbH (2008)

45. ROLE – Responsive Open Learning Environments, http://www.role-project.eu (accessed: April 19, 2009)

## Implementation and Evaluation of a Tool for Setting Goals in Self-regulated Learning with Web Resources

Philipp Scholl¹, Bastian F. Benz², Doreen Böhnstedt¹, Christoph Rensing¹, Bernhard Schmitz², and Ralf Steinmetz¹

¹ Multimedia Communications Lab (KOM), Technische Universität Darmstadt, Merckstr. 25, 64283 Darmstadt, Germany  
² Pädagogische Psychologie, Technische Universität Darmstadt, Alexanderstr. 10, 64283 Darmstadt, Germany

{scholl,boehnstedt,rensing,ralf.steinmetz}@KOM.tu-darmstadt.de,
{benz,schmitz}@Psychologie.tu-darmstadt.de

## Abstract

Learning effectively and efficiently with web resources demands distinct competencies in self-organization and self-motivation. According to the theory of Self-Regulated Learning, learning processes can be facilitated and supported by an effective goal-management. Corresponding to these theoretic principles, a goal-management tool has been implemented in an interdisciplinary project. It allows learners to set goals for internet research and assign relevant web resources to them. An evaluation study is presented that focuses on short-term learning episodes and selected results are shown that reinforce the benefits of our approach.

**Keywords**: Goal-Setting, Learning with Web Resources, Self-Regulated Learning, Evaluation.

## 1 Introduction

The importance of the World Wide Web as a major source of information for knowledge acquisition is growing steadily. With the web browser being the gateway, both specifically designed learning materials (e.g. contained in Web Based Trainings) and web resources that have not been designed with the intention to provide learning materials (e.g.

Here's the cleaned and normalized Markdown:

## Implementation and Evaluation of a Tool for Setting Goals

P. Scholl et al.

Found, it has only a transient use for learners, as usually it is not archived or persisted appropriately (see [7]). Hence, planning, organizing, setting goals and monitoring the involved processes may ease the difficulties of learners and prevent informational disorientation [10].

In this paper, we present an evaluation study of our goal-management tool that has specifically been designed to address some of these challenges. Section 2 presents a basic overview of the theory of Self-Regulated Learning that adequately describes this self-directed process of learning with web resources. Further, we explicate the term Scaffolds that denotes support of this process. We describe the design and implementation of a tool that enables learners to set learning goals prior to internet research and assign relevant web resources to these goals in section 3. This tool has been implemented into the web browser Firefox[^1], as web browsers are the gateway to most information on the web. Section 4 revisits the results of a previous study and section 5 presents a new study and evaluation of this tool with selected results. Section 6 concludes with a short summary and further steps.

## Self-regulated Learning and Scaffolds

Self-directed, resource-based learning with web resources is a process that is quite demanding for learners: they have to plan, monitor and reflect on their learning process in order to reduce disorientation and enhance quality of their learning achievements. In the following, we present particularities of this kind of learning and possibilities to support it using Scaffolds.

### Self-regulated Learning

It has been shown that supporting learners conducting the tasks mentioned above can improve the learning experience and the outcome [8] (e.g. by providing training or support learners writing a learning diary). For learning scenarios using web resources, i.e. hypertext documents, supporting self-regulated learning has shown to improve learners' understanding and conceptual knowledge of a topic [1].

Central to the theory of Self-Regulated Learning is the notion that learning is a process that is self-directed and needs regulation on the learner's side. According to Boekarts [3], three different systems have to be regulated in order to learn self-directed:

The cognitive system is performing task editing strategies, the learner will choose a strategy that he deems to be effective and efficient. For example, a learner who is researching information on the internet has to think about search query words that are likely to lead to success, i.e. relevant result resources. In his motivational system the learner regulates his volitional and motivational state, so that he will for example start a learning episode, overcome procrastination or better cope with obstacles. Finally, in the metacognitive system, the learner sets learning goals, devises plans and strategies for executing the actual learning process, monitors his progress on his actions, re-adjusts them if necessary and reflects on his learning process, eventually leading to forming of strategies to enhance his learning processes.

Schmitz and Wiese [8] partition the learning process in three phases: before learning, during learning and after learning. Those phases may be combined with the three systems to be regulated [9]. As we focus on metacognitive processes in this paper, we will subsequently only consider processes that are executed in the metacognitive system.

According to the theory of Self-Regulated Learning, learners profit from different metacognitive processes performed in each respective phase (see Table 1): Before learning (pre-actional phase), the learner performs goal-setting and planning, whereas while learning (actional phase), the progress and course of actions are monitored and – if necessary – adapted to possibly changed circumstances. Finally, after having learned (post-actional phase), reflection processes are executed in order to optimize future learning processes.

Table 1. Overview of phases and respective metacognitive processes according to [2]

| Phase | Metacognitive processes |
|-------|------------------------|
| Pre-actional | Goal-Setting and planning |
| Actional | Monitoring, adapting

## Implementation and Evaluation of a Tool for Setting Goals

## The Theory and Background

The theory of Self-Regulated Learning postulates specific processes that contribute towards a high-quality learning process. The concept of scaffolding defines and describes different possibilities to realize learner supports. Combining both approaches, learning processes can be assisted and supported according to the presented theoretical principles.

## The Goal-Management Tool

In this section we will derive the concept of a goal-management tool for internet research from the presented theoretical principles and present the implementation. Learners can enter goals, organize them into goal hierarchies (setting super- and sub-goals), move them via drag&drop and attach found resources relevant to the respective goals. Each goal can have an arbitrary number of sub-goals and resources, organizing everything in a tree structure with exactly one super-goal – analogue to the directory structure of a common file system.

### Conceptualization

The goal-management tool is based on the partition of the learning process into the three phases before learning, while learning and after learning. We focus on the metacognitive processes of goal-setting, planning, monitoring, regulation and finally reflection and modification of the learning process. The scaffolds that support those processes are implemented indirectly, which means that the learner is not instructed to take direct action, but he may choose to use the functionality if he sees the need to.

Before beginning with the internet research, the learner chooses a goal-directed approach and plans his course of actions in the learning process. For example, if a learner has the task to research information for the topic "Classical antiquity", he may begin to structure his approach with the goals "I need to get a general idea about the ancient Rome" and "I need an overview of the ancient Greece". Each goal can be further subdivided into specific sub-goals, e.g. the ancient Rome may contain the sub-goals "Roman Republic" and "First Triumvirate". This way, the learner organizes his research goals into a goal hierarchy. Thus, the tool supports processes of goal-setting and planning.

During the learning process the learner may attach found information in web resources to the set goals and rate their relevance for the respective goal. Monitoring the learning process is supported by multiple scaffolds, e.g. setting the progress of finishing a certain goal and displaying the goal hierarchy in combination with the already found web resources. Both stimulate the learner to contemplate where in the learning process he is right now, which goals he has already achieved and what goals are still open. In order not to loose focus on the goal the learner is following right now, it is possible for him to activate one goal at a time. This goal is displayed prominently, giving a reminder not to go astray and antagonizing the well-known "lost-in-hyperspace" phenomenon (experiencing disorientation due to information overload and aimlessly following hyperlinks). Further, all goals and found resources can be displayed as a knowledge network and an overview, displaying all goals and resources. This enables the learner to reflect on already found information and the current course of action. Is the learner aware of his inefficient advance, he may alter his research behaviour according to his current situation – for example by defining new goals, re-structuring his goal hierarchy or focussing on other goals that are more promising at the moment. Hence, during the research the processes of monitoring and regulation are supported.

### Implementation and Data Model

Research and learning using web resources mostly takes place in the web browser, as most web resources are represented as HTML mark-up. The browser is a virtual window to the internet, downloading and rendering web resources and displaying them to the learner. Therefore, the tool has been implemented as an add-on to the popular open source web browser Firefox.

[Figure 1: The sidebar displaying the tree of goals and resources. The goal "plebs and peasants" is currently activated. At the bottom the buttons for displaying the knowledge network and the overview are located.]

Here's the cleaned Markdown:

## Implementation and Evaluation of a Tool for Setting Goals

## Overview
An exemplary goal hierarchy displayed as a knowledge network. Resources with the same tag "Rome" are marked. A resource's detailed description (snippet) is shown in a tooltip.

Due to portability and extendibility reasons the core functionality has been realized in a Java applet. Data transmission with Firefox and the web resources is performed via an ECMAScript interface that both orchestrates the data flow and forwards user interaction within Firefox or the web resource to the applet. The graphical user interface and data storage has been implemented in Java. Applets as a technology were chosen, as they allow integration in HTML as well as in XUL (the Firefox-specific XML dialect for creating graphical user interfaces).

Because we focus on short-term learning episodes, we confine properties of goals to a title, a description (which may serve to outline a course of actions or additional information) and the level of progress (with the stages "not started", "25%", "50%", "75%" and "finished"). This level of progress can be set by the learner to keep an overview of his open and finished goals. Further, goals can be tagged (i.e. attaching freely chosen key words) for organization and display in the knowledge network. For longer learning episodes (which are not covered here), additional, mostly temporal, properties are planned, e.g. planned start, planned duration etc.

The web resources are inserted into goals by use of the "import" functionality, similar to the process of bookmarking in Firefox. Similar to goals, resources have a title, a description, a relevance rating and tags. As the information need a learner has is often quite specific, just bookmarking a whole web resource is often not enough. Instead, the possibility to extract only the relevant part of the information is more target-oriented towards the real learning goal. Thus, the selected fragment (called snippet) of an imported web resource is stored in the description; learners can access that relevant information later without having to access the original web page. Rating the relevance of a resource or the snippet with the stages "not rated", "not relevant", "a little relevant" and "relevant" is possible as well.

On starting up the web browser, the goal-management tool is displayed in the sidebar. Its user interface shows an overview of the current goal hierarchy and resources. Alternative representations of goals and resources may be used, e.g. a display of the goal hierarchy as a knowledge network. While browsing web resources, they can be imported into the goal tree at the current selection. Both goals and resources may be edited and reorganized later-on.

## The Previous Evaluation
In 2008, we performed an evaluation focussing on the research questions, what differences learning online using different tools make and how explicit prompts are given in order to initiate goal-setting, planning and reflection processes. We asked 64 participants (mainly psychology bachelor students) to answer a knowledge test about the topic "Classical Antiquity" (that we expected the participants to have little prior knowledge about) both before and after learning using Wikipedia for 45 minutes. We formed four different treatment groups:

- One group having pen and paper available as a means to persist findings
- One group using the built-in bookmarking functionality of Firefox
- Two groups using our goal-management tool

The latter groups differed in the given instructions, one group just used the tool without any instructions, the other group was directly scaffolded to set goals, monitor their progress and finally reflect on their learning processes.

In conclusion, we found that scaffolds do influence learning processes. Still, we encountered several issues with the study design. First, we tried to emulate "realistic" environments for the learners, i.e. forming a control group learning using bookmark functionality and a pen and paper group. Therefore, the groups were not comparable in some ways, and we think that influenced the learning outcomes. For example, the pen and paper group did not have to learn using a new tool and could quickly outline information, setting relations between content that was not possible for the other groups. Additionally, the bookmarks group was missing the possibility to save web resource

Here's the cleaned Markdown:

## Evaluation Questions and Design

Additionally, following research questions were of interest:
- What are the differences between learners that organize their found web resources with folders (the control group) and learners that set goals prior to learning (the treatment groups)?
- What are the differences between learners that are explicitly instructed to execute metacognitive processes (the control group and the first treatment group getting indirect scaffolds) and learners that are free to use the functionality to support their metacognitive processes (the treatment group prompted by direct scaffolds)? Thus, what are the benefits of providing direct scaffolds?

### Evaluation Design

104 students (mostly students of Psychology (74.5%) and Education (13.2%), more than 90% being in their first to seventh semester and being between 19 and 28 years of age) could be won for participating in our study. Due to the field of study a majority of the participants were women (72.6%) and 88.7% speak German as first language. The participants were randomly allocated to three groups:

The Control Group (CG, n=34) was using a stripped-down goal-management tool that didn't exhibit the goal-setting functionality. "Goals" were coined "Folders" and could not be activated or attributed progress. Still, the CG was able to put resources and snippets thereof in a folder and access the different displays of the collected data.

The First Treatment Group (TG1, n=35) used the goal-management tool with the complete functionality but was not given instructions on how to organize their research. Hence, this group realized indirect scaffolds as given in section 2.2. The Second Treatment Group (TG2, n=35) used the same tool with integrated metacognitive prompts aimed to activate and support the metacognitive processes "defining relevant goals", "keeping the active goal in mind", "finding relevant pages", "importing relevant information", "assigning relevant information to the relevant goal" and "learning relevant information". For example, before beginning the research (i.e. actional) phase, the learners were instructed to set goals for the research. Further, during search, instructions to reflect on whether the found information was relevant for the currently followed goal were given (see Fig. 3). Five minutes before the end of the evaluation, this group was instructed to reflect on their results.

The overall study was performed in two sessions for each participant. The first session was exclusively for training with the respective tool variant and the second was the research task. The first session was always held the day before the research task and gave the participants a possibility to get to know the handling of the respective tool variant they would use on the research task. First, they watched an introduction in the respective tool, showing common tasks and the functionality of the tool. Then, the participants were presented a small research task in a topic they were confident with, where they could apply the functionality of their tool variant. Further, demographic data and data about the participants' self-conceptions about their computer (estimation of their familiarity in using computers and knowledge about relevant computer- and internet-related concepts) and skills of self-regulated web search (i.e. the competencies to plan and structure their learning processes, based on items of a standardized questionnaire according to [13]) were collected.

The second session was designed to be approximately 1.5 hours in length. Participants were given a first achievement test (multiple-choice) about the "Classical Antiquity" – a topic that is well-covered in Wikipedia and, as we knew from the previous study, students do not have a lot of detailed prior knowledge about. An example for such a question is "Which event led to the end of the Roman Kingdom?" After each question the participants were asked to state how certain they were with answering this question (from the extremes "I guessed" to "I know and I am sure" in four steps). There were ten different versions of the test, which differed in the order the questions were provided. Participants were given the hint that they would receive exactly the same test again after the learning episode. Each participant received a feedback on his individual test performance. Ten questions

## Results of Evaluation

## Background and Setup
For evaluating this study, we chose "Classical Antiquity" as a research topic that students were not familiar with. Prior knowledge assessment showed that 83% had "rather marginal" or "little" background in Roman Antiquity (only 2% claimed "very good" knowledge), and 86% had "rather marginal" or "little" background in Greek Antiquity (only 1% claimed "very good" knowledge).

Due to the nature of tasks, goals were usually set in a topic-oriented way, with process-oriented goals (e.g., "I need to get an overview of...") being rare.

The following results are based on log files and questionnaires.

## Selected Group Differences
To analyze differences between all three groups including differences within specific phases of action, we conducted one-way ANOVAs with quantitative log data as independent variables. Table 2 presents selected significant results.

### Significant Group Differences based on Participants' Actions

Category | Phase of action | ANOVA
---------|----------------|--------
Creation of Goal / Folder | Pre-actional | F(2, 102)=7.729, p<.01, r=.36
Editing Goals / Folder | Pre-actional | F(2, 102)=3.801, p<.05, r=.26
Moving Goals | All | F(2, 102)=3.600, p<.05, r=.26
Moving Goals | Pre-actional | F(2, 102)=6.280, p<.01, r=.33
Following new Link | Post-actional | F(2, 102)=6.885, p<.01, r=.34
Import Resource | Pre-actional | F(2, 102)=5.106, p<.01, r=.30
View Resource | Post-actional | F(2, 102)=3.827, p<.05, r=.26
Editing Resource | Pre-actional | F(2, 102)=3.105, p<.05, r=.24

The results show differences between groups in the pre-actional phase regarding goals/folders created and edited, links followed, and number of imported, viewed and edited resources. The number of viewed resources and links followed in the post-actional phase also varied between groups. Differences in moved goals/folders were found across all phases.

## Research Questions Analysis

### Treatment Groups vs Control Group
When comparing experimental groups (TG1+TG2) with the control group (CG):

- TG1 and TG2 set significantly more goals in the pre-learning phase
- Opened fewer new web pages during pre-actional and post-actional phases
- Restructured goal hierarchy more often while planning
- Updated goals and performed more Wikipedia searches during actional phase
- More frequently revisited collected resources after learning

### Direct vs Indirect Support
Comparing TG2 (direct support) with TG1 and CG (indirect support):

- TG2 set more goals in pre-actional phase but fewer later
- Opened fewer web resources while researching
- More frequently reorganized goals
- Opened significantly fewer new pages before and after learning
- More often reflected on found relevant resources
- Used goal activation functionality more frequently than TG1

## Conclusion
The results demonstrate that the goal-setting tool affects how learners approach web research by:
- Executing more metacognitive processes
- Planning more thoroughly
- Better monitoring progress
- Responding to changed circumstances
- More frequent reflection on learning outcomes and resources

No significant differences were found between groups in terms of performance (correctly answered questions), possibly due to the evaluation's short scope and exclusion of third variables.

Here's the cleaned Markdown:

## Selected Correlations between the Variables

To investigate further dependencies between variables we calculated several correlations accounting for different patterns within different groups and phases of action. A selection of significant correlations is presented in Table 3.

Table 3. Selected Significant Correlations, *:p<.05, **:p<.01

| Group | Variable 1 | Variable 2 | Correlation r (1-tailed) |
|-------|------------|------------|------------------------|
| CG | Computer Competence | helpful in e-learning | .364* |
| | | would use it | .445** |
| | | snippets useful | .472** |
| All | Goals created | Computer Competence | .356** |
| TG1+TG2 | Goals created | Search Competence | .292*; .304* |
| CG+TG2 | Goals created | PANAS "active" | .325*; -.331* |
| All | Opened page | Positive emotions | -.256** |
| TG2 | Opened page | Negative emotions | .436** |

In the Control Group (CG), the higher the participant's computer competence was rated by himself, the more he thought e-learning with web resources to benefit from using the tool, the better he liked the goal-management tool and the more valuable he estimated the snippet functionality for e-learning. In both treatment groups, computer competency was not correlated to those variables. This might indicate that participants of the CG implicitly knew how to use the stripped-down version of the tool if they had a high computer competence. Participants of the other groups, however, were supported in setting goals, monitoring them and reflecting on the learning process. Therefore, giving them that much support might have neutralized the influence of computer competence on organizing their research process.

Further, creation of goals correlated with computer competence in all groups, meaning participants describing themselves as competent in using computers set more goals. Moreover, participants of the treatment groups set more goals the more confident they were of their ability to perform a good web research. These results indicate that the ability and to use technology are major predictors for efficient use. Curiously, there were clear correlations between the emotion to be "active" and the amount of goals/folders created – for the CG, it was positive, meaning that participants in this group felt themselves to be more active when setting more goals, whereas for the TG2 it was negative – the more goals a participant of this group set, the less active he felt. This might indicate that a strong direct support, among all the positive impact, might cause learners to feel less active. To be provided with more freedom, however, might cause the feeling of activeness in terms of being in charge of ones' own actions.

Eventually, the more web resources were opened, the less positive emotions the participants in all groups had and the less activated the participants felt. Additionally, for TG2, negative emotions (PANAS) were correlated to the number of opened resources. This means that browsing the web resources for information aimlessly (thus browsing a lot of different web resources, eventually becoming "lost in hyperspace") affects the emotions of learners negatively. Still, participants in the Control Group didn't have negative emotions when browsing more pages. This might be due to the fact that learners who did not set search goals did less encounter their browsing of many resources as being ineffective and accordingly experienced less negative emotions.

## Conclusions and Further Steps

In this paper, we presented a goal-management tool that is based on theoretical principles of Self-Regulated Learning. We introduced the term Scaffolds for functionality supporting meta-cognitive processes during learning episodes. The implemented functionality was well received by the participants of our study: nearly all of them (91%) saw the need to being able to store only small, relevant snippets of a web resource in learning with web resources.

We evaluated the goal-management tool with a study. Results show that using our tool for setting goals affects the way learners approach research using web resources: they execute

Here's the cleaned Markdown:

## The Impact of Prompting in Technology-Enhanced Learning as Moderated by Students' Motivation and Metacognitive Skills

Pantelis M. Papadopoulos, Stavros N. Demetriadis, and Ioannis G. Stamelos

Aristotle University of Thessaloniki, Informatics Department, PO Box 114,  
54621 Thessaloniki, Greece  
{pmpapad,sdemetri,stamelos}@csd.auth.gr

## Abstract

This work explores the role of students' motivation and metacognitive skills as moderating factors that influence the impact of an instructional method in the ill-structured domain of Software Project Management (SPM). In order to teach aspects of the SPM domain, we developed a web environment for case-based learning and implemented additionally a questioning strategy to help students focus on important parts of the case material. The paper presents the results from three studies revealing how students' motivation and metacognitive awareness influenced their engagement in the cognitively challenging situations induced by the method. The implication for instructors and designers is that implementing a promising method, to help students efficiently process the complex material in an ill-structured domain, might not always lead to the desired learning outcomes. Students' motivation and metacognitive skills should also be addressed, in order to maximize the potential benefits of instruction.

**Keywords**: Ill-structured domains, Question prompts, Case-based learning, Technology-enhanced learning, Motivation, Metacognitive skills.

## 1. Introduction

Teaching in an ill-structured domain poses additional instructional difficulties as compared to well-structured domains [1, 2, 3]. According to Spiro et al. [4], in an ill-structured domain: (a) each case or example of knowledge application typically involves the simultaneous interactive involvement of multiple, wide-application conceptual structures, each of which is individually complex, and (b) the pattern of conceptual incidence and interaction varies substantially across cases nominally of the same type (p. 60). Students, therefore, need to study several domain cases in order to understand how contextual factors in various situations affect the successful (or not) knowledge application.

Many researchers argue that all domains involving the application of knowledge to, unconstrained, real-world situations are substantially ill-structured [e.g., 4, 5]. This notion applies widely in Computer Science Education, a domain we are primarily interested in. For example, while the teaching of programming utilizes well-structured schemata characterized by abstractness, developing a software project for use in the

[References section preserved but omitted for brevity]

## The Impact of Prompting in Technology-Enhanced Learning

## Introduction

To efficiently introduce students to the intricacies of ill-structured domains, we developed eCASE, a web environment for case-based learning, where instructors can upload and organize the presentation of complex case material. As our intention was to further improve the learning experience, we also embedded in the system a questioning strategy to help students focus on important aspects of the presented cases. This, in turn, generated interesting research questions and we proceeded to test the effectiveness of the instructional technique (i.e. the questioning strategy) in three different situations.

The first study explored the impact of the question prompts in three conditions of individual learning (non-prompted, prompted to write answers, prompted to simply think of answers). The second study engaged students in collaborative learning exploring the potential of peer interaction. The third study involved postgraduate students (the students in the two other studies were undergraduates) focusing on students' attitudes in a condition where providing written answers to the prompts was optional. While the research scope of each of the three studies was different, two factors appeared repeatedly in the analysis of students' activity. Quantitative and qualitative data from these studies compose a picture revealing that students' motivation and metacognitive awareness had a major impact on the learning strategy the students applied and, consequently, on their performance.

In the following, we present:
- The theoretical background of our approach
- The research design and results of the three studies
- A discussion on the role of student motivation and meta-cognitive skills, as moderating variables that should be considered by instructors and instructional designers

## Theoretical Background

### Question Prompts as Student Scaffolds

Scaffolds are instructional interventions that aim to help students to develop deeper understanding of the material which might not be within their immediate grasp [6]. One widely implemented form of scaffolding is through the use of question prompts, which are sets of questions, used to guide the learning activity. Research indicates that questioning strategies can be highly beneficial for students, helping them in important cognitive functions, such as stimulating prior knowledge, enhancing comprehension, and facilitating problem-solving processes [7, 8]. Question prompts have been used in technology-enhanced learning environments to help direct students towards learning-appropriate goals (e.g., focusing student attention and modelling the kinds of questions students should be learning to ask [6, 9]).

### Scaffolding in Case-Based Learning

Case-based learning is often cited as a successful teaching method for ill-structured domains [7]. When practicing case-based learning (CBL), two instructionally challenging issues need always careful interventions [10]:

1. How to help students avoid misconceptions by not oversimplifying the material. Students need to work through several cases to develop deeper domain-specific knowledge (such as domain concepts, rules, and principles) [11].

2. How to support students apply their knowledge to new problem situations, which may significantly differ from those encountered in the instructional setting. Kolodner [11] argues that "people...do not always remember the right cases on which to base their reasoning and argumentation". 

We argue that embedding question prompts in case material can be such a productive intervention, as these questions help students focus their attention on important contextual issues. In order to construct a method-specific (and not domain-specific) questioning strategy, we stipulate that the question prompts should trigger those cognitive processes that are relevant to generating the context of a situation. According to Kokinov [12], there are at least three such processes: perception, memory recall and reasoning. It might be beneficial, therefore, for learners who study complex case-based material, to be prompted to:
- Identify and focus on important events in the situation (perception process)
- Relate these events and their impact to what is already known from other similar situations (memory recall process)
- Reach useful conclusions (reasoning process) based also on the results of the two previous steps

### Motivation and Meta-cognition

"Motivation" refers to factors of the learning situation that make students activate their cognitive processes to accomplish the objectives of the activity. According to the ARCS model, four critical

## The Impact of Prompting in Technology-Enhanced Learning

## Common Characteristics of the Three Studies

In the following, we present in juxtaposition the three studies we conducted, investigating the effectiveness of our questioning scheme under different conditions. To be concise, we present first the common characteristics of the three studies and then we continue with the goals and findings of each study, focusing on both students' performance and attitudes, as depicted through pre- and post-tests, and interviews.

### Material

Our interest is mainly Computer Science education, and for this we chose as domain of instruction Software Project Management, a domain of considerable complexity and need for knowledge transfer in job-related situations. SPM is hard to teach and learning relies largely on past experiences and project successes and failures. Difficulties in this domain stem from the fact that software processes are not well-defined, their product is intangible and often hard to measure, and large software projects are different in various ways from other projects [19]. In addition, many aspects of SPM are not adequately formalized and involve subjective quantification, e.g. risk prioritization. As a consequence, software managers recall and use their knowledge about projects they have managed (or are aware of) in the past, and base their decisions on management patterns and anti-patterns. It is worth mentioning that this field has been ranked first among 40 computer science topics whose instruction needs to be intensified in academia because of demands in professional context [20].

For the purpose of our research, we developed eCASE, a web-based environment for case-based learning in the SPM domain. Studying in the environment involves solving ill-structured problems, presented to students as "scenarios". A scenario is a problem-case anchoring student learning in realistic and complex situations in the field. After presenting the problem, a scenario poses to students some critical open-ended questions (scenario questions), engaging them in decision-taking processes, as if they were field professionals.

Before answering scenario questions the learners are guided to study supporting material in the form of "advice-cases". An advice-case is a comprehensive case presenting some useful experience in the field, to help students analyze the demands and risks of Software Project Management. Each scenario was accompanied by a number of related advice-cases, which were selected and adapted from authentic SPM cases reported in the literature [e.g., 21]. Advice-cases are organized in smaller parts ("case-frames") each one presenting a domain theme, that is, some meaningful and self-contained aspect of the whole case. For example, an advice-case could possibly be organized in three case-frames, under the titles "The role of end-users", "Changing requirements" and "Executive support and commitment", which are considered as important themes in the SPM domain. The aforementioned observe-recall-conclude questioning scheme typically appears in each case-frame, prompting students to reflect on the material they just read and provide answers to the three following questions:

1. What concrete events (facts, decisions, etc.) imply possible problems during project development?
2. In what other cases do you recall having encountered similar project development problems?
3. What are some useful implications for the successful development of a project?

### Pre- and Post-Testing

The pre-test was a prior domain knowledge instrument that included a set of 6 open-ended question items relevant to domain conceptual knowledge (e.g., "What role can/should the end-users play in the development of a software project?"). The post-test comprised two sections focusing on: (a) acquired domain-specific conceptual knowledge, and (b) students' potential for knowledge transfer in a new problem situation. The first section included three domain conceptual knowledge questions. The answers to these questions were not to be found as such in the study material, but rather to be constructed by taking into account information presented in various cases. The second section presented a dialogue-formatted scenario. In this scenario, various stakeholders (company CEO, CFO, clients, technicians etc.) were discussing managerial issues of an ongoing software project in an everyday professional context. Students had to identify elements in the scenario that might be indicators of inefficient management and suggest resourceful alternatives.

### Procedure

Here's the cleaned Markdown:

## The Impact of Prompting in Technology-Enhanced Learning

For all statistical analyses a level of significance at .05 was chosen. To validate the use of the parametric tests in the first and the second study, we investigated the respective test assumptions and results showed that none of the assumptions were violated.

The interviews lasted about 10 minutes per student and were semi-structured and audio recorded. The interviews transcripts were used for content analysis.

## First Study: Writing vs. Thinking

### Research Scope

The first study aimed to investigate (a) the effectiveness of the prompting technique, when students studied in a self-paced mode, and (b) whether the way that the students answered the questions (providing answers in written format vs. simply think of the answers) had an impact on the learning outcomes.

When designing a technology-enhanced learning environment, the choice between asking students to explicitly write the answers and prompting to simply make them think of answers is not an easy one to make. Writing has been used as an effective tool for constructive learning [22], supporting students to develop critical thinking and increase their analysis, inference, and evaluation skills [23]. However, a questioning strategy that requires written answers to each and every open-ended question prompt may increase significantly students' cognitive load, thus posing a threat to their motivation for meaningful engagement. Some researchers suggest that students should answer question prompts in writing to avoid superficial engagement [e.g., 24], while others think that periodically asking learners to reflect on the question prompts should be sufficient [e.g., 25].

### Participants

The study employed 59 undergraduate Computer Science students who volunteered to participate. The students were randomly assigned in three conditions: Non-Prompted (NP) (n = 20); Writing Condition (WC) (n = 19); Thinking Condition (TC) (n = 20). Students who successfully completed all the phases of the study were given a bonus grade for the course. Students were domain novices (this was a prerequisite for participation in all the studies) and they had never before been typically engaged in case-based learning activity.

### Treatment

The students in the NP group studied the advice-cases without the question prompts and they were able to answer the scenario-questions after just navigating through the advice-cases. The students in the WC group had to provide written answer in the question prompts that appeared after each case-frame. Only then, they were permitted by the system to answer the scenario-questions. Finally, the TC group studied the advice-cases with the question prompts, but students were only asked to reflect on the material and spend some time thinking of possible answers to the prompts. Similarly to the NP group, the students in the TC were able to answer the scenario-questions after just navigating through the accompanying advice-cases.

### Results

Inter-rater reliability was high for the pre-test (ICC = .90), the conceptual (ICC = .88), and the transfer (ICC = .84) scores. Table 1 presents students' performance in the pre-test and the two measures of the post-test. One-way analysis of variance (ANOVA) results indicated that students were domain novices scoring very low in the pre-test and that the three conditions were comparable regarding students' prior knowledge (F(2,56) = 1.48, p = .23). The results of the multivariate analysis of covariate (MANCOVA), using the pre-test score as covariate, revealed a significant main effect for the prompting condition regarding the two dependent variables of the post-test (Wilk's Lambda: F(4,108) = 2.38, p = .04). Univariate tests for each of the post-test measures showed significant main effects for the prompting condition (conceptual: F(2,55) = 3.68, p = .03; transfer: F(2,55) = 3.53, p = .03). Post hoc tests showed that the students in the writing condition outperformed non-prompted (conceptual: p = .02; transfer

## The Impact of Prompting in Technology-Enhanced Learning

## First Study Results (continued)
reflecting on the same observe-recall-conclude questions was rather tedious. This attitude made these students practically shift into the non-prompted condition. However, there were no differences between the two sub-groups of the TC group (either those engaged on thinking of answers or those simply skipping the prompts) and they both achieved significantly lower scores than the WC group.

## Second Study: Peer Interaction

### Research Scope
The second study investigated how the context-oriented prompting technique could be combined with a collaborative learning method, to scaffold students in ill-structured domains.

Peer interaction is often considered as an effective scaffolding method, research, however, has consistently revealed that freely collaborating students may lack the competence to engage in fruitful learning interactions, without external support and guidance. As a remedy, many researchers explore the potential of scripted collaboration. A collaboration script is a teacher-provided didactic scenario designed to engage a team of students in essential knowledge-generating interactions, and "scripted collaboration" is the practice of actually implementing a collaboration script to have students work within the scaffolding framework provided by the teacher. A computer-supported collaboration script is, accordingly, a computerized representation of a collaboration script.

Script implementation is subject to students' appropriation process, meaning that students are expected to "filter" and adjust the script to their own context during run-time. Dillenbourg underlines this distinction, suggesting that one should distinguish between ideal (the activity as prescribed by the teacher), mental (the mental script representation that the group builds from teacher's prescription) and actual (the actual task and interactions that students engage) script, in order to conceptualize the different teacher's and students' script perspective.

### Participants
The first and the second study were conducted at the same time. Hence, the same Non-Prompted group was used as a control for these studies. Initially, a total of 77 students volunteered. Next, students were asked whether they would like to work collaboratively or not. Finally, 18 students formed 9 dyads (CSCL group), while the rest 59 students were randomly assigned to the three conditions described in the first study. All the students were domain novices, without formal experience in case-based learning, and were given a course bonus grade after completing all the study phases.

### Treatment
As described earlier, the NP group studied the advice-cases without the question prompts and was able to answer the scenario-questions after just navigating through the advice-cases.

For the CSCL group, the observe-recall-conclude questioning scheme appeared once at the end of each advice-case and student dyads had to follow a specific collaboration script, in order to answer the questions and complete the study of the advice-case. The script had three steps guiding students through a peer review process:

1. Each student in a dyad had to answer the questions individually. After both students answered the questions, their answers became available to each other.
2. The students reviewed individually each others answers and identified issues of agreement/disagreement.
3. The students had to collaborate, discuss their reviews, and agree on a common final answer including also argumentation about their choice to present or dismiss issues that appeared in their individual answers. To make collaboration easier, the students were allowed to use the medium of their choice during discussion (eCASE, face-to-face meeting, phone call, email etc.).

The script ends when one of the students in a dyad submits the final common answer in the environment. The same script was applied, while answering the scenario-questions. The students, as always, had to complete the study of the advice-cases, in order to answer the scenario-questions. The collaborating students had to self-organize their activity, in order to communicate and maintain an efficient pace in submitting their answers.

### Results
Inter-rater reliability was high for the pre-test (ICC = .90), the conceptual (ICC = .88), and the transfer (ICC = .85) scores. Table 1 presents the pre- and post-test scores of the two groups

Here's the cleaned Markdown:

## The Impact of Prompting in Technology-Enhanced Learning

### Collaboration Patterns

- **Strong interaction.** Two dyads demonstrated a pattern with almost none interaction. In these dyads, communication was usually one-sided. After both students submitted their individual answers, one of them was solely responsible for the formation and submission of the final answer, considering also comments sent by the other student concerning the two individual answers.

- **Weak interaction.** Another two dyads demonstrated a pattern with almost none interaction. In these dyads, communication was usually one-sided. After both students submitted their individual answers, one of them was solely responsible for the formation and submission of the final answer, considering also comments sent by the other student concerning the two individual answers.

- **No interaction.** Lastly, two other dyads worked in a totally individual mode, as one of the students was usually completely non-participating after submitting the individual answer, while the other student had to write and submit the final answer without any feedback from his or her partner. Additionally, the inspection of students' answers in the environment revealed that in some cases students were submitting superficial individual answers, only to make the system promote them to the next step of the script. This pattern of collaboration clearly violates the ideal script as the instructions were to meaningfully answer the questions and contribute to the effort of the team through interaction and collaboration.

The small number of dyads involved prohibits the quantitative analysis between these four collaboration patterns. It seems reasonable to assume that in a situation where students' engagement and collaboration in the activity were improved their level of learning might also have been improved, although this remains to be examined.

Interviews also revealed misconceptions about the ideal script that led students to unpredicted behaviors distant to the script's goal. For example, the examination of the answers of a dyad showed that the first student was initially submitting comprehensive and good answers, while the other student was answering poorly in short. During the week, the answers of the first student got significantly shorter and adequate analysis was often missing. When asked about, the second student said that she asked her partner to give shorter individual answers to eliminate the differences between their answers and be able to submit a common final answer with more ease. In this student's mind, agreement between partners was conceived as a script requirement and as a general goal to submit a common answer, and not necessarily a more complete answer.

### Third Study: Engaging Postgraduates

#### Research Scope

The third study engaged postgraduates and focused on the possibly different strategies that these students might implement, when learning in the environment.

In general, postgraduates are considered as more advanced learners and research on the expertise reversal effect suggests that instructional design techniques that are effective for beginners may not be effective for more experienced learners. In the previous two studies, results showed higher performance for the WC group, although the prompt-induced workload was an issue for many students. In this exploratory study, we wanted to investigate whether postgraduates would demonstrate a higher level of metacognition in the examined setting and whether their performance and attitudes would differ from those of the undergraduates. The different profile of the students participated in this study and the providing of a stronger motive for achieving higher performance enabled us to analyze the role of motivation and metacognitive skills in the effectiveness of our prompting method.

#### Participants

The study employed 19 students with a diploma in Economics attending an interdisciplinary postgraduate program in Informatics and Business Management. Students were domain novices, but they had considerable experience in learning with cases, as this method was widely applied in their undergraduates courses (e.g., Marketing). Additionally, the course grade bonus awarded to them was calculated based on their performance in the post-test (and not simply on their successful participation, as in the previous studies). This, we believe, gave postgraduates an additional motive for meaningful engagement.

#### Treatment

The students studied individually and the question prompts appeared in each case-frame of the advice-cases. As always, the students had to answer the scenario-questions in writing. However, providing written answers to the question prompts was mandatory only for the advice-cases of the first scenario. Afterwards,

## The Impact of Prompting in Technology-Enhanced Learning

## Discussion and Conclusions

Despite the different research scope in the three presented studies, the comparison of their characteristics and results highlights how students' engagement in a learning activity can be moderated by their motivation and metacognitive awareness. Figure 1 presents students' performance in the five groups participated in the studies.

[Figure 1. Students' performance in the five groups of the three presented studies]

First, one should note that the WC students (first study) were compelled to provide written answers and they outperformed the other two groups (TC and NP). This implies that the instructional method (questioning strategy) was indeed effective and that the additional cognitive load induced by the prompts was germane to the learning task. Remarkably, the highly motivated and meta-cognitively skillful postgraduates (third study) selected freely to follow a similar maximum engagement learning strategy (writing the answers) that eventually helped them to benefit most from the prompting technique. Postgraduates had considerable experience in case-based learning, acknowledged the role of prompts in providing better answer to the scenario-questions, and expressed a very positive opinion about writing the answers.

By contrast, less motivated and meta-cognitively more naive students (TC group in the first study) followed a learning strategy (skipping the prompts) that diminished the learning benefits of the method. Similarly, several collaborating students (second study) adopted a low-interaction version of the scripted activity, thus weakening the impact of the questioning technique through peer interaction (a presumably key learning mechanism in the collaborative activity). TC and CSCL students followed a low engagement strategy, either because of a conscious choice to minimize the workload or because their failed to understand how they would benefit from the proposed method of studying and processing the learning material.

The implication for instructors and designers is that implementing an effective and cognitively challenging method to engage students in deeper content processing in ill-structured domains does not guarantee the same level of learning outcomes in all situations. Students appropriate the instructional method through their own "lenses" of motivation and metacognition. This process may have beneficial or detrimental effect on learning, depending on the engagement strategy the students will choose to follow. Our experience so far indicates that a powerful didactical intervention should also aim to increase students' engagement, addressing motivational and metacognitive issues (and not necessarily forcing students to adopt high engagement strategies). As a key issue for further investigation, we suggest that learning environments for ill-structured domains should also provide opportunities for the learners to reflect on and self-assess their learning strategy. For example, prompting students to analyze the possible benefits and shortcomings of their implemented strategy (possibly by contrasting it to a successful strategy) might be highly beneficial for redirecting the strategy when necessary and becoming meta-cognitively more experienced.

## References

1. Jonassen, D.H.: Instructional design models for well-structured and ill-structured problem-solving learning outcomes. Educational Technology: Research and Development 45, 65-94 (1997)

2. Shin, N., Jonassen, D.H., McGee, S.: Predictors of well-structured and ill-structured problem solving in an astronomy simulation. Journal of Research in Science Teaching 40(1), 6-33 (2003)

3. Voss, J.F., Post, T.A.: On the solving of ill-structured problems. In: Chi, M.H., Glaser, R., Farr, M.J. (eds.) The nature of expertise, pp. 261-285. Lawrence Erlbaum Associates, Hillsdale (1988)

4. Spiro, R.J., Feltovich, P.J., Jacobson, M.J., Coulson, R.L.: Cognitive flexibility, constructivism, and hypertext: Random access instruction for advanced knowledge acquisition in ill-structured domains. In: Duffy, T., Jonassen, D. (eds.) Constructivism and the technology of instruction, pp. 57-75. Erlbaum, Hillsdale

Here's the cleaned Markdown:

## References

12. Kokinov, B.: Dynamics and Automaticity of Context: A Cognitive Modeling Approach. In: Bouquet, P., Serafini, L., Brezillon, P., Benerecetti, M., Castellani, F. (eds.) CONTEXT 1999. LNCS (LNAI), vol. 1688, p. 200. Springer, Heidelberg (1999)

13. Keller, J.M.: Development and use of the ARCS model of instructional design. Journal of Instructional Development 10(3), 2–10 (1987)

14. Keller, J.M., Kopp, T.W.: Application of the ARCS model to motivational design. In: Reigeluth, C.M. (ed.) Instructional Theories in Action: Lessons Illustrating Selected Theories, pp. 289–320. Lawrence Erlbaum Publishers, New York (1987)

15. Flavell, J.: Metacognitive aspects of problem solving. In: Resnick, B. (ed.) The nature of intelligence. Erlbaum, Hillsdale (1976)

16. Jehng, S.D., Johnson, S.D., Anderson, R.C.: Schooling and students' logical beliefs about learning. Contemporary Educational Psychology 18, 45–56 (1993)

17. Tyler, S.W., Voss, J.F.: Attitude and knowledge effects in prose processing. Journal of Verbal Learning and Verbal Behavior 21, 524–538 (1982)

[References 18-32 continue in same format]

## Creating a Natural Environment for Synergy of Disciplines

Evgenia Sendova¹, Pavel Boytchev², Eliza Stefanova², Nikolina Nikolova², and Eugenia Kovatcheva²

¹ Institute of Mathematics and Informatics, Bulgarian Academy of Science, 8, Acad. G. Bontchev, 1113 Sofia, Bulgaria
² Faculty of Mathematics and Informatics, St. Kl. Ohridski University of Sofia, 5, James Bourchier Blvd., 1164 Sofia, Bulgaria

jenny@math.bas.bg, {boytchev,eliza,nnikolova,epk}@fmi.uni-sofia.bg

## Abstract

The paper presents the authors' experience in stimulating the synergy of disciplines via active learning methods; the emphasis being on project based learning. Promoting this method is demonstrated in the context of teachers' training courses and developing a set of IT textbooks. Numerous examples are presented showing that the synergy of various disciplines is quite natural when performed in the context of studying IT. The project samples developed by teachers are inspired by ideas in textbooks and are accomplished by means of specially designed computer applications. The importance of working on projects tuned to the learner's interest as a decisive motivation factor is emphasized. In addition authors show that the bouquet of projects becomes more colorful with every new issue of the courses thanks to the learners' creativity and the collaborative knowledge building.

**Keywords**: Project based learning, learner's motivation, creativity, collaborative knowledge building.

## 1. Promoting Synergy among Disciplines in Teacher Education

To meets the needs of contemporary society synergy between various frontiers of education is crucial. It is not easy to step outside of an individual disciplinary box, learn the language of another field and if necessary, alter the perception. Still, all this become essential in creating collaborative approaches when working on professional projects in science, industry and art. The fields of medical informatics, bioinformatics, bioengineering, design of micro-engineering machines by means of new materials, computer generated art and music provide just a few examples.

In order to prepare the young people to integrate knowledge from different fields we have to expose them to such an experience as early

## Creating a Natural Environment for Synergy of Disciplines

## Background
But such an approach has been applied in Bulgaria in a natural way only in isolated educational experiments. One of them was designed by the Research group on Education (RGE) embracing Bulgarian scientists, educators and software developers with the ambition of facing the challenges of the information age [2]. The experiment was based on two main principles - the integration of disciplines and learning by doing. Its success depended to a great extent on the collaboration among the teachers including joint teaching. The experiment ran for 12 years (up to 1991) in 29 schools.

The policy makers of today feel very proud with reshaping the Bulgarian school – producing every year multiple sets of textbooks for each grade, introducing a new subject (IT) in 5-7 grades, providing a sufficient number of computers for each school. But the essential questions for us are: Do we use technology so as to stimulate thoughtful analysis, expressing oneself in creative ways, seeing and making the connection among various fields? How do the teachers teach by means of technology? How could we define an innovative teacher? Do the teachers get appropriate education and support for their new role of facilitators in the learning process, of research partners of their students?

In our capacity of people involved in the development of computer environments, teaching platforms and materials, as well as in the design of ICT-enhanced teaching strategies we will share an aspect of our work, related to approaches of encouraging teachers' creativity in multidisciplinary context.

## Specifics of Our Environment for Natural Synergy of Disciplines
The environment we try to create for natural integration of disciplines during our teacher education courses is based on a specific I*Teach (Innovative teacher) methodology. It deals with developing the so called ICT-enhanced skills defined as a synergy between the technical and the soft skills – transferable skills in the Life Long Learning society. Putting the emphasis on such skills in the context of ICT education has been addressed in the frames of Leonardo da Vinci I*Teach project [3]. The I*Teach methodology [4-6] has been proposed based on active learning methods – the student is in the center of the learning process, the teacher is a guide and a partner in a project work based on didactic scenarios encouraging learner's creativity.

[Figure 1. A typical I*Teach map of a project scenario]

We shall demonstrate how our approach of implementing the I*Teach methodology in a set of ICT textbooks and teacher's handbooks allows teachers and students to enhance the underlying ideas in their field of interest.

It is typical for the structure of the textbooks that there is a common thread linking: the tasks in a lesson; the lessons in a common ICT theme; and the ICT themes in the whole textbook [7]. The unifying theme of the final book of the series is the coding, which passes as a red thread through the whole content. Each lesson deals with ideas and tools for solving problems considered as milestones towards a final goal (Fig. 1).

The grand finale is a project (Decoding the past) requiring the students to put together all the subject knowledge and skills acquired during the school year and to work creatively in teams, and then – to present their results (Fig. 2a). For the purpose they are expected to decode a message and create computer models of ancient Greek vessels, to figure out their function (Fig. 2b) and thus - to help a local museum to restore them. And, similarly to all real-life projects, the multidisciplinary elements in the project scenario are interweaved in a natural way.

[Figure 2. (a) From an abstract I*Teach Scenario to a concrete Grand finale! (b)]

Let us note that the soft skills expected to be developed when working on this project include:
- Team work (planning, task distribution, communication skills, conflict resolving)
- Information skills (looking for relevant information, critical thinking)
- Presentation skills (preparing written and oral presentation of the milestones and the final product)

Furthermore, the project output is expected to be "put on the table", i.e. to have a fin

## Creating a Natural Environment for Synergy of Disciplines

## Multidisciplinary Projects

### Preparing the Ground

During the last 3 years we have applied the I*Teach methodology in a series of courses with in-service teachers. What proved to be a very valuable idea was to start with an informal introduction of the participants addressing questions of the kind: In which field do you feel an expert and how do you know that? Who was your teacher? What else would you like to learn well? This would give a valuable feedback not only to us but to all of them in terms of interests, background and expertise. Then we would offer a rather general theme offering a lot of room for interpretation and reflection (Be my guests, School out of doors, Which way now?, The Art of Communication). Next, we would group teachers in teams according to their interests. Usually the teams embraced experts in more than one field – a good ground for a multidisciplinary project. Then the teachers would start working on a real-life project formulated by their team after a discussion. The projects were usually rather complex and required a decomposition in subtasks. The team members would solve problems of various type based on their own experience, involving consultation in- and out of the team when needed. The ICT were just an element of the environment and thus were used when necessary.

One of important point is that the teacher trainers and the participants are open to taking into account all coming ideas. If we expect teachers to accept the ideas of their students without fear we should let them experience a similar phenomenon in the role of learners ready to take various paths towards the final goal. Of course, at the beginning of the course not all the participants were ready for such an approach but looking at the results of the team work they reconsidered their initial attitude.

### Looking Around through Mathematical Glasses

Our experience shows that technology enables the learners to approach mathematics with a special enthusiasm when they work on projects tuned to their interests. For instance a very important mathematical concept – the tessellation of the plane – could be perfectly demonstrated by numerous Escher's works and then explored in a computer environment.

The idea has been implemented in our IT textbook for 6 graders within a topic on integration of activities. The students are expected to apply their technical and mathematical skills in tessellating the plane by a shape of a clown's face (Fig. 3) and then - to demonstrate their artistic imagination by generating their own tessellations after Escher [8]. At a first glance, this is a project in fine arts but in order to paint the picture the students have to decompose the project in small subtasks – to find the minimal element tessellating the plane, to figure out what geometric transformation to apply and finally – to implement their skills in choosing a relevant computer environment and using it for accomplishing the goal.

We also used the scenario approach during the in-service teacher education the difference being that we gave the participants freedom to choose the final goal of the project. It was natural that they decided to work on projects involving the design of objects closely related to their professional orientation and/or hobbies – electrical light sources, hats, jewelry (Fig. 4). For the purpose they integrated not only various IT environments (Paint, Comenius Logo, Elica [9], [10] applications) but also knowledge in mathematics (symmetry, rotation in 2d and 3D, fractals), informatics (procedures with parameters, recursion), art. The scenario of their work followed the I*Teach model – setting the final goal the path to which is traced by milestones, e.g. to create a computer model of a rotational solid, to use the necessary mathematical information (in the case of the hats – the surface of the solid so as to calculate the material needed), to make a decoration by means of a Logo procedure or a graphics editor.

Our overall impressions were that although uneasy at the beginning the teachers were inspired by the freedom we gave them concerning the theme of their projects. They came up with a lot of original ideas about various multidisciplinary projects embracing not only mathematics and art but also ecology, geography and even physical education.

A very rewarding experience for us was the

Here's the cleaned Markdown:

## Informing the Design of Intelligent Support for ELE by Communication Capacity Tapering

## Conclusions

We have never seen anybody improve in the skills of working on projects by any means other than engaging in a project. Therefore, we cannot teach the art of working on multidisciplinary projects without engaging ourselves in such a work. With this in mind we encourage the teachers in expressing their creativity, knowledge and interests in a project chosen by them; we act as research partners of their teams and demonstrate how we attack the occurring problems. Looking back at the challenges they have overcome, and feeling proud with the results they and their peers have received, these teachers enter the schools with a newly gained self-confidence, ready to teach the way they have been taught. And if we manage to convince them that the school is not only a preparation for life but life itself we have achieved our goal.

Although good examples of teachers' creativity are not found in every school our endeavor is to spread their achievements through journals and conferences for teachers, and based on such achievements to enrich the in-service and pre-service teacher training. And we are not alone in this endeavor [11].

The main lesson for us as teacher educators could be summarized as follows: if we hope for a real positive change in education, we should bring today's and tomorrow's teachers in situations in which they would stop thinking about the future in terms of tests, exams or teaching pupils only. We should rather enable them to experience what they are doing as intellectually exciting and joyful on its own right.

## References

1. Boytchev, P.: Overview of Research Logo System. In: Brna, P., Dicheva, D. (eds.) Proceedings of the Eight International PEG conference, Sozopol, Bulgaria (1997)

2. Sendova, E.: Identifying Computer Environments and Educational Strategies to Support Creativity and Exploratory Learning. In: Davies, G. (ed.) Teleteaching 1998 Distance Learning, Training and Education, Proceedings of the XV IFIP World Computer Congress, Vienna/Austria and Budapest/Hungary, 31 August – 4 September, p. 889 (1998)

3. Innovative Teacher project site, http://i-teach.fmi.uni-sofia.bg (retrieved on March 5, 2009)

4. Stefanova, E., Sendova, E., Van Deepen, N., Forcheri, P., Dodero, G., Miranowicz, M., Brut, M., et al.: Innovative Teacher - Methodological Handbook on ICT-enhanced skills, Faleza-Office 2000, Sofia (2007)

5. Stefanova, E., Sendova, E., Nikolova, I., Nikolova, N.: When I*Teach means I*Learn: developing and implementing an innovative methodology for building ICT-enhanced skills. In: Benzie, D., Iding, M. (eds.) Informatics, Mathematics, and ICT: a 'golden triangle' IMICT 2007 Proceeding, CCIS. Northeastern University, Boston (2007)

6. Sendova, E., Stefanova, E., Nikolova, N., Kovatcheva, E.: Like a school (of fish) in water (or ICT-Enhanced Skills in Action). In: Mittermeir, R.T., Sysło, M.M. (eds.) ISSEP 2008. LNCS, vol. 5090, pp. 99–109. Springer, Heidelberg (2008)

7. Sendova, E., Stefanova, E., Boytchev, P., Nikolova, N., Kovatcheva, E.: IT education – challenging the limitations instead of limiting the challenges. In: Proceedings of CIIT 2008, Bitola, Macedonia (2008)

8. Seymour, D., Britton, J.: Introduction to

Here's the cleaned and normalized Markdown:

## Informing the Design of Intelligent Support for ELE

(e.g. teachers and researchers in the field of education), iterates through several stages in which students interact with the system, and ends with the system fully implemented to be used by the students. However, interviewing domain experts and even observing students working with such an environment is not enough since the introduction of intelligent components that can provide support has the potential to further transform the interaction, to the extent that previous observations can be rendered useless.

The aforementioned challenges can be tackled using appropriate research, design and development methodologies. Of particular relevance to our work are user-centered approaches which are becoming the norm within software engineering. A unified and promising approach is contextual design [2] which recognises that in-depth understanding of user behaviour requires observing and analysing situations in their actual context.

Our overall methodology for designing and developing intelligent support for TEL systems is inspired by approaches that recommend iterative design and development [3,4] as well as iterative formative evaluations [5]. Moreover, we are strongly influenced by the methods of design experiments or studies [6] which, through iterative, situated, and theory-based research, attempt to understand as well as improve educational processes [7]. A particular relevant methodology from the field of applied Artificial Intelligence in Education (AIEd) is Persistent Collaboration Methodology (PCM) [8] which is inspired by action research (see [9]) and advocates incremental research and development that can also contribute to theories of teaching and learning. PCM recognises not only the need an iterative approach and the transformative nature of interventions in education but also the need for a three-way persistent collaboration involving teachers and their students, researchers and technologists.

But just recognising the need for iterative design and research is not enough. To study the interested phenomena in their actual context, there needs to be a transition in the means of communication from those naturally used by humans to those that are available to the computer. The computer is limited in the amount of information that it can obtain from the student, and is also limited in the amount and types of feedback that it can provide. The limitations are both technical (e.g. natural language processing and generation) and pragmatic (e.g. humans behave differently with computers, i.e. they listen and read with different interest or attention). In some cases (e.g. in well-structured and well-researched and understood domains) this transition can be made abruptly, i.e. knowledge can be elicited from experts, and can be implemented as intelligent support in the system. In some cases, however, this fails to appreciate the difference in language and behaviour between both situations (a problem already noted in [10,11,12]).

This realisation has lead to the development of a method known as wizard-of-oz, in which unimplemented parts of a system are emulated by a hidden human operator. The method has been extensively used for system design and evaluation in the human-computer interaction (HCI) field [13,14,15]. Its importance has been understood especially in the design of dialogue systems [12,16], up to the point that tools to facilitate the preparation and execution of wizard-of-oz sessions have been recently devised [17]. In the last ten years the method has gained popularity for the design of Intelligent Tutoring Systems (ITS). However, there are many cases in the literature in which the process is not explicitly documented. This makes it more difficult to evaluate its usefulness and to employ it to its full potential. We argue that, for the design of TEL systems, it is crucial to pay special attention to the available modalities of the situation as well as the speed and freedom of the messages that the operator can use to provide support to the student.

We will refer to the combination of these concepts as the communication capacity of a situation, and describe it in detail in Section 2.

In this paper we present our methodology for designing intelligent support that is particularly suited for ELEs but is of relevance to all kinds of TEL systems. We examine issues that, to the best of our knowledge, have not been considered explicitly an

## Informing the Design of Intelligent Support for ELE

## Implementation, Studies, Analysis, and Design

![Spiral design and development by communication capacity tapering](Fig. 1)

Studies are conducted with a 'facilitator'[^1], who can be a teacher or a member of the research team as discussed in [12]. The studies are recorded and a researcher carefully observes (or takes part in) the interaction between the student, the facilitator and the environment. This is the most important stage, as it usually uncovers many tacit assumptions particularly when subjects do not respond as expected, or show unexpected behaviours.

The researchers can afterwards reflect on all these issues (reflection and analysis), with the help of their own notes, video and voice recording from the testing sessions. In accordance with PCM, analysis and reflections sessions should include other stakeholders or other qualified individuals (e.g. teachers or experts in domains similar to the one targeted by the TEL system) that can provide insightful comments, review the data and help in identifying explicitly what are the distinctive landmarks that characterise the actions of the student. This process can be repeated several times until an understanding is achieved about how to move to the next cycle with reduced communication capacity.

## Interaction Bandwidth Tapering

We use the term 'interaction bandwidth' to express the available modalities between the student and the facilitator and the speed at which information can be transferred during a situation. This depends mostly on two factors:
- The different modalities available in which the message can be transmitted
- The intrinsic speed of each modality (e.g. it is faster to say an observation than to type it)

In face-to-face communication, there are many different ways to communicate with the student. The facilitator can speak orally, but can also point to entities on the screen, take control of the actions (e.g. moving the mouse for the student) to prove an argument, and draw inferences based on facial expressions and their gaze (e.g. focus of attention, emotions like boredom or excitement, etc). This rich communication is far from what can be achieved by a modern computer-based system. Therefore, in the effort to create a system that supports the student, the interaction bandwidth has to be gradually reduced; in other words, the facilitator has to progressively use communication channels that can provide the same sort of interaction as the one that will be possible with the intelligent system. We refer to this process as bandwidth tapering.

![Interaction bandwidth tapering](Fig. 2)

From its beginning (in which the facilitator interacts face-to-face with the student) to the final stages (where the student interacts only with the system), there is a gradual reduction of bandwidth. This can be implemented through a series computer-mediated (wizard-of-Oz) sessions.

## Message Freedom Tapering

There is another crucial factor when investigating the communication between the student and the TEL system. We refer here to the freedom to choose what message to feed back to the student. This becomes important in the case of exploratory environments, in which the student holds a greater freedom to act than in other systems, while the system keeps the usual limitations in the kind of feedback it can provide.

This issue is specially important in the case of textual communication, which is the most common approach to provide support. Despite the great advances in the NLP field, natural language generation is still far from being a mature technology that can be used easily for the provision of intelligent support during the learning process. Therefore, most systems rely on a template of pre-generated messages for their interventions. The design of these templates is crucial for the correct deployment of effective intelligent support and plays a central role in our methodology.

From the unlimited flexibility that is available in face to face communication, to the limited choice of templates or pre-generated messages that the final system can use, there must be a gradual and structured reduction. This message freedom tapering is illustrated in Figure 3.

[^1]: We use the term facilitator to avoid assumptions that would be introduced by other terms such as wizard, implying that students are not aware of the presence, expert since, as discussed in the Introduction, for

Here's the cleaned Markdown:

## Informing the Design of Intelligent Support for ELE

## Message Freedom Tapering

During the first stages of design, in which the facilitator communicates with the student orally, she has total freedom to choose what to say. As the process progresses, this freedom is gradually reduced. At some points, the limitations are imposed due to technical limitations (e.g. it takes more time to speak through chat than orally); in other cases, this is part of the design, as the facilitator tries to restrict herself to a script of pre-generated interventions.

## Overall Description

The process starts with face-to-face sessions, in which a facilitator interacts directly with a student and the system. A researcher might play the role of the observer and the whole session would be recorded. In some cases, more than one student can be involved in the study. Having more than one student has several positive effects: it makes the situation more comfortable for the students, and the interaction between them makes them verbalize their thoughts (i.e. explain what they want to do to the other student), giving important cues to the researcher. This helps understanding students' interaction with the system and the conceptual difficulties they face. During this stage, the researcher can provide support directly by opening a dialogue with the student(s).

Once the researcher has a fair knowledge of the interaction between the student and the whole environment, the gradual tapering of the communication capacity of the situation should begin. The first step involves physically separating the facilitator and the student, using some kind of remote desktop system to allow them to communicate. Being away from the student, the facilitator loses many cues about what is happening in the student's mind, and she must infer them from the actions she can see on the screen; in other words, some inputs (e.g. student's face, tone of voice or gestures) must be restricted and only what will be available to the computer to analyse should be kept. This way the facilitator and even the students become immersed in the situation [12].

At this stage, it is possible to employ think-aloud methods [20] and to ask both student and facilitator to verbalize their cognitive processes. Advantages and disadvantages for this process have been discussed extensively [20] but of particular interest is the cognitive overloading of the facilitator to react and to record their rationale behind their decisions. To avoid this, our experience suggests that it is worth engaging the facilitator in a setting in which she instructs the operator of the computer-mediated tools (usually the researcher) about what to do or what to say. This forces explicit reflection on her thoughts, which is useful for the researcher to understand the kind of support needed.

Moving away from the student, the facilitator has also lost means to provide feedback. For a start, they can no longer give feedback by body language, facial expressions, eye direction, etc. Other modalities have to be replaced by less fluent alternatives: direct finger-pointing on the screen evolves into remote cursor handling or area selection, voice communication evolves into chat, etc. The alternatives are always limited, but more similar to the equipment available to the computer. Constrained by these limitations, the researcher becomes aware of the kind of feedback that the system will be able to provide, and how to modify messages to be more effective in the new medium.

Gradually through this iterative process, the interventions crystallize into a script. The script contains information about what needs to be said, and when it has to be said. The feedback can be verbal (e.g. written text) or not (e.g. making a special part of the screen to blink), and the triggering condition will probably be a combination of explicit and probabilistic rules. This script is followed by the researcher as closely as possible during each iteration of the design process. The amount of freedom is gradually reduced until the script can start to be implemented by the system. By iteratively developing new components and restricting the freedom of choice the role of the facilitator evolves into a hidden operator.

## Application of the ICCT Methodology: A Case Study

We are certain that several projects implicitly follow aspects that can be framed within

Here's the cleaned and normalized Markdown:

## Informing the Design of Intelligent Support for ELE

To emphasise the structural aspect of patterning rather than the purely numerical. As explained in more detail in [24,25] this is a key difficulty that students face.

The microworld (called eXpresser) allows students to build their constructions and expressions for the figural pattern tasks and to reach expressions (rules) that describe relationships that underpin the patterns. In order to do that, students can use entities that behave like variables and enable the description of the relationships that students perceive.

Patterns are created when a base shape is repeated. In the case of Fig 4 the base shape (shown in A) is repeated 3 times. That is as many times as the value of a student-created variable, named 'reds' (shown in B). The base shape is placed every two squares across (C) and zero places down (D). The pattern is painted correctly and can be animated in the 'General world' (right) where variables take different values (e.g. in Figure 4 the value of 'reds' is 7). Students then express rules that describe the total number of tiles (E).

## Pedagogical Strategies in MiGen

The application of the ICCT methodology in MiGen aims at informing the design of intelligent support and particularly the pedagogical strategies and interventions that can be followed in order to provide support to students and information to teachers during the use of the system in classroom.

Although the mathematics education literature, consultation with the teacher group and our previous research provided suggestions on how to proceed with the design of strategies for the intelligent support, when this part of the work started, the domain of the microworld's validity, the interaction it afforded and particularly the pedagogic strategies that would be effective were unknown.

The ICCT process allowed the identification, investigation and evaluation of several pedagogic strategies. Throughout the rest of the paper we will employ as an example only one strategy that pertains to all stages of ICCT and was introduced through members of the teacher group who had particular experience in dynamic geometry. The strategy, which is referred to as 'messing-up', challenges students to construct models that are impervious to changing values of the various parameters of their construction [26]. In geometry this provides an incentive for creating constructions using the properties of objects rather than 'draw' geometry figures. It also helps understanding variants and invariants of the constructions. The strategy seemed applicable in eXpresser from the outset. Figure 5 shows how changing the number of red tiles breaks the construction if it is not entirely general.

## ICCT in MiGen

The overall design and development process in MiGen involves collaboration among researchers with various expertise, including technical, educational and design-related expertise. We will not elaborate here on the social configuration of the project. For the purposes of this paper, we will refer to an educational team (comprised primarily of mathematics educators), a technical team (includes mostly computer scientists and engineers) which are directly involved in the project and an external group referred to as the 'teacher group' (includes teachers and teacher educators).

In order to inform the design of the intelligent components, researchers from the educational team observed students interacting with the system in different phases of the spiral process. Analysing the think-aloud protocols and screen recordings of the session enabled the adjustment of existing theories of the domain of mathematical generalisation to our particular domain. It also facilitated the iterative development of an interaction model which comprises of state transition diagrams, and the identification and evaluation of pedagogic strategies that can be followed in each state. As part of of the reflection phase, members of the teacher group are presented with scenarios derived from students' work in previous studies and are asked to comment on the pedagogic strategies followed in them. This facilitated the knowledge elicitation process.

Here's the cleaned and normalized Markdown:

## Informing the Design of Intelligent Support for ELE

From experts but also the investigation and subsequent evaluation of the strategies that the intelligent system rather than a human can follow to provide support.

In each stage of the spiral process, the whole team kept reflecting carefully on the communication capacity of the situation and incrementally prioritised the components that need to be implemented to facilitate the next cycle of computer-mediated sessions.

We provide more details below for the specific stages in the ICCT process.

## Face-to-Face Studies

In MiGen, the ICCT process started with several one-to-one, face-to-face sessions in which a facilitator (a teacher from the teacher group or a researcher from the educational team) was helping the student interact with the environment and solve the given tasks while another researcher was observing the situation, mostly keeping notes. Students (particularly the older and higher level ones) were asked to think-aloud. Of course the interaction between student and facilitator was recorded, together with the screen and the interaction of the student with the microworld.

Since thinking-aloud is more difficult for younger students and it interferes sometimes with the task, the team conducted small scale studies where two or three students collaborated with each other. This was particularly important at early stages of the research since little was know about how students appreciate the activities, how they perceive the microworld and whether the pedagogic strategies the literature proposed would be applicable.

These studies validated the importance of the initial set of strategies that the literature and the teacher group suggested. For example, in relation to the 'messing-up' strategy, the studies showed its potential in creating a culture where students take responsibility for distinguishing between patterns that can and cannot be messed up [25].

However, such a situation introduces a lot of noise. During the collaborative session in particular, not only it was difficult to see how individual students perceived the feedback from the didactical situation but also it was hard to control and evaluate the effects of the teachers' actions. According to the discussion in Section 2, this is a situation with high communication capacity. Not only student and teacher are quite free to adapt to the communication requirements of the situation but there is high interaction bandwidth. As expected, it was not easy to generalise all of the strategies to what we envisaged the system would be able to do. Although we could easily imagine how to transfer the effective messing-up strategy to a strategy for the intelligent system, these studies were clearly demonstrating the importance of also drawing students attentions to parts of their constructions through language and gestures. The project's challenge however was to identify ways of helping the students through the computer. This would clearly be a transformative situation which could be investigated only with a simulation or a prototype. Our only means of doing that was clearly through computer-mediated sessions with a reduced interaction bandwidth.

## Reducing the Interaction Bandwidth

When enough data were collected from the aforementioned process the bandwidth of communication between facilitator and students was reduced, following the process described in the ICCT methodology. For example, in the first phase students were allowed to talk with the facilitator through a web-conferencing and application sharing software.[^3]

[^3]: Elluminate (http://www.elluminate.com/) was used for this process.

This for MiGen was the first reduction of communication capacity. It allowed the researchers of the educational team to start considering the actions of the student employing the same bandwidth that would be available to the system, yet provided the flexibility to talk to the students and a rationale for the student to verbalise their thinking since, at least in some critical stages (e.g. when they had an impasse), they had to talk to the researcher.

This allowed a low-cost evaluation of the strategies according to the analysis of the previous iterations and the development of initial scripts for subsequent iterations. In addition, the difficulties encountered and the missing tools required to facilitate the interaction between student and researcher provided requirements for components that could be used to support the next iteration of computer-mediated sessions.

For example, preliminary sessions highlighted the importance of drawing students attention to particular parts of their constructions construction, especially when students

## Informing the Design of Intelligent Support for ELE

## Setup and Role-Playing Studies

The setup required three computers in total (one for the student and two for the remote facilitator, one with the classroom management software and on-screen annotation software and another with the chat interface enabling fast switching between the two modalities).

The team engaged students in role-playing games. A researcher sat beside the student reminding them to think-aloud and helping with technical problems. Students were asked to consider the researcher as their teacher who couldn't always help them in class. Therefore, students had to ask for help from the out-of-sight operator. Although aware of differences in students' perception between asking help from humans versus computers, the manual on-screen annotations necessarily appeared human-like. Nevertheless, the studies provided useful insight regarding annotation requirements and pedagogic strategies.

These studies highlighted that written feedback (especially unsolicited) is often ignored or difficult to understand. This common difficulty with intelligent systems was exacerbated due to the young age of the target group and because the innovative environment required developing particular discourse over multiple sessions. After consulting with the educational team and teacher group, it was decided to maximize non-verbal feedback in the next iteration while carefully introducing students to appropriate language during system interactions.

Regarding the messing-up strategy, the studies showed a lack of robust incentive for students to construct mess-up-proof patterns. This was hypothesized to be due to human presence and artificial remote messing-up without associated language. The facilitator had to manually change pattern attributes. Students felt general constructions weren't necessary without the facilitator, being satisfied with their 'drawings'. This raised requirements for on-screen annotation and less conspicuous messing-up capabilities.

## Emulating Intelligent Support

The sessions facilitated iterative development of the hidden operator script and provided information on strategy effectiveness and implementation. They also informed UI component design in consultation with education and teacher teams.

The tapering process continued by progressively reducing hidden operator freedom while the technical team provided more UI components. For example, chat was replaced with actual prompts for iterative design and evaluation. For the messing-up strategy, the interface allowed changing pattern attributes for more believable messing-up, incentivizing students to create tamper-proof patterns.

In parallel, the hidden operator's freedom was restricted as information was collected. Initially using a draft state transition diagram with possible actions per state. As studies progressed, some actions could be pre-designed, enabling evaluation and collection of interaction data to inform both pedagogical strategies and AI techniques for adaptive, personalized feedback.

## Discussion

The Iterative Communication Capacity Tapering methodology involves gradually reducing communication capacity across stages, though stage boundaries are fluid. Time allocation varies by project needs (e.g., poorly understood domains require more early-stage effort).

Key factors include:
- Useful for indirect knowledge elicitation, especially with students or non-technical adults
- Particularly valuable for 11-12 year olds who struggle to verbalize thoughts
- System domain affects support complexity
- More challenging for exploratory learning environments with many possible actions
- More labor-intensive for abstract mathematical concepts versus tangible domains

The methodology's application differs between adding support to existing environments versus co-developing support with the core environment. In co-development, early ICCT stages take longer as components co-evolve, while later stages may be faster as influences stabilize.

[^5]: Vision classroom sharing tool with Netop's Pointer plugin was used (http://www.codework.com/vision/pointer.php). Thanks to Vision's UK distributor CodeWork and Kam Yousaf for software assistance.

Here's the cleaned and normalized Markdown:

## Informing the Design of Intelligent Support for ELE

It is important to note that the ICCT methodology offers a dual benefit contributing both to research and design. In the first stages, interdisciplinary research has more weight, and researchers learn about the domain, the system, the needs for support and unexpected behaviours on the part of students (what Twidale called the 'cognitive microscope' [30]). In the final stages, design becomes more important as the focus turns to implementing a fruitful system taking advantage of what has been learnt from the literature and the first stages of the design.

## Conclusions and Future Work

This paper presents a methodology for knowledge elicitation and design of intelligent support for TEL systems, especially those based on exploratory environments. The methodology builds on previous work on contextual and iterative design, and wizard-of-oz techniques. It is based on the gradual tapering of communication capacity, on its two dimensions of interaction bandwidth and freedom of message choice. After each iteration of the four-stage cycle of planning & design, implementation, conducting studies, and analysis, the communication capacity of the whole system is reduced. The student is supported by a set of mechanisms that gradually evolve from those used by a human to those available to the final intelligent TEL system. In particular the tapering of the interaction bandwidth and of the message freedom ensures that the final system will provide adequate support, appropriate to its communication capabilities. The final stages of the process place more emphasis on design and on the gradual development and evaluation of the intelligent support components.

We presented our experience through the case study of designing intelligent support for a microworld to support students' mathematical generalisation. A particular consideration that became apparent through this case study is the efficiency of the method, especially as it was employed while the microworld was under iterative development. The method can be time consuming and when the core system changes some of its results can be rendered useless. However, the structured nature of the method offers a dual benefit. On the one hand, it facilitates conducting research that contributes to the growth of theories of teaching and learning. On the other hand, it enables the iterative design, development and evaluation of a system. In the future we will attempt to streamline the process by identifying ways to make it more efficient. A first step is to develop generic tools that can enable the communication capacity tapering in different contexts.

## References

1. Murray, T.: Authoring intelligent tutoring systems: An analysis of the state of the art. International journal of artificial intelligence in education 10, 98-129 (1999)
2. Beyer, H., Holtzblatt, K.: Contextual Design: A Customer-Centered Approach to Systems Designs. Morgan Kaufmann Series in Interactive Technologies (1997)
3. Sharples, M., Jeffery, N., du Boulay, B., Teather, D., Teather, B.: Socio-cognitive engineering. In: European conference on Human Centred Processes (1999)
4. Boehm, B.: A spiral model of software development and enhancement. SIGSOFT Softw. Eng. Notes 11(4), 14-24 (1986)
5. Johnson, L.W., Beal, C.: Iterative evaluation of a large-scale, intelligent game for language learning. In: Proceedings of the International Conference on Artificial Intelligence in Education, pp. 290-297 (2005)
6. Cobb, P., Confrey, J., Disessa, A., Lehrer, R., Schauble, L.: Design experiments in educational research. Educational Researcher 32(1), 9-13 (2003)
7. Disessa, A.A., Cobb, P.: Ontological innovation and the role of theory in design experiments. Journal of the Learning Sciences 13(1), 77-103 (2004)
8. Conlon, T., Pain, H.: Persistent collaboration: a methodology for applied AIED. International Journal of Artificial Intelligence in

Here's the cleaned Markdown:

## Informing the Design of Intelligent Support for ELE

25. Geraniou, E., Mavrikis, M., Hoyles, C., Noss, R.: A constructionist approach to mathematical generalisation. Proceedings of the British Society for Research into Learning Mathematics 28(2) (2008)
26. Healy, L., Hoelzl, R., Hoyles, C., Noss, R.: Messing up. Micromath. 10, 14–17 (1994)
27. Disessa, A.A., Azevedo, F.S., Parnafes, O.: Issues in component computing: A synthetic review. Interactive Learning Environments 12(1-2), 109–159 (2004)
28. Papert, S.: Afterword: After how comes what. In: Sawyer, R.K. (ed.) The Cambridge Handbook of the Learning Sciences, pp. 581–586. Cambridge University Press, Cambridge (2006)
29. Noss, R., Hoyles, C.: Windows on mathematical meanings: Learning cultures and computers. Kluwer, Dordrecht (1996)
30. Twidale, M.: Redressing the balance: the advantages of informal evaluation techniques for intelligent learning environments. Journal of Artificial Intelligence In Education 4, 155–178 (1993)

## Automatic Analysis Assistant for Studies of Computer-Supported Human Interactions

Christophe Courtin and Stéphane Talbot

Équipe Systèmes Communicants, Université de Savoie, Campus de Savoie Technolac, 73376 Le Bourget du Lac cedex

{Christophe.Courtin,Stephane.Talbot}@univ-savoie.fr

## Abstract

This paper presents a system architecture to bridge the gap between the users computing activity in collaborative platforms and the analysis of this activity which is carried out by researchers in human and social sciences. This research work tends to highlight the capacity of a computer-supported observation station, based on a theoretical model called TBS (Trace-Based System), to assist researchers automatically in their activity of analysis using a high abstraction level. We present the modules of a prototype of an observation station called CARTE (Collection, activity Analysis and Regulation based on Traces Enriched) which enable the interoperability between the collaborative platforms, where the users produce raw traces and the analysis environments, where the researchers study traces of a very high abstraction level.

**Keywords**: trace, automatic analysis, observation, learning activity.

## Introduction

The introduction of the technology in the collaborative learning activities has aroused the interest of the researchers in human and social sciences, who study the various forms of concerned cognitive and social activities [1]. There is a complexity in these studies such that it is necessary to assist them, as is possible to do with technology. Actually, the analysis of human interaction with a computer system remains a human activity with a high abstraction level, where the technology can assist the researcher by helping him/her to achieve his/her tasks.

In parallel to these research works in human and social sciences, there are others in computer science relative to the design of computer-supported collaborative learning systems, which we label observation based on activity traces. The relationship of the concerned actors (i.e. learners and teachers) to the software system is where the interest of the study of the traces for learning lies. Indeed, we have shown that we could exploit the activity traces, by means of a regulation model [2], in order to modify the system processing so that it tends towards the user's own model of this system, that we call the use model [3].

## Study Context

The study we present in this article aims to define the significance of the results of research work in computer science in the field of the observation of the collaborative learning activities, for the automatic assistance of human and social science researchers' activities, on the understanding of the analysis processes of the socio-cognitive interactions. It is necessary now

## Automatic Analysis Assistant

## Trace Analysis

We have underlined the difficulty in carrying out automatic analysis of traces of multi-modal and multi-user interactions by use of a computing environment, which makes sense for researchers in human and social sciences. Conversely, the latter are confronted with a complexity of the analysis such that it is necessary for them to have assistance, in particular in the tasks involving very many parameters or time consuming tasks. We identify three families of software tools to carry out these analyses (see Fig. 1).

The first family corresponds to the collaborative platforms which contain the tools of production, communication, cooperation and regulation according to the four dimensions of the clover model of [7] augmented by the regulation by [8]. These software tools intrinsically produce traces which, according to the situation, can be directly exploited for observations generally in recorded mode. We will study the case of the DREW © (Dialogical Reasoning Educational Web) system [1], which we will present hereafter, and which allows the exploitation internally of its own traces.

The second family corresponds to the analysis environments which include software tools dedicated to assisting the observers in the management, the synchronization, the visualization and the analysis of activity traces. In these environments, most of the aforesaid actions are carried out manually on the traces. In our study context, namely the analysis of the human interactions with a computer system, we will study the TATIANA © (Trace Analysis Tool for Interaction ANAlysts) system [9], also presented hereafter, which fits the aforesaid description.

The third family, which is at the heart of our study, concerns the observation stations, i.e. environments which fit the specification of the theoretical observation model which we call a TBS (Trace-Based System) [5], [6], on which we have contributed to its definition with other actors in the Technology Enhanced Learning and Teaching (TELT) field. Today, we have a prototype called CARTE (Collection, activity Analysis and Regulation based on Traces Enriched) [2] which fits this specification and of which we will present the modules which answer the problem presented at the beginning of this article.

### Collaborative Platforms

Collaborative platforms represent the digital workspace environments which place at users' disposal software tools to carry out collectively the tasks of the field of application. We will limit ourselves here to the tools dedicated to the collaborative learning.

In the context of our research, we carried out experiments during a practical class in an English course (foreign language) at the university [4]. The students were to define remotely in pairs English vocabulary stemming from a text. The system was composed of a production tool called "Jibiki" (a specific collaborative text editor to create multilingual dictionaries), created for a research project in linguistics and

[Figure 1 content preserved but not reproduced as it appears to be a diagram]

Here's the cleaned and normalized Markdown:

## Automatic Analysis Assistant

## Tools and Platforms

The system depends on trace exploitation [10], utilizing a communication tool called "CoffeeRoom" (a chat room in which communication spaces are represented by tables), a group structuration tool, and an activity monitoring tool (awareness). Activity traces were gathered by a collection API (Application Programming Interface) of an observation station, through instrumentation of the aforementioned software tools (see Tools 1 and 2 in Fig. 1). The semantic level of traces analyzed automatically with the observation station through predefined tool use models fits the analysis objectives of the concerned observers, i.e. the users of the system (learners and teachers). The chosen architecture, namely the externalization of trace processing towards an observation station, allows us to plan a posteriori other more detailed exploitations of the trace base thus constituted. We will present below the Query/Notify API of the CARTE observation station for the exploitation of this base with other analysis objectives.

The analysis of human interactions with a computer system frequently consists in replaying activities carried out with software tools or described from other sources (e.g. video transcription). The DREW© system has been designed with this idea in mind. DREW is a supported-collaborative learning platform [1] which allows researchers to manage computer-mediated interaction traces stemming from collaborative tools' use (e.g. DREW's chat or DREW's shared text editor). DREW can read its own traces (sequences of events with XML format) and reproduce the activity through an internal replayer within the software tools initially used [11]. Furthermore, the DREW replayer can be synchronized and controlled by an external replayer, such as the TATIANA© analysis tool. Thus, researchers can add indicators in the DREW replayer, for example a color for each participant to differentiate contributions. This coupling between an analysis environment and the DREW collaborative platform allows manual creation of epistemic indicators (high level traces) from behavioral observeds (lower level traces). The DREW system satisfactorily meets the expectations of researchers in human and social sciences for analyses based on the principle of replaying in specific tools.

## Analysis Environments

Analysis environments supply software tools to assist researchers in the management, synchronization, visualization and analysis of traces to create new ones which make sense for them. The TATIANA environment assists researchers in analyzing traces stemming from contexts that are complex because multimedia, multi-modal (synchronization of several trace sources) and multi-user [9]. Researchers can use TATIANA to create "replayables" ("display format") and analyses (use of language for defining filters/rules) [12]. A "replayable" can be displayed in tabular form (an array with columns such as Time/User/Message/Tool) or graphical form (using style sheets). The filters, based on XQuery scripts [13], convert data into XML format (with structure description), then into the format understood by TATIANA ("display format" or pivot format or sequence of events).

## Observation Stations

The third family concerns observation stations - environments dedicated to collecting traces from various sources, structuring them according to a generic format, transforming them according to predefined analysis objectives and re-injecting them towards analysis tools or source tools (retroaction principle of CARTE [2]) to enable activity regulation. An observation station is a system, based on a theoretical observation model, providing observers (e.g. researchers) with observation services to facilitate analysis tasks.

According to the CARTE system's architecture, analysis and trace exploitation tools differ from tools used for application domain activities - all functionalities relative to collection, structuration and analysis activities are integrated into the observation station. Researchers (observers) can use the CARTE observation station to track interactions whose treatment must facilitate their analysis system tasks. CARTE allows real-time trace collection for analyses either in parallel with different use models, or successive (thus cumulative) to increase abstraction levels of resulting traces.

Trace analysis can be carried out at various abstraction levels: from primary traces (e.g. raw data from log files, instrumentation data [4]) in collaborative platforms, from temporarily situated behavioral "observeds" in observation stations, an

## Traces Structuration and Analysis in CARTE System

## Traces Structuration

With the observation theoretical model, traces are placed at the heart of the trace-based system. In this approach, we add an abstraction level between actions to be carried out and the various applications. Thus, if a communication tool (e.g. a structured chat room) is replaced by another one which fits the same specification, the collected raw traces ("signals") will then be impacted, but not the enriched traces ("sequences") because of their high abstraction level. Therefore, the trace format used in the CARTE system has to be as generic as possible. We consider that trace information is divided into two parts: the first one which is common to all the traces (e.g. source, date, etc.) and the second one which is specific to the various tools used (e.g. a sentence in a collaborative text editor, a table name in a structured chat room). The former is represented by the metadata and the latter by a list of parameters.

With the trace manager of CARTE, we are able to manage two kinds of activity traces:

- Signals which correspond to time pinpoints and elementary elements (e.g. a user action, a state modification of the system, and so on)
- Sequences which split into a chronological succession of signals or sub-sequences. Obviously, a sequence also has a duration and normally should make sense to understand what has happened with the tools.

Signals contain:
- A source (the person or the tool which has generated the signal)
- A tool (the tool or the instance tool in which the event has taken place)
- A date (the timestamp which says when the event happened)
- An event id (the list of possible events will depend on the tools we use: connection, disconnection, message emission, etc.)
- A textual description
- A list of parameters (which contains the variable parts of signals)

The sequences are more complex than signals. They are composed of signals or sub-sequences and, as signals, have parameters. In our implementation, each sequence is stored with:
- A start date (timestamp – the beginning of the sequence)
- An end date (timestamp – the end of the sequence)
- A type id, which characterizes the kind of sequence
- A source (the person or the tool which has recognized the sequence – the source is generally the analyzer)
- A textual description
- A list of parameters (which gives all significant details of the memorized episode)

## Observation Station API

### Collection API

The collection API (Application Programming Interface) is aimed at simplifying the process of collection of the traces. This API provides application developers with tools which intend to help them during the task of instrumentation of the tools in the implementation phase (or adapt them afterwards). Furthermore, we postulate that if there are tools which provide the possibility of transforming and adapting application traces from other formats (log files, xml files, and so on), we expect that more and more applications will offer the possibility of generating traces.

Here's the cleaned and normalized Markdown:

## Automatic Analysis Assistant

## Collection API
Tools should be able to create tools to exploit traces and provide users and groups with added values.

In our prototype, CARTE, a service (the collector) gives access to the collection API. Two methods `sendSignal` and `sendSequence` have been defined and allow tools to send signals or sequences to the TBS (Trace-Based System). Because we use a J2EE server, the API are accessible either as a WEB service, or as java RMI or Corba objects (depending on J2EE server configuration).

To simplify system use, we provide different versions of these methods:
- Simplest version: only one parameter needed - the signal or sequence to record
- Second version: signals/sequences can be described using inner parts: time_stamp, source, tool, event, description, parameters
- Special version: includes supplementary parameter for associating session ID with traces gathered during analysis. This ID can be reused to visualize analysis results or replay them.

## Trace Exploitation API
In the first version, the analyzer was tightly coupled with the trace manager, preventing simultaneous analyses or multiple analyzers.

Using the collection approach, we defined the trace exploitation API to normalize trace use and interrogation. We identified two usage types:
- Interrogation needs - ability to request trace base for interesting traces
- Notification needs - tools (like on-line analyzers) should be notified of new traces

We defined API for both: interrogation API and notification API.

## Interrogation API
This "pull-oriented" API makes requests on the trace base. Tools use it to search for particular trace elements.

The service provides two main methods:
- `searchSignal`
- `searchSequence`

Each method has variants:
1. First variant uses a "pattern" (partially instantiated signal/sequence) for searching
2. Second variant applies patterns using "use models" for trace interpretation

## Notification API
This "push-oriented" API has tools acting as trace consumers registered in the TBS. The observation station defines:
- `addSignalListener`
- `addSequenceListener`

Tools must implement either:
- `SignalListener` interface
- `SequenceListener` interface

Listeners can specify which traces they want using patterns, either directly or through "use models".

These APIs provide modularity, allowing:
- Replacement of analyzers
- Running multiple analyzers simultaneously
- Connection of external tools
- Implementation of sophisticated filters

## API Utilization
We tested the API with CARTE system tools during university experiments. Tools instrumented include:
- Group structuration tool
- Dictionary elaboration tool ("JIBIKI")
- Chat tool ("CoffeeRoom")

The chat facility generates specific signals for each user action, with defined events for each possible participant action.

## Automatic Analysis Assistant

## Connection and Event Handling
- On connection/disconnection the chat tool sends a signal, which has this particular event id (connection or disconnection) and with one parameter (the user name of the participant who has connected/disconnected).
- When a participant sends a new message, the server sends a "talk" signal with three parameters (the user name of the sender, the communication space where the message has been sent and the content of the message).
- And when a chat communication space is created or deleted (in our chat tool, the "CoffeeRoom", users can create or delete new communication spaces, represented by tables), two specific signals are also created and sent to the TBS. These particular signals have two parameters: a user name and a name identifying the corresponding communication space created or deleted.

The other two tools used for our experiments have been similarly instrumented. So, during an experiment, we are able to record all the significant actions performed by any of the participants (i.e. the students and the teacher).

## Query/Notify API Development
We have defined the Query/Notify API more recently, so actually we are only using them in order to separate the analyzer from the TBS. The first steps in this direction were made a few months ago and the separation is now effective. The first consequence is that the same analyzer can now be used to perform on-line or off-line analyses (to perform the off-line analyses we just have to re-play the selected traces). We are now changing the analyzer in order to be able to run different analyses in parallel. Another outcome is that normally, any analyzer which implements our API should be able to be plugged in the TBS.

Next we will similarly separate the internal visualization tools from the TBS. And to go one step further, we also plan, in a new project, to use the API to connect our system with DREW [1] and TATIANA [9]. After that, DREW will be seen as a new collaborative platform able to use CARTE to store its traces. In the same way we hope to be able to use TATIANA on these traces as a new analysis tool; not as an automated one like CARTE's current analyzer, but as a learning expert-oriented one.

New experiments will then be carried out, which we hope will demonstrate firstly that our approach is realistic and secondly that if we could combine automatic analyses with human ones, we would obtain better results.

## Conclusion and Perspectives
The work presented in this paper is a preliminary stage for a multi-disciplinary project. We have set out the observation area as being the association of three families of tools:
1. The collaborative platforms
2. The analysis environments
3. The observation stations

These provide researchers (observers) with traces which allow various abstraction levels. We have described a specific module of the CARTE observation station which is able to interoperate with raw traces from the DREW collaborative platform and enriched traces from the analysis environment TATIANA, in order to assist researchers in human and social sciences automatically in their analysis tasks.

In the near future, we plan to place at researchers' disposal modules, included in the CARTE observation station, implementing functionalities to facilitate the automation of certain tasks of the analysis process in any analysis environment. The final objective of such research work is the creation and the sharing of corpora of traces by the communities of researchers, who try to understand the activities performed.

## References
1. Corbel, A., Girardot, J.-J., Lund, K.: A Method for Capitalizing upon and Synthesizing Analyses of Human Interactions. In: van Diggelen, W., Scarano, V. (eds.) Workshop proceedings Exploring the potentials of networked-computing support for face-to-face collaborative learning, 1st European Conference on Technology Enhanced Learning (EC-TEL 2006), Crete, Greece, pp. 38–47 (2006)

[References 2-14 preserved as in original]

Here's the cleaned and normalized Markdown:

## Real Walking in Virtual Learning Environments: Beyond the Advantage of Naturalness

**Matthias Heintz**  
Fraunhofer Institute for Experimental Software Engineering, Fraunhofer-Platz 1  
67663 Kaiserslautern, Germany  
Matthias.Heintz@iese.fraunhofer.de

## Abstract

Real walking is often used for navigation through virtual information spaces because of its naturalness (e.g. [1]). This paper shows another advantage. We present a within-subjects controlled experiment in the area of document retrieval. It compares two concepts of navigation: mouse and tracking. The latter was chosen for its naturalness and its feature to create proprioception. Our idea is that this helps users to orientate themselves and recall positions. This would result in better retrieval of previously visited information. The experiment shows a benefit in accuracy of finding content with tracking. This means proprioception improves users capacity of memory. This finding can serve as a decision support for choosing input devices, when designing immersive virtual learning environments. Therefore it can either help to build a base for a new interaction model for learning environments. Or it can broaden the theoretical framework of Chen et al. [2] to include immersive environments.

**Keywords**: navigation, immersion, input devices, virtual learning environment.

## 1 Introduction

Many virtual environments use real walking as input for navigation through a virtual information space, because it is the most natural way to navigate (e.g. [1] (learning environment) and [3, 4] (non-learning virtual environment)). It is considered natural, because we learn to walk early in our life and use it every day.

This is a benefit from the point of view of the developer who creates the virtual environment. The user will be able to navigate right away without having to learn a navigation metaphor or how to work with the input device used.

But beside these advantages there is another, less obvious one. It is also natural from the users inner point of view. Navigation by natural walking also feels like real navigation. Not like still standing there and magically move through the (virtual) world by just moving your thumb (to push the button on a gamepad). This as well is the reason, why walking-in-place is not as natural as real walking [4]. The movements and perceptions made by the user are only alike, not equal.

With walking for navigation it is possible to take advantage of the additional kinesthetic feedback, the user gains from real movement. "[...] proprioception and kinaesthetic sense [...] [is] the sense that allows us to know our body position and the movement of our limbs." [5] It causes "[...] the awareness of parts of our body's position with respect to itself or to the environment [...]" [6] "[...] via feedback produced within the user's own muscles and joints [...]" [7].

The movements made when using traditional input devices for navigation (e.g. mouse and keyboard, gamepad, joystick) are (negligible) small. Thus proprioceptive feedback is little and can hardly aid the user.

This work addresses the research question, if proprioception can help the user in an immersive virtual environment to retrieve information he has seen before faster and with less errors.

A possible advantage of real walking for navigation in virtual learning environments, which is not explicitly measured in the conducted experiment, is the following. With proprioception it is possible to plan and carry out movements without the need of visual feedback and as it happens "naturally" it is not causing a high cognitive load.

Also not in the scope of this work was the fact that real movement causes a stronger feeling of presence than navigating by using input devices [4].

## 2 State of the Art

As said in the introduction, real walking has been used in several virtual environments for its naturalness.

Kuan and San [1] developed a virtual learning environment to teach basic physics concepts by presenting a game of ballooning. They evaluated several navigation methods and found real walking the most natural one. But because real walking depends on

Here's the cleaned Markdown:

## Real Walking in Virtual Learning Environments

## State of the Art

The last two approaches used proprioception, because screen space was small and thus limited. But it has also been used for large screens, like for the application described in this paper, before.

Mine et al. [10] integrated a menu in their application, which was built to use proprioception to find it. Irrespective of the users position in the virtual world, the three menu items were always above the user, just outside his field of view. Thus the menu did not occlude any screen estate while not needed. But when the user wanted to use it, it could easily be reached by grabbing above and pulling it into sight. A study showed that tree different menu items side by side (above and left or above and center or above and right) can be distinguished by the user.

Tan et al. [11] implemented an application to research if proprioception helps in learning information. They compared the amount of learned elements from a list of words in two conditions. Displayed on a single monitor was compared to separated on three different ones (building a large screen), where the words were shown alternating. The conducted user study demonstrated a 56% increase in memory for the information presented distributed. Thus combining information with location and movement helps the user to recall it.

But proprioception is not only applicable in virtual environments. In the area of learning it can also be used to enhance traditional classroom education, which is then called kinesthetic learning. For example [12] have described this "[…] process where students learn by actively carrying out physical activities rather than by passively listening to lectures." In their paper "A Collection of Kinesthetic Learning Activities for a Course on Distributed Computing", they describe five examples, how this kind of learning could be applied. As learning in classroom was not in the focus of the original work, this kind of kinesthetic learning has not been investigated further.

## Application

The application used for the controlled experiment is an immersive virtual environment for document retrieval (see Figure 1). But as it does not matter to which kind of content (in this case virtual documents) the user is navigating, the general findings of the conducted experiment can be adapted to any immersive virtual environment.

![User navigating through the document space by walking in front of the screen](Figure 1)

### Premises

To create the immersive virtual environment, a room with a PowerWall was used. The PowerWall is a 2.9 m by 2.3 m area illuminated by rear projection. Two projectors create a stereoscopic image through circular polarization, thus the user has to wear spectacles with filters to see the three dimensional image.

There are two types of input devices to be used: The standard mouse and keyboard and an Ascension "Flock of Birds" magnetic tracking system [13]. To be able to track the walking user in the entire physical space available (3 m by 4.5 m) the extended-range transmitter for the "Flock of Birds" tracking system is used.

We utilized two sensors of the tracking system to track the users head and one hand. This allowed for a natural navigation and interaction while creating proprioceptive feedback from the users movements. The mouse was used as common input device to compare the tracking system to.

### Idea

As already described in the motivation and state of the art sections, there have been some other applications [e.g. 1, 8 and 11] which use human movement for navigation and remembering of positions. With the application described in this paper we want to use proprioception to ease document storage and retrieval for users. In the scope of our work we concentrated on the retrieval part, but we had the storage process (which was not implemented yet) already in mind. The nine documents have been positioned in a 3 by 3 grid by the application without any interaction of the user (Figure 2 shows two documents and the user in the nine field interaction grid in which all the documents are arranged. The field labeled "F" on the left is for interacting with the "following document".).

![Drawing of

Here's the cleaned and normalized Markdown:

## Real Walking in Virtual Learning Environments

## Document Comparison Setup
The "following document" was compared with "floating documents" distributed in the virtual environment (arranged in a 3 by 3 grid).

## Interaction Devices and Proprioception
To measure the influence of proprioception, the application was implemented with two different interaction devices, chosen for their contrasting proprioceptive feedback.

### Mouse Input
The common mouse operates with relatively small movements of forearm and hand. Body position and orientation are irrelevant for navigation, producing minimal useable proprioceptive feedback for document position memory. Navigation movements are repetitive - forward movement requires multiple scroll wheel actions. Distinguishing between similar scroll distances is difficult. Movements to reach documents on the right side (3, 6, and 9) are identical except for initial right-plane scrolling.

### Real Walking Input
Tracking real walking incorporates the whole body, with real-world movements directly mapped to the virtual environment. Nearly complete body proprioception is relevant for position. Users can link real room positions and movements to virtual document positions, providing a second information channel beyond visual feedback. Each document requires unique movement patterns.

## Implementation

### Mouse Input
For three-dimensional navigation:
- Mouse movement controls visual plane (x,y)
- Scroll wheel controls third axis (z)
  - Forward scroll: move ahead
  - Backward scroll: move backwards

### Tracking Input
Two tracker sensors were used:
- Head tracker for navigation
- Hand tracker for interaction

Head tracker data was applied to the virtual camera, creating corresponding virtual movement. Hand tracker enabled posture-based interaction:
- Standing in front of document shows "focus frame"
- Angling forearm selects and enlarges document
- Hand bending controls document scrolling
- Moving hand to shoulder deselects document

### Output
- Application written in C++ with OpenGL visualization
- Documents created from real document images as textures
- Page scrolling visualized through side-to-side sliding

## Evaluation

### Experiment Design and Procedure
The evaluation compared proprioception advantages in document retrieval between two interaction concepts:
- Mouse input: minimal proprioception, small movements, repetitive actions
- Real walking tracking: extensive kinesthetic feedback, whole-body involvement

A within-subjects approach was used, with each participant using both input devices to control for mouse experience variations.

## Real Walking in Virtual Learning Environments

## Experimental Design

The task for users was to memorize the content and position of nine documents containing three pages each. To lower the amount of information to learn to a feasible level, only document titles and pictures should be remembered.

At the beginning of each run, subjects had twenty minutes to get familiar with the application and memorize the content. After this learning phase they should search for three document titles and six pictures presented in the "following document".

To eliminate the possibility that information learned in the first run influenced results of the second run (with the other input device), the documents were interchanged. The two document sets were chosen to be equal in title complexity and number and size of pictures to allow for comparability of run one and two.

The experiment was conducted with 16 persons (mostly pupils and students; age ranging from 17 to 57). The independent factor was the kind of interaction device used (mouse or tracking). The participants were divided in two groups of 8 each, with equal distribution of age and computer experience. Both started with document set 1, but the first group used mouse input and the second tracking first. For the second run, the document set was changed to set 2. The first group then used tracking and the second one mouse input to navigate.

Objective result data included time needed and errors (opened incorrect documents) during document retrieval. For subjective data, a questionnaire was completed after the second run.

## Hypotheses

From earlier research in proprioception, three hypotheses were developed:

- Every user will benefit from tracking real movements by making fewer errors during document retrieval, due to proprioceptive feedback from walking as additional aid
- Navigation by tracking real movement will cause faster retrieval of information than mouse input
- Users with less computer experience will benefit more from tracking than experienced users

## Results

### Error Analysis
Total number of errors for all document retrievals:

|               | Mouse input | Tracking |
|--------------|-------------|----------|
|Document title| 19          | 11       |
|Pictures      | 114         | 58       |
|Total         | 133         | 69       |

With tracking, the number of errors compared to mouse input was nearly halved. For 56.25% of users, mouse input resulted in two or more additional errors. 25% had similar results, while 18.75% performed worse with tracking.

### Time Analysis
Average time to find content (in seconds):

|               | Mouse input | Tracking |
|--------------|-------------|----------|
|Document title| 23.52       | 25.77    |
|Pictures      | 25.92       | 27.27    |
|Total         | 49.44       | 53.06    |

Users needed more time when using tracking compared to mouse input, contrary to the hypothesis. This may be due to users' familiarity with mouse navigation and the smaller movements required.

For the third hypothesis, users were categorized based on computer experience using three criteria:
- Self-rated experience
- Years using computers
- Daily computer usage

Nine experienced users had >10 years experience and >3 hours daily usage. Seven less experienced users had 5-10 years experience and <3 hours daily usage.

Here's the cleaned Markdown:

## Real Walking in Virtual Learning Environments

As you can see in tables 3 and 4 less experienced users benefit from tracking both in time and number of errors, whereas experienced ones benefit just in number of errors. If you compare experienced with less experienced computer users you can see that the inexperienced benefit even more than the experienced ones.

Table 3. Comparison of experienced with inexperienced computer users - average number of errors

|                      | experienced computer users | inexperienced computer users |
|----------------------|---------------------------|------------------------------|
| mouse input          | 3.44                     | 14.57                       |
| tracking            | 2.56                     | 6.57                        |

Table 4. Comparison of experienced with inexperienced computer users - average time needed (in seconds)

|                      | experienced computer users | inexperienced computer users |
|----------------------|---------------------------|------------------------------|
| mouse input          | 132.00                   | 347.00                      |
| tracking            | 186.11                   | 290.71                      |

It can be assumed that the additional time needed with tracking by the experienced users is due to their familiarity with mouse input. The use of tracking is new and unusual and although they had time to get familiar they might not have been able to get familiar enough to outperform the mouse (in terms of time).

### Threats of Validity

Although the findings might be very helpful, there are some points to be considered, when examining the results.

- Number of documents: Walking for virtual navigation needs an appropriate amount of real space. The presented concept for tracking is only applicable for a small number of documents. Larger sets would need additional interaction metaphors.
- Number of subjects: Because only 16 people have been tested, the results might depend very much on the performance of each subject.
- Deviation of subjects: Most of the subjects have been pupils and students. This might cause the findings to not being applicable for all users.
- Short period of getting accustomed to navigation with tracking: The results for real walking (especially time needed) might have been even better if the subjects had more time to get familiar with tracking as input for interaction.
- Categorization of experienced and less experienced computer users based on their own estimation: To avoid a wrong segmentation we did not rely solely on their answer to the question about their computer literacy. We also used "objective" values which determined the duration of computer usage. But more time spent using it does not necessarily mean more experience (e.g. less experienced users need more time to accomplish a task than more experienced users). So we still could just estimate the subjects experience in working with a computer because we did not conduct an evaluation to test it.

## Conclusion

In this paper we answer the question if the user profits from the proprioception created from real walking for navigation. We did this by comparing two different interaction concepts in an immersive virtual environment. The first is using the standard mouse input for navigation. The second one is tracking the walking user. The proprioceptive feedback created by these two methods of input is very diverse (due to the amount of movement involved), thus their comparison makes it possible to determine the impact of proprioception. Our experiment showed that most of the subjects made fewer errors when using real movement, therefore the proprioception helped them to retrieve information. They were not faster in general, as estimated given the naturalness of real walking. But the results showed a difference depending on the experience of the subjects in using a computer. The less experienced ones benefit from tracking more than the experienced users (see Figure 5). These advantages in information retrieval make a good case for using tracking of real walking as input for navigation in immersive virtual environments, which go behind its obvious "naturalness".

If the findings of this experiment are applied to the area of learning they suggest, that advantages found in traditional kinesthetic learning, e.g. by Tan et al. [12], could also be used in virtual learning or e-learning environments.

[Figure 5. Research question, experimental comparison and results]

Here's the cleaned Markdown:

## Real Walking in Virtual Learning Environments

The fact that proprioception can be used for planning and carrying out navigation has several advantages for learning environments. As it needs little direct attention of the user he can use his cognitive capacity to examine and learn the displayed content. Because it can be done without using visual feedback the user is able to make sense from visualization while moving, e.g. watching and following meaningful connections between elements.

The motivation for learning and learning process of the user can additionally be supported by his feeling of presence (immersion) (e.g. [14]). The more immersed the user is the fewer distraction from objects or actions in the real world occurs. Thus the learner can better concentrate on the content, which eases learning. The advantages of higher immersion for learning have also been researched and shown by Sowndararajan et al. [15].

The findings of the conducted experiment can also serve as a decision support with regard to choose input devices, if you are designing an immersive virtual learning environment.

Thus it can either help to build a base for a new interaction model for learning environments. Or it can be used to broaden the theoretical framework of Chen et al. [2] to include immersive environments.

### References

1. Kuan, W.L., San, C.Y.: Constructivist physics learning in an immersive, multi-user hot air balloon simulation program (iHABS). In: SIGGRAPH 2003: ACM SIGGRAPH 2003 Educators Program. ACM, New York (2003)
2. Chen, C.J., Toh, S.C., Wan, M.F.: The theoretical framework for designing desktop virtual reality-based learning environments. Journal of Interactive Learning Research 15(2), 147–167 (2004)
3. LaViola, J.J., Feliz, D.A., Keefe, D.F., Zeleznik, R.C.: Hands-free multi-scale navigation in virtual environments. In: I3D 2001: Proceedings of the 2001 symposium on Interactive 3D graphics, pp. 9–15. ACM, New York (2001)
4. Usoh, M., Arthur, K., Whitton, M.C., Bastos, R., Steed, A., Slater, M., Frederick, P., Brooks, J.: Walking > walking-in-place > Flying, in virtual environments. In: SIGGRAPH 1999: Proceedings of the 26th annual conference on Computer graphics and interactive techniques, pp. 359–364. ACM Press/Addison-Wesley Publishing Co., New York (1999)
5. Larssen, A.T., Robertson, T., Edwards, J.: The feel dimension of technology interaction: exploring tangibles through movement and touch. In: TEI 2007: Proceedings of the 1st international conference on Tangible and embedded interaction, pp. 271–278. ACM, New York (2007)
6. Tan, D.S., Pausch, R., Stefanucci, J.K., Proffitt, D.R.: Kinesthetic cues aid spatial memory. In: CHI 2002: CHI 2002 extended abstracts on Human factors in computing systems, pp. 806–807. ACM, New York (2002)
7. Balakrishnan, R., Hinckley, K.: The role of kinesthetic reference frames in two-handed input performance. In: UIST 1999: Proceedings of the 12th annual ACM symposium on User interface software and technology, pp. 171–178. ACM, New York (1999)
8. Ängeslevä, J., O'Modhrain, S., Oakley, I., Hughes, S.: Body mnemonics. In: Physical Interaction (PI03) – Workshop on Real World User Interfaces, a workshop at the Mobile

Here's the cleaned and normalized Markdown:

## Guiding Learners in Learning Management Systems through Recommendations

**Olga C. Santos and Jesus G. Boticario**

aDeNu Research Group, Artificial Intelligence Department, UNED,
Calle Juan del Rosal, 16, Madrid 28040, Spain
{ocsantos,jgb}@dia.uned.es
http://adenu.ia.uned.es

## Abstract

In order to support inclusive eLearning scenarios in a personalized way, we propose to use recommender systems to guide learners through their interactions in learning management systems. We have identified several issues to be considered when building a knowledge-based recommender system and propose a user-centered methodology to design and evaluate a recommender system that can be integrated via web services with existing learning management systems to offer adaptive capabilities. We report some results from a formative evaluation carried out with users receiving recommendations in dotLRN open source eLearning platform.

**Keywords**: Recommender systems, User experience, Accessibility, Recommendations, Learning Management Systems.

## 1. Introduction

Information and Communication Technologies have been considered from the beginning as a way to remove geographical and temporal barriers. Moreover, accessibility barriers can also be eliminated if this technology is properly applied. In this context, a proper usage of technology provides even more opportunities to enhance the learning. Addressing the individual needs in the learning process is difficult to achieve in face to face learning scenarios. However, in the current eLearning scenarios, learners can access virtual course spaces which provide contents and services (e.g. communication tools) through a web-based interface. These interfaces have evolved from simple web pages to complex systems to facilitate the management of the learning.

Learning managements systems (LMS) are broadly used in many institutions and efforts are being done to integrate them with their current technological infrastructure. The interactions done by the users in these systems can be gathered. These data, combined with information obtained explicitly from the users can be used to build user profiles. As a result, these profiles can provide the needed information to describe the needs and expectations of the users with the system. With this information personalized responses that address these individual needs could be offered to the users in LMS.

This situation presents several challenges to the research community on technology enhanced learning (TEL):

- What are the needs of the users in LMS?
- How can users be supported in their needs when using LMS?
- Is there a way to evaluate that users are properly supported in the LMS?
- Can these services be supported in terms of web services architectures?

Our research follows on the idea of combining design and runtime adaptations. According to this approach, adaptations should be applied along the full life cycle of eLearning making a pervasive use of standards to support users in the process. The idea behind is that adaptation is not an idea that can be plugged in a learning environment, but a process that influences the full life cycle of learning, which consists on four steps where the user (and not the system) is the focus.

## 2. Learning Scenarios and Recommender Systems

The first approaches to support learners with technology were done through the usage of Intelligent Tutoring Systems (ITS) [1]. These systems provide direct customized instruction or feedback to students, without the intervention of human beings, whilst performing a task. They contained a description of the knowledge or behaviors that represent expertise in the subject-matter domain the ITS is teaching which was used to detect the misconceptions and knowledge gaps of the learners as they work in the system to offer them the appropriate support. Conceptually, ITS are domain independent, although in practice most ITS have been designed for very specific domains and the knowledge is wired in the system, and hence, any changes on the domain require a development process. Moreover, ITS do not consider the interactions of the users within more collaborative learning scenarios which are supported by a wide diversity of communication tools.

Current eLearning scenarios are supported by LMS. A common feature of these systems is the dispersion on the information available and the variety of communication channels to consider. Some can be structured in terms

Here's the cleaned and normalized Markdown:

## Guiding Learners in Learning Management Systems through Recommendations

## Implementation and Model

The knowledge-based recommender was implemented and integrated into a well-known open source standard-based LMS called dotLRN. This recommender aims at generating suitable recommendations and reasoning about which elements of the domain meet the current user's needs and context.

The recommender system model describes:
1. What should be recommended (different recommendation types relating to LMS object actions, such as sending forum messages, working on objectives, or sharing opinions)
2. When a recommendation should be provided (considering user/course context, application conditions, and timeout restrictions)
3. How a recommendation should be displayed (considering accessibility and usability criteria)
4. Why a recommendation has been produced (category, technique used, and source)

Details on the model are provided elsewhere [4].

[Figure 1: Recommender System integrated in dotLRN LMS]

The figure shows a coursespace in dotLRN where, in addition to communication services such as Forums and a SCORM player for learning materials, a new portlet provides two recommendations for the current user.

## Experiences with Users

To understand users' perception of the recommender, formative evaluations were conducted through two summer courses:
- First course: "Accessibility and disability in the University: a development based on ICT" (UNED, July 2008)
- Second course: "Services of the Web: applications towards the frontiers of knowledge" (UIMP, August 2008)

A total of 29 users participated, including two disabled users. Anonymity was assured through random fictitious logins. Users accessed a dotLRN instance for one hour with integrated recommender system support. The system offered an accessible SCORM-based course and various platform services including questionnaires, file storage, forums, calendar, FAQs, chat room, blog, statistics, and recommendations.

Thirteen recommendations were defined for different course situations. Recommendations disappeared once followed. Initial recommendations included reading platform help, completing learning style questionnaires, accessing course contents, and introducing themselves in course forums.

Results showed:
- Positive user satisfaction from questionnaires
- No usability or accessibility problems detected
- 55% of users completed required tasks in given time
- Users following recommendations showed increased task completion rates

## Ongoing Work

Current research focuses on:
- Defining psycho-educationally sound recommendations using appropriate user-centered design methods
- Applying artificial intelligence techniques to automate recommendation generation
- Developing a methodological approach to evaluate the recommender

The evaluation approach considers breaking down adaptation into constituents for piece-wise system evaluation.

## Guiding Learners in Learning Management Systems through Recommendations

Each constituent of adaptation is evaluated separately where necessary and feasible. The constituents into which adaptation is decomposed are typically termed "layers" and the resulting approach "layered evaluation" [7]. This approach can be used to evaluate the effectiveness of the system and the advantages of the adaptation it provides [8].

We propose to add an extra layer on top of the existing layered approaches from evaluation. The two more cited in literature propose 2 and 5 layers, respectively. The 2-layer evaluation process defined by [9] consists of:
1. Evaluation of user modeling
2. Evaluation of the adaptation decision making

The 5-layer evaluation process is defined by [10] and consists of:
1. Collection of input data
2. Interpretation of the data collected
3. Modeling of the current state of the "world"
4. Deciding upon adaptation
5. Applying adaptation decisions

The latter is a refinement of the former.

For the eLearning domain, we propose an extra layer to evaluate the design time issues. The purpose of this additional layer is to cover those issues which relate to psycho-educational considerations. From our experience, this is a critical issue since adaptive systems in education will only be successful in practice when teachers can easily deal with it.

In any case, the aim of these layers is to focus the evaluation in different directions, as identified in [6]:
1. The design of user interface of the tools required
2. The process to design/generate the recommendations
3. The process to select the appropriate recommendations
4. The analysis of the users' interactions

This new layer (evaluation of design time issues) includes the evaluation of the design of the user interface of the tools required and the process to design the recommendations. The second layer (evaluation of user modeling) covers the analysis of the users' interactions and the third layer covers the process to select the appropriate recommendations.

Several principles are to be taken into account in the evaluation process:
- Accessibility
- Usability
- Learnability
- Standards compliance

Accessibility issues and usability heuristics are to be focused on learnability and they are to be integrated in the layered-based evaluation. The latter provides different layers reflecting the various stages/aspects of the adaptation, starting from low-level input data acquisition or user monitoring, and going up to high-level assessment of the behavioral complexity of the users. This approach provides a series of advantages over those that focus on the overall user's performance and satisfaction, such as useful insight into the success or failure of each adaptation stage separately, facilitation of improvements, generalization of evaluation results, and re-use of successful practices.

## Acknowledgements

The work presented here is framed in the context of the projects carried out by the aDeNu Research group. In particular, the EU4ALL (IST-2006-034478) funded by the European Commission and A2UN@ funded by the Spanish Government.

## References

1. Psotka, J., Massey, L.D., Mutter, S.A.: Intelligent tutoring systems: lessons learned. Lawrence Erlbaum Associates, Mahwah (1988)
2. Drachsler, H., Hummel, H.G.K., Koper, R.: Personal recommender systems for learners in lifelong learning: requirements, techniques and model. International Journal of Learning Technology (2007)
3. Tang, T., McCalla, G.: Smart recommendation for an evolving e-learning system. In: Workshop on Technologies for Electronic Documents for Supporting Learning, Proceedings of 11th International Conference on Artificial Intelligence in Education, Sydney, Australia, July 20–24, pp. 699–710 (2003)
4. Santos, O.C., Boticario, J.G.: Users' experience with a recommender system in an open source standard-based learning management system. In: Proceedings of the 4th Symposium of the WG HCI&UE of the Austrian Computer Society on Usability & HCI for Education and Work,

Here's the cleaned and normalized Markdown:

## Supervising Distant Simulation-Based Practical Work: Environment and Experimentation

**Authors:** Viviane Guéraud¹, Anne Lejeune¹, Jean-Michel Adam¹, Michel Dubois², and Nadine Mandran¹

¹ Laboratoire d'Informatique de Grenoble (LIG), CNRS, Université de Grenoble, France  
² Laboratoire Interuniversitaire de Psychologie, Université de Grenoble, France

## Abstract

In this paper we present research targeting distant simulation-based practical work in various scientific domains. For the 6 past years, we continuously tried to improve the FORMID environment tools that we have designed and developed for building, running and observing such learning situations. This paper focuses on FORMID-Observer which is the FORMID tool intended to provide teachers with semantic information about the learners' progress. We present the analysis of teachers' observation practices during a recent session involving a secondary school group of learners in a practical work in electricity. Throughout the experiment's results, we aim at showing how teachers' diagnosis of learners' domain-knowledge benefit both from the general principles of FORMID-Authoring tool and from the particular features of FORMID-Observer.

**Keywords:** Supervision, Distant monitoring, Semantic data visualization, Teacher interface, Tutoring system, Virtual learning environment, Simulation, Computer supported learning, Distance Learning.

## 1. Motivation and Background

There is an increasing use of e-learning systems providing teaching material via the Web. What happens in a virtual classroom where learning activities are automatically managed by e-learning environments? Which kind of awareness does a teacher need to understand learners' progression throughout the learning process? These questions are not new [1, 2], but the related answers vary depending on the learning situation.

Collecting the pertinent data to know exactly what happens during a learning session depends on the learning context. Some well used course management systems like WebCT/Blackboard, Moodle or Dokeos [3] usually provide general information about the students' activity. These data are content independent, they provide the teacher with an idea of the effort done by each student, but don't really inform about the quality of learning. Several research projects have developed tools that allow teachers to keep track of their learners' interactions with the environment [4, 5, 6, 7], and of their learners' communication activity in distant learning [8, 9, 10, 11]. Learning data can be collected by various means such as computer-interaction traces, videos, voice recordings, etc. The size of the collected data is also a crucial differential factor of awareness. However, making sense of these data remains the most difficult task.

## 2. Theoretical Aspects about Monitoring a Learning Session

Monitoring learner progress in the e-learning context requires a consideration of the mental representation which a teacher generates for the purposes of diagnosing standards of learner development. The cognitive process involved in the perception of on-screen data is intimately connected with the monitoring of learning. The monitoring activity may therefore be conceived as the cognitive mechanisms determining correlations between data drawn from the system and data based on teachers' acquired knowledge.

The meaning of the situation is therefore not established a priori, but is rather constructed from the lowest level data interacting with a variety of cognitive processes. Monitoring a learning session does not merely consist in generating a representation of available on-screen data, but also involves forming a representation of what the on-screen information signifies in terms of learning [16]. In processing surface information, a teacher gradually forms several representations that vary in terms of duration and richness [17].

Except in exceptional circumstances [18], the surface code has a very brief duration and is quickly superseded by a level of representation reflecting meaning rather than the available surface data [19]. In monitoring a learning session, teachers establish connections between different types of on-screen data according to their acquired knowledge of class supervision [20, 21]. The teacher is therefore engaged in several distinct processes:

- A coherent an

Here's the cleaned and normalized Markdown:

## FORMID-Observer: A Flexible Environment for Teachers

## Overview

The FORMID environment is composed of three distinct tools:
1. FORMID-Author for describing computer-supported practical work sessions
2. FORMID-Learner for engaging learners into such sessions and storing learning traces in a database
3. FORMID-Observer, which this paper focuses on, for making teachers aware of class progression throughout a session

The issues relating to a teacher's use of FORMID-Observer encompass: how effectively is the information shown by FORMID-Observer integrated, and what kinds of situational model are devised by teachers?

## System Structure

We are dealing with active learning individual situations in which the learner must solve a problem while interacting with a simulation. In FORMID sessions problems are called exercises. Each exercise is described by a pedagogical scenario structured in steps; each step includes:

- The goal to be achieved by each learner on the simulation: i.e. a condition on the final simulation state to be evaluated (as correct or not) and traced each time the learner requests an end-of-step validation
- A set of specific situations on the simulation, each revealing a typical error (or conversely a good behavior/reasoning) to be automatically detected and traced during the step: i.e. a condition on the simulation state which value has to be observed by automatic frequent inspections

## Features for Teacher Supervision

FORMID provides teachers with the following features:

- When defining a scenario, the teacher specifies what the execution tool will control during learner progression, according to pedagogical approach, targeted learner group and knowledge of past teaching practices
- FORMID-Observer provides three levels of perception, allowing teachers to choose which view they need for supervision at a given time
- For each displayed event, detailed information on the related simulation state provides additional insights
- Semantic learning traces are based on:
  1. Each learner's successive end-of-step validation requests and their value
  2. Each learner's specific situation being detected during the step and their value

## Experimental Analysis

The experiment involved four second-degree physics teachers (2 Males, 2 Females, average age: 52) from the French National Institute of Research in Pedagogy (I.N.R.P.).

Preparation steps included:
1. Session Design: Teachers designed scenarios for the learning session using electric circuits' simulations (90 minutes, 3 exercises)
2. Session Execution: Fifteen secondary school students ran the FORMID session
3. Session Observation: Teachers received 20 minutes training before individually replaying the session with FORMID-Observer

Technical observation methods:
- Observation tracing: All independent teacher interactions with FORMID-Observer were traced and registered
- Verbal comments recording: External system used to record teachers' verbal comments

## Supervising Distant Simulation-Based Practical Work

## Analysis of Teacher Usage

Teachers were advised to be as expressive as possible about their analysis of learners' progress when interacting with FORMID-Observer. 

The research question was: "How is effectively integrated the information shown by FORMID-Observer, and what kinds of situational model are devised by teachers?" To access the mental representations of the learners' actions, behaviors and knowledge, we analyzed their verbatim recorded during the experiment.

FORMID-Observer usage allowed teachers to:

- Describe a learner or group's actions (79%) 
  *"Dubois has replaced the lamp, but has forgotten to set the switch off, he didn't modify the resistance again, so the lamp burnt out again!"*

- Comment on work methods employed to solve problems (38%)
  *"Among those who go forward by guesswork, there are those who have a good intuition: they see how to modify the resistance in order to find the right value, and there are those who do nonsense! It's easy to see that"*

- Express diagnosed domain-knowledge being mobilized (31%)
  *"They have a wrong reasoning about the tension: they are thinking in the same way that for the previous circuit. On the other hand they have a good reasoning about the intensity."*

Note that percentages sum to over 100% as some verbatim related to multiple categories. Verbatim could combine:
- Description and method comments
- Comments and diagnosis
- All three categories

The analysis indicates teachers processed information in steps:
1. Description
2. Comment 
3. Diagnosis

## Conclusion and Perspectives

FORMID-Observer is part of a complete Web-based environment for authoring, running and observing distant practical work learning sessions. Sessions consist of exercises where learners individually solve problems by interacting with simulations. Learning process indicators depend on simulation states evaluated during sessions and chosen during design. The combination of session structuring scenarios and indicators gives meaning to recorded learning traces.

The four teachers involved could track how learners solved problems and what domain knowledge they mobilized. Another study based on observation tracing and prior interviews showed their use of the three FORMID-Observer levels depended on their claimed supervision strategy without observation tools. Additional studies are ongoing. These case studies helped finalize the methodology for studying, tracing and analyzing FORMID-Observer usage. A larger experiment can now be conducted to generalize these results.

[References section preserved but omitted for brevity]

Here's the cleaned Markdown:

[13] Guéraud, V., Cagnat, J.M.: Automatic semantic activity monitoring of distance learners guided by pedagogical scenarios. In: Nejdl, W., Tochtermann, K. (eds.) EC-TEL 2006. LNCS, vol. 4227, pp. 476–481. Springer, Heidelberg (2006)

[14] Guéraud, V., Lejeune, A., Adam, J.M., Dubois, M., Mandran, N.: Flexible Environment for Supervising Simulation-Based Learning Situations. In: AIED 2009, Brighton (UK) (July 2009)

[15] Ben-Naim, D., Marcus, N., Bain, M.: Visualization and Analysis of Student Interactions in an adaptive Exploratory Learning Environment. In: International Workshop on Intelligent Support for Exploratory Environment, EC-TEL 2008, CEUR-WS.org, vol. 381 (2008)

[16] Graesser, A.C., Millis, K.K., Zwaan, R.A.: Discourse comprehension. Annual Review of Psychology 48, 163–189 (1997)

[17] Noordman, L.G.M., Vonk, W.: Memory-based processing in understanding causal information. Discourse Processes 28, 191–221 (1998)

[18] Kintsch, W., Bates, E.: Recognition memory for statements from a classroom lecture. Journal of Experimental Psychology: Human Learning and Memory 3, 150–159 (1977)

[19] Sachs, J.S.: Recognition memory for syntactic and semantic aspects of connected discourse. Perception and Psychophysics 2, 437–442 (1967)

[20] Frank, S.L., Koppen, M., Noordman, L.G.M., Vonk, W.: Modeling knowledge-based inferences in story comprehension. Cognitive Science 27, 875–910 (2003)

[21] Frank, S.L., Koppen, M., Noordman, L.G.M., Vonk, W.: Modeling Multiple Levels of Text Representation. In: Schmalhofer, F., Perfetti, C.A. (eds.) Higher level language processes in the brain: inference and comprehension processes, pp. 133–157. Erlbaum, Mahwah (2005)

[22] Bransford, J.D., Barclay, J.R., Francks, J.J.: Sentence memory: a constructive versus interpretive approach. Cognitive Psychology 3, 193–209 (1972)

[23] Glenberg, A.M., Meyer, M., Lindem, K.: Mental models contribute to foregrounding during text comprehension. Journal of Memory and Language 26, 69–83 (1987)

[24] Després, C.: Synchronous Tutoring in Distance Learning. In: Hoppe, U., Verdejo, F., Kay, J. (eds.) Proc. AIED 2003, pp. 271–278. IOS Press, Amsterdam (2003)

[25] Cortés, G., Guéraud, V.: Experimentation of an authoring tool for pedagogical simulations. In: Proceedings of International Conference CALISCE 1998, Göteborg, Sweden, pp. 39–44 (1998)

[26] Guéraud, V., Adam, J.-M., Lejeune, A., Dubois, M., Mandran, N.: Teachers need support too: FORMID-Observer, a flexible environment for supervising simulation-based learning situations. In: Workshop ISEE, AIED 2009, Brighton (

## Designing Failure to Encourage Success

## Introduction

However, many of these interventions have focused on the use of highly scaffolded or structured treatments that guide a learner through a series of activities. What is being proposed in this paper is that a move away from scaffolding in the initial encounter with a problem may result in better learning.

Research indicates that making mistakes and failing to arrive at the correct answer can encourage learners to reflect on their learning process and to access domains of knowledge and previous experiences, thus encouraging a deeper level of engagement and critical thinking [7-10].

This paper will present the benefits of using Virtual Singapura (VS), a multi-user virtual environment (MUVE), as a platform for learners to engage with complex or ill-defined problems. The research is part of a larger research project, which is the first of its kind in Australia, will focus on the initial cycle of a Productive Failure (PF) treatment in a MUVE.

## Productive Failure – Reaching an Impasse

PF is a learning strategy that designed to enhance or facilitate the transfer of knowledge from one domain activity to another. Recent research utilising PF in complex environments has resulted in significant findings that support the use of a PF treatment [see work by Kapur and Jacobson, Pathak et. al., Jacobson et al.].

As a simple analogy, PF can be viewed as an hourglass wherein students are able to explore an ill-defined problem domain with no structure in the initial activity, before being exposed to a structured activity and then re-exposed to an un-structured activity (see Fig. 1. below). This presents students with an opportunity to reach an impasse in the activity.

Often instructors shy away from allowing students to reach an impasse, however research by VanLehn et al. [10] indicates that allowing students to reach an impasse may encourage students to think more critically about a situation and that reaching an impasse can encourage learning. As Kolodner [9] indicates, we may be novices in one domain, but we can bring a multitude of past experiences into this domain that we can apply to attempt to solve the new problem. Kapur [7, 11] further argues that through using unstructured learning activities a student may develop more flexible and adaptive learning in the long run based on their initial failures.

Hence, the underlying premise of PF suggests that the lack of structure in the initial activity is the key to successful problem solving in subsequent structured and unstructured activities.

## Multi-user Virtual Environments as Learning Tools

MUVEs are becoming widely recognised for their benefits as learning environments. A MUVE is a persistent virtual environment that is usually accessed online via a downloadable software platform such as Active Worlds or is located online. There is a developing body of literature around MUVEs and with this comes crystallisation of the key criteria that classify a MUVE as a distinct tool from other forms of online learning activities. The five main criteria are:
- an avatar that represents the participant
- a 3D virtual environment
- the ability to interact with artefacts and agents
- participants can communicate with other participants and, in some instances, communicate with intelligent agents
- a 'real world' context that is created to provide an authentic experience that a student may not be able to encounter in a classroom environment [12-20]

MUVEs, such as Quest Atlantis [21] and VS [22] provide students with an opportunity to visualise and engage with complex learning systems in a setting that is motivating and engaging.

Nevertheless, all games and educational MUVEs have limitations and educators need to be aware of these limitations in order to maximise the benefits of the experience for leaner – in this research project the cycles of feedback and iteration may address some of the pedagogical and design issues that concern VS and other MUVE environments.

## Virtual Singapura – Solving Complex Problems in a MUVE

VS was developed in Singapore as part of a collaborative project between researchers at Singapore Learning Sciences Laboratory (National Institute of Education) and faculty in Computer Engineering and in Art, Design, and Media at Nan

Here's the cleaned Markdown:

## Participants

The participants in this study will be drawn from an Australian High School. The participants will be studying science in years 7-9 (12-15 years of age) to develop scientific inquiry skills this trial is scheduled for December 2009. Pilot studies will be held in August 2009 with pre-service teachers undertaking a Master Degree at Sydney University.

## Data Collection

A mixed-method approach to data collection will be used. The intervention will have three phases. The first phase of the intervention will expose students to an unstructured activity. The second phase will expose participants to a structured activity. The third phase will expose participants to another unstructured activity. Pre, mid and post-tests will be used.

Verbal communication analysis of the initial unstructured activity will be used and the data will be coded on two levels – firstly, for convergence of ideas and secondly, for linguistic features [25, 26]. Screen capture software will be used to ascertain what aspects of the environment the learners are focusing on [25, 27, 28]. A broad analysis of this data can express whether students are claiming, predicting, eliciting, creating and acting and will be coded to see how students collaborate when trying to solve or engage with the problem domain.

## Final Considerations

One final point to reflect on is that the aim of this research is not to produce a definitive theory on PF, but rather to complement and add to the small body of work that is currently available, and to hopefully provide further data to substantiate the rationale underpinning the use of a PF strategy in complex problem solving activities.

Current research projects indicate that there is unquestionable potential in the use of MUVEs in learning environments, this research into a PF treatment in VS will add to this growing body of work, and may provide another avenue which instructors can use to enable learners to develop problem solving strategies that move beyond the bounds of a traditional classroom environment.

## References

1. Zydney, J.M.: Eighth-Grade Students Defining Complex Problems: The Effectiveness of Scaffolding in a Multimedia Program. Journal of Educational Multimedia and Hypermedia 14(1), 61-90 (2005)
2. Bodemer, D., et al.: Supporting learning with interactive multimedia through active integration of representations. Instructional Science 33, 73-95 (2005)
3. Barnett, M., et al.: Using Virtual Reality Computer Models to Support Student Understanding of Astronomical Concepts. The Journal of Computers in Mathematics and Science Teaching 24(4), 333-356 (2005)
4. Kim, P., Olarciregui, C.: The effects of a concept map-based information display in an electronic portfolio system on information processing and retention in a fifth-grade science class covering the Earth's atmosphere. British Journal of Educational Technology 39(4), 700-714 (2008)
5. Lowe, R.: Interrogation of a dynamic visualisation during learning. Journal of Learning and Instruction 14, 257-274 (2004)
6. Puntambekar, S., Goldstein, J.: Effect of Visual Representation of the Conceptual Structure of the Domain on Science Learning and Navigation in a Hypertext Environment. Journal of Educational Multimedia and Hypermedia 16(4), 429-459 (2007)
7. Kapur, M.: Productive Failure. Cognition and Instruction 26(3), 379-424 (2008)
8. Hmelo, C.E., Holton, D.L., Kolodner, J.L.: Designing to Learn about Complex Systems. The Journal of the Learning Sciences 9(3), 247-298 (2000)
9. Kolodner, J.L.: Case-Based Reasoning. In: Sawyer, K. (ed.) The Cambridge Handbook of the Learning Sciences, pp. 225-242. Cambridge University Press, Cambridge

Here's the cleaned and normalized Markdown:

## References
- Sawyer, K.: Analyzing Collaborative Discourse. In: Sawyer, K. (ed.) The Cambridge Handbook of the Learning Sciences, pp. 187–204. Cambridge University Press, Cambridge (2006)
- Kapur, M., Kinzer, C.K.: Productive Failure in CSCL Groups. International Journal of Computer-Supported Learning 4(1), 21–46 (2009)
- Mazur, J.: Conversation Analysis for Educational Technologists: Theoretical and Methodological issues for Researching the Structures. In: Jonassen, D. (ed.) Processes and Meaning of On-line Talk, in Handbook of Research for Educational Communications and Technology. MacMillian, New York (2004)
- Mazur, J., Lio, C.: Learner Articulation in an Immersive Visualization Environment. In: Conference on Human Factors in Computing Systems, Vienna, Austria. ACM, New York (2004)

## Revisions of the Split-Attention Effect

**Author**: Athanasios Mazarakis  
**Institution**: Forschungszentrum Informatik, Haid-und-Neu-Str. 10-14, 76131 Karlsruhe, Germany  
**Email**: mazarakis@fzi.de

## Abstract
For the learning process with multimedia contents the split-attention effect postulates that learning results are better the higher the spatial proximity of text and picture elements is. This article shows that by the use of an artificially generated relationship between texts and pictures which are far away (according to the new principles of grouping by Palmer), it is possible to attain learning results which are at least equal. The negative impact of the spatial distance between text and picture elements can therefore be avoided in a different way. So an online survey has been conducted and the data of 869 subjects have been evaluated regarding to their retention and transfer performance.

**Keywords**: multimedia learning, cognitive load theory, cognitive theory of multimedia learning, split-attention effect.

## 1 Introduction
There are two commonly used and very similar cognitive theories of learning with multimedia contents: the Cognitive Load Theory and the Cognitive Theory of Multimedia Learning. But both approaches have theoretical weaknesses if they try to handle effects which came into being directly from the theories. In this context the split-attention effect will be discussed further.

## 2 Background of the Used Theories
According to the Cognitive Load Theory of Sweller there are three different so called "loads": The intrinsic cognitive load, the extraneous cognitive load and the germane cognitive load. These three loads are added up to the cognitive load. Here the extraneous cognitive load is the load, which originates from an unadjusted design of the instructions, like e.g. additional multimedia elements, which divert the attention of the learner.

However the germane cognitive load is responsible for the construction and automation of schemata which Sweller regards to be the ideal solution for the learning with multimedia content. For the construction and automation of schemata it is important to observe the limited capacity of the working memory according to Baddeley.

Finally, the intrinsic cognitive load again arises from the natural complexity of the information which has to be learned. On the one hand there are elements which can be learnt independently from others and therefore only cause a low cognitive load. Sweller calls this low-element interactivity material. On the other hand there are elements which correspond strongly to each other, called high-element interactivity. Here a high cognitive load arises due to the fact that the information has to be learned simultaneously in order to achieve a high level of understanding by the learner.

Besides the already presented Cognitive Load Theory, the Cognitive Theory of Multimedia Learning by Mayer and Moreno is the second prominent theory of learning within the multimedia field. This theory is very similar to the Cognitive Load Theory and is mentioned at this point in order for completeness.

###

## Revisions of the Split-Attention Effect

## Background and Theory

Beck and Palmer [11] empirically studied grouping factors. Due to restricted space, only the grouping factor common region is described in this article.

The grouping factor common region implies, according to Palmer [12], that - all else being equal - elements are perceived as a group if they are integrated within a connected, similarly colored or uniformly structured area with the same included contour and color. By "all else being equal" Palmer [12] means that all other features are held constant or eliminated, the so-called "ceteris-paribus-rule". However, if this is not the case, an estimation of the result can no longer be made due to the fact that interactions are neither measurable nor controllable.

An example for the grouping factor common region is shown in illustration 2. It clarifies that the proximity of the points is no longer important for the perceived grouping, although the points within an ellipse are more distant than the two bordering points in the two bordering ellipses.

## Research Questions and Hypotheses

Derived from the work of Mayer [4] and Moreno et al. [10], text and graphic illustrations should be grouped as near as possible on the computer screen, as otherwise it would result in significant losses of learning performance. This article argues that not only proximity between "text" and "picture" elements is important, but also that an artificially created relationship between these elements leads to at least equal learning success.

The following hypotheses are examined:

1. The linked display format with the new principles of grouping according to Palmer [1] does not lead to less learning and transfer performance than the integrated display format.
2. Persons with less meteorological previous knowledge benefit significantly more - according to Mayer [13] - than persons with high meteorological previous knowledge and therefore produce more and more creative solutions.
3. The animation without descriptive text performs as a control condition significantly worse than all other test conditions; the animation is therefore not self-descriptive.

## The Study

The conducted field study was an online survey about the meteorological phenomenon "The creation of lightning." The study was divided into three phases:

1. Subjects judged their own meteorological knowledge, following Moreno et al. [10].
2. Subjects were randomly assigned to one of six conditions viewing a three-minute animation about lightning creation. The conditions varied in:
   - Spatial proximity of text to animation
   - Used principle of grouping

The six conditions were:
- Integrated text condition with spatial proximity (IT)
- Integrated text condition with common region (ITCR)
- Control condition without descriptive text (CG)
- Separated text condition with spatial distance (ST)
- Separated text condition with common region (STCR)
- Separated text condition with element connectedness (STEC)

3. Subjects answered five open questions under time constraint:
   - "Please explain how lightning works." (retention)
   - "What could you do to decrease the intensity of lightning?"
   - "Suppose you see clouds in the sky, but no lightning. Why not?"
   - "What does air temperature have to do with lightning?"
   - "What causes lightning?"

One point was awarded for each correct answer, with no penalty for incorrect answers.

The sample included 869 subjects (452 male), with an average age of 25 years (sd=7), and 63% were students.

## Revisions of the Split-Attention Effect

## Table 1. F-values for the comparison of the test conditions for transfer performance

*Italic printed values cannot be interpreted in an unequivocal way due to the "ceteris-paribus-rule".*

|     | IT   | ITCR | CG        | ST   | STCR | STEC |
|-----|------|------|-----------|------|------|------|
| IT  | ---- | .01  | 9.43**    | .74  | .32  | .24  |
| ITCR| ---- | ---- | 10.80*** | .91  | .42  | .33  |
| CG  | ---- | ---- | ----     | 5.17* | 9.82** | 6.80** |
| ST  | ---- | ---- | ----     | ---- | .26  | .13  |
| STCR| ---- | ---- | ----     | ---- | ---- | .01  |
| STEC| ---- | ---- | ----     | ---- | ---- | ---- |

*p < 0.05; ** p < 0.01; *** p < 0.001.*

It is apparent from table 1 that the transfer performance in the linked text conditions (ITCR, STCR and STEC) is not significantly worse than in the integrated text (IT) condition, the first hypothesis is accepted. The results for the retention performance are the same, although not displayed due to page restrictions. Also the control group without descriptive text performed significantly worse in both conditions. Therefore the third hypothesis is accepted, the animation is not self-descriptive.

The analysis of variance for the second hypothesis did not lead to significant results with FR(1,867) = 1.47, p < 0.3 and FT(1,867) = 1.30, p < 0.3 respectively, the null hypothesis was retained with no significant differences for both groups.

## Discussion and Outlook

The aim of this article was to test additional possible solutions for the split-attention effect in an empirical way. The until now used way of spatial proximity for knowledge acquisition and knowledge transfer of multimedia contents was extended by the new principles of grouping of Palmer [1] in cognition psychology, detailed by common region and element connectedness.

The first hypothesis regarding the equal value of the linked text conditions and the integrated text condition was supported. An artificial connection of the elements text and picture didn't lead to significantly worse results than a display of these elements in spatial proximity. On the other hand the animation without a descriptive text was not self-descriptive, the third hypothesis was confirmed. The results by Mayer [13], which show that novices especially benefit from the integrated formats, couldn't be verified in the course of this study, the second hypothesis was therefore rejected.

This study is measured by its size of the sample probably the largest in the context of research done on the split-attention effect. The number of subjects of the 37 studies in the meta-analysis of Ginns [14] in respect to this effect were mostly in the range of two number digits, sometimes even in the very low three digits number of subjects.

The results of the present study as well as the results of related studies of Michas and Berry [15], and of Bodemer et al. [16] generally lead to doubts about the often commonly cited universal validity of the split-attention effect. But it has to be stated that the two mentioned studies didn't have the aim of questioning the effect, but can only be interpreted in that direction by the non discovery of this effect.

In conclusion it can be recorded that the split-attention effect cannot be replicated as universally valid and science has to carve out the relevant conditions for the occurrence of this effect in the future. However the new principles of grouping have successfully passed their debut in research about the Cognitive Load Theory due to the acceptance of the first hypothesis an

Here's the cleaned and normalized Markdown:

## Grid Service-Based Benchmarking Tool for Computer Architecture Courses

Carlos Alario-Hoyos, Eduardo Gómez-Sánchez, Miguel L. Bote-Lorenzo, Guillermo Vega-Gorgojo, and Juan I. Asensio-Pérez

School of Telecommunication Engineering, University of Valladolid,
Camino Viejo del Cementerio s/n, 47011 Valladolid, Spain
{calahoy@gsic,edugom@tel,migbot@tel,guiveg@tel,juaase@tel}.uva.es

## Abstract

Benchmarking for educational purposes in the context of computer science can be hindered by the low number and the homogeneity of machines to be assessed, and the inaccuracy of the benchmarks to represent specific workloads. Thus, this paper proposes a benchmarking tool developed within a service-oriented grid in order to allow students to benchmark multiple workloads in machines that may belong to several educational institutions. This tool has been validated in a real educational scenario within a course on Computer Architecture.

**Keywords**: Benchmarking, education, architecture, service-oriented grid.

## Introduction

As part of their learning process, computer science students should develop skills related to the design and evaluation of computer systems. To achieve these learning objectives, the Association for Computer Machinery and the IEEE Computer Society state in their guidelines for Computing Curricula [1] that educators should challenge students with realistic scenarios, so that they can reflect on measurement techniques, as well as on the impact of computer organization to the performance of computer systems for specific workloads. Thus, benchmarking (i.e. execution of pieces of software to get performance measures for standardized workloads) plays a significant role as a quantitative measurement approach. Indeed, several Computer Architecture courses (e.g. [2] or [3]) make use of benchmarking to illustrate basic principles such as the dependence of performance on the workload or design driven to improve the performance/cost relationship.

Though it is easy to include a benchmarking activity that supports the evaluation of one machine (for example the lab main server) with a couple of workloads in a Computer Architecture course, it is far more challenging and complex for educators to propose a scenario in which students must advise a realistic customer to acquire a computer system suitable for its workload, due to several reasons.

First of all, the number of different machines available for benchmarking is often reduced in most educational institutions, thus hindering the educational interest of the activity and biasing the conclusions of the students. This is mostly because some machines can be too expensive, but it also happens often that available computer systems are much alike in features because they have been acquired simultaneously to benefit from vendor discounts. Moreover, existing machines are often outdated and might not represent an up-to-date realistic case study. Besides, the benchmarks available for these machines may not represent the intended workload making conclusions reached by the students unreliable. In addition, benchmarking increases security concerns since benchmarks are normally run locally in computer systems, and thus students and educators should remotely connect to these machines. This entails additional problems: the administrator burden is increased to create accounts or allow somehow these connections, besides configuring machines and installing benchmarks; and students and educators should handle a larger number of logins, passwords and commands for the remote connection and the execution of benchmarks in different machines, increasing their cognitive load. It may very well happen that students concentrate too much on the procedure of benchmarking, instead of devoting efforts to plan the experiments or to interpret the results.

Many of these limitations could be overcome if there was a way that several academic units (let them be departments, schools or whole universities) could share their machines in a secure environment, so that they could be used for benchmarking in addition to other processes. The pool of machines to be benchmarked would thus be much larger and more diverse, enriching the learning activity. The administrative burden could be somehow shared among the different unit's administrators. Even more, the complexity

Here's the cleaned and normalized Markdown:

## Grid Service-Based Benchmarking Tool

## Service-Oriented Grid to Overcome the Limitations

A computational grid is a large-scale infrastructure composed by heterogeneous resources that are shared by multiple administrative organizations [9]. The access to these resources may be granted to the authorized members by the grid middleware. A service-oriented grid exposes these virtualized resources as services according to OGSA (Open Grid Service Architecture) [10] and the WSRF (Web Services resource Framework) [11] specifications. They promote the transparent access to the resources through a well-defined service interface.

Thus, within a service-oriented grid, different educational institutions, distributed geographically, could announce benchmarks that can be run in their machines for the benefit of their Computer Architecture courses. In addition, the service-oriented grid can decrease the administration burden by splitting the administration tasks. The main reason is that the distributed members in the grid usually have their own administrators. A service-oriented grid also provides the infrastructure in charge of controlling the access to a secure environment, for example through credential management or delegation mechanisms. Finally, the service-oriented grid can abstract low level details about resources, as they are exposed through a well-defined service interface. Therefore, users do not need to know how to communicate with remote machines for benchmarking as it is internally done between services and resources.

## Grid Service-Based Benchmarking Tool Architecture

As any other service-oriented application, the design of the Grid Service-Based Benchmarking Tool implies splitting the functionality into a set of different services to maximize the reusability when building other applications. Each of the identified services can be offered by one or more institutions participating in the grid, running them using their own local resources. The general architecture of the Grid Service-Based Benchmarking Tool, as well as the set of identified services is shown in Figure 1 and is described next.

The benchmark service is a front-end that allows any institution offering a set of machine/benchmark pairs. The administrator in the local institution, through the administration client, only needs to provide access to the machines in which benchmarks run, to any authorized user. The integration service allows educators through their educator client to select for their students a subset of machine/benchmark pairs from the ones offered by different institutions and gather them as a collection of benchmarks. The index service supports the register and discovery of resources and services. In this case, the index service is used by educators to find machine/benchmark pairs or by students through the student client to find collections of benchmarks and subsequently execute them transparently. In addition, the credential repository service enables secure access to the tool through credentials.

## Grid Service-Based Benchmarking Tool Prototype

A prototype of the Grid Service-Based Benchmarking Tool has been developed according to the WSRF standards and supported by the middleware Globus Toolkit 4.0 [12]. This prototype implements the following services: benchmark service, integration service, and index service. The first two have been developed from scratch while the last one belongs to the middleware. The internal communication between the benchmark service and the machines that it abstracts is based on SSH (Secure Shell). It entails an advantage because the machines do not need to be configured to run a service execution environment, thus there is no need to install the middleware and deploy services on them. Instead, SSH access to the machine needs only to be granted through the front-end service. The three clients (administration client, educator client and student client) have been implemented and distributed with Java Web Start being exposed to the users with a GUI. As an example, Figure 2 represents the GUI screenshoot from the Administration and Student Clients.

## Grid Service-Based Benchmarking Tool

## Validation

Computer Architecture is a fourth year course in the Degree of Telecommunication Engineering (University of Valladolid, Spain). One of the tasks of this course consists on the students assessing and comparing the performance of several real machines through benchmarks to determine which is the most suitable for a given customer workload. In this educational scenario some experiences with the Grid Service-Based Tool prototype were carried out, using 36 machine/benchmark pairs from two educational institutions: the Computer Architecture lab and the GSIC (Intelligent & Cooperative Systems Group) research group.

A questionnaire was voluntarily answered by 47 students after the experience, to detect general tendencies on the validity of the tool and to make suggestions for its improvement. As a sample result, 95.6% of students agreed or completely agreed with the easiness of use of the tool, supporting their opinions with the reduction of their cognitive load. In addition, more than 90% agree with the usefulness of this tool in the context of this course. Nevertheless, students cannot express any opinion about the underlying architecture and technology, because they interact with a front-end client that allows the execution of benchmarks in machines, no matter where they are located, or how this execution is done.

Additionally, administrators expressed some positive opinions when configuring this tool. For example, one remarked that he needed to invest less time than in previous years all along the benchmarking activity. The reason is related to the fact that students did not connect explicitly to the machines and thus, no one changed the password or deleted shared files, saving him the time to restore the original configuration. Besides, educators did not found problems when using the tool and even point out that students needed less assistance than in previous experiences.

## Discussion

The Grid Service-Based Benchmarking Tool has proved to overcome the limitations found in typical educational scenarios in terms of available machines and benchmarks, by sharing distributed and more varied resources between several institutions. Furthermore, the administration burden is also shared among local institutions, and even simplified in the provisioning of access to authorized users. Additionally, the tool removes low-level details for students and educators through an execution front-end, reducing their cognitive load and letting them focus on benchmarking plans and results instead of the procedure.

Nevertheless, some improvements can be done in the design of this tool. For example, an analysis service can be considered to facilitate the interpretation of the results with statistics for the same benchmark and different loads in the machine to be assessed. Besides, a visualization service may compare graphically these statistics in terms of response time or throughput. Additionally, the architecture could be complemented with an execution service that would be used by administrators to install and deploy benchmarks from a benchmark source repository with several benchmarks compiled for different architectures.

## References

1. ACM/IEEE: Computing Curricula 2007: Guidelines for Associate-Degree Transfer Curriculum in Computer Engineering (2007), http://www.acmtyc.org/reports/TYC_CEreport2007Final.pdf (last visited May 2009)
2. Martínez-Monés, A., et al.: Multiple Case Studies to Enhance Project-Based Learning in a Computer Architecture Course. IEEE Transactions on Education 48(3), 482-489 (2005)
3. Figueiredo, R.J., et al.: Network-Computer for Computer Architecture Education: a Progress Report. In: 2001 ASEE. Albulquerque, New Mexico (June 2001)
4. Foster, I., Kesselman, C.: The Grid: Blueprint for a New Computing Infrastructure. Morgan Kaufmann Publishers, San Francisco (1998)
5. Kapadia, N.H., et al.: PUNCH: Web Portal for Running Tools. IEEE Micro 20(3), 38-47 (2000)
6. Fox, G.: Education and the enterprise with the grid. In: Berman, F., Fox, G.C., Hey, A.J.G. (eds.) Grid Computing: Making the Global Infrastructure a Reality, pp. 963-976. John

## Supporting Virtual Reality in an Adaptive Web-Based Learning Environment

Olga De Troyer, Frederic Kleinermann, Bram Pellens, and Ahmed Ewais

Vrije Universiteit Brussel, WISE Research Group, Pleinlaan 2, 1050 Brussel, Belgium  
{Olga.DeTroyer,Frederic.Kleinermann,Bram.Pellens,Ahmed.Ewais}@vub.ac.be

## Abstract

Virtual Reality (VR) is gaining in popularity and its added value for learning is being recognized. However, its richness in representation and manipulation possibilities may also become one of its weaknesses, as some learners may be overwhelmed and be easily lost in a virtual world. Therefore, being able to dynamically adapt the virtual world to the personal preferences, knowledge, skills and competences, learning goals and the personal or social context of the learning becomes important. In this paper, we describe how an adaptive Web-based learning environment can be extended from a technological point of view to support VR.

**Keywords**: Virtual Reality, E-Learning, Adaptive Learning Environment.

## Introduction

Virtual Reality (VR) provides ways to use 3D visualizations with which the user can interact. For some learning situations and topics, VR may be of great value because the physical counterpart may not be available, too dangerous or too expensive. The most famous example is the flight simulator that pilots safely teaches how to fly.

Most of the time, when VR is considered for learning, it is offer as a stand-alone application (e.g., [1], [2], [3]) and there is usually no way to adapt it to personal preferences, prior knowledge, skills and competences, learning goals and the personal or social context of the learner. Augmenting a virtual world with adaptive capabilities could have many advantages [4]. It may be more effective to guide learners through the world according to their background and learning goals, or only show them the objects and behaviors that are relevant for their current knowledge.

In this paper, we explain how VR can be supported in the context of an adaptive Web-based learning environment developed in the context of GRAPPLE, an EU FP7 project. GRAPPLE is mainly oriented towards classical learning resources, but the use of other types of learning materials (VR and simulations) is also investigated. Here, we concentrate on how the learning environment is extended to support VR.

## The GRAPPLE Architecture

GRAPPLE aims at providing a Web-based adaptive learning environment. The two main components are the Authoring Tool and the Adaptive Engine (see figure 1). The Authoring Tool (Web-based) allows a course author to define a course at a conceptual level. This is done by means of a (graphical) Domain Model (DM) and Conceptual Adaptation Model (CAM) [5]. The DM describes the concepts that should be considered in the course. The CAM expresses at a high-level and by using pre-defined pedagogical relations (such as the prerequisite relation) how the content and structure needs to be adapted at runtime. The authoring tool can also be used (by a more experienced person) to define new pedagogical relations, called CRTs. Defining a CRT also implies defining the adaptive behavior associated with the relation. Different adaptive behaviors may be possible for the same pedagogical relation, e.g., the prerequisite relation ("A is prerequisite for B") can be associated with an adaptive behavior that hides the dependent concept B as long as A has not been studied, or with an adaptive behavior that forces the learning sequence A than B. Next, the graphical CAM is translated into a format (called GAL – Generic Adaptation Language) that the adaptive engine can handled. During this translation, the adaptive behaviors, associated with the definition of the pedagogical relations, are used to express the desired adaptive behavior for the course.

The Adaptive Engine does the actual adaptive delivery of the content. Based on the state of the learner's profile (captured in the User Model) and the GAL specifications,

## Supporting VR in an Adaptive Web-Based Learning Environment

To support adaptive VEs, extensions are necessary for the authoring tool and for the adaptive engine. These extensions are necessary because the regular GRAPPLE tools consider a resource as a black box. To be able to adapt the VE itself, i.e. adapting the presentation of the objects in the world, enabling and disabling behaviors and interaction, including objects conditionally, and/or providing dedicated navigation possibilities in the virtual world, this approach is no longer suitable. 

Although some of the adaptations can be seen as extensions of adaptations for text resources, they are very specific for 3D material and the possibilities are much richer. For instance:

- To visually indicate that an object has not yet been studied, we may want to give it a different color or make it smaller
- When a learner is studying a complex object (like a planet of the solar system), the visual appearance of the object could change according to the aspects being studied (size, temperature, geography, etc.) or become more detailed while more knowledge is acquired
- It may be necessary to disable or enable behavior and interaction for an object according to the progress of the learner

To allow specifying this, a dedicated VR authoring tool is necessary. Furthermore, it is necessary to provide a preview of the VE to the author while specifying the adaptations because otherwise he needs to specify adaptations blindly, which may be very difficult. For instance, it is not possible to replace one 3D object in a VE by any other 3D object, as this object may not fit into the VE. Also behaviors are usually strongly connected to the actual 3D object, and it is not always possible to replace a behavior by any other behavior.

The VR authoring tool is implemented as a Web application. It allows specifying VR-specific CRTs and has a component to define CAMs. The VR specific authoring tool does not need a specific DM component; it uses the DM tool of the general authoring tool. Note the availability of a Previewer. The Loading component is responsible for retrieving the necessarily information from the different repositories (using available web services) and for retrieving the VR resources that needs to be previewed. The Saving component is responsible for storing all the information defined by the author, i.e. newly defined CRTs and CAM specifications. The output format is GAL but we also have an independent XML format to be able to connect to other systems.

The extension of the adaptive engine towards VR is realized by means of a browser plug-in responsible for:

1. Updating the VE if the adaptive engine instructs to do so
2. Monitoring the learner's behaviour
3. Sending information about the learner's behavior to the Adaptive Engine

For the retrieval of VR content by the VR browser plug-in, a server-side plug-in is added, the VR-Manager.

The VR browser plug-in has three components:
- The Monitor component
- The Update component
- The VR player

An existing VR player is used to visualize the VR content. We require that the VR player supports Document Object Model (DOM), JavaScript, Scene Authoring Interface (SAI), and X3D. The Scene Authoring Interface is used to communicate to the VR player. In this way, it is possible to update at runtime the scene graph without the need to reload it completely. The Update Component is responsible for interpreting the adaptation requests received from the Adaptive Engine and for translating it into a form that can be understood by the VR player; it instructs the VR player to update the scene. The Monitor Component is responsible for keeping track of what happens in the VE and translating this in a form understandable by the Adaptive Engine, which on its turn will inform the User Model service about the progress made by the learner.

## Supporting VR in an Adaptive Web-Based Learning Environment

## Components and Delivery

![VR Authoring Tool - Components](Fig. 2)

![Adaptive VR Delivery](Fig. 3)

![Studying the Sun](Fig. 4)

To validate parts the adaptive delivery of the VR material, we have created a prototype and elaborated an example course with it. As the adaptive engine of GRAPPLE was not yet available at that time, the prototype is based on AHA! 3.0 [10], an adaptive learning engine on which the GRAPPLE adaptive engine will be based. As VR player we have used Ajax3D [11] that uses the Vivaty player [12]. It can use Ajax and can be embedded inside Firefox and Internet Explorer. Both the Monitor Component and the Update Component have been prototyped.  

To test the prototype, an example adaptive course has been developed. The adaptive course is about the solar system. To investigate the issues related to the combination of different types of content, this course contains plain text explaining the solar system, as well as a VE of the solar system were the sun and different planets are displayed in 3D (see figure 4). The text as well as the VE will adapt according to the learner's knowledge and progress. E.g., a planet appears when the learner starts to study it; planets that have been studied will stop rotating; and when all planets are studied the whole solar system is available in the VE.

## Related Work

Brusilovsky et al. [13] have integrated some adaptive hypermedia methods (mainly for navigation) into Virtual Environments. The approach of Santos and Osorio [14] is based on agents that help the user by providing him more information about interesting products, and by guiding him to their preferred area. The work of Moreno-Ger et al. [15] on 2D games is not on VR but is interesting as it provide an authoring tool allowing authors to create adaptive courses. Celentano and Pittarello [16] monitor a user's behavior and compare it with previous patterns of interaction. Whenever the system detects that the user is entering a recurrent pattern, it may perform some activities on behalf of the user. Chittaro and Ranon did quite some related work, first in the context of e-commerce, later on also for e-learning. Some of their work can be found in [17], [18] and [19]. The work in [19] is close to ours, and especially to the prototype that we have developed and which is also using AHA! (see section 3). However, they don't provide an authoring tool for specifying the adaptive story lines like we do. Furthermore, the main file containing the VE is reloaded at fixed time intervals to keep the adaptation inline with the student's user model. This is a serious drawback, especially for large VEs, because it will make the system very slow. In our approach, runtime adaptations don't require reloading the complete VE.

## Conclusions and Future Work

This paper describes an approach to support the adaptive delivery of Virtual Reality learning material inside GRAPPLE, a Web-based adaptive learning environment. The approach is innovative from different aspects:

- It contains a visual authoring tool for specifying the adaptive strategy for a VE
- The adaptation of the VE is done at run-time without the need to reload the VE each time, which will provide the necessarily performance required for large VE's
- VR material and classical (textual and 2D multimedia) can be integrated in a single course and the adaptation can be performed for whatever type of content
- The activities performed by the learner in the VE can be monitored and the effect can be directly reflected in the VE

First a prototype has been developed for the adaptive delivery. Currently, the implementation of the VR-authoring tool has been started as well as the implementation of the final VR-plug-in. Several experiments are planned to validate the approach as well as it usability and effectiveness.

**Acknowledgments**: This work is realize

## References

1. Alexiou, A., Bouras, C., Giannaka, E., Kapoulas, V., Nani, M., Tsiatsos, T.: Using VR technology to support e-learning: the 3D virtual radiopharmacy laboratory. In: Distributed Computing Systems Workshops, 2004. Proceedings 24th International Conference, pp. 268-273 (2004)

2. KM Quest, http://www.kmquest.net

3. De Byl, P.: Designing Games-Based Embedded Authentic Learning Experiences. In: Ferdig, R.E. (ed.) Handbook of Research Effective Electronic Gaming in Education. Information Science Reference (2009)

4. Chittaro, L., Ranon, R.: Adaptive Hypermedia Techniques for 3D Educational Virtual Environments. IEEE Intelligent Systems 22(4), 31-37 (2007)

5. Hendrix, M., De Bra, P., Pechenizkiy, M., Smits, D., Cristea, A.: Defining adaptation in a generic multi layer model: CAM: The GRAPPLE Conceptual Adaptation Model. In: Dillenbourg, P., Specht, M. (eds.) EC-TEL 2008. LNCS, vol. 5192, pp. 132-143. Springer, Heidelberg (2008)

6. Brutzman, D., Daly, L.: X3D: Extensible 3D graphics for Web Authors. The Morgan Kaufmann Series in Interactive 3D technology (2008)

7. W3C Document Object Model, http://www.w3.org/DOM/

8. JavaScript, http://www.javascript.com

9. Scene Authoring Interface Tutorial, http://www.xj3d.org/tutorials/general_sai.html

10. AHA! 3.0, http://aha.win.tue.nl/

11. Ajax3D, http://www.ajax3d.org/

12. Vivaty, http://www.vivaty.com/

13. Brusilovsky, P., Hughes, S., Lewis, M.: Adaptive Navigation Support in 3-D E-Commerce Activities. In: Proceedings of Workshop on Recommendation and Personalization in eCommerce at the 2nd International Conference on Adaptive Hypermedia and Adaptive Web-Based Systems (AH 2002), Malaga, Spain, pp. 132-139 (2002)

14. dos Santos, C.T., Osorio, F.S.: AdapTIVE: An Intelligent Virtual Environment and Its Application in E-Commerce. In: Proceedings of 28th Annual International Computer Software and Applications Conference (COMPSAC 2004), pp. 468-473 (2004)

15. Moreno-Ger, P., Sierra-Rodriguez, J.L., Ferandez-Manjon, B.: Games-based learning in e-learning Environments. UPGRADE 12(3), 15-20 (2008)

16. Celentano, A., Pittarello, F.: Observing and Adapting User Behaviour in Navigational 3D interface. In: Proceedings of 7th International Conference on Advanced Visual Interfaces (AVI 2004), pp. 275-282. ACM Press, New York (2004)

17. Chittaro, L., Ranon, R.: Adaptive 3D Web Sites. In: Brusilovsky, P., Kobsa, A., Nejdl, W. (eds.) Adaptive Web 2007. LNCS, vol. 4321, pp. 433-462. Springer, Heidelberg (2007)

18. Chittaro, L., Ranon, R.: Adaptive

## A Model to Manage Learner's Motivation

## Research Questions
The research questions in this academic context are:
- "What are the mechanisms to evaluate the student motivation?"
- "Which are the intervention strategies to enhance the student's motivation"
- "How to implement these strategies for a personal schooling intelligent agent?"

To determine the mechanisms to evaluate student motivation, we will analyze previous research in learner's motivation in the first section and propose a three-layer model to assess the learner's motivation state from academic schooling data. In the second section, we will analyze different strategies and interventions to enhance learner's motivation and present our approach.

## Academic Schooling Motivation Diagnosis

Most motivation theorists are convinced that motivation is involved in the learning process. A simple definition of motivation can be [8]:
- internal state or condition that activates behavior and gives it direction
- desire or will that energizes and directs goal-oriented behavior
- influence of needs and desires on the intensity and direction of behavior
- arousal, direction, and persistence of behavior

### Motivational States Computation

In a motivational intelligent system, the first challenge is to determine the learner's motivational state. We can do it with self-report methods, intelligent analysis from sensors to determine the affective state or with the study of data from the interaction between learners and learning content. Table 1 is an extended review of measuring motivation through user-computer/ITS interaction data [7]. It resumes the different research directions in learner's motivation diagnosis. We find that:

1. The motivation is not directly evaluated, the diagnosis uses intermediate indicators
2. The motivation's diagnosis uses in most cases at least the engagement and confidence indicators
3. The computation parameters come from the interaction with learning content

In our case we don't have data from the interaction with learning content; our assistant I-CAN has only the data from academic schooling. So the input data are:
- Academic data: assessment results, quarterly reports, tardiness, absenteeism, suspension, disciplinary, sanction, trouble relationships with adults
- Interaction data: between the student and the intelligent assistant and with the information system

These data won't permit us to assess indicators such as confidence, confusion, attention, independence. We will focus on the diagnosis of the performance (regularity, progression, result), the efficiency, the engagement, and emotional/physical conditions.

### Our Model of Motivation Diagnosis

Our model of motivation is made of three steps and we divide the main problematic: "How to diagnose the learner's motivation?" into sub-problems to solve. Motivation is an aggregation of performance and efficiency.

The first computation step consists in pre-processing the input data and summarizing them into four types of indicators:

1. Performance: result, regularity and progression indicators are calculated from the academic results. It shows the student's global performance.
2. Emotional state: motivation and emotion are closely linked; the emotion can have an impact on the motivation, and vice versa. We can determine it by a self report method or the analysis of student's interaction with the assistant and/or LMS.
3. Physical state: self report methods can be correlated with absences or tardiness.
4. Engagement/effort: tardiness, absenteeism, suspension, disciplinary sanction, trouble relationships will help us to analyse the student's engagement.

## A Model to Manage Learner's Motivation

## Motivation Diagnosis

![Motivation diagnosis model](Fig. 1. Motivation diagnosis model)

Then the efficiency factor is the aggregation of performance, physical state and the engagement indicators.

This model can be implemented by fuzzy rules system and association rules to determine indicators and theirs aggregation.

The motivational and its intermediate indicators will help us to design strategies of dialogue acts such as positive feedback, encouragement and praise adapted to the student's schooling state.

## Motivation Enhancement

Once the learner's motivational state computed, our intelligent assistant I-CAN will use this information to adapt it to this state and to find adequate strategies to maintain or enhance the learner's motivation. There are three mains motivation strategies:

- Motivational design: it increases the effort put into learning tasks
- Learning design: it changes the learning content or selects/recommends appropriate content
- Contingency design: it makes the learner confident that effort and performance are closely coupled with consequences

As our system I-CAN doesn't manage the contents, the strategies of I-CAN are based on motivational design and contingency design.

### Strategies to Manage Motivation

The source of motivation can be categorized as either extrinsic or intrinsic (internal to the person) [12]. Intrinsic motivation will only occur if the learner is highly interested in the activity. If a student has an intrinsic motivation to learn, he will feel satisfaction, enjoyment, and interest [2].

Motivational and contingency design can be done with affective dialogue that contains positive feedback and praise and it uses words and phrases that help attribute success to learner's effort and ability [14].

The interaction with the learner's and I-CAN is in natural language with an embodied conversational module and it will follow three principles:

1. To design a discourse motivational model with communication and educational theories. According to the Ginott model [6], the teacher should practice the congruent communication when giving feedback to students. Congruent communication is a way of communicating that increases self-esteem and decreases conflict. The main rule is "Talk to the situation, not to the personality and character".

2. The global strategy is to enhance the intrinsic learner's motivation. Students with high intrinsic motivation often outperform students with low intrinsic motivation. They engage more in learning activities and are more likely to complete course [14].

3. The development of a self-attribution explanation of the success [8], effort and internal and control ability are needed.

The motivation module is designed to be included in an embodied conversation agent; the aim of our model is to build a motivational discourse model.

### Our Motivation Enhancement Design

![Motivation enhancement model](Fig. 2. Motivation enhancement model)

The construction of the dialogue model is based on two main processes:

1. The first database is constructed from the interview of teachers and the analysis of quarterly reports. We obtain a real corpus of motivational dialog acts (positive feedback, encouragement, praise, reassurance).

2. The second database enhances the first one with the communication and educational theories as the Ginott Model [6].

The motivation management module takes in input the data from diagnosis module and matches it with the knowledge database. Motivation management module can be designed with associated rules or with a decision tree.

The motivational intelligent system would be able to improve our assistant I-CAN in several ways; the diagnosis can provide more information about the students' profiles, give more details about their difficulties. The motivation enhancement module would be able to increase the relation with the student; the dialogue will be more "human" and more personalized. The motivation management can play an important role to reduce the academic dropout.

## Conclusion

In this paper we have proposed an approach to monitor and to adapt to the learner's motivational during his academic learning. Our assistant I-CAN can collaborate with an ITS, the information exchanged will improve the performance of both systems.

One of the most important limitations of our system resides in the other parameters of the learner's motivation:

- The classroom learning, school environment: teacher, peers, learning process/activity
- The social environment: peers, friends, parents, family

Our future works consist in exploring more models in motivation research and in developing this motivational module. We need also to analyze the impact of the motivation in a discourse model. We will add the motivation management to our assistant I-CAN and test it in a real world application with students and teachers.

## References

1. Beck, J.E.: Using response times to model student disengagement. In: ITS2004 Workshop on Social and Emotional Intelligence in Learning Environments. Maceio, Brazil (2004)

2. Blanchard, E., Frasson, C.: An Autonomy-Oriented System Design for Enhancement of Learner's Motivation in E-learning (2004)

3. Cocea, M., Weibelzahl, S.: Cross-system validation of engagement prediction from log files. In: Duval, E., Klamma, R., Wolpers, M. (eds.) EC-TEL 2007. LNCS, vol. 4753, pp. 14–25. Springer, Heidelberg (2007)

4. De Vicente, A., Pain, H.: Motivation diagnosis in intelligent tutoring systems. In: Goettl, B.P., Halff, H.M., Redfield, C.L., Shute, V.J. (eds.) ITS 1998. LNCS, vol. 1452, pp. 86–95. Springer, Heidelberg (1998)

[References 5-14 omitted for brevity]

## Supporting the Learning Dimension of Knowledge Work

## Abstract

We argue that in order to increase knowledge work productivity we have to put more emphasis on supporting this learning dimension of knowledge work. The key distinctions compared to other TEL approaches are:

1. Taking the tight integration of working and learning seriously
2. Enabling seamless transitions on the continuum of learning practices
3. Tapping into the resources (material as well as human) of the organization

Within this contribution we develop the concept of work-integrated learning (WIL) and show how it can be implemented. The APOSDLE environment serves as a reference architecture which proves how a variety of tightly integrated support services implement the three key distinctions discussed above.

## The Learning Dimension of Knowledge Work

We conceptualize learning as a dimension of knowledge work which varies in focus (from focus on work performance to focus on learn performance) and time available for learning. This learning dimension of knowledge work describes a continuum of learning practices. It starts at one side with brief questions and task related informal learning (work processes with learning as a by-product), and extends at the other side to more formalized learning processes (learning processes at or near the workplace). This continuum covers the whole learning practices typology of Eraut and Hirsh [9] and emphasizes that support for learning must enable a knowledge worker to seamlessly switch from one learning practice to another as time and other context factors permit or demand. Research on supporting workplace learning and life long learning so far has focused predominantly on the formal side of this spectrum, specifically on course design applicable for the workplace and blended-learning.

## Supporting the Learning Dimension of Knowledge Work

## Introduction

In contrast, the focus of our work is on the informal side of the spectrum, specifically covering work processes with learning as a by-product and learning activities located within work processes. We coined the term work-integrated learning (WIL) [11] to refer to these learning practices. This emphasizes that learning at the workplace needs to be truly integrated in current work processes and practices and makes use of existing organizational resources – both knowledge artifacts (e.g. reports, project results) and humans (e.g. peers, communities).

WIL is relatively brief and unstructured (in terms of learning objectives, learning time, or learning support). The main aim of WIL activities is to enhance task performance. From the learner's perspective, WIL is spontaneous and/or unintentional. Learning in this case is a by-product of workplace activities. This conceptualization enables a shift from the training perspective of the organization to the learning perspective of the individual.

We have shown in [2] that the learning continuum exists for all commonly agreed upon knowledge work types (create, transfer, apply, package). For example, knowledge can be informally created within work practices when people learn from each other based on observations, or through more formalized workplace settings like dedicated brainstorming sessions. To support knowledge work, we must provide learning support for all four knowledge work types on a continuum of formality. Therefore, we present our proposed WIL support functionalities structured along these four knowledge work types.

## Supporting WIL with APOSDLE

This section provides a brief overview of how the APOSDLE environment supports the learning dimension of knowledge work. We have already evaluated much of the presented WIL support in previous prototypes within workplace situations of our application partners as well as within controlled lab studies, for example [12]. Future work in the APOSDLE project will mainly focus on a summative evaluation of the entire APOSDLE environment at four participating organizations over three months.

### Supporting Creation and Transfer of Knowledge

#### Sharing Knowledge Artifacts

In APOSDLE knowledge resides in knowledge artifacts: documents, parts of documents (referred to as snippets), notes, collaboration reflections, collections, etc. Such artifacts are containers for more or less structured information which relate to individual or collaborative tasks and activities. Knowledge artifacts are created from resources within the organizational memory by (automatically) attaching metadata which define the relationship and semantic meaning of artifacts in relationship to the work domain. They are shared throughout the organization.

A variety of different knowledge artifact types can be created and edited by knowledge workers. For example, knowledge workers can create:
- Notes in relation to other knowledge artifacts
- Collections containing other related knowledge artifacts 
- Reflections containing transcripts of collaborative activities and individual reflections of knowledge applied for certain learning contexts or situations

Knowledge workers are made aware of knowledge artifacts through automatic suggestions.

#### Scripted, Contextualized Collaboration

Collaboration is a social interaction in which knowledge workers transfer and construct knowledge while working or learning together. In APOSDLE, the collaboration process is structured into pre-collaboration, collaboration and post-collaboration phases to allow clear allocation of preparatory, executive and closing work or learning functions [13]. This structure is made explicit with the Collaboration Wizard, which guides collaborating knowledge workers through the process. It provides collaboration scripts on macro and micro level [7] for each phase to support collaboration as a structured process. These scripts help knowledge workers use each phase efficiently. In pre-collaboration, a combination of problem formulating, social and fading script is used to collect required information for coupling knowledge workers in collaborative interactions.

The Collaboration Wizard also contextualizes the work environment with information required for common anticipation of collaborative activities where knowledge needs to be transferred. This contextual information comes from previous and current activities: searched information, related knowledge artifacts, snapshots of individual work environments, etc.

### Supporting Application of Knowledge

#### Providing an Overview of Past Experiences

Meta-cognitive skills have been identified as an important ingredient of self-directed learning [3] [13]. Studies suggest that mirroring the learner's actions and their results have positive effects on learning. These intervent

## Supporting the Learning Dimension of Knowledge Work

## Suggesting and Visualizing Knowledge

Within the tree map the size of a square is related to the frequency with which the user has been engaged with the topic. The larger the square, the more frequent the engagement has been. This overview of activities allows the user to reflect on her past actions, to immediately asses her activity patterns, and to become aware of topics which she might want to advance further in.

### Suggesting Knowledge Artifacts

In order to apply knowledge to a specific work situation, a knowledge worker has to assess the situation and transform the knowledge to fit the situation. Reducing the effort for this learning transfer is believed to improving the likelihood of application of learned knowledge. APOSDLE takes the following approach: an intelligent recommendation algorithm suggests knowledge artifacts to the learner which are similar to the task or topic at hand and which have been retrieved from the organizational memory – thus improving the likelihood of offering highly relevant information which can be directly applied to the work situation with little or no learning transfer required. In doing so, APOSDLE also utilizes the automatically maintained user profile of the learner in order to compute a learning gap. The learning gap expresses the difference between knowledge about topics needed when executing a work task and the knowledge the user possesses about these topics. Based on this learning gap APOSDLE suggests relevant learning goals which the learner could pursue within her current work situations.

### Suggesting Knowledgeable People

Besides suggesting knowledge artifacts to the user, APOSDLE also suggests people in the organization which are knowledgeable in this specific task or topic. The goal is not, to always suggest the most knowledgeable person (e.g. the official topic matter expert). Instead, our algorithm seeks to identify peers which have (recently) executed the task before and which are believed to possess more or equal knowledge to the user in question. The identification of knowledgeable persons is based on the user profile.

## Supporting Acquisition of Knowledge

### Learning Paths

Sometimes, learners wish to learn a substantive part of a relatively unfamiliar learning domain, but this will frequently take more than several hours to complete. In order to successfully realize such learning, learners should carefully plan and manage the entire learning process. For self-directed learners, planning a learning path is often difficult, as most learners can not rely on instructional knowledge and have limited prior knowledge about the learning domain.

In APOSDLE, planning is supported with learning paths. A learning path describes how a learning domain can be traversed in an ordered way when learning about the domain. There are many possible paths through a learning domain. Learning paths can be created by the system or by learners.

The learning path wizard helps learners to construct and optimize learning paths. The wizard takes existing knowledge of the learner in the user profile into account and checks whether learners lack the prerequisite knowledge for their learning goals. The wizard suggests prerequisite topics and topics that might be relevant for a learning trajectory.

Topics in a learning path are automatically ordered in such a way, that the learning paths can be traversed easily. Basic knowledge is addressed first and more advanced knowledge that builds on the basic knowledge is addressed afterwards.

### Hints

Though in general it is expected that workers are motivated to acquire new knowledge in the context of their work, the knowledge acquisition process can be enhanced by providing hints how one could process the information retrieved. In APOSDLE hints are based on two features of learning: learning goals and the possible instructional meaning of retrieved information. According to Gery [10] and Choo [5], people often have specific questions or requests that come to mind when faced with performing new or complex tasks. For instance, questions like: "What must I do? How do I do it? Am I doing it right?", or requests like: "Show me…". The information type associated with such a question or request can reasonably be defined. One way of supporting learners is be to identify a set of relevant questions and requests and a set of related information types. This is similar to the approach followed by Anderson and Krathwohl [1] who developed a taxonomy of learning goals which are subsequently used for assessment purposes.

In APOSDLE, we opt

Here's the cleaned Markdown:

## References

1. Anderson, L.W., Krathwohl, D.R.: A taxonomy for learning, teaching and assessing: A Revision of Bloom's Taxonomy of Educational Objectives. Pearson Education, London (2001)

2. APOSDLE Consortium: Integrated APOSDLE Deliverables 2.8 and 3.5 APOSDLE Approach to Self-Directed Work-Integrated Learning (2009)

3. Bannert, M.: Metakognition beim lernen mit Hypermedien: Erfassung, Beschreibung und Vermittlung wirksamer metakognitiver Strategien und Regulationsaktivitäten. Waxmann Verlag (2007) ISBN 3830918720

4. Bonestroo, W., Kump, B., Ley, T., Lindstaedt, S.: Learn@Work: Competency Advancement with Learning Templates. In: Memmel, M., Ras, E., Wolpers, M., VanAssche, F. (eds.) Proceedings of the 3rd Workshop on Learner-Oriented Knowledge Management, pp. 9–16 (2007)

5. Choo, C.W.: The knowing organization. How organizations use information to construct meaning, create knowledge, and make decision. Oxford University Press, New York

6. Davenport, T.O.: Human Capital: What It Is and Why People Invest it. Jossey-Bass, San Francisco (1999)

7. Dillenbourg, P., Hong, F.: The mechanics of CSCL macro scripts. International Journal of Computer-Supported Collaborative Learning H. 3, 5–23 (2008)

8. de Hoog, R., Kabel, S., Barnard, Y., Boy, G., DeLuca, P., Desmoulins, C., Riemersma, J., Verstegen, D.: Re-using technical manuals for instruction: creating instructional material with the tools of the IMAT project. In: Workshop proceedings Integrating technical and training documentation, 6th International Intelligent Tutoring Systems conference (ITS 2002), San Sebástian, Spain, pp. 28–39 (2002)

9. Eraut, M., Hirsh, W.: The Significance of Workplace Learning for Individuals, Groups and Organisations. SKOPE Monograph, vol. 9. Oxford University: Department of Economics (2007)

10. Gery, G.: Electronic Performance Support Systems: how and why to remake the workplace through the strategic application of technology. Cambridge ZIFF Institute (1991) ISBN 0961796812

11. Lindstaedt, S., Ley, T., Scheir, P., Ulbrich, A.: Applying Scruffy Methods to Enable Work-integrated Learning. The European Journal of the Informatics Professional 9(3), 44–50 (2008)

12. Scheir, P., Ghidini, C., Lindstaedt, S.N.: A Network Model Approach to Retrieval in the Semantic Web. In: Sheth, A. (ed.) International Journal on Semantic Web and Information Systems, vol. 4, pp. 56–84. IGI Global Publishers, Hershey (2008)

13. Simons, P.R.J.: Towards a constructivistic theory of self-directed learning. In: Straka, G.A. (ed.) Conceptions of self-directed learning: theoretical and conceptional considerations, pp. 155–169. Waxmann, Münster (2000)

## User-Adaptive Recommendation Techniques in Repositories of Learning Objects: Combining Long-Term and Short-Term Learning Goals

**Authors:** Almudena

## User-Adaptive Recommendation Techniques in Repositories of LOs

## Describing the Required Knowledge

We agree with Draschler et al. [4] that the learning field imposes specific requirements on the recommendation process. For instance, recommenders would benefit from taking into account the cognitive state of the learner, which changes over time. Successful learning paths and strategies could also provide guiding principles for recommendation. For instance, recommendation could benefit from simple pedagogical rules like 'go from simple to complex tasks' or 'gradually decrease the amount of guidance'. Learning paths could represent routes and sequences designed by the instructors and successfully tried in the classroom, or they could correspond with successful study behaviour of advanced learners.

Our recommendation approach follows a two-step process, retrieval and ranking. The retrieval stage looks for LOs that satisfy, in an approximate way, the student's short-term learning goals represented in a query (in-session learning goals). These LOs should be "ready to be explored" by the student according to her current knowledge and the defined learning paths. Once LOs are retrieved, the ranking stage sorts them according to the quality assigned to each LO. The quality is computed so that priority is given to those LOs that are most similar to the student's query and, at the same time, have a high pedagogical utility in the light of the student's cognitive state (long-term learning goals).

Our previous weak personalization required domain knowledge in order to compute the similarity between the query and the domain concepts covered by the retrieved LOs. The adopted strong personalization imposes some additional requirements from the knowledge representation point of view. The retrieval stage requires the existence of suitable learning paths over the different domain concepts as well as information about the student cognitive state in the form of persistent profiles. The ranking stage also profits from the student profiles. It also follows remedial instructional strategies as a guideline for facing the student long-term learning goals and filling the student knowledge gaps, which results in an improvement of her mastery and skills.

### The Domain Ontology

We suggest the use of an ontology to index LOs within the repository. Ontologies provide a general indexing scheme that lets include similarity knowledge between the concepts representing the domain topics, which is a crucial knowledge in the similarity-based retrieval and ranking contexts employed by the recommender.

The ontology is populated with concepts in the field of study. Concepts are organized in a taxonomy using the typical relation is_a. The ontology should also establish a precedence property among the concepts. We use this precedence to reflect a traditional sequence or order of concepts used when teaching in the corresponding field. The precedence lets establish the learning paths that will be used in the retrieval stage to filter out LOs that exemplify non-reachable concepts given a concrete cognitive state of the student.

### The Learning Objects

In our context the recommended items are LOs of educational repositories. The LOs can be developed according to Learning Object Metadata (LOM). We propose to use the next upper-level LOM categories: General, Life cycle, Technical, Educational, Relation and Classification. The General category plays an important role in the retrieval stage. This category contains keywords that describe what domain ontology concept(s) the concrete LO covers. The other categories represent descriptive information that it is not used in the recommendation phases.

### The Student Profile

As we noted above, the strong personalization requires persistent profiles of the students. A profile stores information about the student's history of navigation −the LOs that she has already explored− and the goals achieved in the learning process. Concepts already explored by the student are assigned the competence level attained in each one. This level is considered as a degree of satisfaction, a metric that allows the recommender to know about the student's knowledge level on a particular concept. The competence level will be an important element in the retrieval stage.

## Describing the Recommendation Phases

The content-based recommendation strategy presented here follows a reactive approach: the student provides an explicit query and the recommender system reacts with a recommendation response. The student poses a query using the concepts existing in the domain ontology. This query represents her in-session learning goals: the concepts she wants to learn

## User-Adaptive Recommendation Techniques in Repositories of LOs

## The Retrieval Stage

The initial set of LOs is filtered to discard those indexed by concepts non-reachable by the target student. An ontology concept is "reachable" by a given student if, according to their current profile and the learning paths defined in the ontology, it fulfills any of the following conditions:

- It is a concept already explored by the student, appearing in their profile with its corresponding competence level.
- It is a concept that the student has not explored yet but can discover: if a concept c1 precedes a concept c2 in the ontology, a student can discover c2 if the student competence level for c1 exceeds a given "progress threshold". If several concepts c1, c2, ..., ck directly precede a concept cx, cx could be discovered if the student competence level in all the directly preceding concepts exceeds the given "progress threshold".

## The Ranking Stage

The ranking phase sorts the LOs retrieved according to the quality assigned to each LO. Priority is given to those LOs that are most similar to the student's query and have high pedagogical utility based on the student's profile.

The quality of a given LO L for a student S with query Q is computed as the weighted sum of two relevancies: the similarity (Sim) between Q and the concepts that L covers, and the pedagogical utility (PU) of L with respect to student S:

Quality(L,Q,S) = α × Sim(L,Q) + (1-α) × PU(L,S)    (1)

The similarity Sim(L,Q) compares the conjunction of query concepts (Q_conj_concept) and the conjunction of concepts covered by L (L_conj_concept):

Sim(L,Q) = |super(Q_conj_concept) ∩ super(L_conj_concept)| / |super(Q_conj_concept) ∪ super(L_conj_concept)|    (2)

The pedagogical utility PU(L,S) is computed as:

PU(L,S) = 1 - AM(L,S)    (3)

where AM(L,S) is the normalized arithmetic mean of the student's competence levels in concepts that L covers.

The value of α in equation (1) controls the balance between similarity and pedagogical utility:

- High α values prioritize query-relevant LOs, suitable for high-performing students
- Low α values emphasize filling knowledge gaps, appropriate for students with lower performance

## Conclusions and Future Work

This approach enables personalized content-based recommendation of LOs through:

- Light long-term personalization in the filtering step
- Strong personalization in the ranking stage through quality metric (1)
- A generic framework that can be instantiated with different approaches for computing Sim and PU relevancies

Here's the cleaned Markdown:

## Great Is the Enemy of Good: Is Perfecting Specific Courses Harmful to Global Curricula Performances?

We have carried out experiments in the Computer Programming domain but the approach could be easily transferred to others learning domains.

In order to alleviate the steep-use curve related with posing a query, we plan to complement the reactive approach with a proactive strategy that proposes the student LOs that could be of interest in a learning session, without the need of an explicit query. Preliminary work about the proactive strategy appears in [7].

Nowadays, we use the information about the navigation history recorded in the student profile in order to visually mark the recommended LOs that the student has already explored. A refinement of the quality metric could also take into account this fact in order to penalize these LOs.

### Acknowledgments
This work has been supported by the Spanish Committee of Education and Science project TIN2006-15202-C03-03 and the UCM project PIMCD2008-136.

### References
1. Farzan, R., Brusilovsly, P.: Social navigation support in a course recommender system. In: Wade, V.P., Ashman, H., Smyth, B. (eds.) AH 2006. LNCS, vol. 4018, pp. 91–100. Springer, Heidelberg (2006)

2. O' Mahony, M., Smyth, B.: A Recommender System for On-line Course Enrolment: An Initial Study. In: ACM Conference on Recommender Systems, pp. 133–136. ACM, Minneapolis (2007)

3. Gómez-Albarrán, M., Jiménez-Díaz, G.: Recommendation and Students' Authoring in Repositories of Learning Objects: A Case-Based Reasoning Approach. International Journal on Emerging Technologies in Learning 4(Special issue), 35–40 (2009)

4. Draschler, H., Hummel, H., Koper, R.: Recommendations for learners are different: Applying memory-based recommender systems techniques to lifelong learning. In: Workshop on Social Information Retrieval for Technology-Enhanced Learning (2007)

5. González-Calero, P., Díaz-Agudo, B., Gómez-Albarrán, M.: Applying DLs for Retrieval in Case-Based Reasoning. In: International Workshop on Description Logics, pp. 51–55 (1999)

6. Siemer, J., Angelides, M.C.: Towards an Intelligent Tutoring System Architecture that Supports Remedial Tutoring. Artificial Intelligence Review 12(6), 469–511 (1998)

7. Ruiz-Iniesta, A., Jiménez-Díaz, G., Gómez-Albarrán, M.: Recommendation in Repositories of Learning Objects: A Proactive Approach that Exploits Diversity and Navigation-by-Proposing. In: IEEE International Conference on Advanced Learning Technologies. IEEE Computer Society Publications, California (2009)

## Introduction

Content Sharing, Flickr, YouTube, Social Networking, Wikipedia... These are only some of today buzzwords, the words used in the Web 2.0 era, term defined to denote a set of principles and practices characterizing the "new" web, intended as a social and participation platform in which the content is produced by a multitude of users, e.g., the wisdom of crowds [1]. Also e-learning takes advantage of Web 2.0 potentialities. Nowadays, in fact, the emphasis is posed on Collaborative Learning, a social oriented e-learning strategy in which collaboration plays the major role. The network is no longer a mere tool for content distribution but it is rather a facilitator for the interaction among the participants involved in the educational process

Here's the cleaned and normalized Markdown:

## Great Is the Enemy of Good

## The Context of Our Experience

The University of Genova is a medium-size traditional university offering face-to-face courses. Since the beginning of 2005, efforts have been made to improve the quality of teaching by the introduction of ICT support in the educational process and, accordingly, of a Moodle-based Learning Management System (called AulaWeb[^1]) to be offered as a central service at the university level [5].

Though the numbers and the fast growth of the AulaWeb use are greatly encouraging, so far its use has been mostly unsophisticated, with download of material (slides, papers, lecture notes) as prevalent activity. But, it is now well accepted that the best learning occurs when students are actively involved in the learning process, possibly co-constructing pieces of knowledge, and software tools such as wikis, blogs, fora can be used for introducing some form of collaboration within the class. Initially, resource sharing had the lion's share of the online activities. This phenomenon is well known in literature for the first attempts to introduce web-based technologies in a traditional educational process, so far mostly based on lecturing and information giving.

To make the technological leap and actually take advantage of the full power of Web 2.0 support, instructional strategies and teaching styles have to be changed and to speed up this process professors have to be formed with the help of professionals, so that they can readily overcome their fear of technology and change their way of teaching to accommodate the novelty. In the last year our university has been involved in such a project. The action Web Enhanced Learning (WEL) has been launched in Apr. 2008, with the specific objectives of devising and experimenting a model for the transfer of instructional design knowledge and skills to subject-oriented university teachers. It is worth noting that WEL was not centered on the mere transfer of technological knowledge. Indeed, a short analysis showed that the causes behind the limited usage of tools supporting interactive ways of learning were mostly the lack of place for such kind of activities in the classical in-presence teaching/learning process, preferred by the quasi totality of our faculties.

The WEL course consisted of a few initial plenary lectures followed by face-to-face individual meetings with instructional design experts. A plenary meeting has been organized in Feb. 2009 to share the experiences of those colleagues who have been online in the first semester. Thanks to the introduction of a team of instructional specialists supporting faculty members, "many professors indicated their instructional strategies and teaching styles had changed."

Comparing the usage data of the intervals April 07-08 and April 08-09, we can observe that the usage of instruments like wikis and glossaries is increasing this year respectively of almost 75% and 140%, which is a percentage of growth much larger than that of the courses (24%) and the resources (41%). Moreover, the numbers suggest that also the approach to the use of the tools is improving. For instance, not only the number of wikis has increased, but that of pages and versions has dramatically grown, about 4 times the percentage of the wikis themselves! Thus, we can infer that not only we have a larger number of wikis, but also that they are used differently, with more online activities going on.

## Our Experience: Benefits for the Involved Courses

We describe now our personal experiences on three subjects delivered in Sept.-Dec. 2008 with the benefit of the WEL course. The first two courses are both mandatory and expected to have the same audience, that is, the students of the third and last year of the first cycle. The third course is an advanced course for the second cycle and it is interesting to compare the different approaches of the students to this and the previous courses.

Programming Advanced Techniques (TAP[^2]) since its introduction in 2003/04 has being organized around a project, requiring the students to individually realize a component. The course has a traditional organization, with lessons and small activities in the laboratory finalized to the project (which used to go mostly deserted), and was loosely supported by AulaWeb,

Here's the cleaned and normalized Markdown:

## Great Is the Enemy of Good

## Results of IS and TAP restricted to the first semester

| | TAP | | | IS | | |
|---|---|---|---|---|---|---|
| | 06/07 | 07/08 | 08/09 | 06/07 | 07/08 | 08/09 |
| Enrolled Students | 86 | 85 | 108 | 86 | 114 | 97 |
| Active Students | 44.19% | 35.29% | 82.41% | 75.58% | 75.44% | 87.63% |
| Passed Exams | 6.98% | 5.88% | 18.52% | 18.6% | 15.79% | 20.62% |
| Passed Projects | 6.98% | 8.24% | 34.26% | 32.56% | 31.58% | 72.16% |

Software Engineering with Project (IS) introduces the main concepts of software engineering, relying, to let the students experience such concepts, on a group project on realistic software development, taking up about half credits of the course. Until five years ago, the project was traditionally managed: the students worked on an assignment at their own pace with the only constraint of the final deadline. But, probably due to the inherent complexity of this kind of project, most groups were unable to complete it. Thus, in the academic year 2004/05 the project has been totally restructured, with the introduction of phases, with intermediate milestones and more interaction between students and teachers (see e.g., [7] for a detailed description). With the current organization, the results were much improved (see Table 1 for the data of the last two years).

Since IS already had a lot of interaction and community construction, the changes introduced accordingly to the WEL project were mostly technical. The structure of the course on AulaWeb was reorganized to make easier to find information; some activities, like for instance common development of exercise solutions, which were formerly loosely supported by an all-purposes forum, got their own devoted wiki and so on. The results were quite disappointing, being comparable with those of the previous years, as shown in Table 1. The active students are about 12% more, the completed projects have doubled, but the percentage of passed written examinations is only slightly better than the past years. Apparently the students focused on the project to the detriment of the preparation for the written examination and in particular all optional activities, mostly finalized to such preparation indeed, were dropped altogether. We think that IS already took its quality leap when the project organization changed and now technical adjustments gives only small improvements.

Network's Applications 2 (AR2) is an optional course, for the students of the second cycle of study, and this edition involved just 13 participants. Lectures varied from Web 2.0 technologies to the theory of Complex Networks, and the choice was that of mixing in-presence lessons with a small online activity for the first part of the course, that related to Web 2.0 technologies. In the first two weeks of Oct. 2008, students, split into 4 groups formed by teachers, have been asked to collaboratively write on a wiki a CookBook of software examples using technologies such as Web Services, REST, Ajax. For each example (individually chosen by each group) the students had to describe the product, the software language and the software libraries selected to develop it, and the overall architecture. All the decisions have been taken by sending posts to a technical forum associated with the wiki. 2 out of the 13 initial students dropped out since they realized they could not meet the online activity deadlines. Indeed, these 2 students were in their first level of study and decided to anticipate the subject, but experimented an interference with other courses. The other students realized imaginative projects which have been presented to the class in a demo session two weeks after the end of the online phase

Here's the cleaned and normalized Markdown:

## Evolution of Professional Ethics Courses from Web Supported Learning towards E-Learning 2.0

## Course Organization and Challenges

The current trend toward a more participative and technologically supported learning model may create a divide between modern and traditional courses. Finding balance among different competing courses is crucial to enable student participation across the curriculum. This requires:

- Changing university organization to group exams by year
- Applying instructional design at the curriculum level
- Harmonizing activities across different courses

The AR2 course presented a different experience, with no interference with other courses. The maturity of students allowed them to better plan their curriculum and distribute effort effectively.

## References

1. Surowiecki, J.: The Wisdom of Crowds. Why the Many Are Smarter Than the Few. Abacus (2005)
2. Trentin, G.: La sostenibilità didattico-formatica dell'e-learning. Social networking e apprendimento attivo. Franco Angeli (2008)
3. Dick, W., Carey, L., Carey, J.O.: The Systematic Design of Instruction, 6th edn. Merrill (2004)
4. Leshin, C.B., Pollock, J., Reigeluth, C.M.: Instructional Design Strategies and Tactics. Education Technology Publications, Englewood Cliffs (1992)
5. Ribaudo, M., Rui, M.: AulaWeb, web-based learning as a commodity. The experience of the University of Genova. In: 1st Int. Conf. on Computer Supported Education, Lisbon, Portugal (2009)
6. Oakley, B., Felder, R.M., Brent, R., Elhajj, I.: Turning Student Groups into Effective Teams. Journal of Student Centered Learning 2 (2004)
7. Astesiano, E., Cerioli, M., Reggio, G., Ricca, F.: A phased highly-interactive approach to teaching uml-based software development. In: Staron, M. (ed.) Proc. of Educators' Symposium at MoDELS 2007. Research Reports in Software Engineering and Management, IT University of Göteborg, pp. 9-18 (2007)

## Introduction

Skopje and Novi Sad share several joint Professional Ethics courses at undergraduate and postgraduate levels, delivered to almost 1000 students from 14 different target groups. Over seven years, teaching, learning and assessment have evolved from traditional Web-supported learning through blended learning towards Web 2.0.

Early research by Markus concluded that despite integration of multimedia and early email etiquette, negative social impacts of new technology were difficult to eliminate. Morahan-Martin and Schumacher's 2003 survey claimed Internet use caused loneliness. Since Jay Cros coined "e-learning" in 1997 for Internet-enabled learning, traditional face-to-face education's role diminished as students moved to online classes, sometimes becoming more alienated.

Here's the cleaned and normalized Markdown:

## Evolution of Professional Ethics Courses

## Introduction

First attempt to "socialize" Internet users was the site Classmates.com [4]. Launched too early, it couldn't get high attention, but soon later, social networking sites made a revolution between Internet users. It was high time to switch from Web 1.0 to Web 2.0. Recent research made by Nielsen Online [5] reports that top 10 social networking sites had almost 76 million unique visitors in September 2008. Compared with 33 million visitors in September 2007, the average growth is 167%.

In Web 1.0 a few content authors provided content for a wide audience of relatively passive readers. Web 2.0 is already transforming our social lives and is quickly becoming a competitive tool for education [6]. Very important conclusions connected to usage of social networks in education are given by De Weaver [7]. A survey conducted on a large group of students and instructors, revealed that newer forms of activities, like collaborating and sharing information to a community, are less popular though. Social software has the potential not only to enhance particular aspects of teaching and learning, but also to significantly contribute to the creation of new forms of these activities. Bryant [8] summarises potential developments in this area as: 'The adoption of social software tools, techniques and ideas will be the most important and visible example of the use of emerging technology in education over the next few years'. Another example of related work is reported by Franceschi [9], where a suggestion for improvement of social networks within e-learning systems has been given. The last, but not the least research is done within Comtella project [10, 11, and 12]. It is an impressive example of the implementation of Web 2.0 in blended classes, based on self-developed peer-to-peer file and bookmark sharing system aimed to share papers in several courses, including a professional ethics course.

## Related Work

The emergence of Web 2.0 technologies promotes the growth of service-based applications and greater user-control over content and connection [13]. Recent developments in web-based services and the enhancement of collaborative tools have fuelled the demand for similarly-specified educational software and services. A lot of universities across the world now deploy blogs, ePortfolios and educational social software for use by the academic community. In spite of the widespread support of these learning tools, still there is no adequate number of reports and analyses to appropriately validate the level of their utilization by tutors and students. But there are some publications bringing more or less optimistic results. The main analysis in [14] was based on observing student access and use of educational tools as well as on the anonymous recording of student experiences of using other social software in a non-educational context. More complex view of educational activities is given in [15]. They concluded that usage of social tools allow students to share capabilities and knowledge, bringing the synergetic effect to learning and life as well. Recent paper by Bernsteiner [16] presents the results of an empirical survey in order to highlight the benefits of the Web-based social software tools from the student's point of view. As motivation is on different levels, the lecturers have to increase it during lessons. Fortunately there are students, who were highly motivated and were creating the content and adding them to the wikis [17].

## Setting Up the Scene

In last decade, many LMS have been developed to support new education trends. Probably one of the most popular, particularly for educators, is Moodle with more than 28 million users, supporting the delivery of more than 2.5 million courses [18]. Starting from academic 2005/06, both institutions presented in this paper switched from static LMS to Moodle (Skopje), or from static usage of Moodle to social networks (Novi Sad), showing that static LMS at both institutions become obsolete. Encouraged by the appreciation of more than 3500 active participants at both institutions, we can claim that the success of social network strategy in e-education utilized in our institutions is evident. One additional note

## Evolution of Professional Ethics Courses

## Stage Two: Blended Learning

Beginning of the course for first generation of postgraduate students in Novi Sad and in Skopje started in 2006, when Moodle was implemented, initially aiming to augment face-to-face lectures. Initially, Moodle was mostly used as a repository of teaching materials, either as a fixed collection of files, or as an active set of animated e-lessons. Still, the repository was in its essence static. Communication was aimed towards teachers and teachers only. While lecture attendance was part of the obligatory requirements for the new generations of students, e-communication was still an idea worth introducing, as an attempt in perfection of the course.

In order to avoid exhausting oral examinations, an e-test with 250 questions was designed in Skopje. Initially weak results soon became impeccable. After a small investigation, it appeared that students who had already finished the e-test copied the questions and their correct answers, and distributed them to those who will have the exam later. This student fake showed that it was high time to change the delivery of the course, to enhance student active participation, and to change the grading scheme. In Novi Sad, similar repository of around 200 questions exists, but it is not used for e-testing, but within "regular" classroom tests instead. Since this assumes presence of the assistant, elements of cheating, while existing, were not that flagrant.

## Stage Three: Active Contribution of All the Participants

The experience gathered during the usage of Moodle from some other joined courses [22] showed that the inclusion of other elements available within LMS, like forums, chats, or e-mail usage, could create a more dynamic system, system known in contemporary research as a social network. This academic year, almost all the students participated in social network rather freely. Even those who are recognized as shy and silent persons during lectures, find themselves very involved in discussions, arguments, and even quarrels with other colleagues, when it comes to questions important to them. Yet, this does not come as a surprise, since the tendency of introvert students to reveal their opinions within electronic communication, when not faced literally with the rest of colleagues.

Another point worth mentioning is the fact that created social networks influenced widening of topics in question. Even though at the beginning points to be discussed were strictly defined, very often discussions diverged to various directions, touching each matter connected to the original one that is interesting for students. As a natural improvement, forums were used to apply well-known technique of role-playing games. Students were given certain roles and were invited to participate in a scenario connected with some ethical and moral issues, discussing and defending opinions represented by their roles. During a fortnight, student teams actively defended their roles, with an average of 9.73 posts per student. Teachers were also involved in the discussions to direct them. At the end, using a supporting forum, student prepared team reports of their groups. This forum had 10.07 posts per student, showing the usefulness of on-line discussions. It took some time for students to start communicating and sharing opinions, but each year, it eventually came to this point. Probably because of shared experience with previous generations, time between those phases has been shortened.

## Conclusion and Intended Evolution of the Courses

Obvious benefit of the steady evolution of our joint courses towards social software was the active involvement of all the students, including those who are usually idle. With new "socialised" approach, students were motivated, stimulated and sometimes provoked to reveal their own ideas. To support their assertions, they dug into different sources to discover other sources in favour of their opinion. Such research stimulated their intellectual capacities, and prepared them for future research. In many occasions, research was not directed to computers ethics only, but also to related areas.

Further great benefit of Web 2.0 in our course was the possibility of relaxed, and at the same time, efficient group collaboration. Using forums, students virtually met their colleagues, followed the development of the group project, and presented their findings. Research and group essay preparation progress was clearly evident at every moment, individual contribution was obvious

## References

1. Markus, M.L.: Finding a happy medium: explaining the negative effects of electronic communication on social life at work. ACM Transactions on Information Systems (TOIS) 12(2), 119–149 (1994)

2. Morahan-Martin, J., Schumacher, P.: Loneliness and social uses of the Internet. Computers in Human Behaviour 19(6), 659–671 (2003)

3. Cross, J.: An informal history of eLearning. On the Horizon (12/3), 103–110 (2004)

4. Boyd, D.M., Ellison, N.B.: Social Network Sites: Definition, History, and Scholarship, http://jcmc.indiana.edu/vol13/issue1/boyd.ellison.html

5. Nielsen online blog "Connecting the dots", http://blog.nielsen.com/nielsenwire/wp-content/uploads/2008/10/press_release24.pdf

6. Franklin, T., Van Harmelen, M.: Web 2.0 for Content for Learning and Teaching in Higher Education, http://www.jisc.ac.uk/publications/publications/web2andpolicyreport.aspx

7. De Wever, B., Mechant, P., Veevaete, P., Hauttekeete, L.: E-Learning 2.0: social software for educational use. In: Proc. of 9th IEEE International Symp. on Multimedia, pp. 511–516 (2007)

8. Bryant, L.: Emerging trends in social software for education. British Educational Communications and Technology Agency Emerging Technologies for Learning (2007)

9. Franceschi, K., Lee, R., Hinds, D.: Engaging E-Learning in Virtual Worlds: Supporting Group Collaboration. In: Proc. of 41st Hawaii International Conf. on System Sciences (2008)

10. Vassileva, J.: Harnessing P2P Power in the Classroom. In: Lester, J.C., Vicari, R.M., Paraguaçu, F. (eds.) ITS 2004. LNCS, vol. 3220, pp. 305–314. Springer, Heidelberg (2004)

11. Webster, A.S., Vassileva, J.: Visualizing Personal Relations in Online Communities. In: Wade, V.P., Ashman, H., Smyth, B. (eds.) AH 2006. LNCS, vol. 4018, pp. 223–233. Springer, Heidelberg (2006)

12. Vassileva, J., Sun, L.: Using Community Visualization to Stimulate Participation in Online Communities. e-Service Journal 6(1), 3–40 (2007)

13. O'Reilly, T.: What Is Web 2.0: Design Patterns and Business Models for the Next Generation of Software (2005)

14. Stepanyan, K., Mather, R., Payne, J.: Awareness of the capabilities and use of social software attributes within and outside the educational context: moving towards collaborative learning with Web 2.0. In: Proceedings of Conference ICL 2007, pp. 1–9 (2007)

15. Itamar, S., Bregman, D., Israel, D., Korman, A.: Do eLearning Technologies Improve the Higher Education Teaching and Learning Experience? In: Fifth International Conference on eLearning for Knowledge-Based Society, pp. 24.1–24.7 (2008)

16. Bernsteiner, R., Ostermann, H., Staudinger, R.: Facilitating E-Learning with Social Software: Attitudes and Usage from the Student's Point of View. Int. J. of Web

## Towards an Ontology for Supporting Communities of Practice of E-Learning "CoPEs": A Conceptual Model

Lamia Berkani¹ and Azeddine Chikh²

¹National Institute of Computer Science, INI, Algiers, Algeria  
²Information Systems Dept., King Saud University, Riyadh, Saudi Arabia

## Abstract

The Community of Practice of E-learning (CoPE) represents a virtual space for exchanging, sharing, and resolving problems faced by actors in e-learning. One of the major concerns of CoPEs is to favor practices of reuse and exchange through the capitalization of techno-pedagogical knowledge and know-how. In this paper, we present a conceptual model of CoPEs. This model constitutes the theoretical platform upon which an ontology dedicated to CoPEs will be built. This ontology aims to annotate the CoPE's knowledge resources and services, so as to enhance individual and organizational learning within CoPEs.

**Keywords**: E-learning, CoP of e-learning, O'CoPE, ontology concepts

## 1. Introduction

Today, we are witnessing a fast and significant expansion of the e-learning domain. Companies, schools, universities, and organizations of all sizes are currently using e-learning as a tool of training, learning and professional development. The increase in interest of e-learning is seen through the development of large projects launched everywhere in the world and through the proliferation of specifications and standards for e-learning systems too. However, despite the large quantity of knowledge accumulated in this field, the know-how and the feedback from acquired experience are not always capitalized and exchanged in a systematic way between its actors.

Furthermore, this field is facing a number of challenges related to:

1. The difference of interpretation of its concepts. For example, software tools (e.g. simulation or translation tools) used in an online course are considered sometimes either as resources or services
2. The complexity resulting from the multiplicity of its standards (LOM, SCORM, IMS-LD, IMS-LIP, ...), and the heterogeneity of its tools such as authoring tools and LMS (Learning Management systems) like Moodle¹, Acolad² or Blackboard³
3. The diversity of its teaching domains from arts, literature, fundamental and applied sciences to engineering requiring different educational approaches and techniques

Accordingly, actors involved in e-learning must exchange efficiently both of their problems and experiences. Based on work done on Communities of Practice (CoPs) and the success they made in collaborative learning [1], especially in the domain of teaching [2; 3; 4; 5], we have thought to extend this technology to e-learning as sub-domain of teaching. So, we consider CoPEs (Communities of Practice of E-learning) as a virtual framework for exchanging and sharing techno-pedagogic knowledge and know-how between actors of e-learning.

In [6; 7] we have defined a CoPE and the underlying concepts. In the present paper, we try to refine and enrich the previous definitions through a conceptual model. This model constitutes the theoretical grounding upon which an ontology dedicated to CoPEs will be built. This last will offer a uniform vocabulary to explicitly specify all the CoPE's concepts, and with which the CoPE's resources and services can be annotated, so as to support the learning processes in the CoPE.

## 2. Background and Related Work

A CoPE is a group of professionals in e-learning who gather, collaborate, and organize themselves in order to:

- Share information and experiences related to e-learning development and use
- Collaborate to solve together e-learning problems (e.g. interoperability, adaptativity) and to build techno-pedagogic knowledge and best practices
- Learn from each other and develop their skills in instructional engineering
- Promote the use of e-learning standards: IMS-LD, SCORM, LOM...

We address in this paper the need to model the CoPE's

## Towards an Ontology for Supporting CoPEs

## Previous Work
Palette project proposed several models for describing Communities of Practice (CoPs), including: community, actor, learner profile, competency, collaboration, process/activity, and lessons learnt. These models are built based on analysis of twelve existing CoPs.

## Contribution: A Conceptual Model for CoPEs

The most important concepts of the CoPE include: "Community", "Actor" with "Role" and "Profile", "Activity", "Competency", "Knowledge", and "Environment".

### Community
CoPEs have three fundamental features:
- Mutual engagement: indicates how the CoPE functions and binds members together
- Joint enterprise: indicates what the CoPE is about, as continuously negotiated by members
- Shared repository: represents the CoPE memory including resources (Knowledge, learner profiles, outcomes)

Community builds relationships enabling collective learning, while Practice anchors learning in what people do.

### Actor and Role
Actors in CoPEs work primarily in e-learning, with varying skill levels. They can be:
1. Members
2. Contributors (participating in specific activities/periods)
3. Partners (supporting entities)

Actors can organize into groups based on objectives. Two main roles exist:
- Support member: contributes to CoPE function (coordinator, animator, reporter, manager, administrator)
- Learner member: contributes to current CoPE activities

Each role is described using IMS Learning Design specification data and CoPE-specific concepts including: Category, Rights, Profile, and Participation.

### Activity
Activities are classified into four categories:
- Analysis activities
- Design activities  
- Implementation activities
- Utilization activities

Activities are described using IMS-LD data and CoPE-specific elements: Approach, Metadata, Classification, Execution, Result.

### Environment
The environment consists of:
- Resources (classified by activity type)
- Services (three categories):
  1. Knowledge Management Services
  2. Mediation Services  
  3. Information Services

Services are described using an enriched Group-service structure with elements like:
- Service category
- Service mission
- Service profile

### Knowledge
CoPEs capitalize on techno-pedagogical knowledge, classified as:
- Tacit Knowledge (TK)
- Explicit Knowledge (EK)

Knowledge is categorized based on SECI framework modes:
1. Experiential knowledge assets (hands-on experiences/skills)
2. Conceptual knowledge assets (articulated EK)
3. Systemic knowledge assets (systematized/packaged EK) 
4. Routine knowledge assets (embedded EK in practices)

## Using Collaborative Techniques in Virtual Learning Communities

## Introduction

Computer Supported Collaborative Learning (CSCL) is the research area that focuses on debate-based learning and peer negotiation in online learning environments (The Cognition and Technology Group at Vanderbilt, 1991; Scardamalia & Bereiter, 1994; Dillenbourg, 1999; Kanuka & Anderson, 1999). In these contexts it is quite common to adopt "techniques" or "scripts" with the aim of providing a structure to activities, so as to foster collaboration and exchange (Kanuka & Anderson, 1999; Dillenbourg 2002; Hernández-Leo et al., 2005; Persico & Sarti, 2005; Jaques & Salmon, 2007; Fischer et al., 2009). Techniques and scripts are usually content-independent and serve as scaffolds to activities (which on the other hand are content-dependent).

Examples are: Discussion, Peer Review, Role Play, Jigsaw, Case Study, etc. In this paper a study is described, which illustrates the application of a Jigsaw[^1], a Role

## References

1. Langelier, L., Wenger, E.: Work, Learning and Networked, Québec, CEFRIO (2005)
2. Center for Teaching Excellence (CTE), http://www.sc.edu/cte/cop/
3. Learning Network for Teachers (Learn-Nett), http://ute2.umh.ac.be/learn-nett/
4. ePrep, http://www.eprep.org/
5. Did@cTIC, http://www.unifr.ch/didactic/
6. Chikh, A., Berkani, L., Sarirete, A.: Modeling the Communities of Practice of E-learning – CoPEs. In: 4th Annual Conference of Learning International Networks Consortium, LINC 2007 (2007)
7. Chikh, A., Berkani, L., Sarirete, A.: Communities of Practice of E-learning "CoPE" – Definition and Concepts. In: IEEE International Workshop on Advanced Information Systems for Enterprises, IWAISE 2008, pp. 31–37 (2008)
8. Rosson, M.B., Dunlap, D.R., Isenhour, P.L., Carrol1, J.M.: Teacher Bridge: Creating a Community of Teacher Developers. In: 40th Annual Hawaii International Conference on System Sciences, HICSS 2007 (2007)
9. Dubé, L., Bourhis, A., Jacob, R.: Towards a typology of virtual communities of practice, Cahiers du GReSI 03-13 (2003)
10. PALETTE: Pedagogically sustained Adaptive Learning through the Exploitation of Tacit and Explicit Knowledge, http://palette.ercim.org/

[^1]: During the Jigsaw (Aronson et al., 1978) the content to be addressed is segmented into sub-items and each learner is assigned the task to study in detail his/her sub-item. To do so, all the students who should become "experts" of a specific sub-item, join together in the so called "expert group", with the aim of discussing the main points of their segment and rehearsing a presentation. At the end of this phase, expert groups are loosened and new groups are formed, called "jigsaw groups". Within his/her new jigsaw group, each learner is asked to report his/her segment to the others, so that at the end all the groups gain a complete overview of the content.

Here's the cleaned Markdown:

## Using Collaborative Techniques in Virtual Learning Communities

## Research Context and Methods

The present study is rooted in the context of two twin courses run in 2007 respectively in Liguria and Veneto on the issue "Educational Technology" (hereafter called "TD-SSIS Liguria" and "TD-SSIS Veneto"). The courses were devoted to student teachers and the main aim was that of making students familiarize with the most important issues related to the introduction of ICT in schools. The communities of both the courses consisted of post-graduate adults who were diversified as for backgrounds, interests and expectations from the course; the majority of them was at its first experience of online collaborative learning. In the present study we concentrate on one class of TD-SSIS Liguria, composed of 21 students, and one class of TD-SSIS Veneto, consisting of 24 students; the two classes were tutored by the same tutor. The courses shared the same contents and structure, and thus they both envisaged three subsequent online collaborative activities (lasting 3 weeks each). The first activity was based on a Jigsaw; during the second activity students were proposed a Role Play; finally the last activity was based on a Discussion. The CMC system used for carrying out the online activities was in both cases Moodle (Persico et al., 2009).

In order to investigate the nature of the interactions occurred while performing the proposed online activities, an evaluation framework was used, which had been previously developed and extensively used to assess similar online experiences (Pozzi et al. 2007; Persico et al., 2009). The model considers four dimensions as those characterizing a learning process in CSCL contexts, namely the participative, the cognitive, the social and the teaching dimensions. In the model, each dimension is defined by a set of relevant indicators that can be used to evaluate it; in particular:

- The participative dimension is defined by indicators of: Active Participation (P1), Reactive Participation (P2) and Continuity (P3)
- The social dimension is defined by indicators of: Affection (S1) and Cohesion (S2)
- The cognitive dimension is defined by indicators of: Individual Knowledge Building (C1), Group Knowledge Building (C2) and Meta-Reflection (C3)
- The teaching dimension is defined by indicators of: Organizational matters (T1), Facilitating Discourse (T2) and Direct Instruction (T3) (Persico et al., 2009)

As far as the methods and means that have allowed to gauge these indicators, an analysis of all the messages exchanged by the students during the activities (1164 messages) was carried out. In particular, the indicators concerning the participative dimension have been gathered directly from the data tracked by Moodle, whereas the analysis of the cognitive, the social and the teaching dimensions is based on a "manual" content analysis.

## Results

In the following data are synthesized concerning the participative, the social, the cognitive and the teaching dimensions, as they have been developed during the execution of the Jigsaw, the Role Play and the Discussion respectively in TD-SSIS Liguria and in TD-SSIS Veneto.

As far as the participative dimension is concerned, Table 1 reports the data of active participation in the two courses. As one may note, in TD-SSIS Liguria during the Discussion the students sent the highest number of messages, while in the Jigsaw and the Role Play the number of sent messages is nearly the same. Besides, the mean messages per student is quite high in all the three activities. In TD-SSIS Veneto the number of messages is overall lower than in Liguria, but, despite this, here again the Discussion resulted to be the most participated technique, followed by the Jigsaw and then the Role Play.

Table 1. Active participation in TD-SSIS Liguria and TD-SSIS Veneto

| | TD-SSIS

## Using Collaborative Techniques in Virtual Learning Communities

## Analysis of Dimensions

As far as the cognitive dimension is concerned, C1 (individual knowledge building) is always lower than group knowledge building (C2), whereas C3 (meta-reflection) is almost absent in all three techniques. Values of C1 in the three techniques are quite close, and the same applies to values for C2 and C3. Finally, the three indicators of the teaching dimension (T1, T2 and T3) are more or less all at the same level with the only exceptions of T1 in the Discussion and T2 in the Role Play, which both reached higher levels.

[Figure 1: Social, cognitive and teaching dimensions in TD-SSIS Liguria]

[Figure 2: Social, cognitive and teaching dimensions in TD-SSIS Veneto]

As already mentioned, TD-SSIS Veneto registered an overall lower number of messages. Still, there is a common trend in all three activities. In particular, a bias is registered in the social dimension between affection (S1), which is quite low, and cohesion (S2), which is very high (with the only exception of the Role Play, whose S2, even if higher than S1, is sensibly lower than S2 of the other two techniques). In all three techniques C1 is lower than C2, with the Jigsaw developing the highest cognitive dimension, followed by the Discussion and then by the Role Play.

## Discussion and Conclusions

First of all, it should be noted that in both courses, despite some differences in the values assumed by the indicators, these seem to follow the same trend independently of the technique used. In particular:

- The group cohesion always shows high values, while affection tends to be much lower
- Individual knowledge building is on average quite low during this kind of activities
- Group knowledge construction is usually high (reasonable in a collaborative learning context)
- Meta-reflection indicators are quite scarce in all three proposed activities

It should also be noted that individual knowledge building and meta-reflection are latent variables and therefore, as De Wever et al. (2006) pointed out, their low levels might not necessarily mean that they did not take place but that they were simply not made explicit in the student messages. Besides, it seems that all activities have supported adequate levels of teaching dimension with no particular predisposition for one or the other aspect of it.

Together with such a general "common trend," each activity revealed a specific ability in supporting different dimensions:

- The Discussion resulted in more participation by both groups and mostly fostered the social dimension
- The Role Play obtained the lowest levels for C1, C2 and C3 while being quite good for the teaching dimension
- The Jigsaw obtained the highest level of group knowledge building in both courses

This leads us to think that while no activity is inherently better than others, the technique or script used may have a different impact on different dimensions. A low structure seems to foster more social dimension, whereas a higher degree of structuredness seems to have more positive effects on the cognitive dimension.

It is worthwhile noting that some data may have been affected by factors impossible to set aside in a real context: the order of activities, the topics themselves, and individual student differences may have partially affected the results. Further investigations would be interesting to ascertain whether there are significant changes in the distribution of indicators when these variables can be set aside.

## References

1. Aronson, E., Blaney, N., Stephin, C., Sikes, J., Snapp, M.: The jigsaw classroom. Sage Publishing Company, Beverly Hills (1978)

2. De Wever, B., Shellens, T., Valcke, M., Van Keer, H.: Content analysis schemes to analyze transcripts of online asynchronous discussion groups: A review. Computers and Education 46, 6–28 (2006)

3. Dillenbourg, P. (ed.): Collaborative Learning: Cognitive and Computational Approaches. Pergamon Press (1999)

4. Dillenbourg, P.: Over-scripting CSCL: The risks of blending collaborative learning with instructional design. In: Kirschner, P.A. (ed.) Three worlds of CSCL. Can we support CSCL, pp. 61–91. Open Universiteit Nederland, Heerlen (2002)

5. Fischer, F., Kollar, I., Mandl, H., Haak, J.M.: Scripting Computer-Supported Collaborative Learning. Springer, New York (2009)

6. Henri, F.: Computer conferencing and content analysis. In: Kaye, A.R. (ed.) Collaborative Learning Through Computer Conferencing, The Najaden Papers, New York, pp. 115–136. Springer, Heidelberg (1992)

7. Hernández-Leo, D., Asensio-Pérez, J.I., Dimitriadis, Y., Bote-Lorenzo, M.L., Jorrín-Abellán, I.M., Villasclaras-Fernández, E.D.: Reusing IMS-LD Formalized Best Practices in Collaborative Learning Structuring. Advanced Technology for Learning 2(3), 223–232 (2005)

8. Jaques, D., Salmon, G.: Learning in groups: A Handbook for Face-To-Face and Online Environments. Routledge, London (2007)

9. Kanuka, H., Anderson, T.: Using Constructivism in Technology-Mediated Learning: Constructing Order out of the Chaos in the Literature. Radical Pedagogy 1(2) (1999)

10. Persico, D., Pozzi, F.: Evaluation in CSCL: Tracking and analyzing the learning community. In: Szücs, A., Bø, I. (eds.) E-competences for Life, Employment and Innovation, Proceedings of the EDEN 2006 Annual Conference, Vienna, June 14-17, pp. 502–507 (2006)

11. Persico, D., Pozzi, F., Sarti, L.: A model for monitoring and evaluating CSCL. In: Juan, A.A., Daradoumis, T., Xhafa, F., Caballe, S., Faulin, J. (eds.) Monitoring and Assessment in Online Collaborative Environments: Emergent Computational Technologies for E-learning Support. IGI Global (2009)

12. Persico, D., Sarti, L.: Social Structures for Online Learning: a design perspective. In: Chiazzese, G., Allegra, M., Chifari, A., Ottaviano, S. (eds.) Methods and technologies for learning, Proceedings of the International Conference on Methods and Technologies for Learning. WIT Press, Southampton (2005)

13. Pozzi, F., Manca, S., Persico, D., Sarti, L.: A general framework for tracking and analyzing learning processes in CSCL environments. Innovations in Education and Teaching International 44(2), 169–180 (2007)

14. Renner

## Capturing Individual and Institutional Change

The purpose of this poster is to introduce a distinction between what we term horizontal and vertical transitions that can be used to capture individual and institutional change in technology-rich environments. This distinction is seen as a methodological tool in that it directs our attention to the analytical practice. We argue that research on both vertical and horizontal transitions has merits and makes valuable contributions to advance our understanding of how to analyze change in technology-rich environments; both have their own explanatory power. Nonetheless, research investigating these transitions differs completely in its focus; while studies on vertical transitions employ a specific focus on individuals within one single domain or on a single tool, studies on horizontal transitions employ a broader perspective in that they extend their focus beyond a single domain or technology. A major problem however is that, in past research, both transitions are mixed up easily. We argue that although vertical and horizontal transitions in technology-rich environments go hand in hand, and thus can be reconciled to same extent, they should not be intermingled blindly: From an analytical stance, we argue that studies investigating vertical or horizontal transitions follow very different strategies and aims.

To structure our argument on vertical and horizontal transitions, our discussion is organized in two sections. First, we discuss the concept of horizontal and vertical transitions in more detail. How does the individual and the institutional context change in technology-rich environments? How can this change be captured and analyzed? To illustrate an answer to these questions, we have chosen some significant studies in the domain of medical image diagnosis. Medicine is—among others—one example of a dynamic domain owing to its constant technological progress, and thus useful to show how learning and development occur under conditions of change. Second, we discuss implications of the proposed analytical distinction for future work in professional TEL, and how the analysis of horizontal and vertical transitions can add value for researching what it means to learn with and from technology.

## Horizontal versus Vertical Transitions in Technology-Rich Environments

In order to provide a detailed account for what we term horizontal and vertical transitions, we will focus on two levels: the individual and the institutional context in which the individual is embedded in. From an analytical perspective, the individual and the context are separated here for the sake of discussion. Our argument is put forward in the next two paragraphs by discussing individual and institutional change.

### Individual Change

Individual change in technology-rich environments is highly associated with technology. The interaction with technological tools and artifacts in different activities at work can trigger individual trajectories and stimulate the development of expertise. We focus here on individual trajectories although we acknowledge that these can be also related to a collective or an organizational level. Here, the individual development on a continuum of expertise can be traced as a vertical and a horizontal transition. Each is described in turn.

Traditionally, learning and the development of expertise in high-tech domains has been studied vertically by focusing on the development from novice to expert. The focus is on individual skill acquisition along a continuum of competence development. A typical assumption from studies investigating vertical transitions of an individual is that the institutional context, where the individual is working or learning in, is stable. We argue that such a perspective is useful for analyzing individual differences in routine tasks or in situations where rules are set. Examples for studies investigating individual vertical transitions can be found in classical expertise research, in domains that have reached a sufficient state of maturity. For example, in medicine, the reading of X-ray pictures with its roots back in the 19th century has been one of the most extensively studied tasks [4,5]. X-ray images remained rather constant over decades, and they even today afford the analysis of anatomical features based on grey-scale pictorial representations. Studies have mainly focused on individual differences in decision making, perceptual processes, and the representation of knowledge by comparing novices, intermediates, and experts. These comparisons are typically made in relation to a previously established "best practice", thus treating the context as something relatively stable. Questions that are usually addressed in studies tracing vertical transitions relate to what are the characteristics of expertise on different skill levels? How can the development from novice to expert in a routine task be explained?

Studies tracing horizontal transitions of the individual pose different questions, based on a different underlying assumption. Unlike to studies in stable environments, the interest here

## Capturing Individual and Institutional Change

## Individual Change

Note that this shift requires a certain amount of willingness and motivation to be done. How do employees in technology-rich environments regulate their motivation? And which goals and motivational profiles support or impede transitory steps? Future research can address these questions along with the mutual complementarities of vertical and horizontal transitions that constitute individual change.

## Institutional Change

Institutional change in technology-rich environments is highly associated with technology. Although the institutional context can be traced on many more levels than just on the level of technology, we argue that changes in work practices, policies, communities, division of labor, or the domain as a whole are mainly following from technological changes. We illustrate this argument with two examples from medicine as a technology-rich environment: (1) the case of MRI as a vertical transition and (2) changing technologies in nuclear medicine and radiology as horizontal transitions.

First, vertical transitions can be captured by focusing on one specific tool that is used in a particular domain. Questions that are usually addressed in studies tracing vertical transitions relate to how a technique has developed since its introduction, and how respectively what kind of institutional routines have emerged as a response to the development of the technical tool. In medicine, [6] analyzes the vertical transitions magnetic resonance imaging (MRI) has gone through since its development in the 1970s. First, its name changed from zeugmatography and nuclear magnetic resonance (NMR) imaging to the today established name of MRI. Second, MRI data representation changed from a numerical data output to a pictorial data output. In radiology departments, where MRI apparatuses have been installed, this has caused changes in work practices and also challenged the professional identity of radiologists. The implementation of MRI forced radiologists to adapt their work practices and to reconstitute their professional identities: New interpretation skills were required to make meaning of those new representations, and to handle the scanners appropriately. Since MRI makes no use of radiation, it was unclear if these apparatuses should be installed in radiology departments. Other departments raised a claim for the new techniques and with it a claim for the visual authority to analyze these digital pictures [7]. This example in radiology exemplifies how the transformation of imaging tools implies changes in current work practices which in turn demands professionals to renegotiate and re-organize their expertise, both in terms of individual knowledge and of their identity as a well-established discipline. In sum, the analysis of the vertical transition of one technology has the potential to uncover also the trajectories of institutional routines and how they develop over time.

The second avenue to capture institutional change is to analyze horizontal transitions. This can be done by focusing on how a technological tool develops through connections to neighboring domains or by focusing on how a domain as a scientific discipline matures over time. Questions that can be addressed in studies tracing horizontal transitions relate to how a domain becomes more interdisciplinary through the introduction of a technology. How do technologies afford synergies and boundary-crossings to other domains? In medicine, horizontal transitions occur frequently through the evolution of imaging technologies. For example, as described above, nuclear medicine has faced the evolution of its technical domain standard from positron emission tomography (PET) to a joint PET/CT image. This is seen as a horizontal transition since it involves a side step to a neighboring domain: PET/CT converges radiologic and nuclear medicine routines to produce and interpret medical images; it cuts across any neat boundaries between these two medical sub-specialties; and it creates a new stream from novice to expert in handling a new technical tool, associated with its emerging work practices and policies. Besides PET, another example is the shift from traditional X-ray technique to tomosynthesis, a new technology in which the images represent the anatomy of the lungs; the image is projected three-dimensionally. Since tomosynthesis represents an improvement in the technology for diagnosing cancer in comparison to ordinary X-ray, and since the costs and radiation dose are lower than in the case of computer tomography (CT), the benefits for healthcare and patients promise to be considerable. To make full use of this technological advancement, however, it is important to further our understanding of how professionals develop expertise in

## Capturing Individual and Institutional Change

The vertical-horizontal distinction advances our understanding of the multidirectional dialectics between the individual, technology, and the broader institutional context in which both are enacted [1,2,7].

Future research implications relate to two key aspects:

## Learning Spaces
The 'where' - the learning spaces in which vertical and horizontal transitions occur. Multidirectional learning processes frequently happen outside school settings. [8] noted that the TEL community has focused perhaps too heavily on technology-enhanced education in formal institutions, indicating a need for more knowledge about informal learning contexts. The workplace becomes a central environment for analyzing the multi-directionality of individual and institutional development with technology, without disregarding formal contexts.

## Challenge of Capturing Change 
Both implications point to the challenge of capturing individual and institutional change due to the multi-directionality of mechanisms and functions of individual, social, and contextual development associated with technological tools in professional work contexts.

## A Platform Based on Semantic Web and Web2.0 as Organizational Learning Support

## Introduction
Globalization and information and communication technologies (ICT) have transformed how we learn and work. An organization's knowledge and competences capital is increasingly crucial. Organizational survival depends on the capacity to:

- Access new knowledge
- Diffuse competences quickly  
- Efficiently exploit and preserve expertise durably

Many lessons and experience feedbacks are often acquired then lost. Organizations must become learning organizations - where work is embedded in organizational culture that encourages training at various levels (individual, group and organization) and knowledge/competence transfers between these levels.

Web2.0 technologies can support such organizational learning by offering new forms of sharing, exchange and learning.

[References section preserved as-is]

Here's the cleaned Markdown:

## A Platform Based on Semantic Web and Web2.0

Within the approach MEMORAe we are interested in these new learning forms. We consider that they are connected to the knowledge management practices and we developed a learning environment based on the concept of learning organizational memory. This environment is a web platform using semantic annotations and Web2.0 technologies.

In this article, we focus on the modeling and the integration of competences in the MEMORAe2.0 project. Thus we present the link between organizational learning and competences. Then we present the approach MEMORAe and our organizational learning memory. Finally we show the E-MEMORAe2.0 web platform which we have developed.

## Organizational Learning and Competences

In the current economic environment, to learn became the best means, for a company, to be competitive in preserving knowledge and experiments of each collaborator and each team. To become learning, on the one hand, companies must be able to capitalize and transfer the individual/collective experiments and competences created in their core. On the other hand, they must enable their members to develop their individual competences.

According to the Commission of the European Communities[^1] competence is a combination of knowledge (explicit and implicit), abilities and skills influenced by needs, motives, personal goals, values, standards and attitudes. It is marked by effective use of resources, repeated application and accomplishment of tasks within defined conditions.

Schmiedinger [1] extends the competence definition to organizations and includes therefore existing tools and materials to a new definition called 'organizational competencies': Organizational competence is the combination of human competence and physical resources respectively actions successfully carried out by individuals using operating resources and work equipment or materials, to contribute to the organizational performance.

These definitions show the necessity to define competences and manage resources linked to competences in order to facilitate organizational learning.

## Approach MEMORAe

Organizational learning represents the organization capacity to increase the efficiency of its collective action. To favor this capacity organizations need to:

- Manage their knowledge, competences and resources (facilitate their creation, share and capitalization)
- Favor group work: define group (members and their functions in the group) and the group aims (project, problem, idea, ...), collaboration (group repository), communication(forum, chat,...) and coordination(shared agenda) between groups members.

In the framework of the approach MEMORAe, we propose to answer to these needs in associating:

- Knowledge engineering and educational engineering
- Semantic Web and Web2.0 technologies

to model and build a learning collaborative web platform as organizational learning support [2]. We chose to adapt the concept of Organizational Memory. Dieng define such a concept as an 'explicit, disembodied, persistent representation of knowledge and information in an organization, in order to facilitate its access and reuse by members of the organization, for their tasks' [3]. Extending this definition, we propose the concept of Learning Organizational Memory for which users' task is learning.

## Learning Organizational Memory Modeling

An organizational memory is composed of knowledge, competences and resources linked to these knowledge and competences. Our learning organizational memory modeling is structured by means of ontologies which define knowledge and competences within the organization. We used these ontologies to semantically index capitalized resources. We distinguished two types of ontology: the domain ontology and the application ontology. Each ontologies are composed by two sub-ontologies which represent competences and knowledge. Knowledge ontologies are describe in [4], in this paper we present competences ontologies.

### Competence Domain Ontology

The domain ontology represents specific conceptualizations of a domain. In the framework of our projects: the domain is learning organization.

Competence domain sub-ontology allows to model organizational learning competences. Stader and Macintosh proposed an ontology of organizational competences [5]. We adapt this ontology within our context. The figure 1 show a part of our domain sub-ontology centered on organizational learning competences.

### Competence Application Ontology

The application ontology represents knowledge [

## A Platform Based on Semantic Web and Web2.0

## E-MEMORAe2.0 Web Platform

In order to put into practice our modeling we developed the environment E-MEMORAe2.0 (see figure 3).

The user interface proposes:
- An access to different repositories (individual, group and organization), specifying the repository visualized and allowing to access to authorized repositories
- Entry points enabling to start the navigation with a given concept
- A short definition of the current notion
- A part of the ontology centered on the current notion
- A list of resources which contents are related to the current concept
- History of navigation

Thus, by means of this interface, users navigate through the ontologies and can explore the memory content. Vertical navigation (see figure 3) allows to explore subsumption relations and to reach related concepts. Horizontal navigation allows to explore proximity relations (other than subsumption) [2].

E-MEMORAe2.0 gives the possibility of learners to have a private space and participate to share spaces according to their rights. All these spaces (repositories) share the same ontologies but store different resources and different entry points. They can be visualized at the same time. Thus figure 3 illustrates the visualization of three spaces: one dedicated to organization members, one dedicated to gp3 members and one to the connected individual. Let us note that by default, user visualizes two repositories: one concerning his private memory and one concerning his organization memory. However he can choose spaces he wants to visualize by selecting them in the memories choice window (in the left top). These choices are registered and will be considered for the next session.

Group can work on a problem. User can use entry point to reach the problem concept (see figure 3). From this concept user can use vertical navigation to see problem type. Then he can use horizontal navigation to reach competences required to solve it. In the same way, users can reach knowledge puts into practice by competences.

In such a platform, resource transfers can be done following two mainly ways:
- Users can visualize different spaces/memories content at the same time. Thus, they can make a drag and drop to transfer a resource or an entry point from a specific repository to another one.
- We developed a semantic forum. All the forum contributions are distributed in the resource space among the other resources (see figure 3). Users don't access to the forum itself but to the repository resource space and then select resources of Forum type to participate to the forum about the selected concept (knowledge or competence) which thus represent the topic [2]. Consequently, users can exchange ideas about specific topics. We plan to develop semantic chats and semantic agendas in the same way.

## Conclusion

In this paper we presented links we made between knowledge management, e-learning, semantic web, and Web2.0 technologies to build a collaborative environment in the framework of the approach MEMORAe. We focus to the modeling and to the integration of competences in the MEMORAe2.0 project.

We present the web platform developed E-MEMORAe2.0. It is a memory where it is possible to organize any resources or micro-resources (produced in the forum framework) in different work spaces (individual, group, organization) around shared ontologies (describing knowledge and competences). Thus users can easily transfer resources from one space to another one. All the micro-resources are capitalized and accessed like any resources in the memory (course, web site, exercise, etc.).

With our approach we take into account at the same time formal (access, capitalization and sharing of explicit knowledge) and informal (tacit knowledge externalisation and capitalization) training. Our learning organizational memory allows to structure knowledge and competences of learning organization. It facilitates exchanges and interactions between learners. All these interactions are automatically capitalized and semantically indexed.

E-MEMORAe2.0 evaluations gave us good results [6]. Learners used their different memories and forums. Currently our environment is used by academics. We have contact with industrials in order to evaluate such an environment to foster learning and innovation

Here's the cleaned and normalized Markdown:

## Erroneous Examples: A Preliminary Investigation into Learning Benefits

Dimitra Tsovaltzi¹, Erica Melis¹, Bruce M. McLaren¹, Michael Dietrich², Georgi Goguadze², and Ann-Kristin Meyer²

¹ German Research Center for Artificial Intelligence  
Stuhlsatzenhausweg 3, D-66123 Saarbrücken, Germany  
dimitra.tsovaltzi@dfki.de  
www.activemath.org

² Universität des Saarlandes  
Fachbereich Informatik, D-66123 Saarbrücken, Germany

## Abstract

In this work, we investigate the effect of presenting students with common errors of other students and explore whether such erroneous examples can help students learn without the embarrassment and demotivation of working with one's own errors. The erroneous examples are presented to students by a technology enhanced learning (TEL) system. We discuss the theoretical background of learning with erroneous examples, describe our TEL setting, and discuss initial, small-scale studies we conducted to explore learning with erroneous examples.

## Theoretical and Empirical Background

Correctly worked examples have traditionally been used to help students learn mathematics and science problem solving and have proven to be quite effective (1; 2). However, erroneous examples, that is, worked solutions including one or more errors that the student is asked to detect, explain, and/or correct, have rarely been investigated or used as a teaching strategy, particularly not in technology-enhanced learning systems. The question of if – and how – erroneous examples are beneficial to learning is still very much open.

Some theoretical and empirical research has explored the effects of erroneous examples in mathematics learning and provides some evidence that studying errors can support learning by providing new problem solving opportunities and motivating reflection and inquiry, e.g. (3; 4; 5). Moreover, the highly-publicised TIMSS studies (6) showed that math students in Asian countries – where curricula often include the careful analysis and discussion of incorrect solutions – outperform their counterparts in most of the western world. One study explored self-explaining correct and incorrect examples (7; 8). Siegler et al found that when students self-explained both correct and incorrect examples they learned more in comparison to self-explaining correct examples only. Grosse and Renkl also showed some learning benefit of erroneous examples but only for learners with strong prior knowledge and for far transfer learning (9).

We plan to take the earlier studies further by investigating erroneous examples used in the context of TEL. In contrast to other studies, we are interested in the correlations between students' benefit from erroneous examples and the situational and learner characteristics, with an eye toward eventually adapting erroneous examples instruction. To this end, we use the adaptive learning platform ActiveMath (10), a web-based learning environment for mathematics. In contrast to the Grosse and Renkl work, we are investigating erroneous examples with help. Our primary rationale for including help in the empirical studies is that students are not accustomed to working with and learning from erroneous examples and, hence, they need assistance and support in doing so.

We hypothesise that learning from the 'errors of others' can help students enhance their cognitive competencies as well as their meta-cognition and learning orientation. We propose two primary reasons for this. First, a student can best learn error detection and correction by reviewing and studying errors, something that is impossible to do with correct examples – and difficult to do with unsupported problem solving. Second, reviewing erroneous examples appears to be more supportive of a learning orientation rather than a performance orientation.

Furthermore, we hypothesise that students will benefit from erroneous examples when encountered at the right time and in the right way. Rewarding a student for error detection may lead to marking of errors in memory such that they will be avoided in subsequent retrieval. Moreover, a student is less likely

## Erroneous Examples: A Preliminary Investigation into Learning Benefits

## Example and Error Correction

An erroneous example is presented to students who must first identify errors and then correct them, with varying feedback between conditions. For instance, when a student incorrectly selects a correct step as wrong (Step 1), they receive feedback stating "Not really. Susanne's 3rd step is wrong". The system then asks students to explain the error by choosing from options:

- because Susanne must translate the integer 3 into a fraction
- because 3 has to be added to both the numerator and denominator of 2/3
- because the 3 has to be cancelled: 3̸ + 2/3̸
- I don't know

After selecting the correct explanation (first option), students are prompted to correct the error.

## Observations

A key observation was that 6th grade students often could not correct erroneous steps even when they could identify the correct explanation. This suggests that while students may know fraction operation rules and recognize explanations, they have knowledge gaps that emerge when asked to make corrections.

This phenomenon, described by Ohlsson as a dissociation between declarative and practical knowledge, occurred even with students who could solve exercises but couldn't correct similar erroneous examples. Students may follow well-practiced steps when solving problems, masking knowledge gaps that erroneous examples can reveal.

## Feedback Design

Three types of unsolicited feedback are provided:

1. Minimal feedback: Green/red coloring with correct/incorrect indication
2. Error-awareness and detection (EAD) feedback: Supports meta-cognitive skills
3. Help messages

In the error-finding phase, students receive EAD feedback followed by scaffolded multiple choice questions (MCQs) with 3-4 nested layers. The correction phase provides specific error correction feedback.

## Technical Implementation

The system features:
- Automated presentation of study materials
- Random ordering of intervention sequences
- Session persistence
- Online pre/post questionnaires
- Implementation within ActiveMath's tutorial strategy

## Pilot Study

A study with ten 8th-graders compared two conditions:
- No-Erroneous-Examples (NOEE): worked examples and exercises
- Erroneous-Examples-With-Help (EEWH): worked examples, exercises, and erroneous examples with help

Results showed:
- NOEE performance decreased (mean=-13.7, stdv=13.6)
- EEWH performance increased (mean=13.1, stdv=7.7)
- Similar performance on conceptual questions (60% vs 55%)
- Positive student feedback despite technical issues

## Outlook

Future studies will investigate:
- Relationship between finding/explaining errors versus correcting them
- Addressing the observed discrepancy where students can identify but not correct errors
- Testing whether error-finding competency combined with targeted feedback can reduce performance errors

## Towards a Theory of Socio-technical Interactions

## References

1. McLaren, B.M., Lim, S.J., Koedinger, K.R.: When and how often should worked examples be given to students? new results and a summary of the current state of research. In: Love, B.C., McRae, K., Sloutsky, V.M. (eds.) Proceedings of the 30th Annual Conference of the Cognitive Science Society, Austin, TX, pp. 2176-2181. Cognitive Science Society (2008)

2. Trafton, J., Reiser, B.: The contribution of studying examples and solving problems. In: Proceedings of the Fifteenth Annual Conference of the Cognitive Science Society (1993), http://www.citeseer.nj.nec.com/

3. Borasi, R.: Capitalizing on errors as "springboards for inquiry": A teaching experiment. Journal for Research in Mathematics Education 25(2), 166-208 (1994)

4. Müller, A.: Aus eignen und fremden Fehlern lernen. Praxis der Naturwissenschaften 52(1), 18-21 (2003)

5. Oser, F., Hascher, T.: Lernen aus Fehlern - Zur Psychologie des negativen Wissens. Schriftenreihe zum Projekt: Lernen Menschen aus Fehlern? Zur Entwicklung einer Fehlerkultur in der Schule, Pädagogisches Institut der Universität Freiburg, Schweiz (1997)

6. OECD: International report PISA plus (2001)

7. Siegler, R.: Microgenetic studies of self-explanation. In: Granott, N., Parziale, J. (eds.) Microdevelopment, Transition Processes in Development and Learning, pp. 31-58. Cambridge University Press, Cambridge (2002)

8. Siegler, R., Chen, Z.: Differentiation and integration: Guiding principles for analyzing cognitive change. Developmental Science 11, 433-448 (2008)

9. Grosse, C., Renkl, A.: Finding and fixing errors in worked examples: Can this foster learning outcomes? Learning and Instruction 17, 612-634 (2007)

10. Melis, E., Goguadse, G., Homik, M., Libbrecht, P., Ullrich, C., Winterstein, S.: Semantic-aware components and services in ActiveMath. British Journal of Educational Technology. Special Issue: Semantic Web for E-learning 37(3), 405-423 (2006)

11. Melis, E.: Design of erroneous examples for ActiveMath. In: Looi, C.-K., McCalla, G., Bredeweg, B., Breuker, J. (eds.) 12th International Conference on Artificial Intelligence in Education. Supporting Learning Through Intelligent and Socially Informed Technology (AIED 2005), vol. 125, pp. 451-458. IOS Press, Amsterdam (2005)

12. Ohlsson, S.: Learning from performance errors. Psychological Review 103(2), 241-262 (1996)

## Abstract

Technology enhanced learning environments are characterized by socio-technical interactions. Socio-technical interactions involve individuals interacting with (a) technologies, and (b) other individuals. These two critical aspects of socio-technical interactions in technology enhanced learning environments are theoretically conceived as (a) appropriation of socio-technical affordances and (b) structures and functions of technological intersubjectivity.

Briefly, socio-technical affordances are action-taking possibilities and meaning-making opportunities in an actor-environment system with reference to actor competencies and technical capabilities of the

## Towards a Theory of Socio-technical Interactions

## Theoretical Framework

### Affordances

The notion of affordance was introduced by J. J. Gibson [1]. Gibson was primarily concerned with providing an ecologically grounded explanation to visual perception. The ontological foundations of the notion of affordances are materialist and dynamicist [2]. Turvey [2, p. 180] citing Lombardo [3] identifies "the principle of reciprocity—distinguishable yet mutually supportive realities" as the central insight of Gibson's ecological psychology of visual perception. This principle of reciprocity is highly relevant to technology supported collaboration as multiple individuals each with a specific subjectivity and identity shape mutually supportive interactional realities. The ecological approach is dynamicist but not dialectical and processual, holding that "everything changes in some respects, but not in all respects" [2, p. 175]. Drawing upon foundational work in ecological psychology on the formal definition of affordances [2, 4], the following definition of socio-technical affordance is provided. Narrative expositions follow the definition.

#### Definition of Socio-technical Affordance

Let Wpqr (e.g., person-sending-email-to-another-person system) = (Tp, Sq, Or) be composed of different things T (e.g., concept-mapping technology); S (e.g., concept-map node creator) and O (e.g., concept-map node receiving partner). Let p be a property of technology T; q be a property of subject S and r be a property of other O. The relation between p, q and r, p/q/r, defines a higher order property (i.e., a property of the socio-technical system), a. Then a is said to be a socio-technical affordance of Wpqr if and only if:

(i) Wpqr = (Tp ,Sq, Or) possesses a
(ii) Neither T ,S, O, (T, S), (T,O), (S,O) possesses a

The formal definition of socio-technical affordance presented above is for the minimal situation of dyadic interaction in technology supported interactional environments. For a social situation involving n distinct social actors, an n-tuple would characterize the system. This formalism can be read as an activity system of subject, object and tools [5]. Relating the definition to Latour's actor-network theory [6], both actors and "actants" are implicated in the notion of socio-technical affordances. The formal definition of socio-technical affordance captures the two facets of interaction in socio-technical systems: (1) interacting with technology and (2) interacting with other persons (technological intersubjectivity to be discussed later). It is important to realize that affordances are action-taking possibilities and meaning-making opportunities in actual situations in an actor-environment system relative to actor competencies and technology capabilities. Norman's [7] gulf of execution and gulf of evaluation can be read as gulfs in the perception of action-taking possibilities and meaning-making opportunities respectively.

Socio-technical affordances are not things or widgets or features or functionalities. This category conflation has been the source of much confusion in the HCI design community [8]. Socio-technical affordances are the relational properties in particular situations of a specific user-technology system. By virtue of being relational properties with reference to an actor, socio-technical affordances can be termed relative to the actor and/or the technology, but relativity is not subjectivity. In that sense, affordances are not subjective properties. Affordances are neither arbitrary properties nor are they socially constructed [9]. Affordances are relational through and through, as they are the informational structure to be perceived in ambient arrays of the actor-environment system.

### Appropriation of Affordances

Cognition in the ecological psychology sense has been articulated as the "cooperative appropriation of affordances" [10, p. 135]. After Rogoff

## Towards a Theory of Socio-technical Interactions

## 2.3 Technological Intersubjectivity

Intersubjectivity is the key presupposition underlying human social interaction [17]. Human beings are not only functional communicators but also hermeneutic actors. Technological intersubjectivity is an emergent resulting from a technology supported self–other social relationship. In technological intersubjectivity, technology mediation can sometimes (but not necessarily always) disappear like in Clarke's [18] third law of technology.

### 2.3.1 Definition of Technological Intersubjectivity

Technological intersubjectivity (TI) refers to a technology supported interactional relationship between two or more participants. TI emerges from a dynamic interplay between the technological relationship of participants with artifacts and their social relationship with others.

Information and Communication Technologies (ICT) and the Internet have changed our social relations with others and objects in fundamental ways that transcend technology mediation. Our psychological perception and phenomenological relation with others is changed fundamentally by the advances in information and communication technologies and social software. Our interactions with others and objects are increasingly informed by the logic of technology, hence technological intersubjectivity. (Note that natural language is the bedrock of TI). Technological intersubjectivity deals with the ICT enabled capabilities to place-shift (i.e., to be physically embodied in one physical space but to be able to virtually embodied in a different place) and the ability to time-shift (i.e., to be able to refer back to earlier interactions or to be able to defer forward interactions).

## 3 Discussion

The rethinking of the productive notion of affordances can help inform the design of TEL systems. The concept of affordance has been much used, misused, and abused in fields of human computer interaction [8] as well as in the learning sciences. In my opinion, most current usages of the term affordance are far removed from its ecological origins and subsequent developments in ecological psychology. In many ways, the concept of affordance had been subjected to "conceptual stretching" by uncritical conflation with "technology features". By returning the concept of affordance to its ecological roots and following its intellectual trajectory since Gibson's seminal contribution, this theoretical framework rethinks affordances as socio-technical action taking possibilities and meaning making opportunities in an actor-environment socio-technical system relative to actor competencies and technology capabilities.

This allows us TEL researchers and practitioners to critically engage with design and evaluation of learning technologies by concentrating on all four aspects:
- Action taking possibilities
- Meaning making opportunities provided by intended design or creative appropriation
- How these are relative to learner competencies in terms of digital literacy, domain-specific knowledge, motivation, critical thinking competencies
- Finally the pedagogically innovative technological capabilities built into the TEL system

The definition and discussion of the concept of appropriation of affordance indicates that learners situated in TEL environments might choose to appropriate culturally relevant (or appropriate) affordances. That is, context-sensitive and situation-bounded embodied actions of individual learners engaged in TEL environments will be influenced by not only the micro-genetic unfolding interactional contingencies but also by the macro-structural cultural concerns and metacognitive functions [19-21]. This allows for a richer conception, instrumentation, and analysis of interactional data from the TEL environments [see 22, for a description of a design framework of usability, sociability, and learnability].

The concept of technological intersubjectivity (TI) goes beyond the traditional HCI notions (such as presence and connected presence) and the humanities' notions (such as networked individualism, information subject) by bringing together both psychological and phenomenological aspects of technology supported social interactions [23]. This provides for a broader and deeper understanding of the new generation of learners that are increasingly growing up with pervasive and ubiquitous information and communication technologies and other computational devices and gadgets (such as the so-called millennials and digital natives). One of the prime arguments for TEL has been that in a world of constant connectivity and near ubiquity of IC

## References

1. Kaptelinin, V., Nardi, B.A.: Acting with Technology: Activity Theory and Interaction Design. MIT Press, Cambridge (2006)

2. Latour, B.: Reassembling the Social: An Introduction to Actor-Network-Theory. Oxford University Press, Oxford (2005)

3. Norman, D.: The design of everyday things. Doubleday, New York (1990)

4. Torenvliet, G.: We can't afford it!: the devaluation of a usability term. Interactions 10, 12-17 (2003)

5. Hacking, I.: The Social Construction of What? Harvard University Press, Cambridge (1999)

6. Reed, E.S.: Cognition as the Cooperative Appropriation of Affordances. Ecological Psychology 3, 135-158 (1991)

7. Rogoff, B., Lave, J.: Everyday Cognition: Its Development in Social Context. Harvard University Press, Cambridge (1984)

8. Stoffregen, T.A.: Affordances and Events. Ecological Psychology 12, 1-27 (2000)

9. Blumer, H.: Symbolic Interactionism: Perspective and Method. Prentice-Hall, Englewood Cliffs (1969)

10. Wertsch, J.: Vygotsky and the social formation of mind. Harvard University Press, Cambridge (1985)

11. Garfinkel, H.: Studies in Ethnomethodology. Prentice-Hall, Englewood Cliffs (1967)

12. Sacks, H., Schegloff, E.A., Jefferson, G.: A Simplest Systematics for the Organization of Turn-Taking for Conversation. Language 50, 696-735 (1974)

13. Crossley, N.: Intersubjectivity: The Fabric of Social Becoming. Sage, London (1996)

14. Clarke, A.C.: Profiles of the future: an inquiry into the limits of the possible. Harper & Row (1962)

15. Vatrapu, R.: Cultural Considerations in Computer Supported Collaborative Learning. Research and Practice in Technology Enhanced Learning 3, 159-201 (2008)

16. Vatrapu, R.: Technological Intersubjectivity and Appropriation of Affordances in Computer Supported Collaboration. Communication and Information Sciences, PhD. University of Hawaii at Manoa, Honolulu, 538 (2007), http://lilt.ics.hawaii.edu/~vatrapu/docs/Vatrapu-Dissertation.pdf

17. Vatrapu, R., Suthers, D.: Culture and Computers: A Review of the Concept of Culture and Implications for Intercultural Collaborative Online Learning. In: Ishida, T., Fussell, S.R., Vossen, P.T.J.M. (eds.) IWIC 2007. LNCS, vol. 4568, pp. 260-275. Springer, Heidelberg (2007)

18. Vatrapu, R., Suthers, D., Medina, R.: Usability, Sociability, and Learnability: A CSCL Design Evaluation Framework. In: Proceedings of the 16th International Conference on Computers in Education, ICCE 2008 (2008) (CD-ROM)

19. Vatrapu, R., Suthers, D.: Technological Intersubjectivity in Computer Supported Intercultural Collaboration. In: Proceeding of the 2009 international Workshop on intercultural Collaboration, IWIC 2009, Palo Alto, California, USA, February 20-21, pp. 155-164. ACM, New York (2009)

## Knowledge

Here's the cleaned and normalized Markdown:

## Knowledge Maturing in the Semantic MediaWiki

There are several approaches analyzing the theory of Knowledge Maturing. [6] describes conceptual foundations for systems which support knowledge maturing. For that purpose the three dimensions, content, semantics and processes were taken into account. Indicators for content maturing were examined in [2] by analyzing articles within the online encyclopedia Wikipedia. [1] deals with ontology maturing in folksonomies and [4] covers ontology evolution in Web2.0 environments. [5] describes the lifecycle of task patterns as part of process management.

## Maturing Services for the Semantic Media Wiki

Wikis are prime examples of tools that allow for a collective construction of knowledge in a community setting. There are certainly good examples of Wikis being used as tools for creating a collective knowledge repository, for teaching and learning purposes, and for organizational knowledge management, see [3]. In the perspective of a knowledge worker, Wikis might be very well suited for enabling the maturing of artefacts, especially because of the ease of editing the content and the policy that everyone can edit anything. Additionally, they make the collective construction process traceable (utilizing the wiki's history functionality) and allow for discussion processes around artefacts. The career guidance sector is heavily content dependent (Labour Market Information, statistics etc.), thus a Semantic MediaWiki was chosen as a basis for a prototype supporting knowledge maturing in this sector. Several functionalities were developed to enrich the Semantic MediaWiki in terms of searching, collaborating, adding semantic mark-up and visualisation. Each of these services to support knowledge workers will be described in detail in the following.

### Search Support Service
This service provides a search interface which helps the user to aggregate information related to a certain topic without the need to use multiple search engines. Using different search facilities of various web resources (yahoo search, YouTube, wiki articles, Xing) and Yahoo Omnifind to enable including local information sources, the Search Support Service provides a combined interface that is embedded in the edit-mode of a wiki article. By default, the tags suggested by the system on the basis of the existing text in the article, are used as default search keywords. The wide range of information sources, varing between textual content, pictures, persons, ... stimulates the user's inspiration and so provokes the evolutionary growth.

### Collaboration Initiation Service
This service offers the facility to initiate easy collaboration with authors of articles or interested persons via Skype (see fig. 2 (marker 4)) by not having to switch to another tool since it is embedded into the wiki and enables easier use. The user can send messages or web-links to wiki articles in order to support negotiation of and consolidation of artefacts. Additionally, within the visualisation of the wiki network, every author related to an article in the wiki can be contacted by clicking on the author's node.

### Maturing Indicator Services
The objective of analyzing content is to facilitate the assessment of the maturity of a document. This maturity level allows to decide whether the maturity of a certain document should be improved by supporting the user in creating or editing a knowledge artefact. The bottleneck in assessing the maturity of text is the selection of qualified attributes reflecting the maturity of the content. Assuming that the readability and the maturity have a strong correlation, see [2], we tested within the design study two metrics for readability scores where both scores analyse English text samples.

### Mark-up Recommendation Service
Creating semantic mark-up conveys to the enrichment of wiki content. Additional annotation of articles enables the user to browse through the wiki and facilitates the retrieval of knowledge based on semantic mark-up. In addition, mark-up is used as a basis for recommendation of useful resources and visualisation of emergent content structures. The markup recommendation services strive for two goals. First, lowering the barrier for creating mark-up which replaces the complex Semantic MediaWiki syntax and second, improving the quality of structure by recommendation of meaningful, pre-consolidated mark-up. Depending on the content of an article, the system analyses used words and their

## Knowledge Maturing in the Semantic MediaWiki

## System Features and Implementation

A Semantic Media Wiki Edit-Page with additional feature bar provides enhanced functionality. Users can write articles, create categories containing sections, articles, and tags. The visualization allows users to:

- Define maximum path-length for network levels shown
- Choose graph type (hierarchical, cyclic)
- Browse content by clicking nodes to update connected nodes
- Create new nodes (users/articles)
- Open and edit articles in new browser windows
- Contact users through the Collaboration Initiation Service

This service supports daily work by enabling visual browsing through wiki content and related articles/users, providing topic overviews and expert access.

## Evaluation in a Real World Context

The prototype was evaluated in career guidance organizations with Personal Advisers (P.A.s). Development used rapid prototyping with iterative design phases, mock-ups, and regular feedback through questionnaires, interviews and workshops.

Key findings included:

- Visual Appearance: System needs adaptability for individual preferences and learning styles
- Easy Access to Relevant Information: Articles should have summaries visible in search results and visualizations
- Accuracy Control: Time and content accuracy requires monitoring; automatic date flags could remind authors to update content
- Awareness for Collaboration: Users need immediate visibility of online status for help and discussions

## Conclusion

The study explored knowledge maturing processes in career guidance organizations through tool development. The Semantic Media Wiki was enhanced with interfaces supporting collaboration, content visualization, and usability. The evaluation revealed features relevant for knowledge maturing support, with findings applicable to knowledge workers in other contexts.

### Acknowledgement

This work was partially funded by the European Commission as part of the MATURE IP (grant no. 216346) within the 7th Framework Programme of IST. The Know-Center is funded within the Austrian COMET Program under the Austrian Ministry of Transport, Innovation and Technology, the Austrian Ministry of Economics and Labor and the State of Styria.

### References

1. Braun, S., Schmidt, A.: People Tagging & Ontology Maturing: Towards Collaborative Competence Management. In: 8th International Conference on the Design of Cooperative Systems (COOP 2008), Carry-le-Rouet, France (2008)

2. Braun, S., Schmidt, A.: Wikis as a Technology Fostering Knowledge Maturing: What we can learn from Wikipedia. In: 7th International Conference on Knowledge Management (IKNOW 2007), Special Track on Integrating Working and Learning in Business (IWL), Austria (2007)

3. Jaksch, B., Kepp, S.J., Womser-Hacker, C.: Integration of a wiki for collaborative knowledge development in an e-learning context for university teaching. In: Holzinger, A. (ed.) USAB 2008. LNCS, vol. 5298, pp. 77–96. Springer, Heidelberg (2008)

4. Juffinger, A., Neidhart, T., Granitzer, M., Kern, R., Scharl, A.: Distributed Web2.0 Crawling for Ontology Evolution. International Journal of Internet Technology and Secure Transactions

5. Ong, E., Grebner, O., Riss, U.: Pattern-Based Task Management: Pattern Lifecycle and Knowledge Management. In: WM 2007 Proceedings of the 4th Conference Professional Knowledge Management. IKMS 2007 Workshop Potsdam, Germany, pp. 357–364 (2007)

6. Schmidt, A., Hinkelmann, K., Ley, T., Lindstaedt, S., Maier, R., Riss, U.: Conceptual Foundations for a Service-oriented Knowledge and Learning Architecture: Supporting Content. In: Process and Ontology Maturing. Springer, Heidelberg (2009)

7. Schmidt, A.: Knowledge

## Internet Self-efficacy and Behavior in Integrating the Internet into Instruction: A Study of Vocational High School Teachers in Taiwan

## Abstract

The purpose of the study was to explore the relationship between Internet self-efficacy and behavior in integrating the Internet into instruction. Participants in the study were 449 vocational high school teachers in Taiwan. A validation study was conducted with Internet Self-Efficacy Scale (ISES) and Integrating the Internet into Instruction Behavior Scale (IIIBS). The findings revealed that general and communicative Internet self-efficacy might foster behavior in integrating the Internet into instruction. The teachers' behavior was classified as five aspects: course preparation, teaching activities, learning guidance, assessment, and product sharing. Furthermore, this study employed structural equation model (SEM) to investigate the causal relations among the variables considered in this study. The SEM analysis revealed that teachers with higher Internet self-efficacy showed more Internet integration in their course preparation. In addition, course preparation is a mediating factor between Internet self-efficacy and other four aspects of behavior in integrating the Internet into instruction.

Keywords: Internet self-efficacy, integrating the Internet into instruction, vocational high school teachers.

## 1 Introduction

The Internet is widely used in vocational high schools. The use of Internet technology to learn for educational purposes has been growing rapidly. Through the Internet, students can access useful tools and resources to enhance their learning. Perceiving the power of Internet-based technologies, the Ministry of Education in Taiwan has encouraged the use of information technology in schools. In addition, teachers have been encouraged to attend a series of workshops to prompt their informational literacy and further foster their ability to integrate information technology into their teaching. However, the implementation of technology integration is burdensome. Not every teacher is willing to adopt new approach for their teaching. Thus, study on factors related to teachers' behavior in integrating the Internet into instruction is crucial for educational policy and intervention.

Self-efficacy can be described as a person's beliefs, expectations and perceived confidence in him/her to successfully perform a task [1][2][3]. Research has showed that self-efficacy affects people's effort to devote while performing a task, and people's persistence to deal with difficult situations [4][5]. Studies have further revealed a link between teachers' self-efficacy and students' achievement [6][7]. Thus, teachers' self-efficacy is a valuable issue for educators. Harrison, Rainer, Hochwarter, & Thompson [8] suggested that employees with a high level of computer self-efficacy increased performance with computer-related tasks significantly. The explosive growth of computers and the Internet into the classroom over the last decades has made most teachers access to the Internet easily. Therefore, their Internet self-efficacy, which may affect their behavior in integrating Internet into instruction, would be an important topic to study.

## 2 Methodology

### 2.1 Participants

This investigation used purposive sampling, and focused on the vocational high school teachers in Taiwan. A total of 449 paper-and-pencil survey questionnaires were gathered. The participants were 449 teachers from a selection of schools in Taiwan. They dispersed in 36 vocational high schools, including 316 female and 133 male teachers.

### 2.2 Instruments

Internet Self-Efficacy Scale (ISES) and Integrating Internet into Instruction Behavior Scale (IIIBS) were utilized to meet the purpose of this study. Internet Self-Efficacy Scale (ISES) is designed to assess teachers' self-perceived confidence and expectation of using Internet, including general internet self-efficacy and communicative internet self-efficacy. ISES used a six-point Likert scale with 10 items, which were adapted from the items developed by Tsai and Tsai [9] and Peng, Tsai and Wu [10]. The ten items were divided into two factors, the first one assessed teachers' Internet self-efficacy in general (5 items) and the second one assessed teachers' efficacy in communication and interaction on the Internet (5

Here's the cleaned and normalized Markdown:

## Internet Self-efficacy and Behavior in Integrating the Internet into Instruction

Teachers showed higher general Internet self-efficacy than communicative Internet self-efficacy (mean score 5.40 versus 4.32). Moreover, they expressed inconsistent tendency for five aspects of integrating the Internet into instruction behavior (between 4.71 and 2.55 in 1-6 Likert scale). They preferred to integrate Internet into their course preparation more than teaching activities, product sharing, learning guidance and assessment.

### Table 1. Descriptive data for teachers' scores on ISES and IIIBS

Scale | Mean | S.D.
---|---|---
General Internet Self-efficacy | 5.397 | 0.659
Communicative Internet Self-efficacy | 4.318 | 1.403
Assessment | 2.553 | 1.166
Course Preparation | 4.710 | 0.891
Learning Guidance | 3.410 | 1.123
Teaching Activities | 3.578 | 1.132
Product Sharing | 3.531 | 1.191

### The Correlation between Internet Self-efficacy and Integrating the Internet into Instruction

Table 2 displays Pearson correlation analysis between teachers' scores on ISES and IIIBS. It was found that teachers' communicative Internet self-efficacy and their scores on each scale of IIIBS were all significantly positively correlated. That is, teachers with higher communicative self-efficacy integrated more Internet resources into all aspects of their instruction. On the other hand, teachers' general Internet self-efficacy was also significantly related to their behavior in integrating the Internet into instruction, except for "assessment." Both general and communicative Internet self-efficacy played an important role on teachers' integrating Internet into instruction. High Internet self-efficacy may promote teachers to integrate the Internet into their teaching.

### Table 2. The correlation between teachers' responses on ISES and IIIBS

 | General Internet Self-efficacy | Communicative Internet Self-efficacy
---|---|---
Course Preparation | .461*** | .413***
Teaching Activities | .272*** | .401***
Learning Guidance | .184*** | .312***
Assessment | .055 | .275***
Product Sharing | .245*** | .380***

***p<0.001, **p<0.01, *p<0.05.

### Structural Model: The Causal Relation between Internet Self-efficacy and Integrating the Internet into Instruction Behavior

This study applied the structural equation modeling (SEM) analysis to explore the causal relationships for the variables. The predictor (exogenous) variable was Internet self-efficacy and the outcome (endogenous) variable was integrating the Internet into instruction behavior. According to previous literature [12][13][14][15][16][17], the fit measures of the structural model in the present study indicated an adequately fit (Chi-square/df =3.5, recommended value ≤ 5; Root Mean Square Error of Approximation (RMSEA) = 0.079, recommended value ≤0.08; Goodness-of-Fit Index (GFI) = 0.86, recommended value ≥ 0.90; Normed Fit Index (NFI) = 0.96, recommended value ≥ 0.90; Comparative Fit Index (CFI) = 0.97, recommended value ≥ 0.90).

From Figure 1, the structural model implied that both general and communicative Internet self-efficacy had positive effects on course preparation; but communicative Internet self-efficacy had a stronger effect than general Internet self-efficacy. Furthermore, course preparation had strongly positive effects on the other four aspects of integrating the Internet into instruction behavior, such as teaching activities, learning guidance, assessment, and product sharing.

Here's the cleaned and normalized Markdown:

## Internet Self-efficacy and Behavior in Integrating the Internet into Instruction

Teachers need to develop ways to integrate new technologies into suitable approaches to facilitate student growth and learning.

SEM (structural equation model) analysis in this study revealed that teachers' Internet self-efficacy had a positive effect on their behavior in integrating the Internet into instruction. Communicative Internet self-efficacy affected their integrating the Internet resource into their course preparation directly; and then through the mediator of course preparation further affected the other four aspects of behavior in integrating the Internet into instruction. Thus, for effectively promoting teachers' Internet-integration instruction, it's essential to enhance teachers' Internet self-efficacy, especially communicative Internet self-efficacy.

## Acknowledgement

Funding of this research work was supported by National Science Council, Taiwan, under grant numbers NSC 96-2511-S-011-002-MY3.

## References

1. Bandura, A.: Self-Efficacy Mechanism in Human Agency. American Psychologist 37, 122-147 (1982)
2. Bandura, A.: Perceived Self-efficacy in Cognitive-development and Functioning. Educational Psychologist 28, 117-148 (1993)
3. Bandura, A.: Multifaceted Impact of Self-efficacy Beliefs on Academic Functioning. Child Development 67, 1206-1222 (1996)
4. Bong, M., Clark, R.E.: Comparison between Self-concept and Self-efficacy in Academic Motivation Research. Educational Psychologist 34(3), 139-153 (1999)
5. Klassen, R.: Writing in Early Adolescence: A Review of the Role of Self-efficacy Beliefs. Educational Psychology Review 14, 173-203 (2002)
6. Ross, J., Hogaboam-Gray, A., Hannay, L.: Effects of Teacher Efficacy on Computer Skills and Computer Cognitions of Canadian Students in Grades K-3. The Elementary School Journal 102(2), 141-156 (2001)
7. Cannon, J., Scharmann, L.C.: Influence of a Cooperative Early Field Experience on Preservice Elementary Teachers Science Self-efficacy. Science Education 80, 419-436 (1996)
8. Harrison, A., Rainer, R., Hochwarter, W., Thompson, K.: Testing the Self-efficacy-performance Linkage of Social-cognitive Theory. The Journal of Social Psychology 137(1), 79-87 (1997)
9. Tsai, M.-J., Tsai, C.-C.: Information Searching Strategies in Web-based Science Learning: The Role of Internet Self-efficacy. Innovations in Education and Teaching International 40, 43-50 (2003)
10. Peng, H., Tsai, C.-C., Wu, Y.-T.: University Students' Self-efficacy and their Attitudes Toward the Internet: The Role of Students' Perceptions of the Internet. Educational Studies 32, 73-86 (2006)
11. Nunnally, J.C., Bernstein, I.H.: Psychometric Theory, 3rd edn. McGraw-Hill, New York (1994)
12. Bagozzi, R.P., Yi, Y.: On the Evaluation of Structural Equation models. Academy of Marketing Science Journal 16, 74-94 (1988)
13. Bentler, P.M.: EQS: Structural Equations Program Manual. Multivariate Software, Encino (1995)
14. Hu, L., Bentler, P.B.: Cutoff Criteria for Fit Indexes in Covariance Structure Analysis: Conventional Criteria Versus New Alternatives. Structural Equation Modeling 6(1), 1

Here's the cleaned and normalized Markdown:

## WebQuests and Their Design

On the Web, there are some attempts to provide a design process for a WebQuest but they are mostly focused on the pedagogical background, preparation and motivation, for which, of course, there is very little support a computer can provide. In this section, we propose an operational design process of a WebQuest that is meant to identify the phases where the computer-support can help teachers in building effectively and efficiently new WebQuests.

As pedagogical design process, we refer to the one provided into the WebQuest official site [9]. The phases are depicted as follows:

1. Select a topic appropriate for WebQuests
2. Select a design
3. Describe how learners will be evaluated
4. Design the process
5. Polish and Prettify

The output of the process is the (specific) WebQuest containing at least the following building blocks:
- An introduction, to provide background information
- A task involving the learners to analyze and transform the gathered information
- A process, that delineates the steps to follow in accomplishing the task
- A set of evaluation criteria for the work accomplished
- A conclusion, to inform the learners about their results and finally a teacher page, that could be useful for other teachers to implement WebQuests

Our proposal is to augment the WebQuest scenario with the computer-support to orchestrate the whole set of activities, from the design and authoring to the execution and documenting of the WebQuest. In fact, our operational design process of a WebQuest is defined as composed by the following fundamental phases:

- Design, that is to help the teacher in choosing a pedagogically motivated template; the template contains not only introduction, task, evaluation criteria, but also a step-by-step executable sequence of cooperative actions to be performed by the students in a synchronous work session, each one using his/her own PC.
- Authoring, when the teacher fills-in the details of the topic found and the base material (links, etc.) for the students. In this phase, adjustment of the process provided by the template are possible, and merging/splitting/creating new steps into the process (as well as changing the nature of the steps) are to be supported.
- Execution. This is the new phase that allows each student to communicate and discuss both orally and computer-mediated and, at the same time, use the computer as information-seeker and note-taker.
- Documenting is the final phase that consists in publishing on the Web the results (in HTML) in such a way that the results of the WebQuest are publicly available.

While a lot of useful resources are available on the Web [5] to create high-quality WebQuests and different tools are available to support online authoring and hosting services [10,11,12,13,14], no system is actually able to fully support the WebQuest process, by lacking the computer-support in the execution of the WebQuest in the classroom.

In general all the state-of-the-art tools are fill-in-the-blank tools that guide authors through the phases of picking a topic, searching resources in Internet and documenting them into online learning activities. These activities encompass three (i.e., designing, authoring and documenting) of the four steps of the operational design of WebQuests. Conversely, the execution phase has not been envisioned and implemented by any system that use WebQuests for face-to-face educational settings (see Table 1).

| Tool | Design | Authoring | Executing | Documenting |
|------|---------|-----------|------------|-------------|
| CoFFEE [15] | √ | √ | √ | √ |
| QuestGarden [10] | √ | √ | - | √ |
| Filamentaly [11] | - | √ | - | √ |
| zWebquest [14] | - | √ | - | √ |
| PHPWebQuest [12] | - | √ | - | √ |

## Computer-Supported WebQuests

## Design Patterns and Lesson Planning

The Lesson Planner and Session Editor address issues raised in [7] and [21] about structure and implementation by unexperienced teachers. We leverage the Lesson Planner's ability to provide CoFFEE-based templates and created implementations of several known and pedagogically well-motivated design patterns from [20]. As proof of concept, we created templates for the following patterns:

- "Commemorative" (Design tasks category)
- "Comparative judgment" (Decision tasks)
- "Behind the book" (Creative Tasks)

These can be downloaded (with additional material) from http://coffee-soft.wiki.sourceforge.net/CoFFEE+within+WebQuest and imported into the Lesson Planner (included with CoFFEE).

As shown in Fig. 1, the teacher is supported by a narrative, wizard-like structure. First, the teacher chooses a CoFFEE template from the grouped categories. For each template, additional information (metadata and description) are shown. The teacher can then advance to the "Edit" tab to instantiate tasks and instructions for each step and modify group numbers. If satisfied, they can proceed to the "Summary and Save" tab, or choose the "Advanced Editor" tab where the Session Editor offers complete control over the session. The Session Editor can also be used to author sessions from scratch. In the "Save/Publish" tab, templates can be exported as zip files to facilitate exchange.

## Executing a WebQuest

The main technical challenge in supporting WebQuests was introducing tools not directly related to discussion and debate but focused on Web browsing and resource sharing. New tools developed include:

### InternetExplorer Tool
- Allows standard web navigation with private browsing
- Provides "follow-me" mechanism for guided navigation
- Stores navigation in session log files
- Includes document repository (HTTP server)
- Uses OLE technology for complete Internet Explorer Control behavior
- Allows switching between synchronous and asynchronous navigation modes

### DocumentBrowser Tool
- HTTP server for document sharing
- Provides scaffolded browsing with basic navigation functions
- No free browsing capabilities
- Enables independent learner navigation for personal tasks
- Works alongside collaborative CoFFEE tools

## Documenting a WebQuest

The documenting phase enables publishing inquiry activities on the Web. CoFFEE allows exporting structured discussions (sessions) in PDF, RTF and HTML formats through the Controller. Since discussions can be saved in HTML format, the entire student learning activity can be accessed and edited by external systems, allowing modification of discussion details beyond just the WebQuest output.

## Computer-Supported WebQuests

## Conclusions and Future Works

In this paper we presented a system to computer-support WebQuests from the creation to the publication phase. The system is based on CoFFEE [15] but required two new tools to be introduced and integrated into the system. We also showed a operational design process that is completely supported by the system.

Among the future work, we are currently working on the implementation of group synchronous navigation for the InternetExplorer tool, since now the "follow-me" is only teacher-to-class and does not allow turn-taking "follow-me" mode within the class/group.

## References

1. Webb, N.M., Palincsar, A.S.: Group processes in the classroom. Macmillan, New York (1996)

2. Slavin, R., Hurley, E., Chamberlain, A.: Cooperative learning and achievement: Theory and research. Handbook of Psychology, 177-198 (2003)

3. Dodge, B.: WebQuests: A Technique for Internet-Based Learning. Distance Educator 1(2), 10-13 (1995)

4. Dodge, B.: FOCUS: Five Rules for Writing a Great WebQuest. Learning & Leading with Technology 28(8), 6-9 (2001)

5. Dodge, B.: WebQuest Portal (2009), http://www.webquest.org/ (accessed April 18, 2009)

[References 6-21 continue in same format]

## A 3D History Class: A New Perspective for the Use of Computer Based Technology in History Classes

Claudio Tosatto¹ and Marco Gribaudo²

¹ Discipline Storiche, Dottorato in Storia e Informatica, Università di Bologna
claudio.tosatto@gmail.com, marcog@di.unito.it

² Dip. di Informatica, Università di Torino
marcog@di.unito.it

## Abstract

The job of the historian is to understand the past like the people who have lived it have comprehended it, but also to communicate it with instruments and techniques that belong to an age and that influence the mentality of whom in that age live. Technologies, especially in the area of multimedia and virtual reality, allow the historians to communicate the experience of the past in a wide variety of senses. In this work we present a case study, that tries to answer the demand to "make history" involving directly the students, engaged in 3D reconstruction of a building from the past, by carefully checking all the problems of authenticity and by using methods of historical research. In this way, students are able to learn history by re-creating the past with information technology instruments.

## Introduction

There is a wide range of multimedia products related to historic subjects, especially for what concerns the delivery of the results. The need of the historians to use appropriate media to communicate the results of their researches, comes from the fact that students, and all the other possible audiences, are starting to show less and less interest for the traditional text-based and paper printed media. It is thus important, due to the fast evolution of computer tools, to get used to the idea that a research does not finish with the publication of a paper, but that it should be accompanied by an on-line version, capable of exploiting a wide variety of multi-media and interactive features. The representation of the past in fictions broadcasted on televisions or into generic non-peer reviewed web sites (like wikipedia) poses several questions about the validity of those presentations and about the fidelity of the sources they use [11]. Visual culture is nowadays code and can change our way of looking at past: while a book tends to split its contents over several units that deals with separate analysis, the flows of images in a movie or events in a video game mix all the different subjects in a single entity. The question is then whether the emotions carried by such media can be actively used to convey knowledge about the past [5]. Many independent projects have tried to give an answer to

Here's the cleaned and normalized Markdown:

## A 3D History Class: A New Perspective for Computer Based Technology

## Background

The project from the University of Bologna (Italy) tries to reconstruct its city with the introduction of a temporal variable that allows the user to see the 3D reconstruction of the place in a given temporal epoch. It also proposes an effective methodology for an extensive use of computer-based techniques to present the results of the researches made by the historians [1]. John Bonnet's experience and his "3D Virtual Buildings" are the outcome of a cooperation among the National Research Council of Canada, Industry Canada and the Ottawa University. Its focus is to help students to understand an important concept: the historical model should remain separate from the objects it wants to represent. History does not exist until it is reconstructed, and this reconstruction can also be made using a 3D modeling software [9]. None of them, however, has considered in depth the problem of correct transmission of historical knowledge.

## Our Proposal

In this paper we propose a methodology that extends the one proposed in Bonnet works. We share with that works the idea that 3D reconstructions can be important tools from an academic point of view. In particular, we focus on the communication of results of historic researches, and we show with an experience (called Conceria Fiorio in Real Time) how we can improve the students learning process (in history) by making them use the 3D computer tools in first person.

Our idea is that presenting researches' results with various media - in this case with the construction of 3D models - can improve students learning process, and increase their critical abilities, giving them the opportunity to face a large number of problems that historians have to solve while their do their job of trying to reconstruct the past. This allows the students to directly face the problems that characterize the gathering of the sources and of all the necessary data to perform the reconstruction.

In this sense, we intend "multimedia" as a collection of superposed narrations (coming from different sources), and we exploit the interactivity features of computer based presentations not only to present the facts, but also to allow the final user to move among different narrations [10]. We use the PC as a tool with which students can reconstruct the past. This allow them to became authors of a historical narration themselves, and more importantly, to face with historical research.

We restrict our attention to the reconstruction of a building because we believe that is the easiest reconstruction (from a technical point of view) that can make students correctly focus on the methodologies of historical research. For this purpose, it is required to research various material using different sources. Students will have to look for those data by themselves and will discover how documents can give us much more information if correctly compared one with the other.

For the 3D reconstruction, we wanted to use a framework that could be well-known by most of the students. For this reason, we have chosen to use the 3D engine of a famous video game: Unreal Tournament [2]. Our key idea is that the user interface of a game engine like Unreal has been created to allow any player (regardless of their computer background) to create their own world. It has thus been created "simple enough" that students are able to manage it quite quickly. This allows the course to focus on historical methodology, requiring only a very short introduction on the use of the authoring application.

When the sources that narrate the historical facts, and the media used to reconstruct it are of different nature (in this case we are dealing with texts, pictures, architectural blue prints, virtual reality), the results of the learning process and of the critic capacity of the students increase, thanks to the work done on the sources.

## Implementation

In this paper we will present the tools that were used to create the 3D reconstruction. In particular, the building is recreated in Unreal Engine, a game engine developed by Epic Games. The engine was initially shipped with the games Unreal Tournament 2003 and Unreal Tournament 2004. Later, a reduced version (called Unreal Engine) was made freely available online for non commercial purposes.

The choice of Unreal as the platform

## A 3D History Class: A New Perspective for Computer Based Technology

## Background

The "Conceria Fiorio" was a production factory that became one of the centers of clandestine activity for the CLN (national liberation committee) in December 1943, through the actions of its owner Sandro Fiorio. The relationship between buildings and people in Turin was significant, particularly in the connection between the factory and workers' organization during 1943-45, which was an important political and social entity during the war [8].

The factory participated in the "Class and Cross" mission in contact with the OSS (U.S. intelligence service). Most financial support for the allies passed through this factory before reaching the CLN. The entire factory, including offices, plants, and trucks, was used by the Resistance for operations inside the city [6]. A dramatic period for the city began on September 8th, 1943, lasting 18 months.

Factories were conceptual nodes through which city life could be understood - they were places where people spent most of their day, and their activities influenced the city, making them centers of political activity. These factors motivated the decision to focus the experiment on reconstructing the "Conceria Fiorio" [7].

## Technical Workflow

The reconstruction process followed these steps:

1. Historical research based on:
   - Archive sources
   - On-site inspections
   - Witness descriptions

2. Resource utilization:
   - Archive maps for environment reconstruction
   - On-site photographs for texture creation
   - Witness descriptions for object selection

3. Final assembly in the Unreal Engine

## Conclusions

The project aimed to test 3D virtual reconstruction as a tool for historical instruction. Its value lies in enabling spatial perception of reality and helping audiences comprehend historical structures and phenomena. In "Conceria in Real Time," the concept of research communication was transformed - project participants became active creators of historical information rather than passive recipients.

The case study addressed the need to "make history" by directly involving students in the 3D reconstruction of historical buildings using historical research methods and representation techniques. This approach allowed students to experience firsthand the challenges historians face in reconstructing the past. The process of communicating history through multiple senses enabled students/developers to enhance their historical knowledge while gathering information and reconstructing 3D artifacts. The use of information technologies in rebuilding the past suggests significant opportunities for historians in utilizing 3D objects and environments.

Here's the cleaned Markdown:

## Language-Driven, Technology-Enhanced Instructional Systems Design

Iván Martínez-Ortiz, José-Luis Sierra, and Baltasar Fernández-Manjón

Fac. Informática. Universidad Complutense de Madrid
C/ Prof. José García Santesmases s/n 28040 Madrid, Spain
+34913947606
{imartinez,jlsierra,balta}@fdi.ucm.es

## Abstract

In this paper we propose to extend the ADDIE (Analysis – Design – Development – Implementation – Evaluation) process for Instructional Systems Design (ISD) with a new linguistic layer. This layer allows developers to provide instructors with domain-specific languages to support and guide them through ISD. Instructors use the toolsets associated with these languages to produce technology-enhanced learning systems more effectively. We also describe how to put these ideas into practice by adopting modern model-driven software development processes together with the language engineering principles. This language engineering approach has been applied to <e-LD>, a highly flexible and extensible authoring tool for IMS Learning Design Units of Learning.

**Keywords**: Technology-Enhanced Instructional Systems Design, ADDIE, Software Language Engineering, IMS Learning Design, <e-LD>.

## 1 Introduction

Instructional Systems Design (ISD) and the generic Analysis – Design – Development – Implementation – Evaluation ADDIE process were conceived as means of designing and developing learning systems, independently of whether these systems are technology-enhanced or not [2]. However, the introduction of a technological factor in the development process also introduces new issues that must be carefully addressed. One of the most important problems is the need to manage the active collaboration of instructors and developers. A way of addressing this collaboration is to use suitable domain-specific languages (DSLs) [10]. The application of DSLs results in a more rational distribution of roles: instructors use the languages to configure the technology-enhanced components, while developers provide the instructors with all the required machinery to make such a configuration possible.

In this paper we propose an extension of the generic ADDIE process model with a linguistic layer and illustrate this new process model using <e-LD> [6,7], an authoring tool for the production and reengineering of IMS Learning Design (IMS LD) Units of Learning (UoL) developed at Complutense University.

## 2 The Language-Driven ADDIE Model

The Language-Driven ADDIE (LD-ADDIE) model is sketched in Fig. 1. This model is based on the revised ADDIE model proposed by the US Department of the Air Force (see [2]). It organizes the concepts and phases of the revised ADDIE model into five different layers. More precisely:

- The evaluation layer includes activities centered on the continuous evaluation of the different aspects of the instructional system. It corresponds to the evaluation phase in the original ADDIE model.
- The production layer encompasses the systematic sequence of phases oriented to the production of the instructional system. It corresponds to the other four ADDIE phases (i.e., analysis, design, development and implementation).
- The linguistic layer contains phases for the systematic production of the domain-specific languages and the associated toolsets. Although these phases mirror the phases in the production layer, their purpose is very different: to develop the languages and tools used by instructors for the development of learning systems.
- The system layer contains the main functions of the learning system: management, administration, support and delivery.

## References

1. http://www.storiaeinformatica.it/
2. http://www.unrealtechnology.com/
3. http://www.gimp.org/
4. http://www.blender.org/
5. Rosenstone, R.A.: Visions of the Past: The Challenge of Film to Our Idea of History. Longman History (1995)
6. Pavone, C.: Una Guerra civile, Saggio

## Language-Driven, Technology-Enhanced Instructional Systems Design

## Overview of LD-ADDIE

LD-ADDIE adds a linguistic layer to explicitly address the technological factor of technology-enhanced instructional systems. The quality improvement layer represents the mechanisms needed for continuous quality improvement.

The linguistic layer phases, mainly carried out by developers, include:

- During linguistic analysis, developers analyze the instructional domain and instructor vocabulary to determine main terms, concepts and relationships using standard domain analysis techniques from software and domain engineering.

- During linguistic design, developers specify the domain-specific language's syntax, constraints and operational semantics. The language typically includes abstract syntax (for operational semantics) and concrete syntaxes (for instructor use), linked by transformations. Tools like authoring environments and component generators are also conceived.

- During linguistic development, developers build the DSL toolset using established language processor construction techniques or emerging software language engineering approaches.

- During linguistic implementation, the DSL and associated toolsets are made available to instructors as part of the learning system's support function.

## The Language-Driven ADDIE Model in Practice with <e-LD>

<e-LD> is an experimental, adaptable authoring tool for IMS LD UoL developed at Complutense University. It supports three main functions:

1. Importation: Allows loading pre-existing IMS LD UoL and produces:
   - A hypertextual view
   - A dependency graph showing learning activity sequencing relationships

2. Authoring: Enables editing UoL descriptions using a visual notation

3. Exportation: Automatically generates IMS LD UoL from <e-LD> descriptions through translation of flowcharts into rule-based systems

<e-LD> facilitates systematic design of evaluation instruments based on UoL structure. It plays key roles in production phases:

- During system analysis: Helps examine pre-existing UoL to determine student knowledge expectations and learning process requirements

- During system design: Enables reuse and modification of existing UoL, and helps author formalized instruction plans for technology-enhanced components

## Language-Driven, Technology-Enhanced Instructional Systems Design

- During system development, <e-LD> provides a catalog to determine the different instructional resources and materials to be developed.
- During system implementation, instructors use <e-LD> to automatically generate standardized versions of the authored UoL encoded in IMS LD.

Regarding the linguistic layer, the development of <e-LD> follows the principles of modern software language engineering [4]. Indeed, the root of <e-LD> is a DSL developed using the language workbench provided by the Eclipse Modeling Project. Thus, <e-LD> can be meaningfully conceived as the main product of an incarnation of the LD-ADDIE linguistic layer:

- As regards linguistic analysis, <e-LD> represents a cost-effective solution to the otherwise costly domain analysis processes. Indeed, <e-LD> reuses many of the conceptual structures of a pedagogically neutral language (IMS LD) with the hope of increasing the applicability of the solution while still maintaining a reasonable domain-specific nature.

- During linguistic design, the abstract syntax of the <e-LD> modeling language is characterized as a metamodel [4] that captures the main terms and concepts required to describe UoL in <e-LD>, as well as the relationships between these concepts, and the additional constraints affecting these elements. On the other hand, the concrete syntax corresponds to the aforementioned visual notation. These two syntaxes are related by an abstract-to-concrete-syntax mapping. Thus, by changing the concrete syntax model and this mapping, it is possible to tailor <e-LD> to the particular idiosyncratic requirements of each particular community of instructors. Finally, the operational semantics in <e-LD> are actually defined by the translation of flowchart-oriented specifications to rule-based ones used in the exportation function and described in [9].

- Linguistic development takes full advantage of the Eclipse Modeling Project. Indeed, the metamodels of <e-LD>'s abstract and concrete syntaxes are supported by EMF (the Eclipse Modeling Framework). Translation to IMS LD (carried out during exportation) is currently done as an ad-hoc model-to-model transformation; however, we are starting to refactor this process using the model-to-model transformation languages provided by the Eclipse Model to Model project. <e-LD> also takes full benefit of GMF (the Graphical Modeling Framework of Eclipse) to facilitate the development of the <e-LD> authoring function. Finally, the <e-LD> importation function is implemented as an XML processing component. We are currently refactoring it using XLOP (XML Language Oriented Processing) [12], an environment for the processing of XML documents with attribute grammars [11] also developed at Complutense University.

- Finally, during linguistic implementation, <e-LD> is deployed for the instructors as an Eclipse-based standalone authoring tool. Currently we are also working on integrating it with other IMS LD compliant platforms and tools, particularly IMS LD players.

Following the guidelines encouraged by LD-ADDIE, <e-LD> is an integral part of the learning systems' support function. In addition, it is also subject to continuous improvement. The adoption of principles strongly rooted in software language engineering in its design and development facilitates this continuous improvement.

## Conclusions and Future Work

In this paper we have described an extension of the ADDIE model for instructional systems design that highlights the collaboration between instructors and developers during the development of learning systems with significant technology-enhanced components. For this purpose, the extension promotes the production of domain-specific languages and associated toolsets as support for instructors. The resulting model (LD-ADDIE) makes explicit a linguistic layer oriented to the systematic production of language-oriented assets. We have illustrated the model with <e-LD>, an authoring tool for IMS LD UoL. From a linguistic point of view, the development of <e-LD> takes advantage of

Here's the cleaned and normalized Markdown:

## The Influence of Coalition Formation on Idea Selection in Dispersed Teams: A Game Theoretic Approach

Rory L.L. Sie, Marlies Bitter-Rijpkema, and Peter B. Sloep

Open University of The Netherlands,
Centre for Learning Sciences and Technologies,
Valkenburgerweg 177, 6419 AT Heerlen, The Netherlands
{Rory.Sie,Marlies.Bitter,Peter.Sloep}@ou.nl

## Abstract

In an open innovation environment, organizational learning takes place by means of dispersed teams which expand their knowledge through collaborative idea generation. Research is often focused on finding ways to extend the set of ideas, while the main problem in our opinion is not the number of ideas that is generated, but a non-optimal set of ideas accepted during idea selection. When selecting ideas, coalitions form and their composition may influence the resulting set of accepted ideas. We expect that computing coalitional strength during idea selection will help in forming the right teams to have a grand coalition, or having a better allocation of accepted ideas, or neutralising factors that adversely influence the decision making process. Based on a literature survey, this paper proposes the application of the Shapley value and the nucleolus to compute coalitional strength in order to enhance the group decision making process during collaborative idea selection.

**Keywords**: idea selection, game theory, coalition formation, dispersed team, open innovation.

## Introduction

With the increased use of Internet technology, companies are increasingly trying to reduce transactional costs. R&D costs may similarly be reduced by the adoption of Internet technology, as this fosters the communication in dispersed working teams and across collaborating companies. Indeed, with the adoption of these collaboration tools, we are well on the road to open innovation. The expertise relevant for the design of a new product is not always available within the boundaries of one team or firm. Hence the idea of open innovation suggests to create online distributed teams in which people from different companies and disciplines co-operate on the design of a new product. However, utilising a team's full innovation potential poses some serious problems. Most research thus far has focused on the extension of the set of ideas, and researchers have tried to neutralise potential pitfalls. There are however indicators that dispersed teams do come up with enough ideas, but just do not select the right ideas. Hence, we should take a closer look at enhancing idea selection, rather than looking at ways to extend the set of ideas during idea generation[1].

## Theoretical Background

When looking at the incentives for collaboration, we see that collaboration is a way for people to learn from each other, or to create new things with the combined knowledge that they have. In corporate environments, teams are created to generate innovative solutions or new products. While historically we see that research and development mainly took place inside the firm, we now see a tendency towards an increase of inter-firm alliances to support so-called open innovation[2]. The reasons for alliances between companies involve sharing risks, obtaining access to new markets and technologies[3], reducing product-to-market times, and pooling complementary skills[4,5]. Research and development departments of these companies tend to use open innovation to introduce new products faster and at a lower cost. This however requires collaboration and the corresponding notions of trust, reciprocity and negotiation, as co-operation is likely to have competitive aspects as well[6].

When firms collaborate through open innovation, we see that they are hindered by a variety of problems. They may experience individual problems regarding decision making, such as emotional involvement, exogenous factors[7], bounded rationality[8] and escalation of commitment[9]. Besides, the collaboration may be subject to group deficiencies, such as social loafing, group think and group polarisation. The latter two influence the formation of coalitions in open innovation.

## The Influence of Coalition Formation on Idea Selection

Innovation teams face challenges in idea generation and selection, where people need additional support to have their ideas accepted. They form coalitions to strengthen their position against other coalitions and ideas. While self-interested, people may support others' ideas in exchange for reciprocal support. This leads to a non-optimal set of accepted ideas.

For example, in collaborative idea generation, hierarchical positions can influence decisions. When person A outranks person B, B may accept A's ideas assuming A is more informed about company strategy. However, A might promote their own moderate ideas that don't align well with organizational strategy. This shows how good ideas can be overlooked due to individual and group deficiencies in the selection process.

## Computing Coalition Payoffs

To address non-optimal idea selection, we must study coalition formation's influence on idea allocation by determining each participant's share. Two main approaches in formal game theory compute participant shares and coalition payoff division:

1. The Shapley value
2. The nucleolus

These concepts are central to coalitional form games (many-person co-operative games) where players can transfer utility through side payments. Side payments share profit from mutually beneficial strategies, such as when companies share R&D departments.

## Characteristic Functions and Coalition Values

The characteristic function v defines coalition values. With three players, possible coalitions include:
- Empty coalition (⊘)
- One-person coalitions: {1}, {2}, {3}
- Two-person coalitions: {1,2}, {1,3}, {2,3}
- Grand coalition (N)

The grand coalition typically has the highest payoff, supporting that the whole exceeds the sum of its parts.

## Shapley Value and Nucleolus Comparison

The Shapley value considers how participants view coalition formation value. For example, if:
- c{1} = 2
- c{2} = 1
- c{1,2} = 1
- c{1,3} = 3
- cN = -2

Player 1's Shapley value would be: φ1 = c{1} + c{1,2}/2 + c{1,3}/2 - cN/3 = 3 + 1/3

The nucleolus extends the Shapley value by considering minimum payoffs and minimizing maximum dissatisfaction. In a bankruptcy example with 7200 euros to distribute among three players (A:2000, B:4000, C:6000), the nucleolus yields (1200,2100,4100) while the Shapley value gives (1200,2200,3800), compared to pro rata distribution of (1200,2400,3600).

## The Influence of Coalition Formation on Idea Selection

## Discussion
If we translate the example given above to idea selection, it is not always the case that we have an equal distribution of the set of ideas among participants, based on their individual skills in idea generation. If we compare the outcomes for the coalitions and the individual payoff when not co-operating, we may see different distributions of the payoff. For instance, if we base our imputation on the number of ideas generated during individual idea generation, it may be that forming a coalition pays off. We expect that this is the reason why people choose to form coalitions during idea selection.

## Conclusions
We think that studying coalition formation in open innovation is a sensible approach, which regrettably has been ignored thus far. We need to pay attention to the way coalitions are formed during collaborative idea selection and to what extent this influences the allocation of accepted ideas among the participants. Based on literature, we see that people often run into a number of problems while co-operating, such as escalation of commitment, bounded rationality, group think and group polarisation, which may lead to the formation of coalitions in such a way that a non-optimal set of ideas are accepted during idea selection. It is shown that the nucleolus and the Shapley value may lead to different distributions than the pro rata distribution of ideas. We expect that if we present the participants with the computations of the nucleolus and Shapley value, they may become better aware of the group's potential, thus forming coalitions that are better suited to optimise the set of accepted ideas. And if such coalitions are not formed, a moderator may try to put different people together during idea selection to have the right coalitions formed. However, forming coalitions may not always be beneficial for all participants, due to the problems we have sketched in this paper. We may thus choose to try to neutralise the factors that benefit some, but are detrimental to others. For instance, if a group is polarised, we may add people that bridge the gap between the groups that represent the poles to prevent a sub optimal idea from being accepted. If we do so, we may deviate from the original game theoretical notions of the Shapley value and the nucleolus, as we include external (social) factors.

## Future Research
The above overview suggests many avenues for further research on coalition formation in open innovation. These avenues will be investigated in the context of the EU funded idSpace project, which focuses on tools for distributed, collaborative product innovation. The following steps are envisaged. Based on the literature, we will first define a model that describes the formation of coalitions in idea selection. This will be followed by a social simulation that will help us in analysing the resulting set of accepted ideas. After that, we will try to adapt the model in such a way that we will be able to predict the formation of coalitions. The desired result of our final model will be either the optimisation of the formation of 'optimal' coalitions, that the influencing factors of 'sub-optimal' coalitions will be neutralised, or that the right people will be chosen in advance of idea generation to eventually have a grand coalition during idea selection.

These findings will be empirically tested and underpinned in suitable contexts in which open innovation takes place. We will also look into the possibility of extending our results to contexts in which collaboration takes place which is not necessarily focused on (open) innovation. A case in point would be so-called Learning Networks [12], which are online, social networks designed to foster non-formal learning and knowledge exchange.

## Acknowledgments
This paper provides a theoretical framework that will be part of a PhD study conducted within the idSpace project. The idSpace project is partially supported/co-funded by the European Union under the Information and Communication Technologies (ICT) theme of the 7th Framework Programme for R&D. This document does not represent the opinion of the European Union, and the European Union is not responsible for any use that might be made of its content.

## References
1. Barki, H., Pinsonneault, A.: Small group brainstorming and idea quality: Is electronic brainstorming the most effective

## How to Support the Specification of Observation Needs by Instructional Designers: A Learning-Scenario-Centered Approach

Boubekeur Zendagui  
Computer science laboratory of the Maine university  
IUT of Laval/ Dep. Info  
52 rue des docteur Calmette et Guérin  
53020, Laval – France  
Boubekeur.Zendagui@lium.univ-lemans.fr

## Abstract

In this paper, we present the conceptual model we propose to specify observation needs. Because our work takes place in a learning scenario re-engineering context, the observation process is prepared while instructional designers define their learning scenarios. Our work aims at helping these designers to specify the informations they want to get by the observation of the learning situation progress in order to improve the underlying learning scenario for future uses. In this paper we show how the observation needs specification can be guided by informations specified in learning scenarios. We will show how we use the Engeström triangle to model the observation context and how, from the context, some observables will be proposed and used by some observation techniques we propose to use, to define the informations to get by the observation process.

**Keywords**: Instructional design, Observation, observation needs, learning scenario, observation context.

## 1 Introduction

The preparation of a distant learning situation is generally done by the design of a learning scenario that contains informations about the learning activities, usually by using an educational modeling language (EML) [1]. This scenario is qualified as a predictive model of the learning situation. Our goal is to help instructional designers to specify, for a given predictive model, what is important to observe when the actors implied in the learning situation perform their activities. The results of the observation process will be used to improve the predictive scenario for future uses: re-engineering of the learning scenario. Into the REDiM project [2], we noted that it is difficult for instructional designers to specify their observation need: they have to guess how will be used the learning environment and have to make some assumptions about the learning situation progress; it is necessary to clarify and formalize the description of observation needs in order to guide the development of tools for collecting and analyzing tracks. The lacks of expressiveness from both learning scenario and EML may also add some difficulties to specify observation needs.

We want to help instructional designers in specifying the informations they want to have by the observation process. These informations are specified in a model we call the observation needs. These observation needs are defined in the design of a learning scenario step and used to guide the observation process during the learning situation progress. They help to define and develop the observation means, ie. tools to collect and analyze data about the effective progress of the learning situation. We think that thanks to these observation needs, the observation process will produce more helpful informations for designers to improve their learning scenario.

To assist instructional designers in their observation needs specification task, we have studied the observation activity and its preparation within both classic face-to-face and distance learning situations. We also worked with a teacher that uses the UMTice learning environment to give some courses in addition of the ones given in the classroom. From this theoretical study and work with the teacher, we proposed the conceptual model of observation needs presented in the next section.

## 2 Conceptual Model of Observation Needs

We define an observation need as composed of four parts (see Fig.1).

[Figure 1. The observation needs conceptual model]

The observation objectives are useful to define the "why" of observation needs. This information allows designers to explicit what they want to do when they will know the results of their observation needs from the concrete observation of the learning situation runtime. This information can also be useful to facilitate the reuse of observation needs for other situations sharing the same objectives.

### 2.1 The Context Layer

The observation context allows to define conditions under which the activity to observe will be done. It consists in selecting one or more pedagogical scenario elements concerned by the observation need and defined to be used by the learning situation actors. Contexts are important and must be well defined since it allows to identify

Here's the cleaned Markdown:

Several works deal with the modeling of context [4] but there is not a unique and single definition for this concept. This depends on the context of its use. We use the definition from [5] who focuses its definition of context on the concept of entity. The context is a set of inter-related entities playing roles. An entity can be an object, person, tool, or anything that may influence the activity to study. To guide the definition of the context entities, we use the Engeström triangle [6] from work on the activity theory, because the study of the media use, when an actor is doing a particular activity, is one among the basic principles of this theory [7]. In our research context, these media have important roles in the progress of a learning situation.

![The Engeström triangle (at left), the representation of the context of an activity (at right)](fig2.png)

We consider that the context of any activity can be represented in a single form by using the Engeström triangle [6] (Fig.2 right side) in which each activity is done by a subject and guided by an object. The result is a production. To perform an activity, the subject uses some tools and can interact within a community by respecting some rules. The community members have to share tasks to achieve the activity objectives [6]. The entities composing the context of an observation need are the concepts of the Engeström triangle (Fig.2 left side). Each activity is performed by one or more actors, and is guided by a particular object. We represent this object by the production which can be of two kinds: a tangible production (eg. production of a report) or intangible production (eg. the acquisition of knowledge). Learning activities are done by using tools which can in turn be of two kinds: services/materials to ensure the good functioning of progress of learning activities, and pedagogical tools/materials needed to guide and structure the learning activities. In the context of an activity, actors play roles, have tasks to perform and have to respect some behaviors and functioning rules. This simple representation allows on one hand to facilitate the construction of context by using a limited list of entities types that have a significant impact on learning activities [8] and, on the other hand, to help the instructional designers to ask the right questions about the learning activities progress and the choice of which informations to consider in observing of a given activity [9].

Our works are not based on a particular EML. Each EML proposes a specific vocabulary and a dedicated semantics for specifying learning situations. To guide the definition of the context, the element of EMLs have to be annotated according to the concepts of the Engeström triangle. This allows to give a simple and common semantic for elements of any educational modeling language and to unify the modeling of an observation need context whatever the used EML. The observation need context definition is guided by the learning scenario and the annotated EML. Each element of the observation need context is an element of the learning scenario.

## The Observables Layer

The data collected when learners and tutor use the learning environment are specified thanks to the definition of observables. An observable is defined in [2] as a variable that gets a value by the observation of the learning situation progress. Because our works takes place within the design phase of learning scenarios, we define an observable as any learning scenario elements for which designers want to get informations after the end of a learning session.

The observables are pedagogical scenario elements for which designers want to get informations after the learning situation execution. Concretely, these observables are defined at a scenario level but are conforming to those defined at the EML level. Their specification is done by selecting observables among those that can be automatically proposed according to the context delimitation and the observables identified in the annotated EML.

An observable can be any element of the pedagogical scenario. In the process for the observation need specification we propose in [10], there is a step in which an expert analyzes the EML in order to identify the potential observables. This identification is made by adding annotations on the elements of the EML considered, by this expert, as relevant to observe. The result

## How to Support the Specification of Observation Needs by Instructional Designers

## The Informations Layer

From our previous work with instructional designers using the UMTice learning platform, we note that a list of pair <observable-observed>, where "observed" is the value of the observable obtained by the observation activity, is sometimes not sufficient to give the informations instructional designers are waiting for to understand the effective learning activities progress. The available data contain a lot of informations. Instructional designer can use all these informations or make efforts to select only the relevant one for them. To address this problem, we propose to provide a set of observation techniques instructional designer can use to specify the informations they want to get by the observation process.

Each observation technique is a kind of a function whose result is a simple data like a number or a percentage, or a set of data like all messages posted by learners in a forum. By using an observation technique, one knows the nature of it result. Choosing an observation technique between various ones depend on it result nature and the observation needs of instructional designers. We aim, in this layer, to provide instructional designers with a set of observation techniques that allow them to define all informations they want to get and this by using the selected observables.

To this end, we propose to use the sign and the category of behavior techniques. These two observation techniques are used in the classical face-to-face learning situation observation [3]. A sign is a particular behavior to observe. For example, a learner begins an activity later then what was planned in the learning scenario. The signs based observation can be used to focus the observation on some specific behaviors. The use of behavior categories to observe the learning situation progress regroups several behaviors in homogeneous sets and analyzes them as a whole to better understand the behavior of the learning situation actors. For example, by defining a category of behavior in which there are the messages exchanged between students within a forum can enable the detection of active and passive learners or learners in difficulty. The analysis of each message alone can be relevant, but the analysis of all messages in a chronological order could provide more informations to instructional designers. In our mind, sign and category of behavior techniques are two examples of the use of observation techniques. Other observation techniques can be used in this layer.

## Conclusion

In this paper we presented the conceptual model of observation need we propose. In our research context, observation needs are defined during the elaboration phase of learning scenarios by instructional designers. Our goal is to guide the specification of observation needs by using the information defined in the learning scenarios. To this aim, we use the Engeström triangle to structure and guide the definition of the context of observation needs. The context definition allows to provide a vision of the learning situation instructional designer want to observe and it allows to propose some observables that can attest the effective progress of the learning situation. Instructional designers can select some observables to define the informations they want to get by the observation process.

The originality of our approach relies on the definition of observation needs in relation with informations about learning situations defined in learning scenarios and annotations made on the used EML. Because EMLs can be used to define many learning scenarios, annotations must be defined in a generic way to be used for all learning scenario. We are working currently on defining techniques allowing to contextualize annotations to each learning scenario used to define observation needs.

## References

1. Koper, R., Tattersall, C.: Learning Design – a handbook on Modeling and Delivering Networked Education and Training. Springer, Heidelberg (2005)
2. Choquet, C.: Engineering and re-engineering of TEL systems, the REDiM approach. Professor's degree thesis. Le Maine University, France (2007) (in French)
3. Wragg, E.C.: Introduction to classroom observation, 2nd edn. Routeledge (1999)
4. Strang, T., Linnhoff-Popien, C.: A Context Modeling Survey. Workshop on Advanced Context Modeling. In: Reasoning and Management as part of UbiComp, Nottingham

Here's the cleaned and normalized Markdown:

## Using Third Party Services to Adapt Learning Material: A Case Study with Google Forms

Luis de la Fuente Valentín*, Abelardo Pardo, and Carlos Delgado Kloos

Telematics Engineering Department,
University Carlos III of Madrid,
Av. Universidad 30, Leganés, Spain
{lfuente,abel,cdk}@it.uc3m.es
http://gradient.it.uc3m.es

## Abstract

Current Learning Management Systems were typically conceived to offer a self-contained "one size fits all" learning environment. Adaptive educational systems have been exhaustively studied and proposed to satisfy the different needs of students, but they have a poor presence in the LMS market due to integration issues. The emerging trend in the web is toward combining very specialised services into highly personalised environments, and LMS are no exception. This paper presents the Generic Service Integration architecture conceived to embed the use of any third party service as a regular resource in a learning experience. A course author includes a description with the required functionality and the appropriate service is searched and instantiated at enactment time. A case study is presented where Google Forms are used to implement assessment in a IMS Learning Design based course, and adapt its content based on the obtained results.

**Keywords**: IMS Learning Design, adaptive educational systems, service integration.

## Introduction

Learning Management Systems (LMS) in educational institutions have reached a stage of widespread adoption. The variety of commercial and open-source products conform a wide spectrum of possibilities to manage learning experiences. Most of current LMS can be described as a "one size fits all" service, where as much functionality as possible is provided. However, the trend emerging on the web points to open LMS that allow integration with third party services.

One factor that pushes this integrating trend is the innumerable amount of services conforming what is called the Web 2.0. Most of participants of a learning experience are likely to use 2.0 services, but still they are forced to use the counterparts offered by the LMS. Some LMS offer email, bookmark collections, picture albums, personal web pages, etc. This tendency suggests educational systems to act as service orchestrators where the functionality is given by third party providers and the pedagogical structure of the course is promoted at the LMS.

## Adaptation Using Third Party Services

The term "adaptation" refers to purposely changing one or several aspects of a learning environment to cater to the needs of a student. The effectiveness of adaptation has been a matter of great discussion (see [6] for a thorough examination of some of them or [7] for a discussion in the context of engineering education). As pointed out in [1], tools that facilitate adaptive learning tend to be extremely specialised in an aspect of the learning process at the expense of the integration in a learning management system. In recent years, there has been an effort to provide adaptive tools that are integrated in conventional LMS.

The second area relevant to the ideas presented in this paper is the use of third party services. A learning experience may require (or take advantage of) the orchestration of a set of external services.

Here's the cleaned and normalized Markdown:

## Using Third Party Services to Adapt Learning Material

## Introduction

The concept of a Personal Learning Environment (PLE) [8] is discussed in [5], where a new paradigm is outlined to allow IMS Learning Design engines and services to exchange information and react to each other's events. To offer versatile service integration while maintaining platform usability, a pragmatic approach is taken. The proposed solution is based on minimum requirements to be fulfilled by both an LMS (the IMS LD engine) and a service.

Learning Design [3] is a specification that supports the formal description of activity-centered learning. IMS LD allows multiple pedagogical approaches to be modelled as a Unit of Learning (UoL) [9]. A UoL contains the description of all activities, instructions on participant interaction, and properties and conditions to be deployed in a virtual learning context. Learning Design offers adequate formalism to achieve adaptation of educational experiences. The case study presented uses the Generic Service Integration architecture implemented in GRAIL [10], a Learning Design engine integrated in the open source Learning Management System .LRN.

## Generic Service Integration Architecture

The proposed Generic Service Integration architecture provides semantics to include third party services in IMS LD courses, but can be extended to work with any course authoring/delivery framework that supports basic group management, saves course state and reacts to this state.

In GSI, integrating a third party service in a learning course has two requirements:
1. Definition of service usage in the course context
2. Runtime environment capable of enacting service functionality

The proposal consists of two course life-cycle areas:
- Semantic description to capture service behavior
- Execution model to use the service

The vocabulary has been generically defined, assuming each supported service provides specific meaning for used verbs. This allows behavior definition specific to concrete services while allowing alternatives that meet requirements.

Key elements include:

- **Groups element**: Describes grouping policy when participants are unknown during authoring. Groups map to IMS LD roles.
- **Tool element**: Describes required service functionality in abstract notation (set-values, open, close, modify-permissions, etc.). Includes metadata to define suitable service types.
- **Constraints element**: Defines requirements for service behavior, detailing how and when actions must trigger.

## Using Third Party Assessment in a Course

Assessment is considered a weakness in the current IMS LD specification, addressed in different ways [12] [13]. This case study uses Google Forms as a third party assessment service. Google Forms creates web forms with submissions stored in Spreadsheets, accessible via API with SubAuth protocol authentication similar to OAuth [11].

The course consists of two acts:
1. A profiling questionnaire
2. Suggested readings based on questionnaire results

Teaching staff track activity and monitor student results. The profiling questionnaire integration occurs during authoring through groups, tool and constraints elements.

During course instantiation with GSI services:
- Third party services must be allocated and configured
- GSI architecture launches software plugins
- Engine selects best-matching service and configures appropriate plugin
- Plugin mediates service requests
- Service output can be parsed and formatted for property data types

GSI service configuration requires pre-enactment where participants enter before deployment completion.

## Using Third Party Services to Adapt Learning Material

## Interaction and Deployment

Figure 1 shows the interaction among actors during the deployment and enactment phases. At this point, participants must grant permissions to access their personal data in the third party service. In the presented example, only teachers are requested to do so. Some extra adjustments may take place in this phase: the form's target where data is submitted can be only obtained after service deployment, and current limitations of the API imposes manual intervention to fill the proper value.

When the enactment phase starts, interactions with the third party service come about:
- Students insert their responses in the Spreadsheet by using a form
- As the plugin acts as a mediator, an identification token is attached to each response
- Teachers can access at any time to the actual Spreadsheet
- The course engine retrieves all the gathered data (obtained as an ATOM feed) and makes next activity behave depending on the student responses

## Results and Conclusions

The case study was included as part of a regular postgraduate programme in a higher educational institution. A total of 19 students took part in the experience. It is relevant to remark the successful deployment of the experience, with the robust definition of service life cycle phases as the key factor. Further, IMS LD provided a framework where adaptation was possible.

The usage of third party services is potentially much more versatile than the use presented in this article. It would be possible, for example, to use spreadsheet to calculate a formula that takes student results as parameters. This calculated value could be used in the adaptation strategy. The difficulty of IMS LD in the field of data manipulation can be avoided by using a more specialised tool.

The results of the case study show the potential of the deployment infrastructure: services from different vendors can be coordinated by IMS LD courses in order to provide adaptation not restricted to facilities build within the LMS.

Derived from the experience under study, further developments are suggested to improve the GSI model:
- A larger set of plugins needs to be developed
- The use of the model is restricted to supported services, so it is desirable to feature a wider set of choices
- A rise in the available plugins number will bring up the matter of service search facilities
- Keywords, in which the system is based currently, may not be good enough for a larger set of available plugins
- Further research on better search techniques, such as semantic based search, must be accomplished to improve usability of the architecture

## Acknowledgement

This work has been partially funded by the Project Learn3 (TIN2008-05163/TSI) from the Plan Nacional I+D+I and the Spanish National Project FLEXO (TSI-020301-2008-19, www.ines.org.es/flexo).

## References

1. Brusilovsky, P.: Knowledgetree: a distributed architecture for adaptive e-learning. In: Proceedings of the 13th international World Wide Web conference on Alternate track papers & posters, pp. 104-113. ACM, New York (2004)
2. Meccawy, M., Blanchfield, P., Ashman, H., Brailsford, T., Moore, A.: WHURLE 2.0: Adaptive Learning Meets Web 2.0. In: Dillenbourg, P., Specht, M. (eds.) EC-TEL 2008. LNCS, vol. 5192, pp. 274-279. Springer, Heidelberg (2008)
3. IMS Learning Design specification (February 2003), http://www.imsglobal.org/learningdesign/
4. Martel, C., Vignollet, L.: Using the learning design language to model activities supported by services. International Journal of Learning Technology 3(4), 368-387 (2008)
5. de la Fuente Valentín, L., Miao, Y., Pardo, A., Delgado Kloos, C.: A supporting architecture for

Here's the cleaned Markdown:

## Virtual Worlds for Organization Learning and Communities of Practice

## References
1. Koper, R., Tattersall, C. (eds.): Learning Design. A handbook on Modelling and Delivering Networked Education and Training. Springer, Heidelberg (2005)

2. de la Fuente Valentín, L., Pardo, A., Delgado Kloos, C.: Experiences with GRAIL: Learning design support in .LRN. In: TENCompetence Workshop on Current Research in IMS Learning Design and Lifelong Competence Development Infrastructures (2007)

3. OAuth core 1.0, http://oauth.net/core/1.0/

4. Miao, Y., Sloep, P., Koper, R.: Modeling units of assessment for sharing assessment process information: Towards an assessment process specification. In: Li, F., Zhao, J., Shih, T.K., Lau, R., Li, Q., McLeod, D. (eds.) ICWL 2008. LNCS, vol. 5145, pp. 132-144. Springer, Heidelberg (2008)

5. Dalziel, J.: Implementing learning design: the learning active management system (LAMS). In: Proceedings of the 20th Annual Conference of the Australasian Society for Computers in Learning, pp. 593-596 (2003)

## Abstract
An increasing number of organizations have established presences in Second Life or virtual worlds for organizational learning. The types of activities range from staff training, annual meetings, to leadership development and commercial transactions. This paper reviews relevant literature on how virtual worlds, especially Second Life, are utilized for organizational learning. Specific emphases will be on the translation of applicable learning theories into the pedagogical design of virtual worlds. Furthermore, the paper explores how organizations establish virtual communities of practice. Finally, examples of virtual worlds that are established for organization learning are examined.

**Keywords**: virtual worlds, virtual communities of practice, organization learning.

## 1. Introduction
Virtual worlds, which refer to a 3D virtual learning environment that supports multiple learners, have been employed by an increasing number of corporations, universities, and education agencies for learning and training [1]. Virtual worlds have a low barrier-to-entry for content creation, can be programmable, and provide an abundant reusable instructional content [2]. In the last few years, a rapidly growing number of business and higher education institutions have established presences in Second Life and other similar virtual worlds. People enter the virtual worlds in Second Life via an avatar to represent themselves. The avatars can walk, talk, and move around the same way that they would move in real world. Most of the current discussions have focused on the pedagogical applications of virtual worlds for learners in higher education. Although some of the theoretical principles can be applied to learners in both education and business, domain-specific examples based on the shared theoretical principles can provide practitioners in organizations a better framework in adopting virtual worlds for training and development. This paper will focus on theoretical frameworks for organization learning in virtual worlds and examples of workplace learning in virtual worlds, especially in Second Life.

## 2. Literature Review
This section will start with a general discussion on the affordances of virtual worlds and the capabilities of virtual world to support learning. Next, the discussion will examine the theoretical principles that provide the guidelines for learning in virtual worlds.

### 2.1 Affordances of Virtual Worlds
As technology evolves, new technological capabilities can infuse innovative approaches into teaching and learning activities in education and the workplace. In Second Life's virtual world, learners can utilize many of its features to form learning networks, create new identities, and construct new worlds with flexible building tools. In table 1, Jarmon [3] summarized how these new technological features can afford users to transform their experiences in the 3D virtual world.

Table 1. Affordances / Extended Capabilities in 3-D Virtual World of Second Life [3]

| Affordance

## Virtual Worlds for Organization Learning and Communities of Practice

## Adult Learning in Virtual Worlds

Knowles [4] identified five characteristics of adult learners. Zielke, Roome, & Krueger [5] matched the characteristics of adult learning with the features of virtual worlds as summarized below:

- Adults are autonomous and self-directed. Virtual worlds enable independent learning.
- Adults have accumulated a foundation of life experiences and knowledge. Virtual worlds encourage sharing of life experience with others.
- Adults are goal-oriented. Virtual worlds allow goal-setting and increase skill levels for use in work or hobby.
- Adults are relevancy-oriented. Virtual worlds provide the opportunity to check own progress and re-learning if needed.
- Adults are practical and value knowledge that are useful to work. Virtual worlds offer opportunities for problem-solving and immediate application of materials to be learned.

Zielke, Roome, and Krueger [5] presented a case study on how virtual worlds can assist people with disabilities to experience physical activities through their avatars. Activities such as dancing, walking, and running, not possible in real-life, are possible in virtual worlds. The new found capabilities can strongly motivate learners to engage in learning.

## Communities of Practice

The concept of communities of practice (CoP) has been identified by many as a means to effective knowledge management in organization learning [6]. The concept has existed in various parts of the world for centuries. However, it did not become an established theory in organization learning until Lave and Wenger [7] theorized it in their seminal: Situated Learning: Legitimate Peripheral Participation. Wenger [8] defined a community of practice as "groups of people who share a concern or a passion for something that they do and learn how to do it better as they interact regularly" along three dimensions:

- What it is about – its joint enterprise as understood and continually renegotiated by its members
- How it functions – mutual engagement that bind members together into a social entity
- What capability it has produced – the shared repertoire of communal resources (routines, sensibilities, artifacts, vocabulary, styles, etc.) that members have developed over time

Research has shown that virtual communities of practice are emerging [9, 10]. Virtual CoP has been a more standard term to describe a network of individuals "who share a domain of interest about which they communicate online" [11]. There is a difference between a virtual learning community and virtual CoP. The former aims at enhancing the knowledge of the participating members via formal education or professional development. The latter enhances the knowledge of community members via informal learning. Novice members tend to move from peripheral to center through observation of experts and apprenticeship with experienced members.

## Case Examples

University campuses and business have established locations in virtual worlds. Cross and O'Driscoll [12] observed that corporations are using virtual worlds for the following purposes:

- A new level of always-on, real time connectivity for collaboration
- Empowering both customer and employee groups
- Making informal viral learning a core mechanism of transformation

Werner [13] suggested that virtual worlds have become an appealing venue for training and development for the following reasons: (1) engagement, (2) low cost relative to real life, and (3) quick and easy to change. Virtual worlds are engaging because learners can immerse themselves in a 3D environment that has a high-fidelity to the real environment and move freely in-world with an identity of their choices. Virtual Worlds have been commonly used for the following types of workplace learning: (1) 3D demonstration, (2) simulation, and (3) virtual meetings.

### Workplace-Related Examples

#### 3D Demonstration
Palomar West Hospital in Second Life is a prototype of the hospital that is under construction and due to open in 2011. It was designed to provide a preview of the new facility to hospital staff, future patients, media, and the larger medical community [14]. The site can be accessed through the SLRL: http://slurl.com/secondlife/PalomarWest%20Hospital/33/127/34/

####

## Virtual Worlds for Organization Learning and Communities of Practice

## Organization Learning Examples

Center, a library, and areas for community gathering. IBM estimated that the return of investment (ROI) for the Virtual World Conference was roughly $320,000 [16].

## Communities of Practice

The above-mentioned examples presented more concrete and observable cases of organization learning. However, communities of practice for the purposes of organization learning in virtual worlds are limited. Research on business-related virtual CoP in virtual worlds is still a relatively new area.

As more organizations establish presences in virtual worlds, more research data will provide a better understanding of the processes and outcomes. Here is a small sample of professional organizations that serve as the venues for virtual CoPs:

- American Society for Training and Development (ASTD): http://slurl.com/secondlife/ASTD%20Island/113/84/23
- International Society for Technology in Education (ISTE) Islands: http://slurl.com/secondlife/ISTE%20Island/93/83/30
- New Media Consortium (NMC) Campus: A large consortium of universities, organizations, and museums that supports events, classes, demonstration, and art exhibits. http://slurl.com/secondlife/NMC%20Campus/136/91/23
- Gronstedt Group: Weekly "Train for Success" sessions bring training and communication professionals globally to explore the new development in leading corporations, http://slurl.com/secondlife/Wolpertinger/161/82/51

## Conclusion and Future Trends

In this paper, the applications of adult learning theory and communities of practice to organization learning in virtual worlds were reviewed. Examples of workplace-related learning were introduced. Although virtual worlds have been in existence for decades [17], it was not until the introduction of Second Life to the public in 2003 that establishing communities in virtual worlds became a norm in the academic and the business world. It is not clear how organizations can be more effectively exploring the opportunities offered by virtual worlds for organization learning. More studies on how communities of practice in virtual worlds can contribute to knowledge construction, collaboration, and motivation are needed. What will the future hold for organization learning through virtual CoP in virtual worlds? In addition to the affordances of technology and the usability of virtual worlds, it is also important to cultivate a sense of belonging to encourage information sharing, collaboration, and interaction. The development of virtual worlds will be as exciting as the World Wide Web in the 90s.

## References

1. The New Media Consortium. The Horizon Report. 2007 Edition (2007), http://www.nmc.org/horizon/2007/report
2. Mason, H.: Experiential Education in Second Life. In: Livingstone, D., Kemp, J. (eds.) Proceedings of the Second Life Education Workshop, pp. 14–18 (2007), http://www.simteach.com/slccedu07proceedings.pdf
3. Jarmon, L.: Learning in Virtual World Environments: Social Presence, Engagement, & Pedagogy. In: Encyclopedia of Distance and Online Learning. IGI Global (2008)
4. Knowles, M.S.: Andragogy in Action. Applying modern principles of adult education. Jossey Bass, San Francisco (1984)
5. Zielke, M.A., Roome, T.C., Krueger, A.B.: A Composite Adult Learning Model for Virtual World Residents with Disabilities: A Case Study of the Virtual Ability Second Life® Island. Journal of Virtual Worlds Research 2 (2009), http://jvwresearch.org/
6. Kimble, C., Hildreth, P.: Communities of Practice: Going One Step Too Far? http://ideas.repec.org/p/wpa/wuwpio/0504008.html
7. Lave, J., Wenger, E.: Situated learning: Legitimate peripheral participation. Cambridge University Press, Cambridge (1991)
8. Wenger, E.: Communities of

## A Methodology and Framework for the Semi-automatic Assembly of Learning Objects

**Authors:** Katrien Verbert¹, David Wiley², and Erik Duval¹

¹Dept. Computerwetenschappen, Katholieke Universiteit Leuven, Celestijnenlaan 200A, B-3001 Leuven, Belgium  
²Instructional Design and Technology Department, Brigham Young University, Provo, UT, USA

## Abstract

One of the major obstacles in developing high quality content for learning is the substantial development cost and effort. In addition, the return on investment is often low, as developed learning materials are difficult to reuse and adapt to new and different educational contexts. In this paper, we present a semi-automatic content assembly methodology to automate, at least partially, the reuse of existing learning content in high quality and effective learning sequences. In addition, we present a case study that integrates the approach into the LAMS learning design environment.

**Keywords:** learning object reuse, learning object metadata, learning design

## 1. Introduction

Many existing course documents merge the representation of content and the instructional approach [1]. Such hardwired pedagogy restricts the options for teaching and learning, both in terms of reusability and adaptation of learning sequences. Typically, teachers create their teaching strategies and content from scratch or reuse parts of existing course documents by ad-hoc and time-consuming copy-and-paste actions. In addition, adaptation to individual learning or teaching styles, background, experiences, interests or preferences is generally not possible, unless learning content is specifically designed for personalization purposes [2].

In this paper, we present a semi-automatic content assembly methodology for the generation of learning sequences tailored to different pedagogical approaches, based on the explicit design of these sequences by a teacher. The assembly framework employs a teacher model, an instructional model and a domain model to enable the focused retrieval and aggregation of learning resources into learning sequences. Learning resources are retrieved through the GLOBE network of educational repositories [http://globe-info.org/] and from various community driven websites, such as WikiAnswers.com, ProProfs.com and Wikipedia. The assembly framework is described in the next Section. We present a case study that integrates the approach into the LAMS [3] learning design environment in Section 3. Related work is discussed in Section 4, followed by conclusions and remarks on future work.

## 2. Content Assembly Framework

The content assembly framework supports the selection and assembly of existing learning resources. The framework employs the following models to enable the focused retrieval and aggregation of resources:

- The instructional model captures the semantics of the pedagogical strategy employed by a learning sequence and is based on [4]. Narrative structures within this model outline the flow of concepts of a particular learning design strategy and are used as templates when assembling learning sequences. An example is an inquiry based learning strategy that sequences activities like "answer questions", "vote on a list", "discuss responses", "read expert view", "discuss expert view" and "personal reflection".

- The domain model represents the knowledge domain of a course. It includes concepts outlined in the objectives of a course and their interrelationships.

- The teacher model defines teacher attributes to enable the personalized aggregation of learning resources [5]. The model includes attributes for representing the level of expertise of the teacher, interests and activities, teaching strategy preferences, background, and presentation styles (Fig. 1).

The assembly engine maps instructional, domain and teacher concepts to PLQL queries and federates the queries to SQI-enabled repositories. The approach is exemplified in [6]. PLQL [7] is primarily a query interchange format for repositories. SQI [8] is a query transport standard that is widely used within the technology enhanced

## A Methodology and Framework for the Semi-automatic Assembly of Learning Objects

## Introduction
The GLOBE alliance [http://globe-info.org/] builds on the SQI standard to enable worldwide access to learning repositories.

Moreover, to enable retrieval of relevant content resources on the Web, several SQI wrappers were built on top of community driven websites that host large amounts of content, such as WikiAnswers.com, ProProfs.com and Wikipedia. The wrappers retrieve both relevant pages and relevant fragments within the pages. The engine typically exploits the structure of pages to identify content fragments that are reusable, such as individual questions and answers of multiple choice questions or animations within HTML pages. Simple screen scraping approaches are employed to retrieve relevant parts of domain specific websites. Depending on the granularity of the narrative concept, single assets or larger compositions are retrieved, such as single questions versus entire surveys.

## LAMS Case Study
We integrated the assembly approach into the LAMS Learning Activity Management System [3] that integrates different environments for authoring, running and monitoring learning designs. The LAMS authoring environment enables authors to sequence different types of learning activities, such as discussion activities and web polls, as illustrated in Fig. 2. In the next step, learning resources can be added to the learning activities.

We have extended the LAMS authoring environment to automate, at least partially, this process. An author can create a sequence of activities or reuse an existing learning design. Suppose she wants to teach the concepts of velocity and acceleration in an inquiry based learning strategy that sequences the activities "answer questions" (a1), "vote on a list" (a2), "discuss responses" (a3), "read expert view" (a4), "discuss expert view" (a5) and "personal reflection" (a6). For activities a1 and a4 that have associated learning resources, the assembly engine generates content suggestions based on domain concepts (velocity and acceleration), instructional concepts (answer questions and read expert view) and teacher attributes (in our current prototype: language, familiar measures and weights, and typical student age range). Learning resources are retrieved on-the-fly from learning object repositories and online Web sources and shown in the content suggestions area, as illustrated in Fig. 2.

To obtain a first indication of the quality of the generated content suggestions, a small-scale experiment was conducted in April 2009 at Brigham Young University, during a post-doctoral stay of the first author of this paper. Six staff members of the Instructional Design and Technology department and six students in history and social sciences teaching were asked to reuse an inquiry based sequence and to rate the quality of the generated content suggestions. Two dimensions of quality were assessed: relevancy and accuracy. Relevancy measures whether the content suggestions are applicable and helpful for the task at hand. Accuracy is defined as the extent to which the content is correct, reliable and free of error. The mean for both dimensions on a 7 point scale was 6.5833 (0.51493 std dev.). Although these results are only preliminary, they indicate that participants found the generated content highly relevant and accurate.

## Related Work
Reuse is considered to be an effective strategy for building high-quality learning sequences [9]. Whereas both basic and applied research have been conducted in the area of decomposing content into reusable components, little research is available on the automated reuse and assembly of content. In contrast, numerous research efforts have been made to support the development of adaptive personalized courses based on content that has been designed specifically for the course at hand [2]. Typically, multiple models are employed to support adaptivity. Dagger et al. [4] identify an instructional model, a learner model, a teacher model and a domain model. The ADAPT project [10] identifies the context of use, content domain, instructional strategy, instructional view, learner model, adaptation model and detection mechanism. The GRAPPLE project [11] identifies a domain model, a user model, a context model, an instruction model and an adaptation model. In this paper, we shifted the focus from the learner to the teacher, as automated assembly

Here's the cleaned Markdown:

## References

1. Bush, M.D., Mott, J.D.: The Transformation of Learning with Technology. Learner-Centricity, Content and Tool Malleability, and Network Effects. Educational Technology Magazine (March-April 2009)

2. Vercoustre, A., McLean, A.: Reusing Educational Material for Teaching and Learning: Current Approaches and Directions. International Journal on E-Learning 4(1), 57-68 (2005)

3. Dalziel, J.R.: Implementing Learning Design: The Learning Activity Management System (LAMS). In: Crisp, G., Thiele, D., Scholten, I., Barker, S., Baron, J. (eds.) Interact, Integrate, Impact: Proceedings of the 20th Annual Conference of the Australasian Society for Computers in Learning in Tertiary Education, December 7-10, Adelaide (2003)

4. Dagger, D., Wade, V., Conlan, O.: Personalisation for All: Making Adaptive Course Composition Easy. IFETS Journal of Educational Technology and Society, Special Issue on Authoring of Adaptable and Adaptive Educational Adaptive Hypermedia (2005)

5. Virvou, M., Moundridou, M.: Adding an Instructor Modelling Component to the Architecture of ITS Authoring Tools. International Journal of Artificial Intelligence in Education 12, 185-211 (2001)

6. Wiley, D.: Learning objects and the new CAI: So what do I do with a learning object (1999), http://opencontent.org/docs/instruct-arch.pdf

7. Ternier, S., Massart, D., Campi, A., Guinea, S., Ceri, S., Duval, E.: Interoperability for Searching Learning Object Repositories: The ProLearn Query Language. D-Lib Magazine 14(1/2) (2008)

8. Simon, B., Massart, D., van Assche, F., Ternier, S., Duval, E., Brantner, S., Olmedilla, D., Miklos, Z.: A Simple Query Interface for Interoperable Learning Repositories. In: Proceedings of the 1st Workshop on Interoperability of Web-based Educational Systems, pp. 11-18 (2005)

9. Schluep, S.: Modularization and structured markup for web-based learning content in an academic environment. Shaker Verlag, Aachen (2005)

10. Garzotto, F., Cristea, A.I.: ADAPT: Major design dimensions for educational adaptive hypermedia. In: Proc. of ED-MEDIA 2004, June 21-26, pp. 1334-1339 (2004)

11. De Bra, P., Pechenizkiy, M., van der Sluijs, K., Smits, D.: GRAPPLE: Integrating Adaptive Learning into Learning Management Systems. In: Proceedings of World Conference on Educational Multimedia, Hypermedia and Telecommunications 2008, pp. 5183-5188. AACE, Chesapeake (2008)

12. Reload Project, http://www.reload.ac.uk/ (accessed April 20, 2009)

13. Van Rosmalen, P., Boticario, J.: Using Learning Design to Support Design and Runtime Adaptation. In: Koper, R., Tattersall, C. (eds.) Learning Design. A Handbook on Modelling and Delivering Networked Education and Training, The Netherlands, pp. 291-301. Springer, Heidelberg (2005)

14. Van der Vegt, W.: CopperAuthor. Heerlen:

Here's the cleaned Markdown:

## Search and Composition of Learning Objects in a Visual Environment

Complex topic [5]. In order to palliate these two weaknesses, several models have been proposed which enrich the semantic dimension of standards. For example, SIMBAD [6] includes semantic models of the learning domain, learners and composed LOs. The search for an LO may be done by a learner or by a teacher: learners in order to learn a concept or a lesson; teachers in order either to use an LO directly during their lessons or to reuse it with others, thus creating a new LO. Nevertheless, considering the inner complexity of LOs, the search, reuse and annotation of complex LOs are also complex. Existing tools are inappropriate: they do not provide any support to authors (no clear visualization of the components of an LO, no rich query language, no composition language using existing LOs [7]). To our knowledge, a few works provide some answers to these problems: [8] in which composition is not taken into account and [9], a project which is still under study. We propose thus an iterative approach to search for LOs: the end user browses a set of LOs and within the inner structure of each one, chooses the ones he/she is interested in. The end user composes his/her own LO, as in the case of a teacher. An iterative, navigational, query language is a complex language. It is not conceivable to propose a textual interaction to end users. Moreover, query results are complex: the number of LOs may be too great to be presented as a list, the inner structure of an LO may be complex and recursive. To resolve these problems we propose a sequence of rich and intuitive visual interfaces.

This paper is organized as follows: Section 2 describes the SIMBAD model we used to build our system. Section 3 presents the system architecture, describing the different user interfaces, the query engine, the composition validation and the dynamic annotation. Section 4 concludes and proposes perspectives to our work.

## SIMBAD Model

The SIMBAD model includes semantic models of the knowledge domain (domain ontology), of the learner (her/his knowledge, preferences) and of the LO (content, prerequisites, knowledge gained at the end of the learning). An LO may be atomic or complex. A complex LO is built by applying (if necessary, recursively) composition operators on LOs (atomic or complex). The composition of an LO is a graph. This graph can only have one entry (one LO) but may have several exits. We have chosen five operators, three simple operators (SEQ for the sequence, PAR for parallelism, ALT for alternative) and two more complex operators (AGG for aggregation of two LOs and PROJ to define an LO by projection of another). For example, let R10 be a complex LO; its composition graph is defined by: R10 = R1 SEQ (R5 ALT (R2 SEQ (R3 PAR R4))). R1 is atomic; R2 to R5 are complex.

## System Architecture

The system architecture is presented in Fig 1. The following scenario illustrates the utilization of the different components. A teacher searches for an LO in order to compose a new course. She/He specifies her/his research criteria in the query interface (Fig. 1, n°1). This query is sent to the query engine which interacts with the knowledge server and sends back the answers to the result visualisation interface (Fig. 1, n°2). At this stage, the teacher may explore the structure of the LO (Fig. 1, n°3). The teacher may copy/past each LO or a component of the LO which she/he wants to keep (Fig. 1, n°2 and 3) and it is sent to the composition editor (Fig. 1, n°4). When she/he validates a composition, the validation module checks its validity and annotates it automatically. The result of these annotations is propose

Here's the cleaned and normalized Markdown:

## Learning Object Search and Composition in a Visual Environment

The user builds their mental model of the ontology step by step, with a reasonable cognitive load. The progressive perception of the ontology throughout their search allows them to learn progressively, based on their interests. Fig. 2 illustrates the initial visualization of the query results and then the navigation (zoom) on this result. The LO composition interface (n°5) is a free editor. The author can search for LOs or parts of LOs by using search and LO composition interfaces (n°2 and 3). They can select them and drop them into their composition space. They can then define operators between the LO and thus create a new LO which will be added to the system.

![Results windows, initial (left) and after a zoom (right)](Fig. 2)

### Query Processor

The query processor takes queries from the user interface (n°1) and translates them to be sent to the Ontobroker knowledge server. Ontobroker takes queries and commands to add facts to the knowledge base specified in F-Logic. Facts correspond to semantic descriptions of LOs. Queries contain criteria specified by the user to search for LOs.

When the user searches for an LO, each input of the user interface form is verified: if an input is filled, the associated criteria are used to generate an F-logic query. For example, query R1 allows searching for LOs having a SIMBAD metadata description. In R1, O is the variable representing an LO; this variable is instantiated and returned. Suppose that, facing the results of R1 processing, the user refines the search criteria filling the input title of the form. Query R2 is then obtained.

R1: "FORALL O,X,N,M<- N#O[N#hasMetadata->N#X:N#SIMBAD]@M""

R2: "FORALL O,X,N,M <- N#O[N#hasMetadata->N#X:N#SIMBAD]@M" AND EXISTS G1,T N#X[N#hasElement->N#G1:N#General[N#title->T]]@M AND contains(T,\""+title+"\")@M".

OntoBroker returns the result of a query to the query processor. Let O1 a LO belonging to the result. O1 may be described in the following way:

[O1, S1, "\"http://www.owl-ontologies.com/lom.owl#\"",""\"http://www.owl-ontologies.com/\"#'lom.owl'"]

### Validation and Annotation of Composed LO

The composition of an LO is performed by following a composition pattern (generic graph or composition model) or on the fly. The first case is safer because the pattern proposed by an expert or a teacher is normally valid while the second case may entail problems of composition validity. We focused on the second problem of composition validity with a particular interest for free composition.

An LO is valid if its composition graph complies with a set of constraints to ensure the coherence from a structural, semantic and pedagogic point of view. The structural validation checks whether the topography of the graph is correct, by controlling, for example, that the graph has only one start node. As a result, using graph patterns implies structural validity. The more complex semantic validation examines the coherency in the sequencing of the LO. It is necessary, for example, to verify that the level of acquisition of the LO increases with the progression in the graph and not the opposite, or a learner having the required prerequisites has access to at least one path of the graph. The semantic validity is never assured, whatever the composition type (pattern-based or free composition). The pedagogic validation is based on the accordance of the composition graph with a known learning theory. This latest type of validation is not implemented yet.

The validation phase is followed by a phase of annotation before storing the new LO in the

Here's the cleaned Markdown:

## A Framework to Author Educational Interactions for Geographical Web Applications

The Nhan Luong, Thierry Nodenot, Philippe Lopistéguy, and Christophe Marquesuzaà

IUT de Bayonne Pays Basque, LIUPPA-DESI, 2 Allée du Parc Montaury  
64600 Anglet, France  
{thenhan.luong,thierry.nodenot,philippe.lopisteguy,christophe.marquesuzaa}@iutbayonne.univ-pau.fr

## Abstract

This paper focuses on the production of authoring tools that teachers may use to prototype interactive geographical web applications. We present some computational models and a toolset that we designed to address some needs of teachers trying to make use of particular localized documents called "travel stories". Our research challenge is to enable teachers to design interaction scenarios for such a domain, avoiding any programmer intervention. In the design process, the teacher typically faces three activities: (a) Identification of candidate documents, (b) Evaluation of the adequacy of the document and (c) Production of the learning application making use of the selected document. In this paper, we mainly focus on the (c) Production activity. We highlight the necessary use of an "agile" approach to shorten as much as possible the delay between the design and the evaluation step of a prototype. To address the technological challenges raised by such an aim, we present WIND framework and we discuss its capabilities while considering some examples of interactive scenarios generated with WIND framework.

## 1 Introduction

Educational scenarios are particular design artifacts that take advantage of current enhancements in the domain of "Science of Design" [1]. Research works dedicated to the design of educational scenarios propose new paradigms, concepts, approaches, models and theories that promote stronger bases for the design of TEL environments [2]. These bases are foundations enabling to improve the processes of both coding, evaluating and maintaining such type of application. Recent works focus on:

- the definition and role of a pedagogical scenario [3, 4]
- the definition of visual instructional languages [5] and executable [6] scenarios
- the definition and the evaluation of methodological principles allowing designers to produce and to re-use such scenarios [7]

## References

1. Beck, R.: Learning Objects Collections (2007), http://www.uwm.edu/Dept/CIE/AOP/LO_collections.html
2. Duval, E.: The Ariadne Knowledge Pool System. Communications of ACM 44(5), 72–78 (2001)
3. Learning Technology Standard Committee: IEEE Standard for Learning Object Metadata, IEEE Std 1484.12.1
4. Advanced Distributed Learning Initiative (ADLI). Sharable Content Object Reference Model. The SCORM Content Aggregation Model. V. 1.2. adlnet.org/ (2007)
5. Harris, M.C., Thom, J.A.: Challenges facing the retrieval and the reuse of learning objects. Workshop on learning object repositories as digital libraries: current challenges. In: 10th European Conference on Digital Libraries (ECDL) Workshop (2006)
6. Duitama, F., Defude, B., Bouzeghoub, A., Lecocq, C.: A framework for the generation of adaptative courses based on semantic metadata. Multimédia Tools and Applications 25(3), 377–390 (2005)
7. Lopes Gançarski, A., Bouzeghoub, A., Defude, B., Lecocq, C.: Iterative search of composite learning objects. In: IADIS International Conference WWW/Internet, Vila Real, Portugal (October 2007)
8. Ramzay, J., McAteer, E., Harris, R., Allan, M., Henderson, J.: Flexible, structured support for the reuse of online

Here's the cleaned and normalized Markdown:

## A Framework to Author Educational Interactions

Nowadays, there is also a strong emphasis on the process of transforming an abstract scenario (that a teacher is able to understand and to design by himself) into an executable scenario (that an execution infrastructure can process). Several works promote model-driven engineering techniques and tools to fully integrate the functions supported by the chosen infrastructure. This approach is interesting not only because of underlying model-driven scientific challenges [8], but also because model-driven transformations must respect educational constraints specified in the scenario produced by the teacher [9].

Most of identified works are still in progress and it is thus difficult to know if they will soon provide teachers with toolboxes fitted to the design and the implementation of constructivist learning situations. Moreover the complexity of required technologies may put the teacher out of the play (when the educational scenario becomes very detailed, when the scenario is deployed on a target infrastructure…). In most works, the author is a pedagogic engineer. Such designer profiles can be found in e-learning firms but not in most classrooms and teaching institutes: though they are not computer-scientists, teachers must fully handle the design process (from the scenarization step to the deployment step).

This paper focuses these particular teachers: we propose a framework that they may use to edit/prototype and to evaluate by themselves an educational scenario. This framework targets the scenarization of interactive resources to be used in inquiry learning activities [10] for a specific applied domain: travel stories.

## Background and Objectives

The DESI group aims to propose software architectures and tools to re-vitalize localized documents that generally rest in the depth of archives, museums and libraries.

In particular, travel stories offer very challenging revitalization objectives because tourists and teachers could benefit from e-services developed from such localized documents. Travel stories have intrinsic characteristics that make them good teaching-resource candidates. A travel story is a sort of text whose author tells what he discovered while travelling through a territory or a country. On the one hand, the author tries to very precisely present the places he/she visited; on the other hand, he/she tries to tell the events that occurred during his/her trip, he/she reports on his/her activities and explorations. Indeed, the travel story aims at using words to describe the travel reality: the travel story is told day after day, the duration of the trip is often explicitly written in the text in conjunction with the travelled locations. Moreover, travel stories provide an opportunity to ground the design and the operation of systems with text, map and calendar components that require extensive human-machine interaction.

Following the experiment available at http://erozate.iutbayonne.univ-pau.fr/forbes2007/exp/, we proposed three authoring steps to assist as much as possible the process of authoring educational applications making use of travel stories. The first teacher's task consists in selecting in a corpus of documents the travel stories that deal with geographical areas [11, 12]. The second task consists in evaluating the adequacy of the document as regards of teacher's pedagogical aims [13]. The third teacher's task consists in producing a highly interactive application based on the semantics of the validated travel story. To this end, the teacher needs an authoring environment that enables him/her to quickly evaluate/correct his/her conceptual choices. This paper focuses on this third task.

Following A. Gibbons' works [14, 15], our approach aims at breaking such a design dichotomy/gap for the particular case of educational applications making use of travel stories. Indeed, Gibbons' instructional design layers are: content, strategy, control, message, representation, media-logic, data-management. Design of each layer can be considered separately from the other layers, providing an important modularization to the design effort. Applied to our application domain (study and design of educational applications making use of geographical information embedded in travel stories), Gibbons' design theory leads us to design interactions at four levels of abstraction, as suggested in [16]:

1. The most elementary level deals with the data and geographical information embedded/retrieved in a text (cf. the data-management, media-logic and representation layer) that may

Here's the cleaned Markdown:

## A Framework to Author Educational Interactions

### Application Design

Evaluation step is used to check/criticize pedagogical choices. We define the concept of an "agile" design tool as a piece of software supporting such an approach. An "agile" method can be defined as a design approach not only by fully implying the end-user along the whole process but also by rapidly integrating their requirements in a technical solution [17]. Final quality of the generated application is ensured thanks to a continuous control throughout the production process.

Each teacher's pedagogical choice must be fully and automatically traduced into executable code. This constraint implies the use of an applicative model as a design framework. An applicative model is an application generic model that may be instantiated throughout the design step; each instance of this model is then automatically traduced into executable code. Our proposed design approach is based on a model-driven approach [18, 19] which is also used for TEL engineering [8]. We distinguish three levels:

1. The generic applicative model describes the core concepts of the application classes.
2. The application model created by the teacher during their design step. This model is an instance of the previous generic model. It describes the characteristics of the application desired by the teacher.
3. The code generated from the application model designed by the teacher.

The WIND generic applicative model [20] defines the core of the interactive web applications that a teacher will be able to produce. An interaction may be simply defined as a triple <area, event, reaction>. Interaction is the central mechanism which characterizes the applications we wish to develop. The expressive capacity of the interactions may be declined to express not only simple interactions but also more complex ones.

This WIND generic applicative model is described in a WIND-XSD schema (available at http://erozate.iutbayonne.univ-pau.fr/Nhan/WINDv2/schema.xsd). Each concept of the model is described as a specific element. This XSD schema helps to instantiate WIND generic applicative model into XML format that describes the interactions of a WIND application model. That is to say it permits to describe a web-based application embedding textual, map and calendar interactive components.

Taking advantages of JavaScript, WIND generic applicative model is supported by a WIND-API that implements the different classes as well as their associated methods. WIND-API proposes a homogeneous layer built on lower level APIs, specialized in the handling of text, map and calendar.

To avoid any programmer intervention in the teacher activity devoted to the application production, we have developed a JavaScriptCodeGenerator. The JavaScriptCodeGenerator can parse any WIND-XSD compliant data file (e.g. a WIND application model description) in order to generate JavaScript code for interactions that WIND API can execute. These technologies enable us to shorten the delay between the design and the evaluation step of a prototype. The implementation of WIND interactions may simply be done with four main steps:

1. Defining the components of the application and their characteristics.
2. Defining reactive areas for each component defined in the previous step.
3. Defining possible reactions for the reactive areas.
4. Defining interactions upon previously defined reactive areas and reactions.

### Discussion and Future Directions

WIND is an operational framework that allows both describing and implementing interactions of web applications mixing texts, maps and calendars. This framework promotes an agile process fitted to designers without computer-science skills: its characteristics make easier the description of interactions. Yet, WIND still needs further developments. We must extend our current framework because WIND does not completely address the design of the four interaction layers presented in section 2.

Current version of WIND framework correctly addresses the data-layer: it enables designers to manage sensible parts corresponding to the main concepts (places, dates, movement-verbs, etc.) automatically retrieved in travel stories. As a consequence, interaction design can take advantage of these specific sensible parts. However, we still need to extend WIND framework to manage the same way more complex concepts of an itinerary.

Current version of WIND framework enables a designer to specify

## References

1. NSF 2007, Science of Design: National Science Foundation 07-505, Program Solicitation (2007), http://www.nsf.gov/publications/pub_summ.jsp?ods_key=nsf07505

2. Tchounikine, P.: Pour une ingénierie des Environnements Informatiques pour l'Apprentissage Humain. Information Interaction Intelligence 2(1), 59–93 (2002)

3. Pernin, J.-P., Emin, V., Guérayd, V.: ISiS: An Intention-Oriented Model to Help Teachers in Learning Scenarios Design. In: Second European Conference on Technology Enhanced Learning, pp. 338–343 (2008)

4. Dillenbourg, P., Tchounikine, P.: Flexibility in macro-scripts for computer-supported collaborative learning. Journal of Computer Assisted Learning 23(1), 1–13 (2007)

5. Nodenot, T.: Scénarisation pédagogique et modèles conceptuels d'un EIAH: Que peuvent apporter les langages visuels? International Journal of Technologies in Higher Education 4(2), 85–102 (2007)

6. Ferraris, C., Martel, C.: LDL for Collaborative Activities. In: Botturi, L., Stubbs, T. (eds.) Handbook of Visual Languages in Instructional Design; Theories and Practices, pp. 226–253. IDEA Group, Hershey (2007)

[References 7-20 continue in same format]

## Temporal Online Interactions Using Social Network Analysis

Álvaro Figueira

Universidade do Porto, Faculdade de Ciências, DCC - CRACS
Rua do Campo Alegre, 1021/1055, 4169-007 Porto, Portugal
arf@dcc.fc.up.pt

## Abstract

Current Learning Management Systems generically provide online forums for interactions between students and educators. In this article we propose a tool, the iGraph, that can be embedded in Learning Management Systems that feature hierarchical forums. The iGraph is capable of depicting and analyzing online interactions in an easy to understand graph. The positioning algorithm is based on social network analysis statistics, taken from the collected interactions, and is able to smoothly present temporal evolution in order to find communicational patterns and report them to the educator.

**Keywords**: Visualization of online interaction, Web-based learning, Automatic graph drawing, Temporal analysis, Online discussion forums.

## Introduction

Characterizing interactions of a group that usually communicates through an online context is frequently not a simple task. We do recognize that currently written communication has assumed particularities (emoticons, capitalizations, exaggerated punctuations) that were not considered in the past.

We propose a tool to help characterizing online interactions depicting them in the form of a graph that in turn is built with the help of "social network analysis" indicators. The proposed graph represents all interactions occurred up to the drawing moment. This characteristic allows building a "history" of interactions, drawing each network state in a singular frame. A slideshow of all available frames can then provide additional insight for the teacher as he may analyze the class according to different key moments and observe its progress over time, such as actors that maintain leadership roles during most of the time, or actors that shift between more or less active positions in different moments.

## Online Social Network Analysis 

Social Network Analysis (SNA) consists in the "mapping" and analysis of the relations between people, groups or organizations, through a visual representation and also a mathematical analysis. The visual representation results in a network that includes a set of actors that interact among themselves as well as information flows.

Here's the cleaned Markdown:

## Temporal Online Interactions Using Social Network Analysis

The illustration of this network is represented as a Graph, with actors as vertices and interactions as a set of ties, between two or more vertices, represented by lines. We use the event "reply to" a previous posted message as an atomic interaction. The counting process of the answers that were received and sent begins at the first "reply to" in a discussion. The analysis process in SNA generally consists in three perspectives. The first reports to the actors' positions individually; the second, to group action and, the third to the group or community as a whole.

Centrality measures are seen as fundamental attributes of a social network. We assumed Freeman's [1] procedures to calculate centrality. According to Hanneman & Riddle [2], many Sociologists argue that one of the basic properties of social structures is power. In our study, for a reason of semantic proximity, we will also use this concept intending that it could also be understood as "influence". Scott [3] also recalls the need to carefully choose indicators and how to apply them keeping in mind the understanding of their properties and if they are adequate and relevant for the study that is being conducted. For the iGraph we used three indicators: Centrality Degree, calculated by summing the vertices that are adjacent to vertex i. Actors who obtain higher results in this indicator may be characterized by being more autonomous and having more influence in the network. Clique identification in a network [1],[2] allows us to locate group of actors where all possible connections are present and expand our comprehension of the group at a global range. Density is one of the mostly used indicators [3],[4]. This indicator reveals, in percentage, the high or low connectivity of a network and is defined as the ratio between the existing and the possible connections. Centralization Index is an indicator for analyzing the network as a whole and is expressed in percentage. It is characterized by the existence of an actor that clearly plays a central role, while being connected to all the vertices in the network.

## Building a History

The motivation for adding history is to understand how the online community evolved along time. Although a graphical representation of the current state of an online community is of much use, that representation lacks the temporal dimension which may hide important aspects of interaction that occurred in past. For example, it is possible that at some time during the interaction, we could find actors that played important roles during the development of the interactions and then their leadership was overcome by two or three other actors, which in present time makes their past importance much reduced.

### Drawing the iGraph

There is a vast literature and research area concerning automatic graph drawing [5]. A variety of layout algorithms that are based on graph theoretical foundations have been developed in the last three decades [6]. In 1963 Bill Tutte wrote a paper: How to draw a graph [7] in which he suggested an algorithm that places each vertex into the center of its neighbors. A long way of research has been pursued since then. However, some basic criteria, supported by psychology studies [8][9], still hold: vertices displaying the objects should not overlap each other, nor the lines representing the edges. Moreover, one would want to minimize the edge crossings.

Our algorithm evolves from a set of basic principles/premises to improve readability and ease of understanding:
- distribute vertices avoiding overlapping
- information hubs should tend to be placed near the center
- minimize the crossing of edges and of vertices
- group cliques
- dense net tends to spread equally

According to those principles, we built a model of "orbits" in which we place the vertices equally spaced in clockwise manner. The outer orbit is placed near the border of the drawing canvas. In Fig.4 we depict this model.

The orbit of each vertex is computed according to its centrality degree (the greater the degree, the closer to the center will be the orbit). The centralization index is useful to compute the radius of the closest orbit to the center (a centralization index of 100% means that the smallest orbit will have radius of 0). The net density parameter is useful to set the number of possible orbits (a dense net, will have more orbits

## Temporal Online Interactions Using Social Network Analysis

## Graph Layout and Temporal Analysis

The coherency of graph layout between different frames is ensured by establishing two important premises:
- The minimum temporal slot for each time frame is the "reply to" interaction
- The algorithm for graph drawing must be deterministic to create an illusion of movement and vertex positioning continuity

Taking the "reply to" relation, the following may happen:
- The network density changes
- The centralization index changes  
- Two centralization degrees change
- A new Clique is formed

In situations where network density or centralization degrees change, despite vertices changing size, the illusion of continuity is preserved. Density changes create more orbits and trigger new vertex-to-orbit assignments while preserving continuity. Clique formation may lead to creation of a neighbor Clique that continuously increases in size, potentially "absorbing" the other Clique. If this dissolves the previous Clique in favor of the new one, a new vertex permutation must be found. This situation impacts continuity between frames and requires local animation of involved vertices.

## Example Interaction Analysis

Table 2. Example of interaction between three actors
```
Posts  0  1  2  3  4  5  6  7  8  9  10 11 12
1      A              A     B  A     
2         B     B        B     B     B
3            C              C  C  A
```

According to interactions listed in Table 2, there are 11 interactions to consider from post 2 to post 12. Figure 6 shows four time frames of the temporal evolution of the iGraph, depicting frames at "momentum zero" (T=0) and interactions 5, 8, and 12 (final iGraph).

The temporal evolution in the iGraph provides key insights: Looking only at time frame 12, one might conclude actor C was absent from discussions while actor B had a leadership role. However, observing the evolution shows that by interaction 5, actor B had much smaller importance and was actually the "outsider". Only by interaction 8 did all actors have equal interactions, after which actor B took the lead.

## The Interface

The iGraph system mines LMS forums for posted messages and presents an interface embedded in a web page. The Centrality Degree is divided into:
- Input cases: number of actors responding to an actor
- Output cases: number of actors to which an actor replies

The Centralization Index is also divided into input and output cases, expressed as percentages. Isolated nodes are included in the graph as nodes without links to others. The interface allows selection of any forum within the current online course and the iGraph mode. It can also show cliques of n vertices. In the current version, actors are assigned letters resolved to actual names in a box at lower right.

## Conclusions

The system provides automatic characterization of online forum interactions, capable of showing current state or frame-by-frame analysis from forum inception. Development focused on achieving continuity between frames through positioning algorithms and frame transition methodology. While finding optimal vertex positioning in reasonable time remains impossible, the algorithm achieves a sub-optimal, aesthetically pleasing and readable layout that is difficult to improve manually.

## Temporal Online Interactions Using Social Network Analysis

## References

1. Freeman, L.C.: Centrality in Social Networks: Conceptual Clarification. Social Networks 1, 215–239 (1978), http://moreno.ss.uci.edu/27.pdf

2. Hanneman, R.A., Riddle, M.: Introduction to Social Network Methods. [electronic version] (2005), http://faculty.ucr.edu/~hanneman/

3. Scott, J.: Social Network Analysis: a Handbook. Sage, London (1997)

4. Borgatti, S.P., Everett, M.G.: Network Analysis of 2-Mode Data. Social Networks, pp. 243–269 (1997), http://www.analytictech.com/borgatti/papers/borgatti%20-%20network%20analysis%20of%202-mode%20data.pdf

5. Jünger, M., Mutzel, P.: Graph Drawing Software. Springer, Heidelberg (2004)

6. Nishizeki, T., Rahman, S.: Planar Graph Drawing. Lecture Notes Series on Computing, vol. 12. World Scientific, Singapore (2004)

7. Tutte, W.T.: How to Draw a Graph. Proceedings of the London Mathematics Society 13, 743–768 (1963)

8. Purchase, H.: Which aesthetic has the greatest effect on human understanding? In: Di Battista, G. (ed.) GD 1997. LNCS, vol. 1353, pp. 248–261. Springer, Heidelberg (1997)

9. Purchase, H., Allder, J.-A., Carrington, D.: User preference of graph layout aesthetics: A UML study. In: Marks, J. (ed.) GD 2000. LNCS, vol. 1984, pp. 5–18. Springer, Heidelberg (2001)

10. Figueira, A., Laranjeiro, J.: Interaction Visualization in Web-Based Learning using iGraphs. In: Proceedings of Hypertext 2007, Manchester, UK (2007)

## Context-Aware Combination of Adapted User Profiles for Interchange of Knowledge between Peers

Sergio Gutierrez-Santos¹, Mario Muñoz-Organero², Abelardo Pardo², and Carlos Delgado Kloos²

¹ London Knowledge Lab, Birkbeck College, University of London, UK
² University Carlos III of Madrid, Spain

sergut@lkl.ac.uk, {mario,abel,cdk}@it.uc3m.es

## Abstract

This paper presents a system that connects students with complementary profiles, so they can interchange knowledge and help each other. The profile of the students is built by a modified intelligent tutoring system. Every time the user profile is updated, a gateway updates the profile stored in the user's personal terminal using a web-service based communication mechanism. The terminals (e.g. mobile phones) are able to find and communicate between themselves using Bluetooth. When they find two complementary user profiles, they help the users getting into contact, thus providing the benefits of social network tools but at short-range and with physical context awareness. Two students are complementary when one knows what the other wants to learn and viceversa, so they can be of mutual help.

**Keywords**: mobile learning, bluetooth, profile matching.

## Introduction

Traditional learning environments are changing significantly. The introduction of pervasive technologies is enhancing the learning process making it more ubiquitous and personalized. However, the anytime-anywhere personalized learning requires also the deployment of an anytime-anywhere personal environment that helps and guides the learning process. This paper defines and provides an implementation of such a ubiquitous personalized tutoring environment by combining a modified intelligent tutoring system with a context aware mobile profile matching service. We describe

## Context-Aware Combination of Adapted User Profiles for Interchange of Knowledge

There is a third way. A student can ask for help from a peer student that has deeper knowledge. This "more able peer" is somehow similar to having a personal tutor. However, students are not professional teachers and might not be interested in helping their peers more than occasionally, unless they have something to exchange. The work presented here is based on an economic view of this scenario. In our view, knowledge and expertise in different domains are the scarce resources. Students have a varying amount of knowledge about different subjects. If two students have complementary user profiles (e.g. the first one has a deep knowledge of operating systems, while the second has mastered the computer architecture part of the course) they might be interested in being put in touch to help each other. Therefore, they can interchange what they know and help each other.

The use of short-range communication technologies to disseminate information about knowledge and learning needs leads to spontaneous collaboration [1]. Once the system has built a proper profile (i.e. learner model), this is submitted to the personal communication terminal of the student (e.g. mobile phone with Bluetooth capabilities). The terminal operates autonomously from then on, looking for similar devices in the surroundings. Once two such terminals identify themselves, they interchange their user profiles (i.e. learner model). If two profiles are found to be complementary, a message is shown to the students along with additional information. This information aims at facilitating the contact between the two human students (i.e. breaking the ice) and encourages their knowledge interchange.

Many systems have tried to benefit from inherent context that exists in short-range technologies such as Bluetooth. The work presented in [5] shows a Bluetooth-based ad hoc e-learning system that connects together students and instructors so that the students can participate in a face-to-face lecture using their personal mobile devices and instructors can receive instant feedback about the students. Although this work uses some of the concepts and technologies presented in this paper, its scope is limited to facilitate student-instructor interactions in a face-to-face class. The work presented here connects the concepts of ITS with context-aware mobile profile-matching applications. Another related work is the one presented in [2] which defines and implement a pervasive communication system from a central learning management system to mobile students based both on SMS and Bluetooth. The idea of synchronizing the status of a central learning management system with the mobile learners is similar to ours. However, we introduce a profile based synchronization mechanism from which peer to peer relationships among students can be established.

## Architecture

The combined central e-learning server-oriented and student's mobile peer to peer architecture of the system that we have defined is depicted in Figure 1.

The architecture presents two main parts. The first one is the server, that contains an Adaptive Profiler (in our case, a modified intelligent tutoring system) and a synchronization gateway. As a consequence of the interactions between the students and the profiler, the students' profiles (i.e. user models) stored in a database are populated. These profiles contain the information about the strengths and weaknesses in the learning process of each student. The second part is deployed on the mobile terminals of the students. It contains both the implementation of the synchronization interface used by the gateway to update the student's profile, and the peer-to-peer profile matching application used to find other students with complementary profiles.

It is important to note that the word "server" is used in the figure to express that the Adaptive Profiler and the Gateway are located in a central machine. The server does not actually export any service. The personal terminal, however, does export one synchronization service, shown in Figure 1 with the method setProfile().

In the server part, the two main components are the Adaptive Profiler and the Gateway. The first one is responsible of building the user profile, while the second takes care updating the user profiles to the mobile devices. The user interacts with the Adaptive Profiler through a web browser, either from a desktop computer or from the mobile phone itself. The relational database acts as the indirect

## Context-Aware Combination of Adapted User Profiles for Interchange of Knowledge

## Profile Synchronization and Web Services

These profiles are periodically updated by the Adaptive Profiler and need to be synchronized with the context-aware personal user application running on the user's mobile device. Since mobile devices tend to only implement the consumer part for web-service based communications we have defined and implemented a complete environment for developing and executing web-service based server applications on limited mobile devices. This part of the system is based on a simplification of the J2EE Servlet API on top of which we define a SOAP processing Servlet capable of exporting concurrent web services. One of these web services is the user profile synchronization web service.

As described in [3], we have defined and implemented a simplified Servlet API for mobile devices that concentrates on providing the basic functionality required to process HTTP requests. On top of the implementation of this Servlet API we have created the WebServiceServlet which implements the doGet() and doPost() methods to parse the SOAP part of a web service invocation. The main information contained in the web service invocation is the name of the operation to execute and the values of the parameters. The WebServiceServlet parses the XML content of the SOAP message, obtains the name of the operation, creates an array of arguments, instantiates the service class implementing the business logic of the web service and executes the associated method. The result generated is then encapsulated in a SOAP response message and sent back to the client.

The UML sequence diagram in the invocation process is shown in Figure 2. We have included the implementation of the synchronization web service in order to show the entire invocation process.

[Figure 2. Synchronization process]

The implementation of the synchronization web service contains the business logic for the communication between the Gateway and the mobile device. The class contains two main methods. The setProfile() method implements the synchronization protocol between the server and the mobile device. The call() method is needed to connect the synchronization web service class to the WebServiceServlet described in the previous sub-section in systems that do not provide introspection mechanisms (e.g. MIDP profile in J2ME).

## Communication between the Terminals

After interacting with the server, mobile students have their personal profiles synchronized in their mobile devices. The personal profile describes the strengths and weaknesses of the student. When different students get nearby each other either in class, in laboratories or even at the canteen, they may be interested in meeting other students with complementary profiles. We have implemented a Bluetooth based "communication with peers" module for mobile devices in MIDP. This module detects mobile devices near the student, validates that the discovered devices implement the profile matching service and exchanges the student profiles. If there are any students with appropriate complementary profiles, the module shows their details about them and their profiles in order to facilitate face-to-face interaction.

The Bluetooth technology provides both the appropriate distance for the communication (showing details only of students a few meters away) and the appropriate service discovery mechanism to find the surrounding mobile personal terminals. Our implementation uses the DiscoveryAgent of the LocalDevice to continuously find devices near the student (we are only interested in devices that implement the profile matching service).

## Conclusions and Future Work

This paper presents a system that helps students finding other students with complementary profiles. The search is performed in short range, making it context-dependent and specially suited for blended learning scenarios in which students interact in classes, at the library, etc. Using context-aware technologies makes it possible to create a sort of virtual market of knowledge, in which students interchange what they know, but without the high cost of advertise themselves.

The paper has presented the architecture of the system. The most important parts are the Adaptive Profiler (a modified ITS that builds the user profile) and the module of Communication with Peers at the personal terminal, that is responsible of locating other terminals and interchanging user profiles. Communication between the terminal and the server is also an important issue, which has made it necessary to create a web service infrastructure on the mobile terminal. The system assumes that students interact with the ITS mostly individually (

## ReMashed – Recommendations for Mash-Up Personal Learning Environments

Hendrik Drachsler1, Dries Pecceu2, Tanja Arts2, Edwin Hutten2, Lloyd Rutledge2, Peter van Rosmalen1, Hans Hummel1, and Rob Koper1

Open University of the Netherlands, 1 Centre for Learning Sciences and Technologies & 2 Computer Science Department, PO-Box 2960, 6401 DL Heerlen, The Netherlands

{hendrik.drachsler,lloyd.rutledge,peter.vanrosmalen,hans.hummel,rob.koper}@ou.nl,  
{pecceu,ekh.hutten,tg.arts}@studie.ou.nl

## Abstract

The following article presents a Mash-Up Personal Learning Environment called ReMashed that recommends learning resources from emerging information of a Learning Network. In ReMashed learners can specify certain Web2.0 services and combine them in a Mash-Up Personal Learning Environment. Learners can rate information from an emerging amount of Web2.0 information of a Learning Network and train a recommender system for their particular needs. ReMashed therefore has three main objectives:

1. To provide a recommender system for Mash-up Personal Learning Environments to learners
2. To offer an environment for testing new recommendation approaches and methods for researchers
3. To create informal user-generated content data sets that are needed to evaluate new recommendation algorithms for learners in informal Learning Networks

## Introduction

Nowadays, Internet users take advantage of Personal Environments (PEs) like iGoogle or Netvibes to create a personal view on information they are interested in. The existence of PEs inspired researchers in Technology-Enhanced Learning (TEL) to explore this technology for learning purposes. As a consequence Personal Learning Environments (PLEs) were invented for learners [1, 2]. Because of the combination of various Web2.0 sources in a PLE they are also called Mash-Up Personal Learning Environments (MUPPLEs) [3].

MUPPLEs are a kind of instance of the Learning Network concept [4] and therefore share several characteristics with it. Learning Networks consist of user-generated content by learners who are able to create, comment, tag, rate, share and study learning resources. Due to the large amount of learning resources and learners the Learning Network can show emerging patterns. Learning Networks are from the bottom-up driven because their content is not created by paid domain experts but rather by their members. These networks explicitly address informal learning because no assessment or accreditation process is connected to them.

MUPPLEs also support informal learning as they require no institutional background and no fees. Instead the focus is on the learner independent from institutional needs like student management or assessments. Although, they are most appropriate for informal learning, educational scenarios are imaginable where MUPPLEs become integrated into formal courses as well. MUPPLEs are used to combine different information from the web that is supportive to the individual learner regarding the personal competence development. Most of the time, the sources are free to use and selected by the learner.

A common problem for PEs and MUPPLEs is the amount of data that is gathered in a short time frame. The learners can be overwhelmed by the information they receive or they might have problems selecting the most suitable learning resource for their personal competence development. Therefore, we developed a recommender system that offers advice to learners to find suitable learning resources for their individual competence development. The main purpose of recommender systems on the Internet is to pre-select information a user might be interested in. The motivation for a recommender system for MUPPLEs is to improve the 'educational provision'; to offer a better learning goal attainment and to spend less time to search for suitable learning resources [5].

## Related Work

Nowadays, 'mashing' information becomes a widely used activity on the Internet. Various tools (Yahoo Pipes, D

## ReMashed – Recommendations for Mash-Up Personal Learning Environments

## Background
ReMashed offers a new approach by mashing data of learners from various Web2.0 services to provide pedagogical recommendations. While rating data has been used in other domains, it has not been attempted for learners in MUPPLEs (Mash-Up Personal Learning Environments).

## The ReMashed System
Similar to the MovieLens project by GroupLens research group, ReMashed has three main objectives:
1. To provide a recommender system for MUPPLEs to learners
2. To offer an environment for testing new recommendation approaches and methods for researchers
3. To create informal user-generated-content data sets needed to evaluate new recommendation algorithms for learners in informal Learning Networks

The system allows learners to integrate their Web2.0 sources and personalize emerging community information to their preferences. Users can rate information from Web2.0 sources to indicate their preferences, which ReMashed uses to offer tailored recommendations through collaborative filtering.

### Technical Architecture
ReMashed is an Open Source project built with:
- PHP5
- Zend Framework 1.7 with Dojo Ajax framework
- MySQL database
- Apache Server
- Duine recommendation engine

The system consists of five sub-systems:
- User Interface: Handles user interaction, authentication, registration, and user data updates
- Data Collector: Connects to Web2.0 services and gathers new data hourly via CRON job
- Logger: Stores log messages and monitors user actions
- Recommender System: Composes recommendations and allows implementing new algorithms
- Duine Prediction Engine: Provides configurable recommendation algorithms that can be combined into strategies

### System Evaluation
The system was tested in a usability evaluation with 49 users from 8 different countries over one month. Results included:
- 4961 resources collected
- 420 resources rated
- 813 recommendations offered
Overall satisfaction was positive, though participants suggested improvements for future development.

## Conclusions and Future Research
### End-user Perspective
Future developments should:
- Integrate additional Web2.0 features (e.g., Facebook)
- Improve isolation of informal learners towards learning communities
- Provide widget interface for integrating recommendations into MUPPLEs

### Researcher Perspective
ReMashed enables:
- Creation of user-generated-content data sets across various domains
- Development of standard evaluation datasets for TEL recommender systems
- Solutions for cold-start problems through domain-specific rated datasets

Here's the cleaned Markdown:

## ReMashed – Recommendations for Mash-Up Personal Learning Environments

## Acknowledgement
Authors' efforts were (partly) funded by the European Commission in TENCompetence (IST-2004-02787) (http://www.tencompetence.org).

## References
1. Liber, O., Johnson, M.: Personal Learning Environments. Interactive Learning Environments 16, 1–2 (2008)
2. Wild, F., Kalz, M., Palmer, M. (eds.): Mash-Up Personal Learning Environments. CEUR Workshop Proceedings Maastricht, The Netherlands, vol. 388 (2008)
3. Wild, F., Moedritscher, F., Sigurdarson, S.E.: Designing for Change: Mash-Up Personal Learning Environments. eLearning Papers 9 (2008)
4. Koper, R., Tattersall, C.: New directions for lifelong learning using network technologies. British Journal of Educational Technology 35, 689–700 (2004)
5. Drachsler, H., Hummel, H., Koper, R.: Identifying the Goal, User model and Conditions of Recommender Systems for Formal and Informal Learning. Journal of Digital Information 10, 4–24 (2009)
6. Wilson, S., Sharples, P., Griffith, D.: Distributing education services to personal and institutional systems using Widgets. In: Wild, F., Kalz, M., Palmer, M. (eds.) Mash-Up Personal Learning Environments, Proceedings of the 1st MUPPLE workshop. CEUR-Proceedings, Maastricht, The Netherlands, vol. 388 (2008)
7. Shepitsen, A., Gemmell, J., Mobasher, B., Burke, R.: Personalized recommendation in social tagging systems using hierarchical clustering. In: Recommender Systems 2008, pp. 259–266. ACM, New York (2008)
8. Symeonidis, P., Nanopoulos, A., Manolopoulos, Y.: Tag recommendations based on tensor dimensionality reduction. In: Recommender Systems 2008, pp. 43–50. ACM, New York (2008)
9. Garg, N., Weber, I.: Personalized, interactive tag recommendation for flickr. In: Recommender System 2009, pp. 67–74. ACM, New York (2009)
10. Sarwar, B.M., Karypis, G., Konstan, J., Riedl, J.: Recommender systems for large-scale e-commerce: Scalable neighborhood formation using clustering. In: Fifth International Conference on Computer and Information Technology (2002)
11. Herlocker, J.L., Konstan, J.A., Riedl, J.: Explaining collaborative filtering recommendations. In: Proceedings of the 2000 ACM conference on Computer supported cooperative work, pp. 241–250 (2000)
12. Drachsler, H., Hummel, H., Koper, R.: Personal recommender systems for learners in lifelong learning: requirements, techniques and model. International Journal of Learning Technology 3, 404–423 (2008)
13. Van Setten, M.: Supporting people in finding information. Hybrid recommender systems and goal-based structuring. Telematica Instituut Fundamental Research Series No. 016 (TI/FRS/016) (2005)
14. Drachsler, H., Peccau, D., Arts, T., Hutten, E., Rutledge, L., Van Rosmalen, P., Hummel, H., Koper, R.: R

## Hanse 1380 - A Learning Game for the German Maritime Museum

## 1. Game-Based Learning

Game-based learning means that learning content is embedded within a game. In the last years a lot of researches have shown that learning through games can have various advantages. Richard van Eck points out one advantage of games [4, p. 4]:

> Games embody well-established principles and models of learning. For instance, games are effective partly because the learning takes place within a meaningful (to the game) context. What you must learn is directly related to the environment in which you learn and demonstrate it; thus, the learning is not only relevant but applied and practiced within that context. Learning that occurs in meaningful and relevant contexts, then, is more effective than learning that occurs outside of those contexts, as is the case with most formal instruction.

Van Eck stresses the advantage that within a game new knowledge is more meaningful as it can be applied directly. The success of a certain action or strategy is usually shown immediately.

Another strength of game-based learning is that learning is joyful as it happens while playing. Traditional learning situations, like lectures in school or self-study from books have the negative picture of being boring and pupils have to be "forced" to learn (e.g. to pass exams). The motivation of playing computer games is much higher as playing is seen as pleasure and not as work. Malone and Lepper researched about what can people motivate to learn, and they have found out that many features found in games (like challenge and performance feedback) positively influence motivation for learning [5]. They differentiate between intrinsic and extrinsic motivation, whereas they define intrinsically motivated learning as learning that occurs in a situation in which the most narrowly defined activity from which the learning occurs would be done without any external reward or punishment. [5, p. 229] They state the hypothesis that intrinsically motivated learning will lead to better learning results.

## 2. Putting the Exhibits in Context

Historic exhibits are dead objects, they are no longer in use nowadays. It is hard to imagine, why certain objects were important in times which are completely different to the present. The conserved cog, which is the main attraction of the exhibition about medieval ships in the German Maritime Museum (GMM), is more then 500 years old and destroyed to a large extent. No doubt that it has an enormous historic value, but without the context of how it was used in the past it cannot be fully understood. Within a game the museum visitor can be enabled to experience the past and learn about the context in which the shown exhibits were used.

## 3. Restrictions

### 3.1 Target Group

As a target group for the game, pupils aged between 10 and 14 years were taken.

### 3.2 Needs for a Terminal Game in a Museum

As the game should be played on a computer terminal within a museum, it must be easy to understand. A quantitative study by Fleck et al. [6] has shown that a typical museum visitor spends 1-2 minutes at a museum object. However, if the visitor is engaged within that time, the time at one exhibit can increase to 10-15 minutes. The same study has shown that labels and instructions for interactive exhibits are usually not read. Interactive exhibits are tried out directly and people just refer to the instructions if they fail.

For a learning game in a museum that means that it is necessary to motivate the visitor within 1-2 minutes to play the game. Long instructions should be avoided and in contrast it should be possible to explore the game. To allow exploration of the game, it must be intuitive and easy to use (which also includes the computer terminal). Finally, the overall game time should not be longer than 10-15 minutes.

To summarize, these three requirements were defined:
- The game should start immediately.
- A tutorial should make it possible to explore the game step by step.
- Intuitive hardware controls should make the controlling as easy as possible.

## 4. Results

The final result is a simulation game. The player takes the role of

## Hanse 1380 - A Learning Game for the German Maritime Museum

![Trading part of the game in Lübeck. Important parts of city—as the church—are based on old drawings.](Fig. 1)

## Game Tutorial
When the player successfully finishes one step in the tutorial, the next step is shown. Therefore the new knowledge is connected to the current situation in the game and thus should be remembered easier.

## Computer Terminal
To control the cog in the sailing simulation, the player uses a miniature model of a capstan and a rudder. The design of the controls is connected to the real look of those instruments. Firstly, the mental mapping of the control to its corresponding function should be supported by that. Secondly, due to this similarity to the real instruments, the player also gets an impression how these instruments look like on cogs. Also, the whole terminal design looks like a small cog, which creates a more interesting atmosphere and invites people to use the terminal. Additionally the game uses a touchscreen for user-input.

## User Test
With an unfinished prototype of the game, a user test with 29 pupils fitting the target group was conducted. It tested if the pupils are able to understand the game and control the cog, if they like the game (and which parts of it) and if they achieve the learning objectives. Additionally it included questions about general usage of computer games.

### Attitude Towards Computer Games
Some pupils play computer games daily and all of them play at least multiple times per week. Regarding the preferred genre no clear preference can be found. The games range from "shooting games" (in particular Counter-Strike), strategy games, racing games to simulation games (The Sims). Shooting games are more popular for boys (7 boys and 3 girls stated to play shooting games), whereas The Sims is only played by girls in this test group. The majority of the tested pupils have not played games in museums so far (21 of 29).

### Usability
In general the usability of the game was good. All of the pupils understood how to control the cog and they rated the difficulty of it with 2.21³. 89.29% of the tested pupils understood what their task in the game is. 89.29% understood how the current time of the season is indicated. 72.41% understood how the damage of the cog is indicated. 96.55% understood how the wind is indicated. And 85.71% understood the landmarks.

On the question how much they like the game and single parts of it (graphics, sound, dialogue, overall) an average of 2.16⁴ was achieved.

### Learning Objectives
In general not all children achieved the learning objectives, which were requested in the post-interview. 89.66% of the pupils remembered at least one hanse city. The naming of correct products was more difficult, but the trading feature was not fully implemented in the test-version of the game. 44.83% of the pupils could name the correct duration of a trading season, but again the prototype was not finished regarding that aspect, so it is not a surprise to have this result.

The century in which this game takes place was not remembered well, just 41% did so. The same percentage of pupils could name the trading alliance, this game is dealing with. As this knowledge is not needed within the game, it supports the hypothesis that factual knowledge, which is not applied in the game, is not remembered very well.

### Summary
A general positive result is that most pupils liked the game. An overall grade of 2.16 is promising. It shows that the gameplay functions and that the goal to make a good game in general is reached. In particular the victory condition of the game is communicated well (89.29% understood it), which by supporting the competitive element is an important part of a game [7]. What is also very positive is that the vast majority understood the game itself and the interface very well.

## Conclusion
Learning objectives need to be integrated strongly within the game. Information which is just provided but not needed to successfully finish the game will not be retaine

Here's the cleaned Markdown:

## Hanse 1380 - A Learning Game for the German Maritime Museum

Two different ways to integrate learning content can be observed. Firstly, content can be transported via rules. For example if the objective is that the player should know how long a trading season is, then the according game rule can stress that the player has to finish a task within one trading season.

Another way to integrate a learning objective into a game is via a feature. An example used in this game are pirates. The according learning objective is to show the danger of pirates in the medieval time. It is implemented in a way that on special routes the players cog might be attacked by pirates. To survive the attack of pirates the player then has various possibilities which correlate to the possibilities that seamen had in medieval times.

At the same time it got clear that information which is not directly integrated into the game is not remembered. Our tests have shown that not many children could remember the name of the famous trading union ("Hanse") although textual hints refer to it multiple times and also the name of the game itself "Hanse 1380" which is very prominently placed.

## References

1. Witcomb, A.: Interactivity: Thinking beyond. In: Macdonald, S. (ed.) A Companion to Museum Studies, pp. 353-361 (2007)
2. Stevenson, J.: Getting to grips. Museums Journal, 30-32 (May 1994)
3. Fahy, A.: New technologies for museum communication. In: Hooper-Greenhill, E. (ed.) Museum, media, message, pp. 82-96. Routledge, London (2002)
4. Eck, R.V.: Digital Game-Based learning: It's not just the digital natives who are restless. EDUCAUSE Review 41(2) (2006)
5. Malone, T.W., Lepper, M.R.: Making Learning Fun: A Taxonomic Model of Intrinsic Motivations for Learning. In: Conative and Affective Process Analyses. Aptitude, Learning, and Instruction, vol. 3 (1987)
6. Fleck, M., Frid, M., Kindberg, T., O'Brien-Strain, E., Rajani, R., Spasojevic, M.: From informing to remembering: ubiquitous systems in interactive museums. IEEE Pervasive Computing 1(2), 13-21 (2002)
7. Salen, K., Zimmerman, E.: Rules of Play: Game Design Fundamentals. MIT Press, Cambridge (2003)

## A Linguistic Intelligent System for Technology Enhanced Learning in Vocational Training – The ILLU Project

In this paper I will describe a linguistic intelligent software system, using methods from computational linguistics, for the automatic evaluation of translations in online training of interpreters and translators. With this system the students gain an online interface offering them proper translation training. The main aim in developing such a system was to create an e-learning unit which allows the students to translate a given text in a special online environment and afterwards receive an automatic evaluation of the entered translation from the system. This is done on a computational linguistics basis using special analyzing software, model solutions and stored classifications of typical translation mistakes.

**Keywords**: Vocational training, Language Learning, Natural Language Processing.

## Introduction

The types of interactive e-learning units used in the vocational training of translators and interpreters are currently limited by the technical possibilities provided by various e-learning systems. On the one hand there are e-learning units where users can obtain an automatic evaluation that is performed by the system. On the other hand, the evaluation of the texts is done by tutors. In the aforementioned case the given data is initially sent to the relevant tutor. After the evaluation of the texts by the tutor the results are sent back to the students or stored in an online rating system. If the e-learning unit offers automatic evaluation by the system

## A Linguistic Intelligent System for Technology Enhanced Learning

## Description
In this paper I will describe an intelligent software system, using methods from computational linguistics, which is able to evaluate free text translations record-by-record automatically. In addition the system is able to give qualified feedback for each mistake found automatically. The process-scheme is shown in Figure 1.

![Process-scheme](Fig. 1. Process-scheme)

## Requirements
For the successful implementation of such a system certain requirements were necessary. These included as the core the linguistic resources. Furthermore it was necessary to provide additional resources, including the source texts and possible model translations as well as examples of possible mistakes. A differentiated error code and corresponding feedback texts were also required and material about special translational problems. For an initial automatic evaluation of the posted translation commercial spell and grammar checkers are used. For a more profound analysis the posted text is morphosyntactically and semantically analysed. For this also, depending on the source language, various existing software packets are used. Finally special software for the comparison between the analysed translation posted by the students and the stored model solutions and examples of possible mistakes had to be developed within the project. In the process both model solutions as well as possible mistakes are stored in the system. A consistent, differentiated error code, which describes precisely the various mistake-scenarios, provides the basis for detailed feedback messages to the students. The system was initially intended to focus only on special translational problems of a certain language pair. Therefore it was necessary to provide material for these specific problems together with corresponding examples.

## Approach
For the prototypical system (special translational problems E->D and F->D respectively) as a spell and grammar checker the existing software "Duden Korrektor Plus" of the Duden Verlag Mannheim is used. This software provides spell and grammar checking in consideration of the context. In detail the system offers correction of typing errors, spelling of hyphenated words, upper and lower case, compound or separate spelling, abbreviations, punctuation, mistakes in congruency, typography and regimen. This is done on the basis of the standard Duden dictionaries and books of reference [1]. For the morphosyntactic and semantic analysis of the posted translation the program MPRO is used in the ILLU system. MPRO is a software package for the morphosyntactic and semantic analysis of texts, which was developed by the Institute of Applied Information Science (IAI) in Saarbrücken. The program assigns a bundle of linguistic information to every recognized character string of a text. Normally the basic form (citation form) and part of speech (noun, verb, adjective etc.) are generated. Furthermore MPRO provides information about the inflection (case, number, gender, tense, person) as well as the structure of a word. For so-called "meaningful words" (nouns, adjectives, verbs, adverbs) the program also provides a semantic class. The assigned information is added to each string in form of a feature bundle. For the analysis of a word MPRO uses a dictionary of morphemes. The dictionary for German presently contains about 90,000 entries [2].

## Comparison Module
Due to the morphosyntactic and semantic analysis there are many features available for the comparative operation between the posted translation and the stored model solutions and possible mistakes. At word level the most important are the original string and the basic form, case, number, gender, tense and part of speech. At sentence level there are some more, e.g. word occurrence, word order, marking of phrases or sentences to name but a few. For the comparison operation it was necessary to define distinct parameters on the basis of which the comparison is made. On the one hand the feature bundles which are used for the comparison had to be defined. After that it was essential to define a method to compute a measure of similarity between the posted text and the stored model solutions and possible mistakes. Initial tests led to the implementation of a prototypical comparison module. The program computes whether certain feature bundles between two structures are identical or not. Depending on the various linguistic features this is done using different strategies to find the differences between the structures. Finally the

Here's the cleaned Markdown:

## A Linguistic Intelligent System for Technology Enhanced Learning

## Detailed Process Sequence

![Fig. 2. Detailed process sequence (translation E->D or F->D respectively)](fig2)

The implementation of rules for the determination of mistakes was very labour-intensive at the beginning of the project. But together with the aforementioned comparison operation these rules are responsible for the quality. The more differentiated the rules for a certain translation and the corresponding model solutions and possible mistakes, the more high-quality the system is. Beside rules based on the morphological, syntactic and semantic level (e.g. false verb, false relative pronoun etc.) it is also possible to implement rules which are sentence specific (e.g. changed constituents, word occurrence). If the topic of a certain unit is a particular translational problem, it is also possible to define specific rules for this.

So far only rules on the morphological and syntactic level have been implemented. One of the ideas of the project is, that after initially collecting all rules as singular rules per text and translation, perhaps at a later date specific rules can be summarised to more abstract rules. Additionally this might be a chance to gain interesting results for translation studies. After the translational mistakes have been precisely determined by the comparison operation the corresponding feedback messages are sent back to the students. After processing one sentence the messages are given back to the students. Until now there is a fixed set of possible feedback messages implemented. But there is no restriction concerning the form of the feedback messages. It is for example possible to store not only detailed feedback messages for specific translational problems. In the future whole e-learning units and links to special phenomena and further literature can be provided.

## Examples and Preliminary Results

![Fig. 3. User interface of the prototypical System (tutor interface; translation E->D)](fig3)

The original text in the source language is shown in the text field "Originalsatz". The text field "Lösung" contains a possible model translation, which is shown to the students on demand. The textfield "Lösungshinweis" contains advice for a possible solution and is also shown to the students on demand. Further down the corresponding model solutions and possible mistakes in German are entered into the system. Due to linguistic intelligence this is possible on a phrase basis. This provides more possible combinations and therefore variety for possible translations.

The system has the basic strategy of identifying first correct and false solutions. If this process is finished and none of the stored model solutions or possible mistakes correspond with the posted translation, the system gives feedback to check the translation again. At the same time the students can on demand obtain advice about a possible solution as well as a model solution for the current translational problem. And simultaneously the possibility of a separate evaluation of the posted translation by a tutor is given within the frame of parallel translation lessons or via email.

## Evaluation and Conclusion

The advantage of interactive e-learning units for translators and interpreters is, as for all e-learning systems, their availability. It is an additional e-learning possibility, which the students can use independent of time and place. A further advantage is that it also reduces the workload of the lecturers. Within the translation lessons only special translational problems need to be covered. No more time need be spent on spelling and grammar mistakes. These mistakes have already been corrected automatically by the system. Furthermore, interactive e-learning units for translators and interpreters are particularly suitable for the consolidation of special translational problems. Special translational phenomena can be explained by model sentences and texts. With the help of a detailed feedback system additional material can be provided for the students. Here the system can be constructed in a modular way and used in addition to the translation lessons, where attendance for students is obligatory.

## A Linguistic Intelligent System for Technology Enhanced Learning

The present prototype implementation of the rules for the comparison module turned out to be difficult. This requires further analysis. Perhaps the use of certain existing methods, e.g. "fuzzy-match" techniques of TM Systems is a solution to this problem. A further difficulty turned out to be the storing of model solutions and possible mistakes. During the implementation of the current system various interfaces were developed. Finally now both these things are possible with the help of a special tutor interface, which is easy to use and therefore suitable also for lecturers without any programming knowledge. Another disadvantage of the outlined system is that the automatic evaluation of translations is only possible record-by-record. Thus not all possible versions of a translation can be covered. Perhaps this problem can be solved in the near future by techniques used already in the alignment process of Translation Memory systems.

However, it has been demonstrated that the development of linguistic intelligent interactive e-learning units used in the vocational training of translators and interpreters is possible. Further tests with the prototype will need to demonstrate whether the students accept such systems. Certainly the potential effects of such a system on the e-learning community are obvious: When it is possible to evaluate free text with relation to certain stored model solutions or other requirements, the system represents a powerful software tool which can be used not only in the vocational training of translators and interpreters, but also in other areas, where the possibility of free text input is desirable.

## References

1. Duden Verlag Mannheim. Bücher und Software. Bibliographisches Institut & F. A. Brockhaus AG (2007), http://www.duden.de/produkte/

2. Maas, H.-D.: Multilinguale Textverarbeitung mit MPRO. In: Lobin, G. (ed.) Europäische Kommnikationskybernetik heute und morgen. KoPäd, München (1998)

3. MeLLange: Multilingual eLearning in LANGuage engineering (2007), http://mellange.eila.jussieu.fr/

4. NIST: Automatic Evaluation of Machine Translation Quality Using N-gram Co-Occurrence Statistics, Automatic Evaluation of MT Quality, NIST (2005)

5. Papineni, K., Roukos, S., Ward, T., Zhu, W.-J.: BLEU: A Method for Automatic Evaluation of Machine Translation. In: Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (2002)

## e³-Portfolio – Supporting and Assessing Project-Based Learning in Higher Education via E-Portfolios

Philip Meyer, Thomas Sporer, and Johannes Metscher  
Institute for Media and Educational Technology  
Universitätsstr. 2, 86135 Augsburg, Germany  
surname.lastname@its.uni-augsburg.de

## Abstract

e³-portfolio is a software tool which supports learning and working in student project groups. Besides features for collaboration via social media, the software offers an electronic portfolio system. The e-portfolio helps to integrate informal project-based learning into the formal curriculum of higher education. This paper gives an overview of how the software tool is designed and relates the design to the underlying didactic concept.

**Keywords**: Project-based learning, e-portfolio, e-collaboration, e-assessment.

## Introduction

Practical experiences and key competencies are becoming increasingly important for students in today's working life. One way to attain those competencies is to take part in self-organized project groups at the periphery of their university. Here students learn to solve problems and become part of a community of practice [1]. At the University of Augsburg students can get such extra-curricular learning activities accredited through the study programme "Problem Solving Competencies" [2]. This study programme builds on the reflection of the student's experiences via e-portfolios and focuses the assessment on the articulation of the competencies that the students acquire [3]. The organisation of that study

## e³-Portfolio – Supporting and Assessing Project-Based Learning in Higher Education

The three main areas can only be accessed to their full extent after registration. In the following sections these areas are described – in their functionality for unregistered and already registered users.

## Community Area

For unregistered users the community area gives an overview of the project groups that take part in the study programme (e.g. campus magazine or campus radio). Each project has a public space where they can present themselves, the project ideas (e.g. via video interviews with the project leaders) and descriptions of the activities participants can take on. Project groups can adapt this public area to their "corporate design" to ensure the identity of the project is maintained. News about the project can also be published to inform others about the initiative. After registration the internal community area provides access to all the groups of which the user is a member or owner. Registered users can create new project groups or join existing groups by request.

Additionally the community area features various tools for project and knowledge management:
- A community blog where discussions within the group can take place and by which the group can organize their collaboration by announcing important dates and deadlines
- A wiki for each group which offers the functionality to share knowledge between group members
- A document repository which allows publishing meeting protocols and sharing files

## Portfolio Area

In its unregistered view the portfolio area shows exemplary profiles from participants of the study programme. In short video interviews participants describe what motivated them to attend the project group and what is special about being part of their project. Aside you can view some personal information about the participants and browse through their learning journals.

After registration the participants can write their project diary in form of a blog in the portfolio area. Here students periodically reflect on the experiences they make during their project activities. The reflection process is scaffolded by guiding questions like "What happened since the last entry in my project diary?" or "What are my thoughts and feelings as to the current situation in the project?". At the end of each semester students can create a project report that summarises the salient events during their participation in the project and presents them in form of a learning history.

The portfolio area also helps students keep track of all their diary entries and project reports. Here they can collect all these items and prepare them for submission to the assessment area.

## Assessment Area

In its public view the assessment area shows a description of what this area offers: a space for registered users to submit project diaries and reports and to get feedback for their learning and working achievements. The registered view enables the organisation of all achievements performed in the context of the study programme and their accreditation in the formal curriculum.

After completing all building blocks of the study programme, participants can obtain the certificate "Problem Solving Competencies". If students want credit points gained during project work accredited in their formal studies, the project report must be handed in via the assessment area and becomes graded by the coordinator of the co-curricular study programme.

## Underlying Didactical Concept

The platform was designed to support a didactical concept which focuses on the integration of informal learning activities into the formal university curriculum [4]. The three main areas differ in the degree of formalisation of the learning setting. The community area is very close to the practice of the project group as an informal learning community. Students discuss, collaborate and share their experiences, but this happens on an informal level with a low degree of formalisation.

In the portfolio area, students begin to formalise their experiences by writing them down in a personal diary. This still happens close to the context of what is actually going on in the project practice and the involvement of theoretical assumptions is marginal. Finally, in the assessment area, students decide which texts and artifacts created during project work are worth submitting to programme coordinators. Students choose entries where the reference to formal studies goals is obvious. They also make assumptions in their project report on how their project participation and formal studies relate to one another.

The portfolio-based assessment strategy can be summarized as follows: Students collect their working achievements and diary entries in the working portfolio. At the end of the semester they combine these artifacts into a coherent learning history in the story portfolio. Via the test portfolio they finally argue what competencies

Here's the cleaned Markdown:

## Areas of e³-portfolio and Blended Assessment Strategy

![Fig. 4. Areas of e³-portfolio and blended assessment strategy](no-image)

## Conclusion and Future Work

This article described the features of a software tool which is currently being used at the University of Augsburg. The software tool supports the collaboration of student's project groups and it offers a way to integrate informal learning activities into the formal curriculum of higher education via a blended assessment strategy based on e-portfolios. Recently, evaluation studies have shown that students want more interconnectedness between the different areas of the software tool. Especially in regard to the portfolio and the assessment area the current state of implementation lacks the functionality to give feedback on the content provided by the participants. Due to the collaborative nature of the community area there is already a lot of interactive functionality present. However, we are planning to introduce even more features in the community area that can support group collaboration.

## References

1. Dürnberger, H., Sporer, T.: Selbstorganisierte Projektgruppen von Studierenden: Neue Wege bei der Kompetenzentwicklung an Hochschulen. Erscheint im Tagungsband der 14. Europäischen Jahrestagung der Gesellschaft für Medien in der Wissenschaft. Waxmann, Münster (in press)

2. Sporer, T., Reinmann, G., Jenert, T., Hofhues, S.: Begleitstudium Problemlösekompetenz (Version 2.0): Infrastruktur für studentische Projekte an Hochschulen. In: Merkt, M., Mayrberger, K., Schulmeister, R., Sommer, A., Berk, I.v.d. (eds.) Studieren neu erfinden – Hochschule neu denken, pp. 85–94. Waxmann, Münster (2007)

3. Reinmann, G., Sporer, T., Vohle, F.: Bologna und Web 2.0: Wie zusammenbringen, was nicht zusammenpasst? In: Keil, R., Kerres, M., Schulmeister, R. (eds.) eUniversity - Update Bologna. Education Quality Forum. Bd. 3, pp. 263–278. Waxmann, Münster (2007)

4. Sporer, T., Jenert, T., Meyer, P., Metscher, J.: Entwicklung einer Plattform zur Integration informeller Projektaktivitäten in das formale Hochschulcurriculum. In: Seehusen, S., Lucke, U., Fischer, S. (Hrsg.) DeLFI 2008. Die 6. e-Learning Fachtagung Informatik der Gesellschaft für Informatik e.V. Gesellschaft für Informatik, Bonn (2008)

[Author index section removed as it appears to be from a different document]

## Author Index

- Heintz, Matthias 584
- Held, Christoph 254
- Hendrix, Maurice 7
- Herder, Eelco 240
- Hesse, Friedrich W. 5
- Hoppe, H. Ulrich 365
- Howard, Yvonne 127
- Hsiao, I-Han 88
- Hummel, Hans 788
- Hutten, Edwin 788
- Indriasari, Theresia Devi 310
- Ivanović, Mirjana 657
- Jahn, Marco 507
- Jarke, Matthias 310
- Jenner, Walter 794
- Jeremić, Zoran 441
- Jiménez-Díaz, Guillermo 645
- Jovanović, Jelena 140, 441
- Kahrimanis, Georgios 267
- Kalz, Marco 160
- Kaplan, Frederic 211
- Karabinos, Michael 391
- Karsten, Anton 160
- Kawase, Ricardo 240
- Kempf, Fabian 344
- Kennedy-Clark, Shannon 609
- Klamma, Ralf 166
- Kleinermann, Frederic 627
- Koper, Rob 160, 477, 788
- Kovatcheva, Eugenia 549
- Krauß, Matthias 226
- Kravcik, Milos 52
- Krogstie, Birgit R. 418
- Kump, Barbara 73
- Law, Effie Lai-Chong 181
- Leblanc, Adeline 682
- Leclet, Dominique 405
- Lecocq, Claire 763
- Lehtinen, Erno 676
- Lejeune, Anne 602
- Lewandowski, Arnaud 405
- Ley, Tobias 73, 700
- Lindstaedt, Stefanie N. 73, 639, 700
- Lopes Gançarski, Alda 763
- Lopistéguy, Philippe 769
- Loughin, Tom 37
- Lu, Tianxiang 67
- Lucas, Margarida 325
- Luong, The Nhan 769
- Magoulas, George D. 106
- Maillet, Katherine 763
- Malandrino, Delfina 712
- Malzahn, Nils 365
- Mandran, Nadine 602
- Manno, Ilaria 712
- Marenzi, Ivana 154
- Markus, Thomas 385
- Marquesuza`a, Christophe 769
- Marsala, Christophe 633
- Martínez-Ortiz, Iván 725
- Martel, Christian 379
- Mavrikis, Manolis 556
- Mazarakis, Athanasios 615
- McLaren, Bruce M. 391, 688
- McSweeney, Patrick 127
- Meier, Anne 267
- Melis, Erica 67, 688
- Memmel, Martin 112
- Metscher, Johannes 806
- Meyer, Ann-Kristin 688
- Meyer, Philip 806
- Millard, David E. 127
- Mohabbati, Bardia 37
- Monachesi, Paola 385
- Moreira, António 325
- Mossel, Eelco 385
- Moura de Araújo, Leonardo 794
-