# Module 2: Paraphrasing, Summarising & Synthesising Skills
**UCLC1008 UE1 (2025-26, S1)**  
© 2025 Language Centre-HKBU

## Activity 3.3: Determining the Relationships between Ideas

Read the following excerpts by Caines (2021) and Seng et al. (2021) below. What synthesising techniques have the authors used? What kind of relationships do you think Caines (2021) and Seng et al. (2021) are trying to express through the sources they cited in each excerpt?

Discuss in groups and report on your answers.

---

### Example 1: Caines (2021, p. 38)

We have already mentioned the various shortcomings of facial recognition software. The marketing efforts of facial recognition companies have in many cases been less than truthful (more on this later). Almost all of these technologies exhibit varying accuracy when used on a diverse population. The following four categories of subjects appear to yield the greatest inaccuracies:

1. The very young (particularly below 17) and the very old (above 71)
2. Women (as compared to men)
3. Individuals with darker skin tone
4. Ethnic minorities—such as Native Americans in the U.S.

The metric for inaccuracy used by the most recent NIST study was **false positives**—the frequency that the algorithm falsely indicated the identity of an input photo. The study examined 189 commercially available algorithms from 99 developers. Using datasets that included domestic mug shots, application photos for immigration benefits, visa photographs, and border crossing photos of travelers (a total of 18.27 million images of 8.49 million people), the study found variations in accuracy from a factor of 10 to beyond 100, particularly with West and East African faces and East Asian faces. Additionally, domestic law enforcement algorithms had the highest false positives with African American and Asian faces. Interestingly, algorithms created in Asia showed no dramatic difference in false positives between Asian and Caucasian faces. Significantly, when an individual belongs to multiple categories, inaccuracy rates compound.

Different studies, including the *Gender Shades* study by MIT professor Joy Buolamwini and Microsoft researcher Timnit Gebru, have shown that black women generated an error rate approximately **33.9% higher** than their white male counterparts in a test of three commercially available algorithms. Facts such as these made communities, privacy advocates, and criminal justice experts wary when major jurisdictions such as New York City began to create databases of juvenile minors as young as 12.

Another application involving children was implemented by the school district of Lockport, NY. In 2019, the school district launched a **$1.4 million AEGIS facial recognition system**, intended to detect disgruntled former students, fired and suspended employees, or those on a sex offender list. The district has provided minimal information about the system, claiming no student data would be stored, and retention would last only 60 days unless there is an incident. Other critical details such as specifics on the training data and false positive rates have not yet been released.

---

### Example 2: Seng et al. (2021)

#### Excerpt 1 (pp. 2-3)

As a result, there is growing discussion in the media about the use of facial recognition (FR) in everyday life. Recent news indicates that people are in favor of using FR when retailers have to prevent shoplifting (West, 2018) or to help a celebrity identify her stalkers (Castro, 2019). On the other hand, there are concerns about the use of FR, including its biased accuracy. For example, the evaluation of three commercial gender classification systems indicates that darker-skinned females are the most misclassified group, with error rates of up to **34.7%**, while the maximum error rate for lighter-skinned males is **0.8%** (Buolamwini & Gebru, 2018).

#### Excerpt 2 (p. 3)

A survey conducted by Pew Research Centre focused on people’s trust in law enforcement agencies regarding the use of facial recognition to identify suspected criminals (Smith, 2019). It found that more than half of U.S. adults trust law enforcement agencies with the sensible use of FR. In similar contexts, the Centre for Data Innovation conducted a survey to learn about people’s expectations for the U.S. government in controlling the use of FR, which showed that few people in the U.S. want the government to limit its use (Castro & McLaughlin, 2019). In the U.K., however, the majority of people want the government to impose restrictions on law enforcement agencies with the use of FR (Ada Lovelace Institute, 2019). These surveys (Castro & McLaughlin, 2019; Ada Lovelace Institute, 2019; Smith, 2019) examined trust in law enforcement agencies with the use of FR. However, there is still a large gap in understanding users’ perceptions of FR in everyday life.