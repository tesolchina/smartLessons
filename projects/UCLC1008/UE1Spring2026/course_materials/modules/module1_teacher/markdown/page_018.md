<!-- Page 18 -->

# Module 2: Paraphrasing, Summarising & Synthesising Skills (Teacher's Copy)

<!-- Copyright: Â© 2025 Language Centre-HKBU -->

- Facial recognition (FR) disproportionately emphasises "detecting" the gender and race of individuals it identifies.
- These technologies schematise human faces to foreground calculations of race and gender, arbitrarily dividing human populations (Stark, 2019).
- High-profile controversies have shown some FR systems' inability to discern non-white faces due to racially skewed training databases.
- Even if identification becomes technically accurate, sorting students into socially constructed racialised/gendered categories is discriminatory, as it conflates biological traits with social attributes.
- FR technology can "resuscitate long-debunked race 'science'" by attempting to formalise phenotypic differences, which often leads to claims about genetic capabilities.
- Stark (2019) argues that even in non-racist societies, FR would incline towards racism; in societies that are racist, FR exacerbates that animus.

## Supporting Point 11:

<!-- Header: Topic Sentences (Main idea of this section) -->
Another point of concern is the inescapability of facial monitoring within school contexts. While such coercion applies to the use of facial recognition in all public spaces, it is especially acute in schools.

<!-- Header: Key evidence or reasoning used (What kind of support do the authors provide for this point?) -->
- Unlike other personal data, facial data is inherently linked to individuals (people are always connected to their faces), making it susceptible to constant and permanent surveillance.
- Students have no option to self-curate or restrict facial data they share.
- While students might opt-out of some facial detection elements (e.g., eye-tracking for learning analytics), there is no right to decline "non-cooperative" facial recognition systems.
- This coercion is especially acute in schools due to policies like dress codes that prevent students from covering their faces.
- Any promise of "informed consent" is inadequate because systems for security and attendance require complete sweeps of classrooms/corridors.
- Even with opt-out protocols, the system must scan a student's face before it can recognise they have opted out.

<!-- Watermark: UCLC1008 UE1 (2025-26, S1) -->