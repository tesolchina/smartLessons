# RAG-Annotated Manuscript with Citation Suggestions

*This version includes inline citation suggestions based on RAG analysis*


## Introduction

**ðŸŽ¯ Citation Opportunities Found: 11**

# introduction
 of the AI-based chatbot was associated with an immediate and sustained increase in both the quantity and quality of student goal-setting (Table 2 ). The number of participants submitting goals remained high throughout the semester, starting at 38 pre-intervention (Week 3), increasing to 39 immediately post-intervention, and gradually declining to 25 by Week 15, a trend that largely tracked overall goal-setting participation, and the observed decrease in week 15 can likely be attributed to students reallocating their focus toward preparing for final examinations in their other courses **[CITE: Doran (1981), Latham & Locke (2007), Schunk (1990)]**. The total word count of goal submissions increased dramatically from 1,069 at baseline to 4,855 immediately after the intervention, with subsequent totals remaining substantially above pre-intervention levels. This pattern was mirrored in the mean length of goal statements, which rose from 9.2 words at baseline to 26.2 post-intervention, and continued to grow, reaching 34.9 words by Week 15. Similarly, the mean number of goals per participant increased from 3.1 at baseline to 4.7 post-intervention, and further to 6.4 by Week 15, indicating that students not only elaborated more on their goals but also set more of them over time. Table 2: Student Goal-Setting Metrics Before and After Intervention Metric Pre-Intervention Baseline (Week 3) Post-intervention (Week 3) Post-intervention (Week 8) Post-intervention (Week 11) Post-intervention (Week 15) Number of participants who submitted goals 38 39 36 32 25 Total word count of goal submissions 1069 4855 5706 3538 5556 Total number of goal statements 116 185 171 163 159 Mean length of goal statements (words) 9.2 26.2 33.4 21.7 34.9 Mean number of goals per participant 3.1 4.7 4.8 5.1 6.4 Improvement in Goal Quality: SMART Criteria Analysis of goal statements according to the SMART framework yielded evidence of substantial improvement in goal quality (Table 3 ) **[CITE: Doran (1981), Bjerke & Renger (2017)]**. Prior to the intervention, only 16.38% of goals met all five SMART criteria (SMART-5), while 63% were classified as SMART-0, SMART-1, or SMART-2, indicating vague or incomplete goals. Students may set vague goals when they lack a clear understanding of the learning expectations (McCardle, et al **[CITE: Brady et al **[CITE: Doran (1981), Latham & Locke (2007), Schunk (1990)]**. (2024), Garavalia & Gredler (2002), Kizilcec et al. (2017)]**., 2016). To ensure students understood what they were supposed to learn, we introduced the intended learning outcomes clearly at the beginning of the course **[CITE: Doran (1981), Latham & Locke (2007), Schunk (1990)]**. Thus, a gap between students â€™ internal understanding and their ability to express it with precision can explain the poor quality of their initial goals, a finding supported by McCardle et al (2016). Following the chatbot intervention, the proportion of fully SMART goals (SMART-5) rose sharply to 68.11%, and this improvement was largely sustained or enhanced through Week 15, when 84.28% of goals met all SMART criteria. The proportion of low-quality goals (SMART-0 and SMART-1) dropped precipitously to less than 3% post-intervention and was completely eliminated by Week 15. Following the intervention, the total share of intermediate-level categories (SMART-2 to SMART-4) also declined over time, dropping from 37.07% to 29.19% in week 3 and continuing to fall to 15.73% by week 15, reflecting a shift toward more complete and effective goal statements **[CITE: Doran (1981), Latham & Locke (2007), Schunk (1990)]**. This pattern demonstrates both the immediate and long-term effectiveness of the chatbot intervention in fostering high-quality goal-setting. Table 3: Distribution and Changes in SMART Goals Patterns Before and After Intervention Goals before intervention (week 3) Goals after intervention (week 3) Week 8 Week 11 Week 15 Total number of goals 116 185 171 163 159 Percentage of SMART-0 type 1.72% 0.54% 0.58% 0.00% 0.00% Percentage of SMART-1 type 44.83% 2.16% 2.92% 0.61% 0.00% Percentage of SMART-2 type 16.38% 4.86% 8.19% 3.68% 2.52% Percentage of SMART-3 type 12.93% 6.49% 9.36% 9.20% 6.92% Percentage of SMART-4 type 7.76% 17.84% 14.62% 7.98% 6.29% Percentage of SMART-5 type 16.38% 68.11% 64.33% 78.53% 84.28% Behavioral Engagement with the Chatbot Metrics of behavioral engagement with the chatbot indicated active and substantive student interaction (Table 4 ). 39 students used the goal-setting chatbot to help them make study goals **[CITE: Doran (1981), Latham & Locke (2007), Schunk (1990)]**. On average, students engaged in 11 **[CITE: Doran (1981), Latham & Locke (2007), Schunk (1990)]**.95 utterance turns (SD = 9.27) per chatbot session, with a range from 2 to 46 turns, reflecting variability in the depth of interaction. The word count per student also varied widely (from 2 to 560 words), with a mean of 136.95 (SD = 166.98). The chatbot â€™ s engagement data shows that 20 students engaged with the chatbot within 10 turns. Engagement extended to 30 turns for 16 students, while three students were particularly active, with one achieving 30 turns, another 34, and a third 46. An analysis of user prompt length revealed that 26 students used fewer than 130 words in total, and another 10 stayed between 130 and 500 words. Conversely, three students provided more than 500 words, at 535, 543, and 560, respectively. Table 4: utterance turns and user words N Minimum Maximum Mean Std. Deviation Conversation turns 39 2 46 11.95 9.265 User words 39 2 560 136.95 166.978 Student Perceptions of Usefulness and Ease of Use Students reported highly positive perceptions of both the usefulness and the ease of use of the AI-based chatbot for goal-setting (Table 5 ). All items related to perceived usefulness received mean ratings above 4.3 on a 5-point scale, with the highest ratings for making the goal-setting process easier (M = 4.67, SD = 0.84) and more effective (M = 4 **[CITE: Doran (1981), Latham & Locke (2007), Schunk (1990)]**.62, SD = 0.71). Students also strongly agreed that the chatbot helped them keep making SMART goals in subsequent weeks (M = 4.54, SD = 0.82) and that it was overall useful in their studies (M = 4.38, SD = 0.94). Perceived ease of use was similarly rated highly, with mean values ranging from 4.44 to 4.56. Students found the chatbot easy to use (M = 4 **[CITE: Doran (1981), Latham & Locke (2007), Schunk (1990)]**.56, SD = 0.82), user-friendly (M = 4.49, SD = 0.97), and were able to recover from errors easily (M = 4.44, SD = 0.94). The questionnaire demonstrated high internal reliability (Cronbachâ€™s Î± = 0.962 for usefulness, 0.919 for ease of use). Table 5: Perceived usefulness and ease of use of the goal-setting chatbot Item N Mean(SD) usefulness Using the chatbot helped me to set my goals and study plans. 39 4.51 (.82) Using the chatbot helped me to make SMART goals and plans. 39 4.49 (.85) Using the chatbot helped me to keep making SMART goals and plans during the past weeks. 39 4.54 (.82) The chatbot made the goal-setting process easier. 39 4.67 (.84) The chatbot made the goal-setting process more effective **[CITE: Doran (1981), Latham & Locke (2007), Schunk (1990)]**. 39 4.62 (.71) Overall, the chatbot was useful in my study. 39 4.38 (.94) Ease of use It was easy to use the chatbot. 39 4.56 (.82) The chatbot acted as anticipated. 39 4.44 (.88) Despite encountering errors while using the chatbot, I was able to recover and continue easily. 39 4.44 (.94) Overall, the chatbot was user-friendly. 39 4.49 (.97) Studentsâ€™ perceptions and experiences of chatbot-facilitated goal setting To gain a deeper understanding of studentsâ€™ experiences and perceptions, a thematic analysis (Braun & Clarke, 2006, 2020) was conducted on qualitative data gathered from open-ended surveys and interviews. The analysis followed a structured process of identifying initial codes, grouping them into initial themes, and finally synthesizing them into overarching final themes. This process ensured a comprehensive and nuanced interpretation of student feedback. The resulting themes not only elucidate the qualitative aspects of student engagement but also correlate strongly with the quantitative findings on perceived usefulness and ease of use, providing a multi-faceted view of the chatbot interventions. Four themes emerged as a 


---

### ðŸ“š Detailed Citation Suggestions for this Section:

**1. Effective Goals**
- **Text:** "effective. 39 4.62 (.71) Overall, the chatbot was useful in my study. 39 4.38 (.94) Ease of use It was easy to use the chatbot. 39 4.56 (.82) The chatbot acted as anticipated. 39 4.44 (.88) Despite encountering errors while using the chatbot, I was able to recover and continue easily. 39 4.44 (.94) Overall, the chatbot was user-friendly. 39 4.49 (.97) Studentsâ€™ perceptions and experiences of chatbot-facilitated goal setting"
- **Suggested Citations:** Doran (1981), Latham & Locke (2007), Schunk (1990), Bandura & Schunk (1981), McCardle et al. (2016)
- **Context:** 4) The chatbot made the goal-setting process more effective. 39 4.62 (.71) Overall, the chatbot was ...

**2. Student Goal Setting**
- **Text:** "Students found the chatbot easy to use (M = 4.56, SD = 0.82), user-friendly (M = 4.49, SD = 0.97), and were able to recover from errors easily (M = 4.44, SD = 0.94). The questionnaire demonstrated high internal reliability (Cronbachâ€™s Î± = 0.962 for usefulness, 0.919 for ease of use). Table 5: Perceived usefulness and ease of use of the goal-setting chatbot Item N Mean(SD) usefulness Using the chatbot helped me to set my goals"
- **Suggested Citations:** Doran (1981), Latham & Locke (2007), Schunk (1990), Bandura & Schunk (1981), McCardle et al. (2016)
- **Context:** ghly, with mean values ranging from 4.44 to 4.56. Students found the chatbot easy to use (M = 4.56, ...

**3. Effective Goals**
- **Text:** "effective (M = 4.62, SD = 0.71). Students also strongly agreed that the chatbot helped them keep making SMART goals in subsequent weeks (M = 4.54, SD = 0.82) and that it was overall useful in their studies (M = 4.38, SD = 0.94). Perceived ease of use was similarly rated highly, with mean values ranging from 4.44 to 4.56. Students found the chatbot easy to use (M = 4.56, SD = 0.82), user-friendly (M = 4.49, SD = 0.97), and were able to recover from errors easily (M = 4.44, SD = 0.94). The questionnaire demonstrated high internal reliability (Cronbachâ€™s Î± = 0.962 for usefulness, 0.919 for ease of use). Table 5: Perceived usefulness and ease of use of the goal-setting"
- **Suggested Citations:** Doran (1981), Latham & Locke (2007), Schunk (1990), Bandura & Schunk (1981), McCardle et al. (2016)
- **Context:** ing process easier (M = 4.67, SD = 0.84) and more effective (M = 4.62, SD = 0.71). Students also str...

**4. Student Goal Setting**
- **Text:** "students engaged in 11.95 utterance turns (SD = 9.27) per chatbot session, with a range from 2 to 46 turns, reflecting variability in the depth of interaction. The word count per student also varied widely (from 2 to 560 words), with a mean of 136.95 (SD = 166.98). The chatbot â€™ s engagement data shows that 20 students engaged with the chatbot within 10 turns. Engagement extended to 30 turns for 16 students, while three students were particularly active, with one achieving 30 turns, another 34, and a third 46. An analysis of user prompt length revealed that 26 students used fewer than 130 words in total, and another 10 stayed between 130 and 500 words. Conversely, three students provided more than 500 words, at 535, 543, and 560, respectively. Table 4: utterance turns and user words N Minimum Maximum Mean Std. Deviation Conversation turns 39 2 46 11.95 9.265 User words 39 2 560 136.95 166.978 Student Perceptions of Usefulness and Ease of Use Students reported highly positive perceptions of both the usefulness and the ease of use of the AI-based chatbot for goal-setting (Table 5 ). All items related to perceived usefulness received mean ratings above 4.3 on a 5-point scale, with the highest ratings for making the goal-setting process easier (M = 4.67, SD = 0.84) and more effective (M = 4.62, SD = 0.71). Students also strongly agreed that the chatbot helped them keep making SMART goals"
- **Suggested Citations:** Doran (1981), Latham & Locke (2007), Schunk (1990), Bandura & Schunk (1981), McCardle et al. (2016)
- **Context:** hatbot to help them make study goals. On average, students engaged in 11.95 utterance turns (SD = 9....

**5. Student Goal Setting**
- **Text:** "students used the goal-setting chatbot to help them make study goals"
- **Suggested Citations:** Doran (1981), Latham & Locke (2007), Schunk (1990), Bandura & Schunk (1981), McCardle et al. (2016)
- **Context:** nd substantive student interaction (Table 4 ). 39 students used the goal-setting chatbot to help the...

**6. Effective Goals**
- **Text:** "effective goal statements. This pattern demonstrates both the immediate and long-term effectiveness of the chatbot intervention in fostering high-quality goal-setting"
- **Suggested Citations:** Doran (1981), Latham & Locke (2007), Schunk (1990), Bandura & Schunk (1981), McCardle et al. (2016)
- **Context:** k 15, reflecting a shift toward more complete and effective goal statements. This pattern demonstrat...

**7. Student Goal Setting**
- **Text:** "students understood what they were supposed to learn, we introduced the intended learning outcomes clearly at the beginning of the course. Thus, a gap between students â€™ internal understanding and their ability to express it with precision can explain the poor quality of their initial goals, a finding supported by McCardle et al (2016). Following the chatbot intervention, the proportion of fully SMART goals (SMART-5) rose sharply to 68.11%, and this improvement was largely sustained or enhanced through Week 15, when 84.28% of goals met all SMART criteria. The proportion of low-quality goals (SMART-0 and SMART-1) dropped precipitously to less than 3% post-intervention and was completely eliminated by Week 15. Following the intervention, the total share of intermediate-level categories (SMART-2 to SMART-4) also declined over time, dropping from 37.07% to 29.19% in week 3 and continuing to fall to 15.73% by week 15, reflecting a shift toward more complete and effective goal statements. This pattern demonstrates both the immediate and long-term effectiveness of the chatbot intervention in fostering high-quality goal-setting. Table 3: Distribution and Changes in SMART Goals"
- **Suggested Citations:** Doran (1981), Latham & Locke (2007), Schunk (1990), Bandura & Schunk (1981), McCardle et al. (2016)
- **Context:**  expectations (McCardle, et al., 2016). To ensure students understood what they were supposed to lea...

**8. Learning Outcomes**
- **Text:** "learning expectations (McCardle, et al., 2016). To ensure students understood what they were supposed to learn, we introduced the intended learning outcomes"
- **Suggested Citations:** Brady et al. (2024), Garavalia & Gredler (2002), Kizilcec et al. (2017)
- **Context:** goals when they lack a clear understanding of the learning expectations (McCardle, et al., 2016). To...

**9. Student Goal Setting**
- **Text:** "Students may set vague goals"
- **Suggested Citations:** Doran (1981), Latham & Locke (2007), Schunk (1990), Bandura & Schunk (1981), McCardle et al. (2016)
- **Context:** or SMART-2, indicating vague or incomplete goals. Students may set vague goals when they lack a clea...

**10. Smart Framework**
- **Text:** "SMART Criteria Analysis of goal statements according to the SMART framework"
- **Suggested Citations:** Doran (1981), Bjerke & Renger (2017)
- **Context:**  3.1 4.7 4.8 5.1 6.4 Improvement in Goal Quality: SMART Criteria Analysis of goal statements accordi...

**11. Student Goal Setting**
- **Text:** "students reallocating their focus toward preparing for final examinations in their other courses. The total word count of goal submissions increased dramatically from 1,069 at baseline to 4,855 immediately after the intervention, with subsequent totals remaining substantially above pre-intervention levels. This pattern was mirrored in the mean length of goal statements, which rose from 9.2 words at baseline to 26.2 post-intervention, and continued to grow, reaching 34.9 words by Week 15. Similarly, the mean number of goals per participant increased from 3.1 at baseline to 4.7 post-intervention, and further to 6.4 by Week 15, indicating that students not only elaborated more on their goals but also set more of them over time. Table 2: Student Goal-Setting Metrics Before and After Intervention Metric Pre-Intervention Baseline (Week 3) Post-intervention (Week 3) Post-intervention (Week 8) Post-intervention (Week 11) Post-intervention (Week 15) Number of participants who submitted goals"
- **Suggested Citations:** Doran (1981), Latham & Locke (2007), Schunk (1990), Bandura & Schunk (1981), McCardle et al. (2016)
- **Context:** d decrease in week 15 can likely be attributed to students reallocating their focus toward preparing...




## Results

**ðŸŽ¯ Citation Opportunities Found: 1**

# results
 are promising, this study has limitations that point toward fruitful avenues for future research. The primary limitations concern the study's generalizability. The findings are based on a relatively small sample of first-year engineering students at a single university, which limits their applicability to broader, more diverse populations across different cultural contexts, academic levels, and disciplines. Furthermore, the current research focused exclusively on the goal-setting phase of self-regulated learning. Future work should explore how AI chatbots can be designed to support additional SRL phases, such as monitoring progress, facilitating help-seeking, and guiding self-reflection, to provide more comprehensive learning support **[CITE: Hew et al. (2022), Singh et al. (2019), Ng et al. (2024)]**. Several technical and ethical considerations must also be addressed in future iterations. The potential for AI hallucination necessitates the development of safeguards to ensure the accuracy of the feedback provided. Data privacy is paramount when handling student interactions, and the accessibility of proprietary models remains a barrier for widespread adoption. Future development could explore using retrieval-augmented generation (RAG) to ground the chatbotâ€™s responses in vetted educational materials, improving accuracy and reducing fabrications. Based on student feedback and technological possibilities, several exciting directions emerge for future research. Developing chatbots with memory functions would enable more personalized and context-aware interactions, eliminating the need for students to repeat information. Integrating visual outputs, reminder systems, and community features could significantly enhance usability and motivation. Finally, exploring how the chatbot can be integrated into a broader ecosystem that includes peer and teacher feedback would create a powerful, multi-layered support system for learners. 


---

### ðŸ“š Detailed Citation Suggestions for this Section:

**1. Chatbot Education**
- **Text:** "chatbots can be designed to support additional SRL phases, such as monitoring progress, facilitating help-seeking, and guiding self-reflection, to provide more comprehensive learning"
- **Suggested Citations:** Hew et al. (2022), Singh et al. (2019), Ng et al. (2024), Guan et al. (2024), Wollny et al. (2021)
- **Context:** lated learning. Future work should explore how AI chatbots can be designed to support additional SRL...




## Literature Review

# Literature Review
 on Chatbots in Education. Frontiers in Artificial Intelligence, 4(), . HYPERLINK "https://doi.org/10.3389/frai.2021.654924" https://doi.org/10.3389/frai.2021.654924 Lai, J. (2024). Adapting Self-Regulated Learning in an Age of Generative Artificial Intelligence Chatbots. Future Internet, 16(6), 

## 218. HYPERLINK "https:
//doi.org/10.3390/fi16060218" https://doi.org/10.3390/fi16060218 Terblanche, N., Molyn, J., de, E. & O., V. (2022). Comparing artificial intelligence and human coaching goal attainment efficacy. PLOS ONE, 17(6), e

## 0270255. HYPERLINK "https:
//doi.org/10.1371/journal.pone.0270255" https://doi.org/10.1371/journal.pone.0270255 Raluy, D., & Mislang, R. (2022). Developing learner autonomy and goal-setting through logbooks. Studies in Self-Access Learning Journal, 13(3), 347â€“

## 366. HYPERLINK "https:
//doi.org/10.37237/130304" https://doi.org/10.37237/130304 Guo, K. & Li, D. (2024). Understanding EFL studentsâ€™ use of self-made AI chatbots as personalized writing assistance tools: A mixed 




## Methods

# Methods
 Research ( 3rd ed.). Sage Publications. Wang, S. (2024, August 8). Where to start with generative AI chatbot customization. Times Higher Education. https://www.timeshighereducation.com/campus/where-start-generative-ai chatbot-customisation. Mayer, R. E. (2017). Using multimedia for e-learning. Journal of Computer Assisted Learning, 33(5), 403â€“423.



## Discussion

**ðŸŽ¯ Citation Opportunities Found: 6**

# discussion
 integrates these findings to address the three 

## research questions
, situating them within the broader literature on SRL and educational technology **[CITE: Chang et al. (2013), Scholl et al. (2009), Davis (1989)]**. The Chatbot as an Effective Instructional Scaffold for Acquiring SMART Goal-Setting Skills The most striking finding of this study pertains to the dramatic improvement in the quality of students' self-set goals, directly addressing RQ1 **[CITE: Doran (1981), Latham & Locke (2007), Schunk (1990)]** **[CITE: Doran (1981), Bjerke & Renger (2017)]** **[CITE: Doran (1981), Latham & Locke (2007), Schunk (1990)]**. The quantitative data (Table 3) show a profound shift from vague goals to fully articulated SMART goals, with the proportion of SMART-5 goals rising from 16.38% at baseline to 84.28% to 68.11% immediately after intervention. The figure has risen to 84.28% by Week 15. This was not a transient effect but a sustained change, evidenced by the high-quality goals students continued to set autonomously weeks after the initial intervention **[CITE: Doran (1981), Latham & Locke (2007), Schunk (1990)]**. The qualitative data provide the crucial explanation for this shift: the chatbot functioned as an effective teacher of the SMART framework **[CITE: Doran (1981), Latham & Locke (2007), Schunk (1990)]**. Students reported entering the interaction with only " a n unclear understanding " (Interview, Nie) of effective goal-setting. Through its structured, multi-path designâ€”offering instruction, examples, and, most importantly, iterative feedbackâ€”the chatbot provided clarity on how to formulate SMART goals . As one student noted, it " taught me how to set SMART goals by giving me examples and explaining what SMART goals are. Through interaction and practical exercises, it helped me refine and optimize my goals " (Interview, Huang). This aligns with the principles of multimedia learning (Mayer, 2017), suggesting that the conversational presentation of the material enhanced comprehension and skill acquisition. This finding extends the existing literature on educational goal-setting chatbots. While previous research using rule-based chatbots successfully introduced goal-setting (Hew et al., 2021, 2022; Du et al., 2021), their reliance on multiple-choice options limited the depth of learning and was frequently cited as a limitation by students. Our study demonstrates that an AI-based chatbot, capable of processing open-ended input and generating personalized, constructive feedback, can move beyond mere awareness-raising to facilitate a deeper internalization of complex SRL strategies. It effectively addresses the persistent problem identified by McCardle et al. (2016) and Raluy & Mislang (2022) , where students' goals remain vague even after instruction, by providing a low-stakes, interactive environment for practice and refinement. Facilitating Personalized and Autonomous Learning The study's 


---

### ðŸ“š Detailed Citation Suggestions for this Section:

**1. Effective Goals**
- **Text:** "effective teacher of the SMART framework. Students reported entering the interaction with only " a n unclear understanding " (Interview, Nie) of effective goal-setting"
- **Suggested Citations:** Doran (1981), Latham & Locke (2007), Schunk (1990), Bandura & Schunk (1981), McCardle et al. (2016)
- **Context:** tion for this shift: the chatbot functioned as an effective teacher of the SMART framework. Students...

**2. Student Goal Setting**
- **Text:** "students continued to set autonomously weeks after the initial intervention. The qualitative data provide the crucial explanation for this shift: the chatbot functioned as an effective teacher of the SMART framework. Students reported entering the interaction with only " a n unclear understanding " (Interview, Nie) of effective goal-setting. Through its structured, multi-path designâ€”offering instruction, examples, and, most importantly, iterative feedbackâ€”the chatbot provided clarity on how to formulate SMART goals"
- **Suggested Citations:** Doran (1981), Latham & Locke (2007), Schunk (1990), Bandura & Schunk (1981), McCardle et al. (2016)
- **Context:** ained change, evidenced by the high-quality goals students continued to set autonomously weeks after...

**3. Student Goal Setting**
- **Text:** "students' self-set goals"
- **Suggested Citations:** Doran (1981), Latham & Locke (2007), Schunk (1990), Bandura & Schunk (1981), McCardle et al. (2016)
- **Context:** ins to the dramatic improvement in the quality of students' self-set goals, directly addressing RQ1....

**4. Smart Framework**
- **Text:** "SMART Goal-Setting Skills The most striking finding of this study pertains to the dramatic improvement in the quality of students' self-set goals, directly addressing RQ1. The quantitative data (Table 3) show a profound shift from vague goals to fully articulated SMART goals, with the proportion of SMART-5 goals rising from 16.38% at baseline to 84.28% to 68.11% immediately after intervention. The figure has risen to 84.28% by Week 15. This was not a transient effect but a sustained change, evidenced by the high-quality goals students continued to set autonomously weeks after the initial intervention. The qualitative data provide the crucial explanation for this shift: the chatbot functioned as an effective teacher of the SMART framework"
- **Suggested Citations:** Doran (1981), Bjerke & Renger (2017)
- **Context:** an Effective Instructional Scaffold for Acquiring SMART Goal-Setting Skills The most striking findin...

**5. Effective Goals**
- **Text:** "Effective Instructional Scaffold for Acquiring SMART Goal-Setting"
- **Suggested Citations:** Doran (1981), Latham & Locke (2007), Schunk (1990), Bandura & Schunk (1981), McCardle et al. (2016)
- **Context:** SRL and educational technology. The Chatbot as an Effective Instructional Scaffold for Acquiring SMA...

**6. Ed Tech**
- **Text:** "educational technology"
- **Suggested Citations:** Chang et al. (2013), Scholl et al. (2009), Davis (1989)
- **Context:** ing them within the broader literature on SRL and educational technology. The Chatbot as an Effectiv...




## Conclusion

**ðŸŽ¯ Citation Opportunities Found: 1**

# conclusion
, this study makes a significant contribution to the field of AI-driven educational support by demonstrating the efficacy of a customized chatbot in improving the quality of students' self-set learning goals **[CITE: Doran (1981), Latham & Locke (2007), Schunk (1990)]**. The research provides robust evidence that an AI chatbot can serve as an effective instructional scaffold, making the process of learning to set SMART goals more manageable, motivating, and effective. The mixed-


---

### ðŸ“š Detailed Citation Suggestions for this Section:

**1. Student Goal Setting**
- **Text:** "students' self-set learning goals"
- **Suggested Citations:** Doran (1981), Latham & Locke (2007), Schunk (1990), Bandura & Schunk (1981), McCardle et al. (2016)
- **Context:**  a customized chatbot in improving the quality of students' self-set learning goals. The research pr...



