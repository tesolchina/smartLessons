# Talk Outline: Flipped Classroom 2.0 — AI as a Force Multiplier

Date: 2025-09-18
Audience: HKBU colleagues (Language Centre / GE)
Presenter: Dr Simon Wang

---

## Objectives

- Share key messages on the evolution of flipped learning (2017 → now)
- Demonstrate practical AI tooling with minimal setup: AI video, streaming avatars, vibe coding
- Provide an adoption roadmap colleagues can follow next week
- Invite collaborators to join a pilot cohort and co-design concrete workflows

## Key Messages (arguments)

1. Time-to-teach is collapsing: AI reduces video prep from hours to minutes without sacrificing clarity or quality for most content types
2. Streaming avatars create scalable support: Q&A, pronunciation models, and practice partners without extra staff hours
3. Vibe coding lowers the barrier: you can prototype useful teaching widgets through natural-language collaboration with AI
4. Pedagogy first: align with learning outcomes; use AI as a scaffold, not a replacement for teaching judgement

## Narrative Arc

- 2017 SCMP letter: rationale for flexible attendance and flipped learningLink: https://www.scmp.com/comment/letters/article/2109347/relaxed-attendance-rules-hong-kongs-baptist-university-will-improve
- Today’s constraints: time costs, tooling friction, inconsistent production, learner variability
- The AI toolkit:
  - AI video generation (HeyGen)
  - Streaming avatars for just-in-time support
  - Vibe coding for custom micro-tools (e.g., quiz widgets)
- Tie tools to outcomes: comprehension checks, feedback loops, student readiness
- Roadmap + invitation: make it real this semester

## Timing Plan (45–60 minutes)

- Intro + context: 5–7 min
- Why now (evidence + pain points): ~5 min
- Demo 1: AI Video (HeyGen): 10–12 min
- Demo 2: Streaming Avatars: 8–10 min
- Demo 3: Vibe Coding: 10–12 min
- Roadmap + Q&A + invitation: 7–10 min

## Live Demo Plan (how we demonstrate the tech)

- AI Video (HeyGen):
  - Prompt → generate a 60–90s micro-lecture
  - Emphasize speed, voice/brand consistency, captions
- Streaming Avatar:
  - Scripted scenario (FAQ) + a live Q&A turn
  - Highlight language practice and office-hours relief
- Vibe Coding:
  - Evolve a quiz widget from a plain-English spec
  - Show quick iteration: requirements → working prototype → small refinements

## Adoption Roadmap (practical steps)

- Week 1–2: Produce one AI micro-lecture; collect baseline prep time; deploy to a small group for feedback
- Month 1: Add avatar Q&A; pilot the quiz widget; gather student engagement and accuracy data
- Semester: Integrate with LMS; scale across topics; share best practices and assets with colleagues

## Success Metrics

- Prep time reduction per lecture (target ≥ 60%)
- Student completion and engagement for pre-class materials
- In-class readiness (quiz accuracy, reduced remedial time)
- Colleague adoption; cross-course reuse of assets

## Risks & Mitigations

- Quality drift → quick rubric + faculty review loop
- Over-automation → keep a human voice; use AI for scaffolding, not judgement
- Access/ethics → transparent labeling; minimal data footprints; align with institutional guidelines

## Invitation to Colleagues (CTA)

- Join a small pilot cohort to co-design practical AI workflows for our courses
- Contribute 1–2 micro-lectures and one activity; share outcomes and tips
- Optional: showcase session mid-semester

## Resources

- Workshop modules in this repo (Overview, AI Video, Streaming Avatars, Vibe Coding, Time Reflection, Implementation, Resources)
- Poster: `docs/poster.jpg`
- Notes and references: `docs/note.md`

## Prep Checklist (for presenter)

- Draft micro-lecture prompt and expected learning outcome
- Prepare one avatar scenario and a sample Q&A question
- Outline a simple quiz widget spec for the vibe coding demo
- Confirm access/logins and network

---

Notes to self:

- Keep explanations short; prioritize live showing over telling
- Ask for 1–2 volunteers to try an avatar Q&A turn
- Collect names for the pilot cohort before end of session
